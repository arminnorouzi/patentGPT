<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005301A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005301</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17783760</doc-number><date>20201217</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-230599</doc-number><date>20191220</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>60</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>74</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>16</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>33</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>60</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>74</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>172</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>33</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">CONTROL APPARATUS, CONTROL METHOD, AND NON-TRANSITORY COMPUTER READABLE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NEC Corporation</orgname><address><city>Minato-ku, Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Aoyagi</last-name><first-name>Toru</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>NEC Corporation</orgname><role>03</role><address><city>Minato-ku, Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/047162</doc-number><date>20201217</date></document-id><us-371c12-date><date>20220609</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A control apparatus (<b>2000</b>) acquires a certificate image (<b>30</b>) being an image of an identification card. The control apparatus (<b>2000</b>) outputs screen data (<b>70</b>) of a screen (<b>60</b>) including the certificate image (<b>30</b>). The control apparatus (<b>2000</b>) acquires a user image (<b>50</b>) generated by capturing an image performed in a state where the screen (<b>60</b>) is displayed.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="101.77mm" wi="140.04mm" file="US20230005301A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="217.93mm" wi="140.12mm" orientation="landscape" file="US20230005301A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="112.01mm" wi="110.15mm" file="US20230005301A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="142.66mm" wi="139.28mm" file="US20230005301A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="91.19mm" wi="129.12mm" file="US20230005301A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="200.24mm" wi="87.21mm" orientation="landscape" file="US20230005301A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="128.78mm" wi="129.29mm" file="US20230005301A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="203.37mm" wi="122.09mm" file="US20230005301A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="129.29mm" wi="111.68mm" file="US20230005301A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="129.29mm" wi="112.86mm" file="US20230005301A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="212.94mm" wi="122.26mm" orientation="landscape" file="US20230005301A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present invention relates to personal identification using an identification card.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">When opening a bank account, creating a credit card, or the like, personal identification using an identification card is performed. Then, as in a case of opening an account or the like via the Internet, and the like, an image acquired by capturing an identification card by a camera, instead of an original of the identification card, may be used for personal identification.</p><p id="p-0004" num="0003">There is Patent Document 1 as a related document relating to personal identification using an image of an identification card. Patent Document 1 discloses a system for confirming that a personal identification document is of a user by comparing capturing data about a face photograph of the personal identification document with capturing data about the user.</p><p id="p-0005" num="0004">In addition, in the system according to Patent Document 1, in order to acquire an image of a plurality of surfaces of a personal identification document (identification card), a moving image capturing the personal identification document is generated, while issuing an instruction such as &#x201c;please capture a front surface of a personal identification document&#x201d; or &#x201c;please capture a back surface of a personal identification document&#x201d; on a user terminal. Then, the moving image is transmitted to an authentication server.</p><heading id="h-0003" level="1">RELATED DOCUMENT</heading><heading id="h-0004" level="1">Patent Document</heading><p id="p-0006" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0005">[Patent Document 1] Japanese Patent No. 6541140</li></ul></p><heading id="h-0005" level="1">DISCLOSURE OF THE INVENTION</heading><heading id="h-0006" level="1">Technical Problem</heading><p id="p-0007" num="0006">The inventor of the present invention has developed a new technique for performing personal identification by using an image of an identification card and an image of a user. One of objects of the present invention is to provide a new technique for performing personal identification by using an image of an identification card and an image of a user.</p><heading id="h-0007" level="1">Solution to Problem</heading><p id="p-0008" num="0007">A control apparatus according to the present invention includes 1) a first acquisition unit that acquires a certificate image being an image of an identification card, 2) a screen data output unit that outputs screen data of a first screen including the certificate image, and 3) a second acquisition unit that acquires an image of a user being generated by capturing an image performed in a state where the first screen is displayed.</p><p id="p-0009" num="0008">A control method according to the present invention is executed by a computer. The control method includes 1) a first acquisition step of acquiring a certificate image being an image of an identification card, 2) a screen data output step of outputting screen data of a first screen including the certificate image, and 3) a second acquisition step of acquiring an image of a user being generated by capturing an image performed in a state where the first screen is displayed.</p><heading id="h-0008" level="1">Advantageous Effects of Invention</heading><p id="p-0010" num="0009">According to the present invention, a new technique for performing personal identification by using an image of an identification card and an image of a user is provided.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram for describing an outline of a control apparatus according to an example embodiment 1.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating a functional configuration of the control apparatus according to the example embodiment 1.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating a computer for achieving the control apparatus.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating a flow of processing executed by the control apparatus according to the example embodiment 1.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating a usage environment of the control apparatus.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating a flow of personal identification of a user.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating a screen displayed on a display apparatus by an application when causing a user to capture an image of an identification card.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating a screen for capturing an image of a user's face.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating a screen for performing biometric detection for a user.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating a screen for performing confirmation of a thickness of an identification card.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0021" num="0020">Hereinafter, an example embodiment of the present invention will be described with reference to the drawings. Note that, in all the drawings, a similar component is denoted by a similar reference sign, and description thereof is not repeated as appropriate. In addition, except for a case described in particular, in each block diagram, each block represents a configuration of a functional unit, not a configuration of a hardware unit. In the following description, various predetermined values (threshold values or the like) are stored in advance in a storage apparatus being accessible from a functional component unit that uses the values, unless otherwise described.</p><heading id="h-0011" level="1">Example Embodiment 1</heading><heading id="h-0012" level="2">&#x3c;Overview&#x3e;</heading><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram for describing an outline of a control apparatus <b>2000</b> according to the present example embodiment. Note that, <figref idref="DRAWINGS">FIG. <b>1</b></figref> is an example for facilitating understanding of the control apparatus <b>2000</b>, and a function of the control apparatus <b>2000</b> is not limited to that illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0023" num="0022">The control apparatus <b>2000</b> acquires data used for personal identification of a user <b>10</b>. Specifically, the control apparatus <b>2000</b> acquires a user image <b>50</b> and a certificate image <b>30</b>. The user image <b>50</b> is an image generated by capturing an image of the user <b>10</b>. The certificate image <b>30</b> is an image generated by capturing an image of a face of an identification card <b>20</b>. The identification card <b>20</b> is any certificate that can be used for certificating a person's identity. For example, the identification card <b>20</b> is a driver's license, another license, a national identification number card, a passport, various certificates, a student's certificate, a company's identification card, an insurance card, or the like. However, it is preferable that a face image of a certified person (a person whose identity is certified by the identification card <b>20</b>) is displayed on the face of the identification card <b>20</b>. Note that, in the following description, a surface on which a face image of a certified person is displayed between faces of the identification card <b>20</b> is referred to as a main surface. In addition, the other surface is referred to as a back surface.</p><p id="p-0024" num="0023">The control apparatus <b>2000</b> acquires the certificate image <b>30</b> prior to the user image <b>50</b>. The certificate image <b>30</b> is generated, for example, by a camera <b>44</b> controllable by a terminal (user terminal <b>40</b>) used by a user. The camera <b>44</b> may be incorporated in the user terminal <b>40</b>, or may be externally attached to the user terminal <b>40</b>. Note that, the control apparatus <b>2000</b> may be achieved as the user terminal <b>40</b>, or may be achieved as another apparatus (e.g., a server machine) that acquires data from the user terminal <b>40</b>. In the example in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the control apparatus <b>2000</b> is achieved as an apparatus being separate from the user terminal <b>40</b>.</p><p id="p-0025" num="0024">After acquiring the certificate image <b>30</b>, the control apparatus <b>2000</b> outputs a screen data <b>70</b> of a screen <b>60</b> on which an image of the user <b>10</b> is to be captured. The screen data <b>70</b> may be the screen <b>60</b> itself, or may be data for generating the screen <b>60</b>.</p><p id="p-0026" num="0025">The screen <b>60</b> includes the certificate image <b>30</b>. The screen <b>60</b> is displayed on a display apparatus <b>42</b> controllable by the user terminal <b>40</b>. Note that, the display apparatus <b>42</b> may be incorporated in the user terminal <b>40</b>, or may be externally attached to the user terminal <b>40</b>.</p><p id="p-0027" num="0026">In a state where the screen <b>60</b> is displayed on the display apparatus <b>42</b>, the user <b>10</b> captures an image of the user <b>10</b> by using the camera <b>44</b> provided in the user terminal <b>40</b>. Thus, the user image <b>50</b> is generated by the camera <b>44</b>. The user image <b>50</b> preferably includes at least a face of the user <b>10</b>. The control apparatus <b>2000</b> acquires the user image <b>50</b> generated by the camera <b>44</b>.</p><heading id="h-0013" level="2">&#x3c;One Example of Advantageous Effect&#x3e;</heading><p id="p-0028" num="0027">According to the control apparatus <b>2000</b> of the present example embodiment, when causing the user <b>10</b> to capturing an image of himself/herself for personal identification, the certificate image <b>30</b> being an image of a face of the identification card <b>20</b> is displayed on the display apparatus <b>42</b> of the user terminal <b>40</b> used by the user <b>10</b>. According to such a display, the user <b>10</b> captures his/her own image while viewing the image of the identification card <b>20</b> which has been declared to be his/her own. Therefore, when the user <b>10</b> is trying to illegally use the identification card <b>20</b> of another person, the user <b>10</b> has to capture his/her own image while viewing the image of the identification card <b>20</b> of the another person, and it is conceivable that the user <b>10</b> feels psychological resistance. Therefore, according to the control apparatus <b>2000</b> of the present example embodiment, it is possible to reduce possibility that a user illegally uses the identification card <b>20</b>.</p><p id="p-0029" num="0028">Hereinafter, the present example embodiment will be described in further detail.</p><heading id="h-0014" level="2">&#x3c;Example of Functional Configuration&#x3e;</heading><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating a functional configuration of the control apparatus <b>2000</b> according to the example embodiment 1. The control apparatus <b>2000</b> includes a first acquisition unit <b>2020</b>, a screen data output unit <b>2040</b>, and a second acquisition unit <b>2060</b>. The first acquisition unit <b>2020</b> acquires the certificate image <b>30</b>. The screen data output unit <b>2040</b> outputs the screen data <b>70</b> representing the screen <b>60</b>. The second acquisition unit <b>2060</b> acquires the user image <b>50</b>. Generation of the user image <b>50</b> (capturing an image of the user <b>10</b>) is performed in a state where the screen <b>60</b> is displayed on the display apparatus <b>42</b>.</p><heading id="h-0015" level="2">&#x3c;Example of Hardware Configuration of Control Apparatus <b>2000</b>&#x3e;</heading><p id="p-0031" num="0030">Each functional component unit of the control apparatus <b>2000</b> may be achieved by hardware (e.g., a hard-wired electronic circuit, or the like) that achieves each functional component unit, or may be achieved by a combination of hardware and software (e.g., a combination of an electronic circuit and a program that controls the electronic circuit, or the like). Hereinafter, a case where each functional component unit of the control apparatus <b>2000</b> is achieved by a combination of hardware and software will be further described.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating a computer <b>1000</b> for achieving the control apparatus <b>2000</b>. The computer <b>1000</b> is any computer. For example, the computer <b>1000</b> is a portable computer such as a smartphone or a tablet terminal. In addition, for example, the computer <b>1000</b> may be a stationary computer such as a personal computer (PC) or a server machine.</p><p id="p-0033" num="0032">The computer <b>1000</b> may be a dedicated computer designed to achieve the control apparatus <b>2000</b>, or may be a general-purpose computer. In the latter case, for example, a function of the control apparatus <b>2000</b> is achieved in the computer <b>1000</b> by installing a predetermined application (an application <b>100</b> to be described later) with respect to the computer <b>1000</b>. The application described above is configured by a program for achieving each functional component unit of the control apparatus <b>2000</b>.</p><p id="p-0034" num="0033">The computer <b>1000</b> includes a bus <b>1020</b>, a processor <b>1040</b>, a memory <b>1060</b>, a storage device <b>1080</b>, an input/output interface <b>1100</b>, and a network interface <b>1120</b>. The bus <b>1020</b> is a data transmission path through which the processor <b>1040</b>, the memory <b>1060</b>, the storage device <b>1080</b>, the input/output interface <b>1100</b>, and the network interface <b>1120</b> mutually transmit and receive data. However, a method of connecting the processors <b>1040</b> and the like to each other is not limited to bus connection.</p><p id="p-0035" num="0034">The processor <b>1040</b> is various processors such as a central processing unit (CPU), a graphics processing unit (GPU), and a field-programmable gate array (FPGA). The memory <b>1060</b> is a main storage apparatus achieved by using a random access memory (RAM) or the like. The storage device <b>1080</b> is an auxiliary storage apparatus achieved by using a hard disk, a solid state drive (SSD), a memory card, a read only memory (ROM), or the like.</p><p id="p-0036" num="0035">The input/output interface <b>1100</b> is an interface for connecting the computer <b>1000</b> and an input/output device. For example, an input apparatus such as a keyboard and an output apparatus such as a display apparatus are connected to the input/output interface <b>1100</b>. When the control apparatus <b>2000</b> is achieved by the user terminal <b>40</b>, the display apparatus <b>42</b> and the camera <b>44</b> are connected to the input/output interface <b>1100</b>.</p><p id="p-0037" num="0036">The network interface <b>1120</b> is an interface for connecting the computer <b>1000</b> to a communication network. The communication network is, for example, a local area network (LAN) or a wide area network (WAN).</p><p id="p-0038" num="0037">The storage device <b>1080</b> stores a program module (program module for achieving the above-described application) for achieving each functional component unit of the control apparatus <b>2000</b>. The processor <b>1040</b> achieves a function associated with each program module by reading each program module into the memory <b>1060</b> and executing the problem module.</p><heading id="h-0016" level="2">&#x3c;Regarding User Terminal <b>40</b>&#x3e;</heading><p id="p-0039" num="0038">The user terminal <b>40</b> is any terminal operated by the user <b>10</b>. When the control apparatus <b>2000</b> is achieved by an apparatus other than the user terminal <b>40</b>, the user terminal <b>40</b> has the hardware configuration illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, for example, similarly to the control apparatus <b>2000</b>.</p><heading id="h-0017" level="2">&#x3c;Flow of Processing&#x3e;</heading><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating a flow of processing executed by the control apparatus <b>2000</b> according to the example embodiment <b>1</b>. The first acquisition unit <b>2020</b> acquires the certificate image <b>30</b> (S<b>102</b>). The screen data output unit <b>2040</b> outputs the screen data <b>70</b> (S<b>104</b>). The second acquisition unit <b>2060</b> acquires the user image <b>50</b> (S<b>106</b>).</p><heading id="h-0018" level="2">&#x3c;Acquisition of Certificate Image <b>30</b>: S<b>102</b>&#x3e;</heading><p id="p-0041" num="0040">The first acquisition unit <b>2020</b> acquires the certificate image <b>30</b> (S<b>102</b>). A method of acquiring the certificate image <b>30</b> by the first acquisition unit <b>2020</b> is various methods. For example, the first acquisition unit <b>2020</b> receives the certificate image <b>30</b> transmitted from an apparatus generating the certificate image <b>30</b>. In addition, for example, the first acquisition unit <b>2020</b> accesses an apparatus generating the certificate image <b>30</b>, and acquires the certificate image <b>30</b> stored in the apparatus.</p><p id="p-0042" num="0041">Note that, the certificate image <b>30</b> may be stored, by an apparatus generating the certificate image <b>30</b>, in a storage apparatus provided outside the apparatus. In this case, the first acquisition unit <b>2020</b> accesses the storage apparatus, and acquires the certificate image <b>30</b>.</p><heading id="h-0019" level="2">&#x3c;Regarding Generation of Certificate Image <b>30</b>&#x3e;</heading><p id="p-0043" num="0042">The certificate image <b>30</b> is generated by capturing an image of a face of the identification card <b>20</b>. When generating the certificate image <b>30</b>, it is preferable to capture an image of the identification card <b>20</b> in a state where the main surface of the identification card <b>20</b> is viewed in plan. In other words, it is preferable that the certificate image <b>30</b> is an image including the identification card <b>20</b> whose main surface is viewed in plan. However, the certificate image <b>30</b> may include the main surface of the identification card <b>20</b>, and is not limited to the one in which the main surface is viewed in plan.</p><p id="p-0044" num="0043">The certificate image <b>30</b> is generated by any capturing apparatus capable of capturing an image of the identification card <b>20</b>. For example, the certificate image <b>30</b> is generated by capturing an image of the identification card <b>20</b> with the camera <b>44</b> provided in the user terminal <b>40</b>. In addition, for example, the certificate image <b>30</b> may be generated by scanning the identification card <b>20</b> with a scanner. Note that, the certificate image <b>30</b> does not necessarily have to be generated in a flow of a procedure for personal identification, and may be stored in advance in a storage apparatus. In this case, for example, the user <b>10</b> uses the user terminal <b>40</b> to select an image to be used as the certificate image <b>30</b> from images stored in advance in a storage apparatus, and thereby provides the certificate image <b>30</b> to the control apparatus <b>2000</b>.</p><heading id="h-0020" level="2">&#x3c;Output of Screen Data <b>70</b>: S<b>104</b>&#x3e;</heading><p id="p-0045" num="0044">The screen data output unit <b>2040</b> outputs the screen data <b>70</b> (S<b>104</b>). The screen data <b>70</b> are screen data representing the screen <b>60</b>. The screen <b>60</b> is a screen for capturing an image of the user <b>10</b> (generating the user image <b>50</b>). In addition, the screen <b>60</b> includes the certificate image <b>30</b>. For example, the screen data output unit <b>2040</b> acquires template data of the screen data <b>70</b> prepared in advance and the certificate image <b>30</b> acquired by the first acquisition unit <b>2020</b>. Then, the screen data output unit <b>2040</b> combines the certificate image <b>30</b> and the template data, and thereby generates the screen data <b>70</b>. Note that, an existing technique can be used as a technique for generating screen data of a screen including an image acquired from the outside, by combining a template of screen data and the image.</p><p id="p-0046" num="0045">The screen data output unit <b>2040</b> outputs the generated screen data <b>70</b>, and thereby displays the screen <b>60</b> on the display apparatus <b>42</b>. As described above, the screen data <b>70</b> may be the screen <b>60</b> itself, or may be data for generating the screen <b>60</b>. The data for generating the screen <b>60</b> are, for example, a combination of a piece of data of each text or an image included in the screen <b>60</b> and a piece of format data (e.g., HTML file) representing an arrangement of the text or image. In the latter case, the screen <b>60</b> is generated by performing processing for generating the screen <b>60</b> (e.g., processing for rendering an HTML file) on the screen data <b>70</b>.</p><p id="p-0047" num="0046">When the control apparatus <b>2000</b> is achieved by the user terminal <b>40</b>, the screen data output unit <b>2040</b> outputs the screen <b>60</b> to the display apparatus <b>42</b>. Herein, when the screen data <b>70</b> are data for generating the screen <b>60</b>, the screen data output unit <b>2040</b> generates the screen <b>60</b> from the screen data <b>70</b>, and outputs the generated screen <b>60</b> to the display apparatus <b>42</b>.</p><p id="p-0048" num="0047">On the other hand, when the control apparatus <b>2000</b> is achieved by an apparatus other than the user terminal <b>40</b>, the screen data output unit <b>2040</b> outputs the screen data <b>70</b> to the user terminal <b>40</b>. The user terminal <b>40</b> receiving the screen data <b>70</b> outputs the screen <b>60</b> to the display apparatus <b>42</b>.</p><p id="p-0049" num="0048">Herein, when the received screen data <b>70</b> are data for generating the screen <b>60</b>, the user terminal <b>40</b> generates the screen <b>60</b> from the screen data <b>70</b>, and outputs the generated screen <b>60</b> to the display apparatus <b>42</b>.</p><heading id="h-0021" level="2">&#x3c;Acquisition of User Image <b>50</b>: S<b>106</b>&#x3e;</heading><p id="p-0050" num="0049">The second acquisition unit <b>2060</b> acquires the user image <b>50</b>. A method of acquiring the user image <b>50</b> by the second acquisition unit <b>2060</b> is various methods. For example, the second acquisition unit <b>2060</b> receives the user image <b>50</b> transmitted from the camera <b>44</b>. In addition, for example, the second acquisition unit <b>2060</b> accesses the camera <b>44</b>, and acquires the user image <b>50</b> stored in the camera <b>44</b>. In addition, when the camera <b>44</b> stores the user image <b>50</b> in an external storage apparatus, the second acquisition unit <b>2060</b> acquires the user image <b>50</b> from the storage apparatus.</p><heading id="h-0022" level="2">&#x3c;Specific Example of Using Control Apparatus <b>2000</b>&#x3e;</heading><p id="p-0051" num="0050">Hereinafter, a specific method of using the control apparatus <b>2000</b> will be exemplified. However, the method of using the control apparatus <b>2000</b> is not limited to that described herein.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating a usage environment of the control apparatus <b>2000</b>. In this example, the control apparatus <b>2000</b> is achieved by the user terminal <b>40</b>. The user terminal <b>40</b> is, for example, a smart phone provided with the camera <b>44</b>.</p><p id="p-0053" num="0052">The user <b>10</b> uses the user terminal <b>40</b>, and thereby performs a procedure in which personal identification is required (e.g., opening a bank account). To do so, the user <b>10</b> uses the user terminal <b>40</b>, and thereby provides a server machine <b>80</b> with various data necessary for personal identification.</p><p id="p-0054" num="0053">An application <b>100</b> for causing the user terminal <b>40</b> to function as the control apparatus <b>2000</b> is installed in the user terminal <b>40</b>. The user <b>10</b> starts the application <b>100</b> to perform a procedure. As described below, the application <b>100</b> controls a procedure performed by the user <b>10</b> by changing a screen displayed on the display apparatus <b>42</b> in response to a user input and a processing result in the server machine <b>80</b>.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating a flow of personal identification of the user <b>10</b>. The personal identification of the user <b>10</b> is performed in a flow of capturing an image of a main surface of the identification card <b>20</b> (S<b>202</b>), capturing an image of a back surface of the identification card <b>20</b> (S<b>204</b>), capturing an image of a face of the user <b>10</b> (S<b>208</b>), biometric detection (S<b>210</b>), and confirming a thickness of the identification card <b>20</b> (S<b>212</b>). Hereinafter, each will be described.</p><heading id="h-0023" level="2">&#x3c;&#x3c;Capturing an Image of the Identification Card <b>20</b>: S<b>202</b>, S<b>204</b>&#x3e;&#x3e;</heading><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating a screen displayed on the display apparatus <b>42</b> by the application <b>100</b> when the user <b>10</b> captures an image of the identification card <b>20</b>. A screen <b>110</b> is a screen for capturing an image of the main surface of the identification card <b>20</b>. A screen <b>120</b> is a screen for capturing an image of the back surface of the identification card <b>20</b>.</p><p id="p-0057" num="0056">An image generated by the camera <b>44</b> is displayed in real time in a display area <b>114</b> of the screen <b>110</b>. The user <b>10</b> views the screen <b>110</b>, confirms that an image of the main surface of the identification card <b>20</b> is correctly captured, and presses an image capturing button <b>112</b>. As a result, an image generated by the camera <b>44</b> at a timing when the image capturing button <b>112</b> is pressed is stored in a storage apparatus of the user terminal <b>40</b> as an image (i.e., the certificate image <b>30</b>) of the main surface of the identification card <b>20</b>.</p><p id="p-0058" num="0057">Note that, an image of the main surface of the identification card <b>20</b> may be automatically captured without providing the image capturing button <b>112</b> on the screen <b>110</b>. For example, the camera <b>44</b> repeatedly captures an image from the time when the screen <b>110</b> is displayed, and generates a plurality of images. The application <b>110</b> determines a degree of image quality of each of the generated images, and when an image whose image quality is equal to or higher than a threshold value is detected, the application <b>110</b> stores the image in the storage apparatus of the user terminal <b>40</b> as an image of the main surface of the identification card <b>20</b>.</p><p id="p-0059" num="0058">As an index indicating a degree of image quality, reducing of defocusing and blurring, or the like can be used. Note that, an existing technique can be used as a technique for determining a degree of image quality of an image, based on reducing of defocusing and blurring, or the like.</p><p id="p-0060" num="0059">In addition, the application <b>110</b> may determine whether the entire identification card <b>20</b> is included in an image, in addition to a degree of image quality. In this case, when an image satisfying a condition that &#x201c;image quality is equal to or higher than a threshold value, and the entire identification card <b>20</b> is included&#x201d; is detected from an image generated by the camera <b>44</b>, the application <b>110</b> stores the image in the storage apparatus of the user terminal <b>40</b> as an image of the main surface of the identification card <b>20</b>.</p><p id="p-0061" num="0060">An existing technique can be used as a technique for determining whether an image includes a predetermined object. For example, when an object having a shape similar to a predetermined shape of the identification card <b>20</b> is detected from an image, the application <b>110</b> determines that the entire identification card <b>20</b> is included in the image.</p><p id="p-0062" num="0061">In addition, it is preferable that an image of the main surface of the identification card <b>20</b> includes the identification card <b>20</b> in a size equal to or larger than a certain size. Therefore, a condition such as &#x201c;a ratio of an image area representing the identification card <b>20</b> to the entire image is equal to or larger than a threshold value&#x201d; may be further added to a condition for handling an image as the image of the main surface of the identification card <b>20</b>.</p><p id="p-0063" num="0062">When capturing an image of the main surface of the identification card <b>20</b> is completed, the application <b>100</b> changes a screen displayed on the display apparatus <b>42</b> from the screen <b>110</b> to the screen <b>120</b>. The user <b>10</b> captures an image of the back surface of the identification card <b>20</b> by similar operation to an operation on the screen <b>110</b>. As a result, the image of the back surface of <b>20</b> is also stored in the storage apparatus of the user terminal <b>40</b>. Herein, an image capturing button <b>122</b> may also not be provided on the screen <b>120</b>, and an image of the back surface of the identification card <b>20</b> may be automatically captured. The specific method is similar to the above-described method in which an image of the main surface of the identification card <b>20</b> is automatically captured.</p><p id="p-0064" num="0063">The application <b>100</b> transmits images of the main surface and the back surface of the identification card <b>20</b> stored in the storage apparatus to the server machine <b>80</b>. The server machine <b>80</b> performs processing for extracting necessary information from the image of the main surface and the image of the back surface of the identification card <b>20</b>. For example, the server machine <b>80</b> performs optical character recognition (OCR) processing on the image of the main surface of the identification card <b>20</b>, and thereby extracts various pieces of character information (e.g., a name and an address of the user <b>10</b>, identification information attached to the identification card <b>20</b>, and the like). In addition, the server machine <b>80</b> extracts an image of a person (hereinafter, a person image) from the image of the main surface of the identification card <b>20</b>. Similarly, the server machine <b>80</b> extracts various pieces of information from the image of the back surface of the identification card <b>20</b>.</p><p id="p-0065" num="0064">Each of pieces of processing described above may be performed by the application <b>100</b>. In this case, the application <b>100</b> transmits each piece of information extracted from an image of the identification card <b>20</b> to the server machine <b>80</b> together with an image of the identification card <b>20</b> or instead of the image of the identification card <b>20</b>.</p><p id="p-0066" num="0065">In addition, the application <b>100</b> may check whether capturing an image of the identification card <b>20</b> has been correctly performed, by extracting the above-described information. At this time, when necessary information cannot be extracted from the image of the identification card <b>20</b>, the application <b>100</b> may display the screen <b>110</b> or the screen <b>120</b> again on the display apparatus <b>42</b> together with a message instructing in such a way as to restart photographing, and cause the user <b>10</b> to capture an image of the identification card <b>20</b> again.</p><p id="p-0067" num="0066">Alternatively, the application <b>100</b> may accept input of personal information such as a name or the like from the user <b>10</b> separately, and check whether the information input by the user <b>10</b> matches information acquired from an image of the identification card <b>20</b>. The check may be performed by the application <b>100</b>, or may be performed by the server machine <b>80</b>. In addition, for example, the application <b>100</b> may display information such as a name extracted from the image of the identification card <b>20</b> on the display apparatus <b>42</b>, and cause the user <b>10</b> to be able to correct an erroneous portion. The processing can be performed at any timing after an image of the identification card <b>20</b> is captured (e.g., after an image of the back surface of the identification card <b>20</b> is captured, after a thickness of the identification card <b>20</b> is confirmed, or the like).</p><p id="p-0068" num="0067">Herein, capturing an image of the identification card <b>20</b> separately from the user <b>10</b> in this manner has an advantage that a labor of the user <b>10</b> can be reduced and an advantage that a high-quality image can be acquired. When the user <b>10</b> is caused to simultaneously capture an image of both the user <b>10</b> and the identification card <b>20</b>, the user <b>10</b> has to adjust an angle and the like of the identification card <b>20</b> and the camera <b>44</b> in such a way that both the user <b>10</b> and the identification card <b>20</b> are correctly captured by the camera <b>44</b>. Thus, a labor of the user <b>10</b> required for capturing an image increases. Also, capturing an image may not be successful, resulting in poor quality of one or both of the images of the user <b>10</b> and the identification card <b>20</b>. Therefore, in the present usage example, the identification card <b>20</b> and the user <b>10</b> are captured separately.</p><heading id="h-0024" level="2">&#x3c;&#x3c;Capturing an Image of a User <b>10</b>'s Face: S<b>206</b>&#x3e;&#x3e;</heading><p id="p-0069" num="0068">After transmitting the information extracted from the identification card <b>20</b> to the server machine <b>80</b>, the application <b>100</b> causes the user <b>10</b> to capture an image of his/her face (S<b>206</b>). To do so, the application <b>100</b> outputs the screen <b>60</b> to the display apparatus <b>42</b>.</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating a screen for capturing an image of a user's face. As described above, the screen <b>60</b> includes the certificate image <b>30</b>. In addition, in a display area <b>64</b> of the screen <b>60</b>, similarly to the screen <b>110</b> and the like, an image generated by the camera <b>44</b> is displayed in real time. The user <b>10</b> views the display area <b>64</b>, and presses an image capturing button <b>62</b> in such a way that his/her face is correctly captured. As a result, an image generated by the camera <b>44</b> at a timing when the image capturing button <b>62</b> is pressed is stored in the storage apparatus of the user terminal <b>40</b> as the user image <b>50</b>.</p><p id="p-0071" num="0070">The application <b>100</b> transmits the user image <b>50</b> to the server machine <b>80</b>. The server machine <b>80</b> receiving the user image <b>50</b> compares a person image extracted from the certificate image <b>30</b> with the user image <b>50</b>, and thereby determines whether the persons represented by these images are the same. This is equivalent to determining whether the identification card <b>20</b> included in the certificate image <b>30</b> is an identification card of the user <b>10</b>. An existing technique can be used as a technique for determining whether a person represented by each of two images matches with each other.</p><p id="p-0072" num="0071">When a person represented by the person image extracted from the certificate image <b>30</b> and a person represented by the user image <b>50</b> do not match, the server machine <b>80</b> transmits a notification indicating failure of matching to the application <b>100</b>. The application <b>100</b> receiving the notification indicating failure of matching outputs a message indicating an error to the display apparatus <b>42</b>.</p><p id="p-0073" num="0072">When a person represented by the person image extracted from the certificate image <b>30</b> matches a person represented by the user image <b>50</b>, the server machine <b>80</b> transmits a notification indicating success of matching to the application <b>100</b>. The application <b>100</b> receiving the notification indicating success of matching outputs a screen for performing biometric detection to the display apparatus <b>42</b>.</p><p id="p-0074" num="0073">Including the certificate image <b>30</b> in the screen <b>60</b> in this manner has an advantageous effect, as described above, that the user <b>10</b> is psychologically less likely to illegally use of the identification card <b>20</b>.</p><p id="p-0075" num="0074">Herein, the image capturing button <b>64</b> may not be provided on the screen <b>60</b>. In this case, while the screen <b>60</b> is displayed, the camera <b>44</b> repeatedly captures an image. and generates a plurality of user images <b>50</b>. In addition, matching with a person image extracted from the certificate image <b>30</b> is performed for each of the plurality of user images <b>50</b> generated in this manner.</p><p id="p-0076" num="0075">Then, when any one of the user images <b>50</b> matches the person image extracted from the certificate image <b>30</b>, it is handled as matching success. On the other hand, when there is no user image <b>50</b> that matches the person image extracted from the certificate image <b>30</b>, it is handled as matching failure.</p><heading id="h-0025" level="2">&#x3c;&#x3c;Biometric Detection: S<b>208</b>&#x3e;&#x3e;</heading><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating a screen for performing biometric detection for the user <b>10</b>. The biometric detection herein is processing for confirming that an image captured by using the camera <b>44</b> is a person actually existing on the spot, and is not other than a person such as a photograph or the like. By performing biometric detection, it is possible to prevent the user <b>10</b> who is not a certified person of the identification card <b>20</b> from impersonating the certified person of the identification card <b>20</b> (e.g., on the screen <b>60</b>, capturing a photograph or the like of the certified person of the identification card <b>20</b> by the camera <b>44</b>).</p><p id="p-0078" num="0077">Similarly to the screen <b>60</b>, a screen <b>130</b> includes the certificate image <b>30</b>. In addition, an image generated by the camera <b>44</b> is displayed in real time in a display area <b>134</b> of the screen <b>130</b>. While checking a user's own appearance displayed in the display area <b>134</b>, the user <b>10</b> performs an action (an action of facing up, down, left, or right, an action of tilting a face to left or right, an action of shutting a left or right eye, making a smile, opening a mouth, or the like) for instructed biometric detection.</p><p id="p-0079" num="0078">The application <b>100</b> performs biometric detection by using an image captured by the camera <b>44</b> while the screen <b>130</b> is being displayed. Specifically, the application <b>100</b> determines whether a state of the user <b>10</b> is in a predetermined state (a state instructing to the user <b>10</b>) for each image captured by the camera <b>44</b> after the screen <b>130</b> is output. When an image in which a state of the user <b>10</b> is in a predetermined state is detected, the biometric detection is successful. Note that, an existing technique can be used as a technique for analyzing an image including a person and thereby determining whether a state of the person is in a predetermined state.</p><p id="p-0080" num="0079">When an image in which a state of the user <b>10</b> is in a predetermined state is not detected, the biometric detection fails. For example, the application <b>100</b> continues to display the screen <b>130</b> until the biometric detection succeeds. However, it is also possible to set a limitation on a time for continuing to display the screen <b>130</b>, and to output an error message to the display apparatus <b>42</b> by the application <b>100</b> when the biometric detection does not succeed even after the limitation time has elapsed.</p><p id="p-0081" num="0080">Note that, the above-described determination of the biometric detection may be performed by the server machine <b>80</b> instead of the application <b>100</b>. In this case, the application <b>100</b> transmits each image generated by the camera <b>44</b> to the server machine <b>80</b>. The server machine <b>80</b> transmits a notification indicating success or failure of the biometric detection to the application <b>100</b>.</p><p id="p-0082" num="0081">Herein, in order to perform biometric detection with high accuracy, it is preferable to cause the user <b>10</b> to perform a plurality of types of actions. In this case, the application <b>100</b> sequentially displays the screen <b>130</b> for each of a plurality of types of actions on the display apparatus <b>42</b>, and performs detection of each type of action.</p><heading id="h-0026" level="2">&#x3c;&#x3c;Confirmation a Thickness of the Identification Card <b>20</b>: S<b>208</b>&#x3e;&#x3e;</heading><p id="p-0083" num="0082">When the biometric detection succeeds, confirmation of a thickness of the identification card <b>20</b> is performed (S<b>208</b>). This is performed to confirm that the user <b>10</b> has an original of the identification card <b>20</b>. Only receiving a provided image of the identification card <b>20</b> does not eliminate a possibility that, for example, the user <b>10</b> acquires a copy of the identification card <b>20</b> of another person and captures an image of the copy with the camera <b>44</b>. Therefore, in order to confirm that the user <b>10</b> has an original of the identification card <b>20</b>, not only a face of the identification card <b>20</b> but also the identification card <b>20</b> is captured from various angles to confirm that the identification card <b>20</b> has a thickness.</p><p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating a screen for performing confirmation of a thickness of the identification card <b>20</b>. In a screen <b>140</b>, the user <b>10</b> causes the camera <b>44</b> to capture an image of the main surface of the identification card <b>20</b>. The application <b>100</b> analyzes the image generated by the camera <b>44</b>, and detects that the main surface of the identification card <b>20</b> has been captured. At this time, it is preferable that the application <b>100</b> confirms that the acquired image of the main surface of the identification card <b>20</b> matches the certificate image <b>30</b>. For example, the confirmation is performed by confirming whether a person image included in an image of the identification card <b>20</b> acquired in a state where the screen <b>140</b> is displayed matches a person image included in the certificate image <b>30</b> acquired in S<b>202</b>.</p><p id="p-0085" num="0084">Thereafter, the application <b>100</b> outputs a screen <b>150</b>, and causes the user <b>10</b> to capture an image of the identification card <b>20</b> while rotating the identification card <b>20</b>. The application <b>100</b> analyzes a plurality of images captured while rotating the identification card <b>20</b>, and thereby confirms that the identification card <b>20</b> has a thickness. For example, the application <b>100</b> detects an image in which the identification card <b>20</b> is captured in each of a plurality of predetermined states (e.g., an image in which the main surface of the identification card <b>20</b> is captured from an angle of obliquely 45 degrees, an image in which the identification card <b>20</b> is captured from a right side, an image in which the back surface of the identification card <b>20</b> is captured from an angle of obliquely 45 degrees, and the like). When an image of the identification card <b>20</b> captured in each of a plurality of predetermined states is detected, the application <b>100</b> determines that confirmation of a thickness of the identification card <b>20</b> has succeeded. As a result, a series of pieces of processing for personal identification is completed.</p><p id="p-0086" num="0085">While example embodiments of the present invention have been described above with reference to the drawings, these are examples of the present invention, and combinations of the above-described example embodiments or various configurations other than the above may be adopted.</p><p id="p-0087" num="0086">Some or all of the above example embodiments may also be described as the following supplementary notes, but are not limited to the following.<ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0087">1. A control apparatus including:</li></ul></p><p id="p-0088" num="0088">a first acquisition unit that acquires a certificate image being an image of an identification card;</p><p id="p-0089" num="0089">a screen data output unit that outputs screen data of a first screen including the certificate image; and</p><p id="p-0090" num="0090">a second acquisition unit that acquires an image of a user being generated by capturing an image performed in a state where the first screen is displayed.<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0091">2. The control apparatus according to supplementary note 1, wherein</li></ul></p><p id="p-0091" num="0092">the image of the user is generated by a camera controllable by a user terminal to be used by the user in a state where the first screen is displayed on a display apparatus controllable by the user terminal.<ul id="ul0004" list-style="none">    <li id="ul0004-0001" num="0093">3. The control apparatus according to supplementary note 1 or 2, wherein</li></ul></p><p id="p-0092" num="0094">a second screen for capturing an image of the identification card is displayed before the first screen, and</p><p id="p-0093" num="0095">the first acquisition unit acquires the certificate image generated by capturing an image performed in a state where the second screen is displayed.<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0096">4. The control apparatus according to any one of supplementary notes 1 to 3, wherein</li></ul></p><p id="p-0094" num="0097">an image of a person is displayed on the identification card, and</p><p id="p-0095" num="0098">the second acquisition unit determines whether a person included in the certificate image matches a person included in an image acquired by the second acquisition unit.<ul id="ul0006" list-style="none">    <li id="ul0006-0001" num="0099">5. A control method to be executed by a computer, including:</li></ul></p><p id="p-0096" num="0100">a first acquisition step of acquiring a certificate image being an image of an identification card;</p><p id="p-0097" num="0101">a screen data output step of outputting screen data of a first screen including the certificate image; and</p><p id="p-0098" num="0102">a second acquisition step of acquiring an image of a user being generated by capturing an image performed in a state where the first screen is displayed.<ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0103">6. The control method according to supplementary note 5, wherein</li></ul></p><p id="p-0099" num="0104">the image of the user is generated by a camera controllable by a user terminal to be used by the user in a state where the first screen is displayed on a display apparatus controllable by the user terminal.<ul id="ul0008" list-style="none">    <li id="ul0008-0001" num="0105">7. The control method according to supplementary note 5 or 6, wherein</li></ul></p><p id="p-0100" num="0106">a second screen for capturing an image of the identification card is displayed before the first screen,</p><p id="p-0101" num="0107">the control method further including,</p><p id="p-0102" num="0108">in the first acquisition step, acquiring the certificate image generated by capturing an image performed in a state where the second screen displayed.<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0109">8. The control method according to any one of supplementary notes 5 to 7, wherein</li></ul></p><p id="p-0103" num="0110">an image of a person is displayed on the identification card,</p><p id="p-0104" num="0111">the control method further including,</p><p id="p-0105" num="0112">in the second acquisition step, determining whether a person included in the certificate image matches a person included in an image acquired in the second acquisition step.<ul id="ul0010" list-style="none">    <li id="ul0010-0001" num="0113">9. A program causing a computer to execute the control method according to any one of supplementary notes 5 to 8.</li></ul></p><p id="p-0106" num="0114">This application is based upon and claims the benefit of priority from Japanese patent application No. 2019-230599, filed on Dec. 20, 2019, the disclosure of which is incorporated herein in its entirety by reference.</p><heading id="h-0027" level="1">REFERENCE SIGNS LIST</heading><p id="p-0107" num="0000"><ul id="ul0011" list-style="none">    <li id="ul0011-0001" num="0115"><b>10</b> User</li>    <li id="ul0011-0002" num="0116"><b>20</b> Identification card</li>    <li id="ul0011-0003" num="0117"><b>30</b> Certificate image</li>    <li id="ul0011-0004" num="0118"><b>40</b> User terminal</li>    <li id="ul0011-0005" num="0119"><b>42</b> Display apparatus</li>    <li id="ul0011-0006" num="0120"><b>44</b> Camera</li>    <li id="ul0011-0007" num="0121"><b>50</b> User image</li>    <li id="ul0011-0008" num="0122"><b>60</b> Screen</li>    <li id="ul0011-0009" num="0123"><b>62</b> Display area</li>    <li id="ul0011-0010" num="0124"><b>62</b> Image capturing button</li>    <li id="ul0011-0011" num="0125"><b>64</b> Display area</li>    <li id="ul0011-0012" num="0126"><b>64</b> Image capturing button</li>    <li id="ul0011-0013" num="0127"><b>70</b> Screen data</li>    <li id="ul0011-0014" num="0128"><b>80</b> Server machine</li>    <li id="ul0011-0015" num="0129"><b>100</b> Application</li>    <li id="ul0011-0016" num="0130"><b>110</b> Screen</li>    <li id="ul0011-0017" num="0131"><b>112</b> Image capturing button</li>    <li id="ul0011-0018" num="0132"><b>114</b> Display area</li>    <li id="ul0011-0019" num="0133"><b>120</b> Screen</li>    <li id="ul0011-0020" num="0134"><b>130</b> Screen</li>    <li id="ul0011-0021" num="0135"><b>134</b> Display area</li>    <li id="ul0011-0022" num="0136"><b>140</b> Screen</li>    <li id="ul0011-0023" num="0137"><b>150</b> Screen</li>    <li id="ul0011-0024" num="0138"><b>1000</b> Computer</li>    <li id="ul0011-0025" num="0139"><b>1020</b> Bus</li>    <li id="ul0011-0026" num="0140"><b>1040</b> Processor</li>    <li id="ul0011-0027" num="0141"><b>1060</b> Memory</li>    <li id="ul0011-0028" num="0142"><b>1080</b> Storage device</li>    <li id="ul0011-0029" num="0143"><b>1100</b> Input/output interface</li>    <li id="ul0011-0030" num="0144"><b>1120</b> Network Interface</li>    <li id="ul0011-0031" num="0145"><b>2000</b> Control apparatus</li>    <li id="ul0011-0032" num="0146"><b>2020</b> First acquisition unit</li>    <li id="ul0011-0033" num="0147"><b>2040</b> Screen data output unit</li>    <li id="ul0011-0034" num="0148"><b>2060</b> Second acquisition unit</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A control apparatus comprising:<claim-text>at least one memory configured to store instructions; and</claim-text><claim-text>at least one processor configured to execute the instructions to perform operations comprising:</claim-text><claim-text>acquiring a certificate image being an image of an identification card;</claim-text><claim-text>outputting screen data of a first screen including the certificate image; and</claim-text><claim-text>acquiring an image of a user being generated by capturing an image performed in a state where the first screen is displayed.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the image of the user is generated by a camera controllable by a user terminal to be used by the user in a state where the first screen is displayed on a display apparatus controllable by the user terminal.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>a second screen for capturing an image of the identification card is displayed before the first screen, and</claim-text><claim-text>the at least one processor is further configured to execute the instructions to acquire the certificate image generated by capturing an image performed in a state where the second screen is displayed.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>an image of a person is displayed on the identification card, and</claim-text><claim-text>the at least one processor is further configured to execute the instructions to determine whether a person included in the certificate image matches a person included in the image of the user.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. A control method to be executed by a computer, comprising:<claim-text>a first acquisition step of acquiring a certificate image being an image of an identification card;</claim-text><claim-text>a screen data output step of outputting screen data of a first screen including the certificate image; and</claim-text><claim-text>a second acquisition step of acquiring an image of a user being generated by capturing an image performed in a state where the first screen is displayed.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The control method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein<claim-text>the image of the user is generated by a camera controllable by a user terminal to be used by the user in a state where the first screen is displayed on a display apparatus controllable by the user terminal.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The control method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein<claim-text>a second screen for capturing an image of the identification card is displayed before the first screen, and</claim-text><claim-text>the control method further comprises,</claim-text><claim-text>in the first acquisition step, acquiring the certificate image generated by capturing an image performed in a state where the second screen is displayed.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The control method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein<claim-text>an image of a person is displayed on the identification card, and</claim-text><claim-text>the control method further comprises,</claim-text><claim-text>in the second acquisition step, determining whether a person included in the certificate image matches a person included in an image acquired in the second acquisition step.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A non-transitory computer readable medium storing a program causing a computer to execute a control method, the control method comprising:<claim-text>a first acquisition step of acquiring a certificate image being an image of an identification card;</claim-text><claim-text>a screen data output step of outputting screen data of a first screen including the certificate image; and<claim-text>a second acquisition step of acquiring an image of a user being generated by capturing an image performed in a state where the first screen is displayed.</claim-text></claim-text></claim-text></claim></claims></us-patent-application>
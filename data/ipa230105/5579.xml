<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005580A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005580</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17942166</doc-number><date>20220911</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-046019</doc-number><date>20200317</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>15</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>30</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>15</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>30</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>0012</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20081</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">DOCUMENT CREATION SUPPORT APPARATUS, METHOD, AND PROGRAM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/010610</doc-number><date>20210316</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17942166</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>FUJIFILM Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MOMOKI</last-name><first-name>Yohei</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>FUJIFILM Corporation</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A document creation support apparatus includes at least one processor, and the processor specifies, with respect to a first region specified in a first image of a subject, a second region corresponding to the first region in each of a plurality of second images of the subject whose imaging time is different from that of the first image. The processor specifies a second description regarding the specified second region, which is included in a plurality of sentences related to each of the plurality of second images. The processor displays a plurality of second descriptions specified for each of the plurality of second images in a switchable manner.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="184.49mm" wi="82.13mm" file="US20230005580A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="250.27mm" wi="158.33mm" file="US20230005580A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="205.57mm" wi="84.16mm" file="US20230005580A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="203.96mm" wi="151.72mm" file="US20230005580A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="234.53mm" wi="155.53mm" file="US20230005580A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="215.48mm" wi="161.54mm" orientation="landscape" file="US20230005580A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="216.32mm" wi="162.81mm" orientation="landscape" file="US20230005580A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="215.48mm" wi="161.54mm" orientation="landscape" file="US20230005580A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="237.83mm" wi="154.69mm" file="US20230005580A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="245.70mm" wi="86.61mm" file="US20230005580A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="245.45mm" wi="131.49mm" orientation="landscape" file="US20230005580A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="215.48mm" wi="161.54mm" orientation="landscape" file="US20230005580A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="155.02mm" wi="78.23mm" file="US20230005580A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="251.21mm" wi="86.44mm" file="US20230005580A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="215.48mm" wi="161.71mm" orientation="landscape" file="US20230005580A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="190.67mm" wi="78.23mm" file="US20230005580A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="229.62mm" wi="86.61mm" file="US20230005580A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="186.27mm" wi="118.28mm" file="US20230005580A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="214.04mm" wi="162.64mm" orientation="landscape" file="US20230005580A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="230.97mm" wi="161.04mm" file="US20230005580A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a Continuation of PCT International Application No. PCT/JP2021/10610, filed on Mar. 16, 2021, which claims priority to Japanese Patent Application No. 2020-046019, filed on Mar. 17, 2020. Each application above is hereby expressly incorporated by reference, in its entirety, into the present application.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Technical Field</heading><p id="p-0003" num="0002">The present disclosure relates to a document creation support apparatus, method, and program.</p><heading id="h-0004" level="1">Related Art</heading><p id="p-0004" num="0003">In recent years, advances in medical devices, such as computed tomography (CT) apparatuses and magnetic resonance imaging (MRI) apparatuses, have enabled image diagnosis using high-resolution medical images with higher quality. In particular, since a region of a lesion can be specified and analyzed accurately by image diagnosis using CT images, MRI images, and the like, appropriate treatment can be performed.</p><p id="p-0005" num="0004">In addition, image diagnosis is also made by analyzing a medical image via computer-aided diagnosis (CAD) using a learning model in which machine learning is performed by deep learning or the like, discriminating properties such as the shape, density, position, and size of structures of interest such as abnormal shadows included in the medical images, and acquiring them as an analysis result. The analysis result acquired by CAD is associated with examination information such as a patient name, gender, age, and a modality that has acquired the medical image, and is saved in a database. The medical image and the analysis result are transmitted to a terminal of a radiologist who interprets the medical images. The radiologist interprets the medical image by referring to the transmitted medical image and analysis result and creates an interpretation report, in his or her own terminal.</p><p id="p-0006" num="0005">Meanwhile, with the improvement of the performance of the CT apparatus and the MRI apparatus described above, the number of medical images to be interpreted is also increasing. However, since the number of radiologists has not kept up with the number of medical images, it is desired to reduce the burden of the image interpretation work of the radiologists. Therefore, various methods have been proposed to support the creation of medical documents such as interpretation reports. For example, JP2019-153250A proposes a method for automatically generating a sentence to be included in an interpretation report based on keywords input by a radiologist and on information indicating a property of a structure of interest (hereinafter referred to as property information) included in an analysis result of a medical image. In the methods described in JP2019-153250A, a sentence relating to medical care (hereinafter referred to as a medical sentence) is created by using a learning model in which machine learning is performed, such as a recurrent neural network trained to generate a sentence from characters representing the input property information. By automatically generating the medical sentence as in the method described in JP2019-153250A, it is possible to reduce a burden on a radiologist at the time of creating a medical document such as an interpretation report.</p><p id="p-0007" num="0006">Incidentally, in the case of following up on a patient, in creating an interpretation report based on the latest medical image of the patient, the past medical image interpretation report is often referred to. In order to easily refer to such a past interpretation report, a method has been proposed in which a past image of the same patient is specified and findings information associated with the past image is acquired (see JP2017-204041A). In addition, a method has been proposed in which, in a case where there is a past image of the same part for the same patient, the current image and the past image of the part are displayed at the same time, and in a case where there is findings information about the region, the findings information is transmitted (see JP2011-024622A). Further, a method has been proposed in which an interpretation report for a current medical image and an interpretation report for a past medical image are displayed at the same time (see JP2017-189390A).</p><p id="p-0008" num="0007">In creating an interpretation report that describes the findings about abnormal shadows included in a medical image of a certain patient, there may be a plurality of sentences such as interpretation reports that describe past images of the same patient and corresponding findings. In such a case, if the sentence such as the interpretation report for the past image can be referred to, the interpretation report including the findings about the abnormal shadow included in the current medical image can be efficiently created.</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0009" num="0008">The present disclosure has been made in view of the above circumstances, and an object thereof is to enable efficient reference to sentences about images in a case where there are a plurality of images with different imaging times.</p><p id="p-0010" num="0009">According to an aspect of the present disclosure, there is provided a document creation support apparatus comprising at least one processor, in which the processor is configured to specify, with respect to a first region specified in a first image of a subject, a second region corresponding to the first region in each of a plurality of second images of the subject whose imaging time is different from that of the first image, specify a second description regarding the specified second region, which is included in a plurality of sentences related to each of the plurality of second images, and display a plurality of second descriptions specified for each of the plurality of second images in a switchable manner.</p><p id="p-0011" num="0010">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to further display a description region for describing a sentence related to the first region.</p><p id="p-0012" num="0011">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to transcribe at least one of the plurality of second descriptions to the description region.</p><p id="p-0013" num="0012">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to analyze the first region to generate a first description regarding the first region, and display the first description in the description region.</p><p id="p-0014" num="0013">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to derive a difference between a property related to the first region included in the first description and a property related to the second region included in the second description specified for each of the plurality of second images, and display the difference between the property included in the first description and the property included in the second description in a visually recognizable manner.</p><p id="p-0015" num="0014">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to derive a difference between the first region and the second region.</p><p id="p-0016" num="0015">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to display the second description in a case where the difference has been derived.</p><p id="p-0017" num="0016">In the document creation support apparatus according to the aspect of the present disclosure, the processor may be configured to notify that the difference has not been derived in a case where the difference has not been derived.</p><p id="p-0018" num="0017">According to another aspect of the present disclosure, there is provided a document creation support method comprising: specifying, with respect to a first region specified in a first image of a subject, a second region corresponding to the first region in each of a plurality of second images of the subject whose imaging time is different from that of the first image; specifying a second description regarding the specified second region, which is included in a plurality of sentences related to each of the plurality of second images; and displaying a plurality of second descriptions specified for each of the plurality of second images in a switchable manner.</p><p id="p-0019" num="0018">In addition, a program for causing a computer to execute the document creation support method according to the aspect of the present disclosure may be provided.</p><p id="p-0020" num="0019">According to the aspects of the present disclosure, in a case where there are a plurality of images with different imaging times, the sentence about the images can be efficiently referred to.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing a schematic configuration of a medical information system to which a document creation support apparatus according to a first embodiment of the present disclosure is applied.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram showing a schematic configuration of the document creation support apparatus according to the first embodiment.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a functional configuration diagram of the document creation support apparatus according to the first embodiment.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram showing a first medical image and a second medical image.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram for describing an example of property information.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram for describing the specification of a second description.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram showing a display screen in the first embodiment.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram showing a display screen in the first embodiment.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram showing a display screen in the first embodiment.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart showing a process performed in the first embodiment.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a functional configuration diagram of a document creation support apparatus according to a second embodiment.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram schematically showing a configuration of a recurrent neural network.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram showing a display screen in the second embodiment.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart showing a process performed in the second embodiment.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a functional configuration diagram of a document creation support apparatus according to a third embodiment.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram showing a display screen in the third embodiment.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart showing a process performed in the third embodiment.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a functional configuration diagram of a document creation support apparatus according to a fourth embodiment.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram for describing the difference between a first region and a second region.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a diagram showing a display screen in the fourth embodiment.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a flowchart showing a process performed in the fourth embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0042" num="0041">Hereinafter, embodiments of the present disclosure will be described with reference to the drawings. First, a configuration of a medical information system <b>1</b> to which a document creation support apparatus according to the present embodiment is applied will be described. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing a schematic configuration of the medical information system <b>1</b>. The medical information system <b>1</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is, based on an examination order from a doctor in a medical department using a known ordering system, a system for imaging an examination target part of a subject, storing a medical image acquired by the imaging, interpreting the medical image by a radiologist and creating an interpretation report, and viewing the interpretation report and observing the medical image to be interpreted in detail by the doctor in the medical department that is a request source.</p><p id="p-0043" num="0042">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in the medical information system <b>1</b>, a plurality of imaging apparatuses <b>2</b>, a plurality of interpretation workstations (WSs) <b>3</b> that are interpretation terminals, a medical care WS <b>4</b>, an image server <b>5</b>, an image database (hereinafter referred to as an image DB) <b>6</b>, a report server <b>7</b>, and a report database (hereinafter referred to as a report DB) <b>8</b> are communicably connected to each other through a wired or wireless network <b>10</b>.</p><p id="p-0044" num="0043">Each apparatus is a computer on which an application program for causing each apparatus to function as a component of the medical information system <b>1</b> is installed. The application program is recorded on a recording medium, such as a digital versatile disc (DVD) or a compact disc read only memory (CD-ROM), and distributed, and is installed on the computer from the recording medium. Alternatively, the application program is stored in a storage apparatus of a server computer connected to the network <b>10</b> or in a network storage in a state in which it can be accessed from the outside, and is downloaded to and installed on the computer in response to a request.</p><p id="p-0045" num="0044">The imaging apparatus <b>2</b> is an apparatus (modality) that generates a medical image showing a diagnosis target part of the subject by imaging the diagnosis target part. Specifically, examples of the modality include a simple X-ray imaging apparatus, a CT apparatus, an MRI apparatus, a positron emission tomography (PET) apparatus, and the like. The medical image generated by the imaging apparatus <b>2</b> is transmitted to the image server <b>5</b> and is saved in the image DB <b>6</b>.</p><p id="p-0046" num="0045">The interpretation WS <b>3</b> is a computer used by, for example, a radiologist of a radiology department to interpret a medical image and to create an interpretation report, and encompasses a document creation support apparatus <b>20</b> according to the present embodiment. In the interpretation WS <b>3</b>, a viewing request for a medical image to the image server <b>5</b>, various image processing for the medical image received from the image server <b>5</b>, display of the medical image, input reception of comments on findings regarding the medical image, and the like are performed. In the interpretation WS <b>3</b>, an analysis process for medical images and input comments on findings, support for creating an interpretation report based on the analysis result, a registration request and a viewing request for the interpretation report to the report server <b>7</b>, and display of the interpretation report received from the report server <b>7</b> are performed. The above processes are performed by the interpretation WS <b>3</b> executing software programs for respective processes.</p><p id="p-0047" num="0046">The medical care WS <b>4</b> is a computer used by a doctor in a medical department to observe an image in detail, view an interpretation report, create an electronic medical record, and the like, and is configured to include a processing apparatus, a display apparatus such as a display, and an input apparatus such as a keyboard and a mouse. In the medical care WS <b>4</b>, a viewing request for the image to the image server <b>5</b>, display of the image received from the image server <b>5</b>, a viewing request for the interpretation report to the report server <b>7</b>, and display of the interpretation report received from the report server <b>7</b> are performed. The above processes are performed by the medical care WS <b>4</b> executing software programs for respective processes.</p><p id="p-0048" num="0047">The image server <b>5</b> is a general-purpose computer on which a software program that provides a function of a database management system (DBMS) is installed. The image server <b>5</b> comprises a storage in which the image DB <b>6</b> is configured. This storage may be a hard disk apparatus connected to the image server <b>5</b> by a data bus, or may be a disk apparatus connected to a storage area network (SAN) or a network attached storage (NAS) connected to the network <b>10</b>. In a case where the image server <b>5</b> receives a request to register a medical image from the imaging apparatus <b>2</b>, the image server <b>5</b> prepares the medical image in a format for a database and registers the medical image in the image DB <b>6</b>. In the present embodiment, it is assumed that a diagnostic guideline according to the disease is also saved in the image server <b>5</b>, but the present disclosure is not limited thereto.</p><p id="p-0049" num="0048">Image data of the medical image acquired by the imaging apparatus <b>2</b> and accessory information are registered in the image DB <b>6</b>. The accessory information includes, for example, an image identification (ID) for identifying each medical image, a patient ID for identifying a subject, an examination ID for identifying an examination, a unique ID (unique identification (UID)) allocated for each medical image, examination date and examination time at which a medical image is generated, the type of imaging apparatus used in an examination for acquiring a medical image, patient information such as the name, age, and gender of a patient, an examination part (an imaging part), imaging information (an imaging protocol, an imaging sequence, an imaging method, imaging conditions, the use of a contrast medium, and the like), and information such as a series number or a collection number in a case where a plurality of medical images are acquired in one examination.</p><p id="p-0050" num="0049">In addition, in a case where the viewing request from the interpretation WS <b>3</b> and the medical care WS <b>4</b> is received through the network <b>10</b>, the image server <b>5</b> searches for a medical image registered in the image DB <b>6</b> and transmits the searched for medical image to the interpretation WS <b>3</b> and to the medical care WS <b>4</b> that are request sources.</p><p id="p-0051" num="0050">The report server <b>7</b> incorporates a software program for providing a function of a database management system to a general-purpose computer. In a case where the report server <b>7</b> receives a request to register the interpretation report from the interpretation WS <b>3</b>, the report server <b>7</b> prepares the interpretation report in a format for a database and registers the interpretation report in the report DB <b>8</b>.</p><p id="p-0052" num="0051">In the report DB <b>8</b>, an interpretation report including at least the comments on findings created by the radiologist using the interpretation WS <b>3</b> is registered. The interpretation report may include, for example, information such as a medical image to be interpreted, an image ID for identifying the medical image, a radiologist ID for identifying the radiologist who performed the interpretation, a lesion name, lesion position information, information for accessing a medical image including a specific region, and property information.</p><p id="p-0053" num="0052">Further, in a case where the report server <b>7</b> receives the viewing request for the interpretation report from the interpretation WS <b>3</b> and the medical care WS <b>4</b> through the network <b>10</b>, the report server <b>7</b> searches for the interpretation report registered in the report DB <b>8</b>, and transmits the searched for interpretation report to the interpretation WS <b>3</b> and to the medical care WS <b>4</b> that are request sources.</p><p id="p-0054" num="0053">In the present embodiment, it is assumed that the medical image is a three-dimensional CT image consisting of a plurality of tomographic images with a lung as a diagnosis target, and an interpretation report on an abnormal shadow included in the lung is created by interpreting the CT image in the interpretation WS <b>3</b>. The medical image is not limited to the CT image, and any medical image such as an MM image and a simple two-dimensional image acquired by a simple X-ray imaging apparatus can be used.</p><p id="p-0055" num="0054">The network <b>10</b> is a wired or wireless local area network that connects various apparatuses in a hospital to each other. In a case where the interpretation WS <b>3</b> is installed in another hospital or clinic, the network <b>10</b> may be configured to connect local area networks of respective hospitals through the Internet or a dedicated line.</p><p id="p-0056" num="0055">Next, the document creation support apparatus according to a first embodiment of the present disclosure will be described. <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a hardware configuration of the document creation support apparatus according to the first embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the document creation support apparatus <b>20</b> includes a central processing unit (CPU) <b>11</b>, a non-volatile storage <b>13</b>, and a memory <b>16</b> as a temporary storage area. Further, the document creation support apparatus <b>20</b> includes a display <b>14</b> such as a liquid crystal display, an input device <b>15</b> such as a keyboard and a mouse, and a network interface (I/F) <b>17</b> connected to the network <b>10</b>. The CPU <b>11</b>, the storage <b>13</b>, the display <b>14</b>, the input device <b>15</b>, the memory <b>16</b>, and the network I/F <b>17</b> are connected to a bus <b>18</b>. The CPU <b>11</b> is an example of a processor in the present disclosure.</p><p id="p-0057" num="0056">The storage <b>13</b> is realized by a hard disk drive (HDD), a solid state drive (SSD), a flash memory, and the like. A document creation support program <b>12</b> is stored in the storage <b>13</b> as a storage medium. The CPU <b>11</b> reads a document creation support program from the storage <b>13</b>, loads the read document creation support program <b>12</b> into the memory <b>16</b>, and executes the loaded document creation support program <b>12</b>.</p><p id="p-0058" num="0057">Next, a functional configuration of the document creation support apparatus according to the first embodiment will be described. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram showing a functional configuration of the document creation support apparatus according to the first embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the document creation support apparatus <b>20</b> according to the first embodiment comprises an acquisition unit <b>21</b>, a region specifying unit <b>22</b>, a description specifying unit <b>23</b>, a display control unit <b>24</b>, a save control unit <b>25</b>, and a communication unit <b>26</b>. Then, in a case where the CPU <b>11</b> executes the document creation support program, the CPU <b>11</b> functions as the acquisition unit <b>21</b>, the region specifying unit <b>22</b>, the description specifying unit <b>23</b>, the display control unit <b>24</b>, the save control unit <b>25</b>, and the communication unit <b>26</b>.</p><p id="p-0059" num="0058">The acquisition unit <b>21</b> acquires a first medical image G<b>1</b> for creating an interpretation report from the image server <b>5</b> according to an instruction from the input device <b>15</b> by the radiologist who is an operator. Further, the acquisition unit <b>21</b> acquires, from the image server <b>5</b>, a plurality of second medical images G<b>2</b>-<i>i </i>(i=2 to n, n is the number of second medical images, and the larger n is, the older the imaging time is) whose imaging time is earlier than that of the first medical image G<b>1</b> for a patient who has acquired the first medical image G<b>1</b>. Further, the acquisition unit <b>21</b> acquires an interpretation report R<b>2</b>-<i>i </i>for the plurality of second medical images G<b>2</b>-<i>i </i>from the report server <b>7</b>. The acquired first medical image G<b>1</b> and second medical images G<b>2</b>-<i>i</i>, and the interpretation report R<b>2</b>-<i>i </i>are saved in the storage <b>13</b>.</p><p id="p-0060" num="0059">The region specifying unit <b>22</b> specifies, with respect to a first region specified in the first medical image G<b>1</b> of a subject, a second region corresponding to the first region in each of the plurality of second medical images. To this end, the region specifying unit <b>22</b> has a learning model <b>22</b>A that has been trained to detect abnormal shadows on the lungs included in the medical image.</p><p id="p-0061" num="0060">The learning model <b>22</b>A consists of, for example, a convolutional neural network (CNN) in which deep learning has been performed using supervised training data so as to discriminate whether or not each pixel (voxel) in a medical image represents an abnormal shadow.</p><p id="p-0062" num="0061">The learning model <b>22</b>A is constructed by machine learning using, for example, a combination of a medical image including an abnormal shadow and correct answer data representing a position of the abnormal shadow in the medical image as supervised training data. In a case where the medical image is input, the learning model <b>22</b>A outputs a score indicating that each pixel is an abnormal shadow in the input medical image. The score is a score indicating a prominence of abnormal shadows in medical images. The score takes a value of 0 or more and 1 or less, for example, and the larger the value of the score, the higher the likelihood of the abnormal shadow. Then, the learning model <b>22</b>A extracts pixels having a score equal to or larger than a predetermined threshold value (for example, 0.5) as pixels of abnormal shadows.</p><p id="p-0063" num="0062">The region specifying unit <b>22</b> specifies the region of the abnormal shadow in the first medical image G<b>1</b> as a first region A<b>1</b> by using the learning model <b>22</b>A. Although a plurality of abnormal shadows may be specified, it is assumed here that one first region A<b>1</b> is specified in the first medical image G<b>1</b> for the sake of description.</p><p id="p-0064" num="0063">The region specifying unit <b>22</b> specifies a second region A<b>2</b>-<i>i </i>corresponding to the first region A<b>1</b> specified in the first medical image G<b>1</b> in each of the plurality of second medical images G<b>2</b>-<i>i</i>. At this time, the region specifying unit <b>22</b> may specify the second region A<b>2</b>-<i>i </i>by using the learning model <b>22</b>A for each of the plurality of medical images G<b>2</b>-<i>i</i>. Further, for the second medical image G<b>2</b>-<i>i</i>, the abnormal shadow has already been specified, and the information indicating the position of the specified abnormal shadow may be saved in the image server <b>5</b> together with the second medical image G<b>2</b>-<i>i</i>. In such a case, the acquisition unit <b>21</b> may acquire information indicating the position of the abnormal shadow together with the second medical image G<b>2</b>-<i>i</i>, and use the information to specify the second region A<b>2</b>-<i>i </i>in the second medical image G<b>2</b>-<i>i. </i></p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram showing a region specified in a medical image. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in the first medical image G<b>1</b>, the first region A<b>1</b> is specified. Further, in two second medical images G<b>2</b>-<b>1</b> and G<b>2</b>-<b>2</b>, second regions A<b>2</b>-<b>1</b> and A<b>2</b>-<b>2</b> are specified, respectively. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in the first medical image G<b>1</b> and the second medical images G<b>2</b>-<b>1</b> and G<b>2</b>-<b>2</b>, the newer the imaging time, the larger the specified region.</p><p id="p-0066" num="0065">The description specifying unit <b>23</b> specifies a second description regarding the specified second region A<b>2</b>-<i>i </i>in a plurality of sentences related to each of the plurality of second medical images G<b>2</b>-<i>i</i>. In the present embodiment, the interpretation report R<b>2</b>-<i>i </i>is created for each of the plurality of second medical images G<b>2</b>-<i>i</i>, and is acquired by the acquisition unit <b>21</b> and is saved in the storage <b>13</b>. The description specifying unit <b>23</b> specifies the second description regarding the second region A<b>2</b>-<i>i </i>among a plurality of descriptions included in the corresponding interpretation report R<b>2</b>-<i>i </i>for each of the plurality of second medical images G<b>2</b>-<i>i</i>. To this end, the description specifying unit <b>23</b> has a learning model <b>23</b>A that has been trained to discriminate the properties of the abnormal shadow included in the medical image for each of a plurality of predetermined property items.</p><p id="p-0067" num="0066">Here, examples of the property item specified for the abnormal shadow include the location of the abnormal shadow, the size of the abnormal shadow, the shape of the boundary (clear and irregular), the type of absorption value (solid type and frosted glass type), the presence or absence of spicula, whether it is a tumor or a nodule, the presence or absence of pleural contact, the presence or absence of pleural invagination, the presence or absence of pleural infiltration, the presence or absence of a cavity, and the presence or absence of calcification.</p><p id="p-0068" num="0067">In the present embodiment, the learning model <b>23</b>A consists of a convolutional neural network in which deep learning is performed using supervised training data so as to discriminate the properties of abnormal shadows in medical images.</p><p id="p-0069" num="0068">The learning model <b>23</b>A is trained by machine learning using, for example, a plurality of combinations of a medical image including an abnormal shadow and a property label representing the property of the abnormal shadow as supervised training data. In a case where a medical image is input, the learning model <b>23</b>A outputs a property score derived for each property item in the abnormal shadow included in the medical image. The property score is a score indicating the prominence of the property for each property item. The property score takes a value of 0 or more and 1 or less, for example, and the larger the value of the property score is, the more pronounced the property is.</p><p id="p-0070" num="0069">For example, in a case where the property score for &#x201c;the presence or absence of spicula&#x201d;, which is one of the property items of an abnormal shadow, is, for example, 0.5 or more, it is specified that the property for &#x201c;the presence or absence of spicula&#x201d; of the abnormal shadow is &#x201c;with spicula (positive)&#x201d;, and in a case where the property score for &#x201c;the presence or absence of spicula&#x201d; is less than, for example, 0.5, it is specified that the property for the presence or absence of spicula of the abnormal shadow is &#x201c;no spicula (negative)&#x201d;. The threshold value 0.5 used for property determination is merely an example, and is set to an appropriate value for each property item.</p><p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram for describing an example of property information specified by the description specifying unit <b>23</b>. As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, in property information <b>30</b> specified by the description specifying unit <b>23</b>, the properties for each property item are &#x201c;under left lung pleura&#x201d;, &#x201c;4.2 cm&#x201d;, &#x201c;irregular&#x201d;, &#x201c;solid&#x201d;, &#x201c;with spicula&#x201d;, &#x201c;tumor&#x201d;, &#x201c;with pleural contact&#x201d;, &#x201c;with pleural invagination&#x201d;, &#x201c;no pleural infiltration&#x201d;, &#x201c;no cavity&#x201d;, and &#x201c;no calcification&#x201d;. In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, + is given in the case of &#x201c;yes&#x201d;, that is, positive, and&#x2014;is given in the case of &#x201c;no&#x201d;, that is, negative.</p><p id="p-0072" num="0071">Further, the description specifying unit <b>23</b> specifies a second description D<b>2</b>-<i>i </i>regarding the second region A<b>2</b>-<i>i</i>, which is included in the interpretation report R<b>2</b>-<i>i</i>, based on the property information <b>30</b> extracted for the second region A<b>2</b>-<i>i. </i></p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram for describing the specification of the second description. Further, in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the extraction of the second description about one second medical image G<b>2</b>-<b>1</b> will be described. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, an interpretation report R<b>2</b>-<b>1</b> for the second medical image G<b>2</b>-<b>1</b> includes a plurality of descriptions for a plurality of abnormal shadows existing at a plurality of locations. On the other hand, property information <b>31</b> about the second region A<b>2</b>-<b>1</b> included in the second medical image G<b>2</b>-<b>1</b> is &#x201c;tumor, with cavity&#x201d;. Therefore, the description specifying unit <b>23</b> specifies, in a second description D<b>2</b>-<b>1</b>, the description of &#x201c;The shadow of the tumor of a right lung S<b>6</b> is about 6.5&#xd7;4 cm and is increasing. The cavity in the center of the tumor is also larger than last time&#x201d; related to the property information <b>31</b> among the plurality of descriptions included in the interpretation report R<b>2</b>-<i>i. </i></p><p id="p-0074" num="0073">In the present embodiment, the plurality of second interpretation reports R<b>2</b>-<i>i </i>for each of the plurality of second medical images G<b>2</b>-<i>i </i>and the plurality of second medical images G<b>2</b>-<i>i </i>have been acquired. Therefore, the description specifying unit <b>23</b> specifies the second description D<b>2</b>-<i>i </i>regarding each of the second regions A<b>2</b>-<i>i </i>from each of the plurality of second interpretation reports R<b>2</b>-<i>i</i>. Note that, in one interpretation report R<b>2</b>-<i>i</i>, not only one second description but also a plurality of second descriptions D<b>2</b>-<i>i </i>may be specified.</p><p id="p-0075" num="0074">Further, as the learning model <b>23</b>A, for example, any learning model such as a support vector machine and a recurrent neural network can be used, in addition to the convolutional neural network.</p><p id="p-0076" num="0075">In addition, the description specifying unit <b>23</b> is not limited to the specification of the description by the learning model <b>23</b>A. The second description D<b>2</b>-<i>i </i>may be specified by searching for the second interpretation report R<b>2</b>-<i>i </i>using the size of the tumor and items included in the diagnostic guideline as keywords.</p><p id="p-0077" num="0076">The display control unit <b>24</b> displays the plurality of second descriptions D<b>2</b>-<i>i </i>specified for each of the plurality of second medical images G<b>2</b>-<i>i </i>on the display <b>14</b> in a switchable manner. <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram showing a display screen in the first embodiment. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a display screen <b>50</b> includes an image display region <b>51</b> and a sentence display region <b>52</b>. The first medical image G<b>1</b> is displayed in the image display region <b>51</b>, and the plurality of second medical images G<b>2</b>-<i>i </i>are displayed below the first medical image G<b>1</b> in a switchable manner. In <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the second medical image G<b>2</b>-<b>1</b> shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is displayed. Further, above the first medical image G<b>1</b> and the second medical images G<b>2</b>-<i>i</i>, the imaging date and time of each medical image is displayed. Below the first medical image G<b>1</b> and the second medical images G<b>2</b>-<i>i</i>, first switching buttons <b>53</b>A and <b>53</b>B for switching the tomographic image displayed for the first medical image G<b>1</b> are displayed.</p><p id="p-0078" num="0077">The switching display of the second medical images G<b>2</b>-<i>i </i>can be performed by selecting second switching buttons <b>56</b>A and <b>56</b>B, which will be described later.</p><p id="p-0079" num="0078">The sentence display region <b>52</b> has a first description region <b>54</b> for describing an interpretation report for the first medical image G<b>1</b>, and a second description region <b>55</b> for displaying the second descriptions D<b>2</b>-<i>i </i>about the second medical images G<b>2</b>-<i>i </i>displayed in the image display region <b>51</b>. In the second description region <b>55</b>, the second descriptions D<b>2</b>-<i>i </i>about the second medical images G<b>2</b>-<i>i </i>are displayed in a switchable manner. In addition, in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the second description D<b>2</b>-<b>1</b> about the second medical image G<b>2</b>-<b>1</b> is displayed in the second description region <b>55</b>.</p><p id="p-0080" num="0079">The switching display of the second descriptions D<b>2</b>-<i>i </i>can be performed by selecting the switching buttons <b>56</b>A and <b>56</b>B displayed below the sentence display region <b>52</b>. Further, in conjunction with this, the second medical images G<b>2</b>-<i>i </i>displayed in the image display region <b>51</b> are also switched. That is, by selecting the left-facing switching button <b>56</b>A, the imaging date and time of the second medical images G<b>2</b>-<i>i </i>displayed in the image display region <b>51</b> becomes new, and the second descriptions D<b>2</b>-<i>i </i>displayed in the second description region <b>55</b> correspond to the displayed second medical images G<b>2</b>-<i>i</i>. Further, by selecting the right-facing switching button <b>56</b>B, the imaging date and time of the second medical images G<b>2</b>-<i>i </i>displayed in the image display region <b>51</b> becomes old, and the second descriptions D<b>2</b>-<i>i </i>displayed in the second description region <b>55</b> correspond to the displayed second medical images G<b>2</b>-<i>i. </i></p><p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram showing a display screen to which the second description has been switched. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in the second description region <b>55</b>, a second description D<b>2</b>-<b>2</b> is displayed in place of the second description D<b>2</b>-<b>1</b>, and in the region below the image display region <b>51</b>, the second medical image G<b>2</b>-<b>2</b> is displayed in place of the second medical image G<b>2</b>-<b>1</b>.</p><p id="p-0082" num="0081">In the initial state, it is assumed that the second medical image G<b>2</b>-<b>1</b> having the latest imaging date and time and the second description D<b>2</b>-<b>1</b> about the second medical image G<b>2</b>-<b>1</b> are displayed.</p><p id="p-0083" num="0082">The radiologist refers to the second medical images G<b>2</b>-<i>i </i>displayed in the image display region <b>51</b> and the second descriptions D<b>2</b>-<i>i </i>displayed in the sentence display region <b>52</b>, and describes the findings about the first medical image G<b>1</b> in the first description region <b>54</b>. Then, after describing the findings, the confirmation button <b>57</b> is selected.</p><p id="p-0084" num="0083">Here, in <figref idref="DRAWINGS">FIGS. <b>7</b> and <b>8</b></figref>, nothing is described in the first description region <b>54</b> in the initial state. However, as shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the second description D<b>2</b>-<b>1</b> about the second medical image G<b>2</b>-<b>1</b> displayed in the initial state may be transcribed in the first description region <b>54</b>. In this case, in a case where the displayed second description D<b>2</b>-<i>i </i>is switched and displayed, the description transcribed in the first description region <b>54</b> may also be switched. Thereby, in a case where the comments on findings about the first medical image G<b>1</b> are generated, the second description D<b>2</b>-<b>1</b> can be easily diverted, and therefore the comments on findings about the first medical image G<b>1</b> can be easily created.</p><p id="p-0085" num="0084">By the selection of the confirmation button <b>57</b> performed by the operator, the save control unit <b>25</b> saves the interpretation report including the comments on findings described in the first description region <b>54</b> and the first medical image G<b>1</b> referred to in the case of generating the interpretation report together in the storage <b>13</b>.</p><p id="p-0086" num="0085">The communication unit <b>26</b> transfers the interpretation report including the comments on findings described in the first description region <b>54</b> and the first medical image G<b>1</b> referred to in the case of generating the interpretation report together to the report server <b>7</b> via the network I/F<b>17</b>. The report server <b>7</b> saves the interpretation report including the comments on findings described in the first description region <b>54</b> and the first medical image G<b>1</b> referred to in the case of generating the interpretation report together.</p><p id="p-0087" num="0086">Next, a process performed in the first embodiment will be described. <figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart showing a process performed in the first embodiment. It is assumed that the first medical image G<b>1</b> to be interpreted, the plurality of second medical images G<b>2</b>-<i>i</i>, and the plurality of interpretation reports R<b>2</b>-<i>i </i>are acquired from the image server <b>5</b> and the report server <b>7</b> by the acquisition unit <b>21</b>, and are saved in the storage <b>13</b>. A process is started in a case where an instruction to create an interpretation report is given by the radiologist, and the region specifying unit <b>22</b> specifies the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>which are abnormal shadows by analyzing the first medical image G<b>1</b> and the plurality of second medical images G<b>2</b>-<i>i </i>(region specification; Step ST<b>1</b>).</p><p id="p-0088" num="0087">Next, the description specifying unit <b>23</b> specifies the second description D<b>2</b>-<i>i </i>regarding the specified second region A<b>2</b>-<i>i </i>in the second interpretation report R<b>2</b>-<i>i </i>related to each of the plurality of second medical images G<b>2</b>-<i>i </i>(Step ST<b>2</b>).</p><p id="p-0089" num="0088">Then, the display control unit <b>24</b> displays the plurality of second descriptions D<b>2</b>-<i>i </i>specified for each of the plurality of second medical images G<b>2</b>-<b>1</b> on the display <b>14</b> in a switchable manner (Step ST<b>3</b>). In this state, the radiologist can describe the comments on findings about the first medical image G<b>1</b> in the first description region <b>54</b>.</p><p id="p-0090" num="0089">On the other hand, the display control unit <b>24</b> determines whether or not the second switching buttons <b>56</b>A and <b>56</b>B have been selected (Step ST<b>4</b>). In a case where Step ST<b>4</b> is affirmative, the display control unit <b>24</b> switches between the second medical images G<b>2</b>-<i>i </i>displayed in the image display region <b>51</b> and the second descriptions D<b>2</b>-<i>i </i>displayed in the sentence display region <b>52</b> (display switching; Step ST<b>5</b>) and returns to Step ST<b>4</b>. In a case where Step ST<b>4</b> is negative, the display control unit <b>24</b> determines whether or not the first switching buttons <b>53</b>A and <b>53</b>B have been selected (Step ST<b>6</b>). In a case where Step ST<b>6</b> is affirmative, the display control unit <b>24</b> switches the tomographic image to be displayed in the image display region <b>51</b> for the first medical image G<b>1</b> (Step ST<b>7</b>), and returns to Step ST<b>1</b>. In a case where Step ST<b>6</b> is negative, it is determined whether or not the confirmation button <b>57</b> has been selected (Step ST<b>8</b>). In a case where Step ST<b>8</b> is negative, the process returns to Step ST<b>4</b>.</p><p id="p-0091" num="0090">In a case where Step ST<b>8</b> is affirmative, the save control unit <b>25</b> saves the first interpretation report R<b>1</b> and the first medical image G<b>1</b> for the first medical image G<b>1</b> together in the storage <b>13</b> (saving the interpretation report or the like; Step ST<b>9</b>). Then, the communication unit <b>26</b> transfers the first interpretation report R<b>1</b> and the first medical image G<b>1</b> together to the report server <b>7</b> via the network I/F<b>17</b> (transfer of the interpretation report or the like; Step ST<b>10</b>), and ends the process.</p><p id="p-0092" num="0091">Here, in the case of creating an interpretation report by interpreting the latest medical image of a certain patient, there may be a plurality of interpretation reports (second interpretation reports R<b>2</b>-<i>i</i>) for each of a plurality of past medical images (second medical images G<b>2</b>-<i>i</i>) for the same patient. In such a case, if the description about the abnormal shadow included in the interpretation report for the past image (that is, the second medical image G<b>2</b>-<i>i</i>) can be referred to, the interpretation report including the findings about the abnormal shadow included in the current medical image (that is, the first medical image G<b>1</b>) can be efficiently created.</p><p id="p-0093" num="0092">In the first embodiment, in the case of creating the interpretation report R<b>1</b> for the first medical image G<b>1</b>, the second descriptions D<b>2</b>-<i>i </i>included in the second interpretation report R<b>2</b>-<i>i </i>for the plurality of medical images G<b>2</b>-<i>i </i>are displayed in a switchable manner. Therefore, in a case where there are a plurality of images of the same patient at different imaging times, the second descriptions D<b>2</b>-<i>i </i>included in the interpretation report R<b>2</b>-<i>i </i>for the past images can be efficiently referred to. Therefore, it is possible to efficiently create the interpretation report R<b>1</b> for the first medical image G<b>1</b>.</p><p id="p-0094" num="0093">Next, a second embodiment of the present disclosure will be described. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram showing a functional configuration of the document creation support apparatus according to the second embodiment. In <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the same reference numerals are assigned to the same configurations as those in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and detailed description thereof will be omitted. As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, a document creation support apparatus <b>20</b>A according to the second embodiment is different from the first embodiment in that it further comprises a sentence generation unit <b>27</b>.</p><p id="p-0095" num="0094">The sentence generation unit <b>27</b> analyzes the first region A<b>1</b> specified by the region specifying unit <b>22</b> in the first medical image G<b>1</b> to generate a first description D<b>1</b> regarding the first region A<b>1</b>. To this end, the sentence generation unit <b>27</b> has a learning model <b>27</b>A for discriminating the properties of the first region A<b>1</b> for each of a plurality of predetermined property items. The learning model <b>27</b>A consists of a convolutional neural network that has been trained in the same manner as the learning model <b>23</b>A possessed by the description specifying unit <b>23</b>. In a case where the first region A<b>1</b> is input, the learning model <b>27</b>A outputs property information representing the properties of the first region A<b>1</b>.</p><p id="p-0096" num="0095">In addition, the sentence generation unit <b>27</b> generates comments on findings using the derived property information. To this end, the sentence generation unit <b>27</b> has a learning model <b>27</b>B that has been trained to generate a sentence from the input property information. As the learning model <b>27</b>B, for example, a recurrent neural network can be used. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram schematically showing a configuration of a recurrent neural network. As shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, a recurrent neural network <b>40</b> consists of an encoder <b>41</b> and a decoder <b>42</b>. The property information output by the learning model <b>27</b>A is input to the encoder <b>41</b>. For example, property information indicating &#x201c;under left lung pleura&#x201d;, &#x201c;4.2 cm&#x201d;, &#x201c;spicula+&#x201d; and &#x201c;tumor&#x201d; is input to the encoder <b>41</b>. The decoder <b>42</b> is trained to document character information, and generates a sentence from the input property information. Specifically, from the above-mentioned property information indicating &#x201c;under left lung pleura&#x201d;, &#x201c;4.2 cm&#x201d;, &#x201c;spicula+&#x201d; and &#x201c;tumor&#x201d;, a medical sentence &#x201c;A 4.2 cm diameter tumor having spicula is found under the left lung pleura.&#x201d; is generated. In <figref idref="DRAWINGS">FIG. <b>12</b></figref>, &#x201c;EOS&#x201d; indicates the end of the sentence (end of sentence).</p><p id="p-0097" num="0096">In this way, in order to output the comments on findings by inputting the property information, the recurrent neural network <b>40</b> is constructed by training the encoder <b>41</b> and the decoder <b>42</b> using a large amount of supervised training data consisting of a combination of the property information and the comments on findings. Note that, the generated sentence shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref> represents the findings about the lung nodule, and is generated by learning the learning model by inputting the property information of the lung nodule.</p><p id="p-0098" num="0097">In the second embodiment, the display control unit <b>24</b> displays the sentences generated by the sentence generation unit <b>27</b>, that is, the comments on findings in the first description region <b>54</b>. <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram showing a display screen in the second embodiment. In <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the same reference numerals are assigned to the same configurations as those in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, and detailed description thereof will be omitted. As shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, on the display screen <b>50</b>A in the second embodiment, in the initial state, the comments on findings regarding the first region A<b>1</b> included in the first medical image G<b>1</b> are displayed in the first description region <b>54</b> as the first description D<b>1</b>.</p><p id="p-0099" num="0098">Next, a process performed in the second embodiment will be described. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart showing a process performed in the second embodiment. It is assumed that the first medical image G<b>1</b> to be interpreted, the plurality of second medical images G<b>2</b>-<i>i</i>, and the plurality of interpretation reports R<b>2</b>-<i>i </i>are acquired from the image server <b>5</b> and the report server <b>7</b> by the acquisition unit <b>21</b>, and are saved in the storage <b>13</b>. A process is started in a case where an instruction to create an interpretation report is given by the radiologist, and the region specifying unit <b>22</b> specifies the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>which are abnormal shadows by analyzing the first medical image G<b>1</b> and the plurality of second medical images G<b>2</b>-<i>i </i>(region specification; Step ST<b>21</b>).</p><p id="p-0100" num="0099">Next, the description specifying unit <b>23</b> specifies the second description D<b>2</b>-<i>i </i>regarding the specified second region A<b>2</b>-<i>i </i>in the second interpretation report R<b>2</b>-<i>i </i>related to each of the plurality of second medical images G<b>2</b>-<i>i </i>(Step ST<b>22</b>). Further, the sentence generation unit <b>27</b> generates the first description D<b>1</b> regarding the first region A<b>1</b> included in the first medical image G<b>1</b> (Step ST<b>23</b>). Then, the display control unit <b>24</b> displays the first description D<b>1</b> in the first description region <b>54</b> (Step ST<b>24</b>), and proceeds to the process of Step ST<b>3</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. The process of Step ST<b>23</b> may be performed before the process of Step ST<b>21</b>, or may be performed in parallel with the processes of Steps ST<b>21</b> and ST<b>22</b>. Further, the process of Step ST<b>24</b> may be performed after the process of Step ST<b>3</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, or may be performed in parallel with the process of Step ST<b>3</b>.</p><p id="p-0101" num="0100">In this way, in the second embodiment, the first description D<b>1</b> regarding the first region A<b>1</b> included in the first medical image G<b>1</b> is generated, and the first description D<b>1</b> is displayed in the first description region <b>54</b>. Therefore, it is possible to reduce the burden on the radiologist who generates the comments on findings about the first region A<b>1</b> included in the first medical image G<b>1</b>.</p><p id="p-0102" num="0101">In the second embodiment, the first description D<b>1</b> generated by the sentence generation unit <b>27</b> is displayed in the first description region <b>54</b>, but in addition to the first description D<b>1</b>, the second description D<b>2</b>-<i>i </i>displayed in the second description region <b>55</b> may be transcribed in the first description region <b>54</b>. In this case, in the first description region <b>54</b>, the first description D<b>1</b> and the second description D<b>2</b>-<i>i </i>are displayed in a vertically arranged manner, for example.</p><p id="p-0103" num="0102">Next, a third embodiment of the present disclosure will be described. <figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram showing a functional configuration of the document creation support apparatus according to the third embodiment. In <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the same reference numerals are assigned to the same configurations as those in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, and detailed description thereof will be omitted. As shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, a document creation support apparatus <b>20</b>B according to the third embodiment is different from the second embodiment in that it further comprises a property difference deriving unit <b>28</b>.</p><p id="p-0104" num="0103">The property difference deriving unit <b>28</b> derives a difference between the properties for the first region A<b>1</b> included in the first description D<b>1</b> generated by the sentence generation unit <b>27</b> and the properties for the second region A<b>2</b>-<i>i </i>included in the second description D<b>2</b>-<i>i </i>specified for each of the plurality of second medical images G<b>2</b>-<i>i</i>. To this end, the property difference deriving unit <b>28</b> has a learning model <b>28</b>A that has been trained to output a difference in properties included in two sentences in a case where the two sentences are input. As the learning model <b>28</b>A, for example, a recurrent neural network can be used. The recurrent neural network constituting the learning model <b>28</b>A is constructed by training an encoder and a decoder constituting a recurrent neural network by using a large number of supervised training data consisting of a combination of two sentences and a phrase representing a difference between the two sentences.</p><p id="p-0105" num="0104">Thereby, in a case where, in the learning model <b>28</b>A of the property difference deriving unit <b>28</b>, &#x201c;a tumor with a 7&#xd7;5 cm-sized cavity is found in a right lung S<b>6</b>. Partial pleural invagination is found&#x201d; is input as the first description D<b>1</b> and &#x201c;A shadow of the tumor of the right lung S<b>6</b> is about 6.5&#xd7;4 cm and is increasing. A cavity in the center of the tumor is also larger than last time&#x201d; is input as the second description D<b>2</b>-<i>i, &#x201c;</i>7&#xd7;5 cm&#x201d; and &#x201c;pleural invagination&#x201d;, which are differences in properties included in the two descriptions, are output.</p><p id="p-0106" num="0105">The property difference deriving unit <b>28</b> derives the difference between the property included in the first description D<b>1</b> and the properties included in all the second descriptions D<b>2</b>-<i>i</i>. At this time, the difference between the property included in the first description D<b>1</b> and the properties included in all the second descriptions D<b>2</b>-<i>i </i>may be derived at once, and each time the second description D<b>2</b>-<i>i </i>is switched and displayed, the difference between the properties included in the displayed second description D<b>2</b>-<i>i </i>and the property included in the first description may be derived. For example, in a case where the switched second description D<b>2</b>-<i>i </i>is &#x201c;The shadow of the tumor of the right lung S<b>6</b> is 3&#xd7;2 cm&#x201d;, the property difference deriving unit <b>28</b> outputs &#x201c;7&#xd7;5 cm&#x201d; and &#x201c;pleural invagination&#x201d;, which are differences between the properties included in the switched second description and the property included in the first description D<b>1</b>.</p><p id="p-0107" num="0106">In the third embodiment, in a case where the difference is derived by the property difference deriving unit <b>28</b>, the display control unit <b>24</b> displays the difference between the property included in the first description D<b>1</b> and the properties included in the second description D<b>2</b>-<i>i </i>on the display <b>14</b> in a visually recognizable manner. <figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram showing a display screen in the third embodiment. In <figref idref="DRAWINGS">FIG. <b>16</b></figref>, the same reference numerals are assigned to the same configurations as those in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, and detailed description thereof will be omitted. As shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, on the display screen <b>50</b>B in the third embodiment, in the initial state, the first description D<b>1</b> regarding the first region A<b>1</b> included in the first medical image G<b>1</b> is displayed in the first description region <b>54</b>. Further, in the first description D<b>1</b>, &#x201c;7&#xd7;5 cm&#x201d; and &#x201c;pleural invagination&#x201d;, which different portions in properties from the displayed second description D<b>2</b>-<i>i</i>, are highlighted. In <figref idref="DRAWINGS">FIG. <b>16</b></figref>, highlighting is shown by enclosing different properties in a square, but the present disclosure is not limited thereto. Different phrases may be underlined, the background color of different properties may be changed, or the character color of different phrases may be changed.</p><p id="p-0108" num="0107">Next, a process performed in the third embodiment will be described. <figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart showing a process performed in the third embodiment. It is assumed that the first medical image G<b>1</b> to be interpreted, the plurality of second medical images G<b>2</b>-<i>i</i>, and the plurality of interpretation reports R<b>2</b>-<i>i </i>are acquired from the image server <b>5</b> and the report server <b>7</b> by the acquisition unit <b>21</b>, and are saved in the storage <b>13</b>. A process is started in a case where an instruction to create an interpretation report is given by the radiologist, and the region specifying unit <b>22</b> specifies the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>which are abnormal shadows by analyzing the first medical image G<b>1</b> and the plurality of second medical images G<b>2</b>-<i>i </i>(region specification; Step ST<b>31</b>).</p><p id="p-0109" num="0108">Next, the description specifying unit <b>23</b> specifies the second description D<b>2</b>-<i>i </i>regarding the specified second region A<b>2</b>-<i>i </i>in the second interpretation report R<b>2</b>-<i>i </i>related to each of the plurality of second medical images G<b>2</b>-<i>i </i>(Step ST<b>32</b>). Further, the sentence generation unit <b>27</b> generates the first description D<b>1</b> regarding the first region A<b>1</b> included in the first medical image G<b>1</b> (Step ST<b>33</b>). Then, the property difference deriving unit <b>28</b> derives the difference between the property included in the first description D<b>1</b> and the property included in the second description D<b>2</b>-<i>i </i>(Step ST<b>34</b>).</p><p id="p-0110" num="0109">Next, the display control unit <b>24</b> displays the first description D<b>1</b> in the first description region <b>54</b> (Step ST<b>35</b>), further highlights the different portion in properties from the second description D<b>2</b>-<i>i </i>in the first description D<b>1</b> (Step ST<b>36</b>), and proceeds to the process of Step ST<b>3</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. The process of Step ST<b>33</b> may be performed before the process of Step ST<b>31</b>, or may be performed in parallel with the processes of Steps ST<b>31</b> and ST<b>32</b>. Further, the processes of Steps ST<b>35</b> and ST<b>36</b> may be performed after the process of Step ST<b>3</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, or may be performed in parallel with the process of Step ST<b>3</b>.</p><p id="p-0111" num="0110">In this way, in the third embodiment, the first description D<b>1</b> regarding the first region A<b>1</b> included in the first medical image G<b>1</b> is generated, and the first description D<b>1</b> is displayed in the first description region <b>54</b>. Further, at this time, by deriving the differences in properties between the first description D<b>1</b> and the second description D<b>2</b>-<i>i </i>and highlighting the different portions, the differences in properties can be displayed in a visually recognizable manner. Therefore, it is possible to reduce the burden on the radiologist who generates the comments on findings about the first region A<b>1</b> included in the first medical image G<b>1</b>, and to check the difference in the description contents regarding the properties of the generated first description D<b>1</b> and the second description D<b>2</b>-<i>i. </i></p><p id="p-0112" num="0111">In the third embodiment, in the first description D<b>1</b> the different portions in properties from the second description D<b>2</b>-<i>i </i>are highlighted, but the present disclosure is not limited thereto. In the second description D<b>2</b>-<i>i</i>, the different portions from the property of the first description may be highlighted, and the different portions in properties in both the first description D<b>1</b> and the second description D<b>2</b>-<i>i </i>may be highlighted.</p><p id="p-0113" num="0112">Next, a fourth embodiment of the present disclosure will be described. <figref idref="DRAWINGS">FIG. <b>18</b></figref> is a diagram showing a functional configuration of the document creation support apparatus according to the fourth embodiment. In <figref idref="DRAWINGS">FIG. <b>18</b></figref>, the same reference numerals are assigned to the same configurations as those in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and detailed description thereof will be omitted. As shown in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, a document creation support apparatus <b>20</b>C according to the fourth embodiment is different from the first embodiment in that it further comprises a region difference deriving unit <b>29</b>.</p><p id="p-0114" num="0113">The region difference deriving unit <b>29</b> derives a difference between the first region A<b>1</b> detected from the first medical image G<b>1</b> and the second region A<b>2</b>-<i>i </i>detected from each of the plurality of second medical images G<b>2</b>-<i>i</i>. To this end, the region difference deriving unit <b>29</b> has a learning model <b>29</b>A that has been trained to output a difference between two images in a case where the two images are input. As the learning model <b>29</b>A, for example, a convolutional neural network can be used. The convolutional neural network constituting the learning model <b>29</b>A is constructed by training a convolutional neural network by using a large number of supervised training data consisting of a combination of two images and information indicating a difference between the two images (for example, a difference region, a difference value, or the like).</p><p id="p-0115" num="0114">Thereby, in a case where the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>are input to the learning model <b>29</b>A of the region difference deriving unit <b>29</b>, the difference between the two regions is output. <figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram for describing the derivation of the difference between the two regions. Note that <figref idref="DRAWINGS">FIG. <b>19</b></figref> shows only the abnormal shadows in the first medical image G<b>1</b> and the second medical image G<b>2</b>-<i>i</i>, that is, the partial region including the first region A<b>1</b> and the second region A<b>2</b>-<i>i</i>. As shown in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, in a case where the first region A<b>1</b> in the first medical image G<b>1</b> is smaller than the second region A<b>2</b>-<i>i </i>in the second medical image G<b>2</b>-<i>i</i>, the region difference deriving unit <b>29</b> derives a difference <b>60</b> in the region as shown in <figref idref="DRAWINGS">FIG. <b>19</b></figref>.</p><p id="p-0116" num="0115">The region difference deriving unit <b>29</b> derives the difference between the first region A<b>1</b> and all the second regions A<b>2</b>-<i>i</i>. At this time, the difference between the first region A<b>1</b> and all the second regions A<b>2</b>-<i>i </i>may be derived at once, and each time the second medical image G<b>2</b>-<i>i </i>is switched and displayed, the difference between the second region A<b>2</b>-<i>i </i>and the first region A<b>1</b> detected from the displayed second medical image G<b>2</b>-<i>i </i>may be derived.</p><p id="p-0117" num="0116">In the fourth embodiment, the display control unit <b>24</b> displays the second description D<b>2</b>-<i>i </i>in a case where the difference between the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>is derived by the region difference deriving unit <b>29</b>. In addition, in the present embodiment, a plurality of second medical images G<b>2</b>-<i>i </i>are acquired, and regarding the second region A<b>2</b>-<i>i </i>detected from each of the second medical images G<b>2</b>-<i>i</i>, there are some that are different from the first region A<b>1</b> and some that are not different from the first region A<b>1</b>. Therefore, the display control unit <b>24</b> displays the second description D<b>2</b>-<i>i </i>in the second description region <b>55</b> only in a case where the second medical image G<b>2</b>-<i>i </i>including the second region A<b>2</b>-<i>i </i>that is different from the first region A<b>1</b> is displayed. On the other hand, in a case where the second medical image G<b>2</b>-<i>i </i>including the second region A<b>2</b>-<i>i </i>that is not different from the first region A<b>1</b> is displayed, the display control unit <b>24</b> displays that there is no difference in the second description region <b>55</b>. For example, as shown in a display screen <b>50</b>C of <figref idref="DRAWINGS">FIG. <b>20</b></figref>, the display control unit <b>24</b> displays, in the image display region <b>51</b>, a second medical image G<b>2</b>-<b>3</b> including a second region that is not different from the first region A<b>1</b> included in the first medical image G<b>1</b>, and displays, in the second description region <b>55</b>, the text &#x201c;there is no change in the abnormal shadows of the two medical images&#x201d;.</p><p id="p-0118" num="0117">Next, a process performed in the fourth embodiment will be described. <figref idref="DRAWINGS">FIG. <b>21</b></figref> is a flowchart showing a process performed in the fourth embodiment. It is assumed that the first medical image G<b>1</b> to be interpreted, the plurality of second medical images G<b>2</b>-<i>i</i>, and the plurality of interpretation reports R<b>2</b>-<i>i </i>are acquired from the image server <b>5</b> and the report server <b>7</b> by the acquisition unit <b>21</b>, and are saved in the storage <b>13</b>. A process is started in a case where an instruction to create an interpretation report is given by the radiologist, and the region specifying unit <b>22</b> specifies the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>which are abnormal shadows by analyzing the first medical image G<b>1</b> and the plurality of second medical images G<b>2</b>-<i>i </i>(region specification; Step ST<b>41</b>).</p><p id="p-0119" num="0118">Next, the description specifying unit <b>23</b> specifies the second description D<b>2</b>-<i>i </i>regarding the specified second region A<b>2</b>-<i>i </i>in the second interpretation report R<b>2</b>-<i>i </i>related to each of the plurality of second medical images G<b>2</b>-<i>i </i>(Step ST<b>42</b>). Further, the region difference deriving unit <b>29</b> derives the difference between the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>(Step ST<b>43</b>). The process of Step ST<b>43</b> may be performed before the process of Step ST<b>42</b>, or may be performed in parallel with the process of Step ST<b>42</b>.</p><p id="p-0120" num="0119">Then, the display control unit <b>24</b> determines whether or not there is a difference between the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>with respect to the second medical image G<b>2</b>-<i>i </i>displayed in the initial state (Step ST<b>44</b>). In a case where Step ST <b>44</b> is affirmative, the display control unit <b>24</b> displays the second descriptions D<b>2</b>-<i>i </i>specified for the second medical image G<b>2</b>-<b>1</b> to be displayed in the initial state on the display <b>14</b> in a switchable manner (Step ST<b>45</b>). In a case where Step ST<b>44</b> is negative, the display control unit <b>24</b> displays that there is no difference in the second description region <b>55</b> (Step ST<b>46</b>).</p><p id="p-0121" num="0120">Following Steps ST<b>45</b> and ST<b>46</b>, the display control unit <b>24</b> determines whether or not the second switching buttons <b>56</b>A and <b>56</b>B have been selected (Step ST<b>47</b>). In a case where Step ST<b>47</b> is affirmative, the display control unit <b>24</b> switches the second medical image G<b>2</b>-<i>i </i>to be displayed in the image display region <b>51</b> (display switching; Step ST<b>48</b>), and returns to Step ST<b>44</b>. In a case where Step ST<b>47</b> is negative, the display control unit <b>24</b> determines whether or not the first switching buttons <b>53</b>A and <b>53</b>B have been selected (Step ST<b>49</b>). In a case where Step ST<b>49</b> is affirmative, the display control unit <b>24</b> switches the tomographic image to be displayed in the image display region <b>51</b> for the first medical image G<b>1</b> (Step ST<b>50</b>), and returns to Step ST<b>41</b>. In a case where Step ST<b>49</b> is negative, the display control unit <b>24</b> determines whether or not the confirmation button <b>57</b> has been selected (Step ST<b>51</b>). In a case where Step ST<b>51</b> is negative, the process returns to Step ST<b>47</b>. In a case where Step ST<b>51</b> is affirmative, the process proceeds to Step ST<b>9</b> shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0122" num="0121">In this way, in the fourth embodiment, the difference between the first region A<b>1</b> and the second region A<b>2</b>-<i>i </i>is derived, and in a case where there is a difference, the second description D<b>2</b>-<i>i </i>is displayed. Therefore, in a case where there is a change in the abnormal shadow between the first medical image G<b>1</b> and the second medical image G<b>2</b>-<i>i</i>, the second description D<b>2</b>-<i>i </i>about the abnormal shadow can be referred to. Therefore, with respect to the first medical image G<b>1</b>, it is possible to efficiently create a comment on findings regarding the change in the abnormal shadow.</p><p id="p-0123" num="0122">In the fourth embodiment, in a case where the display control unit <b>24</b> displays the second medical image G<b>2</b>-<i>i </i>including the second region A<b>2</b>-<i>i </i>that is not different from the first region A<b>1</b>, the display control unit <b>24</b> displays that there is no difference in the second description region <b>55</b>. However, the present disclosure is not limited thereto. In a case where the second medical image G<b>2</b>-<i>i </i>including the second region A<b>2</b>-<i>i </i>that is not different from the first region A<b>1</b> is displayed, the display control unit may display the second description D<b>2</b>-<i>i </i>about the second medical image G<b>2</b>-<i>i </i>in the second description region <b>55</b>, and may display that there is no difference in the first description region <b>54</b>.</p><p id="p-0124" num="0123">Further, in the fourth embodiment, the region difference deriving unit <b>29</b> is provided in the first embodiment, but the present disclosure is not limited thereto. In the second embodiment or the third embodiment, the region difference deriving unit <b>29</b> may be provided.</p><p id="p-0125" num="0124">Further, in each of the above embodiments, the technique of the present disclosure is applied in the case of creating an interpretation report using a medical image with the lung as the diagnosis target, but the diagnosis target is not limited to the lung. In addition to the lung, any part of a human body such as a heart, liver, brain, and limbs can be diagnosed. In this case, the diagnostic guideline according to the diagnosis target part may be acquired, and the corresponding portion corresponding to the item of the diagnostic guideline in the interpretation report may be specified.</p><p id="p-0126" num="0125">Further, in each of the above embodiments, for example, as hardware structures of processing units that execute various kinds of processing, such as the acquisition unit <b>21</b>, the region specifying unit <b>22</b>, the description specifying unit <b>23</b>, the display control unit <b>24</b>, the save control unit <b>25</b>, the communication unit <b>26</b>, the sentence generation unit <b>27</b>, the property difference deriving unit <b>28</b>, and the region difference deriving unit <b>29</b>, various processors shown below can be used. As described above, the various processors include a programmable logic device (PLD) as a processor of which the circuit configuration can be changed after manufacture, such as a field programmable gate array (FPGA), a dedicated electrical circuit as a processor having a dedicated circuit configuration for executing specific processing such as an application specific integrated circuit (ASIC), and the like, in addition to the CPU as a general-purpose processor that functions as various processing units by executing software (programs).</p><p id="p-0127" num="0126">One processing unit may be configured by one of the various processors, or may be configured by a combination of the same or different kinds of two or more processors (for example, a combination of a plurality of FPGAs or a combination of the CPU and the FPGA). In addition, a plurality of processing units may be configured by one processor.</p><p id="p-0128" num="0127">As an example where a plurality of processing units are configured by one processor, first, there is a form in which one processor is configured by a combination of one or more CPUs and software as typified by a computer, such as a client or a server, and this processor functions as a plurality of processing units. Second, there is a form in which a processor for realizing the function of the entire system including a plurality of processing units via one integrated circuit (IC) chip as typified by a system on chip (SoC) or the like is used. In this way, various processing units are configured by one or more of the above-described various processors as hardware structures.</p><p id="p-0129" num="0128">Furthermore, as the hardware structure of the various processors, more specifically, an electrical circuit (circuitry) in which circuit elements such as semiconductor elements are combined can be used.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A document creation support apparatus comprising at least one processor,<claim-text>wherein the processor is configured to</claim-text><claim-text>specify, with respect to a first region specified in a first image of a subject, a second region corresponding to the first region in each of a plurality of second images of the subject whose imaging time is different from that of the first image,</claim-text><claim-text>specify a second description regarding the specified second region, which is included in a plurality of sentences related to each of the plurality of second images, and</claim-text><claim-text>display a plurality of second descriptions specified for each of the plurality of second images in a switchable manner.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The document creation support apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to further display a description region for describing a sentence related to the first region.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The document creation support apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the processor is configured to transcribe at least one of the plurality of second descriptions to the description region.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The document creation support apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the processor is configured to<claim-text>analyze the first region to generate a first description regarding the first region, and</claim-text><claim-text>display the first description in the description region.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The document creation support apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the processor is configured to<claim-text>derive a difference between a property related to the first region included in the first description and a property related to the second region included in the second description specified for each of the plurality of second images, and</claim-text><claim-text>display the difference between the property included in the first description and the property included in the second description in a visually recognizable manner.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The document creation support apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to derive a difference between the first region and the second region.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The document creation support apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the processor is configured to display the second description in a case where the difference has been derived.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The document creation support apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the processor is configured to notify that the difference has not been derived in a case where the difference has not been derived.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A document creation support method comprising:<claim-text>specifying, with respect to a first region specified in a first image of a subject, a second region corresponding to the first region in each of a plurality of second images of the subject whose imaging time is different from that of the first image;</claim-text><claim-text>specifying a second description regarding the specified second region, which is included in a plurality of sentences related to each of the plurality of second images; and</claim-text><claim-text>displaying a plurality of second descriptions specified for each of the plurality of second images in a switchable manner.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A document creation support program causing a computer to execute a procedure comprising:<claim-text>specifying, with respect to a first region specified in a first image of a subject, a second region corresponding to the first region in each of a plurality of second images of the subject whose imaging time is different from that of the first image;</claim-text><claim-text>specifying a second description regarding the specified second region, which is included in a plurality of sentences related to each of the plurality of second images; and</claim-text><claim-text>displaying a plurality of second descriptions specified for each of the plurality of second images in a switchable manner.</claim-text></claim-text></claim></claims></us-patent-application>
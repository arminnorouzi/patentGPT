<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004217A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004217</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364878</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>73</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>246</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>378</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>013</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>74</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>248</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>5</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>378</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">EYE TRACKING IMAGER WITH GATED DETECTORS RECEIVING A SPECULAR REFLECTION</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>MICROSOFT TECHNOLOGY LICENSING, LLC</orgname><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>PUTTASWAMY</last-name><first-name>Niranjan Achugundla</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>GIBSON</last-name><first-name>Gregory Theodore</first-name><address><city>Duvall</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>MARGOLIS</last-name><first-name>Jeffrey Neil</first-name><address><city>Seattle</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>TARDIF</last-name><first-name>John Allen</first-name><address><city>Bellevue</city><state>WA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Technologies are described herein for an eye tracking that may be employed by devices and systems such as head mount display (HMD) devices. Light that is reflected from a user's eye may be specular or scattered. The specular light has an intensity or magnitude that may saturate the electronics. The presently disclosed techniques mitigate saturation by generating detected signals from an optical detector, evaluating the signal levels for the detected signal, and selectively gating the detected signals that have saturated. The remaining scattered signals can be combined to achieve a combined signal that can be converted into a digital signal without saturating the electronics, which can then be processed to form an image of the eye for identification purposes, for tracking eye movement, and for other uses. The described technologies provide a clear image without ambient light reflections or specular light interfering with the image.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="93.47mm" wi="158.75mm" file="US20230004217A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="261.45mm" wi="167.30mm" orientation="landscape" file="US20230004217A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="254.42mm" wi="167.98mm" orientation="landscape" file="US20230004217A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="238.51mm" wi="167.98mm" orientation="landscape" file="US20230004217A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="254.59mm" wi="176.70mm" orientation="landscape" file="US20230004217A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="258.57mm" wi="167.98mm" orientation="landscape" file="US20230004217A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="252.90mm" wi="166.71mm" orientation="landscape" file="US20230004217A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="248.67mm" wi="166.79mm" orientation="landscape" file="US20230004217A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="206.84mm" wi="133.60mm" file="US20230004217A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Near-Eye-Display (NED) systems are designed to generate computer-generated images (&#x201c;CG images&#x201d;) that are observable in a user's field of view. In one example, an augmented-reality (AR) system generates one or more hologram images that are rendered in the user's line of sight, where the hologram images are overlaid or combined with other objects present in the real world. In another example, a virtual-reality (VR) system creates a user's entire view such that the real world is completely obstructed by a virtual world.</p><p id="p-0003" num="0002">The NED systems may often be referred to as a head-mounted display, hereinafter &#x201c;HMD,&#x201d; since the NED system is typically worn as a headset that is located on the user's head about their eyes. An HMD can include cameras or video devices for capturing the real-world scenes and objects, as well as other devices such as gyroscopic sensors to sense motion and movement of the user's head. As a user moves their head during a session, the various sensors can detect motion and rendered the correct images and environment so that the user may be provided with a proper perspective and view of the virtual objects. In some instances, the HMD system may include additional devices to track the motion of a user's eye. By tracking motion of the eye, the HMD can determine the appropriate images to render based on the direction and focus of the user's gaze.</p><p id="p-0004" num="0003">The disclosure made herein is presented with respect to these and other considerations.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0005" num="0004">Technologies are described herein for an eye tracking that may be employed by devices and systems such as head mount display (HMD) devices. Light that is reflected from a user's eye may be specular or scattered. The specular light has an intensity or magnitude that may saturate the electronics. The presently disclosed techniques mitigate saturation by generating detected signals from an optical detector, evaluating the signal levels for the detected signal, and selectively gating the detected signals that have saturated. The remaining scattered signals can be combined to achieve a combined signal that can be converted into a digital signal without saturating the electronics, which can then be processed to form an image of the eye for identification purposes, for tracking eye movement, and other for uses. The described technologies provide a clear image without ambient light reflections or specular light interfering with the image.</p><p id="p-0006" num="0005">It should be appreciated that the above-described subject matter may also be implemented as part of an apparatus, system, or as part of an article of manufacture. These and various other features will be apparent from a reading of the following Detailed Description and a review of the associated drawings.</p><p id="p-0007" num="0006">This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended that this Summary be used to limit the scope of the claimed subject matter. Furthermore, the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0008" num="0007">The Detailed Description is described with reference to the accompanying figures. References made to individual items of a plurality of items can use a reference number with a letter of a sequence of letters to refer to each individual item. Generic references to the items may use the specific reference number without the sequence of letters.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a schematic diagram of an example imager system.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a schematic diagram of another example imager system.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a partial view of yet another example imager system.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a partial view of still another example imager system.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a graph of example signals in an example imager system.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a partial view of still yet another example imager system.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows the display device in the form of a head-mounted display device.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an example computing environment in which the computer device may be enacted.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0017" num="0016">In the following detailed description, reference is made to the accompanied drawings, which form a part hereof, and which is shown by way of illustration, specific example configurations of which the concepts can be practiced. These configurations are described in sufficient detail to enable those skilled in the art to practice the techniques disclosed herein, and it is to be understood that other configurations can be utilized, and other changes may be made, without departing from the spirit or scope of the presented concepts. The following detailed description is, therefore, not to be taken in a limiting sense, and the scope of the presented concepts is defined only by the appended claims.</p><p id="p-0018" num="0017">Throughout the specification and claims, the following terms take the meanings explicitly associated herein, unless the context clearly dictates otherwise. The meaning of &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; includes plural reference, the meaning of &#x201c;in&#x201d; includes &#x201c;in&#x201d; and &#x201c;on.&#x201d; The term &#x201c;connected&#x201d; means a direct electrical connection between the items connected, without any intermediate devices. The term &#x201c;coupled&#x201d; means a direct electrical connection between the items connected, or an indirect connection through one or more passive or active intermediary devices and/or components. The terms &#x201c;circuit&#x201d; and &#x201c;component&#x201d; means either a single component or a multiplicity of components, either active and/or passive, that are coupled to provide a desired function. The term &#x201c;signal&#x201d; means at least a power, current, voltage, or data signal.</p><p id="p-0019" num="0018">Technologies are described herein for an eye tracking that may be employed by devices and systems such as head mount display (HMD) devices. Light that is reflected from a user's eye may be specular or scattered. The specular light has an intensity or magnitude that may saturate the electronics, which may occlude certain features of the eye that could be used for user authentication. The presently disclosed techniques mitigate saturation by generating detected signals from an optical detector, evaluating the signal levels for the detected signal, and selectively gating the detected signals that have saturated. The remaining scattered signals can be combined to achieve a combined signal that can be converted into a digital signal without saturating the electronics, which can then be processed for a number of uses such as tracking eye movement, capturing a clear view of features for a user's eye that may be used for authentication, etc.</p><p id="p-0020" num="0019">HMD devices often include multiple lasers that each emit a beam of laser light corresponding to a different color (e.g., Red, Green, Blue), and one or more mirror devices that direct each of the beams of laser light into the user's field of view. The mirror devices, which are typically implemented as a micro electromechanical systems (MEMs) based devices, direct and/or deflect the beams to scan across a region of the user's eye. Through this scanning operation, a MEMs-based scanner device is able to render an image that is viewable to the user.</p><p id="p-0021" num="0020">In addition to a color image that is directed to the user's eye as a drawn image by one or more lasers, the HMD device may also include a laser that emits an infrared (IR) light beam (or light wave). The infrared light beam may be deflected or directed to the user's eye by a MEMS based mirror device. In some examples, the same MEMS mirror device as one of the color lasers may be used to deflect or direct the IR light beam to the user's eye.</p><p id="p-0022" num="0021">An IR light beam may be used to track the motion of the user's eye as will be further described below. However, any other wavelength of light may also be used to track the user's eye. For example, one or more of a red (R) laser light, a green (G) laser light, a blue (B) laser light, or various combinations thereof may be used to track the user's eye. Additionally, an infrared laser light may be used in combination with one or more of the red laser light, the green laser light, and/or the blue laser light, without departing from the spirit of the present disclosure. For simplicity, the remaining disclosure will refer to the infrared light beam being used for eye-motion tracking, but the disclosure is not so limited.</p><p id="p-0023" num="0022">Once an infrared light wave strikes an object such as the user's eye, light will be reflected and scattered by the surface, referred to as a specular or a scattered reflection. For a specular reflection, the reflected ray of light will have an angle of reflection (&#x3b8;<sub>r</sub>) that is the same as the incident angle (&#x3b8;<sub>i</sub>), meaning &#x3b8;<sub>r</sub>=&#x3b8;<sub>i</sub>; while for a scattered reflection the reflected ray of light will have a different angle of reflection (&#x3b8;<sub>r</sub>) from the incident angle (&#x3b8;<sub>i</sub>), meaning &#x3b8;<sub>r</sub>&#x2260;&#x3b8;<sub>i</sub>. The specular reflection corresponds to the &#x201c;glint&#x201d; of the user's eye, while the scatter reflections correspond to the user's iris information. As a result, these reflections can also be used to authenticate the user's iris.</p><p id="p-0024" num="0023">Due to the properties of the surface of a user's eye, multiple reflections may be generated at the same time from one incident light beam. Each of these reflections will have a different reflection angle, where the intensity (or amplitude) of a specular reflection will be higher than the intensity of any of the scattered reflection. These reflections can be captured and analyzed by photosensitive devices, as will be further described below.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a schematic diagram of an example eye-tracking imager system <b>100</b> that is arranged in accordance with aspects of the presently disclosed technology. System <b>100</b> includes a digitizer <b>101</b>, a processor <b>170</b>, and a memory <b>180</b>.</p><p id="p-0026" num="0025">Digitizer <b>101</b> is configured to receive one or more reflected light beams, <b>10</b>-<b>1</b> to <b>10</b>-N, from an object <b>103</b>. The reflected light beams, <b>10</b>-<b>1</b> through <b>10</b>-N, may correspond to direct reflections from an object or indirect reflections from the object. Indirect reflections may be provided by other optical devices, including but not limited to optical waveguides, lenses, convex or concave lenses, collimators, prisms, mirrors, MEMS, filters, etc.). In various examples described herein, the object that is the source of reflections may correspond to a user's eye.</p><p id="p-0027" num="0026">The digitizer <b>103</b> may be used to capture the specular and scattered reflections from the object (or user's eye) and to generate an electrical response. The electrical response can be a digital signal <b>51</b>, which may then be processed by processor <b>170</b> to generate an image. Processor <b>170</b> can interact with memory <b>180</b> via a communication bus <b>72</b>. In some examples, processor <b>170</b> may include memory <b>180</b> as either a separate memory or an onboard memory, which may be configured to store image data for each of the pixels from the image(s).</p><p id="p-0028" num="0027">In one example, processor <b>170</b> captures image data from digital signal <b>51</b>, wherein the captured image data is time stamped and stored in memory <b>180</b>. The captured image data can be correlated with the x, y pixel positions based on time, since the scan angle of the mirrors correspond to specific pixel positions. Thus, an image can be formed by correlation of the captured image data and the corresponding x,y position based on the time stamp.</p><p id="p-0029" num="0028">The processor <b>170</b> may be a controller, a microcontroller, a microprocessor, a digital signal processor, or any other appropriate processor that may be implemented as an integrated or discrete solution, or a combination thereof. An example processor <b>170</b> may also be implemented as a system-on-a-chip (SOIC), an application specific integrated circuit (ASIC), a hybrid circuit, or some combination thereof.</p><p id="p-0030" num="0029">The digitizer <b>103</b> may be used to generate an initial image of a user's eye from a digital signal <b>51</b> that is output from the digitizer <b>103</b>. Additionally, multiple eye images may be generated from the digital signal <b>51</b>, spanning across a time period. The digital signal(s) <b>151</b> for each individual image corresponds to a position of the user's eye at a specific point in time. The differences between each image can be evaluated (e.g., by processor <b>170</b>) to determine how the user's eye moves from one image to the next, tracking the direction of gaze and/or movement of the eye position over time.</p><p id="p-0031" num="0030">The digitizer <b>101</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> includes an optical filter <b>110</b>, an optical detector <b>120</b>, a signal combiner <b>130</b>, an analog filter <b>140</b>, an analog-to-digital converter (ADC) <b>150</b>, and a controller circuit <b>160</b>. The optical filter <b>110</b> is positioned between the optical detector <b>120</b> and the reflected light beams <b>10</b>-<b>1</b> to <b>10</b>-N. Responsive to the reflected lights beams, <b>12</b>-<b>1</b> to <b>12</b>-N, the optical detector <b>120</b> is configured to generate analog detection signals <b>12</b>-<b>1</b> to <b>12</b>-N. Signal combiner <b>130</b> is configured to receive the analog detection signals <b>12</b>-<b>1</b> to <b>12</b>-N and generate a combined analog signal <b>31</b>, which corresponds to a summation of one or more of the analog detection signals <b>12</b>-<b>1</b> to <b>12</b>-N. The combined analog signal <b>31</b> is received by the analog filter <b>140</b>, which responsively generates a filtered analog signal <b>41</b>. The filtered analog signal <b>41</b> is received by the analog-to-digital converter <b>150</b>, which responsively generates the digital signal <b>51</b>.</p><p id="p-0032" num="0031">Optical filter <b>110</b> is an optional device that may be employed for wavelength or spatial filtering of optical signals received by the optical detector <b>120</b>. This filter can be configured to filter out light with wavelengths that are different from the incident beam (e.g. the wavelength of the beam that is incident on object <b>103</b>). In one example, the optical filter <b>110</b> can be used to block undesired ambient light, while allowing the reflected light from the object <b>103</b> to pass through the optical filter <b>110</b>. In another example, the optical filter <b>110</b> can be configured to block out (or alternatively pass light) in the red, green, and/or blue light spectrums. In yet another example, the optical filter <b>110</b> may be configured to block light waves with wavelengths in the visible spectrum. In still other examples, the optical filter <b>110</b> may be configured to block light (or alternatively pass light) with a wavelength in a specific portion of the infrared wavelength spectrum (or any other spectrum). In yet still other examples, the optical filter <b>110</b> may be configured to block or pass light with a specific polarization.</p><p id="p-0033" num="0032">Optical detector <b>120</b> is a sensor device that is configured to generate multiple (N) electrical signals <b>12</b>-<b>1</b> to <b>12</b>-N, or analog detection signals, which result from light being detected as incident on the optical detector <b>120</b>. Optical detector <b>120</b> is a photo-multiplier type of device that includes multiple photodiode circuits, each one generating a signal responsive to light incident thereon. The photodiode circuits are photosensitive PN junction devices that can be built on a silicon substrate, where each PN junction generates an electrical signal in response to photons that are incident thereon. In some examples, the photodiode circuits include avalanche type photodiodes, while in other examples the photodiode circuits include PIN type photodiodes.</p><p id="p-0034" num="0033">The signal combiner <b>130</b> is configured to receive the electrical signals <b>12</b>-<b>1</b> to <b>12</b>-N from the optical detector <b>120</b>, and combine the signals into a single analog output, combined analog signal <b>31</b>. The signal combiner <b>130</b> includes circuitry and/or logic that favors non-saturated signals over saturated signals, given that the non-saturated signals contain useful information, while saturated signals contain less useful information. As such, the circuits and/or logic of the signal combiner is configured to evaluate adjacent pairs of detection signals to determine if either of the adjacent pairs of signals have saturated, and promotes the non-saturated signal for summation with the other signals.</p><p id="p-0035" num="0034">In some examples, the signal combiner <b>130</b> may provide one or more digital saturation detection signals <b>32</b> to the processor <b>170</b>, where digital signal <b>32</b> indicates whether saturation occurs in the optical detector <b>120</b>. Processor <b>170</b> may capture the digital saturation detection signals <b>32</b> and store saturation data in memory <b>180</b>. The saturation data may further include a time stamp that can be correlated with other characteristics of the image generation (e.g., a time and position of a scanning mirror can be correlated to an image of the eye at a particular scan angle).</p><p id="p-0036" num="0035">Analog Filter <b>140</b> is an optional device that may be any variety of analog filter that may be employed to filter the combined analog signal <b>31</b> from the signal combiner <b>130</b> prior to sampling the electrical response with ADC <b>150</b>. The analog filter may be a high-pass filter, a low-pass filter, a band-pass filter, a phase-shape filter, or any combination thereof. The filter(s) may be employed to effectively reduce the signal-to-noise ratio to improves the output of the ADC <b>150</b>. In some examples, the analog filter <b>140</b> may include a passive circuit (e.g. without gain), while in other examples the analog filter <b>140</b> may include an active circuit (e.g. with gain).</p><p id="p-0037" num="0036">ADC <b>150</b> is an analog-to-digital converter that is configured to sample the electrical response from an optical detector <b>120</b>, via the combined analog signal <b>31</b> from the signal combiner <b>130</b>. ADC <b>150</b> may sample the combined analog signal <b>31</b> at a predetermined frequency. As previously described, an optional analog filter <b>140</b> may be employed to filter the optical sensor's electrical response before the ADC samples, thereby reducing the signal to noise ratio and improves the output of the ADC. Also, a gain block may be employed to gain scale the signal before conversion by ADC <b>150</b> to improve the quantization and/or linearity of the ADC. The described gain block may be separate from the filter, included in the filter, or incorporated in the ADC <b>150</b>. In some further examples, multiple optical detectors <b>120</b> may be employed, each with a corresponding signal combiner <b>130</b> and ADC <b>150</b>.</p><p id="p-0038" num="0037">The controller circuit <b>160</b> is configured to receive one or more configuration signals from the processor <b>170</b> via a communication interface <b>71</b>, which may be either an analog configuration signal or a digital configuration signal (e.g., data). In response to the one or more configuration signals, the controller circuit <b>160</b> is configured to generate one or more control signals for the signal combiner <b>130</b>, the analog filter <b>140</b>, and the ADC <b>150</b>. As will be described later, one control signal, e.g., <b>61</b>, may be utilized to configure threshold voltage settings in the signal combiner <b>130</b>. Another control signal, e.g. <b>62</b>, may be utilized to adjust filter or gain coefficients for analog filter <b>140</b>. Still another control signal, e.g. <b>63</b>, may be utilized to control ADC <b>150</b> (e.g., start/end/run calibration of the ADC, adjust/select a reference value for the ADC, clock frequency or duty cycle of clock signals, adjust gain or linearity of the ADC, etc.).</p><p id="p-0039" num="0038">The intensity of a specular reflection is higher than the intensity of a diffuse/scattered reflected infrared light waves. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, intensity is shown by the varying thickness of the weighted lines. The thinnest lines have the lowest intensity, while the thickest lines have the highest intensity.</p><p id="p-0040" num="0039">As previously stated, an incident laser beam on an object (such as a user's eye) will result in specular and scattered reflections that can be captured by the digitizer <b>103</b> to generate an electrical response. However, there is a high likelihood that a reflection from the cornea of a user will result a large specular reflection, where a large percentage of the incident laser power will reflect from the object and become incident on the optical detector <b>120</b>. This large specular reflection may result in an undesirable saturation of the optical detector <b>120</b> and/or the signal processing electronics. For example, the signals resulting from the specular reflections can exceed the dynamic range of the optical sensors or the signal processing electronics, which results in a saturated area of the image. Information in these saturated areas is essentially lost, since the saturated areas offer no information.</p><p id="p-0041" num="0040">The signal combiner <b>130</b> described herein is configured to evaluate the output of the optical detector <b>120</b> output and gate the detector signals that are likely to saturate the signal electronics. Saturation is avoided and the overall signals can be processed for improved images without loss of information. As will be described herein, the signal combiner <b>130</b> includes selection logic that automatically preserves the intensity level in regions that have been gated off due to the specular reflections. A continuous greyscale image may be formed without areas that would have been saturated by the specular reflections. The image data is captured by processor <b>170</b> capturing digital signal <b>31</b>, which is output from ADC <b>150</b>, and storing the collection of samples in memory <b>180</b>.</p><p id="p-0042" num="0041">In addition to detection, the saturation information about the optical detector <b>120</b> can be utilized to assist in image capture and detection of glints. The location of a glint in an image may be correlated to the position of the mirror at the time where a spectral reflection is observed. For example, a spectral reflection may be identified when a optical detector <b>120</b> saturates at a particular time, which is captured as digital saturation detection signal <b>32</b> along with a time stamp of the capture; and the mirror position of the scanner at that same time provides angle information. For this example, an image may be formed two ways: a first image may be formed from a collection of digital signal <b>51</b> and time stamped from ADC <b>150</b>, and a second image may be formed from a collection of time stamped digital saturation detection signals <b>32</b>. The first image may correspond to the collection of pixel information for an unsaturated image (e.g. from signal <b>51</b>); while the second image may correspond to the collection of saturation detections (e.g., from signal <b>32</b>). The time stamped saturation detection signals may thus correspond to mask, where the mask highlights common centroid saturation regions in the unsaturated image. The combination of the two images can be used to closely track the eye position.</p><p id="p-0043" num="0042">In other examples, the described images may be used to track features of the eye such as in a user authentication system, where features of the user's eye may be captured and stored for authentication purposes. Since specular light has an intensity or magnitude that may saturate the electronics, such a saturation may occlude certain features of the eye that could be used for the user authentication. The presently disclosed techniques provide the benefit of gating off detectors that would occlude those features, and thus a clear image is provided without ambient light reflections or specular light interfering with the image.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a schematic diagram of another example imager system <b>200</b> that is arranged in accordance with the presently disclosed techniques. System <b>200</b> includes optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b>, saturation detectors <b>230</b>-<b>1</b> and <b>230</b>-<b>2</b>, path selectors <b>240</b>-land <b>240</b>-<b>2</b>, summer <b>250</b>, and ADC <b>260</b>.</p><p id="p-0045" num="0044">Optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b> are photodetector circuits that are each configured to generate a respective one of analog detection signals <b>12</b>-<b>1</b> and <b>12</b>-<b>2</b>, responsive to incident light. The optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b> may be part of optical detector <b>120</b> from <figref idref="DRAWINGS">FIG. <b>1</b></figref>, where each of the individual optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b> may correspond to one photodetector circuit in an array.</p><p id="p-0046" num="0045">The optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b> may optionally each include an amplifier <b>210</b>-<b>1</b> and <b>210</b>-<b>2</b>. The amplifiers may be voltage amplifiers or current amplifiers (e.g., transimpedance amplifiers), depending on the specific implementation. The output of the photodetector devices in the optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b> may thus correspond to an electrical signal (<b>21</b>-<b>1</b>, <b>21</b>-<b>2</b>) that is coupled to a respective input to one of the amplifiers <b>210</b>-<b>1</b> and <b>210</b>-<b>2</b>. Thus, the electrical <b>21</b>-<b>1</b> of optical detector circuit <b>120</b>-<b>1</b> is coupled to an input of amplifier <b>210</b>-<b>1</b>; and electrical signal <b>21</b>-<b>2</b> of optical detector circuit <b>120</b>-<b>2</b> is coupled to an input of amplifier <b>210</b>-<b>2</b>.</p><p id="p-0047" num="0046">Each of the amplifiers <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b> may receive an electrical signal from a respective photodetector in the optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b>; and generate an analog detection signal <b>12</b>-<b>1</b> and <b>12</b>-<b>2</b>, which is proportional to the corresponding electrical signal. Thus, analog detection signal <b>12</b>-<b>1</b> is proportional to electrical signal <b>21</b>-<b>1</b> and analog detection signal <b>12</b>-<b>2</b> is proportional to electrical signal <b>21</b>-<b>2</b>. In some examples, the electrical signals correspond to a current that is output from a photodetector, and the analog detection signals correspond to a voltage, where a transimpedance amplifier converts the photodetector current into an analog voltage.</p><p id="p-0048" num="0047">Analog detection signal <b>12</b>-<b>1</b> is coupled to an input of the first saturation detector <b>230</b>-<b>1</b>, a first input (path <b>0</b>) of a first path selector <b>240</b>-<b>1</b>, and a second input (path <b>1</b>) of a second path selector <b>240</b>-<b>2</b>. Analog detection signal <b>12</b>-<b>2</b> is coupled to an input of the second saturation detector <b>230</b>-<b>2</b>, a second input (path <b>1</b>) of the first path selector <b>240</b>-<b>1</b>, and a first input (path <b>0</b>) of the second path selector <b>240</b>-<b>2</b>.</p><p id="p-0049" num="0048">The first saturation detector <b>230</b>-<b>1</b> is configured to generate a first selector signal <b>23</b>-<b>1</b>, which has a logic value of logic 1 or 0 based on a signal level associated with the analog detection signal <b>12</b>-<b>1</b>. When analog detection signal <b>12</b>-<b>1</b> has an amplitude (or value) that is below a threshold (e.g., VREF<b>1</b>), then saturation detector <b>230</b>-<b>1</b> will set the first selector signal <b>23</b>-<b>1</b> to a first value (e.g., 0). Similarly, when analog detection signal <b>12</b>-<b>1</b> has an amplitude (or value) that is above a threshold (e.g., VREF<b>1</b>), then saturation detector <b>230</b>-<b>1</b> will set the first selector signal <b>23</b>-<b>1</b> to a second value (e.g., 1). The first path selector <b>240</b>-<b>1</b> will select a path for either signal <b>12</b>-<b>1</b> or signal <b>12</b>-<b>2</b> based on the value of the first selector signal <b>23</b>-<b>1</b>. When the first selector signal <b>23</b>-<b>1</b> is the first value, path selector <b>240</b>-<b>1</b> couples analog detection signal <b>12</b>-<b>1</b> to a first input of the summer <b>250</b> as signal <b>24</b>-<b>1</b>; otherwise path selector <b>240</b>-<b>1</b> couples analog detection signal <b>12</b>-<b>2</b> to the first input of the summer <b>250</b> as signal <b>24</b>-<b>1</b>.</p><p id="p-0050" num="0049">The second saturation detector <b>230</b>-<b>1</b> is configured to generate a second selector signal <b>23</b>-<b>2</b>, which has a logic value of logic 1 or 0 based on a signal level associated with the analog detection signal <b>12</b>-<b>2</b>. When analog detection signal <b>12</b>-<b>2</b> has an amplitude (or value) that is below a threshold (e.g., VREF<b>2</b>), then saturation detector <b>230</b>-<b>2</b> will set the second selector signal <b>23</b>-<b>2</b> to a first value (e.g., 0). Similarly, when analog detection signal <b>12</b>-<b>2</b> has an amplitude (or value) that is above a threshold (e.g., VREF<b>2</b>), then saturation detector <b>230</b>-<b>2</b> will set the second selector signal <b>23</b>-<b>2</b> to a second value (e.g., <b>1</b>). The second path selector <b>240</b>-<b>2</b> will select a path for either signal <b>12</b>-<b>1</b> or <b>12</b>-<b>2</b> based on the value of the second selector signal <b>23</b>-<b>2</b>. When the second selector signal <b>23</b>-<b>2</b> is the first value, path selector <b>240</b>-<b>2</b> couples analog detection signal <b>12</b>-<b>2</b> to a second input of the summer <b>250</b> as signal <b>24</b>-<b>2</b>; otherwise path selector <b>240</b>-<b>2</b> couples analog detection signal <b>12</b>-<b>1</b> to the second input of the summer <b>250</b> as signal <b>24</b>-<b>2</b>.</p><p id="p-0051" num="0050">The signals <b>23</b>-<b>1</b> and <b>23</b>-<b>2</b> also correspond to signals S<b>1</b> and S<b>2</b>, respectively, and may be output to the processor (e.g., processor <b>170</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>) to assist in forming a map or image that may be used for eye-tracking or other uses; similar to signal <b>32</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0052" num="0051">Summer <b>250</b> is an analog signal summer that is configured to combine the signals <b>24</b>-<b>1</b> and <b>24</b>-<b>2</b> into a combined analog signal <b>25</b>, which is input to the ADC <b>260</b>. The ADC converts the combined analog signal <b>25</b> into a digital signal <b>26</b>, which may be further processed by a processor (e.g., processor <b>170</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>). Considering signal <b>12</b>-<b>1</b> as A<b>1</b>, signal <b>12</b>-<b>2</b> as A<b>2</b>, signal <b>24</b>-<b>1</b> as B<b>1</b>, signal <b>24</b>-<b>2</b> as B<b>2</b>, and signal <b>25</b> as C, the following chart is helpful in understanding the signal paths:</p><p id="p-0053" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="1" colwidth="28pt" align="left"/><colspec colname="2" colwidth="28pt" align="left"/><colspec colname="3" colwidth="14pt" align="left"/><colspec colname="4" colwidth="14pt" align="left"/><colspec colname="5" colwidth="35pt" align="left"/><colspec colname="6" colwidth="98pt" align="left"/><thead><row><entry namest="1" nameend="6" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row><row><entry>Level</entry><entry>Level</entry><entry/><entry/><entry/><entry/></row><row><entry>of A1</entry><entry>of A2</entry><entry>B1</entry><entry>B2</entry><entry>C</entry><entry>Comment</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>A1 &#x3c;</entry><entry>A2 &#x3c;</entry><entry>A1</entry><entry>A2</entry><entry>A1 + A2</entry><entry>No Specular Reflection Detected</entry></row><row><entry>VREF1</entry><entry>VREF2</entry></row><row><entry>A1 &#x3e;</entry><entry>A2 &#x3c;</entry><entry>A2</entry><entry>A1</entry><entry>A2 + A2</entry><entry>Specular Reflection Detected</entry></row><row><entry>VREF1</entry><entry>VREF2</entry><entry/><entry/><entry/><entry>on A1</entry></row><row><entry>A1 &#x3c;</entry><entry>A2 &#x3e;</entry><entry>A1</entry><entry>A1</entry><entry>A1 + A1</entry><entry>Specular Reflection Detected</entry></row><row><entry>VREF1</entry><entry>VREF2</entry><entry/><entry/><entry/><entry>on A2</entry></row><row><entry>A1 &#x3e;</entry><entry>A2 &#x3e;</entry><entry>A2</entry><entry>A1</entry><entry>A1 + A2</entry><entry>Specular Reflection on both A1</entry></row><row><entry>VREF1</entry><entry>VREF2</entry><entry/><entry/><entry/><entry>and A2 (theoretically, this case</entry></row><row><entry/><entry/><entry/><entry/><entry/><entry>should not occur)</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0054" num="0052"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a partial view of yet another example imager system <b>300</b>, arranged in accordance with at least some aspects described herein. System <b>300</b> is substantially similar to system <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, with the addition of example saturation detector circuits <b>330</b>-<b>1</b> and <b>330</b>-<b>2</b>, and controller circuit <b>310</b>.</p><p id="p-0055" num="0053">Saturation detector circuit <b>330</b>-<b>1</b> includes a first input coupled to analog detection signal <b>12</b>-<b>1</b> or A<b>1</b>, a second input coupled to VREF<b>1</b>, and an output coupled to <b>30</b>-<b>1</b> or Sl. Saturation detector circuit <b>330</b>-<b>2</b> includes a first input coupled to analog detection signal <b>12</b>-<b>2</b> or A<b>2</b>, a second input coupled to VREF<b>2</b>, and an output coupled to <b>30</b>-<b>2</b> or S<b>2</b>. Saturation detector circuits <b>330</b>-<b>1</b> and <b>330</b>-<b>2</b> replace saturation detectors <b>230</b>-<b>1</b> and <b>230</b>-<b>2</b> from <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and thus the outputs <b>30</b>-<b>1</b> and <b>30</b>-<b>2</b> substantially correspond to <b>23</b>-<b>1</b> and <b>23</b>-<b>2</b> from <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0056" num="0054">The example saturation detector circuits <b>330</b>-<b>1</b> and <b>330</b>-<b>2</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> are shown as comparator circuits. For example, saturation detector circuit <b>330</b>-<b>1</b> is configured to compare analog detection signal <b>12</b>-<b>1</b> or A<b>1</b> to VREF<b>1</b> and assert selector signal <b>30</b>-<b>1</b> or S<b>1</b> in response to the comparison. Similarly, saturation detector circuit <b>330</b>-<b>2</b> is configured to compare analog detection signal <b>12</b>-<b>2</b> or A<b>2</b> to VREF<b>2</b> and assert selector signal <b>30</b>-<b>2</b> or S<b>2</b> in response to the comparison. The signals <b>30</b>-<b>1</b> and <b>30</b>-<b>2</b> (S<b>1</b> and S<b>2</b>), may be output to the processor (e.g., processor <b>170</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>); similar to signal <b>32</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0057" num="0055">Controller circuit <b>310</b> is configured to adjust the values of the thresholds for each of the comparators, by adjusting VREF<b>1</b> and VREF<b>2</b>. In a simple example, VREF<b>1</b>=VREF<b>2</b>. In other examples, VREF<b>1</b> and VREF<b>2</b> are independently set. The independent adjustment of VREF<b>1</b> and VREF<b>2</b> may be preferred in examples where the optical detector circuits (including any photodetectors, amplifiers, etc.) and/or comparators are not exactly matched in performance, allowing a calibration of the thresholds.</p><p id="p-0058" num="0056">The saturation detection circuits <b>330</b>-<b>1</b> and <b>330</b>-<b>2</b> may employ hysteresis to offer some level of immunity from instability that may occur when a comparator is on the edge of tripping. For example, when A<b>1</b> is very close to VREF<b>1</b> and there is a noise signal present in either input signal, there is a possibility that the saturation detection circuit <b>330</b>-<b>1</b> will thrash back and forth, and inject noise into the B<b>1</b> signal. By adding hysteresis to the input of the comparators, the exact signal thresholds for a 0-&#x3e;1 change will be different that that for a 1-&#x3e;0 change, which will prevent the comparator oscillating or thrashing back and forth.</p><p id="p-0059" num="0057"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a schematic diagram of another example imager system <b>400</b> that is arranged in accordance with the presently disclosed techniques. System <b>400</b> includes optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b> saturation detectors <b>230</b>-<b>1</b> and <b>230</b>-<b>2</b>, path selectors <b>240</b>-<b>1</b> and <b>240</b>-<b>2</b>, and summer <b>250</b>; all substantially similar to system <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. System <b>400</b> further includes example delay circuits <b>410</b>-<b>1</b> and <b>410</b>-<b>2</b>, and an example controller <b>420</b>.</p><p id="p-0060" num="0058">Delay circuit <b>410</b>-<b>1</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> is inserted between the first optical detector circuit <b>120</b>-<b>1</b> and the first path selector <b>240</b>-<b>1</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Thus, analog detection signal <b>12</b>-<b>1</b> or A<b>1</b> is coupled to an input of delay circuit <b>410</b>-<b>1</b>, and an output signal <b>41</b>-<b>1</b> or A<b>1</b>D of delay circuit <b>410</b>-<b>1</b> is coupled to a first input (Path <b>0</b>) of the first path selector <b>240</b>-<b>1</b>, and a second input (Path <b>1</b>) of the second path selector <b>240</b>-<b>2</b>.</p><p id="p-0061" num="0059">Delay circuit <b>410</b>-<b>2</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> is inserted between the second optical detector circuit <b>120</b>-<b>2</b> and the second path selector <b>240</b>-<b>2</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Thus, analog detection signal <b>12</b>-<b>2</b> or A<b>2</b> is coupled to an input of delay circuit <b>410</b>-<b>2</b>, and an output signal <b>41</b>-<b>2</b> or A<b>2</b>D of delay circuit <b>410</b>-<b>2</b> is coupled to a second input (Path <b>1</b>) of the first path selector <b>240</b>-<b>1</b>, and the first input (Path <b>0</b>) of the second path selector <b>240</b>-<b>2</b>.</p><p id="p-0062" num="0060">Operationally, delay circuits <b>410</b>-<b>1</b> and <b>410</b>-<b>2</b> are configured to delay the input signals to the path selectors from changing prior to the evaluation of the signals by the saturation detectors. This guarantees that the saturation detectors will select a path prior to the path selectors coupling their selected paths to the inputs of the summer <b>250</b>. For example, if a specular reflection is detected by saturation detector <b>230</b>-<b>2</b> by analog detection signal <b>12</b>-<b>2</b> or A<b>2</b> exceeding a threshold signal (e.g., A<b>2</b>&#x3e;VREF<b>2</b>), the path selector <b>240</b>-<b>2</b> will change from Path<b>0</b> to Path<b>1</b> prior to a the analog detection signal <b>12</b>-<b>2</b> or A<b>2</b> reaching the output signal <b>41</b>-<b>2</b> of the delay <b>410</b>-<b>2</b>, and thus preventing a signal transition from being coupled to the input of Summer B<b>2</b>.</p><p id="p-0063" num="0061">The delay circuits <b>310</b>-<b>1</b> and <b>410</b>-<b>2</b> may optionally be adjusted for an amount of delay in response to one or more control signals D<b>1</b> or D<b>2</b> from the controller circuit <b>420</b>. The adjustment of delay time may be desirable to guarantee proper performance without any excessive delays. Additionally, delay time may in one direction (e.g., from a 0-&#x3e;1 transition) may be different from a delay time in the other direction (e.g., from a 1-&#x3e;0 transition).</p><p id="p-0064" num="0062">Amplifiers may be included in the optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b> as illustrated by amplifiers <b>210</b>-<b>1</b> and <b>210</b>-<b>2</b>. These amplifiers may optionally be adjusted for an amount of gain in response to one or more control signals G<b>1</b> or G<b>2</b> from the controller circuit <b>420</b>. The adjustment in gain may be desirable to guarantee proper performance by calibrating the signal gain for each of the optical detector circuits <b>120</b>-<b>1</b> and <b>120</b>-<b>2</b>.</p><p id="p-0065" num="0063"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a graph of example signals <b>500</b> in an example eye tracking imager system such as system <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>. The example graph shows signal A<b>1</b>, A<b>1</b>D, A<b>2</b>, A<b>2</b>D, B<b>1</b>, S<b>1</b> and S<b>2</b>.</p><p id="p-0066" num="0064">As illustrated, selection signals S<b>1</b> and S<b>2</b>, from the saturation detectors, are initially low in value, and signal B<b>1</b> initially corresponds to signal A<b>1</b>, which is the output <b>12</b>-<b>1</b> of optical detector circuit <b>120</b>-<b>1</b>. At time t<b>0</b>, signal A<b>1</b> exceeds a threshold voltage (A<b>1</b>&#x3e;VREF<b>1</b>), which indicates that signal A<b>1</b> has saturated as a result of a specular reflection. However, at this time signal A<b>2</b> is below the threshold for saturation detection (A<b>2</b>&#x3c;VREF<b>2</b>), which indicates that signal A<b>2</b> has not saturated.</p><p id="p-0067" num="0065">After a small delay time (x) from time t<b>0</b>, selector signal S<b>1</b> transitions from a low signal (Logic 0) to high signal (Logic 1), and first path selector <b>240</b>-<b>1</b> changes the path selected from path<b>0</b> to path<b>1</b>. Once path<b>1</b> is selected, the output <b>12</b>-<b>2</b> or A<b>2</b> of optical detector circuit <b>120</b>-<b>2</b>, is coupled through path selector <b>240</b>-<b>1</b> to signal B<b>1</b> at the input to Summer <b>150</b>. However, signal A<b>1</b> and A<b>2</b> are delayed by a first amount (i.e., Delay1&#x3e;x, and t<b>1</b>=t<b>0</b>+Delay1) by the delay circuit <b>410</b>-<b>1</b> and <b>410</b>-<b>2</b>, and thus the switch path path<b>0</b> to path<b>1</b> is completed before time t<b>1</b>, and thus the input B<b>1</b> to summer <b>150</b> has not reached saturation and signal integrity is preserved.</p><p id="p-0068" num="0066">At time t<b>2</b>, the signal A<b>1</b> dips below the threshold voltage VREF<b>1</b> for saturation detection, and after another delay (y) the selector signal S<b>1</b> transitions from a high signal (Logic 1) back to a low signal (Logic 0). In this example, the delay after the threshold crossing (A<b>1</b>&#x3c;VREF<b>1</b>) crossing is again longer than the delay for switching the path from path<b>1</b> back to path<b>0</b> (i.e., Delay2&#x3e;y, and t<b>3</b>=t<b>2</b>+Delay2).</p><p id="p-0069" num="0067">The various signals illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> are for illustration purposes, actual signals may have a different shape based on the response time and intensity of incident light upon the photodetector circuit.</p><p id="p-0070" num="0068"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a partial view of still yet another example imager system <b>600</b>, arranged in accordance with the presently disclosed techniques. System <b>600</b> include an optical detector circuit <b>120</b>-<b>1</b> and a saturation detector <b>230</b>-<b>1</b>; all substantially similar to systems described for <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>4</b></figref>. However, system <b>600</b> illustrates an array implementation with N optical detector circuits <b>210</b>-<b>1</b>: N (each shown with an optional amplifier <b>210</b>-<b>1</b>:N) and N saturation detectors <b>230</b>-<b>1</b>:N; yielding analog detection signals <b>12</b>-<b>1</b>:N, and N selection signals S<b>1</b>:N.</p><p id="p-0071" num="0069"><figref idref="DRAWINGS">FIG. <b>6</b></figref> also includes a signal combiner <b>610</b>, which includes a decoder logic <b>611</b>, an array of 2-1 multiplexers <b>612</b>, and a summer <b>613</b>. Each of the 2-1 multiplexers <b>612</b> is configured to receive a pair of inputs from two different optical detector circuits, such as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The outputs of all of the multiplexers are combined by the summer <b>613</b>.</p><p id="p-0072" num="0070">A first input of each of the multiplexers <b>612</b> is coupled to an output of a respective one of the optical detector circuits <b>120</b>-<b>1</b>:N. For example, an output of the first optical detector circuit <b>120</b>-<b>1</b> is coupled to a first input of a first one of the multiplexers <b>612</b>, an output of the second optical detector circuit <b>120</b>-<b>2</b> is coupled to a first input of a second one of the multiplexers <b>612</b>, and an output of an Nth optical detector circuit <b>120</b>-N is coupled to a first input to an Nth one of the multiplexers <b>612</b>. A second input to each of the multiplexers <b>612</b> is coupled to one of the other optical detector circuits. For example, the second input of the first multiplexer may corresponds to an output of one of optical detector circuits <b>120</b>-<b>2</b>:N; while the second input of the second multiplexer may correspond to an output of one of optical detector circuits <b>120</b>-<b>1</b>, <b>120</b>-<b>3</b>:N. The choice of the first and second inputs to the multiplexers may preferably be optical detector circuits that are reasonably in close proximity since the signal levels between adjacent optical detectors may be closer in overall amplitude.</p><p id="p-0073" num="0071">Given that it is highly unlikely that more than one specular reflection will occur for a scan, the adjacent pairs should be able to provide an improved signal level since the specular reflection will be rejected by the saturation detectors. The decoder logic receives the various inputs from the saturation detectors S<b>1</b>:N and generates control signals for each of the multiplexers <b>612</b>. Thus, the paths from each of the multiplexers will be selected based on those signals that are preferably below the saturation threshold of the corresponding saturation detector, promoting the non-saturated signals from the optical detector circuits (<b>120</b>-<b>1</b>:N) for summation by the summer <b>613</b>.</p><p id="p-0074" num="0072">The output of the summer <b>613</b> can again be coupled to an ADC circuit, or optionally to a filter <b>620</b> and/or a gain stage <b>630</b>. As described earlier, gain and/or filtering of the output signal from the summer can be utilized to improve the signal to noise ratio of the signal for the ADC.</p><p id="p-0075" num="0073"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows the display device in the form of a head-mounted display device. The head-mounted display may be a near-eye display (&#x201c;NED&#x201d;) device <b>700</b> that includes a mirror control system <b>710</b> implementing aspects of the technologies disclosed herein. The mirror control system <b>710</b> includes the laser beam emitter <b>714</b>, mirrors <b>716</b> and <b>718</b>, and controllers <b>712</b>.</p><p id="p-0076" num="0074">In some examples, the NED device <b>700</b> may utilize the mirror control system <b>710</b> to generate a composite view (e.g., from a perspective of a user that is wearing the NED device <b>700</b>) that includes both one or more computer-generated (&#x201c;CG&#x201d;) images and a view of at least a portion of a real-world environment surrounding the NED device <b>700</b>. For example, the mirror control system <b>710</b> may utilize various technologies such as, for example, augmented reality (&#x201c;AR&#x201d;) technologies to generate composite views that include CG images superimposed over a real-world view. As such, the mirror control system <b>710</b> may be configured to generate CG images via a display panel <b>704</b>.</p><p id="p-0077" num="0075">In the illustrated example, the display panel <b>704</b> includes separate right eye and left eye transparent display panels, labeled <b>704</b>R and <b>704</b>L, respectively. In some examples, the display panel <b>704</b> may include a single transparent display panel that is viewable with both eyes and/or a single transparent display panel that is viewable by a single eye only.</p><p id="p-0078" num="0076">It can be appreciated that the techniques described herein may be deployed within a single-eye NED device <b>700</b> (e.g. GOOGLE GLASS) and/or a dual-eye NED device <b>700</b> (e.g. MICROSOFT HOLOLENS). The NED device <b>700</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> is an example device that is used to provide context and illustrate various features and aspects of the mirror control system <b>710</b> disclosed herein. Other devices and systems may also use the mirror control system <b>710</b> disclosed herein.</p><p id="p-0079" num="0077">In some examples, the display panel <b>704</b> may be a waveguide display that includes one or more diffractive optical elements (&#x201c;DOEs&#x201d;) for in-coupling incident light into a waveguide, expanding the incident light in one or more directions for exit pupil expansion, and/or out-coupling the incident light out of the waveguide (e.g., toward a user's eye). In some examples, the NED device <b>700</b> may further include an additional see-through optical component in the form of a transparent veil <b>708</b> positioned between the real-world environment (which real-world environment makes up no part of the claimed invention) and the display panel <b>704</b>.</p><p id="p-0080" num="0078">It can be appreciated that the transparent veil <b>708</b> may be included in the NED device <b>700</b> for purely aesthetic and/or protective purposes. The NED device <b>700</b> may further include various other components, for example speakers, microphones, accelerometers, gyroscopes, magnetometers, temperature sensors, touch sensors, inertial measurement sensors, biometric sensors, other image sensors, energy-storage components (e.g. battery), a communication facility, a global positioning system (&#x201c;GPS&#x201d;) receiver, etc.</p><p id="p-0081" num="0079">In the illustrated example, a controller <b>720</b> is operatively coupled to the mirror control system <b>710</b>. The controller <b>720</b> includes one or more logic devices and one or more computer memory devices storing instructions executable by the logic device(s) to deploy aspects of the functionality described herein with relation to the mirror control system <b>710</b>. The controller <b>720</b> and the mirror control system <b>710</b> of the NED device <b>700</b> are operatively connected, for example, via a bus <b>730</b>, which can include one or more of a system bus, a data bus, an address bus, a PCI bus, a Mini-PCI bus, and any variety of local, peripheral, and/or independent buses.</p><p id="p-0082" num="0080">The controller <b>720</b> can also include one or more processing units <b>722</b>. The processing unit(s) <b>722</b>, can represent, for example, a CPU-type processing unit, a GPU-type processing unit, a field-programmable gate array (&#x201c;FPGA&#x201d;), a digital signal processor (&#x201c;DSP&#x201d;), or other hardware logic components that may, in some instances, be driven by a CPU. For example, and without limitation, illustrative types of hardware logic components that can be used include Application-Specific Integrated Circuits (&#x201c;ASICs&#x201d;), Application-Specific Standard Products (&#x201c;ASSPs&#x201d;), System-on-a-Chip Systems (&#x201c;SOCs&#x201d;), Complex Programmable Logic Devices (&#x201c;CPLDs&#x201d;), etc.</p><p id="p-0083" num="0081">The controller <b>720</b> can also include one or more computer-readable media <b>724</b> storing an operating system <b>726</b> and data such as, for example, image data that defines one or more CG images for presentation by the NED device <b>700</b>. The computer-readable media <b>724</b> may further include an image-generation engine <b>728</b> that generates output signals to control aspects of the operation of the mirror control system <b>710</b> to present the CG images.</p><p id="p-0084" num="0082">As used herein, computer-readable media, such as computer-readable media <b>724</b>, can store instructions executable by the processing units <b>722</b>. The computer-readable media <b>724</b> can also store instructions executable by external processing units such as by an external CPU, an external GPU, and/or executable by an external accelerator, such as an FPGA type accelerator, a DSP type accelerator, or any other internal or external accelerator. In various examples, at least one CPU, GPU, and/or accelerator is incorporated in the NED device <b>700</b>, while in some examples one or more of a CPU, GPU, and/or accelerator are external to the NED device <b>700</b>.</p><p id="p-0085" num="0083">As used herein, the term computer-readable media can include computer storage media and/or communication media. Computer storage media can include one or more of volatile memory, nonvolatile memory, and/or other persistent and/or auxiliary computer storage media, removable and non-removable computer storage media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules, or other data.</p><p id="p-0086" num="0084">Thus, computer storage media includes tangible and/or physical forms of media included in a device and/or hardware component that is part of a device or external to a device, including but not limited to random access memory (&#x201c;RAM&#x201d;), static random-access memory (&#x201c;SRAM&#x201d;), dynamic random-access memory (&#x201c;DRAM&#x201d;), phase change memory (&#x201c;PCM&#x201d;), read-only memory (&#x201c;ROM&#x201d;), erasable programmable read-only memory (&#x201c;EPROM&#x201d;), electrically erasable programmable read-only memory (&#x201c;EEPROM&#x201d;), flash memory, rotating media, optical cards or other optical storage media, magnetic storage, magnetic cards or other magnetic storage devices or media, solid-state memory devices, storage arrays, network attached storage, storage area networks, hosted computer storage or any other storage memory, storage device, and/or storage medium that can be used to store and maintain information for access by a computing device in a non-transitory fashion.</p><p id="p-0087" num="0085">In contrast to computer storage media, communication media can embody computer-readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave, or other transmission mechanism. As defined herein, computer storage media does not include communication media. That is, computer storage media does not include communications media consisting solely of a modulated data signal, a carrier wave, or a propagated signal, per se.</p><p id="p-0088" num="0086"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an example computing environment in which aspects of the technologies disclosed herein can be implemented. In particular, <figref idref="DRAWINGS">FIG. <b>8</b></figref> schematically shows a non-limiting embodiment of a computing system <b>800</b> that can be used to implement the technologies disclosed herein. Computing system <b>800</b> may take the form of one or more personal computers, server computers, tablet computers, home-entertainment computers, network computing devices, gaming devices, mobile computing devices, mobile communication devices (e.g., smart phone), and/or other computing devices, and wearable computing devices such as smart wristwatches and head mounted augmented reality devices.</p><p id="p-0089" num="0087">Computing system <b>800</b> includes a logic processor <b>802</b> volatile memory <b>804</b>, and a non-volatile storage device <b>806</b>. Computing system <b>800</b> may optionally include a display subsystem <b>808</b>, input subsystem <b>810</b>, communication subsystem <b>812</b>, and/or other components not shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0090" num="0088">Logic processor <b>802</b> includes one or more physical devices configured to execute instructions. For example, the logic processor may be configured to execute instructions that are part of one or more applications, programs, routines, libraries, objects, components, data structures, or other logical constructs. Such instructions may be implemented to perform a task, implement a data type, transform the state of one or more components, achieve a technical effect, or otherwise arrive at a desired result.</p><p id="p-0091" num="0089">The logic processor <b>802</b> may include one or more physical processors (e.g. hardware) configured to execute software instructions. Additionally, or alternatively, the logic processor <b>802</b> may include one or more hardware logic circuits or firmware devices configured to execute hardware-implemented logic or firmware instructions.</p><p id="p-0092" num="0090">The logic processor <b>802</b> may be single-core or multi-core, and the instructions executed thereon may be configured for sequential, parallel, and/or distributed processing. Individual components of the logic processor <b>802</b> optionally may be distributed among two or more separate devices, which may be remotely located and/or configured for coordinated processing. Aspects of the operation of the logic processor <b>802</b> may be virtualized and executed by remotely accessible, networked computing devices configured in a cloud-computing configuration. In such a case, these virtualized aspects are run on different physical logic processors of various different machines, it will be understood.</p><p id="p-0093" num="0091">Non-volatile storage device <b>806</b> includes one or more physical devices configured to hold instructions executable by the logic processors to implement aspects of the methods and processes described herein. When such methods and processes are implemented, the state of non-volatile storage device <b>806</b> may be transformed&#x2014;e.g., to hold different data.</p><p id="p-0094" num="0092">Non-volatile storage device <b>806</b> may include physical devices that are removable and/or built in. Non-volatile storage device <b>806</b> may include optical memory (e.g., CD, DVD, HD-DVD, Blu-Ray Disc, etc.), semiconductor memory (e.g., ROM, EPROM, EEPROM, FLASH memory, etc.), and/or magnetic memory (e.g., hard-disk drive, floppy-disk drive, tape drive, MRAM, etc.), or other mass storage device technology. Non-volatile storage device <b>806</b> may include nonvolatile, dynamic, static, read/write, read-only, sequential-access, location-addressable, file-addressable, and/or content-addressable devices. It will be appreciated that non-volatile storage device <b>806</b> is configured to hold instructions even when power is cut to the non-volatile storage device <b>806</b>.</p><p id="p-0095" num="0093">Volatile memory <b>804</b> may include physical devices that include random access memory. Volatile memory <b>804</b> is typically utilized by logic processor <b>802</b> to temporarily store information during processing of software instructions. It will be appreciated that volatile memory <b>804</b> typically does not continue to store instructions when power is removed from the volatile memory <b>804</b>. Aspects of logic processor <b>802</b>, volatile memory <b>804</b>, and non-volatile storage device <b>806</b> may be integrated together into one or more hardware-logic components, such as within an ASIC, SOC, or FPGA.</p><p id="p-0096" num="0094">The terms &#x201c;module,&#x201d; &#x201c;program,&#x201d; and &#x201c;engine&#x201d; may be used to describe an aspect of computing system <b>800</b> typically implemented in software by a processor <b>802</b> to perform a particular function using portions of volatile memory <b>804</b>, which function involves transformative processing that specially configures the processor <b>802</b> to perform the function. Thus, a module, program, or engine may be instantiated via logic processor <b>802</b> executing instructions held by non-volatile storage device <b>806</b>, using portions of volatile memory <b>804</b>.</p><p id="p-0097" num="0095">It will be understood that different modules, programs, and/or engines may be instantiated from the same application, service, code block, object, library, routine, API, function, etc. Likewise, the same module, program, and/or engine may be instantiated by different applications, services, code blocks, objects, routines, APIs, functions, etc. The terms &#x201c;module,&#x201d; &#x201c;program,&#x201d; and &#x201c;engine&#x201d; may encompass individual or groups of executable files, data files, libraries, drivers, scripts, database records, etc.</p><p id="p-0098" num="0096">When included, display subsystem <b>808</b> may be used to present a visual representation of data held by non-volatile storage device <b>806</b>. The visual representation may take the form of a graphical user interface (&#x201c;GUI&#x201d;). As the herein described methods and processes change the data held by the non-volatile storage device, and thus transform the state of the non-volatile storage device, the state of display subsystem <b>808</b> may likewise be transformed to visually represent changes in the underlying data. Display subsystem <b>808</b> may include one or more display devices utilizing virtually any type of technology, such as the LBS display devices disclosed herein. Such display devices may be combined with logic processor <b>802</b>, volatile memory <b>804</b>, and/or non-volatile storage device <b>806</b> in a shared enclosure, or such display devices may be peripheral display devices.</p><p id="p-0099" num="0097">When included, input subsystem <b>810</b> may comprise or interface with one or more user-input devices such as a keyboard, mouse, touch screen, or game controller. In some embodiments, the input subsystem may comprise or interface with selected natural user input (&#x201c;NUI&#x201d;) componentry. Such componentry may be integrated or peripheral, and the transduction and/or processing of input actions may be handled on- or off-board.</p><p id="p-0100" num="0098">Example NUI componentry may include a microphone for speech and/or voice recognition; an infrared, color, stereoscopic, and/or depth camera for machine vision and/or gesture recognition; a head tracker, eye tracker, accelerometer, and/or gyroscope for motion detection and/or intent recognition; as well as electric-field sensing componentry for assessing brain activity; and/or any other suitable sensor.</p><p id="p-0101" num="0099">When included, communication subsystem <b>812</b> may be configured to communicatively couple various computing devices described herein with each other, and with other devices. Communication subsystem <b>812</b> may include wired and/or wireless communication devices compatible with one or more different communication protocols. As non-limiting examples, the communication subsystem may be configured for communication via a wireless telephone network, or a wired or wireless local- or wide-area network, such as a HDMI over Wi-Fi connection. In some embodiments, the communication subsystem may allow computing system <b>800</b> to send and/or receive messages to and/or from other devices via a network such as the Internet.</p><p id="p-0102" num="0100">It will be understood that the configurations and/or approaches described herein are exemplary in nature, and that these specific embodiments or examples are not to be considered in a limiting sense, because numerous variations are possible. The specific routines or methods described herein may represent one or more of any number of processing strategies. As such, various acts illustrated and/or described may be performed in the sequence illustrated and/or described, in other sequences, in parallel, or omitted. Likewise, the order of the above-described processes may be changed.</p><p id="p-0103" num="0101">The disclosure presented herein also encompasses the subject matter set forth in the following clauses:</p><p id="p-0104" num="0102">Clause 1: A device to detect and process light reflected from an eye of a user, the device comprising: a first optical detector circuit (<b>120</b>-<b>1</b>) that provides a first analog detection signal (<b>12</b>-<b>1</b>) responsive to a first incident light reflected from the eye of the user; a second optical detector circuit (<b>120</b>-<b>2</b>) that provides a second analog detection signal (<b>12</b>-<b>2</b>) responsive to a second incident light reflected from the eye of the user; a first path selector (<b>240</b>-<b>1</b>) with a first input to receive the first analog detection signal (<b>12</b>-<b>1</b>), a second input to receive the second analog detection signal (<b>12</b>-<b>2</b>), a control input to receive a first selection signal (<b>23</b>-<b>1</b>), and an output (<b>24</b>-<b>1</b>) to selectively couple one of the first and second inputs to the output responsive to the first selection signal (<b>23</b>-<b>1</b>); a second path selector (<b>240</b>-<b>2</b>) with a first input to receive the second analog detection signal (<b>12</b>-<b>2</b>), a second input to receive the first analog signal (<b>12</b>-<b>1</b>), a control input to receive a second selection signal (<b>23</b>-<b>2</b>), and an output (<b>24</b>-<b>2</b>) to selectively couple one of the first and second inputs to the output responsive to the second selection signal; and a summer (<b>250</b>) with a first input that is coupled to the output of the first path selector (<b>24</b>-<b>1</b>), a second input that is coupled to the output of the second path selector (<b>24</b>-<b>2</b>), and generate a combined analog signal (<b>25</b>) as a summation of the first and second inputs to the summer.</p><p id="p-0105" num="0103">Clause 2: The device of any of the example clauses, further comprising: an analog-to-digital converter to receive the combined analog signal, sample the combined analog signals, and generate a digital signal as a conversion of the sampled analog signal into a digital value.</p><p id="p-0106" num="0104">Clause 3: The device of any of the example clauses, further comprising a processor that is configured to receive the digital signals from the analog-to-digital converter, generate a first image of the eye of the user based on the digital signal at a first time, generate a second image of the eye of the user based on the digital signal at a second time, and determine a direction of gaze or movement of the eye based on a comparison of the first image and the second image.</p><p id="p-0107" num="0105">Clause 4: The device of any of the example clauses, further comprising: a first saturation detector to receive the first analog detection signal and generate the first selection signal responsive to a comparison of the first analog detection signal to a first threshold; and a second saturation detector to receive the second analog detection signal and generate the second selection signal responsive to a comparison of the second analog detection signal to a second threshold.</p><p id="p-0108" num="0106">Clause 5: The device of any of the example clauses, wherein the first and second thresholds are the same.</p><p id="p-0109" num="0107">Clause 6: The device of any of the example clauses, wherein the first and second saturation detectors each correspond to a comparator with hysteresis.</p><p id="p-0110" num="0108">Clause 7: The device of any of the example clauses, further comprising: a first delay circuit that is coupled between the first optical detector circuit and the first and second path selectors, wherein the first delay circuit generates a first delayed analog signal that is delayed in time with respect to the first analog detection signal; and a second delay circuit that is coupled between the second optical detector circuit and the first and second path selectors, wherein the second delay circuit generates a second delayed analog signal that is delayed in time with respect to the second analog detection signal.</p><p id="p-0111" num="0109">Clause 8: The device of any of the example clauses, further comprising: a third optical detector circuit that provides a third analog detection signal responsive to a third incident light reflected from the eye of the user; a third path selector with a first input to receive the third analog detection signal, a second input to receive one of the first or second analog detection signals, a control input to receive a third selection signal, and an output to selectively couple one of the first and second inputs to the output responsive to the third selection signal; and wherein the summer is further includes a third input that is coupled to the output of the third path selector, wherein the summer generates the combined analog signal as a summation of the first, second, and third inputs to the summer.</p><p id="p-0112" num="0110">Clause 9: The device of any of the example clauses, further comprising: a first saturation detector to receive the first analog detection signal and generate the first selection signal responsive to a comparison of the first analog detection signal to a first threshold; a second saturation detector to receive the second analog detection signal and generate the second selection signal responsive to a comparison of the second analog detection signal to a second threshold; and a third saturation detector to receive the third analog detection signal and generate the third selection signal responsive to a comparison of the third analog detection signal to a third threshold.</p><p id="p-0113" num="0111">Clause 10: The device of any of the example clauses, further comprising: an optical filter that is located between each optical detector circuit and the light incident on the optical detector circuit, wherein the optical filter comprises one or more of: a first filter that selectively blocks wavelengths that are different from an incident beam, a second filter that selectively blocks undesired ambient light, a third filter that selectively blocks light in the red, green, or blue light spectrums, a fourth filter that blocks light in the visible spectrum, a fifth filter that selectively blocks light a wavelength in a specific portion of the infrared wavelength spectrum, or a sixth filter that passes light with a specific polarization.</p><p id="p-0114" num="0112">Clause 11: The device of any of the example clauses, further comprising: an analog filter that filters the combined analog signal prior to generate a filtered signal, wherein the analog filter comprises one or more of a passive filter, an active filter, a low-pass filter, a high-pass filter, a band-pass filter, or a phase-shape filter; and an analog-to-digital converter that receives the filtered signal and converts the filtered signal to a digital value.</p><p id="p-0115" num="0113">Clause 12: The device to detect and process incident light reflected from an eye of a user, the device comprising: an array of optical detectors (<b>120</b>-<b>1</b>, N), each configured to provide a corresponding one of an array of analog detection signals (<b>12</b>-<b>1</b>, N) responsive to a corresponding incident light reflected from the eye of the user; an array of saturation detectors (<b>230</b>-<b>1</b>, N), each configured to receive the corresponding array of analog detection signal (<b>12</b>-<b>1</b>, N) and generate a corresponding selection signal (<b>23</b>-<b>1</b>, N) responsive to a comparison of the corresponding analog detection signal (<b>23</b>-<b>1</b>, N) to a corresponding threshold; and a signal combiner (<b>130</b>, <b>610</b>) configured to receive the plurality of selection signals (<b>23</b>-<b>1</b>, N) and the plurality of analog detection signals (<b>12</b>-<b>1</b>, N), wherein the signal combiner (<b>610</b>) is configured to selectively combine the plurality of analog detection signals (<b>12</b>-<b>1</b>, N) to generate a combined analog signal (<b>31</b>, <b>61</b>) based on the array of selection signals (<b>23</b>-<b>1</b>, N), wherein non-saturated signals are promoted over saturated signals in the combined analog signal (<b>31</b>, <b>61</b>).</p><p id="p-0116" num="0114">Clause 13: The device of any of the example clauses, wherein the signal combiner comprises: a decoder logic that generates control signals based on the selection signals from the saturation detectors; a set of multiplexers, where each of the multiplexers receives two different ones of the analog detection signals; and a summer, wherein the summer is configured to combine the outputs of the set of multiplexers to generate the combined analog signal.</p><p id="p-0117" num="0115">Clause 14: The device of any of the example clauses, further comprising: an analog-to-digital converter to receive the combined analog signal, sample the combined analog signals, and generate a digital signal as a conversion of the sampled analog signal into a digital value; and a processor that is configured to receive the digital signals from the analog-to-digital converter, generate a first image of the eye of the user based on the digital signal at a first time, generate a second image of the eye of the user based on the digital signal at a second time, and determine a direction of gaze or movement of the eye based on a comparison of the first image and the second image.</p><p id="p-0118" num="0116">Clause 15: A device to generate an electrical response to light incident (<b>10</b>-<b>1</b>, N) that light includes specular and scattered reflections from the eye of a user, the device comprising: an optical detector (<b>120</b>) that generates a plurality of electrical signals (<b>12</b>-<b>1</b>, N) responsive to the light incident on the optical detector (<b>120</b>); a signal combiner (<b>130</b>) that receives the plurality of electrical signals (<b>12</b>-<b>1</b>, N) from the optical detector (<b>120</b>), evaluates a signal level of each of the plurality of electrical signals (<b>12</b>-<b>1</b>, N) to determine when the signal level of the corresponding one of the plurality of electrical signals has saturated, and selectively combines the plurality of electrical signals (<b>12</b>-<b>1</b>, N) to generate a combined analog signal (<b>31</b>) based on the determined signal levels such that non-saturated signals are promoted over saturated signals in the combined analog signal (<b>31</b>); and an analog-to-digital converter (<b>150</b>) that receives the combined analog signal (<b>31</b>) from the signal combiner (<b>130</b>), samples the combined analog signals, and generates a digital signal (<b>51</b>) as a conversion of the sampled analog signal into a digital value.</p><p id="p-0119" num="0117">Clause 16: The device of any of the example clauses, further comprising: an optical filter that is located between the optical detector and the light incident on the optical detector, wherein the optical filter comprises one or more of: a first filter that selectively blocks wavelengths that are different from an incident beam, a second filter that selectively blocks undesired ambient light, a third filter that selectively blocks light in the red, green, or blue light spectrums, a fourth filter that blocks light in the visible spectrum, a fifth filter that selectively blocks light a wavelength in a specific portion of the infrared wavelength spectrum, or a sixth filter that passes light with a specific polarization.</p><p id="p-0120" num="0118">Clause 17: The device of any of the example clauses, further comprising: an analog filter that filters the combined analog signal prior to sampling by the analog-to-digital converter, wherein the analog filter comprises one or more of a passive filter, an active filter, a low-pass filter, a high-pass filter, a band-pass filter, or a phase-shape filter.</p><p id="p-0121" num="0119">Clause 18: The device of any of the example clauses, further comprising: multiple photodiode circuits, each one being configured to generate a separate one of the plurality of electrical signals responsive to incident light thereon.</p><p id="p-0122" num="0120">Clause 19: The device of any of the example clauses, further comprising a controller circuit configured to receive one or more configuration signals from an external processor via a communication interface, wherein the one or more configuration signals corresponds to either an analog configuration signal or a digital configuration signal.</p><p id="p-0123" num="0121">The device of any of the example clauses, further comprising a processor that is configured to receive the digital signals from the analog-to-digital converter, generate a first image of the eye of the user based on the digital signal at a first time, generate a second image of the eye of the user based on the digital signal at a second time, and determine a direction of gaze or movement of the eye based on a comparison of the first image and the second image.</p><p id="p-0124" num="0122">The above specification, examples and data provide a complete description of the manufacture and use of the composition of the invention. Since many embodiments of the invention can be made without departing from the spirit and scope of the invention, the invention resides in the claims hereinafter appended.</p><p id="p-0125" num="0123">In closing, although the various configurations have been described in language specific to structural features and/or methodological acts, it is to be understood that the subject matter defined in the appended representations is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as example forms of implementing the claimed subject matter.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A device to detect and process light reflected from an eye of a user, the device comprising:<claim-text>a first optical detector circuit that provides a first analog detection signal responsive to a first incident light reflected from the eye of the user;</claim-text><claim-text>a second optical detector circuit that provides a second analog detection signal responsive to a second incident light reflected from the eye of the user;</claim-text><claim-text>a first path selector with a first input to receive the first analog detection signal, a second input to receive the second analog detection signal, a control input to receive a first selection signal, and an output to selectively couple one of the first and second inputs to the output responsive to the first selection signal;</claim-text><claim-text>a second path selector with a first input to receive the second analog detection signal, a second input to receive the first analog signal, a control input to receive a second selection signal, and an output to selectively couple one of the first and second inputs to the output responsive to the second selection signal; and</claim-text><claim-text>a summer with a first input that is coupled to the output of the first path selector, a second input that is coupled to the output of the second path selector, and generate a combined analog signal as a summation of the first and second inputs to the summer.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising: an analog-to-digital converter to receive the combined analog signal, sample the combined analog signals, and generate a digital signal as a conversion of the sampled analog signal into a digital value.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising a processor that is configured to receive the digital signals from the analog-to-digital converter, generate a first image of the eye of the user based on the digital signal at a first time, generate a second image of the eye of the user based on the digital signal at a second time, and determine a direction of gaze or movement of the eye based on a comparison of the first image and the second image.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a first saturation detector to receive the first analog detection signal and generate the first selection signal responsive to a comparison of the first analog detection signal to a first threshold; and</claim-text><claim-text>a second saturation detector to receive the second analog detection signal and generate the second selection signal responsive to a comparison of the second analog detection signal to a second threshold.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the first and second thresholds are the same.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the first and second saturation detectors each correspond to a comparator with hysteresis.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising:<claim-text>a first delay circuit that is coupled between the first optical detector circuit and the first and second path selectors, wherein the first delay circuit generates a first delayed analog signal that is delayed in time with respect to the first analog detection signal; and</claim-text><claim-text>a second delay circuit that is coupled between the second optical detector circuit and the first and second path selectors, wherein the second delay circuit generates a second delayed analog signal that is delayed in time with respect to the second analog detection signal.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a third optical detector circuit that provides a third analog detection signal responsive to a third incident light reflected from the eye of the user;</claim-text><claim-text>a third path selector with a first input to receive the third analog detection signal, a second input to receive one of the first or second analog detection signals, a control input to receive a third selection signal, and an output to selectively couple one of the first and second inputs to the output responsive to the third selection signal; and</claim-text><claim-text>wherein the summer is further includes a third input that is coupled to the output of the third path selector, wherein the summer generates the combined analog signal as a summation of the first, second, and third inputs to the summer.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising<claim-text>a first saturation detector to receive the first analog detection signal and generate the first selection signal responsive to a comparison of the first analog detection signal to a first threshold;</claim-text><claim-text>a second saturation detector to receive the second analog detection signal and generate the second selection signal responsive to a comparison of the second analog detection signal to a second threshold; and</claim-text><claim-text>a third saturation detector to receive the third analog detection signal and generate the third selection signal responsive to a comparison of the third analog detection signal to a third threshold.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising: an optical filter that is located between each optical detector circuit and the light incident on the optical detector circuit, wherein the optical filter comprises one or more of: a first filter that selectively blocks wavelengths that are different from an incident beam, a second filter that selectively blocks undesired ambient light, a third filter that selectively blocks light in the red, green, or blue light spectrums, a fourth filter that blocks light in the visible spectrum, a fifth filter that selectively blocks light a wavelength in a specific portion of the infrared wavelength spectrum, or a sixth filter that passes light with a specific polarization.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>an analog filter that filters the combined analog signal prior to generate a filtered signal, wherein the analog filter comprises one or more of a passive filter, an active filter, a low-pass filter, a high-pass filter, a band-pass filter, or a phase-shape filter; and</claim-text><claim-text>an analog-to-digital converter that receives the filtered signal and converts the filtered signal to a digital value.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A device to detect and process incident light reflected from an eye of a user, the device comprising:<claim-text>an array of optical detectors, each configured to provide a corresponding one of an array of analog detection signals responsive to a corresponding incident light reflected from the eye of the user;</claim-text><claim-text>an array of saturation detectors, each configured to receive the corresponding array of analog detection signal and generate a corresponding selection signal responsive to a comparison of the corresponding analog detection signal to a corresponding threshold; and</claim-text><claim-text>a signal combiner configured to receive the plurality of selection signals and the plurality of analog detection signals, wherein the signal combiner is configured to selectively combine the plurality of analog detection signals to generate a combined analog signal based on the array of selection signals, wherein non-saturated signals are promoted over saturated signals in the combined analog signal.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the signal combiner comprises:<claim-text>a decoder logic that generates control signals based on the selection signals from the saturation detectors;</claim-text><claim-text>a set of multiplexers, where each of the multiplexers receives two different ones of the analog detection signals; and</claim-text><claim-text>a summer, wherein the summer is configured to combine the outputs of the set of multiplexers to generate the combined analog signal.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising:<claim-text>an analog-to-digital converter to receive the combined analog signal, sample the combined analog signals, and generate a digital signal as a conversion of the sampled analog signal into a digital value; and</claim-text><claim-text>a processor that is configured to receive the digital signals from the analog-to-digital converter, generate a first image of the eye of the user based on the digital signal at a first time, generate a second image of the eye of the user based on the digital signal at a second time, and determine a direction of gaze or movement of the eye based on a comparison of the first image and the second image.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A device to generate an electrical response to light incident that light includes specular and scattered reflections from the eye of a user, the device comprising:<claim-text>an optical detector that generates a plurality of electrical signals responsive to the light incident on the optical detector;</claim-text><claim-text>a signal combiner that receives the plurality of electrical signals from the optical detector, evaluates a signal level of each of the plurality of electrical signals to determine when the signal level of the corresponding one of the plurality of electrical signals has saturated, and selectively combines the plurality of electrical signals to generate a combined analog signal based on the determined signal levels such that non-saturated signals are promoted over saturated signals in the combined analog signal; and</claim-text><claim-text>an analog-to-digital converter that receives the combined analog signal from the signal combiner, samples the combined analog signals, and generates a digital signal as a conversion of the sampled analog signal into a digital value.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising: an optical filter that is located between the optical detector and the light incident on the optical detector, wherein the optical filter comprises one or more of: a first filter that selectively blocks wavelengths that are different from an incident beam, a second filter that selectively blocks undesired ambient light, a third filter that selectively blocks light in the red, green, or blue light spectrums, a fourth filter that blocks light in the visible spectrum, a fifth filter that selectively blocks light a wavelength in a specific portion of the infrared wavelength spectrum, or a sixth filter that passes light with a specific polarization.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising: an analog filter that filters the combined analog signal prior to sampling by the analog-to-digital converter, wherein the analog filter comprises one or more of a passive filter, an active filter, a low-pass filter, a high-pass filter, a band-pass filter, or a phase-shape filter.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, the optical detector further comprising: multiple photodiode circuits, each one being configured to generate a separate one of the plurality of electrical signals responsive to incident light thereon.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising a controller circuit configured to receive one or more configuration signals from an external processor via a communication interface, wherein the one or more configuration signals corresponds to either an analog configuration signal or a digital configuration signal.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising a processor that is configured to receive the digital signals from the analog-to-digital converter, generate a first image of the eye of the user based on the digital signal at a first time, generate a second image of the eye of the user based on the digital signal at a second time, and determine a direction of gaze or movement of the eye based on a comparison of the first image and the second image.</claim-text></claim></claims></us-patent-application>
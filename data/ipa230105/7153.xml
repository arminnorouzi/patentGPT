<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007154A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007154</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17943361</doc-number><date>20220913</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>238</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>225</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>17</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>238</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>2254</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>2258</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180801</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232933</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23216</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23241</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>17</main-group><subgroup>002</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>2257</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23209</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180801</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>22521</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">IMAGE CAPTURE DEVICE WITH INTERCHANGEABLE INTEGRATED SENSOR-OPTICAL COMPONENT ASSEMBLIES</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17215453</doc-number><date>20210329</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11445126</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17943361</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16231765</doc-number><date>20181224</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10999528</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17215453</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>62611670</doc-number><date>20171229</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62611199</doc-number><date>20171228</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>GoPro, Inc.</orgname><address><city>San Mateo</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Cotoros</last-name><first-name>Ingrid A.</first-name><address><city>Hillsborough</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Woodman</last-name><first-name>Nicholas D.</first-name><address><city>Big Sky</city><state>MT</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Barna</last-name><first-name>Sandor Lee</first-name><address><city>Los Altos</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Stern</last-name><first-name>Jonathan</first-name><address><city>San Mateo</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An image capture device includes an image capture module and a base module. The image capture module is releasably connectable to the base module. The image capture module includes an integrated image sensor and optical component for capturing image data. The base module includes a processor. The processor is configured and the base module is calibrated based on identification data provided by the image capture module when releasably connected to the base module. The image information and identification data may be wirelessly transferred from the image capture module to the base module.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="89.66mm" wi="142.24mm" file="US20230007154A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="222.76mm" wi="145.97mm" file="US20230007154A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="222.84mm" wi="145.80mm" file="US20230007154A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="203.71mm" wi="101.35mm" file="US20230007154A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="165.27mm" wi="111.68mm" orientation="landscape" file="US20230007154A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="216.58mm" wi="156.72mm" orientation="landscape" file="US20230007154A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="210.90mm" wi="146.90mm" orientation="landscape" file="US20230007154A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="215.14mm" wi="154.18mm" orientation="landscape" file="US20230007154A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="74.76mm" wi="149.44mm" orientation="landscape" file="US20230007154A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="133.43mm" wi="110.57mm" orientation="landscape" file="US20230007154A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="228.35mm" wi="91.44mm" file="US20230007154A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="219.12mm" wi="160.78mm" file="US20230007154A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="212.77mm" wi="165.95mm" file="US20230007154A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="217.00mm" wi="133.43mm" orientation="landscape" file="US20230007154A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="169.08mm" wi="120.57mm" file="US20230007154A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="212.94mm" wi="141.48mm" file="US20230007154A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of U.S. application patent Ser. No. 17/215,453, filed Mar. 29, 2021, entitled &#x201c;Image Capture Device with Interchangeable Integrated Sensor-Optical Component Assemblies&#x201d;, which is a continuation of U.S. application patent Ser. No. 16/231,765, filed Dec. 24, 2018, entitled &#x201c;Image Capture Device with Interchangeable Integrated Sensor-Optical Component Assemblies&#x201d;, which claims priority to and the benefit of U.S. Provisional Application Patent Ser. No. 62/611,670, filed Dec. 29, 2017, entitled &#x201c;Digital Image Capturing Device with Interchangeable Integrated Sensor-Lens Assemblies,&#x201d; and U.S. Provisional Application Patent Ser. No. 62/611,199, filed Dec. 28, 2017, entitled &#x201c;Modular Camera System,&#x201d; the entire disclosures of which are hereby incorporated by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">This disclosure relates to image capture devices, in particular, image capture devices having interchangeable integrated sensor-optical component assemblies.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Image capture devices are used in various applications including, for example, hand-held cameras and video recorders, drones, and vehicles. Image capture devices typically include one or more optical elements, e.g., lenses, as well as one or more image sensors, image signal processors, encoders, or combinations thereof to capture and process image data. More specifically, the optical element(s) capture content by receiving and focusing light via, and the captured content is converted to an electronic image signal by the image sensor. The image signal generated by the image sensor is then processed by an image signal processor to form an image, which may be stored and/or encoded.</p><p id="p-0005" num="0004">Each of the optical elements included in an image capture device has an associated field-of-view that extends in lateral and longitudinal directions. Traditionally, the fields of view for image capture devices are altered by changing the lens(es) of the device. Many digital single-lens reflex (DSLR) cameras, for instance, are configured for use with a variety of interchangeable lenses. The one or more lenses, when connected to a camera body, focus light onto the image sensor in different manners to provide the image capture device with different functionality (e.g., different focal lengths). However, in more modern image capture devices, lenses cannot simply be exchanged due to the high degree of precision required in alignment of the lens and the image sensor, which cannot be satisfied by traditional mechanical means. The image sensor and the lens are manufactured separately and, therefore, not precisely calibrated to each other to account for any manufacturing variability. Moreover, each time one of the lenses is removed, the image sensor is exposed to contaminants (e.g., dust, moisture, etc.) that may be detrimental to performance of the image capture device.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">Disclosed herein are implementations of image capture devices having an image capture module and a base module. The image capture module is releasably connectable to the base module. The image capture module may include an integrated image sensor and optical component for capturing image data. The base module may include a processor. The processor may be configured and the base module may be calibrated based on identification data provided by the image capture module when releasably connected to the base module. The image information and identification data may be wirelessly transferred from the image capture module to the base module.</p><p id="p-0007" num="0006">In an implementation, the image capture module is a plurality of image capture modules, where each image capture module may have an integrated image sensor and optical component assembly which has different image sensor properties and optical component properties. Each of these image capture modules being releasably attachable to the base module.</p><p id="p-0008" num="0007">In an implementation, the processor is a system-on-chip, image signal processor, a controller or combinations thereof which are configured for optimal performance based on the identification data provided by the image capture module. In an implementation, the base module may be calibrated based on the identification data provided by the image capture module. In an implementation, a user interface which is configurable based on the identification data.</p><p id="p-0009" num="0008">In an implementation, image information may be captured after processor configuration and base module calibration are complete. In an implementation, an audio or visual signal may be provided to indicate completion.</p><p id="p-0010" num="0009">In an implementation, the identification data may be stored in local storage on the image capture module. In an implementation, the image capture module control information is different for different image capture modules.</p><p id="p-0011" num="0010">In an implementation, the image information and the identification data may be provided using wired techniques, wireless technique, or a combination thereof.</p><p id="p-0012" num="0011">In an implementation, the base module and image capture module have corresponding or complementary mounting structures which are configured and dimensioned for releasable attachment of the image capture module to the base module. In an implementation, the corresponding or complementary mounting structures may provide mechanical coupling and electrical connectivity between the image capture module to the base module. In an implementation, the corresponding or complementary mounting structures may provide bidirectional electrical communication between the base module and the image capturing device.</p><p id="p-0013" num="0012">In an implementation, releasable attachment of the image capture module to the base module uses an interface. The interface may provide mechanical cooperation with the base module and electrical communication between the image capturing module and the base module. In an implementation, the interface may assist in data transfer between the image capture module and the base module.</p><p id="p-0014" num="0013">In an implementation, the image capture module may draw power from the base module, the interface, a power source on the image capture module or a combination thereof.</p><p id="p-0015" num="0014">In an implementation, the image capture module and base module may include environmentally proof housing to protect an image sensor or a processor, respectively.</p><p id="p-0016" num="0015">In an implementation, an image capture device includes an image capture module having a first integrated image sensor and optical component assembly and a second integrated image sensor and optical component assembly, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly in a diametric opposite configuration, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to detect image information and a base module having a processor for processing the image information, where the image capture module is releasably attachable to the base module.</p><p id="p-0017" num="0016">In an implementation, the image capture module is releasably attached to a centrally located receptacle in the base module to form a spherical camera. In an implementation, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to detect the image information in a 360 degree field of view. In an implementation, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to form a spherical camera. In an implementation, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly have different image sensor properties. In an implementation, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly have different optical component properties. In an implementation, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly have different image sensor properties and optical component properties. In an implementation, the processor is configurable based on identification data received from the image capture module when the image capture module is releasably attached to the base module. In an implementation, the image capture device further includes an interface, the interface configured to be in cooperation with the base module and the image capture module. In an implementation, the interface can provide electrical, mechanical, and signal connectivity between the base module and the image capture module. In an implementation, the image capture module is configured to draw power from the interface.</p><p id="p-0018" num="0017">In an implementation, an image capture device includes an image capture module configured to detect image information, a base module having a processor for processing the image information, and an interface configured to provide releasably attachable electrical, mechanical, and signal connectivity between the base module and the image capture module.</p><p id="p-0019" num="0018">In an implementation, the interface is configured to provide power to the image capture module. In an implementation, the image capture module includes a first integrated image sensor and optical component assembly and a second integrated image sensor and optical component assembly, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly in a diametric opposite configuration. In an implementation, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to detect the image information in a 360 degree field of view. In an implementation, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to form a spherical camera.</p><p id="p-0020" num="0019">In an implementation, a method of using an image capture device includes releasably attaching an image capture module to a base module to form the image capture device, wherein the image capture module includes a first integrated image sensor and optical component assembly and a second integrated image sensor and optical component assembly, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly in a diametric opposite configuration and detecting a <b>360</b> degree field of view image using the releasably attached image capture module.</p><p id="p-0021" num="0020">In an implementation, the releasably attaching further includes connecting the base module to an interface and connecting the image capture module to the interface, where the interface can provide electrical, mechanical, and signal connectivity between the base module and the image capture module. In an implementation, the method further includes powering the image capture module from the interface. In an implementation, the method further includes communicating control information from the image capture to the base module and configuring the base module based on the control information.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0022" num="0021">The disclosure is best understood from the following detailed description when read in conjunction with the accompanying drawings. It is emphasized that, according to common practice, the various features of the drawings are not to-scale. On the contrary, the dimensions of the various features are arbitrarily expanded or reduced for clarity.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref> are isometric views of an example of an image capture device.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. <b>2</b>A-B</figref> are isometric views of another example of an image capture device.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b>C</figref> is a cross-sectional view of the image capture device of <figref idref="DRAWINGS">FIGS. <b>2</b>A-B</figref>.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. <b>3</b>A-B</figref> are block diagrams of examples of image capture systems.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a perspective view of another example an image capture device together with an associated field-of-view;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic representation of an image capture device.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic representation of an example of an image capture device including an integrated sensor-optical component assembly in accordance with embodiments of this disclosure.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram of an example method for calibrating an image capture device including an integrated sensor-optical component assembly in accordance with embodiments of this disclosure.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic representation of an example of another embodiment of an integrated sensor-optical component assembly in accordance with embodiments of this disclosure.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flow diagram of an example method for using an image capture device including an integrated sensor-optical component assembly in accordance with embodiments of this disclosure.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a schematic of an example of another image capture device including an integrated sensor-optical component assembly in accordance with embodiments of this disclosure.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a front view of the example image capture device of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in an assembled state in accordance with embodiments of this disclosure.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a rear view of the example image capture device of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in an assembled state in accordance with embodiments of this disclosure.</p><p id="p-0036" num="0035">FIG.<b>13</b> is a front, upper, right perspective view of the example image capture device of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in a disassembled state.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a rear, lower, left perspective view of the example image capture device of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in the disassembled stated.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a schematic view of an example controller that may be included in an image capture device including an integrated sensor-optical component assembly.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a top schematic view of an example of another image capture module in an image capture device including an integrated sensor-optical component assembly.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a top schematic view of an example of another image capture module in an example image capture device including an integrated sensor-optical component assembly.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a top schematic view of an example of another image capture module in an example image capture device including an integrated sensor-optical component assembly.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a top schematic view of an example of another image capture module in an example image capture device including an integrated sensor-optical component assembly.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a top schematic view of an example of another image capture module in an example image capture device including an integrated sensor-optical component assembly.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0044" num="0043">Disclosed herein are embodiments of image capture devices having an image capture module and a base module that are interchangeable. The image capture module includes an integrated image sensor-optical component assembly that may be fixed in relation to a housing of the image capture module. The integrated image sensor-optical component assembly includes an image sensor and an optical component that may be coupled to each other in a precisely determined spatial or fixed arrangement to optimize the image sensor and optical component pairing. In an implementation, the optical component is a lens or multiple lenses. In an implementation, the image sensors in the image capture modules are maintained inside environmentally proof housings, such as for example, waterproof housings. The base module includes a system-on-chip (SoC) that is configurable based on identification provided by the image capture module. The SoC may support multiple image sensor modules, image sensors and the like. In an implementation, the SoC may be configured based on the image sensor, lens, field of view, and other like features or characteristics of the image capture module.</p><p id="p-0045" num="0044">In an implementation, the image capture module and the base module may include mounting structures that may provide releasable mechanical coupling and electrical connectivity. In an implementation, the electrical connectivity may be used to provide power and facilitate the transfer of data between the image capture module and the base module. In an implementation, the data may include image data and identification information from the image capture modules. In an implementation, the data may be transmitted wirelessly between the image capture module and the base module.</p><p id="p-0046" num="0045">Each of the image capture modules may be configured to provide image capture functions differently from each other, such as by having different resolutions, light sensitivities, frame rates, fields of view, and/or fixed or variable focal lengths. As a result, the image capture device may, by coupling different ones of the image capture modules to the base module, provide different image capture functions. Advantageously, a user of the image capture device may thereby be provided with added functionality, improved quality, reduced complexity, and/or reduced cost as compared to other cameras (e.g., the digital point-and-shoot cameras and the single-lens reflex cameras described above).</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref> are isometric views of an example of an image capture device <b>100</b>. The image capture device <b>100</b> may include a body <b>102</b> having a lens <b>104</b> structured on a front surface of the body <b>102</b>, various indicators on the front of the surface of the body <b>102</b> (such as LEDs, displays, and the like), various input mechanisms (such as buttons, switches, and touch-screen mechanisms), and electronics (e.g., imaging electronics, power electronics, etc.) internal to the body <b>102</b> for capturing images via the lens <b>104</b> and/or performing other functions. The image capture device <b>100</b> may be configured to capture images and video and to store captured images and video for subsequent display or playback.</p><p id="p-0048" num="0047">The image capture device <b>100</b> may include various indicators, including LED lights <b>106</b> and LED display <b>108</b>. The image capture device <b>100</b> may also include buttons <b>110</b> configured to allow a user of the image capture device <b>100</b> to interact with the image capture device <b>100</b>, to turn the image capture device <b>100</b> on, and to otherwise configure the operating mode of the image capture device <b>100</b>. The image capture device <b>100</b> may also include a microphone <b>112</b> configured to receive and record audio signals in conjunction with recording video. A side of the image capture device <b>100</b> may include an I/O interface <b>114</b>. The image capture device <b>100</b> may also include another microphone <b>116</b> integrated into the body <b>102</b> or housing. The front surface of the image capture device <b>100</b> may include two drainage ports as part of a drainage channel <b>118</b>. The image capture device <b>100</b> may include an interactive display <b>120</b> that allows for interaction with the image capture device <b>100</b> while simultaneously displaying information on a surface of the image capture device <b>100</b>. As illustrated, the image capture device <b>100</b> may include the lens <b>104</b> that is configured to receive light incident upon the lens <b>104</b> and to direct received light onto an image sensor internal to the lens <b>104</b>.</p><p id="p-0049" num="0048">The image capture device <b>100</b> of <figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref> includes an exterior that encompasses and protects the internal electronics which are further described in later sections. In the present example, the exterior includes six surfaces (i.e. a front face, a left face, a right face, a back face, a top face, and a bottom face) that form a rectangular cuboid. Furthermore, both the front and rear surfaces of the image capture device <b>100</b> are rectangular. In other embodiments, the exterior may have a different shape. The image capture device <b>100</b> may be made of a rigid material such as plastic, aluminum, steel, or fiberglass. Additional features, such as the features described above, may be affixed to the exterior. In some embodiments, the image capture device <b>100</b> described herein includes features other than those described below. For example, instead of a single interface button, the image capture device <b>100</b> may include additional buttons or different interface features, such as multiple microphone openings to receive voice or other audio commands.</p><p id="p-0050" num="0049">Although not expressly shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref>, in some implementations, the image capture device <b>100</b> may include one or more image sensors, such as a charge-coupled device (CCD) sensor, an active pixel sensor (APS), a complementary metal-oxide semiconductor (CMOS) sensor, an N-type metal-oxide-semiconductor (NMOS) sensor, and/or any other image sensor or combination of image sensors.</p><p id="p-0051" num="0050">Although not expressly shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref>, the image capture device <b>100</b> may include one or more other information sources or sensors, such as an inertial measurement unit (IMU), a global positioning system (GPS) receiver component, a pressure sensor, a temperature sensor, a heart rate sensor, or any other unit, or combination of units, that may be included in an image capture apparatus.</p><p id="p-0052" num="0051">The image capture device <b>100</b> may interface with or communicate with an external device, such as an external user interface device, via a wired or wireless computing communication link (not shown). The user interface device may, for example, be the personal computing device <b>360</b> described below with respect to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>. Any number of computing communication links may be used. The computing communication link may be a direct computing communication link or an indirect computing communication link, such as a link including another device or a network, such as the internet, may be used. In some implementations, the computing communication link may be a Wi-Fi link, an infrared link, a Bluetooth (BT) link, a cellular link, a ZigBee link, a near field communications (NFC) link, such as an ISO/IEC 20643 protocol link, an Advanced Network Technology interoperability (ANT+) link, and/or any other wireless communications link or combination of links. In some implementations, the computing communication link may be an HDMI link, a USB link, a digital video interface link, a display port interface link, such as a Video Electronics Standards Association (VESA) digital display interface link, an Ethernet link, a Thunderbolt link, and/or other wired computing communication link.</p><p id="p-0053" num="0052">The image capture device <b>100</b> may transmit images, such as panoramic images, or portions thereof, to the user interface device (not shown) via the computing communication link, and the user interface device may store, process, display, or a combination thereof the panoramic images.</p><p id="p-0054" num="0053">The user interface device may be a computing device, such as a smartphone, a tablet computer, a phablet, a smart watch, a portable computer, and/or another device or combination of devices configured to receive user input, communicate information with the image capture device <b>100</b> via the computing communication link, or receive user input and communicate information with the image capture device <b>100</b> via the computing communication link.</p><p id="p-0055" num="0054">The user interface device may display, or otherwise present, content, such as images or video, acquired by the image capture device <b>100</b>. For example, a display of the user interface device may be a viewport into the three-dimensional space represented by the panoramic images or video captured or created by the image capture device <b>100</b>.</p><p id="p-0056" num="0055">The user interface device may communicate information, such as metadata, to the image capture device <b>100</b>. For example, the user interface device may send orientation information of the user interface device with respect to a defined coordinate system to the image capture device <b>100</b>, such that the image capture device <b>100</b> may determine an orientation of the user interface device relative to the image capture device <b>100</b>. Based on the determined orientation, the image capture device <b>100</b> may identify a portion of the panoramic images or video captured by the image capture device <b>100</b> for the image capture device <b>100</b> to send to the user interface device for presentation as the viewport. In some implementations, based on the determined orientation, the image capture device <b>100</b> may determine the location of the user interface device and/or the dimensions for viewing of a portion of the panoramic images or video.</p><p id="p-0057" num="0056">The user interface device may implement or execute one or more applications to manage or control the image capture device <b>100</b>. For example, the user interface device may include an application for controlling camera configuration, video acquisition, video display, or any other configurable or controllable aspect of the image capture device <b>100</b>.</p><p id="p-0058" num="0057">The user interface device, such as via an application, may generate and share, such as via a cloud-based or social media service, one or more images, or short video clips, such as in response to user input. In some implementations, the user interface device, such as via an application, may remotely control the image capture device <b>100</b>, such as in response to user input.</p><p id="p-0059" num="0058">The user interface device, such as via an application, may display unprocessed or minimally processed images or video captured by the image capture device <b>100</b> contemporaneously with capturing the images or video by the image capture device <b>100</b>, such as for shot framing, which may be referred to herein as a live preview, and which may be performed in response to user input. In some implementations, the user interface device, such as via an application, may mark one or more key moments contemporaneously with capturing the images or video by the image capture device <b>100</b>, such as with a tag, such as in response to user input.</p><p id="p-0060" num="0059">The user interface device, such as via an application, may display, or otherwise present, marks or tags associated with images or video, such as in response to user input. For example, marks may be presented in a camera roll application for location review and/or playback of video highlights.</p><p id="p-0061" num="0060">The user interface device, such as via an application, may wirelessly control camera software, hardware, or both. For example, the user interface device may include a web-based graphical interface accessible by a user for selecting a live or previously recorded video stream from the image capture device <b>100</b> for display on the user interface device.</p><p id="p-0062" num="0061">The user interface device may receive information indicating a user setting, such as an image resolution setting (e.g., 3840 pixels by 2160 pixels), a frame rate setting (e.g., 60 frames per second (fps)), a location setting, and/or a context setting, which may indicate an activity, such as mountain biking, in response to user input, and may communicate the settings, or related information, to the image capture device <b>100</b>.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIGS. <b>2</b>A-B</figref> illustrate an image capture device <b>200</b> according to one embodiment. The image capture device <b>200</b> comprises a camera body <b>202</b> having two camera lenses <b>204</b>, <b>206</b> structured on front and back surfaces of the camera body <b>202</b>, various indicators on the front and/or back surface of the camera body <b>202</b> (such as LEDs, displays, and the like), various input mechanisms (such as buttons, switches, microphones, and touch-screen mechanisms), and electronics (e.g., imaging electronics, power electronics, etc.) internal to the camera body <b>202</b> for capturing images via the camera lenses <b>204</b>, <b>206</b> and/or performing other functions. The two lenses <b>204</b>, <b>206</b> are oriented in opposite directions and couple with two images sensors mounted on circuit boards (not shown). Other electrical camera components (e.g., an image processor, camera SoC (system-on-chip), etc.) may also be included on one or more circuit boards within the camera body <b>202</b> of the image capture device <b>200</b>.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>2</b>C</figref> is a cross-sectional view of the image capture device <b>200</b> of <figref idref="DRAWINGS">FIGS. <b>2</b>A-B</figref>. In some implementations, the image capture device <b>200</b> may be a spherical image capture device with fields-of-view <b>210</b>, <b>212</b> as shown in <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>. For example, the image capture device <b>200</b> may include image capture devices <b>220</b>, <b>222</b>, related components, or a combination thereof, arranged in a back-to-back or Janus configuration. For example, a first image capture device <b>220</b> may include the first lens <b>204</b> and a first image sensor <b>240</b>, and a second image capture device <b>222</b> may include the second lens <b>206</b> and a second image sensor <b>242</b> arranged oppositely from the first lens <b>204</b> and the first image sensor <b>240</b>.</p><p id="p-0065" num="0064">The first lens <b>204</b> of the image capture device <b>200</b> may have the field-of-view <b>210</b> shown above a boundary <b>250</b>. Behind the first lens <b>204</b>, the first image sensor <b>240</b> may capture a first hyper-hemispherical image plane from light entering the first lens <b>204</b>, corresponding to the first field-of-view <b>210</b>.</p><p id="p-0066" num="0065">The second lens <b>206</b> of the image capture device <b>200</b> may have a field-of-view <b>212</b> as shown below a boundary <b>252</b>. Behind the second lens <b>206</b>, the second image sensor <b>242</b> may capture a second hyper-hemispherical image plane from light entering the second lens <b>206</b>, corresponding to the second field-of-view <b>212</b>.</p><p id="p-0067" num="0066">One or more areas, such as blind spots <b>260</b>, <b>262</b>, may be outside of the fields-of-view <b>210</b>, <b>212</b> of the lenses <b>204</b>, <b>206</b>, light may be obscured from the lenses <b>204</b>, <b>206</b> and the corresponding image sensors <b>240</b>, <b>242</b>, and content in the blind spots <b>260</b>, <b>262</b> may be omitted from capture. In some implementations, the image capture device <b>200</b> may be configured to minimize the blind spots <b>260</b>, <b>262</b>.</p><p id="p-0068" num="0067">The fields-of-view <b>210</b>, <b>212</b> may overlap. Stitch points <b>270</b>, <b>272</b>, proximal to the image capture device <b>200</b>, at which the fields-of-view <b>210</b>, <b>212</b> overlap may be referred to herein as overlap points or stitch points. Content captured by the respective lenses <b>204</b>, <b>206</b>, distal to the stitch points <b>270</b>, <b>272</b>, may overlap.</p><p id="p-0069" num="0068">Images contemporaneously captured by the respective image sensors <b>240</b>, <b>242</b> may be combined to form a combined image. Combining the respective images may include correlating the overlapping regions captured by the respective image sensors <b>240</b>, <b>242</b>, aligning the captured fields-of-view <b>210</b>, <b>212</b>, and stitching the images together to form a cohesive combined image.</p><p id="p-0070" num="0069">A slight change in the alignment, such as position and/or tilt, of the lenses <b>204</b>, <b>206</b>, the image sensors <b>240</b>, <b>242</b>, or both, may change the relative positions of their respective fields-of-view <b>210</b>, <b>212</b> and the locations of the stitch points <b>270</b>, <b>272</b>. A change in alignment may affect the size of the blind spots <b>260</b>, <b>262</b>, which may include changing the size of the blind spots <b>260</b>, <b>262</b> unequally.</p><p id="p-0071" num="0070">Incomplete or inaccurate information indicating the alignment of the image capture devices <b>220</b>, <b>222</b>, such as the locations of the stitch points <b>270</b>, <b>272</b>, may decrease the accuracy, efficiency, or both of generating a combined image. In some implementations, the image capture device <b>200</b> may maintain information indicating the location and orientation of the lenses <b>204</b>, <b>206</b> and the image sensors <b>240</b>, <b>242</b> such that the fields-of-view <b>210</b>, <b>212</b>, stitch points <b>270</b>, <b>272</b>, or both may be accurately determined, which may improve the accuracy, efficiency, or both of generating a combined image.</p><p id="p-0072" num="0071">Optical axes through the lenses <b>204</b>, <b>206</b> may be substantially antiparallel to each other, such that the respective axes may be within a tolerance such as 1%, 3%, 5%, 10%, and/or other tolerances. In some implementations, the image sensors <b>240</b>, <b>242</b> may be substantially perpendicular to the optical axes through their respective lenses <b>204</b>, <b>206</b>, such that the image sensors may be perpendicular to the respective axes to within a tolerance such as 1%, 3%, 5%, 10%, and/or other tolerances.</p><p id="p-0073" num="0072">The lenses <b>204</b>, <b>206</b> may be laterally offset from each other, may be off-center from a central axis of the image capture device <b>200</b>, or may be laterally offset and off-center from the central axis. As compared to an image capture device with back-to-back lenses, such as lenses aligned along the same axis, the image capture device <b>200</b> including laterally offset lenses <b>204</b>, <b>206</b> may include substantially reduced thickness relative to the lengths of the lens barrels securing the lenses <b>204</b>, <b>206</b>. For example, the overall thickness of the image capture device <b>200</b> may be close to the length of a single lens barrel as opposed to twice the length of a single lens barrel as in a back-to-back configuration. Reducing the lateral distance between the lenses <b>204</b>, <b>206</b> may improve the overlap in the fields-of-view <b>210</b>, <b>212</b>.</p><p id="p-0074" num="0073">Images or frames captured by an image capture device, such as the image capture device <b>100</b> shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref> or the image capture device <b>200</b> shown in <figref idref="DRAWINGS">FIGS. <b>2</b>A-C</figref>, may be combined, merged, or stitched together to produce a combined image, such as a spherical or panoramic image, which may be an equirectangular planar image. In some implementations, generating a combined image may include three-dimensional, or spatiotemporal, noise reduction (3DNR). In some implementations, pixels along the stitch boundary may be matched accurately to minimize boundary discontinuities.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIGS. <b>3</b>A-B</figref> are block diagrams of examples of image capture systems. Referring first to <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, an image capture system <b>300</b> is shown. The image capture system <b>300</b> includes an image capture device <b>310</b> (e.g., a camera or a drone), which may, for example, be the image capture device <b>100</b> shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref> or the image capture device <b>200</b> shown in <figref idref="DRAWINGS">FIGS. <b>2</b>A-B</figref>.</p><p id="p-0076" num="0075">The image capture device <b>310</b> includes a processing apparatus <b>312</b> that is configured to receive a first image from the first image sensor <b>314</b> and receive a second image from the second image sensor <b>316</b>. The processing apparatus <b>312</b> may be configured to perform image signal processing (e.g., filtering, tone mapping, stitching, and/or encoding) to generate output images based on image data from the image sensors <b>314</b> and <b>316</b>. The image capture device <b>310</b> includes a communications interface <b>318</b> for transferring images to other devices. The image capture device <b>310</b> includes a user interface <b>320</b> to allow a user to control image capture functions and/or view images. The image capture device <b>310</b> includes a battery <b>322</b> for powering the image capture device <b>310</b>. The components of the image capture device <b>310</b> may communicate with each other via the bus <b>324</b>.</p><p id="p-0077" num="0076">The processing apparatus <b>312</b> may include one or more processors having single or multiple processing cores. The processing apparatus <b>312</b> may include memory, such as a random-access memory device (RAM), flash memory, or another suitable type of storage device such as a non-transitory computer-readable memory. The memory of the processing apparatus <b>312</b> may include executable instructions and data that can be accessed by one or more processors of the processing apparatus <b>312</b>. For example, the processing apparatus <b>312</b> may include one or more dynamic random access memory (DRAM) modules, such as double data rate synchronous dynamic random-access memory (DDR SDRAM). In some implementations, the processing apparatus <b>312</b> may include a digital signal processor (DSP). In some implementations, the processing apparatus <b>312</b> may include an application specific integrated circuit (ASIC). For example, the processing apparatus <b>312</b> may include a custom image signal processor.</p><p id="p-0078" num="0077">The first image sensor <b>314</b> and the second image sensor <b>316</b> may be configured to detect light of a certain spectrum (e.g., the visible spectrum or the infrared spectrum) and convey information constituting an image as electrical signals (e.g., analog or digital signals). For example, the image sensors <b>314</b> and <b>316</b> may include CCDs or active pixel sensors in a CMOS. The image sensors <b>314</b> and <b>316</b> may detect light incident through a respective lens (e.g., a fisheye lens). In some implementations, the image sensors <b>314</b> and <b>316</b> include digital-to-analog converters. In some implementations, the image sensors <b>314</b> and <b>316</b> are held in a fixed orientation with respective fields of view that overlap.</p><p id="p-0079" num="0078">The communications interface <b>318</b> may enable communications with a personal computing device (e.g., a smartphone, a tablet, a laptop computer, or a desktop computer). For example, the communications interface <b>318</b> may be used to receive commands controlling image capture and processing in the image capture device <b>310</b>. For example, the communications interface <b>318</b> may be used to transfer image data to a personal computing device. For example, the communications interface <b>318</b> may include a wired interface, such as a high-definition multimedia interface (HDMI), a universal serial bus (USB) interface, or a FireWire interface. For example, the communications interface <b>318</b> may include a wireless interface, such as a Bluetooth interface, a ZigBee interface, and/or a Wi-Fi interface.</p><p id="p-0080" num="0079">The user interface <b>320</b> may include an LCD display for presenting images and/or messages to a user. For example, the user interface <b>320</b> may include a button or switch enabling a person to manually turn the image capture device <b>310</b> on and off. For example, the user interface <b>320</b> may include a shutter button for snapping pictures.</p><p id="p-0081" num="0080">The battery <b>322</b> may power the image capture device <b>310</b> and/or its peripherals. For example, the battery <b>322</b> may be charged wirelessly or through a micro-USB interface.</p><p id="p-0082" num="0081">The image capture system <b>300</b> may be modular using the implementations described in this disclosure, such as the embodiments and implementations described in <figref idref="DRAWINGS">FIGS. <b>6</b>-<b>19</b></figref>.</p><p id="p-0083" num="0082">Referring next to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, another image capture system <b>330</b> is shown. The image capture system <b>330</b> includes an image capture device <b>340</b> and a personal computing device <b>360</b> that communicate via a communications link <b>350</b>. The image capture device <b>340</b> may, for example, be the image capture device <b>100</b> shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref> or the image capture device <b>200</b> shown in <figref idref="DRAWINGS">FIGS. <b>2</b>A-C</figref>. The personal computing device <b>360</b> may, for example, be the user interface device described with respect to <figref idref="DRAWINGS">FIGS. <b>1</b>A-D</figref>.</p><p id="p-0084" num="0083">The image capture device <b>340</b> includes a first image sensor <b>342</b> and a second image sensor <b>344</b> that are configured to capture respective images. The image capture device <b>340</b> includes a communications interface <b>346</b> configured to transfer images via the communication link <b>350</b> to the personal computing device <b>360</b>.</p><p id="p-0085" num="0084">The personal computing device <b>360</b> includes a processing apparatus <b>362</b> that is configured to receive, using the communications interface <b>366</b>, a first image from the first image sensor <b>342</b> and a second image from the second image sensor <b>344</b>. The processing apparatus <b>362</b> may be configured to perform image signal processing (e.g., filtering, tone mapping, stitching, and/or encoding) to generate output images based on image data from the image sensors <b>342</b>, <b>344</b>.</p><p id="p-0086" num="0085">The first image sensor <b>342</b> and the second image sensor <b>344</b> are configured to detect light of a certain spectrum (e.g., the visible spectrum or the infrared spectrum) and convey information constituting an image as electrical signals (e.g., analog or digital signals). For example, the image sensors <b>342</b> and <b>344</b> may include CCDs or active pixel sensors in a CMOS. The image sensors <b>342</b> and <b>344</b> may detect light incident through a respective lens (e.g., a fisheye lens). In some implementations, the image sensors <b>342</b> and <b>344</b> include digital-to-analog converters. In some implementations, the image sensors <b>342</b> and <b>344</b> are held in a fixed relative orientation with respective fields of view that overlap. Image signals from the image sensors <b>342</b> and <b>344</b> may be passed to other components of the image capture device <b>340</b> via a bus <b>348</b>.</p><p id="p-0087" num="0086">The communications link <b>350</b> may be a wired communications link or a wireless communications link. The communications interface <b>346</b> and the communications interface <b>366</b> may enable communications over the communications link <b>350</b>. For example, the communications interface <b>346</b> and the communications interface <b>366</b> may include an HDMI port or other interface, a USB port or other interface, a FireWire interface, a Bluetooth interface, a ZigBee interface, and/or a Wi-Fi interface. For example, the communications interface <b>346</b> and the communications interface <b>366</b> may be used to transfer image data from the image capture device <b>340</b> to the personal computing device <b>360</b> for image signal processing (e.g., filtering, tone mapping, stitching, and/or encoding) to generate output images based on image data from the image sensors <b>342</b> and <b>344</b>.</p><p id="p-0088" num="0087">The processing apparatus <b>362</b> may include one or more processors having single or multiple processing cores. The processing apparatus <b>362</b> may include memory, such as RAM, flash memory, or another suitable type of storage device such as a non-transitory computer-readable memory. The memory of the processing apparatus <b>362</b> may include executable instructions and data that can be accessed by one or more processors of the processing apparatus <b>362</b>. For example, the processing apparatus <b>362</b> may include one or more DRAM modules, such as DDR SDRAM.</p><p id="p-0089" num="0088">In some implementations, the processing apparatus <b>362</b> may include a DSP. In some implementations, the processing apparatus <b>362</b> may include an integrated circuit, for example, an ASIC. For example, the processing apparatus <b>362</b> may include a custom image signal processor. The processing apparatus <b>362</b> may exchange data (e.g., image data) with other components of the personal computing device <b>360</b> via a bus <b>368</b>.</p><p id="p-0090" num="0089">The personal computing device <b>360</b> may include a user interface <b>364</b>. For example, the user interface <b>364</b> may include a touchscreen display for presenting images and/or messages to a user and receiving commands from a user. For example, the user interface <b>364</b> may include a button or switch enabling a person to manually turn the personal computing device <b>360</b> on and off. In some implementations, commands (e.g., start recording video, stop recording video, or snap photograph) received via the user interface <b>364</b> may be passed on to the image capture device <b>340</b> via the communications link <b>350</b>.</p><p id="p-0091" num="0090">The image capture system <b>340</b> may be modular using the implementations described in this disclosure, such as the embodiments and implementations described in <figref idref="DRAWINGS">FIGS. <b>6</b>-<b>19</b></figref>.</p><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a perspective view of another example an image capture device <b>400</b> together with an associated field-of-view and <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic representation of the image capture device <b>400</b>. The image capture device <b>400</b> includes one or more optical components or elements <b>405</b> with an associated field-of-view <b>410</b> that extends, for example, 90&#xb0; in a lateral dimension X-X and 120&#xb0; in a longitudinal dimension Y-Y. Dependent upon the capabilities of the particular optical component(s) <b>405</b>, however, the extent of the field-of-view <b>410</b> may be varied (i.e., increased or decreased) in the lateral dimension or the longitudinal dimension. Suitable optical component(s) <b>405</b> may include one or more lenses, macro lenses, zoom lenses, special-purpose lenses, telephoto lenses, prime lenses, achromatic lenses, apochromatic lenses, process lenses, wide-angle lenses, ultra-wide-angle lenses, fisheye lenses, infrared lenses, ultraviolet lenses, and perspective control lenses. In some image capture devices, multiple, overlapping fields of view are employed to increases the capability of the device, for example, by including two or more optical elements. For example, a first fisheye image may be a round or elliptical image, and may be transformed into a first rectangular image; a second fisheye image may be a round or elliptical image, and may be transformed into a second rectangular image; and the first and second rectangular images may be arranged side-by-side, which may include overlapping, and stitched together to form the equirectangular planar image.</p><p id="p-0093" num="0092">As seen in <figref idref="DRAWINGS">FIG. <b>4</b></figref> in addition to the optical component(s) <b>405</b>, the image capture device <b>400</b> may further include an audio component <b>415</b>, a user interface (UI) unit <b>420</b>, an input/output (I/O) unit <b>425</b>, a sensor controller <b>430</b>, a processor <b>435</b>, an electronic storage unit <b>440</b>, an image sensor <b>445</b>, a metadata unit <b>450</b>, an optics unit <b>455</b>, a communication unit <b>460</b>, an encoder <b>465</b>, and power system <b>470</b>. Suitable examples of the image sensor <b>445</b> may include a charge-coupled device (CCD) sensor, an active pixel sensor (APS), a complementary metal-oxide semiconductor (CMOS) sensor, an N-type metal-oxide-semiconductor (NMOS) sensor, and/or any other image sensor or combination of image sensors.</p><p id="p-0094" num="0093">During the processing of images, it is envisioned that the processor <b>435</b> may identify motion information, such as motion vectors, representing motion between the respective images and reference data. For example, the processor <b>435</b> may perform motion estimation to generate the motion information. The processor <b>435</b> may then output the processed images, for example, to a memory of the image capture device <b>400</b> for storage.</p><p id="p-0095" num="0094">The image capture device <b>400</b> may be modular using the implementations described in this disclosure, such as the embodiments and implementations described in <figref idref="DRAWINGS">FIGS. <b>6</b>-<b>19</b></figref>.</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic representation of an example of an image capture device <b>600</b> including an integrated sensor-optical component assembly in accordance with embodiments of this disclosure. The image capture device <b>600</b> includes a base module <b>610</b>, sometimes referred to as a base module, an image capture module <b>620</b>, an interface <b>630</b>, and a system-on-chip (SoC) <b>640</b>.</p><p id="p-0097" num="0096">The base module <b>610</b> may include mounting structure <b>612</b>, such as, for example, mechanical clips, a detent assembly, slots, or the like that receive corresponding structure included on the image capture module <b>620</b>. The mounting structure <b>612</b> may facilitate the use of a variety of image capture modules <b>620</b>.</p><p id="p-0098" num="0097">The image capture module <b>620</b> may include a body <b>621</b> with engagement structures <b>623</b> that are configured and dimensioned to correspond with the mounting structure <b>612</b> included on the base module <b>610</b> of the image capture device <b>600</b>. The image capture module <b>620</b> may further include one or more sensors <b>626</b> (e.g., any of the aforementioned image sensors), and one or more optical components <b>627</b> (e.g., any of the aforementioned optical component(s), lens(es) and the like). The one or more sensors <b>626</b> and the one or more optical components <b>627</b> may form an integrated sensor-optical component assembly of the image capture module <b>620</b>. Although shown as including a single sensor <b>625</b> and a single optical element <b>627</b> in the embodiment shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, in alternate embodiments, the number of included sensors <b>625</b> and optical components <b>627</b> may be varied without departing from the scope of the present disclosure.</p><p id="p-0099" num="0098">Several factors may need to be considered for proper alignment of the sensor <b>625</b> and the optical component <b>627</b>. These factors may include the distance between the optical component <b>627</b> and the sensor <b>625</b>, the tip-tilt of the optical component <b>627</b> in relation to the sensor <b>625</b>, and the centration of the optical component <b>627</b> with respect to the sensor <b>625</b>. For example, regarding the distance between the optical component <b>627</b> and the sensor <b>625</b>, accuracy to within microns may be required. Additionally, with respect to tip-tilt, it may be desirable to arrange the optical component <b>627</b> in perpendicular relation to the sensor <b>627</b> to within fractions of a degree. Given this high degree of precision, alignment may be optimized at the manufacturing stage to ensure that the integrated sensor-optical component assembly is in constant focus (i.e., that the distance, tip-tilt, and centration are proper at all times). Specifically, during assembly, targets may be tracked within a field-of-view of the optical component <b>627</b> and the optical component <b>627</b> can then be repositioned relative to the sensor <b>625</b>. This process can be repeated until it is determined that proper alignment between the optical component <b>627</b> and the sensor <b>625</b> has been achieved. The optical component <b>627</b> may then be fixed relative to the sensor <b>625</b>. For example, an optical component mount (not shown) may be glued to the sensor <b>625</b> in order to preserve alignment. An offset may be also implemented to account for normal heating and cooling of the adhesive, the optical component <b>627</b> and the like.</p><p id="p-0100" num="0099">The interface <b>630</b> may be configured and dimensioned for mechanical connection to the base module <b>610</b> of the image capture device <b>600</b>. The interface <b>630</b> may also be adapted for electrical connection and signal communication between the base module <b>610</b> and the image capture module <b>620</b> to facilitate the transfer of data and/or power between the base module <b>610</b> and the image capture module <b>620</b>. In an implementation, the interface <b>630</b> may a mounting structure that is configured and dimensioned for engagement/disengagement with the base module <b>610</b> mounting structure to facilitate attachment/de-attachment of the at least one image capture module <b>620</b> to the base module <b>610</b>.</p><p id="p-0101" num="0100">In an implementation, the image capture module <b>620</b> may draw power from the base module <b>610</b>, for example, from a power source <b>614</b>, such as a battery. This power connection may be facilitated by the electrical connection established by the interface <b>630</b>. In an implementation, the image capture module <b>620</b> may draw power from an alternate power source <b>626</b> included on the image capture module <b>620</b>, e.g., one or more separate batteries. In an implementation the image capture module <b>620</b> may draw power from a power source <b>632</b> included on the interface <b>630</b>. In an implementation, the image capture module <b>620</b> may draw power from a combination of the above implementations or power sources.</p><p id="p-0102" num="0101">In an implementation, data is communicated between the image capture module <b>620</b> and the base module <b>610</b> when the image capture module <b>620</b> and the base module <b>610</b> are connected. In an implementation, the image capture module <b>620</b> and the base module <b>610</b> are physically connected. In an implementation, the data transfer may be bi-directional. The data may include image capture module identification data or information, changes in shutter speed, exposure, and the like. In an implementation, the volume of data flowing from the image capture module <b>620</b> to the base module <b>610</b> may exceed the volume of data flowing from the base module <b>610</b> to the image capture module <b>620</b>.</p><p id="p-0103" num="0102">In an implementation, the SoC <b>640</b> may be adapted and programmed to support multiple image capture modules <b>620</b> and product uses, such as, for example, hand-held applications, drone-based applications, and/or vehicle-based applications. The SoC <b>640</b> may be configured for use with a variety of image capture module <b>620</b>. Each image capture module <b>620</b> may include specific identification data or identifiers that may be communicated to the SoC <b>600</b>. The identification data may provide information concerning particular fields of view of specific optical components, image sensors and the like. Once the image capture module <b>620</b> is identified and processed by the SoC <b>640</b>, the SoC <b>640</b> may execute a self-calibration based on the identification data. The base module <b>610</b> and the SoC <b>640</b> may be configured or loaded with multiple firmware sets to facilitate the calibration process.</p><p id="p-0104" num="0103"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram of an example method <b>700</b> for calibrating an image capture device including an integrated sensor-optical component assembly in accordance with embodiments of this disclosure. The method <b>700</b> includes: attaching <b>710</b> an image capture module with a base module; receiving <b>720</b> image capture module identification data by a SoC on the base module; calibrating <b>730</b> the SoC based on the received image capture module identification data; and receiving <b>740</b> data from the image capture module after calibration is complete.</p><p id="p-0105" num="0104">The method <b>700</b> includes attaching <b>710</b> an image capture module with a base module. In an implementation, attachment may include mechanical coupling and electrical connectivity between the image capture module and the base module. In an implementation, attachment may include mechanical coupling and electrical connectivity between the image capture module, an interface module and the base module. In an implementation, attachment may include engaging mounting structure on the base module with the engagement structure included on the image capture module.</p><p id="p-0106" num="0105">The method <b>700</b> includes receiving <b>720</b> image capture module identification data by a SoC on the base module. In an implementation, the SoC may receive identification data from an integrated sensor-optical component assembly, the sensor or from other components of the image capture module.</p><p id="p-0107" num="0106">The method <b>700</b> includes calibrating <b>730</b> the SoC based on the received image capture module identification data. In an implementation, the SoC may process the identification data and configure the SoC and the base module for operation or optimal operation with the attached image capture module and the integrated sensor-optical component assembly. In an implementation, a controller on the image capture module may be configured for operation or optimal operation between the image capture module and base module. In an implementation, an image signal processor on the image capture module may be configured for operation or optimal operation between the image capture module and base module. In an implementation, a user interface on the image capture module may be configured for operation between the image capture module and base module.</p><p id="p-0108" num="0107">The method <b>700</b> includes receiving <b>740</b> data from the image capture module after calibration is complete. In an implementation, the SoC may signal, for example via an audio or visual signal, that calibration is complete and the image capture device is now ready to use.</p><p id="p-0109" num="0108"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic representation of an example of another embodiment of an image capture module <b>800</b> in accordance with embodiments of this disclosure. The image capture module <b>800</b> may be adapted for attachment to and de-attachment from a base module (not shown) as described herein.</p><p id="p-0110" num="0109">The image capture module <b>800</b> may include a body <b>821</b>, one or more sensors <b>825</b> and one or more optical components <b>827</b>. In an implementation, the one or more sensors <b>825</b> and one or more optical components <b>827</b> may be an integrated sensor-optical component assembly. The body <b>821</b> may include engagement structures <b>823</b> that are configured and dimensioned in correspondence with a mounting structure on a base module, the one or more sensors <b>825</b> and the one or more optical elements <b>827</b>. In this implementation, the optical component <b>827</b> may be configured as a first lens having a first field of view and may be configured as a second lens having a second, different field-of-view, such as, for example, a panoramic field-of-view.</p><p id="p-0111" num="0110"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flow diagram of an example method <b>900</b> for using an image capture device including an integrated sensor-optical component assembly in accordance with embodiments of this disclosure. The method <b>900</b> includes: attaching <b>910</b> a first image capture module to a base module; calibrating <b>920</b> a base module based on identification data; capturing <b>930</b> a first image with the first image capture module; de-attaching <b>940</b> the first image capture module; attaching <b>950</b> a second image capture module to the base module; calibrating <b>960</b> the base module based on identification data; and capturing <b>970</b> a second image with the second image capture module.</p><p id="p-0112" num="0111">The method <b>900</b> includes attaching <b>910</b> a first image capture module to a base module. In an implementation, attachment may include mechanical coupling and electrical connectivity between the image capture module and the base module. In an implementation, attachment may include mechanical coupling and electrical connectivity between the image capture module, an interface module and the base module. In an implementation, attachment may include engaging mounting structure on the base module with the engagement structure included on the image capture module. In an implementation, the image capture module may be pre-attached.</p><p id="p-0113" num="0112">The method <b>900</b> includes calibrating <b>920</b> a base module based on identification data. In an implementation, the calibrating <b>920</b> includes receiving image capture module identification data by a SoC on the base module. In an implementation, the SoC may receive identification data from an integrated sensor-optical component assembly, the sensor or from other components of the image capture module. In an implementation, the SoC may process the identification data and configure the SoC and the base module for optimal operation with the attached image capture module and the integrated sensor-optical component assembly. In an implementation, an image signal processor on the image capture module may be configured for operation or optimal operation between the image capture module and base module. In an implementation, a user interface on the image capture module may be configured for operation between the image capture module and base module.</p><p id="p-0114" num="0113">The method <b>900</b> includes capturing <b>930</b> a first image with the first image capture module. In an implementation, the image may be captured by the integrated sensor-optical component assembly. The method <b>900</b> may include receiving data from the image capture module after calibration is complete. In an implementation, the SoC may signal, for example via an audio or visual signal, that calibration is complete and the image capture device is now ready to use.</p><p id="p-0115" num="0114">The method <b>900</b> includes de-attaching <b>940</b> the first image capture module. In an implementation, de-attachment may include disengagement of the mounting structure and the engagement structure.</p><p id="p-0116" num="0115">The method <b>900</b> includes attaching <b>950</b> a second image capture module to the base module. In an implementation, attachment may include mechanical coupling and electrical connectivity between the image capture module and the base module. In an implementation, attachment may include mechanical coupling and electrical connectivity between the image capture module, an interface module and the base module. In an implementation, attachment may include engaging mounting structure on the base module with the engagement structure included on the image capture module.</p><p id="p-0117" num="0116">The method <b>900</b> includes calibrating <b>960</b> the base module based on identification data. In an implementation, the image may be captured by the integrated sensor-optical component assembly. In an implementation, the calibrating <b>950</b> includes receiving image capture module identification data by a SoC on the base module. In an implementation, the SoC may receive identification data from an integrated sensor-optical component assembly, the sensor or from other components of the image capture module. In an implementation, the SoC may process the identification data and configure the SoC and the base module for optimal operation with the attached image capture module and the integrated sensor-optical component assembly. In an implementation, an image signal processor on the image capture module may be configured for operation or optimal operation between the image capture module and base module. In an implementation, a user interface on the image capture module may be configured for operation between the image capture module and base module.</p><p id="p-0118" num="0117">The method <b>900</b> includes capturing <b>970</b> a second image with the second image capture module. The method <b>900</b> may include receiving data from the image capture module after calibration is complete. In an implementation, the SoC may signal, for example via an audio or visual signal, that calibration is complete and the image capture device is now ready to use.</p><p id="p-0119" num="0118"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a schematic of an example of another image capture device <b>1000</b> including an integrated sensor-optical component assembly in accordance with embodiments of this disclosure. The image capture device <b>1000</b> generally includes one or more image capture modules <b>1110</b> and a base module <b>1150</b>. Each of the one or more image capture modules <b>1110</b> provides various image capture functions, such as image sensing and light focusing. The base module <b>1150</b> may provide various general functions, such as providing a SoC, a user interface, power storage and delivery, and data storage. The one or more image capture modules <b>110</b> are each interchangeably couplable to the base module <b>1150</b>, such that each of the image capture modules <b>1110</b> may be repeatedly coupled to and removed from the base module <b>1150</b>. The image capture module <b>1110</b> may also be referred to as or include an image capture assembly, an image capture unit, a sensor/lens module, sensor/lens assembly, a sensor/lens unit or an integrated sensor-optical component assembly. The base module <b>1150</b> may also be referred to as a base assembly, a base unit, a body module, a body assembly a body unit, or a camera body unit. The image capture device <b>1000</b> may also be referred to as a modular camera system, a video camera system, or a modular video camera system.</p><p id="p-0120" num="0119">Each of the image capture modules <b>1110</b> may be configured to provide image capture functions differently from each other, such as by having different resolutions, light sensitivities, frame rates, fields of view, and/or fixed or variable focal lengths. As a result, the image capture device <b>1000</b> may, by coupling different ones of the image capture modules <b>1110</b> to the base module <b>1150</b>, provide different image capture functions. Advantageously, a user of the image capture device <b>1000</b> may thereby be provided with added functionality, improved quality, reduced complexity, and/or reduced cost as compared to other cameras (e.g., the digital point-and-shoot cameras and the single-lens reflex cameras described above).</p><p id="p-0121" num="0120">As referenced above, the image capture module <b>1110</b> is interchangeably coupleable to the base module <b>1150</b>. In an implementation, the image capture module <b>1110</b> is interchangeably coupleable to the base module <b>1150</b> via a wireless data connection <b>1170</b>, a conductive power connection <b>1180</b>, and a mechanical connection <b>1190</b>. The mechanical connection <b>1190</b> mechanically connects the image capture module <b>1110</b> to the base module <b>1150</b> to prevent physical separation therebetween, for example, by holding the image capture module <b>1110</b> in a predetermined spatial relationship relative to the base module <b>1150</b>. The wireless data connection <b>1170</b> provides wireless data transfer, such as transfer of image information (e.g., images frames of a video stream) from the image capture module <b>1110</b> to the base module <b>1150</b>. For example, the image information may include includes image frames having 4K resolution or more and captured at 30 frames per second or more.</p><p id="p-0122" num="0121">As discussed in further detail below, the wireless data connection <b>1170</b> may be a close proximity, high speed data transfer system that provides data transmission without physical contact between wireless data transfer devices thereof. The conductive power connection <b>1180</b> transfers electrical power to the image capture module <b>1110</b> from the base module <b>1150</b> via physical contact between conductive members, which is then used to power various electrical components of the image capture module <b>1110</b>. The wireless data connection <b>1170</b> may also be referred to as a data connection, a wireless data link, a data link, a wireless data coupling, or a data coupling. The conductive power connection <b>1180</b> may also be referred to as a power connection, a conductive power link, a power link, a conductive power coupling, or a power coupling. The mechanical connection <b>1910</b> may also be referred to as a physical connection, a mechanical coupling, or a physical coupling. The image capture module <b>1110</b> and variations thereof, the base module <b>1150</b>, the wireless data connection <b>1170</b>, the conductive power connection <b>1180</b>, and the mechanical connection <b>1190</b> are discussed in further detail below. In some embodiments, a wired data connection may be provided instead of or in addition to the wireless data connection <b>1170</b>, for example, to transfer subsets or particular types of data (e.g., control instructions). Instead of or in addition to the conductive power connection <b>1180</b>, a wireless power connection may be provided (e.g., inductive power transfer).</p><p id="p-0123" num="0122">Still referring to <figref idref="DRAWINGS">FIG. <b>10</b></figref> and now also to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, which is a front view of the example image capture device of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in an assembled state in accordance with embodiments of this disclosure, <figref idref="DRAWINGS">FIG. <b>12</b></figref>, which is a rear view of the example image capture device of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in an assembled state in accordance with embodiments of this disclosure, FIG.<b>13</b>, which is a front, upper, right perspective view of the example image capture device of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in a disassembled state, and <figref idref="DRAWINGS">FIG. <b>14</b></figref>, which is a rear, lower, left perspective view of the example image capture device of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in the disassembled stated, the image capture module <b>1110</b> generally includes a housing <b>1112</b>, an image sensor <b>1114</b>, and a lens <b>1116</b>. The image capture module <b>1110</b> may additionally include one or more of a wireless data transfer device <b>1118</b>, a power unit <b>1120</b>, a controller <b>1122</b>, or a non-volatile memory <b>1124</b>. The image capture module <b>1110</b> may further include additional sensors <b>1126</b>, such as one or more audio sensors (e.g., microphones), one or more motion sensors (e.g., gyroscope, inertia measurement unit (IMU)), and one or more position or orientation sensors (e.g., altimeter, global positioning (GPS), magnetometer or compass), which collect sensor information. The lens <b>1116</b> may also be referred to as a lens assembly, a lens unit or an optical component. The wireless data transfer device <b>1118</b> may also be referred to as a wireless data transfer unit, a wireless data transmission unit, a wireless data transmitter or transceiver, or a wireless transmitter or transceiver. The power unit <b>1120</b> may also be referred to as a power device, an electrical power unit, or an electrical power device.</p><p id="p-0124" num="0123">The various electrical components of the image capture module <b>1110</b>, such as the image sensor <b>1114</b>, the wireless data transfer device <b>1118</b>, the power unit <b>1120</b>, and the controller <b>1122</b>, or subcomponents thereof, may be mounted (e.g., physically and/or functionally connected) to a printed circuit board <b>1128</b> (e.g., PCB) located in the housing <b>1112</b>.</p><p id="p-0125" num="0124">The housing <b>1112</b> defines one or more cavities in which the various electrical components are positioned. The housing <b>1112</b> is configured to prevent contaminants, such as dust or water, from reaching the image sensor <b>1114</b> and other electrical components contained therein, for example, by satisfying one or more ingress protection standards published by the International Electrotechnical Commission (e.g., IP<b>67</b>). The housing <b>1112</b> may be considered waterproof.</p><p id="p-0126" num="0125">The image sensor <b>1114</b> is configured to detect light of a certain spectrum (e.g., the visible spectrum or the infrared spectrum) and convey image information constituting an image as electrical signals (e.g., analog or digital signals). These electrical signals that convey image information may be referred to as image signals <b>1171</b>, raw image signals, or pre-processed image signals. The image signal <b>1171</b> may, for example, be an RGB signal. The image sensor <b>1114</b> may be a charge-coupled device (CCD) or complementary metal-oxide-semiconductor (CMOS) type of image sensor.</p><p id="p-0127" num="0126">The image sensor <b>1114</b> may have (e.g., be configured with) primary image sensor characteristics that include type (e.g., CCD or CMOS), resolution (e.g., number of pixels), light spectrum (e.g., wavelengths of detectable light), speed (e.g., frame rate), power consumption, and number of image sensors <b>1114</b>. As a result, different ones of the image capture modules <b>1110</b> may have different characteristics, which may be advantageous for different customers (e.g., lower price point for image capture modules <b>1110</b> providing lower quality and/or fewer features) and different use cases (e.g., need for highly detailed images, light conditions, high frame rate requirements, duration of use, monocular view, stereoscopic view, or large field of view). In an implementation, these characteristics may be sent as or part of the identification data as described herein.</p><p id="p-0128" num="0127">The lens <b>1116</b> is configured to direct (e.g., focus) light from outside the cavity <b>1112</b><i>a </i>of the housing <b>1112</b> onto the image sensor <b>1114</b>. The lens <b>1116</b> may be formed as a lens element <b>1116</b><i>a </i>made of suitable material (e.g., glass or polymer) and configured for focusing light onto the image sensor <b>1114</b>. The lens <b>1116</b> may also be configured as an assembly that, for example, includes multiple lens elements <b>1116</b><i>a </i>that direct light to a single image sensor <b>1114</b>, a mechanical support (e.g., a bezel that supports the lens element <b>1116</b><i>a</i>), one or more filters, one or more covers, etc. The lens <b>1116</b> may also be configured as an operable mechanism that includes an operator (e.g., an electric motor) for operation thereof (e.g., moving the lens element <b>1116</b><i>a </i>to provide different focal lengths and/or for focusing). The lens <b>1116</b> may have (e.g., be configured with) primary lens characteristics that include quality or type of material, field of view, a fixed focal length, or a range of focal lengths (e.g., zoom). The lens <b>1116</b> may also include multiple lens elements <b>1116</b><i>a </i>that direct light to multiple image sensors <b>1114</b> of the image capture module <b>1110</b> (e.g., to provide stereoscopic imaging or increased fields of view whereby image information from the multiple image sensors <b>1114</b> is stitched together), or the image capture module <b>1110</b> may include multiple lenses <b>1116</b> that are each associated with one of multiple image sensors (e.g., each being associated with one of multiple image sensors <b>1114</b>), or the image capture module <b>1110</b> may include more than one lens <b>1116</b> (e.g., each being associated with one or more of multiple image sensors <b>1114</b>). Each of these may be referred to as an integrated sensor-optical component assembly.</p><p id="p-0129" num="0128">Moving ahead to <figref idref="DRAWINGS">FIGS. <b>7</b>-<b>11</b></figref>, variations of the image capture module <b>1110</b> are illustrated with different image sensors and different lens combinations. The image capture module <b>1110</b> may, for example, include a single image sensor <b>1114</b> having a high resolution (e.g., 4K) and speed (e.g., capable of 30 fps or 60 fps) and a single lens <b>1116</b> having a fixed focal length.</p><p id="p-0130" num="0129"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a top schematic view of an example of another image capture module <b>1610</b> in an image capture device including an integrated sensor-optical component assembly. Then image capture module <b>1610</b> may be configured with an image sensor <b>1614</b> and a lens <b>1616</b> that are the same as those of the image capture module <b>1110</b> (e.g., having the same primary characteristics) but vary in optical characteristics due to manufacturing variability and, therefore, have different image correction information associated therewith.</p><p id="p-0131" num="0130"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a top schematic view of an example of another image capture module <b>1710</b> in an example image capture device including an integrated sensor-optical component assembly. The image capture module <b>1710</b> includes a single image sensor <b>1714</b> having a lower resolution than the image sensor <b>1114</b>, but which includes a single lens <b>1116</b> having a lens having a fixed focal length that is longer than the lens <b>1116</b>.</p><p id="p-0132" num="0131"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a top schematic view of an example of another image capture module <b>1810</b> in an example image capture device including an integrated sensor-optical component assembly. The image capture module <b>1810</b> includes a single image sensor <b>1814</b> having the same resolution as the image sensor <b>1114</b>, but which includes a single lens <b>1816</b> having a variable focal length.</p><p id="p-0133" num="0132"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a top schematic view of an example of another image capture module <b>1910</b> in an example image capture device including an integrated sensor-optical component assembly. The image capture module <b>1910</b> includes two image sensors <b>1914</b> and two lenses <b>1916</b> to provide a <b>360</b> degree field of view (e.g., forming a spherical camera).</p><p id="p-0134" num="0133"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a top schematic view of an example of another image capture module <b>2010</b> in an example image capture device including an integrated sensor-optical component assembly. The image capture module <b>2010</b> includes to image sensors <b>2014</b> and two lenses <b>2016</b> that face the same direction to provide stereoscopic imaging. These examples of different image capture modules are not intended to be limiting, but rather different image capture modules may include different combinations of image sensors and lenses having different characteristics as described herein. Each of the different image capture modules <b>1110</b>, <b>1610</b>, <b>1710</b>, <b>1810</b>, <b>1910</b>, <b>2010</b> are configured to form the wireless data connection <b>1170</b>, the conductive power connection <b>1180</b>, and the mechanical connection <b>1190</b> with the base module <b>1150</b> in the same manner.</p><p id="p-0135" num="0134">As a result, different ones of the image capture modules <b>1110</b> may have different variability characteristics, which may be advantageous for different customers (e.g., lower price point for the image capture module <b>1110</b> having a lens <b>1116</b> having relatively low image quality and/or fewer features) and different use cases (e.g., macro or long distance, fixed or varying field of view).</p><p id="p-0136" num="0135">The lens <b>1116</b> may be fixedly coupled to the image sensor <b>1114</b> thereby forming a sensor/lens pair of the image capture module <b>110</b>. For example, the lens <b>116</b> may be secured to the image sensor <b>1114</b>, or to the printed circuit board <b>1128</b> to which the image sensor <b>1114</b> is coupled, in a fixed spatial arrangement (e.g., with an adhesive) relative thereto. For example, the lens <b>1116</b> may be aligned to the image sensor <b>1114</b> using an active alignment process. The active alignment process entails the image sensor <b>1114</b> viewing through the lens <b>1116</b> one or more images in a controlled environment, and precisely moving the lens <b>1116</b> relative to the image sensor <b>1114</b> to the fixed spatial arrangement in response to output from the image sensor <b>1114</b>. For example, the lens <b>1116</b> may be precisely moved in six degrees of freedom relative to the image sensor <b>1114</b> and then permanently fixed into the fixed spatial arrangement (e.g., using the adhesive).</p><p id="p-0137" num="0136">Due to manufacturing variability in the image sensor <b>1114</b> and the lens <b>1116</b>, the fixed spatial arrangement between the lens <b>1116</b> and the image sensor <b>1114</b> may vary slightly (e.g., be unique) between the sensor/lens pairs of different ones of the image capture modules <b>1110</b> that are otherwise configured similarly (e.g., with the same primary image sensor characteristics and primary lens characteristics). Manufacturing variability of the image sensor <b>1114</b> and the lens <b>1116</b> of different ones of the image capture modules <b>1110</b>, as well as the variability in the fixed spatial arrangement, may also result in variability of the characteristics the sensor/lens pair of each image capture module <b>1110</b>. Such variability may include lens shading, distortion, white balance, pixel defects, color, and chromatic aberration. During assembly of each sensor/lens pair, such as during, before, or after the active alignment processes, such characteristics may be assessed and image correction information may be determined therefor. For example, for each sensor/lens pair, the image correction information may include one or more of a lens shading correction table, a distortion correction table, a white balance correction table, a pixel defect table or map, a color correction table or matrix, or a chromatic aberration correction table. The one or more image correction information may be stored locally by the image capture module <b>1110</b> and be transferred to the base module <b>1150</b> for processing of image data received thereby (as discussed in further detail below).</p><p id="p-0138" num="0137">The wireless data transfer device <b>1118</b> of the image capture module <b>1110</b> forms the wireless data connection <b>1170</b> with a wireless data transfer device <b>1158</b> of the base module <b>1150</b>, which corresponds thereto. The wireless data transfer device <b>1118</b> is configured to wirelessly transmit information, such as the raw image signals <b>1171</b> with the raw image information from the image sensor <b>1114</b> and/or sensor signals <b>1172</b> with the sensor information from the sensors <b>1126</b>, to the base module <b>1150</b> for processing and/or storage thereby. The wireless data transfer device <b>1118</b> is enclosed by the housing <b>1112</b>, for example, being positioned in the cavity <b>1112</b><i>a</i>. The wireless data transfer device <b>118</b> is located in the housing <b>1112</b>, so as to facilitate wireless data transmission to the wireless data transfer device <b>158</b>. For example, the wireless data transfer device <b>1118</b> may be positioned against, or otherwise proximate, a wall of the housing <b>1112</b> in a fixed location, so as to be positioned in close proximity to the wireless data transfer device <b>1158</b> (e.g., being spaced apart less than 10 mm, such as less than 5 mm or less than 3 mm apart).</p><p id="p-0139" num="0138">The wireless data transfer device <b>1118</b> and the wireless data transfer device <b>1158</b> may employ any suitable wireless data transmission technology, such as Wi-Fi, Bluetooth, or variants thereof, to provide the wireless data connection <b>1170</b>. In some examples, the wireless data transfer device <b>1118</b> and the wireless data transfer device <b>1158</b> are capable of data transfer rates suitable for transferring video at various resolutions and/or frame rates, which may include 4K raw video at <b>30</b> frames per second. In one example, the wireless data transfer device <b>1118</b> and the wireless data transfer device <b>158</b> may employ technology promoted by Keyssa, Inc., which may be referred to as &#x201c;Kiss Connectivity.&#x201d; &#x201c;Kiss Connectivity&#x201d; is described as a &#x201c;solid-state connectivity solution&#x201d; that provides &#x201c;a private point-to-point data transmission of up to 6 Gbit/s,&#x201d; and that can provide an effective data rate of 4 Gbit/s with power consumption of 50 mW.</p><p id="p-0140" num="0139">Use of the wireless data connection <b>1170</b> may be advantageous compared to transferring data via a wired connection. A high speed wired data connection may, for example, require physical contact at <b>60</b> locations, for example with pins being received by corresponding receptacles, which may provide more points for risk of water intrusion, require greater force forming the connection, and/or provide more points for failure, such as missed connections and/or risk for damage. In contrast, the wireless data connection <b>170</b> limits apertures in the respective housings <b>1112</b>, <b>1152</b> so at to limit points for water intrusion, requires no force to form the data connection, and prevents physical contact that might otherwise damage data transmitters.</p><p id="p-0141" num="0140">The wireless data transfer device <b>1118</b> is in direct or indirect wired communication with the image sensor <b>1114</b> for receiving the image information therefrom. For example, each of the wireless data transfer device <b>1118</b> and the image sensor <b>1114</b> may be connected to the printed circuit board <b>1128</b> with conductors (e.g., traces; not shown) extending directly therebetween, or an intermediate electronic component may be arranged therebetween. For example, output from the image sensor <b>1114</b> may be transmitted and/or processed by another component (e.g., an intermediate controller or signal processor, such as an analog-to-digital converter or the controller <b>1122</b>) before the image information reaches the wireless data transfer device <b>1118</b>. The wireless data transfer device <b>1118</b> is similarly in direct or indirect wired communication with the other sensors <b>126</b> for receiving the sensor information therefrom.</p><p id="p-0142" num="0141">The wireless data transfer device <b>1118</b> of the image capture module <b>1110</b> may also be configured to wirelessly receive information from the wireless data transfer device <b>1158</b> of the base module <b>1150</b>, for example, with a control signal <b>1173</b>. The information received by image capture module <b>1110</b> in the control signal <b>1173</b> may include image module instruction information from the base module <b>1150</b>, which is used for operating the various components of the image capture module <b>1110</b>. These instructions may, for example, include instructions based on user selections and/or automated controls (e.g., programming) of the base module <b>1150</b> to control operation of the image sensor <b>1114</b> (e.g., on/off, speed/frame rate), the lens <b>1116</b> (e.g. zoom), and the sensors <b>1126</b> (e.g., on/off, sensitivity, etc.).</p><p id="p-0143" num="0142">The power unit <b>1120</b> of the image capture module <b>1110</b> and a power storage device <b>1160</b> of the base module <b>1150</b> cooperatively form the conductive power connection <b>1180</b>. The power unit <b>1120</b> is configured to receive electrical power from the base module <b>1150</b>. For example, the power unit <b>1120</b> may include power contacts <b>1120</b><i>a </i>(e.g., pads, pins, or receptacles) that are conductive and configured to mate with power contacts <b>1160</b><i>a </i>of the power storage device <b>1160</b> of the base module <b>1150</b>, which correspond thereto. The power contacts <b>1120</b><i>a </i>(e.g., three as shown or more or less) are exposed to outside the housing <b>1112</b>, so as to allow physical contact with the power contacts <b>1160</b><i>a </i>of the base module <b>1150</b>, which correspond thereto. For example, the power contacts <b>1120</b><i>a </i>may protrude from, sit within (e.g., flush), or be recessed relative to apertures in the housing <b>1112</b>. The power contacts <b>1120</b><i>a </i>may additionally be sealed with the housing <b>1112</b>, for example, to for the cavity <b>1112</b><i>a </i>to be waterproof. The power unit <b>1120</b> may otherwise be positioned in the cavity <b>1112</b><i>a. </i></p><p id="p-0144" num="0143">The power unit <b>1120</b> is additionally configured to distribute the electrical power to the various electrically powered components of the image capture module <b>1110</b>, including the image sensor <b>1114</b>, the controller <b>1122</b>, and the sensors <b>1126</b>. For example, the power unit <b>1120</b> may be connected to the printed circuit board <b>1128</b>, while conductors (e.g., traces; not shown) conduct the electrical power from the power unit <b>1120</b> directly or indirectly (e.g., with an intermediate component, such as the controller <b>1122</b>) to the electrically powered components.</p><p id="p-0145" num="0144">The power unit <b>1120</b> may additionally be configured to condition the electrical power for use by one or more of the electrical components of the image capture module <b>1110</b>. For example, reliable operation of the image sensor <b>1114</b> may be susceptible to power fluctuations. The power unit <b>1120</b> includes power conditioning circuitry that receives the electrical power from the base module <b>1150</b> and conditions the electrical power to produce conditioned electrical power that, for example, is within voltage and/or current requirements of the image sensor <b>1114</b>. The conditioned electrical power is then provided to the image sensor <b>1114</b>.</p><p id="p-0146" num="0145">As referenced above, the image capture module <b>1110</b> may also include a controller <b>1122</b>, which may be configured to control operation of various other components of the image capture module <b>1110</b>, such as the image sensor <b>114</b>, the lens <b>116</b> (e.g., if having a zoom function), the wireless data transfer device <b>1118</b>, the power unit <b>1120</b>, and/or the other sensors <b>1126</b>. For example, the controller <b>1122</b> may control operation of the various other components of the image capture module <b>1110</b> according to the control signal <b>1173</b> received from the base module <b>1150</b> (e.g., based on user selections and/or automated controls from the base module) and/or programming stored by the controller <b>1122</b>. The controller <b>1122</b> may, for example, be configured as the controller <b>1500</b> shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. The controller <b>1122</b> is in wired communication with those components that provide inputs thereto and/or are controlled thereby, for example, by being connected to the printed circuit board <b>1128</b> and having conductors (e.g., traces; not shown) extending therebetween.</p><p id="p-0147" num="0146">As referenced above, the image capture module <b>1110</b> may also include a non-volatile memory <b>1124</b> that stores image module information associated with the image capture module <b>1110</b>.The image module information may be transmitted to the base module <b>1150</b> via an image module information signal <b>1174</b> sent by the wireless data transfer device <b>1118</b>. The non-volatile memory <b>1124</b> is positioned within the housing <b>1112</b>, for example, in the cavity <b>1112</b><i>a </i>thereof. The non-volatile memory <b>1124</b> is in wired communication with the wireless data transfer device <b>1118</b>, for example, by being connected to the printed circuit board <b>1128</b>. The non-volatile memory <b>1124</b> may, for example, be the storage device <b>1530</b> of the controller <b>1500</b>. In an implementation, the image module information may be the identification data or a part thereof as described herein. In an implementation, the identification data may be sent in wired or wireless form as described herein</p><p id="p-0148" num="0147">The image module information stored by the non-volatile memory <b>1124</b> may include various types of information associated with the image capture module <b>1110</b>, such as the image correction information (described above), image module control information, and/or security information, which may be used by the base module <b>1150</b>. The image correction information (e.g., one or more image correction tables) may be used by the base module <b>1150</b> when processing and/or storing image data. The image module control information may be used by the base module <b>1150</b> for controlling operation of the image capture module <b>1110</b> with the base module <b>1150</b>. For example, the image module control information may include software programming enabling control of various functions of the image capture module <b>1110</b> not previously stored by the base module <b>1150</b>. For instance, the base module <b>1150</b> may already include (e.g., be preprogrammed with) image module control information for operation of image capture modules <b>1110</b> having certain configurations (e.g., specific combinations of primary sensor characteristics and primary lens characteristics), certain components, or certain features (e.g., mechanical zoom, sensors <b>1126</b>), but may not include image control information required for operation of other configurations, other components, or other features. Security information may include, for example, digital rights management (DRM) security protocols that permit use of the image capture module <b>1110</b> with the base module <b>1150</b>. The image control module information may be transferred form the image capture module <b>1110</b> and thereafter be stored by the base module <b>1150</b> (e.g., a memory thereof), and thereafter be used by the base module <b>1150</b> for controlling or operating another image capture module <b>1110</b>. In an implementation, this information may be the identification data or a part thereof. In an implementation, this data may be used to reconfigure the SoC, controller, image signal processor or base module for optimal operation with the image capture module as described herein above with respect to <figref idref="DRAWINGS">FIGS. <b>6</b>-<b>9</b></figref>.</p><p id="p-0149" num="0148">The base module <b>1150</b> generally includes a housing <b>1152</b>, an image signal processor <b>1154</b>, an encoder <b>1155</b>, and a storage device <b>1156</b>. The base module <b>1150</b> may additionally include the one or more wireless data transfer devices <b>1158</b> (referenced above), a power storage device <b>1160</b>, a controller <b>1162</b>, or a user interface <b>1164</b>. The base module <b>1150</b> may further include sensors <b>1166</b>, such as one or more audio sensors (e.g., microphones), one or more motion sensors (e.g., gyroscope, inertia measurement unit (IMU)), and one or more position or orientation sensors (e.g., altimeter, global positioning (GPS), magnetometer or compass). The image signal processor <b>1154</b> may also be referred to as an ISP or image processor. The encoder <b>1155</b> may also be referred to as an encoder processor or encoding device. The storage device <b>1156</b> may also be referred to as a memory, mass memory, mass memory storage, or mass storage device.</p><p id="p-0150" num="0149">The various electrical components of the base module <b>1150</b>, such as the image signal processor <b>1154</b>, the encoder <b>1155</b>, the storage device <b>1156</b>, the wireless data transfer device <b>1158</b>, and the controller <b>1162</b> may be mounted (e.g., physically and/or functionally connected) to a printed circuit board <b>1168</b> (e.g., PCB) located in the housing <b>1152</b>.</p><p id="p-0151" num="0150">The housing <b>1152</b> defines one or more cavities in which the various electrical components are positioned. The housing <b>1152</b> is configured to prevent contaminants, such as dust or water, from reaching the other electrical components in the cavity <b>1112</b><i>a</i>, for example, by satisfying one or more ingress protection standards (referenced above).</p><p id="p-0152" num="0151">The image signal processor <b>1154</b>, the encoder <b>1155</b>, and the storage device <b>1156</b> are discussed in turn below following discussion of the wireless data transfer device <b>1158</b>.</p><p id="p-0153" num="0152">As referenced above, the wireless data transfer device <b>1158</b> of the base module <b>1150</b> and the wireless data transfer device <b>1118</b> of the image capture module <b>1110</b> cooperatively form the wireless data connection <b>1170</b>. The wireless data transfer device <b>1158</b> is configured to wirelessly receive information from the wireless data transfer device <b>1118</b> of the image capture module <b>1110</b>, for example, via the raw image signal <b>1171</b>, the sensor signal <b>1172</b>, and the image module information signal <b>1174</b>. The wireless data transfer device <b>1158</b> may also transmit information to the wireless data transfer device of the image capture module <b>1110</b>, such as image module instructions with the control signal <b>1173</b>. The wireless data transfer device <b>1158</b> is further configured to transfer such information to various other components of the base module <b>1150</b>, such as the image signal processor <b>1154</b> and the controller <b>1162</b>, for example, by being connected to the printed circuit board <b>1168</b>. The wireless data transfer device <b>1158</b> is located in a fixed position within the housing <b>1152</b>, so as to be arranged in a predetermined spatial arrangement (e.g., close proximity) with the wireless data transfer device <b>1118</b> when the image capture module <b>1110</b> is connected to the base module <b>1150</b>.</p><p id="p-0154" num="0153">The image signal processor <b>1154</b> of the base module <b>1150</b> processes the raw image information captured by the image sensor <b>1114</b> of the image capture module <b>1110</b>. For example, the image signal processor <b>1154</b> may receive image information, such as the raw image information, from the wireless data transfer device <b>1158</b>, and process the raw image information. For example, the image signal processor <b>1154</b> may convert the raw image information in the form of RGB data to processed image information in the form of YUV or YCbCr data, as understood in the art. The image signal processor <b>1154</b> may additionally receive the image module information and process the raw image information and/or the processed image information according thereto. More specifically, the image signal processor <b>1154</b> may receive the image correction information, such as the lens shading correction table, the distortion correction table, the white balance correction table, the pixel defect table or map, the color correction table or matrix, or the chromatic aberration correction table, and process the image information (e.g., raw image information or processed image information) according thereto.</p><p id="p-0155" num="0154">The image signal processor <b>1154</b> receives the raw image information from the wireless data transfer device <b>1158</b> and transmits the processed image information to the encoder <b>1515</b>, for example, by being connected to the printed circuit board <b>1168</b>. The image signal processor <b>1154</b> is additionally contained within the housing <b>1152</b> that is waterproof. The image signal processor <b>1154</b> may be a standalone component or group of components, for example, having a processor, volatile memory (e.g., RAM), and non-volatile memory that stores software programming that may be executed by the processor thereof for processing the raw image information. Alternatively, the image signal processor <b>1154</b>, or functions thereof, may be performed by the controller <b>1162</b> of the base module <b>1150</b>.</p><p id="p-0156" num="0155">The encoder <b>1155</b> processes (e.g., converts or compresses) the processed image information to produce encoded image information. For example, the encoder <b>1155</b> may convert the processed image information (e.g, YUV or YCbCr data) into the encoded image information according to known standards, such as MPEG video format).</p><p id="p-0157" num="0156">The encoder <b>1155</b> receives the processed image information from the image signal processor <b>1154</b> and transmits the encoded image information to the storage device <b>1156</b>, for example, by being connected to the printed circuit board <b>1168</b>. The encoder <b>1155</b> is additionally contained within the housing <b>1152</b> that is waterproof. The encoder <b>1155</b> may be a standalone component or group of components, for example, having a processor, volatile memory (e.g., RAM), and non-volatile memory that stores software programming that may be executed by the processor thereof for processing the processed image information. Alternatively, the encoder <b>1155</b>, or functions thereof, may be performed by the image signal processor <b>1154</b> or the controller <b>1162</b>.</p><p id="p-0158" num="0157">Still further, the image signal processor <b>1154</b> and/or the encoder <b>1155</b> may be omitted from the base module <b>1150</b> and instead be incorporated into the image capture module <b>1110</b>. In such an arrangement, the processed image information or the encoded image information is transferred by the wireless data connection <b>1170</b> from the image capture module <b>1110</b> to the base module <b>1150</b> for further processing (e.g., encoding by the encoder <b>1155</b>) and/or storage by the storage device <b>1156</b>.</p><p id="p-0159" num="0158">The image sensor <b>1114</b> of the image capture module <b>1110</b>, the image signal processor <b>1154</b> of the base module <b>1150</b>, and the encoder <b>1155</b> of the base module <b>150</b> may be considered to cooperatively form an image processing pipeline (e.g., an image processing and encoding pipeline) by cooperatively capturing raw image information, processing the raw information to produce the processed image information, and encoding the processed image information to provide the encoded image information that may be stored in a common image or video format. Further, because the image sensor <b>1114</b>, the image signal processor <b>1154</b>, and the encoder <b>1155</b> are components of separate modules, the image processing pipeline may be considered a physically segregated image processing pipeline and/or an image processing pipeline that incorporates wireless data transmission of image information (e.g., the raw image information) prior to processing and/or encoding thereof.</p><p id="p-0160" num="0159">The storage device <b>1156</b> is configured to store the encoded image information. The storage device <b>1156</b> is a non-volatile storage device, such as a solid-state drive or hard disk drive. The storage device <b>1156</b> may be permanently or removably contained by the housing <b>1152</b> that is waterproof, so as to be protected from contaminants. The storage device <b>1156</b> is in wireless communication with the encoder <b>1155</b>, for example, via the printed circuit board <b>1168</b>.</p><p id="p-0161" num="0160">As referenced above, the power storage device <b>1160</b> forms the conductive power connection <b>1180</b> with the power unit <b>1120</b> of the image capture module <b>1110</b>. The power storage device <b>1160</b> is configured to store electrical energy and transfer the electrical energy to the electrically powered components of the base module <b>1150</b> (e.g., the image signal processor <b>1154</b>, the encoder <b>1155</b>, storage device <b>1156</b>, the wireless data transfer device <b>1158</b>, the controller <b>1162</b>, and the sensors <b>1166</b>) and the electrical components of the image capture module <b>1110</b> (as described above). For example, the power storage device <b>1160</b> may be electrically coupled to the printed circuit board <b>1168</b> to distribute electrical power to the electrical power components of the base module <b>1150</b>. The power storage device <b>1160</b> may, for example, include a battery that is permanently or removably held in the housing <b>1152</b>. The power storage device <b>1160</b> additionally includes the power contacts <b>1160</b><i>a </i>(e.g., pins, pads, or receptacles) that are complementary to the power contacts <b>1120</b><i>a </i>of the image capture module <b>1110</b> to form conductive connections for electrical power transfer therebetween. The power contacts <b>1160</b><i>a </i>are exposed outside the housing <b>1152</b>, for example by protruding from, being flush with, or being recessed from apertures in the housing <b>1152</b>, so as to make physical contact with the power contacts <b>1120</b><i>a </i>of the image capture module <b>1110</b>.</p><p id="p-0162" num="0161">The controller <b>1162</b> is configured to control operation of the various components of the base module <b>1150</b>, such as the image signal processor <b>1154</b>, the encoder <b>1155</b>, the wireless data transfer device <b>1158</b>, the power storage device <b>1160</b>, the user interface <b>1164</b>, and the sensors <b>1166</b>. The controller <b>1162</b> may further be configured to control operation of the various components of the image capture module <b>1110</b>, for example, by providing the image module instructions via the control signal <b>1173</b> to the controller <b>1122</b> thereof. The controller <b>1162</b> may control operation of the various components according to user inputs (e.g., received via the user interface <b>1164</b>) and/or according to stored programming. The controller <b>1162</b> may be configured as the controller <b>1500</b> shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. The controller <b>1162</b> is in wired communication with the components of the base module <b>1150</b> that provide inputs thereto and/or that are controlled thereby, for example, by being connected to the printed circuit board <b>1168</b> and having conductors (e.g., traces; not shown) extending therebetween. The controller <b>1162</b> is additionally contained within the housing <b>1152</b> that is waterproof, so as to be protected from contaminants. In an implementation, the controller <b>1162</b> and image signal processor <b>1154</b> may be configured or calibrated based on identification data provided by the image capture module as shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0163" num="0162">The user interface <b>1164</b> is configured to receive inputs from a user and/or to provide outputs thereto. The user interface <b>1164</b> may, for example, be a touch screen display (e.g., capacitive LCD display screen). The user interface <b>1164</b> provides options that may be selected by the user to control operation of the image capture device <b>1000</b>, such as video recording functions (e.g., start/stop, resolution, frame rate, etc.). The user interface <b>1164</b> may also provide information about the image capture device <b>1000</b> to the user, such as remaining storage capacity of the storage device <b>1156</b>, remaining power capacity of the power storage device <b>1160</b>. The user interface <b>1164</b> may also be able to display the encoded image information stored by the storage device <b>1156</b> (e.g., displaying video and/or still images).</p><p id="p-0164" num="0163">The user interface <b>1164</b> may additionally be reconfigured according to the image capture module <b>1110</b> connected to the base module <b>1150</b>. For example, based on the image module information received in the image module information signal <b>1174</b>, the user interface <b>1164</b> provides options that may be associated with some types of image capture modules <b>1110</b> and not others. For example, the user interface <b>1164</b> may display options associated with image capture modules <b>1110</b> having the lens <b>1116</b> with a controllable zoom function (e.g., a zoom level control option) or with multiple image sensors <b>1114</b> (e.g., stereoscopic or monocular control options), which are not associated with image capture modules <b>1110</b> having a single image sensor <b>1114</b> and a single lens <b>1116</b> of fixed focal length.</p><p id="p-0165" num="0164">Operation of the user interface <b>1164</b> may, for example, be controlled by the controller <b>1162</b>. The user interface <b>1164</b> is in wired communication with the controller <b>1162</b>, for example, by being connected to the printed circuit board <b>1168</b>. The user interface <b>1164</b> is contained in or may form an outer surface of the housing <b>1152</b> that is waterproof.</p><p id="p-0166" num="0165">As referenced above, the base module <b>1150</b> may include one or more sensors <b>1166</b>, such as audio sensors, motion sensors, and position or orientation sensors. The sensors <b>1166</b> collect sensor information that may be stored by the storage device and associated with the image information stored thereby (e.g., the encoded image information).</p><p id="p-0167" num="0166">The mechanical connection <b>1190</b> between the image capture module <b>1110</b> and the base module <b>1150</b> is configured to physically connect the image capture module <b>1110</b> to the base module <b>1150</b> in a predetermined spatial configuration. The mechanical connection <b>1190</b> is releasable and configured for the image capture module <b>1110</b> and the base module <b>1150</b> to support each other. The predetermined spatial configuration between the image capture module <b>1110</b> and the base module <b>1510</b> brings the wireless data transfer devices <b>1118</b>, <b>1158</b> thereof into a predetermined special configuration (e.g., close proximity and alignment) to form the wireless data connection <b>1170</b>. Further, the predetermined spatial configuration between the image capture module <b>1110</b> and the base module <b>1150</b> brings the power contacts <b>1120</b><i>a</i>, <b>1160</b><i>a </i>thereof into physical contact with each other to form the conductive power connection <b>1180</b>. The mechanical connection <b>1190</b> may be formed in different manners. For example, as shown in <figref idref="DRAWINGS">FIGS. <b>13</b>-<b>14</b></figref>, the image capture module <b>1110</b> includes one or more protrusions <b>1191</b> that are configured to be received by receptacles <b>1192</b> of the base module <b>1150</b>. The receptacles <b>1192</b> may, for example, include latch mechanisms (not shown) that releasably engage and retain the protrusions <b>1191</b> inside the receptacles <b>1192</b> and, thereby retain the image capture module <b>1110</b> to the base module <b>1150</b>. The mechanical connection <b>1190</b> instead be formed in other manners that include one or more of a cam lock mechanism, magnets, interference fit, or other latch mechanism.</p><p id="p-0168" num="0167">The mechanical connection <b>1190</b> is additionally configured to isolate one or both of the wireless data connection <b>1170</b> and the conductive power connection <b>180</b> from water intrusion. For example, the base module <b>1150</b> may include a seal <b>1193</b> (e.g., a gasket) that surrounds the power contacts <b>1160</b><i>a </i>and the surface of the housing <b>1152</b> adjacent the wireless data transfer device <b>1158</b> (depicted in dashed lines to represent being contained in the housing <b>1152</b>). The mechanical connection <b>1190</b> is configured to compress the seal <b>1193</b> between the base module <b>1150</b> and the image capture module <b>1110</b>, so as to form a water proof seal therebetween that prevents water intrusion therebetween in regions where the power contacts <b>1120</b><i>a </i>of the image capture module <b>1110</b> and the power contacts <b>1160</b><i>a </i>of the of the base module <b>1150</b> contact each other to form the conductive power connection <b>1180</b> and/or in regions where the wireless data transfer device <b>118</b> of the image capture module <b>1110</b> and the wireless data transfer device <b>1158</b> of the base module <b>1150</b> are positioned proximate each other to form the wireless data connection <b>1170</b>.</p><p id="p-0169" num="0168"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a schematic view of an example controller <b>1500</b> that may be included in an image capture device including an integrated sensor-optical component assembly. The controller <b>1500</b> may be used as the controller <b>122</b>, the controller <b>162</b>, or to otherwise implement the image capture devices described herein. The controller <b>1500</b> generally includes a processor <b>1510</b>, a memory <b>1520</b>, a storage device <b>1530</b>, one or more input devices <b>1540</b> (e.g., the image sensor <b>1114</b>, the sensors <b>1126</b>, the sensors <b>1166</b>, the user interface <b>1164</b>, the wireless data transfer devices <b>1118</b>, <b>1158</b>), and one or more output devices <b>1550</b> (e.g., the user interface <b>1164</b>, the wireless data transfer devices <b>1118</b>, <b>1158</b>, the storage device <b>1156</b>, etc.). The controller <b>1500</b> can also include a bus <b>1560</b> by which the various other components of the controller <b>1500</b> may communication with each other. The processor <b>1510</b> executes instructions (e.g., computer program instructions). For example, the processor <b>1510</b> may be a central processing unit (CPU) or other conventional device. The memory <b>1520</b> may be any suitable type of short-term information storage device (e.g., random-access memory or other volatile, high-speed storage device). The storage device <b>1530</b> may be a non-volatile storage device (e.g., a solid-state drive). The input devices <b>1540</b> may be any suitable input device, such as the user interface <b>1164</b>, the image sensor <b>1114</b>d, the wireless data transfer devices <b>1118</b>, <b>1158</b>, described previously. The output devices <b>1550</b> may be any suitable output device, such as the user interface <b>1164</b> or the wireless data transfer devices <b>1118</b>, <b>1158</b>, described previously.</p><p id="p-0170" num="0169">Throughout this specification, some embodiments have used the expression &#x201c;coupled&#x201d; along with its derivatives. The term &#x201c;coupled&#x201d; as used herein is not necessarily limited to two or more elements being in direct physical or electrical contact. Rather, the term &#x201c;coupled&#x201d; may also encompass two or more elements that are not in direct contact with each other, yet still co-operate or interact with each other, or are structured to provide a thermal conduction path between the elements.</p><p id="p-0171" num="0170">Likewise, as used herein, the terms &#x201c;includes,&#x201d; &#x201c;comprising,&#x201d; &#x201c;including,&#x201d; &#x201c;has,&#x201d; &#x201c;having,&#x201d; or any other variation thereof, are intended to cover a non-exclusive inclusion. For example, a process, method, article, or apparatus that includes a list of elements is not necessarily limited to only these elements but may also include other elements not expressly listed to such process, method, article, or apparatus.</p><p id="p-0172" num="0171">In addition, use of the &#x201c;a&#x201d; or &#x201c;an&#x201d; are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the invention. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.</p><p id="p-0173" num="0172">Finally, as used herein, any reference to &#x201c;one embodiment&#x201d; or &#x201c;an embodiment&#x201d; or &#x201c;some embodiments&#x201d; means that a particular element, feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase &#x201c;in one embodiment&#x201d; or &#x201c;in some embodiments&#x201d; in various places in the specification are not necessarily all referring to the same embodiment.</p><p id="p-0174" num="0173">Upon reading this disclosure, those of skill in the art will appreciate still additional alternative structural and functional designs for a multi-configuration mounting system as disclosed from the principles herein. Thus, while particular embodiments and applications have been illustrated and described, it is to be understood that the disclosed embodiments are not limited to the precise construction and components disclosed herein. Various modifications, changes, and variations, which will be apparent to those skilled in the art, may be made in the arrangement, operation, and details of the method and apparatus disclosed herein without departing from the spirit and scope defined in the appended claims.</p><p id="p-0175" num="0174">While the disclosure has been described in connection with certain embodiments, it is to be understood that the disclosure is not to be limited to the disclosed embodiments but, on the contrary, is intended to cover various modifications and equivalent arrangements included within the scope of the appended claims, which scope is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures as is permitted under the law.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image capture device, comprising:<claim-text>an image capture module having a first integrated image sensor and optical component assembly and a second integrated image sensor and optical component assembly, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly in a diametric opposite configuration, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to detect image information; and</claim-text><claim-text>a base module having a processor for processing the image information,</claim-text><claim-text>wherein the image capture module is releasably attachable to the base module.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image capture device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image capture module is releasably attached to a centrally located receptacle in the base module to form a spherical camera.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image capture device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to detect the image information in a 360 degree field of view.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image capture device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to form a spherical camera.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image capture device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly have different image sensor properties.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image capture device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly have different optical component properties.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image capture device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly have different image sensor properties and optical component properties.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image capture device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configurable based on identification data received from the image capture module when the image capture module is releasably attached to the base module.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The image capture device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>an interface, the interface configured to be in cooperation with the base module and the image capture module.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The image capture device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the interface can provide electrical, mechanical, and signal connectivity between the base module and the image capture module.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The image capture device of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the image capture module is configured to draw power from the interface.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An image capture device, comprising:<claim-text>an image capture module configured to detect image information;</claim-text><claim-text>a base module having a processor for processing the image information; and</claim-text><claim-text>an interface configured to provide releasably attachable electrical, mechanical, and signal connectivity between the base module and the image capture module.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The image capture device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the interface is configured to provide power to the image capture module.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The image capture device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the image capture module includes a first integrated image sensor and optical component assembly and a second integrated image sensor and optical component assembly, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly in a diametric opposite configuration.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The image capture device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to detect the image information in a 360 degree field of view.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The image capture device of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly are configured to form a spherical camera.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A method of using an image capture device, comprising:<claim-text>releasably attaching an image capture module to a base module to form the image capture device, wherein the image capture module includes a first integrated image sensor and optical component assembly and a second integrated image sensor and optical component assembly, the first integrated image sensor and optical component assembly and the second integrated image sensor and optical component assembly in a diametric opposite configuration; and</claim-text><claim-text>detecting a 360 degree field of view image using the releasably attached image capture module.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the releasably attaching further comprises:<claim-text>connecting the base module to an interface; and</claim-text><claim-text>connecting the image capture module to the interface,</claim-text><claim-text>wherein the interface can provide electrical, mechanical, and signal connectivity between the base module and the image capture module.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the method further comprising:<claim-text>powering the image capture module from the interface.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the method further comprising:<claim-text>communicating control information from the image capture to the base module; and</claim-text><claim-text>configuring the base module based on the control information.</claim-text></claim-text></claim></claims></us-patent-application>
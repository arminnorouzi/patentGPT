<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003585A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003585</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17771814</doc-number><date>20201217</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-001631</doc-number><date>20200108</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>J</subclass><main-group>5</main-group><subgroup>48</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>J</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>J</subclass><main-group>5</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>224</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>J</subclass><main-group>5</main-group><subgroup>48</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>J</subclass><main-group>5</main-group><subgroup>025</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>J</subclass><main-group>5</main-group><subgroup>0859</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>224</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10024</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10048</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">INFORMATION PROCESSING APPARATUS, INFORMATION PROCESSING SYSTEM, INFORMATION PROCESSING METHOD, AND STORAGE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only"><addressbook><last-name>TAJIMA</last-name><first-name>Akito</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only"><addressbook><last-name>KOMOTO</last-name><first-name>Shotaro</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant><us-applicant sequence="02" app-type="applicant" designation="us-only"><addressbook><last-name>OHMURA</last-name><first-name>Keiji</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TAJIMA</last-name><first-name>Akito</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KOMOTO</last-name><first-name>Shotaro</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>OHMURA</last-name><first-name>Keiji</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/IB2020/062077</doc-number><date>20201217</date></document-id><us-371c12-date><date>20220426</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An information processing apparatus includes: an information receiver configured to receive imaging data output from an imaging device; and a processing unit configured to generate a color image based on the received imaging data and control a display device to display the generated color image. The processing unit generates a detection frame constituted as plural regions based on the imaging data, controls the display device to display the generated detection frame as being superimposed on the color image, and displays a temperature for each of the plural regions.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="82.55mm" wi="158.75mm" file="US20230003585A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="224.79mm" wi="135.97mm" orientation="landscape" file="US20230003585A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="225.89mm" wi="149.86mm" file="US20230003585A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="122.94mm" wi="86.11mm" file="US20230003585A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="242.57mm" wi="138.01mm" orientation="landscape" file="US20230003585A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="246.72mm" wi="169.59mm" file="US20230003585A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="223.86mm" wi="170.69mm" orientation="landscape" file="US20230003585A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="261.28mm" wi="173.65mm" file="US20230003585A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="263.48mm" wi="167.47mm" file="US20230003585A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="261.79mm" wi="148.25mm" orientation="landscape" file="US20230003585A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="261.87mm" wi="151.89mm" orientation="landscape" file="US20230003585A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="257.47mm" wi="158.33mm" orientation="landscape" file="US20230003585A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="265.68mm" wi="170.10mm" orientation="landscape" file="US20230003585A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="265.68mm" wi="166.03mm" orientation="landscape" file="US20230003585A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="262.81mm" wi="153.42mm" orientation="landscape" file="US20230003585A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="264.16mm" wi="151.89mm" orientation="landscape" file="US20230003585A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="245.70mm" wi="169.67mm" orientation="landscape" file="US20230003585A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present disclosure relates to an information processing apparatus, an information processing system, a method of processing information, and a storage medium.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">A technique is known in which thermal image data from a thermal image sensor is input and the thermal image data is converted into an RGB (Red/Green/Blue) image and visualized based on a preset color map (for example, Patent Literature (PTL) 1). PTL 1 further describes segmenting the thermal image data into a plurality of area data, setting a threshold temperature for each area, comparing a temperature of each area with the threshold temperature, and issuing a notification when the temperature of any area exceeds the threshold temperature. Examples of the thermal image sensor include a thermographic camera, which inputs an amount of infrared rays generated from a monitoring target such as equipment and outputs the amount of infrared rays as thermal image data. According to PTL 1, a trend graph is created based on setting information of a detection area that is set by an operator at will in a monitoring area (corresponding to an angle of view of the thermal image sensor), and the generated trend graph is displayed on a display device in real time.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0004" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0003">[PTL 1]</li>    <li id="ul0001-0002" num="0004">Japanese Unexamined Patent Application Publication No. 2010-216858</li></ul></p><heading id="h-0005" level="1">SUMMARY OF INVENTION</heading><heading id="h-0006" level="1">Technical Problem</heading><p id="p-0005" num="0005">However, according to the background art, the detection area is limited to a part of the monitoring area. Therefore, for example, in a case where sparks or the like produced from an object to be monitored that in an abnormal state leaps to a device or the like existing outside the detection area, a temperature of the device may become an abnormal value. However, since the device exists outside the detection area, the abnormality value of the temperature is hard to be detected. As described above, in the background art, there is room for improvement in detecting the temperature of an object to be monitored.</p><p id="p-0006" num="0006">In view of the above issue, an object of the present disclosure is to appropriately detect a temperature of an object to be monitored.</p><heading id="h-0007" level="1">Solution to Problem</heading><p id="p-0007" num="0007">Example embodiments of the present disclosure include an information processing apparatus including: an information receiver configured to receive imaging data output from an imaging device; and a processing unit configured to generate a color image based on the received imaging data and control a display device to display the generated color image. The processing unit generates a detection frame constituted as plural regions based on the imaging data, controls the display device to display the generated detection frame as being superimposed on the color image, and displays a temperature for each of the plural regions.</p><heading id="h-0008" level="1">Advantageous Effects of Invention</heading><p id="p-0008" num="0008">According to one or more embodiments of the present disclosure, a temperature of an object to be monitored is appropriately detected.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0009" num="0009">The accompanying drawings are intended to depict example embodiments of the present invention and should not be interpreted to limit the scope thereof. The accompanying drawings are not to be considered as drawn to scale unless explicitly noted. Also, identical or similar reference numerals designate identical or similar components throughout the several views.</p><p id="p-0010" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of a configuration an information processing apparatus, according to an embodiment of the present disclosure.</p><p id="p-0011" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of data to be transmitted to a display device, according to an embodiment of the present disclosure.</p><p id="p-0012" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a view of a device, which includes a monitoring target, viewed from the side, according to an embodiment of the present disclosure.</p><p id="p-0013" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a view of the device, which includes the monitoring target, viewed from the above, according to an embodiment of the present disclosure.</p><p id="p-0014" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram for describing an overview of a monitoring operation performed by the information processing apparatus, according to an embodiment of the present disclosure.</p><p id="p-0015" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of a hardware configuration of the information processing apparatus, according to an embodiment of the present disclosure.</p><p id="p-0016" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an example of a hardware configuration of a camera, according to an embodiment of the present disclosure.</p><p id="p-0017" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of functional configurations of the information processing apparatus and the camera, according to an embodiment of the present disclosure.</p><p id="p-0018" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of operation performed by the information processing apparatus, according to an embodiment of the present disclosure.</p><p id="p-0019" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>10</b>B</figref> are diagrams illustrating examples of a detection frame and a color image, according to an embodiment of the present disclosure.</p><p id="p-0020" num="0020"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating an example of the color image displayed on a graphical user interface (GUI) screen, according to an embodiment of the present disclosure.</p><p id="p-0021" num="0021"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating a state in which the detection frame is superimposed on the color image on the GUI screen, according to an embodiment of the present disclosure.</p><p id="p-0022" num="0022"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram for describing an operation performed in step S<b>12</b> and the subsequent steps, according to an embodiment of the present disclosure.</p><p id="p-0023" num="0023"><figref idref="DRAWINGS">FIGS. <b>14</b>A and <b>14</b>B</figref> are flowcharts illustrating an example of operation, according to a variation of the present disclosure.</p><p id="p-0024" num="0024"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram illustrating an example of an RGB image displayed on the GUI screen, according to an embodiment of the present disclosure.</p><p id="p-0025" num="0025"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram illustrating a state in which the detection frame is superimposed on the RGB image on the GUI screen, according to an embodiment of the present disclosure.</p><p id="p-0026" num="0026"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a diagram illustrating an example of display of a graph indicating a tendency of temperature change.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0027" num="0027">The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the present invention. As used herein, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; are intended to include the plural forms as well, unless the context clearly indicates otherwise.</p><p id="p-0028" num="0028">In describing embodiments illustrated in the drawings, specific terminology is employed for the sake of clarity. However, the disclosure of this specification is not intended to be limited to the specific terminology so selected and it is to be understood that each specific element includes all technical equivalents that have a similar function, operate in a similar manner, and achieve a similar result.</p><p id="p-0029" num="0029">Embodiments of the present disclosure are described with reference to accompanying drawings.</p><p id="p-0030" num="0030"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of a configuration an information processing apparatus <b>100</b>, according to the present embodiment. The information processing apparatus <b>100</b> includes a processing unit <b>101</b> that acquires imaging data from a camera <b>1</b> and performs various processing, and a storage unit <b>103</b> that stores various types of data. The camera <b>1</b> is an example of an imaging device. Further, the information processing apparatus <b>100</b> is connected to a display device <b>102</b> that displays a result of processing by the processing unit <b>101</b>. Although in the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the display device <b>102</b> is external to the information processing apparatus <b>100</b>, in another example the information processing apparatus <b>100</b> includes the display device <b>102</b>.</p><p id="p-0031" num="0031">The imaging data includes at least temperature imaging data, and preferably further includes RGB imaging data. A detailed description is given below of the temperature imaging data and the RGB imaging data.</p><p id="p-0032" num="0032">An external device <b>200</b> such as a cloud server is connected to the information processing apparatus <b>100</b>. The cloud server is just an example of the external device <b>200</b>. Other examples of the external device <b>200</b> include, but are not limited to, a storage medium.</p><p id="p-0033" num="0033">A description is now given of data to be transmitted from the processing unit <b>101</b> to the display device <b>102</b>, with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0034" num="0034"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of data to be transmitted to the display device <b>102</b>, according to the present embodiment. The processing unit <b>101</b> according to the present embodiment transmits, as a processing result, information such as information indicating a name of a detection frame, information indicating a display position of the detection frame on the display device <b>102</b>, a temperature representative value of the detection frame, a temperature threshold value of the detection frame, an alert flag (high temperature), an alert flag (low temperature), and a time when the alert flag is turned on, to the display device <b>102</b>. A detailed description is given below of the processing unit <b>101</b>.</p><p id="p-0035" num="0035">A description is now given of a monitoring target <b>301</b>, which is a target to be monitored by the information processing apparatus <b>100</b>, with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref> and <figref idref="DRAWINGS">FIG. <b>4</b></figref>. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a view of a device <b>300</b>, which includes the monitoring target <b>301</b>, viewed from the side. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a view of the device <b>300</b>, which includes the monitoring target <b>301</b>, viewed from the above.</p><p id="p-0036" num="0036">The device <b>300</b> is, for example, a vulcanization furnace. In the embodiments, the monitoring target <b>301</b> to be monitored by the information processing apparatus <b>100</b> is a heat generating portion (e.g., an electric heater) of the vulcanization furnace. An area surrounded by a dashed line is a monitoring area <b>1</b><i>a</i>, which is an area to be monitored by the camera <b>1</b>. The monitoring area <b>1</b><i>a </i>includes the monitoring target <b>301</b> and a surrounding area <b>302</b> of the monitoring target <b>301</b>. The size of the monitoring area <b>1</b><i>a </i>is equal to, for example, an angle of view of each of a thermographic camera and an RGB camera that the camera <b>1</b> includes. A detailed description is given below of the thermographic camera and the RGB camera.</p><p id="p-0037" num="0037">The surrounding area <b>302</b> is, for example, an entire area around the heat generating portion. In another example, the surrounding area <b>302</b> is a part of the entire area around the heat generating portion. The part of the entire area around the heat generating portion is, for example, an area on the front side of the heat generating portion (a side where the camera <b>1</b> is provided), or an area on the back side of the heat generating portion (a side opposite to the side where the camera <b>1</b> is provided). In another example, the part of the entire area around the heat generating portion is an area other than the above-described areas, such as the upper side of the heat generating portion.</p><p id="p-0038" num="0038">The vulcanization furnace is just an example of the device <b>300</b>. Other examples of the device <b>300</b> include, but are not limited to, a lead battery, and a switchboard. In a case where the device <b>300</b> is a lead battery, for example, the monitoring target <b>301</b> is a main unit of the lead battery, and equipment existing the surrounding area <b>302</b> is, for example, a wiring connected to a positive electrode terminal or a negative electrode terminal of the lead battery. In a case where the device <b>300</b> is a switchboard, for example, the monitoring target <b>301</b> is a main unit of the switchboard, and equipment existing in the surrounding area <b>302</b> is, for example, a cable connected to the switchboard.</p><p id="p-0039" num="0039">A description is given now of an overview of a monitoring operation performed by the information processing apparatus <b>100</b>, with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>. Further, a configuration of the information processing apparatus <b>100</b> and operation performed by the information processing apparatus are described in detail with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, etc.</p><p id="p-0040" num="0040"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram for describing an overview of a monitoring operation performed by the information processing apparatus <b>100</b>, according to the present embodiment. First, the information processing apparatus <b>100</b> generates a color image <b>10</b> of the monitoring area <b>1</b><i>a </i>based on image data obtained by imaging the monitoring area <b>1</b><i>a</i>, and controls the display device <b>102</b> to display the generated color image <b>10</b>. The color image <b>10</b> includes, for example, a color image <b>301</b><i>a </i>of the monitoring target <b>301</b>, and a color image <b>302</b><i>a </i>of the surrounding area <b>302</b>. Next, the information processing apparatus <b>100</b> generates a detection frame <b>20</b> for detecting a temperature of the monitoring area <b>1</b><i>a </i>based on the image data obtained by imaging the monitoring area <b>1</b><i>a</i>, and controls the display device <b>102</b> to display the generated detection frame <b>20</b> as being superimposed on the color image <b>10</b>.</p><p id="p-0041" num="0041">The detection frame <b>20</b> is displayed in a manner that the detection frame is superimposed at least a part of each of the color image <b>301</b><i>a </i>and the color image <b>302</b><i>a</i>. More preferably, the detection frame <b>20</b> is displayed in a manner that the detection frame is superimposed on the entirety of each of the color image <b>301</b><i>a </i>and the color image <b>302</b><i>a. </i></p><p id="p-0042" num="0042">A rectangular shape is just an example of the shape of the detection frame <b>20</b>. The detection frame <b>20</b> can have any other suitable shape such as an elliptical shape, provided that the detection frame is displayed as being superimposed on at least a part of each of the color image <b>301</b><i>a </i>and the color image <b>302</b><i>a</i>. Further, plural cells (plural regions) <b>20</b><i>a </i>constituting the detection frame <b>20</b> can also have a shape other than a rectangular shape. Furthermore, although the figure illustrates an example in which the plural cells <b>20</b><i>a </i>are regularly arranged vertically and horizontally, in another example, the plural cells are arranged irregularly.</p><p id="p-0043" num="0043">The information processing apparatus <b>100</b> compares the temperatures of the color image <b>301</b><i>a </i>and the color image <b>302</b><i>a </i>with a predetermined threshold value (a setting value used in determining an abnormal temperature) in each of the plural cells <b>20</b><i>a </i>constituting the detection frame <b>20</b>. According to the comparison result, when the temperature exceeds the threshold value, the information processing apparatus <b>100</b> performs alert processing. The alert processing is, for example, transmitting a notification to the display device <b>102</b>, the external device <b>200</b>, etc. by email. In another example, the alert processing is changing a color display of a signal light that the external device <b>200</b> or the like includes from a normal state to a warning state. In still another example, the alert processing is outputting an alarm sound from a speaker that the external device <b>200</b> or the like includes. In still another example, the alert processing is a combination of at least two of the above processing.</p><p id="p-0044" num="0044">The threshold value has a certain range from an upper limit value to a lower limit value, e.g., from 100&#xb0; C. to 90&#xb0; C. When the temperature exceeds the upper limit value or falls below the lower limit value, the alert processing is performed. A detailed description is given below of an example of the alert processing.</p><p id="p-0045" num="0045"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating an example of a hardware configuration of the information processing apparatus <b>100</b>. The information processing apparatus <b>100</b> includes a central processing unit (CPU) <b>501</b>, a random access memory (RAM) <b>502</b>, a read only memory (ROM) <b>503</b>, a storage <b>504</b>, a network interface (I/F) <b>505</b>, an input device <b>506</b>, a display device <b>507</b>, an external device I/F <b>508</b> and a bus <b>509</b> through which data, control signals and the like are transmitted.</p><p id="p-0046" num="0046">The CPU <b>501</b> is a processor that reads programs and data stored in, for example, the ROM <b>503</b> and the storage <b>504</b> to the RAM <b>502</b> and executes processing, to implement functions of the information processing apparatus <b>100</b>. The RAM <b>502</b> is a volatile memory used as a work area for the CPU <b>501</b>. The ROM <b>503</b> is a nonvolatile memory. The storage <b>504</b> is a storage device such as a hard disk drive (HDD) and a solid state drive (SSD). The storage <b>504</b> stores, for example, an operating system (OS), application programs, and various types of data.</p><p id="p-0047" num="0047">The network I/F <b>505</b> is a communication interface that connects the information processing apparatus <b>100</b> to the network <b>104</b>. The input device <b>506</b> is an input device such as a mouse or a keyboard, and is used to input various operations to the information processing apparatus <b>100</b>. The display device <b>507</b> displays, for example, results of processing performed by the information processing apparatus <b>100</b>. The external device I/F <b>508</b> is an interface that connects the information processing apparatus <b>100</b> to the external device <b>200</b>. Functions of the information processing apparatus <b>100</b> are implemented by the CPU <b>501</b> executing a predetermined program, for example.</p><p id="p-0048" num="0048"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating an example of a hardware configuration of the camera <b>1</b>. The camera <b>1</b> includes a CPU <b>601</b>, a memory <b>602</b>, a network I/F <b>603</b>, a thermographic camera <b>605</b>, an RGB (Red/Green/Blue) camera <b>606</b>, and a bus <b>609</b> through which data, control signals and the like are transmitted.</p><p id="p-0049" num="0049">The CPU <b>601</b> is a processor that executes a predetermined program stored in the memory <b>602</b> to implement functions of the camera <b>1</b>. The memory <b>602</b> is a storage device such as a RAM, a ROM, or a flash ROM. The network I/F <b>603</b> is a communication interface that connects the camera <b>1</b> to the network <b>104</b>.</p><p id="p-0050" num="0050">The thermographic camera <b>605</b> is an imaging device (imaging means) configured to take an image of heat emitted from the monitoring target <b>301</b> as infrared rays. The thermographic camera <b>605</b> takes an image of an inside of the monitoring area <b>1</b><i>a </i>as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> and <figref idref="DRAWINGS">FIG. <b>4</b></figref>, for example, and converts to a temperature of an object or space within the monitoring area <b>1</b><i>a</i>, to generate temperature imaging data and output the generated temperature imaging data. The temperature imaging data is constituted as a plurality of pixels of M&#xd7;N (e.g., vertical 60&#xd7;horizontal 80). The plurality of pixels includes a pixel group corresponding to the monitoring target <b>301</b> and another pixel group corresponding to the surrounding area <b>302</b> of the monitoring target <b>301</b> in the monitoring area <b>1</b><i>a. </i></p><p id="p-0051" num="0051">The RGB camera <b>606</b>, for example, takes an image of the inside of the monitoring area <b>1</b><i>a</i>, to generate RGB imaging data in which colors of an object or space in the imaged monitoring area <b>1</b><i>a </i>are represented by the intensity values of RGB (three colors) and output the generated RGB data. In substantially the same manner as the temperature imaging data, the RGB imaging data is constituted as a plurality of M&#xd7;N pixels.</p><p id="p-0052" num="0052">Hereinafter, the temperature imaging data and the RGB imaging data may be referred to as &#x201c;imaging data&#x201d;, unless they need to be distinguished from each other.</p><p id="p-0053" num="0053"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of functional configurations of the information processing apparatus <b>100</b> and the camera <b>1</b>. The information processing apparatus <b>100</b> includes a communication unit <b>701</b>, an information receiver <b>702</b>, a detection unit <b>703</b>, a notification control unit <b>704</b>, a display control unit <b>707</b>, and a storage unit <b>103</b>. The information processing apparatus <b>100</b> executes a predetermined program to implement the functions of the communication unit <b>701</b>, the information receiver <b>702</b>, the detection unit <b>703</b>, the notification control unit <b>704</b>, and the display control unit <b>707</b>.</p><p id="p-0054" num="0054">The communication unit <b>701</b> connects the information processing apparatus <b>100</b> to the network <b>104</b>, to allow the information processing apparatus to communicate with the camera <b>1</b> and the external device <b>200</b>. The information receiver <b>702</b> receives imaging data from the camera <b>1</b> and stores the received imaging data in the storage unit <b>103</b>.</p><p id="p-0055" num="0055">The detection unit <b>703</b> detects a temperature change in each of the regions (the cells <b>20</b><i>a</i>) in the detection frame <b>20</b> based on the imaging data from the camera <b>1</b>. The notification control unit <b>704</b> compares the temperatures of the color image <b>301</b><i>a </i>and the color image <b>302</b><i>a </i>with the predetermined threshold value (the setting value used in determining an abnormal temperature) in the plural cells <b>20</b><i>a </i>constituting the detection frame <b>20</b>, to perform the alert processing, i.e., notification processing, when the temperature exceeds the threshold value. In the following description, performing the notification processing may be referred to as &#x201c;(to) notify that the temperature exceeds the threshold value&#x201d;.</p><p id="p-0056" num="0056">The display control unit <b>707</b> controls, for example, display by the display device <b>102</b> or display by the external device <b>200</b>. The display control unit <b>707</b> includes a color image display unit <b>707</b><i>a</i>, a detection frame display unit <b>707</b><i>b</i>, and a temperature display unit <b>707</b><i>c. </i></p><p id="p-0057" num="0057">The color image display unit <b>707</b><i>a </i>generates the color image <b>10</b> of the monitoring area <b>1</b><i>a </i>based on the imaging data output from an imaging data acquisition unit <b>722</b>, described below, that takes an image of the monitoring area <b>1</b><i>a </i>including the monitoring target <b>301</b> and the surrounding area of the monitoring target, and controls the display device <b>102</b> to display the generated color image. The detection frame display unit <b>707</b><i>b </i>generates the detection frame <b>20</b> constituted as the plural cells <b>20</b><i>a </i>for detecting the temperature of the monitoring area <b>1</b><i>a </i>based on the imaging data, and controls the display device <b>102</b> to display the generated detection frame <b>20</b> as being superimposed on the color image <b>10</b>. The temperature display unit <b>707</b><i>c </i>displays at least a temperature in each of the plural cells <b>20</b><i>a </i>constituting the detection frame <b>20</b>.</p><p id="p-0058" num="0058">In other words, the temperature display unit <b>707</b><i>c </i>displays at least temperature information indicating the temperature in each of a plurality of regions constituting the detection frame.</p><p id="p-0059" num="0059">Examples of the temperature display include, but are not limited to, a display of a temperature value such as 25&#xb0; C. or 40&#xb0; C. and a color corresponding to the temperature value, such as 25&#xb0; C. is displayed in blue and 40&#xb0; C. is displayed in red.</p><p id="p-0060" num="0060">The camera <b>1</b> includes a communication unit <b>721</b>, the imaging data acquisition unit <b>722</b>, and an information transmitter <b>724</b>.</p><p id="p-0061" num="0061">The communication unit <b>721</b> connects the camera <b>1</b> to the network <b>104</b>, to allow the camera to communicate with the information processing apparatus <b>100</b>. The imaging data acquisition unit <b>722</b> acquires imaging data using the thermographic camera <b>605</b> and the RGB camera <b>606</b> described above. The information transmitter <b>724</b> transmits the imaging data acquired by the imaging data acquisition unit <b>722</b> to the information processing apparatus <b>100</b>.</p><p id="p-0062" num="0062">A description is now given of operation performed by the information processing apparatus <b>100</b>, with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref> to <figref idref="DRAWINGS">FIG. <b>17</b></figref>.</p><p id="p-0063" num="0063"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of operation performed by the information processing apparatus <b>100</b>.</p><p id="p-0064" num="0064">In step S<b>1</b>, the program installed in the information processing apparatus <b>100</b> is activated, and thereby the processing unit <b>101</b> accesses the camera <b>1</b> to acquire imaging data.</p><p id="p-0065" num="0065">In step S<b>2</b>, the processing unit <b>101</b> converts the acquired imaging data into an RGB color image based on a preset color map. The converted color image is stored in the memory of the information processing apparatus <b>100</b> (step S<b>3</b>).</p><p id="p-0066" num="0066">When the imaging data corresponding to a predetermined time period (e.g., a few minutes) is accumulated (step S<b>4</b>: YES), the processing unit <b>101</b> stores a moving image file in a storage folder (step S<b>5</b>).</p><p id="p-0067" num="0067">Thus, when any abnormality occurs in the monitoring target <b>301</b>, an operator checks the monitoring target <b>301</b> and a situation surrounding the monitoring target as viewing the moving image, and identify the cause of the abnormality without difficulty.</p><p id="p-0068" num="0068">In step S<b>6</b>, the processing unit <b>101</b> displays the color image on a graphical user interface (GUI) screen and further draws the detection frame on the color image. Examples of the GUI screen include, but are not limited to, an operation screen displayed on the display device <b>102</b> or a monitor of the external device <b>200</b>.</p><p id="p-0069" num="0069">Examples of the color image and the detection frame are illustrated in <figref idref="DRAWINGS">FIG. <b>10</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>10</b>B</figref>, respectively. <figref idref="DRAWINGS">FIG. <b>10</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>10</b>B</figref> are diagrams illustrating examples of the detection frame and the color image. <figref idref="DRAWINGS">FIG. <b>10</b>A</figref> illustrates an example of the detection frame, and <figref idref="DRAWINGS">FIG. <b>10</b>B</figref> illustrates an example of the color image.</p><p id="p-0070" num="0070"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating an example of the color image displayed on the GUI screen <figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a state in which the detection frame is not yet superimposed on the color image. In the example, the color image is displayed in an area indicated by (1) in <figref idref="DRAWINGS">FIG. <b>11</b></figref> (a left half area on the GUI screen).</p><p id="p-0071" num="0071"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating a state in which the detection frame is superimposed on the color image on the GUI screen. The detection frame is constituted as, for example, 100 grids (vertical 10 cells&#xd7;horizontal 10 cells). This detection frame is displayed as being superimposed on the color image. The detection frame is displayed in a color (e.g., blue) distinguishable from the color image.</p><p id="p-0072" num="0072">In a right half area of the GUI screen, setting buttons indicted by (2) to (6) are displayed. For example, in a &#x201c;Setting&#x201d; field indicated by (2), a desired name of an image file when the image file is to be saved is set. Either one of buttons in a &#x201c;Detection Frame Display&#x201d; field indicated by (3) is selected to switch whether to display only an image represented by the imaging data, to display only the detection frame, or to display both of the image and the detection frame. In a &#x201c;Detection Frame Settings&#x201d; field indicated by (4), the temperature threshold value is set. In an email setting field indicated by (5), an email address of a notification destination is set. A camera image setting field indicated by (6) is provided to change a display mode of the color image to a desired mode. For example, in the camera setting filed, the temperature range is set to a desired range such as from 20&#xb0; C. to 300&#xb0; C. Further, for example, in the camera setting field, a setting is configured of filling one or more cells in the detection frame with red when any abnormality is detected in the corresponding cell(s) and making no change to other cells. The values set in the setting buttons (1) to (6) are examples of a parameter.</p><p id="p-0073" num="0073">Referring again to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, in step S<b>7</b>, the processing unit <b>101</b> displays, for example, a grid name, a temperature, a threshold value, and a time in each of the cells (grids) in the detection frame as illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. The frame name is a name of each frame such as Gl. G is an abbreviation for grid. When the grid name, temperature, threshold value, and time change, the processing unit <b>101</b> sequentially updates the information in the detection frame.</p><p id="p-0074" num="0074">In step S<b>8</b>, when the processing unit <b>101</b> determines, for example in a process of step S<b>20</b> (described below), that the alert flag becomes true (=1) because the temperature corresponding to one of the cells exceeds the threshold value, the processing unit <b>101</b> changes the color of corresponding cell of the detection frame from blue to red, for example (step S<b>9</b>). In other words, among the plural cells, a portion where the temperature reaches an abnormal temperature is highlighted.</p><p id="p-0075" num="0075">Further, the processing unit <b>101</b> stores a still image including the GUI screen and the color image at a time when the color of the cell changes in a storage folder (step S<b>10</b>), and the notification control unit <b>704</b> transmits an alert email to which the still image is attached to a desired email address (step S<b>11</b>). The storage folder is generated in the storage unit <b>103</b>, for example. Therefore, the storage unit <b>103</b> is an example of a storage unit configured to store the color image.</p><p id="p-0076" num="0076">Next, in steps S<b>12</b> to S<b>17</b>, the processing unit <b>101</b> divides the temperature imaging data (e.g., data constituted as pixels of horizontal 80&#xd7;vertical 60) into a submatrix of horizontal 10&#xd7;vertical 10, that is, divides the color image to a submatrix (see <figref idref="DRAWINGS">FIG. <b>13</b></figref>). Thus, a matrix of an N/10&#xd7;M/10 for each of submatrices is generated. N and M are integers of 1 or more. The processing unit <b>101</b> processes the submatrix data of the divided temperature imaging data in order, to calculate an average temperature value from all temperature pixels in the submatrix (see <figref idref="DRAWINGS">FIG. <b>13</b></figref>), and performs noise processing. The noise processing is performed to eliminate sudden abnormalities.</p><p id="p-0077" num="0077">When the program is already activated (step S<b>18</b>: YES), the processing unit <b>101</b> registers the temperature imaging data as a threshold value (step S<b>19</b>).</p><p id="p-0078" num="0078">Further, the processing unit <b>101</b> compares the calculated average temperature value with the threshold value, and when the comparison result indicates that the average temperature value exceeds the threshold value (step S<b>20</b>: YES), the processing unit <b>101</b> turns on the alert flag (step S<b>21</b>).</p><p id="p-0079" num="0079">Finally, the processing unit <b>101</b> stores the calculated average temperature value in a CSV format (see <figref idref="DRAWINGS">FIG. <b>13</b></figref>) in the storage folder (step S<b>22</b>).</p><p id="p-0080" num="0080">Although the description given above is of an example of the operation in which the detection frame is drawn on the color image, the embodiment is not limited thereto. In another example, the detection frame is drawn on the RGB image. Hereinafter, a description is given of an example of operation in which the detection frame is drawn on the RGB image, with reference to <figref idref="DRAWINGS">FIGS. <b>14</b>A and <b>14</b>B</figref> to <figref idref="DRAWINGS">FIG. <b>16</b></figref>. In the following, the description of processes that are the same or substantially the same as the processes described with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref> is omitted, and processes different from the processes described with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref> are described.</p><p id="p-0081" num="0081"><figref idref="DRAWINGS">FIGS. <b>14</b>A and <b>14</b>B</figref> are flowcharts illustrating an example of operation, according to a variation. <figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram illustrating an example of an RGB image displayed on the GUI screen. <figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram illustrating a state in which the detection frame is superimposed on the RGB image on the GUI screen.</p><p id="p-0082" num="0082">For example, before step S<b>1</b>, when the processing unit <b>101</b> acquires the RGB imaging data from the camera <b>1</b>, the processing unit <b>101</b> converts the RGB imaging data into an RGB image (step S<b>31</b>). The processing unit <b>101</b> displays the RGB image on the GUI screen as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, and further draws the detection frame on the RGB image as illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref> (step S<b>36</b>).</p><p id="p-0083" num="0083">Note that in one example, the process of converting the RGB imaging data into the RGB image is performed in step S<b>2</b>. In another example, such process is performed after a conversion process into color pixels (e.g., step S<b>36</b>). Further, in one example, the processing unit <b>101</b> stores the RGB image together with the color image in the memory, and when the RGB images correspond to a predetermined time period are accumulated, stores a moving image file in a desired storage folder. This enables an operator to identify a cause of the abnormality by checking a clear moving image as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref> without difficulty.</p><p id="p-0084" num="0084">In step S<b>37</b>, the processing unit <b>101</b> displays, for example, a grid name, a temperature, a threshold value, and a time in each of the cells (grids) in the detection frame.</p><p id="p-0085" num="0085">Next, in steps S<b>12</b> to S<b>17</b>, the processing unit <b>101</b> divides the temperature imaging data into a submatrix of horizontal 10&#xd7;vertical 10. Thus, a matrix of an M/10&#xd7;N/10 for each of submatrices is generated. M and N are integers of 1 or more. The processing unit <b>101</b> processes the submatrix data of the divided temperature imaging data in order, to calculate a representative value from all temperature pixels in the submatrix, and performs noise processing.</p><p id="p-0086" num="0086">The processing unit <b>101</b> stores the calculated representative value of pixels in the memory until a predetermined time period elapses after the program is activated. Thereby, the processing unit <b>101</b> calculates the representative value from the temperature imaging data corresponding to a predetermined time period and registers the calculated representative value as a threshold value (steps S<b>18</b> to S<b>19</b>).</p><p id="p-0087" num="0087">Thereafter, the processing unit <b>101</b> clears data in the memory (step S<b>50</b>), and when an external temperature change occurs due to air temperature or seasonal fluctuation, updates the threshold value to reflect such change to set the updated threshold value as a new threshold value (step S<b>51</b>).</p><p id="p-0088" num="0088">The processing unit <b>101</b> compares the calculated average temperature value with the threshold value, and when the comparison result indicates that the average temperature value is out of the threshold value, the processing unit <b>101</b> turns on the alert flag (step S<b>21</b>). The processing unit <b>101</b> stores the average temperature value that is calculated most recently as a file in the storage folder (step S<b>52</b>).</p><p id="p-0089" num="0089"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a diagram illustrating an example of display of a graph indicating a tendency of temperature change. The graph illustrated in <figref idref="DRAWINGS">FIG. <b>17</b></figref> is displayed, for example, in response to selection of a desired one of the plural cells (grids) illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, and represents a transition of the temperature in each cell in a chronological order. The graph plots temperatures measured at regular intervals such as every several seconds or every several minutes. By using this graph, the temperature change tendency (temperature change trend) in each grid is checked.</p><p id="p-0090" num="0090">Further, in one example, when the operator clicks a bar displayed corresponding to a time when the temperature exceeds the threshold value, the image file (at least one of the moving image file and the still image file) imaged at the corresponding time is reproduced, or the alert history is displayed. In another example, when desired two or more cells are collectively selected in the plural cells (grids) illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, a graph indicating an average value of the temperatures of the selected cells is displayed.</p><p id="p-0091" num="0091">As described heretofore, the information processing apparatus <b>100</b> according to the present embodiment includes a color image display unit configured to generate a color image of a monitoring area including a monitoring target and a surrounding area of the monitoring target, based on imaging data output from an imaging unit configured to take an image of the monitoring area, and display the generated color image on a display unit. The information processing apparatus <b>100</b> according to the present embodiment further includes a detection frame display unit configured to generate a detection frame constituted as plural cells for detecting a temperature of the monitoring area based on the imaging data, and display the generated detection frame as being superimposed on the color image on the display unit. The information processing apparatus <b>100</b> according to the present embodiment further includes a temperature display unit to display a temperature in each of the plural cells. Examples of the display unit include, but are not limited to, a the display device <b>102</b> and a monitor of the external device <b>200</b>.</p><p id="p-0092" num="0092">With this configuration, based the imaging data obtained by imaging the monitoring area <b>1</b><i>a </i>including the monitoring target <b>301</b> and the surrounding area <b>302</b>, the detection frame <b>20</b> is displayed as being superimposed on the color image <b>10</b> of the monitoring area <b>1</b><i>a </i>on the display device, and at least the temperature in the monitoring area <b>1</b><i>a </i>is displayed in the cells of the detection frame <b>20</b>. Thus, even in a case where the monitoring area <b>1</b><i>a </i>as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> and <figref idref="DRAWINGS">FIG. <b>4</b></figref> is set, when sparks or the like produced from the monitoring target <b>301</b> leaps to equipment existing around the monitoring target <b>301</b>, a temperature of the equipment is monitored. Further, even when a heat source (e.g., a person or a mobile device) approaches the monitoring target <b>301</b>, in a case where there is no abnormality in the monitoring target <b>301</b>, a temperature abnormality of the monitoring target <b>301</b> caused by the heat source is not erroneously detected. Therefore, the temperature of the monitoring target <b>301</b> is appropriately detected while suppressing erroneous detection of the temperature abnormality of the monitoring target <b>301</b> caused by a heat source other than the monitoring target <b>301</b>.</p><p id="p-0093" num="0093">Furthermore, according to the information processing apparatus <b>100</b>, a detection area (detection frame) provided in the entire color image makes the most merits of a feature of a thermal image sensor (camera <b>1</b>) capable of capturing a temperature in a wide range.</p><p id="p-0094" num="0094">Further, recording a moving image makes the most merits of a feature of visualizing the temperature of the thermal image sensor. In the background, since only an image when a temperature exceeds a threshold temperature is saved, it is not possible to check a situation corresponding to a certain time period before and after a fire occurrence of the monitoring target <b>301</b>. The information processing apparatus <b>100</b> according to the present embodiment enables to check a state of the monitoring target <b>301</b> in detail, thereby for example, enabling to determine whether the cause of the fire of the monitoring target <b>301</b> is due to an abnormality of equipment existing in the vicinity of the monitoring target or an abnormality of the monitoring target <b>301</b> itself. Furthermore, compared with a graph of a temperature imaging data, the moving image makes it easier to recognize the tendency and cause of abnormal temperature.</p><p id="p-0095" num="0095">Further, according to the present embodiment, a change in temperature at any position is supported, provided that the change occurs within the angle of view of the camera <b>1</b>. Therefore, during a time period when the system is in operation, the temperature imaging data and the visualized image of the thermal image sensor is saved for each area, thereby the abnormal tendency is analyzed based on the temperature imaging data before and after the notification process by the information processing apparatus <b>100</b>.</p><p id="p-0096" num="0096">The way how to generate the detection frame is not particularly limited. For example, the detection frame is generated by matrix data. Alternatively, for example, the detection frame is expressed by a wire frame.</p><p id="p-0097" num="0097">Further, in one example, the information processing apparatus <b>100</b> automatically restarts when a certain time period has elapsed after the generation of the color image is stopped. This enables continuous monitoring while maintaining the real-time feature of image generation, even when the generation of the color image is temporarily stopped.</p><p id="p-0098" num="0098">Furthermore, the thermographic camera <b>605</b> and the RGB camera <b>606</b> sometimes different angles of view from each other. Therefore, preferably, in superimposing the detection frame on the color image or the RGB image, the information processing apparatus <b>100</b> corrects the angles of view of the thermographic camera <b>605</b> and the RGB camera <b>606</b>, and superimposes the detection frame on the color image or the RGB image whose angles of view are corrected.</p><p id="p-0099" num="0099">The information processing system according to the present embodiment includes the information processing apparatus <b>100</b> and the camera <b>1</b> as the imaging unit.</p><p id="p-0100" num="0100">An information processing method performed by an information processing apparatus according to the present embodiment includes a receiving step of receiving imaging data output from an imaging device. The information processing method further includes a processing step of generating a color image based on the received imaging data and controlling a display device to display the generated color image. The processing step includes generating a detection frame constituted as plural regions based on the imaging data, controlling the display device to display the generated detection frame as being superimposed on the color image, and displaying a temperature for each of the plural regions.</p><p id="p-0101" num="0101">A program according to the present embodiment causes a computer to perform a receiving step of receiving imaging data output from an imaging device. The program further causes the computer to perform a processing step of generating a color image based on the received imaging data and controlling a display device to display the generated color image. The processing step includes generating a detection frame constituted as plural regions based on the imaging data, controlling the display device to display the generated detection frame as being superimposed on the color image, and displaying a temperature for each of the plural regions.</p><p id="p-0102" num="0102">The above-described embodiments are illustrative and do not limit the present invention. Thus, numerous additional modifications and variations are possible in light of the above teachings. For example, elements and/or features of different illustrative embodiments may be combined with each other and/or substituted for each other within the scope of the present invention.</p><p id="p-0103" num="0103">The present invention can be implemented in any convenient form, for example using dedicated hardware, or a mixture of dedicated hardware and software. The present invention may be implemented as computer software implemented by one or more networked processing apparatuses. The processing apparatuses include any suitably programmed apparatuses such as a general purpose computer, personal digital assistant, mobile telephone (such as a WAP or 3G-compliant phone) and so on. Since the present invention can be implemented as software, each and every aspect of the present invention thus encompasses computer software implementable on a programmable device. The computer software can be provided to the programmable device using any conventional carrier medium (carrier means). The carrier medium includes a transient carrier medium such as an electrical, optical, microwave, acoustic or radio frequency signal carrying the computer code. An example of such a transient medium is a TCP/IP signal carrying computer code over an IP network, such as the Internet. The carrier medium also includes a storage medium for storing processor readable code such as a floppy disk, hard disk, CD ROM, magnetic tape device or solid state memory device.</p><p id="p-0104" num="0104">Each of the functions of the described embodiments may be implemented by one or more processing circuits or circuitry. Processing circuitry includes a programmed processor, as a processor includes circuitry. A processing circuit also includes devices such as an application specific integrated circuit (ASIC), a digital signal processor (DSP), a field programmable gate array (FPGA), and conventional circuit components arranged to perform the recited functions.</p><p id="p-0105" num="0105">This patent application is based on and claims priority to Japanese Patent Application No. 2020-001631, filed on Jan. 8, 2020, in the Japan Patent Office, the entire disclosure of which is incorporated herein by reference.</p><heading id="h-0011" level="1">REFERENCE SIGNS LIST</heading><p id="p-0106" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0106"><b>1</b> Camera</li>    <li id="ul0002-0002" num="0107"><b>1</b><i>a </i>Monitoring area</li>    <li id="ul0002-0003" num="0108"><b>10</b> Color image</li>    <li id="ul0002-0004" num="0109"><b>20</b> Detection Frame</li>    <li id="ul0002-0005" num="0110"><b>100</b> Information processing apparatus</li>    <li id="ul0002-0006" num="0111"><b>101</b> Processing unit</li>    <li id="ul0002-0007" num="0112"><b>102</b> Display device</li>    <li id="ul0002-0008" num="0113"><b>300</b> Device</li>    <li id="ul0002-0009" num="0114"><b>301</b> Monitoring target</li>    <li id="ul0002-0010" num="0115"><b>301</b><i>a </i>Color image</li>    <li id="ul0002-0011" num="0116"><b>302</b> Surrounding area</li>    <li id="ul0002-0012" num="0117"><b>302</b><i>a </i>Color image</li>    <li id="ul0002-0013" num="0118"><b>605</b> Thermographic camera</li>    <li id="ul0002-0014" num="0119"><b>703</b> Detection unit</li>    <li id="ul0002-0015" num="0120"><b>704</b> Notification control unit</li>    <li id="ul0002-0016" num="0121"><b>707</b> Display control unit</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An information processing apparatus, comprising:<claim-text>an information receiver configured to receive imaging data; and</claim-text><claim-text>processing circuitry configured to generate a color image based on the received imaging data and control a display to display the generated color image,</claim-text><claim-text>wherein the processing circuitry generates a detection frame including plural regions based on the imaging data, controls the display to display the generated detection frame as being superimposed on the color image, and displays a temperature for each of the plural regions.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The information processing apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a memory to store a plurality of the color images, wherein:<claim-text>the processing circuitry controls the display to display a moving image based on the plurality of the color images stored in the memory.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The information processing apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the processing circuitry controls the display to display a graphical user interface (GUI) that receives an instruction for changing a parameter.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The information processing apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the processing circuitry displays a threshold value based on which the temperature is checked in each of the plural regions.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The information processing apparatus of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:<claim-text>the threshold value is a value having a certain range from an upper limit value to a lower limit value, and</claim-text><claim-text>the information processing apparatus further includes notification control circuitry configured to, in any one of cases where the temperature exceeds the upper limit value and where the temperature is less than the lower limit value, notify that the temperature exceeds the threshold value.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The information processing apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein:<claim-text>the notification control circuitry transmits an email containing the color image, to notify that the temperature exceeds the threshold value.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The information processing apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein:<claim-text>the notification control circuitry notifies an external device that the temperature exceeds the threshold value.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The information processing apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>among the plural regions, a portion where the temperature reaches an abnormal temperature is highlighted.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The information processing apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the information processing apparatus automatically restarts when a certain time period elapses after generation of the color image is stopped.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. An information processing system comprising:<claim-text>the information processing apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>;</claim-text><claim-text>an imaging device which outputs the imaging data; and</claim-text><claim-text>the display.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An information processing method, comprising:<claim-text>receiving imaging data;</claim-text><claim-text>generating a color image based on the received imaging data;</claim-text><claim-text>controlling a display to display the generated color image;</claim-text><claim-text>generating a detection frame including plural regions based on the imaging data;</claim-text><claim-text>controlling the display to display the generated detection frame as being superimposed on the color image; and</claim-text><claim-text>displaying a temperature for each of the plural regions.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A non-transitory computer readable storage medium storing a program for causing a computer to perform a method comprising:<claim-text>receiving imaging data output;</claim-text><claim-text>generating a color image based on the received imaging data;</claim-text><claim-text>controlling a display to display the generated color image;</claim-text><claim-text>generating a detection frame including plural regions based on the imaging data;</claim-text><claim-text>controlling the display to display the generated detection frame as being superimposed on the color image; and</claim-text><claim-text>displaying a temperature for each of the plural regions.</claim-text></claim-text></claim></claims></us-patent-application>
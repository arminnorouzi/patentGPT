<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004565A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004565</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17781495</doc-number><date>20210603</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>TR</country><doc-number>2020/09944</doc-number><date>20200625</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>2455</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>957</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>24552</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>9574</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">A CACHE UPDATING SYSTEM AND A METHOD THEREOF</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Loodos Bilisim Teknolojileri San. Ve Tic. Ltd. Sti.</orgname><address><city>Sariyer/lstanbul</city><country>TR</country></address></addressbook><residence><country>TR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>CETINER</last-name><first-name>Emrah</first-name><address><city>Sariyer/lstanbul</city><country>TR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>ERDEMIR</last-name><first-name>Kaan</first-name><address><city>Sariyer/lstanbul</city><country>TR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Loodos Bilisim Teknolojileri San. Ve Tic. Ltd. Sti.</orgname><role>03</role><address><city>Sariyer/lstanbul</city><country>TR</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/TR2021/050532</doc-number><date>20210603</date></document-id><us-371c12-date><date>20220601</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present invention relates to an asynchronous cache updating system and a method thereof, wherein the problems of repeatedly retrieving data from the main data source as data in cache systems is deleted after a certain period of time and being able to retrieve cached data only in the second and the subsequent requests are eliminated. The present invention particularly relates to a cache updating system and a method thereof that allows for changing cached data over time without using it and without expecting a request from the user and for updating data stored on the cache systems independently of the validity period of the data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="170.43mm" wi="120.99mm" file="US20230004565A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="187.03mm" wi="123.02mm" file="US20230004565A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="111.68mm" wi="172.97mm" file="US20230004565A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD OF THE INVENTION</heading><p id="p-0002" num="0001">The present invention relates to an asynchronous cache updating system and a method thereof, wherein the problems of repeatedly retrieving data from the main data source as data in cache systems are deleted after a certain period of time and being able to retrieve cached data only in the second and the subsequent requests are eliminated.</p><p id="p-0003" num="0002">The present invention particularly relates to a cache updating system and a method thereof that allows for changing cached data over time without using it and without expecting a request from the user and for updating data stored on cache systems independently of the validity period of the data.</p><heading id="h-0002" level="1">STATE OF THE ART</heading><p id="p-0004" num="0003">A cache is a high-speed data storage layer that stores a temporary data subset. In other words, a cache refers to temporarily storing a web page loaded in a browser or an application and data to be retrieved from the Internet. Thus, less bandwidth is used, and fewer requests are sent to the server when the said web page is visited once again. This improves the user experience.</p><p id="p-0005" num="0004">Data in a cache is usually stored in hardware such as Random-Access Memory (RAM) and may require establishing a connection over software in order to access data. There are two types of caches in general. Those are server-side caching and browser-side caching.</p><p id="p-0006" num="0005">Browser-side caching is performed when you try to load a website twice. The respective website collects data in order to load the page on your first try. After downloading the data, the browser serves as temporary storage in order to keep the data. Server-side caching is very similar to browser-side caching. The difference between these two is that the server is temporary storage. A server-side cache is capable of storing more data.</p><p id="p-0007" num="0006">There are many cache systems available since server-side caching uses a server to store the web browser. Said systems may be categorized as full-page caching, object caching, and fragment caching.</p><p id="p-0008" num="0007">Data kept in cache systems is a copy of the original data. Therefore, it will be an invalid piece of information when the data is changed on the main source. In that case, the program utilizing the respective data on the cache will end up performing wrong operations if the corresponding data is not updated.</p><p id="p-0009" num="0008">For this problem, cached data gets deleted after a certain period of time and the respective data must be retrieved once again from the main data source. Consequently, a validity period is determined for the cached data. The existence of validity periods in caching systems ensures that said systems are refreshed at specific intervals.</p><p id="p-0010" num="0009">In addition, cache systems are developed with an architecture that will be formed by data requests of end-users over sources. In other words, a caching system does not contain any data in the beginning. However, when a user requests data, the system reads the corresponding data from the main source and saves it to the caching system. A high-performance response is offered by reading the corresponding data from the caching system only in the second and the subsequent requests. This occurs repeatedly when the validity period of the cached data is expired.</p><p id="p-0011" num="0010">The patent document numbered &#x201c;TR2020/03451&#x201d; was examined as a result of the preliminary search conducted in the state of the art. The abstract of the said invention described in the aforementioned patent application discloses; &#x201c; Method for providing a content part of a multimedia content to a client terminal, corresponding cache. According to the invention, the method for providing a content part of multimedia content to a client terminal, one or more caches being arranged along the transmission path between the client terminal and a remote server, several representations of the said content part being available, comprises:&#x2014;receiving (S0) at the first cache (R), from the client terminal, a request for a given representation of the said content part belonging to a set of allowable representations selected among said available representations of the content part, said request further comprising a list of alternative representations of the set and auxiliary information for specifying the scope of the request;&#x2014;checking (S1) at the said first cache (R) if said given representation is stored in the cache;&#x2014;in case the said given representation is not cached, browsing (S2) at the said first cache (R) alternative representations listed.&#x201d;</p><p id="p-0012" num="0011">The patent document numbered &#x201c;TR 2014/11526&#x201d; was examined as a result of the preliminary search conducted in the state of the art. The abstract of the said invention that is described in the aforementioned patent application discloses; A system and method for management and processing of resource requests at cache server computing devices are provided. Cache server computing devices segment content into an initialization fragment for storage in memory and one or more remaining fragments for storage in a media having higher latency than the memory. Upon receipt of a request for the content, a cache server computing device transmits the initialization fragment from the memory, retrieves the one or more remaining fragments, and transmits the one or more remaining fragments without retaining the one or more remaining fragments in the memory for subsequent processing.&#x201d;</p><p id="p-0013" num="0012">The patent document numbered &#x201c;US20190220530A1&#x201d; was examined as a result of the preliminary search conducted in the state of the art. The invention described in the said patent application discloses a computer software media that is developed for asynchronously tracking the changes in web or database objects for the client-side web caching by using an application server. Said invention provides asynchronous cache management in order to reduce the network overhead caused by the increase in the number of users.</p><p id="p-0014" num="0013">The patent document numbered &#x201c;CA2664270A1&#x201d; was examined as a result of the preliminary search conducted in the state of the art. The invention described in the aforementioned application discloses a method for managing networks wherein the said method allows asynchronous transmission of the data content and optimization of the network for the content transmissions that are initiated within a limited period of time. Said invention reduces the asynchronous delivery of the data content, e.g. mobile TV content, asynchronous sample, or the number of transmissions of the data content, and optimizes the network for the content transmissions that are initiated within a limited period of time. While the synchronized transmission is stored in the cache in the said method, it is stated that this must be consumed first.</p><p id="p-0015" num="0014">The patent document numbered &#x201c;US10523746B2&#x201d; was examined as a result of the preliminary search conducted in the state of the art. The invention described in said patent application discloses a system and method that supports the coexistence of an asynchronous architecture and a synchronous architecture in the same server. Said invention comprises an application programming interface (API) that enables each thread in the keep-alive subsystem on the server to manage multiple connections simultaneously.</p><p id="p-0016" num="0015">The patent document numbered &#x201c;US9674258B2&#x201d; was examined as a result of the preliminary search conducted in the state of the art. The invention described in said patent application discloses a system and method developed for optimizing websites. In said invention, the TPS achieves a significant reduction in the number of resources requested and the amount of the bytes needed for each resource, as the optimizer configures the optimization settings and applies settings to redirect HTTP requests and responses.</p><p id="p-0017" num="0016">The patent document numbered &#x201c;US8689052B2&#x201d; was examined as a result of the preliminary search conducted in the state of the art. The invention described in said patent application discloses a system that enables an asynchronous operation to a database of the online services system or a server by providing a framework or infrastructure that allows for the development of an application to test the functionality of an application. The method disclosed in the said invention enables an asynchronous operation call or send requests to a database or a database server of the online services system by providing a framework or infrastructure that allows for the development of a software application to test the functionality of another software application.</p><p id="p-0018" num="0017">In the caching systems used in the state of the art, the major disadvantage in platforms visited by users over the Internet is the insufficiency of the available hardware and software resources.</p><p id="p-0019" num="0018">In cache systems used in the state of the art, operations cannot be performed without expecting a request from the user. Cached data is retrieved only after receiving a trigger request from the user.</p><p id="p-0020" num="0019">In the caching methods used in the state of the art, updating is performed depending on the validity period of the data kept at the caching systems.</p><p id="p-0021" num="0020">In the caching systems used in the state of the art, addressing is performed by using unique keys in order to access the correct data since accessing cached data more than once may be required.</p><p id="p-0022" num="0021">Consequently, the aforementioned disadvantages, as well as the inadequacy of the available solutions in this regard necessitated making an improvement in the relevant technical field.</p><heading id="h-0003" level="1">OBJECTS OF THE INVENTION</heading><p id="p-0023" num="0022">The most important object of the present invention is to provide a solution to problems in which data is required to be retrieved from the main data source as the data in cache systems is deleted after a certain period of time, and cached data may be retrieved in the second and the subsequent requests only.</p><p id="p-0024" num="0023">Another object of the present invention is to ensure that the data kept on the cache systems may be updated independently of the validity period of the data by means of the asynchronous cache updating feature.</p><p id="p-0025" num="0024">Another object of the present invention is to ensure that the data on the cache system may be retrieved from the main source and updated when the system resources are consumed. Thus, the data of users that is changed on the main source can remain up-to-date all the time on the cache systems.</p><p id="p-0026" num="0025">Yet another object of the present invention is to ensure that the data on the cache system may be created without the user request and may be read in the first request of the user rather than the second and the subsequent requests since the data is updateable and to ensure that the data can be responded to the user with high performance.</p><p id="p-0027" num="0026">Yet another object of the present invention is to ensure that users may get a quick response and use the applications faster since end-users can receive the data over the cache system at the initial request they made.</p><p id="p-0028" num="0027">Yet another object of the present invention is to ensure that the traffic to the servers in which the main data is stored, is controlled in a better way.</p><p id="p-0029" num="0028">Yet another object of the present invention is to ensure that the servers may be run by using less hardware since the system resources on servers are utilized to update the cached data even when the system resources are not available for such task.</p><p id="p-0030" num="0029">Another object of the present invention is to manage the process of requesting and receiving a single piece of data (temporal) asynchronously.</p><p id="p-0031" num="0030">Another object of the present invention is to ensure that asynchronous caching may be performed by means of software architecture without the users visiting.</p><p id="p-0032" num="0031">Another object of the present invention is to ensure that the server provides efficient service by means of shifting the operations to be performed when the server is too busy to a period of time when the said server is free.</p><p id="p-0033" num="0032">Another object of the present invention is to perform the asynchronous operation requests automatically based on the user behaviour predictions.</p><p id="p-0034" num="0033">Another object of the invention is to ensure that operations may be performed over a single system owing to the fact that evaluating the target application performance is not required.</p><p id="p-0035" num="0034">Structural and characteristic features and all advantages of the present invention will be understood more clearly by means of the figures given below and the detailed description written by referring to those figures. Therefore, the evaluation should be conducted by taking those figures and the detailed description into consideration.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">DESCRIPTION OF THE FIGURES</heading><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>1</b></figref>; illustrates the elements of the inventive cache updating system.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>2</b></figref>; illustrates the flow chart of the operation method of the inventive cache updating system.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">REFERENCE NUMERALS</heading><p id="p-0038" num="0037">1. Application</p><p id="p-0039" num="0038">2. Application Programming Interface Gateway</p><p id="p-0040" num="0039">3. Microservices</p><p id="p-0041" num="0040">4. Microservice Database</p><p id="p-0042" num="0041">5. Cache System</p><p id="p-0043" num="0042">6. Cache Updating Module<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0043">100. Reading the configuration file in the cache updating module.</li>        <li id="ul0002-0002" num="0044">101. Determining which cache value is updated asynchronously by means of the cache updating module.</li>        <li id="ul0002-0003" num="0045">102. Retrieving the updated data over related microservice by means of the cache updating module.</li>        <li id="ul0002-0004" num="0046">103. Transmitting the retrieved updated data to the cache system.</li>        <li id="ul0002-0005" num="0047">1001. Sending a request to the cache system in order to retrieve data from the application.</li>        <li id="ul0002-0006" num="0048">1002. Receiving all data incoming from the application by means of the application programming interface gateway.</li>        <li id="ul0002-0007" num="0049">1003. Controlling if there is data on the cache system.</li>        <li id="ul0002-0008" num="0050">1004. Controlling the validity period of the cached data by means of the cache updating module.</li>        <li id="ul0002-0009" num="0051">1005. Sending data with an ongoing validity period to the web application by retrieving the said data over the cache system.</li>        <li id="ul0002-0010" num="0052">1006. Discarding the data with an expired validity period from the cache system.</li>        <li id="ul0002-0011" num="0053">1007. Transmitting the request to the related microservice in case there is no data on the cache system.</li>        <li id="ul0002-0012" num="0054">1008. Retrieving the data requested from the microservice database by means of the cache updating module.</li>    </ul>    </li></ul></p><heading id="h-0006" level="1">DESCRIPTION OF THE INVENTION</heading><p id="p-0044" num="0055">The necessary information is retrieved from the server and added to the cache (especially when the system is not too busy) by means of predicting the operation to be performed before the system is used by a single user or many users having a certain predicted profile. Thus, asynchronous caching is performed via cache updating module (<b>6</b>) without any user request.</p><p id="p-0045" num="0056">End-users may use the applications (<b>1</b>) faster and get a quick response since said users can receive the data over the cache system (<b>5</b>) at the initial request they made by means of the inventive system and the method.</p><p id="p-0046" num="0057">The present invention comprises an application (<b>1</b>), an application programming interface gateway (<b>2</b>), microservices (<b>3</b>), a microservice database (<b>4</b>), a cache system (<b>5</b>), and a cache updating module (<b>6</b>).</p><p id="p-0047" num="0058">Application (<b>1</b>) allows for displaying data to be retrieved by means of sending HTTP requests to the application programming interface gateway (<b>2</b>). HTTP requests allow for retrieving data from mobile/web applications (<b>1</b>). Said application (<b>1</b>) can work on one of many popular platforms such as web, mobile, desktop, computer, smart device, wearable device, etc. as well as the Internet of Things (IoT) devices.</p><p id="p-0048" num="0059">The application programming interface gateway (<b>2</b>), also called API Gateway, functions as a bridge between Application (<b>1</b>) and microservices (<b>3</b>). Said API gateway (<b>2</b>) directs the request it is receiving from its applications (<b>1</b>) to the related microservice (<b>3</b>). Application programming interface gateway (<b>2</b>) controls whether the responses of the related requests are available on the cache system (<b>5</b>). The application programming interface gateway (<b>2</b>) ensures that the data is retrieved from the cache system (<b>5</b>) and communicated to the web application in case the data has been previously added to the cache system (<b>5</b>) and its life cycle had not expired.</p><p id="p-0049" num="0060">Microservices (<b>3</b>) are the service architecture with limited areas of task and responsibility that are capable of performing only one task with all details thereof.</p><p id="p-0050" num="0061">The microservice database (<b>4</b>) is a database in which the data of microservices (<b>3</b>) are stored. Additionally, there is a main data source. The main data source refers to a medium in which the data is maintained and served. Data on said medium is always up to date.</p><p id="p-0051" num="0062">Cache System (<b>5</b>) ensures that the data on the cache system is updated by means of the cache updating module (<b>6</b>) by retrieving data over the main source when the system resources are consumed and new data generated at the main source. Thus, the user data that has changed on the main source can always remain up to date on the cache system (<b>5</b>).</p><p id="p-0052" num="0063">The cache updating module (<b>6</b>) ensures that the data is retrieved from the respective microservice (<b>3</b>) independently of the applications (<b>1</b>) and that the cache system is continuously updated by writing said data on the cache system (<b>5</b>). The cache updating module (<b>6</b>) uses a method while performing the said operations and implements certain process steps during this method.</p><p id="p-0053" num="0064">These process steps can be summarized as follows; first, the configuration file in the cache updating module (<b>6</b>) is read (<b>100</b>). Cache updating module (<b>6</b>) determines (<b>101</b>) which cache value is updated asynchronously. The updated data is retrieved (<b>102</b>) by means of cache updating module (<b>6</b>) over the relevant microservice (<b>3</b>). Retrieved up-to-date data is transmitted (<b>103</b>) to the cache system (<b>5</b>).</p><p id="p-0054" num="0065">A set of process steps are also carried out while determining (<b>101</b>) which cache value is updated asynchronously by means of the cache updating module (<b>6</b>) and retrieving (<b>102</b>) updated data over the corresponding microservice (<b>3</b>) by means of the cache updating module (<b>6</b>).</p><p id="p-0055" num="0066">Herein, a request is sent (<b>1001</b>) to the cache system (<b>5</b>) in order to retrieve data from the applications (<b>1</b>). All data obtained from the application (<b>1</b>) are received (<b>1002</b>) by the application programming interface gateway (<b>2</b>). Cache updating module (<b>6</b>) controls (<b>1003</b>) whether there is data on the cache system (<b>5</b>). In case data is detected as a result of the said controlling operation, the validity period of the cached data is controlled (<b>1004</b>) by means of the cache update module (<b>6</b>). Data with an ongoing validity period is sent (<b>1005</b>) to the application (<b>1</b>) after being retrieved over the cache system (<b>5</b>). Expired data is discarded (<b>1006</b>) from the cache system (<b>5</b>). In case there is no data on the cache system (<b>5</b>) the request is transmitted (<b>1007</b>) to the relevant microservice (<b>3</b>). Data requested from the microservice database (<b>4</b>) is retrieved (<b>1008</b>) by means of the cache updating module (<b>6</b>).</p><p id="p-0056" num="0067">Data kept over the cache system (<b>5</b>) is deleted once its validity period is expired. Data is added to the cache system (<b>5</b>) after the new requests are being submitted to the server by the users. The cache updating module (<b>6</b>) analyzes those requests and the frequency thereof, and the data is cached without expecting requests from the users. There are two main approaches that are emphasized for the mentioned requests' analysis. These approaches are user-based approach and profile-based approach. The user-based approach involves making deductions for the future based on the predictions that are made on the basis of a user's previous requests, visits made in the application, times of the requests', and the visits'. For instance, the possibility of a user logging in the next Monday is taken into consideration for a user who wishes to learn the remaining data amount in its data plan every Monday via the application.</p><p id="p-0057" num="0068">The profile-based approach analyzes the requests of the users having certain profiles (age, gender, location, etc.) in the application and makes various predictions. For example, if it is assumed that men between the ages of <b>18</b> and <b>25</b> living in Istanbul request to learn their &#x201c;remaining data amount&#x201d; every morning, said requests will be pre-cached for all of the users that are categorized in this profile.</p><p id="p-0058" num="0069">The following method and process steps are carried out while the mentioned approaches are applied and analyzed by the cache update module (<b>6</b>). The cache updating module (<b>6</b>) performs caching as a result of the said process steps. Primarily, time groups are created at certain frequencies (for example, one group for every 24 hours). Each group will include 5 different sets. Said sets indicate the possibility of the login of a user at the respective time. Probability classes of the created sets are determined. These sets are classified as very high probability, high probability, moderate probability, low probability, and remote probability. Caching is performed according to the probability class. If it is highly likely for a user to log in at a specific time, then the necessary caching is performed accordingly. Similar patterns are created based on the time group set in which users of similar profiles use the system to be used in the profile-based approach, and the profiles are cached accordingly.</p><p id="p-0059" num="0070">It is assumed that user activities continue infinitely in user-based approaches. Accordingly, a machine learning model is developed in order to predict the next step of the user. Said model predicts the next step of the user in any case. Model updates itself periodically to predict the next step of the users.</p><p id="p-0060" num="0071">The present invention provides a solution to problems in which data is required to be retrieved from the main data source as the data in cache systems (<b>5</b>) is deleted after a certain period of time, and cached data may be retrieved in the second and the subsequent requests only. Thus, data can be read over the cache system (<b>5</b>) and the system can respond with high performance.</p><p id="p-0061" num="0072">The asynchronous cache updating module (<b>6</b>) ensures that the data kept on the cache systems (<b>5</b>) is updated independently of the validity period thereof.</p><p id="p-0062" num="0073">The inventive system ensures that the traffic to the servers in which the main data is maintained is controlled in a better, more efficient way. The present invention further ensures that servers may run with less hardware even during the periods in which system resources of the said servers are completely consumed since system resources would be used for updating the cache data.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. (canceled)</claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. A cache updating method that allows for updating data kept on the cache system (<b>5</b>) independently of the validity period of the data, characterized in that, it comprises the process steps of;<claim-text>reading (<b>100</b>) the configuration file in the cache updating module (<b>6</b>);</claim-text><claim-text>determining (<b>101</b>) which cache value is updated asynchronously by means of the cache updating module (<b>6</b>);</claim-text><claim-text>sending (<b>1001</b>) a request to the cache system (<b>5</b>) to pull data from the applications (<b>1</b>);</claim-text><claim-text>receiving (<b>1002</b>) all data from applications (<b>1</b>) by the application programming interface gateway (<b>2</b>);</claim-text><claim-text>controlling (<b>1003</b>) whether there is data on the cache system (<b>5</b>) by means of the cache updating module (<b>6</b>);</claim-text><claim-text>controlling (<b>1004</b>) the validity period of the cache data by means of the cache updating module (<b>6</b>) in case data is detected as a result of the control;</claim-text><claim-text>retrieving the data, whose validity period is still valid, over the cache system (<b>5</b>) and sending (<b>1005</b>) these to the applications (<b>1</b>);</claim-text><claim-text>discarding (<b>1006</b>) the expired data from the cache system (<b>5</b>);</claim-text><claim-text>transmitting (<b>1007</b>) the request to the related microservice (<b>3</b>) in case there is no data on the cache system (<b>5</b>);</claim-text><claim-text>retrieving (<b>1008</b>) data requested from microservice database (<b>4</b>) by means of the cache updating module (<b>6</b>);</claim-text><claim-text>transmitting (<b>103</b>) the retrieved updated data to the cache system (<b>5</b>).</claim-text></claim-text></claim><claim id="CLM-003-7" num="003-7"><claim-text><b>3</b>-<b>7</b>. (canceled)</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A cache updating method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, it comprises a deep machine learning model in order to predict the next step of the user.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A cache updating method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that, the analysis method of cache updating module (<b>6</b>) comprises the process steps of;<claim-text>Creating time groups at certain frequencies,</claim-text><claim-text>Creating sets that indicate the possibility of login of a plurality of users in the system at the respective time in each one of the groups,</claim-text><claim-text>Determining the probability categories of the created sets,</claim-text><claim-text>Performing the required caching according to the probability category of the user,</claim-text><claim-text>Creating similar patterns according to the set of time groups when users with similar profiles use the system and caching the profiles.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A cache updating method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, characterized in that, the sets of probability categories are very high probability, high probability, moderate probability, low probability, and remote probability.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. (canceled)</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A cache updating method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, characterized in that, the application (<b>1</b>) can be the Internet of Things (IoT) devices.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A cache updating method according to <claim-ref idref="CLM-00001">claim 1</claim-ref> or, characterized in that; platforms on which said application (<b>1</b>) runs on are web, mobile, desktop, computer, smart devices, wearable devices.</claim-text></claim></claims></us-patent-application>
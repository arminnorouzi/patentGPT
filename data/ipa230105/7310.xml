<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007311A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007311</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931450</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-048201</doc-number><date>20200318</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>89</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>124</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>89</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>124</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">IMAGE ENCODING DEVICE, IMAGE ENCODING METHOD AND STORAGE MEDIUM, IMAGE DECODING DEVICE, AND IMAGE DECODING METHOD AND STORAGE MEDIUM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/006754</doc-number><date>20210224</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17931450</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>CANON KABUSHIKI KAISHA</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Shima</last-name><first-name>Masato</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An image encoding device includes a prediction unit configured to generate prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image, a first transform unit configured to generate first transform coefficients by performing orthogonal transform on the prediction errors, a second transform unit configured to generate second transform coefficients by performing LFNST processing on the first transform coefficients, a quantization unit configured to generate quantization coefficients by performing quantization processing on the second transform coefficients, and an encoding unit configured to encode the quantization coefficients, wherein the encoding unit encodes information indicating whether a range of possible values at least taken by the second transform coefficients is to be a range determined based on a bit depth or a fixed range.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="104.14mm" wi="158.75mm" file="US20230007311A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="219.88mm" wi="146.90mm" orientation="landscape" file="US20230007311A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="236.39mm" wi="132.33mm" orientation="landscape" file="US20230007311A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="218.52mm" wi="116.33mm" file="US20230007311A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="177.63mm" wi="118.36mm" file="US20230007311A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="140.89mm" wi="101.52mm" file="US20230007311A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="197.70mm" wi="145.29mm" file="US20230007311A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="146.47mm" wi="141.05mm" file="US20230007311A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="174.92mm" wi="155.96mm" file="US20230007311A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a Continuation of International Patent Application No. PCT/JP2021/006754, filed Feb. 24, 2021, which claims the benefit of Japanese Patent Application No. 2020-048201, filed Mar. 18, 2020, both of which are hereby incorporated by reference herein in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><heading id="h-0003" level="1">Field of the Invention</heading><p id="p-0003" num="0002">The present invention relates to image encoding.</p><heading id="h-0004" level="1">Background Art</heading><p id="p-0004" num="0003">As an encoding scheme for compression recording of a moving image, there is known a High Efficiency Video Coding (HEVC) encoding scheme (hereinafter, written as HEVC). In the HEVC, a plurality of profiles that defines restrictions on encoding technology is defined, and a Main 10 profile supports an image of a bit depth ranging from 8 bits to 10 bits. In addition, in the HEVC, a profile supporting an image of 12 bits and an image of 16 bits is also defined to support an image of a higher bit depth as well. Japanese Patent Application Laid-Open No. 2014-131172 discusses an encoding technique that supports an image encoding scheme supporting such a high-bit depth.</p><p id="p-0005" num="0004">International standardization of a more efficient encoding scheme as a successor to the HEVC has recently been started. The Joint Video Experts Team (JVET) has been established by the ISO/IEC and the ITU-T, and standardization of a Versatile Video Coding (VVC) encoding scheme (hereinafter, VVC) has been underway. In the VVC, in order to improve encoding efficiency, a new technique of, in addition to performing conventional orthogonal transform, further performing secondary transform (LFNST, hereinafter referred to as low-frequency transform) on a low-frequency component of coefficients subjected to the orthogonal transform (hereinafter, written as orthogonal transform coefficients) has been also discussed.</p><heading id="h-0005" level="1">CITATION LIST</heading><heading id="h-0006" level="1">Patent Literature</heading><p id="p-0006" num="0005">PTL 1: Japanese Patent Application Laid-Open No. 2014-131172</p><heading id="h-0007" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0007" num="0006">In VVC, a limit is added to a value of a processing result in encoding processing such as orthogonal transform and quantization to increase the ease of implementation. Specifically, possible values for coefficients subjected to quantization processing (hereinafter, written as quantization coefficients) is limited to &#x2212;32768 to 32767, so that implementation of coefficient encoding processing and inverse-quantization processing on decoding side is made easier. It is considered that, in the VVC, the implementation cost of hardware will not be much increased even in a case where an image of a high-bit depth is encoded. Meanwhile, the above-described limit causes a reduction in arithmetic precision for, in particular, an image of a high-bit depth, so that an issue such as no improvement in image quality has arisen.</p><p id="p-0008" num="0007">To adaptively determine a range of possible values for coefficient values in encoding or decoding processing, an image encoding device according to the present invention includes, for example, the following configuration. That is, the image encoding device includes a prediction unit configured to generate prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image, a first transform unit configured to generate first transform coefficients by performing orthogonal transform on the prediction errors, a second transform unit configured to generate second transform coefficients by performing LFNST processing on the first transform coefficients, a quantization unit configured to generate quantization coefficients by performing quantization processing on the second transform coefficients, and an encoding unit configured to encode the quantization coefficients, wherein the encoding unit encodes information indicating whether a range of possible values at least taken by the second transform coefficients is to be a range determined based on a bit depth or a fixed range.</p><p id="p-0009" num="0008">Further, to solve the problem described above, an image decoding device according to the present invention includes, for example, the following configuration. That is, the image decoding device that decodes an image from an input bitstream includes a decoding unit configured to decode quantization coefficients from the bitstream, an inverse-quantization unit configured to derive first transform coefficients by performing inverse-quantization processing on the quantization coefficients, a first transform unit configured to derive second transform coefficients by performing inverse LFNST processing on the first transform coefficients, and a second transform unit configured to derive prediction errors by performing inverse orthogonal transform processing on the second transform coefficients, wherein the decoding unit decodes information indicating whether a range of possible values at least taken by the first transform coefficients is to be a range determined based on a bit depth or a fixed range, from the bitstream.</p><p id="p-0010" num="0009">Further, to solve the problem described above, an image encoding device according to the present invention includes, for example, the following configuration. That is, the image encoding device includes a prediction unit configured to generate prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image, and an encoding unit configured to encode the prediction errors, using at least BDPCM processing, wherein the encoding unit encodes information indicating whether a range of values obtained by at least the BDPCM processing is to be a range determined based on a bit depth or a fixed range.</p><p id="p-0011" num="0010">Further, to solve the problem described above, an image decoding device according to the present invention includes, for example, the following configuration. That is, the image decoding device that decodes an image from an input bitstream includes a decoding unit configured to decode quantization coefficients from the bitstream, and an inverse-quantization unit configured to derive prediction errors from the quantization coefficients, using at least BDPCM processing, wherein the decoding unit decodes information indicating whether a range of values obtained by at least the BDPCM processing is to be a range determined based on a bit depth or a fixed range, from the bitstream.</p><p id="p-0012" num="0011">Further features of the present invention will become apparent from the following description of exemplary embodiments with reference to the attached drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0008" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration of an image encoding device.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a configuration of an image decoding device.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating image encoding processing in the image encoding device.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating image decoding processing in the image decoding device.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating a computer hardware configuration.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a diagram illustrating an example of a bitstream structure generated by an encoding device and decoded by a decoding device.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is a diagram illustrating an example of a bitstream structure generated by an encoding device and decoded by a decoding device.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a diagram illustrating an example of subblock division.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a diagram illustrating an example of subblock division.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>7</b>C</figref> is a diagram illustrating an example of subblock division.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>7</b>D</figref> is a diagram illustrating an example of subblock division.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>7</b>E</figref> is a diagram illustrating an example of subblock division.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>7</b>F</figref> is a diagram illustrating an example of subblock division.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating a relationship among coefficient range information, a bit depth of an image, and a possible range of coefficients.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0009" level="1">DESCRIPTION OF THE EMBODIMENTS</heading><p id="p-0027" num="0026">Exemplary embodiments will be described in detail below with reference to the attached drawings. Configurations to be described in the following exemplary embodiments are only examples, and the present invention is not limited to the configurations illustrated in the drawings.</p><heading id="h-0010" level="1">First Exemplary Embodiment</heading><p id="p-0028" num="0027">A plurality of features is described in an exemplary embodiment, but all of these plurality of features may not be essential to the invention, and the plurality of features may be freely combined. Further, in the attached drawings, the same or similar configurations are assigned the same reference numerals, and the description thereof will not be repeated.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration of an image encoding device <b>100</b> according to the present exemplary embodiment. The image encoding device <b>100</b> includes a control unit <b>150</b> that controls the entire device. The control unit <b>150</b> includes a CPU, a ROM storing a program to be executed by the CPU, and a RAM to be used as a work area of the CPU. The image encoding device <b>100</b> further includes an input terminal <b>101</b>, a block division unit <b>102</b>, a coefficient range information generation unit <b>103</b>, a prediction unit <b>104</b>, a transform and quantization unit <b>105</b>, an inverse-quantization and inverse-transform unit <b>106</b>, an image reconstruction unit <b>107</b>, a frame memory <b>108</b>, an in-loop filter unit <b>109</b>, an encoding unit <b>110</b>, an integration encoding unit <b>111</b>, and an output terminal <b>112</b>.</p><p id="p-0030" num="0029">The input terminal <b>101</b> inputs image data to be encoded, frame by frame. The image data is acquired from an imaging device that captures an image, a file server, a storage medium or the like storing image data to be encoded, and such a source may be of any type. The output terminal <b>112</b> outputs encoded data to a destination device, and the destination device may also be of any type, such as a storage medium, a file server, or the like.</p><p id="p-0031" num="0030">The block division unit <b>102</b> divides an image of an input frame (picture) into a plurality of basic blocks, and sequentially outputs one of the blocks as a basic block to the prediction unit <b>104</b> in the subsequent stage. Further, for example, a block of 128&#xd7;128 pixels, a block of 64&#xd7;64 pixels, or a block of 3&#xd7;32 pixels may be used as a basic block. Further, a smaller block may be used as a basic block. Further, a basic block is, for example, a coding tree unit or a coding unit. A basic block may be any unit if the unit can be further divided into smaller subblocks.</p><p id="p-0032" num="0031">The coefficient range information generation unit <b>103</b> generates coefficient range information indicating a range of possible values for coefficient values that are a result of each encoding processing to be described below, and outputs the generated information to the transform and quantization unit <b>105</b>, the inverse-quantization and inverse-transform unit <b>106</b>, and the integration encoding unit <b>111</b> in the subsequent stages.</p><p id="p-0033" num="0032">The prediction unit <b>104</b> determines subblock division for image data in units of basic blocks. At this time, the prediction unit <b>104</b> determines whether to divide the basic block into subblocks, and determines how the basic block is to be divided if the basic block is to be divided. In a case where the basic block is not divided into subblocks, the size of a subblock is the same as that of the basic block. The subblock may be a square, and may be a rectangle other than the square.</p><p id="p-0034" num="0033">Subsequently, the prediction unit <b>104</b> generates predicted image data in units of subblocks by performing intra-prediction that is intra-frame prediction, inter-prediction that is inter-frame prediction, or the like. At this time, for example, the prediction unit <b>104</b> selects a prediction method to be performed for a certain subblock, from the intra-prediction, the inter-prediction, and a combination of the intra-prediction and the inter-prediction, and performs the selected prediction to generate predicted image data for the subblock.</p><p id="p-0035" num="0034">Further, the prediction unit <b>104</b> calculates prediction errors in units of pixels from the input image data and the predicted image data in units of subblocks, and outputs the calculated prediction errors. For example, the prediction unit <b>104</b> calculates a difference between each pixel value of the image data of the subblock and each pixel value of the predicted image data generated by the prediction for the subblock, and determines the calculated differences as the prediction errors.</p><p id="p-0036" num="0035">In addition, the prediction unit <b>104</b> outputs information necessary for the prediction, e.g., information indicating the subblock division (the state of the basic block divided into the subblocks) (i.e, information indicating how the basic block is divided into the subblocks), together with the prediction errors. The prediction unit <b>104</b> also outputs information such as a prediction mode and a motion vector used in the prediction of the subblock, together with the prediction errors. This information necessary for the prediction will be hereinafter referred to as prediction information.</p><p id="p-0037" num="0036">The transform and quantization unit <b>105</b> obtains orthogonal transform coefficients representing each frequency component of the prediction errors by orthogonally transforming the prediction errors input from the prediction unit <b>104</b> subblock by subblock. Further, the transform and quantization unit <b>105</b> determines whether to perform low-frequency transform on a low-frequency part of the orthogonal transform coefficients, and generates information about this determination as low-frequency transform information. In other words, the low-frequency transform information is information indicating whether to perform the low-frequency transform on the low-frequency part of the orthogonal transform coefficients. In a case where the low-frequency transform is to be performed on the subblock, the transform and quantization unit <b>105</b> obtains low-frequency transform coefficients by performing low-frequency transform processing on the low-frequency part of the obtained orthogonal transform coefficients, and further obtains residual coefficients (orthogonal transform coefficients subjected to quantization) by quantizing the low-frequency transform coefficients. On the other hand, in a case where the low-frequency transform is not to be performed on the subblock, the transform and quantization unit <b>105</b> obtains residual coefficients by quantizing the orthogonal transform coefficients. The low-frequency transform indicates low-frequency non-separable transform (LFNST) processing, and this is processing for reconstructing (deriving) low-frequency transform coefficients by transforming an orthogonal transform coefficients.</p><p id="p-0038" num="0037">The inverse-quantization and inverse-transform unit <b>106</b> receives the residual coefficients and the low-frequency transform information as input from the transform and quantization unit <b>105</b>, and reconstructs transform coefficients by inversely quantizing the residual coefficients. At this time, the inverse-quantization and inverse-transform unit <b>106</b> reconstructs the transform coefficients, using a quantization matrix and a quantization parameter, for the residual coefficients input from the transform and quantization unit <b>105</b>. The processing of reconstructing (deriving) the transform coefficients from the residual coefficients, using the quantization matrix and the quantization parameter, in such a manner will be referred to as inverse-quantization. The quantization matrix may not be necessarily used in inverse-quantization processing. In particular, in a case where the quantization matrix is not used in the quantization processing by the transform and quantization unit <b>105</b>, the quantization matrix is not used in the inverse-quantization processing by the inverse-quantization and inverse-transform unit <b>106</b>. In addition, it can be determined whether to apply the quantization matrix based on whether the low-frequency transform has been performed on the subblock. For example, in a case where the low-frequency transform has been performed on the subblock, the inverse-quantization is performed without using the quantization matrix, and otherwise, the inverse-quantization is performed using the quantization matrix.</p><p id="p-0039" num="0038">Further, the inverse-quantization and inverse-transform unit <b>106</b> determines whether the low-frequency transform has been performed on the subblock, based on the input low-frequency transform information. In a case where the low-frequency transform has been performed on the subblock, the inverse-quantization and inverse-transform unit <b>106</b> reconstructs orthogonal transform coefficients by performing inverse low-frequency transform processing on the transform coefficients (the low-frequency transform coefficients) obtained by inversely quantizing the residual coefficients, and further reconstructs prediction errors by performing inverse orthogonal transform on the orthogonal transform coefficients. On the other hand, in a case where the low-frequency transform has not been performed on the subblock, the inverse-quantization and inverse-transform unit <b>106</b> reconstructs prediction errors by performing inverse orthogonal transform on the transform coefficients (the orthogonal transform coefficients) obtained by inversely quantizing the residual coefficients. The inverse low-frequency transform processing indicates inverse LFNST processing and is processing of reconstructing (deriving) orthogonal transform coefficients by transforming low-frequency transform coefficients.</p><p id="p-0040" num="0039">The image reconstruction unit <b>107</b> refers to the frame memory <b>10</b> as appropriate and generates predicted image data based on the prediction information output from the prediction unit <b>104</b>. The image reconstruction unit <b>107</b> generates reconstructed image data (reconstructed picture) by adding the prediction errors input from the inverse-quantization and inverse-transform unit <b>106</b> to this predicted image data, and stores the generated reconstructed image data into the frame memory <b>108</b>.</p><p id="p-0041" num="0040">The in-loop filter <b>109</b> performs in-loop filter processing such as deblocking filter or sample adaptive offset, on the reconstructed image stored in the frame memory <b>108</b>, and stores the filter-processed image data again into the frame memory <b>108</b>.</p><p id="p-0042" num="0041">The encoding unit <b>110</b> generates code data by encoding the residual coefficients and the low-frequency transform information output from the transform and quantization unit <b>105</b> and the prediction information output from the prediction unit <b>104</b>, and outputs the generated code data to the integration encoding unit <b>111</b>.</p><p id="p-0043" num="0042">The integration encoding unit <b>111</b> generates a coefficient range information code by encoding the coefficient range information from the coefficient range information generation unit <b>103</b>. Subsequently, header code data including the coefficient range information code is generated. The integration encoding unit <b>111</b> then forms a bitstream by making the code data output from the encoding unit <b>110</b> follow the header code data. The integration encoding unit <b>111</b> then outputs the formed bitstream via the output terminal <b>112</b>.</p><p id="p-0044" num="0043">Here, the image encoding operation in the image encoding device will be described in detail below. In the present exemplary embodiment, a configuration in which 16-bit moving image data is input from the input terminal <b>101</b> frame by frame is adopted, but a configuration in which still image data for 1 frame is input may be adopted. Further, in the present exemplary embodiment, the block division unit <b>101</b> will be described to divide the image data input from the input terminal into basic blocks of 8&#xd7;8 pixels, for the purpose of description. The basic block as used herein is, for example, a coding tree unit. Although an example in which the coding tree unit has a size of 8&#xd7;8 pixels will be described, other sizes may be adopted. For example, any of a size of 32&#xd7;32 pixels to a size of 128&#xd7;128 pixels may be adopted.</p><p id="p-0045" num="0044">Prior to image encoding, a range of possible values for coefficients in the encoding processing according to the present exemplary embodiment is determined.</p><p id="p-0046" num="0045">The coefficient range information generation unit <b>103</b> generates coefficient range information indicating whether a range of possible values for the coefficients in the encoding processing is to be variable depending on the bit depth of an input image or the range is to be fixed irrespective of the bit depth. In the following, the former variable range of possible values for the coefficients in the encoding processing depending on the bit depth of the image will be referred to as high-precision coefficient range, and the latter range fixed irrespective of the bit depth will be referred to as fixed coefficient range. In the present exemplary embodiment, the coefficient range information is 1 in a case where the former high-precision coefficient range is selected, whereas the coefficient range information is 0 in a case where the latter fixed coefficient range is selected. However, the combination of the selected coefficient range and the coefficient range information is not limited to these. In addition, the method of determining the coefficient range information is not particularly limited, either and may be determined prior to the encoding processing, assuming an application to be used by the present encoding device and the corresponding decoding device, or may be selected by a user. For example, the coefficient range information is 1 in a case where the image encoding device <b>100</b> according to the present exemplary embodiment is assumed to use an application that gives top priority to image quality and places importance on arithmetic precision, and the coefficient range information is otherwise 0. The generated coefficient range information is output to the integration encoding unit <b>111</b>, the transform and quantization unit <b>105</b>, and the inverse-quantization and inverse-transform unit <b>106</b>.</p><p id="p-0047" num="0046">The integration encoding unit <b>111</b> generates a coefficient range information code by encoding the coefficient range information input from the coefficient range information generation unit <b>103</b>, and integrates the generated coefficient range information code into header information necessary for encoding of image data.</p><p id="p-0048" num="0047">Subsequently, encoding of image data is performed. Input image data for 1 frame from the input terminal <b>101</b> is supplied to the block division unit <b>102</b>.</p><p id="p-0049" num="0048">The block division unit <b>102</b> divides the input image data for 1 frame into a plurality of basic blocks, and outputs the image data in units of basic blocks to the prediction unit <b>104</b>. In the present exemplary embodiment, the image data in units of basic blocks of 8&#xd7;8 pixels is supplied to the prediction unit <b>104</b>.</p><p id="p-0050" num="0049">The prediction unit <b>104</b> executes prediction processing on the image data in units of basic blocks input from the block division unit <b>102</b>. Specifically, subblock division of dividing the basic block into smaller subblocks is determined, and a prediction mode such as intra-prediction or inter-prediction is further determined subblock by subblock. The intra-prediction generates a prediction pixel of an encoding target block using an encoded pixel spatially located near the encoding target block, and also generates an intra-prediction mode indicating an intra-prediction method such horizontal prediction, vertical prediction, or DC prediction. The inter-prediction generates a prediction pixel of an encoding target block using an encoded pixel of a frame temporally different from the encoding target block, and also generates a frame to be referred to and motion information indicating a motion vector or the like.</p><p id="p-0051" num="0050">A subblock division method will be described with reference to <figref idref="DRAWINGS">FIGS. <b>7</b>A to <b>7</b>F</figref>. A thick frame of each of blocks <b>700</b> to <b>705</b> in <figref idref="DRAWINGS">FIGS. <b>7</b>A to <b>7</b>F</figref> has a size of 8&#xd7;8 pixels that is the same as that of the basic block. Each quadrangle inside the thick frame represents a subblock. <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> illustrates an example of conventional square subblock division, and the basic block <b>701</b> of 8&#xd7;8 pixels is divided into four subblocks of 4&#xd7;4 pixels. Meanwhile, <figref idref="DRAWINGS">FIG. <b>7</b>C</figref> to <figref idref="DRAWINGS">FIG. <b>7</b>F</figref> each illustrate an example of rectangular subblock division. <figref idref="DRAWINGS">FIG. <b>7</b>C</figref> illustrates the basic block <b>702</b> that is divided into two subblocks (long in the vertical direction) each having a size of 4&#xd7;8 pixels. <figref idref="DRAWINGS">FIG. <b>7</b>D</figref> illustrates the basic block <b>703</b> that is divided into two subblocks (long in the horizontal direction) each having a size of 8&#xd7;4 pixels. <figref idref="DRAWINGS">FIG. <b>7</b>E</figref> and <figref idref="DRAWINGS">FIG. <b>7</b>F</figref> respectively illustrate the basic blocks <b>704</b> and <b>705</b> that are each divided into three rectangular subblocks at a ratio of 1:2:1, although the division methods are different. In this way, the encoding processing is performed using not only square subblocks but also rectangular subblocks.</p><p id="p-0052" num="0051">In the present exemplary embodiment, only <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> in which the basic block having the size of 8&#xd7;8 pixels is not divided into subblocks is used, but the subblock division method is not limited thereto. The quadtree division as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, the ternary tree division as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>E</figref> and <figref idref="DRAWINGS">FIG. <b>7</b>F</figref>, or the binary tree division as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref> and <figref idref="DRAWINGS">FIG. <b>7</b>D</figref> may be used.</p><p id="p-0053" num="0052">The prediction unit <b>104</b> generates predicted image data from the determined prediction mode and an encoded region stored in the frame memory <b>108</b>, further calculates prediction errors in units of pixels from the input image data and the predicted image data, and outputs the calculated error to the transform and quantization unit <b>105</b>. In addition, the prediction unit <b>104</b> outputs information about the subblock division, the prediction mode, and the like to the encoding unit <b>110</b> and the image reconstruction unit <b>107</b>, as prediction information.</p><p id="p-0054" num="0053">The transform and quantization unit <b>105</b> first receives the coefficient range information as input from the coefficient range generation unit <b>103</b>, and determines a range of possible values for coefficients in transform processing or quantization processing. In the present exemplary embodiment, a range that can be taken by coefficients obtained as each of arithmetic results of one-dimensional orthogonal transform in each of horizontal and vertical directions, secondary transform of further transforming the coefficients subjected to orthogonal transform, quantization, and the like is determined based on a table illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. However, the combination of the coefficient range information and the range that can be taken by the coefficients obtained as each of the arithmetic results is not limited thereto. In the present exemplary embodiment, because the bit depth of the input image is 16, a range of &#x2212;32768 to 32767 or a range of &#x2212;8388608 to 8388607 is used depending on the coefficient range information. Processing to be executed in a case where each of the arithmetic results falls outside the above-described range is not particularly limited, but the result can be adjusted to fall within the above-described range by clip processing or bit shift processing.</p><p id="p-0055" num="0054">Next, the transform and quantization unit <b>105</b> generates residual coefficients by performing orthogonal transform and quantization on the prediction errors input from the prediction unit <b>104</b>, based on the above-described coefficient range. Specifically, the transform and quantization unit <b>105</b> first generates orthogonal transform coefficients by performing orthogonal transform processing corresponding to the size of the subblock, on the prediction errors. Next, the transform and quantization unit <b>105</b> determines whether to perform low-frequency transform on a low-frequency part of the orthogonal transform coefficients, generates information about this determination as low-frequency transform information, and outputs the low-frequency transform information to the inverse-quantization and inverse-transform unit <b>106</b> and the encoding unit <b>110</b>. The method of determining the low-frequency transform information is not particularly limited; however, in a case such as a case where the orthogonal transform coefficients are concentrated on the low-frequency component, and a further improvement in compression efficiency can expected by performing the low-frequency transform, the low-frequency transform can be further performed. In a case where the low-frequency transform is determined to be performed, the transform and quantization unit <b>105</b> generates low-frequency transform coefficients by performing the low-frequency transform on the low-frequency part of the orthogonal transform coefficients, and, on the other hand, a high-frequency component on which the low-frequency transform has not been performed is handled as 0, regardless of the values of the orthogonal transform coefficients. Then, in a case where the low-frequency transform has been performed, the transform and quantization unit <b>105</b> generates residual coefficients by quantizing the low-frequency transform coefficients. On the other hand, in a case where the low-frequency transform has not been performed, the transform and quantization unit <b>105</b> generates residual coefficients by quantizing the orthogonal transform coefficients.</p><p id="p-0056" num="0055">As with the transform and quantization unit <b>105</b>, the inverse-quantization and inverse-transform unit <b>106</b> first receives the coefficient range information as input from the coefficient range generation unit <b>103</b>, and determines a range of possible values for coefficients in inverse-quantization processing or inverse-transform processing. In the present exemplary embodiment, as with the transform and quantization unit <b>105</b>, a range that can be taken by coefficients obtained as each of arithmetic results of inverse-quantization processing, inverse low-frequency transform processing for a low-frequency component, one-dimensional inverse orthogonal transform in each of horizontal and vertical directions, and the like is determined based on the table illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. In the present exemplary embodiment, as with the transform and quantization unit <b>105</b>, because the bit depth of the input image is 16, a range of &#x2212;32768 to 32767 or a range of &#x2212;8388608 to 8388607 is to be taken depending on the coefficient range information.</p><p id="p-0057" num="0056">Next, the inverse-quantization and inverse-transform unit <b>106</b> reconstructs transform coefficients by inversely quantizing the residual coefficients input from the transform and quantization unit <b>105</b>, based on the above-described coefficient range. Further, the inverse-quantization and inverse-transform unit <b>106</b> determines whether the low-frequency transform has been performed on the subblock, based on the low-frequency transform information input from the transform and quantization unit <b>105</b>. In a case where the low-frequency transform has been performed on the subblock, the inverse-quantization and inverse-transform unit <b>106</b> reconstructs orthogonal transform coefficients by performing inverse low-frequency transform processing on the transform coefficients, and further reconstructs prediction errors by performing inverse orthogonal transform on the orthogonal transform coefficients. On the other hand, in a case where the low-frequency transform has not been performed on the subblock, the inverse-quantization and inverse-transform unit <b>106</b> reconstructs prediction errors by performing inverse orthogonal transform on the transform coefficients. The prediction errors thus reconstructed are output to the image reconstruction unit <b>107</b>.</p><p id="p-0058" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>y</i>=Clip3(CoeffMin, CoeffMax, ((&#x3a3;lowFreqTransMatrix [<i>j</i>]&#xd7;<i>x</i>)+64)&#x3e;&#x3e;7)&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0059" num="0000">(where, Clip3 (a, b, c) indicates processing of clipping a value c using a minimum value a and a maximum value b, and &#x201c;&#x3e;&#x3e;&#x201d; represents a bit shift to the right.) The above expression (1) is one of calculation formulas used in the inverse low-frequency transform processing in the inverse-quantization and inverse-transform unit <b>106</b> according to the present exemplary embodiment. Here, CoeffMin of the expression (1) corresponds to a minimum coefficient value in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, and CoeffMax of the expression (1) corresponds to a maximum coefficient value in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. In the present exemplary embodiment, because the bit depth of the input image is 16 bits, the values of CoeffMin and CoeffMax of the expression (1) are determined based on the coefficient range information. In a case where the coefficient range information is 0, i.e., the fixed coefficient range is selected, CoeffMin is &#x2212;32768 and CoeffMax is 32767, and an output value can be expressed in signed 16 bits. In this case, 16-bit addition/multiplication commands and the like can be used in the subsequent encoding processing, and thus there is an advantage that the implementation cost does not increase. On the other hand, in a case where the coefficient range information is 1, i.e., the high-precision coefficient range is selected, CoeffMin is &#x2212;8388608, and CoeffMax is 8388607. In this case, an output value cannot be expressed in signed 16 bits, and thus the implementation cost in the subsequent encoding processing increases, but high arithmetic precision encoding processing suitable for a high-bit depth such as 16 bits can be realized. As a result, there are advantageous effects such as an improvement in compression efficiency and an increase in image quality when a bitstream of an encoding result is decoded.</p><p id="p-0060" num="0057">The image reconstruction unit <b>107</b> refers to the frame memory <b>108</b> as appropriate and reconstructs a predicted image based on the prediction information input from the prediction unit <b>104</b>. Subsequently, the image reconstruction unit <b>107</b> generates reconstructed image data based on the reconstructed predicted image and the prediction errors reconstructed by the inverse-quantization and inverse-transform unit <b>106</b>, and stores the generated reconstructed image data into the frame memory <b>108</b>.</p><p id="p-0061" num="0058">The in-loop filter unit <b>109</b> reads out the reconstructed image data from the frame memory <b>108</b>, and performs in-loop filter processing such as deblocking filter. Subsequently, the in-loop filter unit <b>109</b> stores the filter-processed image data into the frame memory <b>108</b> again.</p><p id="p-0062" num="0059">The encoding unit <b>110</b> generates code data by entropically encoding the residual coefficients in units of subblocks and the low-frequency transform information generated in the transform and quantization unit <b>105</b>, and the prediction information input from the prediction unit <b>104</b>. The method for entropy encoding is not specified in particular, and Golomb encoding, arithmetic encoding, Huffman encoding, and the like can be used. The encoding unit <b>110</b> outputs the generated code data to the integration encoding unit <b>111</b>.</p><p id="p-0063" num="0060">The integration encoding unit <b>111</b> forms a bitstream by multiplexing the code data input from the encoding unit <b>110</b>, and the like together with the header code data described above. Subsequently, the integration encoding unit <b>111</b> outputs the formed bitstream from the output terminal <b>112</b> to the outside (to a storage medium, a network, or the like).</p><p id="p-0064" num="0061"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is an example of the data structure of a bitstream output in the present exemplary embodiment. The coefficient range information code is included in a sequence header. However, the encoded position is not limited thereto and may be included a picture header section as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref> or a header section consisting of a plurality of pictures.</p><p id="p-0065" num="0062"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating encoding processing performed for 1 frame by the control unit <b>150</b> in the image encoding device <b>100</b> according to the exemplary embodiment.</p><p id="p-0066" num="0063">First, prior to image encoding, in step S<b>301</b>, the control unit <b>150</b> controls the coefficient range information generation unit <b>103</b> to generate coefficient range information.</p><p id="p-0067" num="0064">In step S<b>302</b>, the control unit <b>150</b> controls the integration encoding unit <b>111</b> to encode the coefficient range information generated in step S<b>301</b> to generate a coefficient range information code.</p><p id="p-0068" num="0065">In step S<b>303</b>, the control unit <b>150</b> controls the integration encoding unit <b>111</b> to encode the generated coefficient range information code, and header information necessary for encoding of image data, and to output the result.</p><p id="p-0069" num="0066">In step S<b>304</b>, the control unit <b>150</b> controls the block division unit <b>102</b> to divide an input image in units of frames into basic blocks.</p><p id="p-0070" num="0067">In step S<b>305</b>, the control unit <b>150</b> controls the prediction unit <b>104</b> to execute prediction processing on the image data in units of basic blocks generated in step S<b>304</b> and to generate prediction information such as subblock division information and a prediction mode and predicted image data. Further, the control unit <b>150</b> controls the prediction unit <b>104</b> to calculate prediction errors from the input image data and the predicted image data.</p><p id="p-0071" num="0068">In step S<b>306</b>, the control unit <b>150</b> controls the transform and quantization unit <b>105</b> to determine a coefficient range in encoding processing of this step, based on the coefficient range information generated in step S<b>301</b>. For example, the control unit <b>150</b> determines the coefficient range in the encoding processing of this step as the high-precision coefficient range in a case where the coefficient range information is 1, and determines the coefficient range in the encoding processing of this step as the fixed coefficient range in a case where the coefficient range information is 0. Next, the control unit <b>150</b> controls the transform and quantization unit <b>105</b> to perform orthogonal transform on the prediction errors calculated in step S<b>305</b> to generate orthogonal transform coefficients. Subsequently, the control unit <b>150</b> controls the transform and quantization unit <b>105</b> to determine whether to perform low-frequency transform on the orthogonal transform coefficients generated in the subblock, and to generate information about this determination as low-frequency transform information. In a case where the low-frequency transform is determined to be performed, the control unit <b>150</b> controls the transform and quantization unit <b>105</b> to generate residual coefficients by performing the low-frequency transform and then performing quantization on a low-frequency component of the orthogonal transform coefficients. On the other hand, in a case where the low-frequency transform is determined not to be performed, the control unit <b>150</b> controls the transform and quantization unit <b>105</b> to generate residual coefficients by quantizing the orthogonal transform coefficients.</p><p id="p-0072" num="0069">In step S<b>307</b>, the control unit <b>150</b> controls the inverse-quantization and inverse-transform unit <b>106</b> to determine a coefficient range in encoding processing of this step based on the coefficient range information generated in step S<b>301</b>. For example, the control unit <b>150</b> determines the coefficient range in the encoding processing of this step as the high-precision coefficient range in a case where the coefficient range information is 1, and determines the coefficient range in the encoding processing of this step as the fixed coefficient range in a case where the coefficient range information is 0. Next, the control unit <b>150</b> controls the inverse-quantization and inverse-transform unit <b>106</b> to reconstruct transform coefficients by inversely quantizing the residual coefficients generated in step S<b>306</b>. Next, the control unit <b>150</b> controls the inverse-quantization and inverse-transform unit <b>106</b> to determine whether the low-frequency transform has been performed on the subblock, based on the low-frequency transform information generated in step S<b>306</b>. In a case where the low-frequency transform has been performed on the subblock, the control unit <b>150</b> controls the inverse-quantization and inverse-transform unit <b>106</b> to reconstruct orthogonal transform coefficients by performing inverse low-frequency transform processing on the transform coefficients, and further to reconstruct prediction errors by performing inverse orthogonal transform on the orthogonal transform coefficients. On the other hand, in a case where the low-frequency transform has not been performed on the subblock, the control unit <b>150</b> controls the inverse-quantization and inverse-transform unit <b>106</b> to reconstruct prediction errors by performing inverse orthogonal transform on the transform coefficients.</p><p id="p-0073" num="0070">In step S<b>308</b>, the control unit <b>150</b> controls the image reconstruction unit <b>107</b> to reconstruct a predicted image based on the prediction information generated in step S<b>305</b>, reconstruct image data from the reconstructed predicted image and the prediction errors generated in step S<b>307</b>, and store the reconstructed image data into the frame memory <b>108</b>.</p><p id="p-0074" num="0071">In step S<b>309</b>, the control unit <b>150</b> controls the encoding unit <b>110</b> to encode the prediction information generated in step S<b>305</b> and the residual coefficients and the low-frequency transform information generated in step S<b>306</b> to generate code data. Further, the encoding unit <b>110</b> outputs the generated code data to the integration encoding unit <b>111</b>. The integration encoding unit <b>111</b> places the encoded data from the encoding unit <b>110</b> to follow the header generated earlier, and outputs the result.</p><p id="p-0075" num="0072">In step S<b>310</b>, the control unit <b>150</b> determines whether encoding of all the basic blocks within a frame of interest is completed. In a case where the control unit <b>150</b> determines that the encoding is completed, the processing proceeds to step S<b>311</b>, and in a case where the control unit <b>150</b> determines that there is a basic block that has not been encoded, the processing returns to step S<b>304</b> to continue encoding of the next basic block.</p><p id="p-0076" num="0073">In step S<b>311</b>, the control unit <b>150</b> controls the in-loop filter unit <b>109</b> to perform in-loop filter processing on the image data reconstructed in step S<b>308</b> and generate a filter-processed image, and then the processing ends.</p><p id="p-0077" num="0074">The above-described configuration and operation, especially the encoding of the coefficient range information in step S<b>302</b> make it possible to generate a bitstream that enables switching between encoding processes varying in arithmetic precision and implementation cost, depending on the requirement specification of an application.</p><p id="p-0078" num="0075">In the present exemplary embodiment, the coefficient range is described as the range of possible values for the coefficients to be the results of the transform processing or the quantization processing, but may be used as a range of possible values for coefficients to be results of other encoding processing. For example, in VVC, a technique called Block-based Delta Pulse Code Modulation (BDPCM) is adopted to increase compression efficiency mainly in lossless coding. The BDPCM is a scheme that generates quantization coefficients by performing only quantization on prediction errors without performing transform thereon, instead of encoding residual coefficients obtained by performing transform and quantization on the prediction errors, and encodes differential values between the generated quantization coefficients and respective adjacent left or top quantization coefficients. Here, the coefficient range may be applied to this differential value. Whether the range of possible values for coefficients to be encoded is the high-precision coefficient range or the fixed coefficient range is thereby determined regardless of whether the BDPCM is applied, and thus it is possible to reduce the implementation cost by implementing the encoding unit supporting only one of these ranges.</p><p id="p-0079" num="0076">Further, in the present exemplary embodiment, in a case where, for example, the bit depth of an input image is 8 bits, the coefficient range information code can be omitted. This is because the minimum coefficient value and the maximum coefficient value are equal regardless of the coefficient range information, so that redundant codes can be reduced. The bit depth of the input image for which encoding of the coefficient range information can be omitted is not limited to 8 bits, and encoding of the coefficient range information can be omitted in a case where the minimum coefficient value and the maximum coefficient value are equal regardless of the coefficient range information in other exemplary embodiments.</p><p id="p-0080" num="0077"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a configuration of an image decoding device <b>200</b> that decodes the encoded image data generated in the image encoding device <b>100</b> in the exemplary embodiment. A configuration and operation related to decoding processing will be described below with reference to this drawing.</p><p id="p-0081" num="0078">The image decoding device <b>200</b> includes a control unit <b>250</b> that controls the entire device. This control unit <b>250</b> includes a CPU, a ROM storing a program to be executed by the CPU, and a RAM to be used as a work area of the CPU. Further, the image decoding device <b>200</b> has an input terminal <b>201</b>, a separation decoding unit <b>202</b>, a decoding unit <b>203</b>, an inverse-quantization and inverse-transform unit <b>204</b>, an image reconstruction unit <b>205</b>, a frame memory <b>206</b>, an in-loop filter unit <b>207</b>, an output terminal <b>208</b>, and a coefficient range information decoding unit <b>209</b>.</p><p id="p-0082" num="0079">The input terminal <b>201</b> inputs an encoded bitstream, and the input source is, for example, a storage medium storing the encoded stream; however, the encoded bitstream may be input from a network, and any type of source may be used.</p><p id="p-0083" num="0080">The separation decoding unit <b>202</b> separates information about decoding processing and code data related to coefficients from the bitstream, and decodes code data included in the header section of the bitstream. The separation decoding unit <b>202</b> according to the present exemplary embodiment separates a coefficient range information code, and outputs the coefficient range information code to the coefficient range information decoding unit <b>209</b>. Further, the separation decoding unit <b>202</b> outputs code data of an image to the decoding unit <b>203</b>.</p><p id="p-0084" num="0081">The coefficient range information decoding unit <b>209</b> reconstructs coefficient range information by decoding the coefficient range information code supplied from the separation decoding unit <b>202</b>, and outputs the reconstructed coefficient range information to the inverse-quantization and inverse-transform unit <b>204</b> in the subsequent stage.</p><p id="p-0085" num="0082">The decoding unit <b>203</b> reconstructs residual coefficients, low-frequency transform information and prediction information by decoding the code data of the image output from the separation decoding unit <b>202</b>.</p><p id="p-0086" num="0083">As with the inverse-quantization and inverse-transform unit <b>106</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the inverse-quantization and inverse-transform unit <b>204</b> inversely quantizes the residual coefficients, and reconstructs transform coefficients that are coefficients subjected to the inverse-quantization. Further, the inverse-quantization and inverse-transform unit <b>204</b> determines whether low-frequency transform has been performed on the subblock, using the low-frequency transform information. In a case where the low-frequency transform has been performed on the subblock, the inverse-quantization and inverse-transform unit <b>204</b> reconstructs orthogonal transform coefficients by performing inverse low-frequency transform processing on low-frequency transform coefficients. The inverse-quantization and inverse-transform unit <b>204</b> further reconstructs prediction errors by executing inverse orthogonal transform on these orthogonal transform coefficients or the transform coefficients. On the other hand, in a case where the low-frequency transform has not been performed on the subblock, the inverse-quantization and inverse-transform unit <b>204</b> reconstructs prediction errors by performing inverse orthogonal transform on the orthogonal transform coefficients.</p><p id="p-0087" num="0084">The image reconstruction unit <b>205</b> refers to the frame memory <b>206</b> as appropriate and generates predicted image data based on the input prediction information. Subsequently, the image reconstruction unit <b>205</b> generates reconstructed image data from this predicted image data and the prediction errors reconstructed in the inverse-quantization and inverse-transform unit <b>204</b>, and stores the generated reconstructed image data into the frame memory <b>206</b>.</p><p id="p-0088" num="0085">As with the in-loop filter unit <b>109</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the in-loop filter unit <b>207</b> performs in-loop filter processing such as deblocking filter on the reconstructed image data stored in the frame memory <b>206</b>, and stores the processed image data again into the frame memory <b>206</b>.</p><p id="p-0089" num="0086">The output terminal <b>208</b> sequentially outputs frame images stored in the frame memory <b>206</b> to the outside. An output destination is typically a display device, but may be other devices.</p><p id="p-0090" num="0087">The operation related to image decoding by the image decoding device <b>200</b> of the exemplary embodiment described above will be described more in detail. In the present exemplary embodiment, a configuration in which an encoded bitstream is input frame by frame is adopted.</p><p id="p-0091" num="0088">In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a bitstream for 1 frame input from the input terminal <b>201</b> is supplied to the separation decoding unit <b>202</b>. The separation decoding unit <b>202</b> separates information about decoding processing and code data related to coefficients from the bitstream, and decodes code data included in the header section of the bitstream. Subsequently, the separation decoding unit <b>202</b> supplies a coefficient range information code included in the header section to the coefficient range information decoding unit <b>209</b>, and supplies code data of the image data to the decoding unit <b>203</b>. Specifically, the separation decoding unit <b>202</b> first extracts a coefficient range information code from the sequence header of the bitstream illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, and outputs the extracted coefficient range information code to the coefficient range information decoding unit <b>209</b>. Subsequently, code data in units of basic blocks of picture data is extracted and output to the decoding unit <b>203</b>.</p><p id="p-0092" num="0089">The coefficient range information decoding unit <b>209</b> obtains coefficient range information by decoding the coefficient range information code input from the separation decoding unit <b>202</b>. As with the encoding side, the high-precision coefficient range is used when the coefficient range information is 1, and the fixed coefficient range is used when the coefficient range information is 0. The coefficient range information is output to the inverse-quantization and inverse-transform unit <b>204</b>. In the present exemplary embodiment, a configuration in which a 16-bit image is input on the encoding side and a 16-bit image is output on the decoding side is adopted, and thus a range of &#x2212;32768 to 32767 is used when the coefficient range information is 0, and a range of &#x2212;8388608 to 8388607 is used when the coefficient range information is 1.</p><p id="p-0093" num="0090">The decoding unit <b>203</b> decodes the code data supplied from the separation decoding unit <b>202</b>, reconstruct prediction information, and further reconstruct residual coefficients and low-frequency transform information. First, the decoding unit <b>203</b> reconstructs the prediction information and acquires a prediction mode used in the subblock. The decoding unit <b>203</b> outputs the reconstructed residual coefficients and low-frequency transform information to the inverse-quantization and inverse-transform unit <b>204</b> and outputs the reconstructed prediction information to the image reconstruction unit <b>205</b>.</p><p id="p-0094" num="0091">The inverse-quantization and inverse-transform unit <b>204</b> generates transform coefficients by inversely quantizing the input residual coefficients based on the above-described coefficient range. Then, the inverse-quantization and inverse-transform unit <b>204</b> determines whether low-frequency transform has been performed on the subblock, based on the input low-frequency transform information. In a case where the low-frequency transform has been performed on the subblock, the inverse-quantization and inverse-transform unit <b>204</b> reconstructs orthogonal transform coefficients by performing low-frequency transform processing on the transform coefficients, and further reconstructs prediction errors by performing inverse orthogonal transform on the orthogonal transform coefficients. On the other hand, in a case where the low-frequency transform has not been performed on the subblock, the inverse-quantization and inverse-transform unit <b>204</b> reconstructs prediction errors by performing inverse orthogonal transform on the transform coefficients. The prediction errors thus reconstructed are output to the image reconstruction unit <b>205</b>.</p><p id="p-0095" num="0092">The image reconstruction unit <b>205</b> refers to the frame memory <b>206</b> as appropriate and reconstructs a predicted image based on the prediction information input from the decoding unit <b>203</b>. The image reconstruction unit <b>205</b> according to the present exemplary embodiment uses intra-prediction and/or inter-prediction, as with the prediction unit <b>104</b> on the encoding side. Specific prediction processing is similar to that of the prediction unit <b>104</b> on the encoding side, and thus the description thereof will be omitted. The image reconstruction unit <b>205</b> reconstructs image data from this predicted image and the prediction errors input from the inverse-quantization and inverse-transform unit <b>204</b>, and stores the reconstructed image data into the frame memory <b>206</b>. The stored image data is used for reference in prediction.</p><p id="p-0096" num="0093">As with the in-loop filter unit <b>109</b> on the encoding side, the in-loop filter unit <b>207</b> reads out the reconstructed image from the frame memory <b>206</b> and performs in-loop filter processing such as deblocking filter. Subsequently, the in-loop filter unit <b>207</b> stores the filter-processed image into the frame memory <b>206</b> again.</p><p id="p-0097" num="0094">The reconstructed image stored in the frame memory <b>206</b> is eventually output from the output terminal <b>208</b> to the outside (typically, to a display device).</p><p id="p-0098" num="0095"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating decoding processing by the control unit <b>205</b> in the image decoding device <b>200</b> according to the exemplary embodiment.</p><p id="p-0099" num="0096">First, in step S<b>401</b>, the control unit <b>250</b> controls the separation decoding unit <b>202</b> to separate information about decoding processing and code data related to coefficients from a bitstream and decode code data in a header section. To be more specific, the separation decoding unit <b>202</b> supplies a coefficient range information code to the coefficient range information decoding unit <b>209</b>, and supplies code data of an image to the decoding unit <b>203</b>.</p><p id="p-0100" num="0097">In step S<b>402</b>, the control unit <b>250</b> controls the coefficient range information decoding unit <b>209</b> to decode the coefficient range information code reconstructed in step S<b>401</b>. The description of specific operation of the coefficient range information decoding unit <b>209</b> here has been already provided and thus will be omitted.</p><p id="p-0101" num="0098">In step S<b>403</b>, the control unit <b>250</b> controls the decoding unit <b>203</b> to decode the code data separated in step S<b>401</b>, reconstruct prediction information, and reconstruct residual coefficients and low-frequency transform information.</p><p id="p-0102" num="0099">In step S<b>404</b>, the control unit <b>250</b> controls the inverse-quantization and inverse-transform unit <b>204</b> to determine a coefficient range in decoding processing of this step, based on the coefficient range information decoded in step S<b>402</b>. For example, the control unit <b>150</b> determines the coefficient range in the decoding processing of this step as the high-precision coefficient range in a case where the coefficient range information is 1, and determines the coefficient range in the decoding processing of this step as the fixed coefficient range in a case where the coefficient range information is 0. Next, the control unit <b>250</b> controls the inverse-quantization and inverse-transform unit <b>204</b> to generate transform coefficients by inversely quantizing the residual coefficients reconstructed in step S<b>403</b>. Further, the control unit <b>250</b> controls the inverse-quantization and inverse-transform unit <b>204</b> to determine whether low-frequency transform has been performed on the subblock, based on the low-frequency transform information reconstructed in step S<b>403</b>. In a case where the low-frequency transform has been performed on the subblock, the control unit <b>250</b> controls the inverse-quantization and inverse-transform unit <b>204</b> to reconstruct orthogonal transform coefficients by performing inverse low-frequency transform processing on the transform coefficients and further reconstruct prediction errors by performing inverse orthogonal transform on the orthogonal transform coefficients. On the other hand, in a case where the low-frequency transform has not been performed on the subblock, the control unit <b>250</b> controls the inverse-quantization and inverse-transform unit <b>204</b> to reconstruct prediction errors by performing inverse orthogonal transform on the transform coefficients.</p><p id="p-0103" num="0100">In step S<b>405</b>, the control unit <b>250</b> controls the image reconstruction unit <b>205</b> to reconstruct an image based on the prediction information generated in step S<b>403</b>. Specifically, the image reconstruction unit <b>205</b> refers to the frame memory <b>206</b> and reconstructs a predicted image based on the prediction information. At this time, the image reconstruction unit <b>205</b> uses intra-prediction and/or inter-prediction, as in step S<b>305</b> on the encoding side. Subsequently, the image reconstruction unit <b>205</b> reconstructs image data from the reconstructed predicted image and the prediction errors generated in S<b>404</b>, and stores the reconstructed image data into the frame memory <b>206</b>.</p><p id="p-0104" num="0101">In step S<b>406</b>, the control unit <b>250</b> determines whether decoding of all the basic blocks within the frame of interest is completed. In a case where the decoding is completed, the processing proceeds to step S<b>407</b>, and in a case where there is an unencoded basic block, the processing returns to step S<b>403</b> for the next basic block to be decoded.</p><p id="p-0105" num="0102">In step S<b>407</b>, the control unit <b>250</b> controls the in-loop filter unit <b>207</b> to perform in-loop filter processing on the image data reconstructed in step S<b>405</b> and generates a filter-processed image, and the processing ends.</p><p id="p-0106" num="0103">The above-described configuration and operation make it possible to decode the encoded bitstream generated in the image encoding device <b>100</b> described above, i.e., a bitstream that enables switching between decoding processes varying in arithmetic precision and implementation cost depending on the requirement specification of an application.</p><p id="p-0107" num="0104">In the present exemplary embodiment, the coefficient range is described as the range of possible values for the coefficients obtained as the results of the inverse-quantization processing or the inverse-transform processing, but may be used as a range of possible values for a coefficient obtained as a result of other decoding processing; for example, as with the encoding side, this coefficient range may be applied in BDPCM processing.</p><p id="p-0108" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>dz</i>[<i>x</i>][<i>y</i>]=Clip3(CoeffMin, CoeffMax, <i>dz</i>[<i>x&#x2212;</i>1][<i>y</i>]+<i>dz</i>[<i>x</i>][<i>y</i>])&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0109" num="0000">(where, Clip3 (a, b, c) indicates processing of clipping a value c, using a minimum value a and a maximum value b.) The above expression (2) is one of calculation formulas used in decoding processing using BDPCM, and is an expression in which a differential value is added to a quantization coefficient dz[x&#x2212;1][y] on the left, and clipping processing is performed using a coefficient range in reconstruction of a quantization coefficient dz[x][y]. As with the expression (1), CoeffMin and CoeffMax of the expression (2) correspond to the minimum coefficient value and the maximum coefficient value in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. In a case where the coefficient range information is 0, i.e., the fixed coefficient range is used, the quantization coefficient dz[x][y] that is an output of the expression (2) takes a range of &#x2212;32768 to 32767 and can be expressed in signed 16 bits. In this case, 16-bit addition/multiplication commands and the like can be used in the inverse-quantization processing that is the subsequent decoding processing, and thus there is an advantage that the implementation cost is reduced. On the other hand, in a case where the coefficient range information is 1, i.e., the high-precision coefficient range is selected, the implementation cost in the subsequent decoding processing such as the inverse-quantization processing increases, but decoding processing with high arithmetic precision can be realized. As a result, a bitstream generated with increased compression efficiency on the encoding side can be decoded to have higher image quality.</p><p id="p-0110" num="0105">Each processing unit of the image encoding device <b>100</b> and the image decoding device <b>200</b> according to the exemplary embodiment is described to be configured by hardware. However, the processing performed by each of these processing units illustrated in the drawings may be configured by a computer program.</p><p id="p-0111" num="0106"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating an example of a computer hardware configuration applicable to the image encoding device <b>100</b> and the image decoding device <b>200</b> according to the above-described exemplary embodiment.</p><p id="p-0112" num="0107">A CPU <b>501</b> controls the entire computer using a computer program and data stored in a RAM <b>502</b> and a ROM <b>503</b>, and executes each process described above to be performed by the image encoding device <b>100</b> or the image decoding device <b>200</b> according to the above-described exemplary embodiment. In other words, the CPU <b>501</b> functions as each processing unit illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0113" num="0108">The RAM <b>502</b> has an area for temporarily storing data and the like acquired from an external storage device <b>506</b> or from the outside via an interface (I/F) <b>507</b>. Further, the RAM <b>502</b> is also used as a work area that the CPU <b>501</b> uses when executing various types of processing. For example, the RAM <b>502</b> can be assigned as a frame memory or can provide other various areas as appropriate.</p><p id="p-0114" num="0109">The ROM <b>503</b> stores setting data of the computer, a boot program, and the like. An operation unit <b>504</b> is composed of a keyboard, a mouse, and the like, and a user of the computer can input various instructions to the CPU <b>501</b> by operating the operation unit <b>504</b>. A display unit <b>505</b> displays a result of processing by the CPU <b>501</b>. The display unit <b>505</b> is configured by, for example, a liquid crystal display.</p><p id="p-0115" num="0110">The external storage device <b>506</b> is a large-capacity information storage device represented by a hard disk drive device. The external storage device <b>506</b> stores an operating system (OS) and a computer program (an application program) for causing the CPU <b>501</b> to realize the function of each unit illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Further, the external storage device <b>506</b> may store each piece of image data to be processed.</p><p id="p-0116" num="0111">The computer program and data stored in the external storage device <b>506</b> are appropriately loaded into the RAM <b>502</b> under the control of the CPU <b>501</b>, are to be processed by the CPU <b>501</b>. Networks such as a LAN and the Internet and other devices such as a projection apparatus and a display apparatus can be connected to the I/F <b>507</b>, and the computer can acquire and transmit various kinds of information via this I/F <b>507</b>. <b>508</b> is a bus that connects the above-described units.</p><p id="p-0117" num="0112">When the present device is turned on in the configuration described above, the CPU <b>501</b> executes the boot program stored in the ROM <b>503</b>, loads the OS stored in the external storage device <b>506</b> into the RAM <b>502</b>, and executes the loaded OS. Subsequently, the CPU <b>501</b> loads an application program related to encoding or decoding from the external storage device <b>506</b> into the RAM <b>502</b> and executes the loaded application program under the control of the OS. As a result, the CPU <b>501</b> functions as each processing unit in <figref idref="DRAWINGS">FIG. <b>1</b></figref> or <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and the present device functions as the image encoding device or the image decoding device.</p><heading id="h-0011" level="1">Other Exemplary Embodiments</heading><p id="p-0118" num="0113">The present invention can also be realized by processing of supplying a program for implementing one or more functions in the above-described exemplary embodiment to a system or apparatus via a network or a storage medium and causing one or more processors in a computer of the system or apparatus to read and execute the program. The present invention can also be realized by a circuit (for example, an ASIC) that realizes the one or more functions.</p><p id="p-0119" num="0114">According to each of the above-described exemplary embodiments, a range of possible values for coefficient values in encoding or decoding processing can be adaptively determined.</p><p id="p-0120" num="0115">The present invention is not limited to the above-described exemplary embodiments and various changes and modifications can be made within the spirit and scope of the present invention. Therefore, to make the scope of the present invention public, the following claims are appended.</p><heading id="h-0012" level="1">Other Embodiments</heading><p id="p-0121" num="0116">Embodiment(s) of the present invention can also be realized by a computer of a system or apparatus that reads out and executes computer executable instructions (e.g., one or more programs) recorded on a storage medium (which may also be referred to more fully as a &#x2018;non-transitory computer-readable storage medium&#x2019;) to perform the functions of one or more of the above-described embodiment(s) and/or that includes one or more circuits (e.g., application specific integrated circuit (ASIC)) for performing the functions of one or more of the above-described embodiment(s), and by a method performed by the computer of the system or apparatus by, for example, reading out and executing the computer executable instructions from the storage medium to perform the functions of one or more of the above-described embodiment(s) and/or controlling the one or more circuits to perform the functions of one or more of the above-described embodiment(s). The computer may comprise one or more processors (e.g., central processing unit (CPU), micro processing unit (MPU)) and may include a network of separate computers or separate processors to read out and execute the computer executable instructions. The computer executable instructions may be provided to the computer, for example, from a network or the storage medium. The storage medium may include, for example, one or more of a hard disk, a random-access memory (RAM), a read only memory (ROM), a storage of distributed computing systems, an optical disk (such as a compact disc (CD), digital versatile disc (DVD), or Blu-ray Disc (BD&#x2122;), a flash memory device, a memory card, and the like.</p><p id="p-0122" num="0117">While the present invention has been described with reference to exemplary embodiments, it is to be understood that the invention is not limited to the disclosed exemplary embodiments. The scope of the following claims is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures and functions.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image encoding device comprising:<claim-text>a prediction unit configured to generate prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image;</claim-text><claim-text>a first transform unit configured to generate first transform coefficients by performing orthogonal transform on the prediction errors;</claim-text><claim-text>a second transform unit configured to generate second transform coefficients by performing LFNST processing on the first transform coefficients;</claim-text><claim-text>a quantization unit configured to generate quantization coefficients by performing quantization processing on the second transform coefficients; and</claim-text><claim-text>an encoding unit configured to encode the quantization coefficients,</claim-text><claim-text>wherein the encoding unit encodes information indicating whether a range of possible values at least taken by the second transform coefficients is to be a range determined based on a bit depth or a fixed range.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image encoding device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a quantization matrix is used in a case where the the LFNST processing is applied, and the quantization matrix is not used when the LFNST processing is not applied.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image encoding device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the LFNST processing is a low frequency non separable transformation process.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. An image decoding device that decodes an image from an input bitstream, the image decoding device comprising:<claim-text>a decoding unit configured to decode quantization coefficients from the bitstream;</claim-text><claim-text>an inverse-quantization unit configured to derive first transform coefficients by performing inverse-quantization processing on the quantization coefficients;</claim-text><claim-text>a first transform unit configured to derive second transform coefficients by performing inverse LFNST processing on the first transform coefficients; and,</claim-text><claim-text>a second transform unit configured to derive prediction errors by performing inverse orthogonal transform processing on the second transform coefficients,</claim-text><claim-text>wherein the decoding unit decodes information indicating whether a range of possible values at least taken by the first transform coefficients is to be a range determined based on a bit depth or a fixed range, from the bitstream.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image decoding device according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the first transform unit derives the second transform coefficients by performing inverse LFNST processing on the first transform coefficients.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. An image encoding device comprising:<claim-text>a prediction unit configured to generate prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image; and</claim-text><claim-text>an encoding unit configured to encode the prediction errors, using at least BDPCM processing,</claim-text><claim-text>wherein the encoding unit encodes information indicating whether a range of values obtained by at least the BDPCM processing is to be a range determined based on a bit depth or a fixed range.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. An image decoding device that decodes an image from an input bitstream, the image decoding device comprising:<claim-text>a decoding unit configured to decode quantization coefficients from the bitstream; and</claim-text><claim-text>an inverse-quantization unit configured to derive prediction errors from the quantization coefficients, using at least BDPCM processing,</claim-text><claim-text>wherein the decoding unit decodes information indicating whether a range of values obtained by at least the BDPCM processing is to be a range determined based on a bit depth or a fixed range, from the bitstream.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. An image encoding method comprising:<claim-text>generating prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image;</claim-text><claim-text>generating first transform coefficients by performing orthogonal transform on the prediction errors;</claim-text><claim-text>generating second transform coefficients by performing LFNST processing on the first transform coefficients;</claim-text><claim-text>generating quantization coefficients by performing quantization processing on the second transform coefficients; and</claim-text><claim-text>encoding the quantization coefficients,</claim-text><claim-text>wherein, in the encoding, information indicating whether a range of possible values at least taken by the second transform coefficients is to be a range determined based on a bit depth or a fixed range is encoded.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. An image decoding method of decoding an image from an input bitstream, the mage decoding method comprising:<claim-text>decoding quantization coefficients from the bitstream;</claim-text><claim-text>deriving first transform coefficients by performing inverse-quantization processing on the quantization coefficients;</claim-text><claim-text>deriving second transform coefficients by performing inverse LFNST processing on the first transform coefficients; and</claim-text><claim-text>deriving prediction errors by performing inverse orthogonal transform processing on the second transform coefficients,</claim-text><claim-text>wherein, in the decoding, information indicating whether a range of possible values at least taken by the first transform coefficients is to be a range determined by a bit depth or a fixed range is decoded from the bitstream.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. An image encoding method comprising:<claim-text>generating prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image; and</claim-text><claim-text>encoding the prediction errors, using at least BDPCM processing,</claim-text><claim-text>wherein, in the encoding, information indicating whether a range of values obtained by at least the BDPCM processing is to be a range determined based on a bit depth or a fixed range is encoded.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An image decoding method of decoding an image from an input bitstream, the image decoding method comprising:<claim-text>decoding quantization coefficients from the bitstream; and</claim-text><claim-text>deriving prediction errors from the quantization coefficients, using at least BDPCM processing,</claim-text><claim-text>wherein, in the decoding, information indicating whether a range of values obtained by at least the BDPCM processing is to be a range determined based on a bit depth or a fixed range is decoded from the bitstream.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A non-transitory computer-readable storage medium storing a program for causing a computer to execute a method, the method comprising:<claim-text>generating prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image;</claim-text><claim-text>generating first transform coefficients by performing orthogonal transform on the prediction errors;</claim-text><claim-text>generating second transform coefficients by performing LFNST processing on the first transform coefficients;</claim-text><claim-text>generating quantization coefficients by performing quantization processing on the second transform coefficients; and</claim-text><claim-text>encoding the quantization coefficients,</claim-text><claim-text>wherein, in the encoding, information indicating whether a range of possible values at least taken by the second transform coefficients is to be a range determined based on a bit depth or a fixed range is encoded.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A non-transitory computer-readable storage medium storing a program for causing a computer to execute a method for decoding an image from an input bitstream, the method comprising:<claim-text>decoding quantization coefficients from the bitstream;</claim-text><claim-text>deriving first transform coefficients by performing inverse-quantization processing on the quantization coefficients;</claim-text><claim-text>deriving second transform coefficients by performing inverse LFNST processing on the first transform coefficients; and</claim-text><claim-text>deriving prediction errors by performing inverse orthogonal transform processing on the second transform coefficients,</claim-text><claim-text>wherein, in the decoding, information indicating whether a range of possible values at least taken by the first transform coefficients is to be a range determined based on a bit depth or a fixed range is decoded from the bitstream.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A non-transitory computer-readable storage medium storing a program for causing a computer to execute a method, the method comprising:<claim-text>generating prediction errors being a difference between a predicted image obtained by prediction processing for an input image and the input image; and</claim-text><claim-text>encoding the prediction errors, using at least BDPCM processing,</claim-text><claim-text>wherein, in the encoding, information indicating whether a range of values obtained by at least the BDPCM processing is to be a range determined based on a bit depth or a fixed range is encoded.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory computer-readable storage medium storing a program for causing a computer to execute a method for decoding an image from an input bitstream, the method comprising:<claim-text>decoding quantization coefficients from the bitstream; and</claim-text><claim-text>deriving prediction errors from the quantization coefficients, using at least BDPCM processing,</claim-text><claim-text>wherein, in the decoding, information indicating whether a range of values obtained by at least the BDPCM processing is to be a range determined based on a bit depth or a fixed range is decoded from the bitstream.</claim-text></claim-text></claim></claims></us-patent-application>
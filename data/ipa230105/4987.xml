<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004988A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004988</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364798</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>016</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>0837</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS FOR UTILIZING FEEDBACK DATA</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Walmart Apollo, LLC</orgname><address><city>Bentonville</city><state>AR</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Bhatt</last-name><first-name>Priyanka</first-name><address><city>Haryana</city><country>IN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Bhargava</last-name><first-name>Shankara</first-name><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Kumar</last-name><first-name>Akshay</first-name><address><city>Jaipur</city><country>IN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Agrawal</last-name><first-name>Neeraj</first-name><address><city>Agra</city><country>IN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system can receive a first set of data. The first set of data can include information indicating a first set of user sessions and for each of the first set of user sessions having an associated summary and a corresponding agent indicated intent. The system can also, based on the first set of data, determine a set of utterances and for each of the set of utterances a corresponding set of intents. Additionally, the system can receive a second set of data. The second set of data including information indicating a second set of user sessions and for each of the second set of user sessions having an associated determined utterance and corresponding interaction of a user. Moreover, the system can validate a corresponding intent of one or more utterances of the set of utterances, based on the second set of data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="153.08mm" wi="106.76mm" file="US20230004988A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="199.47mm" wi="112.69mm" orientation="landscape" file="US20230004988A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="155.62mm" wi="102.79mm" file="US20230004988A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="218.78mm" wi="135.38mm" orientation="landscape" file="US20230004988A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="190.92mm" wi="108.80mm" file="US20230004988A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="147.74mm" wi="72.90mm" file="US20230004988A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="186.01mm" wi="108.63mm" file="US20230004988A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="147.74mm" wi="81.62mm" file="US20230004988A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="169.50mm" wi="108.71mm" file="US20230004988A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The disclosure relates generally to systems and methods for utilizing feedback data to optimize models, such as machine learning models.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">At least some ecommerce marketplaces can include a customer help system that can intelligently and automatically assist customers with issues customers present to the customer help system (e.g., tracking and order, starting a return, tracking a return, etc.). In some examples, customer help systems can be text based. In other examples, customer help systems can be audio based. In some implementations, customer help systems can leverage artificial intelligence models to help route customers to appropriate flows (e.g., starting returns, checking orders, etc.). However, in such implementations, such models can be trained on datasets that are labeled by human agents, and therefore can be less than accurate.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">The embodiments described herein are directed to a system and related methods for reducing noise of a large dataset. The system and methods described herein may be applied to a feedback process for machine learning models that can be used across a variety of applications, such as to retrain a trained machine learning model to discount noise (e.g., data/information that is meaningless) in older training datasets which leads to an improved machine learning model. Said processes can improve the average query time of the trained machine learning model, and improve or make more efficient the utilization of computing resources by the network computing systems. For example, the network computing system uses less computing resources overall because the network computing system can more accurately and efficiently route the user to the appropriate flow faster and with less intervening steps.</p><p id="p-0005" num="0004">In accordance with various embodiments, exemplary systems or network computer systems may be implemented in any suitable hardware or hardware and software, such as in any suitable computing device. For example, in some embodiments, a system can include one or more processors and a set of memory resources to store a set of instructions that when executed by the one or more processors, cause the system to receive a first set of data, the first set of data including information indicating a first set of user sessions, each of the first set of user sessions having an associated summary and a corresponding agent indicated intent. Additionally, execution of the instructions can further cause the system to determine a set of utterances and for each of the set of utterances a corresponding intent, based on the first set of data. Moreover, execution of the instructions can further cause the system to receive a second set of data, the second set of data including information indicating a second set of user sessions, each of the second set of user sessions having an associated determined utterance and corresponding interaction of a user. The execution of the instructions can also cause the system to validate the corresponding intent of one or more utterances of the set of utterances.</p><p id="p-0006" num="0005">In another aspect, the system can, based at least on the second set of data, retrain an intent model. In such aspects, the system retraining the intent model includes, for each of the set of utterances, discounting one or more intents of the corresponding set of intents that were not validated.</p><p id="p-0007" num="0006">In another aspect, retraining the intent model is further based on the first set of data.</p><p id="p-0008" num="0007">In another aspect, the system can determine the set of utterances and for each utterance of the set of utterances the corresponding intent, is further based on one or more template based rules.</p><p id="p-0009" num="0008">In another aspect, the execution of the set of instructions, by the one or more processors, further cause the system to detect an input of a user, and determine an utterance from a plurality of predetermined utterances by processing the input. Additionally, the system can determine a set of predicted intents, based on the determined utterance from the plurality of predetermined utterances, the determined set of utterances, and for each utterance of the set of utterances the corresponding intent. Moreover, the system can generate and transmit user interface instructions to a computing device of the user to cause an application executing on the computing device to generate, on a user interface, a graphical representation of each predicted intent of the set of predicted intents, based on the set of predicted intents.</p><p id="p-0010" num="0009">In another aspect, the interactive information indicates that the user had inputted a second input, the second input being indicative of the user selecting a generated graphical representation of one of the set of predicted intents.</p><p id="p-0011" num="0010">In another aspect, the execution of the set of instructions, by the one or more processors, further cause the system to detect a second input of the user, the second input of the user being indicative of an interaction with a generated graphical representation of one of the set of predicted intents, and based on the second input, determine a corresponding set of selectable features. Additionally, the system can transmit user interface instructions to the computing device of the user to cause the application executing on the computing device to update the user interface to include the corresponding set of selectable features.</p><p id="p-0012" num="0011">In another aspect, each of the set of selectable features are configured to cause the application to perform one or more service operations when interacted with.</p><p id="p-0013" num="0012">In some embodiments, the method can include receiving a first set of data, the first set of data including information indicating a first set of user sessions, each of the first set of user sessions having an associated summary and a corresponding agent indicated intent. Additionally, the method can include determining a set of utterances and for each of the set of utterances a corresponding set of intents, based on the first set of data. Moreover, the method can include receiving a second set of data, the second set of data including information indicating a second set of user sessions, each of the second set of user sessions having an associated determined utterance and corresponding interaction of a user. The method can also include validating the corresponding intent of one or more utterances of the set of utterances.</p><p id="p-0014" num="0013">In various embodiments of the present disclosure, a non-transitory computer readable medium is provided. The non-transitory computer readable medium can have instructions stored thereon, wherein the instructions, when executed by the one or more processors, cause a computing system or system to receive a first set of data, the first set of data including information indicating a first set of user sessions, each of the first set of user sessions having an associated summary and a corresponding agent indicated intent. Additionally, execution of the instructions can further cause the system to determine a set of utterances and for each of the set of utterances a corresponding set of intents, based on the first set of data. Moreover, execution of the instructions can further cause the system to receive a second set of data, the second set of data including information indicating a second set of user sessions, each of the second set of user sessions having an associated determined utterance and corresponding interaction of a user. The execution of the instructions can also cause the system to validate the corresponding intent of one or more utterances of the set of utterances.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0015" num="0014">The features and advantages of the present disclosures will be more fully disclosed in, or rendered obvious by the following detailed descriptions of example embodiments. The detailed descriptions of the example embodiments are to be considered together with the accompanying drawings wherein like numbers refer to like parts and further wherein:</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example network computer system for fine tuning an intent model;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates and example computing device of the example network computer system of <figref idref="DRAWINGS">FIG. <b>1</b></figref> in accordance with some embodiments;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates further aspects of an example intent sub-system;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a flow chart of an example method for fine tuning an intent model;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example user interface (UI) of a user session between a user and an artificial intelligence (AI) based agent;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a flow chart of an example method for aggregating training data;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example UI of a user session between a user and a human agent; and</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a flowchart of an example method of updating a currently displayed UI.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0024" num="0023">Throughout the drawings, identical reference numbers designate similar, but not necessarily identical elements. The figures are not necessarily to scale, and the size of some parts may be exaggerated to more clearly illustrate the example shown. Moreover, the drawings provide examples and/or implementations consistent with the description. However, the description is not limited to the examples and/or implementations provided in the drawings.</p><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0025" num="0024">The description of the embodiments is intended to be read in connection with the accompanying drawings, which are to be considered part of the entire written description of these disclosures. While the present disclosure is susceptible to various modifications and alternative forms, specific embodiments are shown by way of example in the drawings and will be described in detail herein. The objectives and advantages of the claimed subject matter will become more apparent from the following detailed description of these exemplary embodiments in connection with the accompanying drawings.</p><p id="p-0026" num="0025">It should be understood, however, that the present disclosure is not intended to be limited to the particular forms disclosed. Rather, the present disclosure covers all modifications, equivalents, and alternatives that fall within the spirit and scope of these exemplary embodiments. As provided herein, the terms &#x201c;user&#x201d; and &#x201c;customer,&#x201d; are used throughout this application interchangeably to describe a person utilizing an application (e.g., a user client or web application) on a computing device to interact with, such as to make requests or inquiries to, a network computer system (e.g., a customer help system). The terms &#x201c;couple,&#x201d; &#x201c;coupled,&#x201d; &#x201c;operatively coupled,&#x201d; &#x201c;connected,&#x201d; &#x201c;operatively connected,&#x201d; and the like should be broadly understood to refer to connecting devices or components together either mechanically, electrically, wired, wirelessly, or otherwise, such that the connection allows the pertinent devices or components to operate (e.g., communicate) with each other as intended by virtue of that relationship.</p><p id="p-0027" num="0026">In various examples, machine learning models can be trained on training datasets that include information about resolved user sessions. The training datasets can include data or information, such as a textual transcript of an interaction or conversation between a user and a human agent. Additionally, the human agent can add tags or labels for each subset of the training data set that corresponds to a resolved user session. The tags can indicate an intent or reason a user contacted the agent or interacted with a corresponding customer help system. However, training datasets that are tagged/labeled by human agents can be noisy and include ambiguous and misspelled labels. Additionally, machine learning models that are trained on such noisy training datasets can be inaccurate. Moreover, such training datasets may not be accommodating to new and evolving intents, and therefore cause the trained machine learning models to not be able to keep up with changing demands or evolving language (e.g., slang). Furthermore, unlike conventional approaches that require complex sampling techniques and can require crowd tagged data to remove or minimize the noise in such training datasets, the system and methods described herein are simpler, less burdensome to computational systems, without sacrificing the accuracy.</p><p id="p-0028" num="0027">Among other benefits, examples described herein provide for a network computer system that implements a process that utilizes feedback datasets or user feedback to fine tune a machine learning model trained to determine intents of a user based on determined utterances of a user input (e.g., text or audio based). For example, the network computer system can implement a process that retrains the trained machine learning model to discount noise (e.g., data/information that is meaningless) in older data which leads to an improved machine learning model. Such processes can not only improve the average query time of the trained machine learning model, but it can also improve or make more efficient the utilization of computing resources by the network computing systems (e.g., the network computing system uses less computing resources overall because the network computing system can more accurately route the user to the appropriate flow faster and with less intervening steps).</p><p id="p-0029" num="0028">For example, the network computer system can receive a first set of data or training data set that includes information regarding resolved user sessions, such as a summary pertaining to each resolved user session. Additionally, such information can include a corresponding intent tag or label. In various implementations, a human agent can tag each summary with an intent tag or label to indicate one or more reasons the user interacted with the user help system. However, training datasets that are tagged or labeled by a human agent can be noisy. The network computer system can utilize a feedback dataset or user feedback to discount the noise. For example, the network computer system can train a machine learning model using the first data set that includes information regarding resolved user sessions and corresponding agent tagged intent. Additionally, during sessions of other users, the network computer system can utilize the trained machine learning model to process an input of the users to determine an utterance, and one or more corresponding predicted intents. The network computer system can also present the predicted intents back to the users in the form of associated content (interactive graphical features) generated on the users' mobile device. Additionally, the network computer system can monitor the response or interactions between the users and the presented content. Based on the response of the users, the network computer system can confirm or verify which predicted intent of the presented predicted intents is the correct intent of the user. That way, the network computer system can utilize such response or interaction information to update or retrain the machine learning model to discount predicted intents that the users did not interact with when presented. In some implementations, the network computer system can disassociate the determined utterance from predicted intents that the user did no interact with.</p><p id="p-0030" num="0029">In various examples, such machine learning models can be utilized in user help systems of an ecommerce system to intelligently and automatically assist customers with issues occurring in a corresponding ecommerce system (e.g., tracking and order, starting a return, tracking a return, etc.). In some implementations, user help systems can be text or audio based. For such systems, machine learning models can be leveraged to help route customers to appropriate flows (e.g., starting returns, checking orders, etc.). For example, trained machine learning models can determine one or more utterances based on the user's input. Additionally, the trained machine learning models can also determine one or more intents of the user (e.g., the user's reason for interacting with the customer help system), based on the determined one or more utterances of the user. As such, such systems can route the user to an appropriate flow, based on the determined intent. For example, such systems can utilize a trained machine learning model to determine that a user's intent is to track a recent order based on determined utterance of &#x201c;where is my order?&#x201d; Additionally, based on the determined intent, the system can then route the user to an appropriate flow, such as a user interface where the user can view information regarding the status of their recent order.</p><p id="p-0031" num="0030">In either the text or audio based customer help systems, such trained machine learning models can determine one or more utterances from the user's text based or audio based inputs. For text based customer help systems, for example, machine learning models can process text inputted by a user into a chat feature of a user interface. For audio based customer help system, for example, machine learning models can process audio content provided by the user.</p><p id="p-0032" num="0031">With examples described, a network computer system can be implemented as, or otherwise utilize, a distributed computing system, where the machine learning models can be trained and fine-tuned, as described. In examples, a network computer system can include, or otherwise utilize user mobile devices to acquire information (e.g., interactions with intents) and/or display content corresponding to the determined predicted intents.</p><p id="p-0033" num="0032">One or more examples described herein provide that methods, techniques, and actions performed by a computing device are performed programmatically, or as a computer-implemented method. Programmatically, as used, means through the use of code or computer-executable instructions. These instructions can be stored in one or more memory resources of the computing device. A programmatically performed step may or may not be automatic.</p><p id="p-0034" num="0033">Additionally, one or more examples described herein can be implemented using programmatic modules, engines, or components. A programmatic module, engine, or component can include a program, a sub-routine, a portion of a program, or a software component or a hardware component capable of performing one or more stated tasks or functions. As used herein, a module or component can exist on a hardware component independently of other modules or components. Alternatively, a module or component can be a shared element or process of other modules, programs, or machines. Moreover, examples described herein can generally require the use of specialized computing devices, including processing and memory resources. For example, one or more examples described may be implemented, in whole or in part, on computing devices such as servers, desktop computers, cellular or smartphones, personal digital assistants (e.g., PDAs), laptop computers, printers, digital picture frames, network equipment (e.g., routers), wearable computing devices, and tablet devices. Memory, processing, and network resources may all be used in connection with the establishment, use, or performance of any example described herein (including with the performance of any method or with the implementation of any system). For instance, a computing device coupled to a data storage device storing the computer program and configured to execute the program corresponds to a special-purpose computing device. Furthermore, any computing systems referred to in the specification may include a single processor or may be architectures employing multiple processor designs for increased computing capability.</p><p id="p-0035" num="0034">Furthermore, one or more examples described herein may be implemented through the use of instructions that are executable by one or more processors. These instructions may be carried on a computer-readable medium. Machines shown or described with figures below provide examples of processing resources and computer-readable mediums on which instructions for implementing examples described can be carried and/or executed. In particular, the numerous machines shown with examples described include processor(s) and various forms of memory for holding data and instructions. Examples of computer-readable mediums include permanent memory storage devices, such as hard drives on personal computers or servers. Other examples of computer storage mediums include portable storage units, such as CD or DVD units, flash memory (such as carried on smartphones, multifunctional devices or tablets), and magnetic memory. Computers, terminals, network enabled devices (e.g., mobile devices, such as cell phones) are all examples of machines and devices that utilize processors, memory, and instructions stored on computer-readable mediums. Additionally, examples may be implemented in the form of computer-programs, or a computer usable carrier medium capable of carrying such a program.</p><p id="p-0036" num="0035">Alternatively, one or more examples described herein may be implemented through the use of dedicated hardware logic circuits that are comprised of an interconnection of logic gates. Such circuits are typically designed using a hardware description language (HDL), such as Verilog and VHDL. These languages contain instructions that ultimately define the layout of the circuit. However, once the circuit is fabricated, there are no instructions. All the processing is performed by interconnected gates.</p><heading id="h-0006" level="1">System Description</heading><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example network computer system to fine tuning an intent model. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, network computer system <b>100</b> and multiple mobile devices <b>140</b>, <b>150</b> and <b>160</b>, operatively coupled over network <b>130</b>. Network computer system <b>100</b> can maintain and train an intent model. In various examples, network computer system <b>100</b> can utilize information utilize data or information, such as user feedback, obtained from one or more mobile device <b>140</b>, <b>150</b> and <b>160</b>, to fine tune the intent model.</p><p id="p-0038" num="0037">In some examples, network computer system <b>100</b> can include intent sub-system <b>108</b>. Intent sub-system <b>108</b> can maintain, train and retrain/fine tune an intent model. In various implementations, intent sub-system <b>108</b> can train the intent model on a training dataset that includes information of summaries of resolved user sessions. Additionally, the training dataset can be tagged by human agents, such that each summary has a corresponding one or more intent tags. Each intent tag can indicate a reason a corresponding user interacted or contacted a user help system.</p><p id="p-0039" num="0038">A training dataset that is tagged by a human agent can be noisy (e.g., include data/information that is meaningless). As such, an intent model that is trained on such a training dataset can be inaccurate. The, for a trained intent model, network computer system <b>100</b> can remove or eliminate noise of the previous training dataset by utilizing a feedback dataset or user feedback. For example, intent sub-system <b>108</b> can obtain, from a mobile device (e.g., mobile device <b>140</b>, <b>150</b>), a feedback dataset including information about a user session. The information can indicate interactions between the user and a chat feature or interface of a user help system, such as any text inputted into the chat interface or any selectable features the user clicked on. The selectable features can be an interactive graphical representations corresponding to intents, intent sub-system <b>108</b> has predicted, based on utterances determined from the text inputted by the user.</p><p id="p-0040" num="0039">In some implementations, mobile devices <b>140</b>, <b>150</b> and <b>160</b> can be operated by users or human agents. Mobile devices <b>140</b>, <b>150</b> and <b>160</b> can each be any suitable computing device that includes any hardware or hardware and software combination for processing and handling information. For example, each can include one or more processors, one or more field-programmable gate arrays (FPGAs), one or more application-specific integrated circuits (ASICs), one or more state machines, digital circuitry, or any other suitable circuitry. In addition, each can transmit data to, and receive data from, network <b>130</b>. Additionally, mobile computing devices <b>140</b>, <b>150</b> and <b>160</b> can be each a cellular phone, a smart phone, a tablet, a personal assistant device, a voice assistant device, a digital assistant, a laptop, a computer, or any other suitable device. In some examples, network computer system <b>100</b> and mobile device <b>160</b> is operated and/or controlled by a retailer, and mobile device <b>140</b> and <b>150</b> are operated by customers of the retailer.</p><p id="p-0041" num="0040">With respect to examples as described, the network computer system <b>100</b> can be implemented on a server, on a combination of servers, and/or on a distributed set of computing devices which communicate over a network such as the Internet. Still further, some examples provide for the network computer system <b>100</b> to be distributed using one or more servers and/or mobile devices. In some variations, the network computer system <b>100</b> can be implemented as part of, or in connection with an ecommerce system <b>120</b>. In some examples, network computer system <b>100</b> can cause an ecommerce system to be displayed or otherwise communicated via one or more websites on mobile devices <b>140</b> and/or <b>150</b>. Users can view, browse and order items that may be made available via the ecommerce system through a mobile device (e.g., mobile device <b>140</b>, <b>150</b>).</p><p id="p-0042" num="0041">In various implementations, network computer system <b>100</b> can be a part of ecommerce system <b>120</b>. Ecommerce system <b>120</b> can include a user help system. In such examples, a user can utilize the help system to make requests/inquiries and report issues pertaining to their ecommerce marketplace experience (e.g., track an order, request status of their order, request a refund, etc.). For example, a user can access a user help system of ecommerce system <b>120</b> by logging onto a website of an ecommerce marketplace that is generated on an application (e.g., application <b>145</b>, <b>155</b>) executing on a mobile device (e.g., mobile device <b>140</b>, <b>150</b>). The user help system can include a chat feature or interface that can enable the user to interact with the help system through the application. For instance, the user can input text corresponding to an inquiry about the status of their order. In turn, a human based or AI based agent can assist and help resolve an issue the user maybe having (e.g., tracking an order, starting a refund, requesting a status of an order, etc.).</p><p id="p-0043" num="0042">In some implementations, network computer system <b>100</b> can leverage a machine learning model, such as an intent model, to intelligently and automatically assist users with ecommerce system related issues. For example, network computer system <b>100</b> can include intent sub-system <b>108</b> and flow sub-system <b>112</b> to intelligently and automatically route customers to appropriate flows that can help resolve the user's ecommerce system related issues (e.g., starting refunds, checking a status of an order, etc.).</p><p id="p-0044" num="0043">In some examples, intent sub-system <b>108</b> can be configured to maintain, train and fine tune an intent model. The intent model can determine one or more intents of a user based on the input of the user. Additionally, flow sub-system <b>112</b> can help route customers to appropriate flows based on the determined one or more intents. For example, a trained intent model can process input, such as text, a user provided through a chat feature or interface through a mobile device (e.g., mobile devices <b>140</b>, <b>150</b>). In some examples, the input, such as text, can be regarding an issue the user would like resolved. Based on the processed input, the trained intent model can determine one or more utterances and predict one or more intents of the user (e.g., a user's reasoning for interacting with the user help system) that may correspond to the one or more utterances. Additionally, flow sub-system <b>112</b> can utilize the determined one or more intents to determine a corresponding flow or resolution process. In various implementations, flow sub-system <b>112</b> can generate user interface instructions based on the determined corresponding flow. Additionally, flow sub-system <b>112</b> can transmit the user interface instructions to the mobile device (e.g., mobile device <b>140</b>, <b>150</b>). The user interface instructions can cause the mobile device to generate content and/or a sequence of user interfaces to enable the operating user to resolve their issue. In some examples, the content and/or sequence of user interfaces generated can guide the operating user to resolving their issue.</p><p id="p-0045" num="0044">In some implementations, network computer system <b>100</b> can include communication interface <b>102</b>. In some examples, the communication interface <b>102</b> can establish one or more communication channels with each mobile device <b>140</b>, <b>150</b> and <b>160</b>. In other examples, communication interface <b>102</b> can communicate with applications <b>145</b>, <b>155</b> and <b>165</b> to establish one or more communication channels with each of the corresponding mobile devices <b>140</b>, <b>150</b>, <b>160</b>. For example, communication interface <b>102</b> can use applications executing on the mobile devices of users to establish secure sockets from which different types of mobile devices can communicate information (e.g., user feedback, user interactions with graphical representations of intents, user interface instructions etc.). The communication interface <b>102</b> can receive feedback datasets, which can be utilized by intent sub-system <b>108</b> to fine tune or update a trained intent model. Additionally, communication interface <b>102</b> can receive training datasets that includes information of summaries of resolved user sessions and agent tagged intents. Such training datasets can be utilized by intent sub-system <b>108</b> to train an intent model. The received feedback datasets and the received training datasets can be stored in database <b>110</b>. Database <b>110</b> can be a remote storage device, such as a cloud-based server, a memory device on another application server, a networked computer, or any other suitable remote storage. In some implementations, database <b>110</b> can be a local storage device, such as a hard drive, a non-volatile memory, or a USB stick.</p><p id="p-0046" num="0045">In some examples, database <b>110</b> can store one or more machine learning models, such as an intent model. Additionally, intent sub-system <b>108</b> may maintain the most current or recently trained/retrained version of the one or more machine learning models in database <b>110</b>. In various implementations, database <b>110</b> stores a listing of predetermined utterances. Additionally, each predetermined utterance may be associated with one or more intent. In some examples, initially, the utterance-intent associations may be based on the training dataset obtained from mobile device <b>160</b> of a human agent. In other examples, intent sub-system <b>108</b> can update the utterance-intent associations based on feedback data. In some implementations, an utterance may be associated with multiple intents, where each of the multiple intents may have a corresponding weight or rank. The weight or rank can indicate an association strength between a particular intent an utterance (e.g., the higher the weight/rank, the stronger the association).</p><p id="p-0047" num="0046">Network <b>130</b> can be a WiFi&#xae; network, a cellular network such as a 3GPP&#xae; network, a Bluetooth&#xae; network, a satellite network, a wireless local area network (LAN), a network utilizing radio-frequency (RF) communication protocols, a Near Field Communication (NFC) network, a wireless Metropolitan Area Network (MAN) connecting multiple wireless LANs, a wide area network (WAN), or any other suitable network. Network <b>130</b> can provide access to, for example, the Internet.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example computing device <b>200</b>. Network computer system <b>100</b> and/or the customer mobile devices <b>140</b>, <b>150</b>, <b>160</b> may include the features shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. For the sake of brevity, <figref idref="DRAWINGS">FIG. <b>2</b></figref> is described relative to network computer system <b>100</b>. It should be appreciated, however, that the elements described can be included, as applicable, in mobile devices <b>140</b>, <b>150</b>, <b>160</b>.</p><p id="p-0049" num="0048">As shown, the network computer system <b>100</b> can be a computing device <b>200</b> that may include one or more processors <b>202</b>, working memory <b>204</b>, one or more input/output devices <b>206</b>, instruction memory <b>208</b>, a transceiver <b>212</b>, one or more communication ports <b>214</b>, and a display <b>216</b>, all operatively coupled to one or more data buses <b>210</b>. Data buses <b>210</b> allow for communication among the various devices. Data buses <b>210</b> can include wired, or wireless, communication channels.</p><p id="p-0050" num="0049">Processors <b>202</b> can include one or more distinct processors, each having one or more cores. Each of the distinct processors can have the same or different structure. Processors <b>202</b> can include one or more central processing units (CPUs), one or more graphics processing units (GPUs), application specific integrated circuits (ASICs), digital signal processors (DSPs), and the like.</p><p id="p-0051" num="0050">Processors <b>202</b> can be configured to perform a certain function or operation by executing code, stored on instruction memory <b>208</b>, embodying the function or operation. For example, processors <b>202</b> can be configured to perform one or more of any function, method, or operation disclosed herein.</p><p id="p-0052" num="0051">Instruction memory <b>208</b> can store instructions that can be accessed (e.g., read) and executed by processors <b>202</b>. For example, instruction memory <b>208</b> can be a non-transitory, computer-readable storage medium such as a read-only memory (ROM), an electrically erasable programmable read-only memory (EEPROM), flash memory, a removable disk, CD-ROM, any non-volatile memory, or any other suitable memory.</p><p id="p-0053" num="0052">Processors <b>202</b> can store data to, and read data from, working memory <b>204</b>. For example, processors <b>202</b> can store a working set of instructions to working memory <b>204</b>, such as instructions loaded from instruction memory <b>208</b>. Processors <b>202</b> can also use working memory <b>204</b> to store dynamic data created during the operation of computing device <b>200</b>. Working memory <b>204</b> can be a random access memory (RAM) such as a static random access memory (SRAM) or dynamic random access memory (DRAM), or any other suitable memory.</p><p id="p-0054" num="0053">Input/output devices <b>206</b> can include any suitable device that allows for data input or output. For example, input/output devices <b>206</b> can include one or more of a keyboard, a touchpad, a mouse, a stylus, a touchscreen, a physical button, a speaker, a microphone, or any other suitable input or output device.</p><p id="p-0055" num="0054">Communication port(s) <b>214</b> can include, for example, a serial port such as a universal asynchronous receiver/transmitter (UART) connection, a Universal Serial Bus (USB) connection, or any other suitable communication port or connection. In some examples, communication port(s) <b>214</b> allows for the programming of executable instructions in instruction memory <b>208</b>. In some examples, communication port(s) <b>214</b> allow for the transfer (e.g., uploading or downloading) of data, such as recommendation data and customer interaction data.</p><p id="p-0056" num="0055">Display <b>216</b> can display a user interface <b>218</b>. User interface <b>218</b> can enable user interaction with computing device <b>200</b>. For example, user interface <b>218</b> can be a user interface that allows an operator to interact, communicate, control and/or modify different features or parameters of computing device <b>200</b>. The user interface <b>218</b> can, for example, display the performance of the computing device <b>200</b> using different textual, graphical or other types of graphs, tables or the like. In some examples, a user can interact with user interface <b>218</b> by engaging input/output devices <b>206</b>. In some examples, display <b>216</b> can be a touchscreen, where user interface <b>218</b> is displayed on the touchscreen.</p><p id="p-0057" num="0056">Transceiver <b>212</b> allows for communication with a network, such as the network <b>130</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, if network <b>130</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a cellular network, transceiver <b>212</b> is configured to allow communications with the cellular network. In some examples, transceiver <b>212</b> is selected based on the type of network <b>130</b> network computer system <b>100</b> will be operating in. Processor(s) <b>202</b> is operable to receive data from, or send data to, a network, such as network <b>130</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, via transceiver <b>212</b>.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates further aspects of an example intent sub-system. Similar to the intent sub-system <b>108</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, intent sub-system <b>300</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> can maintain, train and fine tune or retrain an intent model. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, intent sub-system <b>300</b> can include intent engine <b>306</b>. Intent engine <b>306</b> can be configured to utilize a trained intent model to determine one or more utterances from a user input, such as text, and one or more corresponding predicted intents.</p><p id="p-0059" num="0058">In some implementations, intent sub-system <b>300</b> can include model training engine <b>304</b>. Model training engine <b>304</b> can train an intent model (stored in database <b>110</b>) on a training dataset that includes information of summaries of resolved user sessions. In some examples, a human agent can tag the training dataset so that it includes corresponding intents for each summary. Additionally, the agent can transmit, from mobile device <b>160</b>, the training dataset to network computer system <b>100</b>, over network <b>130</b>.</p><p id="p-0060" num="0059">A training dataset that is tagged by a human agent can be noisy (e.g., include data/information that is meaningless). As such, an intent model that is trained on the training dataset tagged by a human agent can be inaccurate. Intent sub-system <b>300</b> can remove or eliminate such noise by utilizing a feedback dataset. For example, a user of mobile device <b>140</b> can log onto a user help system of ecommerce system <b>120</b> and access a chat interface or feature. During the user's session on the chat interface, the user can make inquiries or requests pertaining to an issue they may have with the ecommerce system <b>120</b> by providing input, such as text, to the chat interface from mobile device <b>140</b>. Intent engine <b>306</b> can obtain such inputs, and utilizing the trained intent model, determine at least one utterance and a set of corresponding predicted intents. Additionally, intent engine <b>306</b> can transmit user interface instructions to mobile device <b>140</b> to cause application <b>145</b> to update the chat interface into include content related to the set of corresponding predicted intents. In some examples such content can include graphical representations of each of the set of corresponding predicted intents. For example, the intent can correspond to returns, and as such, the content generated can include interactive features, such as buttons, labeled &#x201c;Start a return&#x201d; or &#x201c;return policy.&#x201d;</p><p id="p-0061" num="0060">Mobile device <b>140</b> can transmit feedback data to intent sub-system <b>300</b>. The feedback data can include information indicating interactions that may have occurred on mobile device <b>140</b> between the user and any of the content of the set of corresponding predicted intents. For example, mobile device <b>140</b> can generate feedback data pertaining to whether the user interacted, such as clicked on, any of the &#x201c;start a return&#x201d; or &#x201c;return&#x201d; policy. In examples where the chat interface is being presented on a website hosted by ecommerce system <b>120</b>, network computer system <b>100</b> can monitor, through the website being accessed by mobile device <b>140</b>, interactions between the user and any of the presented content of the set of corresponding predicted intents. In such examples, network computer system <b>100</b> can generate feedback data that includes information of such interactions (e.g., whether the user interacted, such as clicked on, any of the &#x201c;start a return&#x201d; or &#x201c;return&#x201d; policy). In other examples, network computer system <b>100</b> can monitor the interactions between the user and any of the presented content of the set of corresponding predicted intents, through application <b>145</b>. In such examples, network computer system <b>100</b> can generate feedback data that includes information of such interactions (e.g., the user clicked on the &#x201c;start a return&#x201d; or &#x201c;return&#x201d; policy).</p><p id="p-0062" num="0061">Based on the feedback data, model training engine <b>304</b> can confirm or validate which of the predicted intents are to correspond to the determined utterance and which of the predicted intents are to be discounted. For example, model training engine <b>304</b> can obtain for a particular utterance, determination information from intent engine <b>306</b>. The determination information can indicate, for a particular iteration of the trained intent model, a determined utterance and a determined corresponding a set of predicted intents, such as &#x201c;starting a return,&#x201d; and &#x201c;tracking an order.&#x201d; Based on the feedback data, which indicates that the user clicked on selectable features corresponding to &#x201c;starting a return,&#x201d; the model training engine <b>304</b> can determine that the determined utterance corresponds to the intent &#x201c;starting a return,&#x201d; and not &#x201c;tracking an order.&#x201d; As such, based on such determinations, model training engine <b>304</b> can retrain the trained intent model such that, for that utterance, the corresponding intent is more likely pertaining to &#x201c;starting a return.&#x201d; Additionally, based on such determinations, model training engine <b>304</b> can retrain the trained intent model such that, for that utterance, the intents pertaining to &#x201c;tracking an order&#x201d; can be discounted/disassociated. In some implementations, the retrained intent model can be stored in database <b>110</b>.</p><p id="p-0063" num="0062">In some implementations, intent engine <b>306</b> can implement a process to rank and select intents in accordance with the likelihood that the intents correspond to the determined utterances. Such processes can initially be based on information from the training datasets. For example, intent engine <b>306</b> can utilize the training datasets to determine for each user session one or more utterances. Additionally, intent engine <b>306</b> can further determine, based on the agent indicated intent tags of each session, a frequency of an intent-utterance association/relationship. Such frequencies can be used to determine, for a given utterance, a weight for a particular intent. For example, the greater the frequency, the higher the weight or rank. In some examples, intent engine <b>306</b> can utilize a trained intent model to select a predetermined number of predicted intents that may correspond to a determined utterance, based on each predicted intents ranking. For example, intent engine <b>306</b> can utilize the trained intent model to select the top 2 ranked predicted intents that may correspond to the determined utterance.</p><p id="p-0064" num="0063">In some implementations, model training engine <b>304</b> can incorporate one or more template based rules when training the intent model. Template based rules can configure the intent model to select a particular intent based on a particular determined utterance. In some examples, some of the template based rules can pertain to simple default interactions such as &#x201c;contact agent,&#x201d; &#x201c;no,&#x201d; and &#x201c;yes.&#x201d; In other examples, a template based rule can pertain to new interactions. Such template based rules enable the intent model to adapt to new user behavior changes or new types of intents. For example, during a pandemic and the increase societal demand for testing and vaccines, a template based rules pertaining to testing for a particular illness or disease or a particular type of vaccination can be incorporated into the training of the intent model. The template based rule can map out, for example, a particular utterance and a corresponding new or emerging type of intent (e.g., setting up an appointment for a particular new type of vaccine).</p><heading id="h-0007" level="1">Methodology</heading><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a flow chart of an example method for fine tuning an intent model. <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a flow chart of an example method for aggregating training data. <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a flow chart for an example method of updating a user interface (UI). In describing an example of <figref idref="DRAWINGS">FIGS. <b>4</b>, <b>6</b> and <b>8</b></figref>, reference is made to elements of <figref idref="DRAWINGS">FIG. <b>1</b> or <b>3</b></figref> for purpose of illustrating a suitable component for performing a set or sub-step being described.</p><p id="p-0066" num="0065">With reference to example method <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, network computer system <b>100</b> can receives] a first set of data (<b>402</b>). The first set of data or training data can include information pertaining to resolved user sessions. For example, the information can include summaries of each resolved user session. Additionally, the first set of data can include agent tagged intents for each of the summaries.</p><p id="p-0067" num="0066">Based on the first set of data, network computer system <b>100</b> can determine a set of utterances, and for each of the set of utterances a corresponding set of intents (<b>404</b>). For example, model training engine <b>304</b> can utilize the first set of data or a training dataset to train an intent model. Additionally, intent engine <b>306</b> can utilize the trained intent model to initially determine which utterances are potentially associated with which one or sets of intents.</p><p id="p-0068" num="0067">Additionally, network computer system <b>100</b> can receive a second set of data (<b>404</b>). The second set of data or feedback data can include information indicating interactions that may have occurred on mobile device <b>140</b> between the user and any of the content of the set of corresponding predicted intents.</p><p id="p-0069" num="0068">For example, a user of mobile device <b>140</b> can log onto a user help system of ecommerce system <b>120</b> and access a chat interface or feature. During the user's session on the chat interface, the user can make inquiries or requests pertaining to an issue they may have with the ecommerce system <b>120</b> by providing input, such as text, to the chat interface from mobile device <b>140</b>. Intent engine <b>306</b> can obtain such inputs, and utilizing the trained intent model, determine at least one utterance and a set of corresponding predicted intents. Additionally, intent engine <b>306</b> can transmit user interface instructions to mobile device <b>140</b> to cause application <b>145</b> to update the chat interface into include content related to the set of corresponding predicted intents. In some examples such content can include graphical representations of each of the set of corresponding predicted intents. For example, the intent can correspond to returns, and as such, the content generated can include interactive features, such as buttons, labeled &#x201c;Start a return&#x201d; or &#x201c;return policy.&#x201d;</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example UI of a user session between a user and an AI-based agent. Example UI <b>500</b> illustrates an example UI chat interface, where a user is making an inquiry about an issue they have with the ecommerce system <b>120</b>, and an AI based agent is assisting the user to resolve the issue. In the chat interface, the user has provided input <b>504</b> that includes language pertaining to an issue they had with one of their orders. Additionally, the chat interface also includes a response <b>506</b> from an AI based agent. The response can be based off of determinations made by intent engine <b>306</b> utilizing a trained intent model. For example, based on the text of input <b>504</b>, intent engine <b>306</b> has determined two corresponding predicted intents&#x2014;&#x201c;start a return&#x201d; and &#x201c;return policy.&#x201d; As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, such intents, can be represented by an interactive graphical feature <b>508</b> and <b>510</b>. In some examples, intent engine <b>306</b> can transmit user interface instructions to a corresponding mobile device (e.g., mobile device <b>140</b>, <b>150</b>) that causes the mobile device to generate such graphical features.</p><p id="p-0071" num="0070">Additionally, intent sub-system <b>300</b> can monitor the interactions between the user and the presented content of the set of corresponding predicted intents. For example, turning to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, mobile device <b>140</b> can generate feedback data pertaining to whether the user interacted, such as clicked on, any of the graphical features <b>508</b> or <b>510</b> that represent &#x201c;start a return&#x201d; or &#x201c;return policy.&#x201d; In examples where the chat interface is being presented on a website hosted by ecommerce system <b>120</b>, network computer system <b>100</b> can monitor, through the website being accessed by mobile device <b>140</b>, interactions between the user and any of the presented content of the set of corresponding predicted intents. In such examples, network computer system <b>100</b> can generate feedback data that includes information of such interactions (e.g., whether the user interacted, such as clicked on, any of the &#x201c;start a return&#x201d; or &#x201c;return&#x201d; policy). In other examples, network computer system <b>100</b> can monitor the interactions between the user and any of the presented content of the set of corresponding predicted intents, through application <b>145</b>. In such examples, network computer system <b>100</b> can generate feedback data that includes information of such interactions (e.g., whether the user interacted, such as clicked on, any of the &#x201c;start a return&#x201d; or &#x201c;return&#x201d; policy).</p><p id="p-0072" num="0071">Based on the second set of data, network computer system <b>100</b> can validate a corresponding intent to one or more utterances of the set of utterances (<b>408</b>). For example, model training engine <b>304</b> can utilize the second set of data to confirm or validate which of the predicted intents are to correspond to the determined utterance and which of the predicted intents are to be discounted. For example, turning to the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, model training engine <b>304</b> can obtain, from intent engine <b>306</b>, a determined utterance based on the text of input <b>504</b>, and determination information. The determination information can indicate, for a particular iteration of the trained intent model, a determined utterance and a determined corresponding a set of predicted intents, such as &#x201c;starting a return,&#x201d; and &#x201c;return policy.&#x201d; Based on the feedback data, which indicates that the user clicked on selectable features corresponding to &#x201c;starting a return,&#x201d; the model training engine <b>304</b> can determine that the determined utterance corresponds to the intent &#x201c;starting a return,&#x201d; and not &#x201c;return policy.&#x201d; As such, based on such determinations, model training engine <b>304</b> can retrain the trained intent model such that, for that utterance, the corresponding intent is more likely pertaining to &#x201c;starting a return.&#x201d; Additionally, or alternatively, based on such determinations and taking into account the initially determined utterance-intents associations (see step <b>404</b>), model training engine <b>304</b> can retrain the trained intent model such that, for that utterance, the intents pertaining to &#x201c;return policy&#x201d; can be discounted/disassociated or even weighed less.</p><p id="p-0073" num="0072">With reference to example method <b>600</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, network computer system <b>100</b> can obtain multiple sets of session data (<b>602</b>). For example, model training engine <b>304</b> can obtain such multiple sets of session data. In some examples, each set of session data corresponds to a particular resolved user session between a user and an agent. In such examples, the agent can be human. Additionally, each set of session data can include information, such as a summary of a corresponding resolved user session and an identifier, such as a session ID. For example, a user of mobile device <b>150</b> can onto a user help system of ecommerce system <b>120</b> and access a chat interface or feature. During the user's session on the chat interface, the user can make inquiries or requests pertaining to an issue they may have with the ecommerce system <b>120</b> by providing input, such as text, to the chat interface from mobile device <b>140</b>. The input can be routed to an agent operating mobile device <b>160</b>. Additionally, the agent operating mobile device <b>160</b> can respond to and assist the user of mobile device <b>150</b> resolve their issue.</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an Example UI of a user session between a user and a human agent. Example UI <b>700</b> illustrates and example UI chat interface and a conversation between a user, such as a user of mobile device <b>150</b>, and an agent, such as an agent of mobile device <b>160</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, UI <b>702</b> includes the user's input <b>704</b> and <b>708</b>, and agent's input <b>706</b>. Graphical representation <b>708</b> can indicate that an agent and/or a user is currently inputting a response.</p><p id="p-0075" num="0074">Network computer system <b>100</b> can also obtain agent indicated intent data for each set of the multiple sets of session data (<b>604</b>). For example, model training engine <b>304</b> can obtain such agent indicated intent data for each set of the multiple sets of session data, from mobile device <b>160</b>. In some examples, the agent indicated intent data can include information indicating an intent and an identifier, such as a session ID.</p><p id="p-0076" num="0075">Additionally, network computer system <b>100</b> can match each set of session data of the multiple sets of session data with each set of agent indicated intent data (<b>606</b>). For example, model training engine <b>304</b> can match each set of session data with a corresponding set of agent indicated intent data based on the identifiers of each set of session data and the agent indicated intent data.</p><p id="p-0077" num="0076">Moreover, network computer system <b>100</b> can generate a first set of data based on the data of each set of session data that is matched to an agent indicated intent data. (<b>608</b>). For example, model training engine <b>304</b> can generate a first set of data or training data that includes information regarding user sessions. Additionally, the information of the user sessions, can pertain to resolved customer issues and the interaction between the user and a human agent. Moreover, the first set of data can include the agent indicated tags that correspond or match to each of the resolved user sessions.</p><p id="p-0078" num="0077">With reference to example method <b>800</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, network computer system <b>100</b> can detect an input of a user (<b>802</b>). In examples where the chat interface is being presented on a website hosted by ecommerce system <b>120</b>, network computer system <b>100</b> can monitor, through the website being accessed by mobile device (e.g., mobile device <b>140</b>, <b>150</b>), interactions between the user and any of the presented content of the set of corresponding predicted intents. In such examples, network computer system <b>100</b> can detect an input and generate feedback data that includes information of such interactions of a user of the mobile device. For example, referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, network computer system <b>100</b> can detect whether the user interacted with interactive graphical feature <b>508</b> or <b>510</b>. In other examples, network computer system <b>100</b> can detect an input of a user based on data transmitted from a mobile device (mobile device <b>140</b>, <b>150</b>). The data can include information indicating interactions that may have occurred through the mobile device between the user and any of the content of the set of corresponding predicted intents (e.g., interactive graphical feature <b>508</b> or <b>510</b>).</p><p id="p-0079" num="0078">Based on the input, network computer system <b>100</b> can determine interaction information (<b>804</b>). The interaction information can indicate interactions between the user and any content of the set of corresponding predicted intents. For example, in the chat feature or interface of a user help system context, interaction information can indicate which interactive graphical feature the user clicked on.</p><p id="p-0080" num="0079">Based on the determined interaction information, network computer system <b>100</b> can determine a corresponding set of selectable features (<b>806</b>). For example, network computer system <b>100</b> can determine content corresponding to an interactive graphical feature the user interacted with (e.g., clicked on). The content can include one or more, or a set of selectable features that can assist with resolving an issue of a user.</p><p id="p-0081" num="0080">Additionally, network computer system <b>100</b> can transmit user interface instructions to a mobile device of the user (<b>808</b>). In some examples, the user interface instructions can cause a mobile device of a user (e.g., mobile device <b>140</b>, <b>150</b>) to generate the determined content. In various implementations, the content can include one or more, or a set of selectable features that can assist with resolving an issue of a user. Additionally, or alternatively, the user interface instructions can cause the mobile device to generate content and/or a sequence of user interfaces to enable the operating user to resolve their issue. In some examples, the content and/or sequence of user interfaces generated can guide the operating user to resolving their issue.</p><p id="p-0082" num="0081">In addition, the methods and system described herein can be at least partially embodied in the form of computer-implemented processes and apparatus for practicing those processes. The disclosed methods may also be at least partially embodied in the form of tangible, non-transitory machine-readable storage media encoded with computer program code. For example, the steps of the methods can be embodied in hardware, in executable instructions executed by a processor (e.g., software), or a combination of the two. The media may include, for example, RAMs, ROMs, CD-ROMs, DVD-ROMs, BD-ROMs, hard disk drives, flash memories, or any other non-transitory machine-readable storage medium. When the computer program code is loaded into and executed by a computer, the computer becomes an apparatus for practicing the method. The methods may also be at least partially embodied in the form of a computer into which computer program code is loaded or executed, such that, the computer becomes a special purpose computer for practicing the methods. When implemented on a general-purpose processor, the computer program code segments configure the processor to create specific logic circuits. The methods may alternatively be at least partially embodied in application specific integrated circuits for performing the methods.</p><p id="p-0083" num="0082">The term model as used in the present disclosure includes data models created using machine learning. Machine learning may involve training a model in a supervised or unsupervised setting. Machine learning can include models that may be trained to learn relationships between various groups of data. Machine learned models may be based on a set of algorithms that are designed to model abstractions in data by using a number of processing layers. The processing layers may be made up of non-linear transformations. The models may include, for example, artificial intelligence, neural networks, deep convolutional and recurrent neural networks. Such neural networks may be made of up of levels of trainable filters, transformations, projections, hashing, pooling and regularization. The models may be used in large-scale relationship-recognition tasks. The models can be created by using various open-source and proprietary machine learning tools known to those of ordinary skill in the art.</p><p id="p-0084" num="0083">The foregoing is provided for purposes of illustrating, explaining, and describing embodiments of these disclosures. Modifications and adaptations to these embodiments will be apparent to those skilled in the art and may be made without departing from the scope or spirit of these disclosures.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system comprising:<claim-text>one or more processors;</claim-text><claim-text>a set of memory resources to store a set of instructions that when executed by the one or more processors, cause the system to:<claim-text>receive a first set of data, the first set of data including information indicating a first set of user sessions, each of the first set of user sessions having an associated summary and a corresponding agent indicated intent;</claim-text><claim-text>based on the first set of data, determine a set of utterances and for each of the set of utterances a corresponding set of intents;</claim-text><claim-text>receive a second set of data, the second set of data including information indicating a second set of user sessions, each of the second set of user sessions having an associated determined utterance and corresponding interaction information of a user; and</claim-text><claim-text>based on the second set of data, validate a corresponding intent of one or more utterances of the set of utterances.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein execution of the set of instructions, by the one or more processors, further cause the system to:<claim-text>based at least on the second set of data, retrain an intent model, wherein retraining the intent model includes, for each of the set of utterances, discounting one or more intents of the corresponding set of intents that were not validated.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein retraining the intent model is further based on the first set of data.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the set of utterances and for each utterance of the set of utterances the corresponding set of intents, is further based on one or more template based rules.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein execution of the set of instructions, by the one or more processors, further cause the system to:<claim-text>detect an input of a user;</claim-text><claim-text>determine an utterance from a plurality of predetermined utterances by processing the input;</claim-text><claim-text>based on the determined utterance from the plurality of predetermined utterances, the determined set of utterances, and for each of the set of utterances the corresponding set of intents, determine a set of predicted intents; and</claim-text><claim-text>based on the set of predicted intents, generate and transmit user interface instructions to a computing device of the user to cause an application executing on the computing device to generate, on a user interface, a graphical representation of each predicted intent of the set of predicted intents.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the interaction information indicates the user selected a generated graphical representation of one of the set of predicted intents.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein execution of the set of instructions, by the one or more processors, further causes the system to:<claim-text>detect a second input of the user, the second input of the user being indicative of an interaction with a generated graphical representation of one of the set of predicted intents;</claim-text><claim-text>based on the second input, determine a corresponding set of selectable features; and</claim-text><claim-text>transmit user interface instructions to the computing device of the user to cause the application executing on the computing device to update the user interface to include the corresponding set of selectable features.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein each of the set of selectable features are configured to cause the application to perform one or more service operations when interacted with.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A computer-implemented method comprising:<claim-text>receiving a first set of data, the first set of data including information indicating a first set of user sessions, each of the first set of user sessions having an associated summary and a corresponding agent indicated intent;</claim-text><claim-text>based on the first set of data, determining a set of utterances and for each of the set of utterances a corresponding set of intents;</claim-text><claim-text>receiving a second set of data, the second set of data including information indicating a second set of user sessions, each of the second set of user sessions having an associated determined utterance and corresponding interaction information of a user; and</claim-text><claim-text>based on the second set of data, validating a corresponding intent of one or more utterances of the set of utterances.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer-implemented method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising:<claim-text>based at least on the second set of data, retraining an intent model, wherein retraining the intent model includes, for each of the set of utterances, discounting one or more intents of the corresponding set of intents that were not validated.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The computer-implemented method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein retraining the intent model is further based on the first set of data.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computer-implemented method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein determining the set of utterances and for each utterance of the set of utterances the corresponding set of intents, is further based on one or more template based rules.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The computer-implemented method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising:<claim-text>detecting an input of a user;</claim-text><claim-text>determining an utterance from a plurality of predetermined utterances by processing the input;</claim-text><claim-text>based on the determined set of utterances and for each of the set of utterances the corresponding set of intents, determining a set of predicted intents; and</claim-text><claim-text>based on the set of predicted intents, generating and transmit user interface instructions to a computing device of the user to cause an application executing on the computing device to generate, on a user interface, a graphical representation of each predicted intent of the set of predicted intents.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The computer-implemented method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the interaction information indicates the user selected a generated graphical representation of one of the set of predicted intents.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The computer-implemented method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising:<claim-text>detecting a second input of the user, the second input of the user being indicative of an interaction with a generated graphical representation of one of the set of predicted intents;</claim-text><claim-text>based on the second input, determining a corresponding set of selectable features; and</claim-text><claim-text>transmitting user interface instructions to the computing device of the user to cause the application executing on the computing device to update the user interface to include the corresponding set of selectable features.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The computer-implemented method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein each of the set of selectable features are configured to cause the application to perform one or more service operations when interacted with.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A non-transitory computer readable medium having instructions stored thereon, wherein the instructions, when executed by one or more processors, cause a computing system to:<claim-text>receive a first set of data, the first set of data including information indicating a first set of user sessions, each of the first set of user sessions having an associated summary and a corresponding agent indicated intent;</claim-text><claim-text>based on the first set of data, determine a set of utterances and for each of the set of utterances a corresponding set of intents;</claim-text><claim-text>receive a second set of data, the second set of data including information indicating a second set of user sessions, each of the second set of user sessions having an associated determined utterance and corresponding interaction information of a user; and</claim-text><claim-text>based on the second set of data, validate a corresponding intent of one or more utterances of the set of utterances.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein execution of the instructions, by the one or more processors, further cause the computing system to:<claim-text>based at least on the second set of data, retrain an intent model, wherein retraining the intent model includes, for each of the set of utterances, discounting one or more intents of the corresponding set of intents that were not validated.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein determining the set of utterances and for each utterance of the set of utterances the corresponding set of intents, is further based on one or more template based rules.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein execution of the instructions, by the one or more processors, further cause the computing system to:<claim-text>detect an input of a user;</claim-text><claim-text>determine an utterance from a plurality of predetermined utterances by processing the input;</claim-text><claim-text>based on the determined set of utterances and for each of the set of utterances the corresponding set of intents, determine a set of predicted intents; and</claim-text><claim-text>based on the set of predicted intents, generate and transmit user interface instructions to a computing device of the user to cause an application executing on the computing device to generate, on a user interface, a graphical representation of each predicted intent of the set of predicted intents.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004989A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004989</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364859</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>62</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>30</main-group><subgroup>016</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>6215</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">CUSTOMER RECOGNITION SYSTEM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Intuit Inc.</orgname><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Zhao</last-name><first-name>Runhua</first-name><address><city>Milpitas</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Sikaria</last-name><first-name>Sonam</first-name><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Liu</last-name><first-name>Jaiyao</first-name><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Kang</last-name><first-name>Linhong</first-name><address><city>Sunnyvale</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Tang</last-name><first-name>Byron</first-name><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Rizvi</last-name><first-name>Bilal</first-name><address><city>Fremont</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method implements a customer recognition system. A request with an identifier of an unidentified user is received. Sparse data is generated from string information corresponding to the identifier. Preexisting identifiers are filtered to generate a list of candidate identifiers using the sparse data. The plurality of preexisting identifiers correspond to a plurality of preexisting users. A core identifier is selected by determining a match between the identifier and a preexisting identifier from the preexisting identifiers using distance information generated using the list of candidate identifiers. The core identifier is matched to the identifier using the match to identify the unidentified user as a preexisting user from the plurality of preexisting users.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="90.59mm" wi="158.75mm" file="US20230004989A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="161.63mm" wi="151.47mm" file="US20230004989A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="238.68mm" wi="152.23mm" orientation="landscape" file="US20230004989A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="118.79mm" wi="156.13mm" file="US20230004989A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="212.51mm" wi="114.89mm" file="US20230004989A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="211.75mm" wi="177.55mm" orientation="landscape" file="US20230004989A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="244.26mm" wi="178.39mm" file="US20230004989A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="228.60mm" wi="124.46mm" file="US20230004989A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Online services maintain accounts for users to verify access to the information and services provided by the online services. Users may be from different groups (different employees of the same organization, different members of the same household, etc.) and may use different devices, email addresses, usernames, etc., to create and access the accounts. A challenge is to recognize the same user or group of users creating and accessing accounts using different, and sometimes conflicting, identifying information and devices.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0003" num="0002">In general, in one or more aspects, the disclosure relates to a method that implements a customer recognition system. A request with an identifier is received of an unidentified user. Sparse data is generated from string information corresponding to the identifier. Preexisting identifiers are filtered to generate a list of candidate identifiers using the sparse data. The plurality of preexisting identifiers correspond to a plurality of preexisting users. A core identifier is selected by determining a match between the identifier and a preexisting identifier from the preexisting identifiers using distance information generated using the list of candidate identifiers. The core identifier is matched to the identifier using the match to identify the unidentified user as a preexisting user from the plurality of preexisting users.</p><p id="p-0004" num="0003">In general, in one or more aspects, the disclosure relates to a server that includes sparse models, ordinal models, and an application that executes on the server. A request with an identifier is received of an unidentified user. Sparse data is generated from string information corresponding to the identifier. Preexisting identifiers are filtered to generate a list of candidate identifiers using the sparse models and the sparse data. The plurality of preexisting identifiers correspond to a plurality of preexisting users. A core identifier is selected using the ordinal models by determining a match between the identifier and a preexisting identifier from the preexisting identifiers using distance information generated using the list of candidate identifiers. The core identifier is matched to the identifier using the match to identify the unidentified user as a preexisting user from the plurality of preexisting users.</p><p id="p-0005" num="0004">In general, in one or more aspects, the disclosure relates to a method of training machine learning models. Sparse models are trained, using training data, to convert strings from the training data into sparse matrices with columns corresponding to different n-grams. Ordinal models are trained, using the training data, to generate training probabilities from training distance information extracted from the training data. An identifier is received. Preexisting identifiers are filtered to a list of candidate identifiers using sparse data and the sparse models. The identifier is matched to one of the preexisting identifiers using distance information and the ordinal models.</p><p id="p-0006" num="0005">Other aspects of the invention will be apparent from the following description and the appended claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, and <figref idref="DRAWINGS">FIG. <b>1</b>C</figref> show diagrams of systems in accordance with disclosed embodiments.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a flowchart in accordance with disclosed embodiments.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> and <figref idref="DRAWINGS">FIG. <b>4</b></figref> show examples in accordance with disclosed embodiments.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>5</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> show computing systems in accordance with disclosed embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0011" num="0010">Specific embodiments of the invention will now be described in detail with reference to the accompanying figures. Like elements in the various figures are denoted by like reference numerals for consistency.</p><p id="p-0012" num="0011">In the following detailed description of embodiments of the invention, numerous specific details are set forth in order to provide a more thorough understanding of the invention. However, it will be apparent to one of ordinary skill in the art that the invention may be practiced without these specific details. In other instances, well-known features have not been described in detail to avoid unnecessarily complicating the description.</p><p id="p-0013" num="0012">Throughout the application, ordinal numbers (e.g., first, second, third, etc.) may be used as an adjective for an element (i.e., any noun in the application). The use of ordinal numbers is not to imply or create any particular ordering of the elements nor to limit any element to being only a single element unless expressly disclosed, such as by the use of the terms &#x201c;before&#x201d;, &#x201c;after&#x201d;, &#x201c;single&#x201d;, and other such terminology. Rather, the use of ordinal numbers is to distinguish between the elements. By way of an example, a first element is distinct from a second element, and the first element may encompass more than one element and succeed (or precede) the second element in an ordering of elements.</p><p id="p-0014" num="0013">Existing solutions use id-mapping technologies that rely on &#x201c;exact&#x201d; matching among identities to create clusters and universal identities. There is no practice using natural language processing (NLP) to identify distance for people's personal information (e.g., email addresses) and geolocations (e.g., location of internet protocol (IP) addresses). Embodiments of the disclosure combines the NLP as well as id-mapping technologies and has stronger prediction power.</p><p id="p-0015" num="0014">In general, customer recognition systems in accordance with the disclosure recognize the same users or groups of users even when the system is accessed using different devices and conflicting information. For example, a user may create an initial free account and then later attempt to create another free account to continue to access the services of the online provider. The initial account may be generated with identifying information that conflicts with the identifying information used to create the subsequent account. For example, the internet protocol (IP) address may be the same, but the email alias may be different. The system detects the same users or groups of users (e.g., companies) attempting to create new accounts. In response, the provider may link the older and newer accounts together or may direct a user to a previously created account.</p><p id="p-0016" num="0015">To identify an unidentified user as a preexisting user, embodiments of the invention use multiple machine learning models. Sparse data models are used to filter a list of preexisting users down to a list of candidates that might be the same person. Distances between personal information and geolocation information for the unidentified user and the candidates are generated with natural language processing models. Ordinal machine learning models are used to determine whether an unidentified user is one of the candidates of the preexisting users of the system.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>1</b>C</figref> show diagrams of embodiments that are in accordance with the disclosure. <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> shows a diagram of the system (<b>100</b>) that implements a customer recognition system. <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> shows a diagram of the server application (<b>115</b>). <figref idref="DRAWINGS">FIG. <b>1</b>C</figref> shows a diagram of the training application (<b>122</b>). The embodiments of <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>1</b>C</figref> may be combined and may include or be included within the features and embodiments described in the other figures of the application. The features and elements of <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>1</b>C</figref> are, individually and as a combination, improvements to machine learning and user identification technology and computing systems. The various elements, systems, and components shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>1</b>C</figref> may be omitted, repeated, combined, and/or altered as shown from <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>1</b>C</figref>. Accordingly, the scope of the present disclosure should not be considered limited to the specific arrangements shown in <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>1</b>B, and <b>1</b>C</figref>.</p><p id="p-0018" num="0017">Turning to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the system (<b>100</b>) detects users and groups of users that match with preexisting users and groups of users. The system (<b>100</b>) includes the client device A (<b>102</b>), the client device B (<b>108</b>), the server (<b>112</b>), and the repository (<b>125</b>). While depicted using a client server architecture, embodiments of the system (<b>100</b>) may be implemented on a single computing system.</p><p id="p-0019" num="0018">The client devices A (<b>102</b>) and B (<b>108</b>) are computing systems (further described in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>). For example, the client devices A (<b>102</b>) and B (<b>108</b>) may be desktop computers, mobile devices, laptop computers, tablet computers, etc. The client devices A (<b>102</b>) and B (<b>108</b>) respectively include the client application (<b>105</b>) and the developer application (<b>110</b>).</p><p id="p-0020" num="0019">The client application (<b>105</b>) and the developer application (<b>110</b>) are programs running on the client devices A (<b>102</b>) and B (<b>108</b>). The client application (<b>105</b>) is operated by user to access the server application (<b>115</b>) to generate and access accounts for online services that may be hosted by the server (<b>112</b>). The developer application (<b>110</b>) is used by a developer to operate the training application (<b>122</b>) to train the machine learning models of the system (<b>100</b>). The client application (<b>105</b>) and the developer application (<b>110</b>) may be native applications or may be browser applications that send and receive messages to and from the applications hosted by the server (<b>112</b>).</p><p id="p-0021" num="0020">The server (<b>112</b>) is a computing system (further described in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>). The server (<b>112</b>) may include multiple physical and virtual computing systems that form part of a cloud computing environment. In one embodiment, execution of the programs and applications of server (<b>112</b>) is distributed to multiple physical and virtual computing systems in the cloud computing environment. In one embodiment, the server (<b>112</b>) includes the server application (<b>115</b>) and the training application (<b>122</b>).</p><p id="p-0022" num="0021">The server application (<b>115</b>) is a collection of programs that may execute on the server (<b>112</b>). In one embodiment, the server application hosts a website accessed by the client application (<b>105</b>). The server application (<b>115</b>) includes the machine learning models (<b>117</b>), the filter (<b>118</b>), and the identifier selector (<b>120</b>).</p><p id="p-0023" num="0022">The machine learning models (<b>117</b>) are programs running as part of the server application (<b>115</b>). The machine learning models (<b>117</b>) may include the sparse models (<b>145</b>) of <figref idref="DRAWINGS">FIG. <b>1</b>B</figref> and the ordinal models (<b>162</b>) of <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>.</p><p id="p-0024" num="0023">The filter (<b>118</b>) is a program running as part of the server application (<b>115</b>). The filter (<b>118</b>) filters the preexisting identifiers (<b>130</b>) using the identifying information (<b>128</b>) to identify a list of users that match to the user of the client device A (<b>102</b>).</p><p id="p-0025" num="0024">The identifier selector (<b>120</b>) is a program running as part of the server application (<b>115</b>). The identifier selector (<b>120</b>) selects identifiers for the users of the system (<b>100</b>).</p><p id="p-0026" num="0025">The training application (<b>122</b>) is a collection of programs that may execute on the server (<b>112</b>). The training application (<b>122</b>) trains the machine learning models used by the system (<b>100</b>) and may be controlled by the developer application (<b>110</b>).</p><p id="p-0027" num="0026">The repository (<b>125</b>) is a computing system that may include multiple computing devices in accordance with the computing system (<b>500</b>) and the nodes (<b>522</b>) and (<b>524</b>) described below in <figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref>. The repository (<b>125</b>) may be hosted by a cloud services provider that also hosts the server (<b>112</b>). The cloud services provider may provide hosting, virtualization, and data storage services as well as other cloud services and to operate and control the data, programs, and applications that store and retrieve data from the repository (<b>125</b>). The data in the repository (<b>125</b>) includes the account information (<b>127</b>), the identifying information (<b>128</b>), the preexisting identifiers (<b>130</b>), and the training data (<b>132</b>).</p><p id="p-0028" num="0027">The account information (<b>127</b>) includes information for the accounts of the users of the system. The account information (<b>127</b>) may identify the services to which a user has access. The account information (<b>127</b>) may also include usernames, email addresses, physical addresses, access logs, user device information, etc., for the users of the system (<b>100</b>).</p><p id="p-0029" num="0028">The identifying information (<b>128</b>) includes information that identifies a user of the system (<b>100</b>). The identifying information (<b>128</b>) include the information about a user when the user attempts to access the system (<b>100</b>). For example, the identifying information (<b>128</b>) may include the names of users, email aliases (the portion of an email without the domain name and before the &#x201c;@&#x201d;), physical address information (number, street name, city, state, etc.), location information (geolocation coordinates, internet protocol (IP) address location mapping, etc.), and digital profile information (e.g., device identifier, operating system identifier, access history, etc.).</p><p id="p-0030" num="0029">The preexisting identifiers (<b>130</b>) are identifiers for preexisting users that have already accessed the system (<b>100</b>) and may already have an account. In one embodiment, the preexisting identifiers (<b>130</b>) are core identifiers. Core identifiers are identifiers that are assigned to the users of the system to uniquely identify the users of the system. Users that have created an account with the system may be referred to as preexisting users and the core identifiers of the preexisting users may be referred to as preexisting identifiers. Additionally, when an unidentified user attempts to access the system, the system identifies a subset of the preexisting users, referred to as candidate users, that may be the same person as the unidentified user. The core identifiers for the candidate users may be referred to as candidate identifiers. Each core identifier has a group identifier and a personal identifier. The group identifier is the same for a group of related users (e.g., same organization or household). The personal identifier is unique to a person within a group.</p><p id="p-0031" num="0030">The training data (<b>132</b>) is the data used to train the machine learning models (<b>117</b>) of the system (<b>100</b>). The training data may include training inputs and labels.</p><p id="p-0032" num="0031">Turning to <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, the server application selects the core identifier (<b>168</b>) based on the identifying information (<b>128</b>). The identifying information (<b>128</b>) is received by the server application (<b>115</b>) from the client application (<b>105</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>) and corresponds to a user (referred to as an unidentified user) accessing the system (<b>100</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>).</p><p id="p-0033" num="0032">The string information (<b>142</b>) is extracted from the identifying information (<b>128</b>). The string information (<b>142</b>) may include multiple different types of string data. In one embodiment, the string information (<b>142</b>) includes the name of the user (e.g., &#x201c;Alan Schaefer&#x201d;), an email alias (e.g., &#x201c;dutch&#x201d; from the email address &#x201c;dutch@predator.com&#x201d;), and a physical address (e.g., a street address).</p><p id="p-0034" num="0033">The sparse models (<b>145</b>) are natural language processing models that generate the sparse data (<b>146</b>) from the string information (<b>142</b>). The sparse models (<b>145</b>) are a subset of the machine learning models (<b>117</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>). Each different type of string data (name, alias, address, etc.) may use a different sparse model from the sparse models (<b>145</b>). In one embodiment, the sparse models (<b>145</b>) are n-gram models that identify the n-grams in the different types of string data from the string information (<b>142</b>). N-grams are combinations of characters in a string. For example, the string &#x201c;dutch&#x201d; includes the trigrams (an n-gram with three characters) &#x201c;dut&#x201d;, &#x201c;utc&#x201d;, and &#x201c;tch&#x201d; and includes the 4-grams &#x201c;dutc&#x201d; and &#x201c;utch&#x201d;.</p><p id="p-0035" num="0034">In one embodiment, the sparse data (<b>146</b>) includes sparse matrices that identify the n-grams in the string information (<b>142</b>). The sparse data (<b>146</b>) includes sparse matrices generated from the identifying information (<b>128</b>) for a user accessing the system (<b>100</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>). The sparse data (<b>146</b>) also includes sparse matrices for the same type of string data for the preexisting users that already have accounts on the system (<b>100</b>). For example, sparse data (<b>146</b>) may include sparse matrices identifying the n-grams for the name, email alias, and physical address for the user accessing the system (<b>100</b>) and for the preexisting users with established accounts.</p><p id="p-0036" num="0035">The sparse models (<b>145</b>) generate the comparison data (<b>147</b>) from the sparse data (<b>146</b>). For example, the sparse models (<b>145</b>) may multiply the sparse matrices generated from the identifying information (<b>128</b>) by the sparse matrices generated from the account information of preexisting users.</p><p id="p-0037" num="0036">The comparison data (<b>147</b>) includes a data structure that identifies the preexisting users with string data that is similar to the string information (<b>142</b>) for the user accessing the system. In one embodiment, the different types of string data are concatenated into a single data structure for the comparison data.</p><p id="p-0038" num="0037">The preexisting identifiers (<b>130</b>) are identifiers for the preexisting users of the system (<b>100</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>). The preexisting identifiers (<b>130</b>) is used to identify the account information (<b>127</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>) that corresponds to the preexisting users.</p><p id="p-0039" num="0038">The filter (<b>118</b>) identifies the list of candidate identifiers (<b>150</b>) from the comparison data (<b>147</b>) and the preexisting identifiers (<b>130</b>). In one embodiment, the filter (<b>118</b>) identifies a threshold number of best matches for each type of string data from the string information (<b>142</b>). For example, the filter (<b>118</b>) may select the five names that best match the name from the identifying information (<b>128</b>), identify the five preexisting identifiers from the preexisting identifiers (<b>130</b>) that correspond with those names, and include those five preexisting identifiers as candidate identifiers in the list of candidate identifiers (<b>150</b>). The same may be done for the email alias and physical address, which may have different thresholds (e.g., best 4 matches, best 3 matches, etc.).</p><p id="p-0040" num="0039">The list of candidate identifiers (<b>150</b>) is a subset of the preexisting identifiers (<b>130</b>). The list of candidate identifiers (<b>150</b>) identifies the preexisting users (also referred to as candidate users) of the system that may be the same person or in the same group as the user accessing the system with the identifying information (<b>128</b>).</p><p id="p-0041" num="0040">The feature extractor (<b>152</b>) uses the identifying information (<b>128</b>) and the list of candidate identifiers (<b>150</b>) to generate the distance information (<b>155</b>). The feature extractor (<b>152</b>) extracts string information, location information, and numeric information from the identifying information (<b>128</b>) and from the account information (<b>127</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>) that corresponds to the identifiers from the list of candidate identifiers (<b>150</b>).</p><p id="p-0042" num="0041">The distance information (<b>155</b>) identifies the distances between data from the identifying information (<b>128</b>) for the unidentified user and data for the candidate users corresponding to the list of candidate identifiers (<b>150</b>). Distances are calculated for each pairing of the unidentified user with a candidate user. The distance information (<b>155</b>) includes the string distances (<b>156</b>), the location distances (<b>157</b>), and the numeric distances (<b>158</b>).</p><p id="p-0043" num="0042">The string distances (<b>156</b>) are the distances between string data for the unidentified user (from the identifying information (<b>128</b>)) and string data for the candidate users (identified with the list of candidate identifiers). For example, with the string data for a name, distances are calculated between the name of the unidentified user and the names of the candidate users. The string distances (<b>156</b>) may include distances for names, email aliases, physical addresses, etc. Multiple distances may be calculated for each type of string.</p><p id="p-0044" num="0043">Multiple phonetic algorithms (soundex, NYSIIS (New York State Information and Intelligence Systems), double metaphone, etc.) may be used to calculate the distances. The phonetic representation of a string replaces the original groups of characters from the original string with phonetic groups of characters that identify the sound made when pronouncing the original groups of characters. The phonetic representations use the same group of characters for different groups of characters with the same sound. For example, &#x201c;to&#x201d;, &#x201c;two&#x201d;, and &#x201c;too&#x201d;, which each sound the same, may be represented by &#x201c;to&#x201d; in a phonetic string.</p><p id="p-0045" num="0044">The distances may be calculated using the Levenshtein distance algorithm, which identifies the minimum number of single-character edits required to change one string into the other. As applied here, for the name of a user, the Levenshtein distance may be calculated for the original string data, for the soundex representation, for the NYSIIS representation, and the double metaphone representation.</p><p id="p-0046" num="0045">The location distances (<b>157</b>) are the distances between the location of the user and the locations of the candidate users. The location distances (<b>157</b>) may include distances between the IP address locations, physical address locations, satellite positioning locations, etc., of the unidentified and candidate users. The IP addresses of the unidentified and candidate users may be mapped to physical locations, which may be mapped to longitude and latitude or satellite positioning coordinates.</p><p id="p-0047" num="0046">The numeric distances (<b>158</b>) are the distances between the information from the digital profiles of the unidentified and candidate users. The distances may be binary. For example, if the unidentified user and a candidate user each use the same operating system, the &#x201c;distance&#x201d; may be &#x201c;1&#x201d; (and &#x201c;0&#x201d; when different).</p><p id="p-0048" num="0047">The ordinal models (<b>162</b>) generate the probabilities (<b>165</b>) using the distance information (<b>155</b>). The ordinal models (<b>162</b>) are a subset of the machine learning models (<b>117</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>). The ordinal models (<b>162</b>) may use multiple different algorithms, including decision trees, support vector machines, random forests, logistic regression, etc.</p><p id="p-0049" num="0048">In one embodiment, the probabilities (<b>165</b>) are a set of ordinal probabilities with the categories of &#x201c;same person&#x201d;, &#x201c;same group&#x201d;, &#x201c;not sure&#x201d;, and &#x201c;not the same&#x201d;. The outputs from each of the ordinal models (<b>162</b>) may be combined to form the probabilities (<b>165</b>). In one embodiment, the outputs are averaged to form a data structure as a vector of probabilities with four elements, one for each of the categories &#x201c;same person&#x201d;, &#x201c;same group&#x201d;, &#x201c;not sure&#x201d;, and &#x201c;not the same&#x201d;. A vector of probabilities is generated for each pairing of the unidentified user with a candidate user.</p><p id="p-0050" num="0049">The identifier selector (<b>120</b>) generates the core identifier (<b>168</b>) using the list of candidate identifiers (<b>150</b>) and the probabilities (<b>165</b>). When the probabilities (<b>165</b>) indicate that the unidentified user (corresponding to the identifying information (<b>128</b>)) is the same as one of the candidate users (corresponding to a candidate identifier from the list of candidate identifiers (<b>150</b>)), the identifier selector (<b>120</b>) may select the core identifier (<b>168</b>) to be the same as the identifier for the candidate user. When the probabilities (<b>165</b>) indicate that the unidentified user is part of the same group as one of the candidate users, the identifier selector (<b>120</b>) may select the core identifier (<b>168</b>) to have the group identifier (<b>169</b>) be the same as the group identifier of the matching candidate user. When the probabilities (<b>165</b>) indicate that the unidentified user is not the same user and not the same group, the identifier selector (<b>120</b>) may select the core identifier (<b>168</b>) to have the group identifier (<b>169</b>) that is different from the group identifiers of the preexisting users of the system (<b>100</b>).</p><p id="p-0051" num="0050">The core identifier (<b>168</b>) is assigned to the unidentified user by the identifier selector (<b>120</b>). The core identifier (<b>168</b>) includes the group identifier (<b>169</b>) and the personal identifier (<b>170</b>). The group identifier (<b>169</b>) identifies a group of users that are from the same entity or household. The personal identifier (<b>170</b>) identifies one user within a group of users.</p><p id="p-0052" num="0051">Turning to <figref idref="DRAWINGS">FIG. <b>1</b>C</figref>, the training application (<b>122</b>) trains the machine learning models (<b>117</b>). The machine learning models (<b>117</b>) include the sparse models (<b>145</b>) and the ordinal models (<b>162</b>). The training application (<b>122</b>) may train each of the models individually.</p><p id="p-0053" num="0052">The training data (<b>132</b>) for the sparse models (<b>145</b>) includes string information for the preexisting users of the system. The training data (<b>132</b>) for the ordinal models (<b>162</b>) includes distance information generated from the account information of preexisting users. The training data (<b>132</b>) for the ordinal models (<b>162</b>) also includes labels to identify if two users are the same user, are in the same group, or are not the same.</p><p id="p-0054" num="0053">The machine learning models (<b>117</b>) generate the training outputs (<b>172</b>) in response to the training data (<b>132</b>). Training output for the sparse models (<b>145</b>) includes the sparse matrices for the string data of preexisting users. Training output for the ordinal models (<b>162</b>) includes sets of ordinal probabilities.</p><p id="p-0055" num="0054">The model update functions (<b>175</b>) update the machine learning models (<b>117</b>) based on the training outputs (<b>172</b>) and the training data (<b>132</b>). The sparse models (<b>145</b>) may be updated to use different types of n-grams (e.g., 3-gram and 4-gram models). The ordinal models (<b>162</b>) may be updated using gradient descent to generate more accurate outputs based on the error between the output from the ordinal models (<b>162</b>) and the labels for the inputs to the ordinal models (<b>162</b>).</p><p id="p-0056" num="0055">The label update application (<b>178</b>) updates the training data (<b>132</b>) based on the training outputs (<b>172</b>). The label update application (<b>178</b>) may identify input data that was incorrectly identified or identified as the category labeled &#x201c;not sure&#x201d; and present the input data to a developer using the developer application (<b>110</b>) (of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>). The developer may identify the correct label for the input data, which is stored to the training data (<b>132</b>).</p><p id="p-0057" num="0056">When training the ordinal models (<b>162</b>), different models may be used during different phases of training. In a first phase, a decision tree model may be used to generate an initial set of labels. In subsequent phases, different models, including logistic regression, support vector machine, and random forest models may be used after the initial set of labels are generated using the initial model (e.g., the decision tree).</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows flowchart of processes in accordance with the disclosure. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart of a method of a customer recognition system. The embodiments of <figref idref="DRAWINGS">FIG. <b>2</b></figref> may be combined and may include or be included within the features and embodiments described in the other figures of the application. The features of <figref idref="DRAWINGS">FIG. <b>2</b></figref> are, individually and as an ordered combination, improvements to machine learning and user identification technology and computing systems. While the various steps in the flowcharts are presented and described sequentially, one of ordinary skill will appreciate that at least some of the steps may be executed in different orders, may be combined or omitted, and at least some of the steps may be executed in parallel. Furthermore, the steps may be performed actively or passively. For example, some steps may be performed using polling or be interrupt driven. By way of an example, determination steps may not have a processor process an instruction unless an interrupt is received to signify that condition exists. As another example, determinations may be performed by performing a test, such as checking a data value to test whether the value is consistent with the tested condition.</p><p id="p-0059" num="0058">Turning to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the process (<b>200</b>) assigns core identifiers to unidentified users. The process (<b>200</b>) may execute as part of a server application on a server.</p><p id="p-0060" num="0059">At Step <b>202</b>, a request with an identifier of an unidentified user is received. The request may be from a client application running on a client device. The client application may be operated by an unidentified user attempting to access the system. The request may also include identifying information linked to the unidentified user. The identifying information may include a name of the user, email address, location information, digital profile information, etc.</p><p id="p-0061" num="0060">At Step <b>204</b>, sparse data is generated from string information corresponding to the identifier. The string information is extracted from the identifying information for the unidentified user. The sparse data includes sparse matrices generated with sparse machine learning models (i.e., sparse models) from the identifying information (for the unidentified user) and from the account information (for the preexisting users).</p><p id="p-0062" num="0061">At Step <b>206</b>, a plurality of preexisting identifiers is filtered to generate a list of candidate identifiers using sparse data generated from string information corresponding to the identifier. The plurality of preexisting identifiers correspond to a plurality of preexisting users. The preexisting identifiers are core identifiers that identify the preexisting users of the system and link to the account information of the preexisting users. The candidate identifiers are core identifiers that identify candidate users that may match with the unidentified user.</p><p id="p-0063" num="0062">In one embodiment, the sparse data is generated by converting the string information to sparse matrices. The string information may include multiple types of string data (e.g., name, email alias, physical address, etc.), a sparse matrix may be generated for each type of string data, and the different sparse matrices may be combined, e.g., by being concatenated together.</p><p id="p-0064" num="0063">In one embodiment, the sparse matrices are generated using a plurality of n-gram machine learning models. For example, 3-gram (character sequences with three characters) and 4-gram (character sequences with four characters) models may be used to generate the columns of the sparse matrices. Each column of a sparse matrix may be linked to a specific n-gram (e.g. &#x201c;joh&#x201d;, &#x201c;bet&#x201d;, &#x201c;anne&#x201d;, etc.) to identify if the input includes the specific n-gram. For example, the input string &#x201c;john&#x201d; includes the n-gram &#x201c;joh&#x201d; but not the n-grams &#x201c;bet&#x201d; or &#x201c;anne&#x201d; so the column for &#x201c;joh&#x201d; may be set to &#x201c;1&#x201d; and the columns for &#x201c;bet&#x201d; and &#x201c;anne&#x201d; may be set to &#x201c;0&#x201d;.</p><p id="p-0065" num="0064">In one embodiment, multiple sparse models are trained, using training data, to convert strings (from the training data) into sparse matrices with columns corresponding n-grams. The sparse models are trained to identify and use a selected set of n-grams. In one embodiment, a sparse model may identify a threshold number of 3-grams and 4-grams (e.g., about 10,000) with the lowest frequency from the training data. Different sparse models may be trained for each type of string data (e.g., name, alias, address, etc.).</p><p id="p-0066" num="0065">In one embodiment, the preexisting identifiers are filtered by comparing sparse matrices and identifying the list of candidate identifiers. A sparse matrix for the unidentified user (i.e., from the sparse data that corresponds to the identifier) is compared to sparse matrices for the preexisting users (i.e., from the sparse data that corresponds to the preexisting identifiers) to generate comparison data. The comparison data and a threshold are used to identify the list of candidates. In one embodiment, the comparison data is a matrix generated from multiplying the sparse matrix for the candidate user by a sparse matrix for the pre-existing users. The comparison data is sorted to identify the preexisting users with information that most closely matches the identifying information of the unidentified user. The preexisting users that are better matches have more n-grams in common with the unidentified user.</p><p id="p-0067" num="0066">At Step <b>208</b>, a core identifier is selected by determining a match between the identifier and one of the preexisting identifiers using distance information generated using the list of candidate identifiers. The distance information is generated for each pairing of the unidentified user with a candidate user. The distance information identifies the distance between information about the unidentified user with information about a preexisting user. For example, the names of the users may be used with the distance identified as the Levenshtein distance between the names of the users.</p><p id="p-0068" num="0067">In one embodiment, the distance information includes string distances between strings from the string information, location distances between physical locations identified from the identifying information, and numeric distances between digital profile values from the identifying information. The string distances may include the Levenshtein distance between strings for the actual names of the users and the Levenshtein distance between strings for phonetic representations of the names of the users. The location distances may also include the distance between the locations identified from the street addresses of the users, locations identified from the IP addresses of the users, locations identified from satellite positioning coordinates of the users. The numeric distances may be based on the differences (i.e., distance) between the digital profiles of the unidentified user and candidate users and use binary values to identify that two users are either the same or different.</p><p id="p-0069" num="0068">In one embodiment, the core identifier is selected by generating, from the distance information, sets of probabilities corresponding to the candidate identifiers from the list of candidate identifiers. The distance information for two users (i.e., the unidentified user and one of the candidate users) is input too multiple ordinal machine learning models. Each of the models outputs a set of ordinal probabilities. The probabilities from the different models may be combined by being averaged together to form a final set of probabilities. In one embodiment, each of the sets of probabilities includes a probability for one of the categories of &#x201c;same person&#x201d;, &#x201c;same group&#x201d;, &#x201c;not sure&#x201d;, and &#x201c;not the same&#x201d;.</p><p id="p-0070" num="0069">A match between the unidentified user and one of the candidate users is then based on the final set of probabilities. For example, when the probability for &#x201c;same person&#x201d; category is the highest of the set of probabilities, the unidentified user may be identified as a match with the corresponding candidate user. When the probability for the &#x201c;same group&#x201d; category is the highest of the set of probabilities, the users may be different, but are identified as being part of the same organization or household. When the probability for the &#x201c;not sure&#x201d; or &#x201c;not the same&#x201d; categories have the highest probability of the set of probabilities, the users do not match.</p><p id="p-0071" num="0070">In one embodiment, multiple ordinal models are trained using training data to generate training probabilities from training distance information extracted from the training data. The training probabilities are sets of probabilities generated during training. The training distance information is distance information generated, during training, from the account information for the preexisting users. Multiple different models may be trained for each type of distance information, including decision trees, support vector machines, random forests, logistic regression, etc.</p><p id="p-0072" num="0071">At Step <b>210</b>, a core identifier is matched to the identifier of the unidentified user using the match to identify the unidentified user as a preexisting user from preexisting users of the system. The core identifier matched to the unidentified user may include a group identifier and a personal identifier that are the same as the group identifiers and personal identifiers for the candidate users.</p><p id="p-0073" num="0072">When the match indicates that the unidentified user is one of the candidate users, then the core identifier assigned to the unidentified user is the same as the core identifier assigned to the candidate user. I.e., the unidentified user and the candidate user have the same group identifiers and personal identifiers.</p><p id="p-0074" num="0073">When the match indicates that the unidentified user is part of the same group as a candidate user, the core identifier assigned to the unidentified user includes the group identifier from the core identifier of the candidate user. A new personal identifier, for the group identified with the group identifier, is generated to distinguish the unidentified user from the other preexisting users that have the same group identifier.</p><p id="p-0075" num="0074">When the match indicates that the unidentified user is not the same person and not in the same group, the core identifier assigned to the unidentified user includes a new group identifier. The personal identifier, of the core identifier assigned to the unidentified user, may be used by other preexisting users that are in different groups and have different group identifiers.</p><p id="p-0076" num="0075">In one embodiment, the request is received as a registration request to register an account for the unidentified user. The registration request may be denied using matches between the unidentified user and the candidate users. For example, when the unidentified user matches as either the same person or the same group as one of the candidate users, the registration request may be denied to prevent the unidentified user from creating a new account.</p><p id="p-0077" num="0076">In one embodiment, account information corresponding to the core identifier is presented in response to the request. For example, the request may be a registration request that is denied and the system may send a response describing the denial of the request. When the request is denied, the user may be given the option to log into the preexisting account. In one embodiment, when the unidentified user matches with a candidate user, the unidentified user may be allowed to link the new account to the preexisting account.</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> show examples of systems and sequences that use private information with a shared single source of truth. <figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example of determining the core identifier (<b>355</b>) using identifying information from the request information (<b>300</b>). <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example of a user attempting to create multiple accounts. The embodiments shown in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> may be combined and may include or be included within the features and embodiments described in the other figures of the application. The features and elements of <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> are, individually and as a combination, improvements to machine learning and user identification technology and computing systems. The various features, elements, widgets, components, and interfaces shown in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> may be omitted, repeated, combined, and/or altered as shown. Accordingly, the scope of the present disclosure should not be considered limited to the specific arrangements shown in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref>.</p><p id="p-0079" num="0078">Turning to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the core identifier (<b>355</b>) is assigned to an unidentified user based on the request information (<b>300</b>). The unidentified user may be attempting to access a computing system by issuing an access request that is linked to the request information (<b>300</b>).</p><p id="p-0080" num="0079">From the request information (<b>300</b>), the name A (<b>301</b>), the alias A (<b>302</b>), and the address A (<b>303</b>) are input to the sparse models A (<b>308</b>), B (<b>309</b>), and C (<b>310</b>) to generate the sparse matrices A (<b>312</b>), B (<b>313</b>), and C (<b>314</b>). The sparse matrices A (<b>312</b>), B (<b>313</b>), and C (<b>314</b>) and the sparse data (<b>318</b>) are input to the filter (<b>320</b>). The sparse data (<b>318</b>) includes sparse matrices for the names, aliases, and addresses of the preexisting users of the system.</p><p id="p-0081" num="0080">The filter (<b>320</b>) generates the list of candidates (<b>322</b>) using the sparse matrices A (<b>312</b>), B (<b>313</b>), and C (<b>314</b>) and the sparse data (<b>318</b>). The filter (<b>320</b>) identifies the preexisting users that have name, alias, and address information that is similar to the name A (<b>301</b>), alias A (<b>302</b>), and address A (<b>303</b>) of the request information (<b>300</b>) for the unidentified user. The preexisting users with the highest similarity (referred to as candidate users) are identified in the list of candidates (<b>322</b>).</p><p id="p-0082" num="0081">After identifying the list of candidates (<b>322</b>), the feature extractor (<b>332</b>) extracts features (the distance information (<b>333</b>)) from the request information (<b>300</b>) and the account information for the candidate users. Sets of distance information are generated for each pairing of the unidentified user and one of the candidate users from the list of candidates (<b>322</b>). The distance information (<b>333</b>) corresponds to the request information (<b>300</b>) (for the unidentified user) paired with the candidate information (<b>325</b>) (for one of the candidate users). The candidate information (<b>325</b>) includes the name B (<b>326</b>), the alias B (<b>327</b>), the address B (<b>328</b>), the location B (<b>329</b>), and the digital profile B (<b>330</b>) for one of the candidate users identified in the list of candidates (<b>322</b>).</p><p id="p-0083" num="0082">The distance information (<b>333</b>) includes multiple distances between data from the request information (<b>300</b>) and the candidate information (<b>325</b>). The distance information (<b>333</b>) includes the name distances (<b>335</b>), the alias distances (<b>336</b>), the address distances (<b>337</b>), the location distances (<b>338</b>), and the digital profile distances (<b>339</b>).</p><p id="p-0084" num="0083">The name distances (<b>335</b>) are the distances between the names A (<b>301</b>) and B (<b>326</b>). The names A (<b>301</b>) and B (<b>326</b>) are the names of the unidentified user and the candidate user. The names A (<b>301</b>) and B (<b>326</b>) may be converted to phonetic representations. In one embodiment, the name distances (<b>335</b>) includes the Levenshtein distances names A (<b>301</b>) and B (<b>326</b>) and one or more phonetic versions of the names A (<b>301</b>) and B (<b>326</b>).</p><p id="p-0085" num="0084">The alias distances (<b>336</b>) are the distances between the aliases A (<b>302</b>) and B (<b>327</b>). The aliases A (<b>302</b>) and B (<b>327</b>) are the aliases extracted from the email addresses of the unidentified user and the candidate user. The alias distances (<b>336</b>) include the Levenshtein distances between the aliases A (<b>302</b>) and B (<b>327</b>) and one or more phonetic versions of the aliases A (<b>302</b>) and B (<b>327</b>).</p><p id="p-0086" num="0085">The address distances (<b>337</b>) are the distances between the addresses A (<b>303</b>) and B (<b>328</b>). The addresses A (<b>303</b>) and B (<b>328</b>) are the physical (e.g., street) addresses for the unidentified user and the candidate user. The address distances (<b>337</b>) include the Levenshtein distances between the aliases A (<b>302</b>) and B (<b>327</b>) and one or more phonetic versions of the aliases A (<b>302</b>) and B (<b>327</b>). In one embodiment, the address distances (<b>337</b>) does not include distances using phonetic versions of the aliases A (<b>302</b>) and B (<b>327</b>).</p><p id="p-0087" num="0086">The location distances (<b>338</b>) are the distances between the locations A (<b>304</b>) and B (<b>329</b>). The locations A (<b>304</b>) and B (<b>329</b>) may include multiple types of location data. The location data may be generated from IP addresses for the unidentified user in the candidate user. The location data may also include coordinates generated by a satellite positioning receiver. The location distances (<b>338</b>) include distances between the unidentified user and the candidate user for each type of location data. The distances is may identify the longitudinal and latitudinal distances between the unidentified user and the candidate user.</p><p id="p-0088" num="0087">The digital profile distances (<b>339</b>) are the distances between the digital profiles A (<b>305</b>) and B (<b>330</b>). The digital profiles A (<b>305</b>) and B (<b>330</b>) include information about the unidentified user and the candidate user. For example, the digital profiles may include identifiers for the type of operating system, the type of client device, the type of client application, etc. A digital profile may also include the browser history of a user. The digital profile distances (<b>339</b>) include binary values that identify if the information from the digital profiles A (<b>305</b>) and B (<b>330</b>) are the same.</p><p id="p-0089" num="0088">The distance information (<b>333</b>) is input to each of the machine learning models A (<b>342</b>), B (<b>345</b>), and C (<b>348</b>). Each of the machine learning models A (<b>342</b>), B (<b>345</b>), and C (<b>348</b>) generate a set of probabilities that are combined to form the combined probabilities (<b>350</b>). The sets of probabilities include probabilities for the categories of &#x201c;same person&#x201d;, &#x201c;same group&#x201d;, &#x201c;not sure&#x201d;, and &#x201c;not the same&#x201d;. In one embodiment, the output from the machine learning models A (<b>342</b>), B (<b>345</b>), and C (<b>348</b>) are averaged to form the combined probabilities (<b>350</b>).</p><p id="p-0090" num="0089">The combined probabilities (<b>350</b>) are input to the selector (<b>352</b>). The selector (<b>352</b>) generates the core identifier (<b>355</b>) using the combined probabilities (<b>350</b>). The selector (<b>352</b>) receives a set of combined probabilities for each of the candidate users identified in the list of candidates (<b>322</b>). When a candidate user matches to the unidentified user as the same person, the core identifier (<b>355</b>) assigned to the unidentified user is the same as the core identifier for the candidate users. When a candidate user matches to the unidentified user as being in the same group, the core identifier (<b>355</b>) for the unidentified user includes the same group identifier as for the candidate user. When the candidate users do not match the unidentified user, the core identifier (<b>355</b>) includes a group identifier that is different from the group identifiers for the preexisting users of the system.</p><p id="p-0091" num="0090">Turning to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a first user successfully creates an initial account with the server (<b>400</b>). A second user attempts to create a new account later, which is detected by the server (<b>400</b>) as being the same person as the first user. The user interacts with a client device to interact with the web pages (<b>402</b>), (<b>415</b>), (<b>422</b>), and (<b>435</b>) from the server (<b>400</b>).</p><p id="p-0092" num="0091">The web page (<b>402</b>), from the server (<b>400</b>), is used to submit information for a new account. The first user inputs identifying information including the name (<b>405</b>), the email address (<b>408</b>), and the address (<b>410</b>). Upon selection of the submit button (<b>412</b>), the identifying information is submitted to the server (<b>400</b>).</p><p id="p-0093" num="0092">The server (<b>400</b>) processes the identifying information to determine if the first user (treated as an unidentified user) is a preexisting user. As described in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the server (<b>400</b>) runs a process to identify a list of candidates from sparse data generated from string information. With the list of candidates, the server (<b>400</b>) generates distance information that is input to machine learning models to identify a match between the unidentified first user and one of the candidate users.</p><p id="p-0094" num="0093">For the first user, no match is found, the first user is assigned a core identifier with a new group identifier, and the web page (<b>415</b>) is presented by the server (<b>400</b>). Selection of the button (<b>418</b>) proceeds with allowing the first user to access the system using the newly created account.</p><p id="p-0095" num="0094">Later, the web page (<b>422</b>) is presented by the server (<b>400</b>) to a second user (who is unidentified by the system) attempting to create another new account. The second user submits a second set of identifying information including the name (<b>425</b>), the email (<b>428</b>), and the address (<b>430</b>). Upon selection of the submit button (<b>432</b>), the second set of identifying information is submitted to the server (<b>400</b>).</p><p id="p-0096" num="0095">The server (<b>400</b>) processes the second set of identifying information. The list of candidates identifies the first user as a preexisting user based on the similarities in the email aliases (&#x201c;dutch&#x201d;) of the email addresses (<b>408</b>) and (<b>428</b>) and the similarities in the address (&#x201c;Hollywood, California&#x201d;). Distance information is generated that indicates the same IP address at the same location is also being used. The distance information is input to the machine learning models that identify the second user as being the same person as the first user.</p><p id="p-0097" num="0096">For the second user, after being matched to the first user, the same core identifier of the first user is assigned to the second user and the web page (<b>435</b>) is presented. Selection of the confirm button (<b>438</b>) allows the second user to confirm that the preexisting account is correct and access the system using the previously created account.</p><p id="p-0098" num="0097">Embodiments of the invention may be implemented on a computing system. Any combination of a mobile, a desktop, a server, a router, a switch, an embedded device, or other types of hardware may be used. For example, as shown in FIG. <b>5</b>A, the computing system (<b>500</b>) may include one or more computer processor(s) (<b>502</b>), non-persistent storage (<b>504</b>) (e.g., volatile memory, such as a random access memory (RAM), cache memory), persistent storage (<b>506</b>) (e.g., a hard disk, an optical drive such as a compact disk (CD) drive or a digital versatile disk (DVD) drive, a flash memory, etc.), a communication interface (<b>512</b>) (e.g., Bluetooth interface, infrared interface, network interface, optical interface, etc.), and numerous other elements and functionalities.</p><p id="p-0099" num="0098">The computer processor(s) (<b>502</b>) may be an integrated circuit for processing instructions. For example, the computer processor(s) (<b>502</b>) may be one or more cores or micro-cores of a processor. The computing system (<b>500</b>) may also include one or more input device(s) (<b>510</b>), such as a touchscreen, a keyboard, a mouse, a microphone, a touchpad, an electronic pen, or any other type of input device.</p><p id="p-0100" num="0099">The communication interface (<b>512</b>) may include an integrated circuit for connecting the computing system (<b>500</b>) to a network (not shown) (e.g., a local area network (LAN), a wide area network (WAN) such as the Internet, a mobile network, or any other type of network) and/or to another device, such as another computing device.</p><p id="p-0101" num="0100">Further, the computing system (<b>500</b>) may include one or more output device(s) (<b>508</b>), such as a screen (e.g., a liquid crystal display (LCD), a plasma display, a touchscreen, a cathode ray tube (CRT) monitor, a projector, or other display device), a printer, an external storage, or any other output device. One or more of the output device(s) (<b>508</b>) may be the same or different from the input device(s) (<b>510</b>). The input and output device(s) (<b>510</b> and (<b>508</b>)) may be locally or remotely connected to the computer processor(s) (<b>502</b>), non-persistent storage (<b>504</b>), and persistent storage (<b>506</b>). Many different types of computing systems exist, and the aforementioned input and output device(s) (<b>510</b> and (<b>508</b>)) may take other forms.</p><p id="p-0102" num="0101">Software instructions in the form of computer readable program code to perform embodiments of the invention may be stored, in whole or in part, temporarily or permanently, on a non-transitory computer readable medium such as a CD, a DVD, a storage device, a diskette, a tape, flash memory, physical memory, or any other computer readable storage medium. Specifically, the software instructions may correspond to computer readable program code that, when executed by a processor(s), is configured to perform one or more embodiments of the invention.</p><p id="p-0103" num="0102">The computing system (<b>500</b>) in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> may be connected to or be a part of a network. For example, as shown in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, the network (<b>520</b>) may include multiple nodes (e.g., node X (<b>522</b>), node Y (<b>524</b>)). Each node may correspond to a computing system, such as the computing system (<b>500</b>) shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, or a group of nodes combined may correspond to the computing system (<b>500</b>) shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>. By way of an example, embodiments of the invention may be implemented on a node of a distributed system that is connected to other nodes. By way of another example, embodiments of the invention may be implemented on a distributed computing system having multiple nodes, where each portion of the invention may be located on a different node within the distributed computing system. Further, one or more elements of the aforementioned computing system (<b>500</b>) may be located at a remote location and connected to the other elements over a network.</p><p id="p-0104" num="0103">Although not shown in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, the node may correspond to a blade in a server chassis that is connected to other nodes via a backplane. By way of another example, the node may correspond to a server in a data center. By way of another example, the node may correspond to a computer processor or micro-core of a computer processor with shared memory and/or resources.</p><p id="p-0105" num="0104">The nodes (e.g., node X (<b>522</b>), node Y (<b>524</b>)) in the network (<b>520</b>) may be configured to provide services for a client device (<b>526</b>). For example, the nodes may be part of a cloud computing system. The nodes may include functionality to receive requests from the client device (<b>526</b>) and transmit responses to the client device (<b>526</b>). The client device (<b>526</b>) may be a computing system, such as the computing system (<b>500</b>) shown in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>. Further, the client device (<b>526</b>) may include and/or perform all or a portion of one or more embodiments of the invention.</p><p id="p-0106" num="0105">The computing system (<b>500</b>) or group of computing systems described in <figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> may include functionality to perform a variety of operations disclosed herein. For example, the computing system(s) may perform communication between processes on the same or different system. A variety of mechanisms, employing some form of active or passive communication, may facilitate the exchange of data between processes on the same device. Examples representative of these inter-process communications include, but are not limited to, the implementation of a file, a signal, a socket, a message queue, a pipeline, a semaphore, shared memory, message passing, and a memory-mapped file. Further details pertaining to a couple of these non-limiting examples are provided below.</p><p id="p-0107" num="0106">Based on the client-server networking model, sockets may serve as interfaces or communication channel end-points enabling bidirectional data transfer between processes on the same device. Foremost, following the client-server networking model, a server process (e.g., a process that provides data) may create a first socket object. Next, the server process binds the first socket object, thereby associating the first socket object with a unique name and/or address. After creating and binding the first socket object, the server process then waits and listens for incoming connection requests from one or more client processes (e.g., processes that seek data). At this point, when a client process wishes to obtain data from a server process, the client process starts by creating a second socket object. The client process then proceeds to generate a connection request that includes at least the second socket object and the unique name and/or address associated with the first socket object. The client process then transmits the connection request to the server process. Depending on availability, the server process may accept the connection request, establishing a communication channel with the client process, or the server process, busy in handling other operations, may queue the connection request in a buffer until server process is ready. An established connection informs the client process that communications may commence. In response, the client process may generate a data request specifying the data that the client process wishes to obtain. The data request is subsequently transmitted to the server process. Upon receiving the data request, the server process analyzes the request and gathers the requested data. Finally, the server process then generates a reply including at least the requested data and transmits the reply to the client process. The data may be transferred, more commonly, as datagrams or a stream of characters (e.g., bytes).</p><p id="p-0108" num="0107">Shared memory refers to the allocation of virtual memory space in order to substantiate a mechanism for which data may be communicated and/or accessed by multiple processes. In implementing shared memory, an initializing process first creates a shareable segment in persistent or non-persistent storage. Post creation, the initializing process then mounts the shareable segment, subsequently mapping the shareable segment into the address space associated with the initializing process. Following the mounting, the initializing process proceeds to identify and grant access permission to one or more authorized processes that may also write and read data to and from the shareable segment. Changes made to the data in the shareable segment by one process may immediately affect other processes, which are also linked to the shareable segment. Further, when one of the authorized processes accesses the shareable segment, the shareable segment maps to the address space of that authorized process. Often, only one authorized process may mount the shareable segment, other than the initializing process, at any given time.</p><p id="p-0109" num="0108">Other techniques may be used to share data, such as the various data described in the present application, between processes without departing from the scope of the invention. The processes may be part of the same or different application and may execute on the same or different computing system.</p><p id="p-0110" num="0109">Rather than or in addition to sharing data between processes, the computing system performing one or more embodiments of the invention may include functionality to receive data from a user. For example, in one or more embodiments, a user may submit data via a graphical user interface (GUI) on the user device. Data may be submitted via the graphical user interface by a user selecting one or more graphical user interface widgets or inserting text and other data into graphical user interface widgets using a touchpad, a keyboard, a mouse, or any other input device. In response to selecting a particular item, information regarding the particular item may be obtained from persistent or non-persistent storage by the computer processor. Upon selection of the item by the user, the contents of the obtained data regarding the particular item may be displayed on the user device in response to the user's selection.</p><p id="p-0111" num="0110">By way of another example, a request to obtain data regarding the particular item may be sent to a server operatively connected to the user device through a network. For example, the user may select a uniform resource locator (URL) link within a web client of the user device, thereby initiating a Hypertext Transfer Protocol (HTTP) or other protocol request being sent to the network host associated with the URL. In response to the request, the server may extract the data regarding the particular selected item and send the data to the device that initiated the request. Once the user device has received the data regarding the particular item, the contents of the received data regarding the particular item may be displayed on the user device in response to the user's selection. Further to the above example, the data received from the server after selecting the URL link may provide a web page in Hyper Text Markup Language (HTML) that may be rendered by the web client and displayed on the user device.</p><p id="p-0112" num="0111">Once data is obtained, such as by using techniques described above or from storage, the computing system, in performing one or more embodiments of the invention, may extract one or more data items from the obtained data. For example, the extraction may be performed as follows by the computing system (<b>500</b>) in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>. First, the organizing pattern (e.g., grammar, schema, layout) of the data is determined, which may be based on one or more of the following: position (e.g., bit or column position, Nth token in a data stream, etc.), attribute (where the attribute is associated with one or more values), or a hierarchical/tree structure (consisting of layers of nodes at different levels of detail-such as in nested packet headers or nested document sections). Then, the raw, unprocessed stream of data symbols is parsed, in the context of the organizing pattern, into a stream (or layered structure) of tokens (where each token may have an associated token &#x201c;type&#x201d;).</p><p id="p-0113" num="0112">Next, extraction criteria are used to extract one or more data items from the token stream or structure, where the extraction criteria are processed according to the organizing pattern to extract one or more tokens (or nodes from a layered structure). For position-based data, the token(s) at the position(s) identified by the extraction criteria are extracted. For attribute/value-based data, the token(s) and/or node(s) associated with the attribute(s) satisfying the extraction criteria are extracted. For hierarchical/layered data, the token(s) associated with the node(s) matching the extraction criteria are extracted. The extraction criteria may be as simple as an identifier string or may be a query presented to a structured data repository (where the data repository may be organized according to a database schema or data format, such as XML).</p><p id="p-0114" num="0113">The extracted data may be used for further processing by the computing system. For example, the computing system (<b>500</b>) of <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, while performing one or more embodiments of the invention, may perform data comparison. Data comparison may be used to compare two or more data values (e.g., A, B). For example, one or more embodiments may determine whether A&#x3e;B, A=B, A !=B, A&#x3c;B, etc. The comparison may be performed by submitting A, B, and an opcode specifying an operation related to the comparison into an arithmetic logic unit (ALU) (i.e., circuitry that performs arithmetic and/or bitwise logical operations on the two data values). The ALU outputs the numerical result of the operation and/or one or more status flags related to the numerical result. For example, the status flags may indicate whether the numerical result is a positive number, a negative number, zero, etc. By selecting the proper opcode and then reading the numerical results and/or status flags, the comparison may be executed. For example, in order to determine if A&#x3e;B, B may be subtracted from A (i.e., A&#x2212;B), and the status flags may be read to determine if the result is positive (i.e., if A&#x3e;B, then A&#x2212;B&#x3e;0). In one or more embodiments, B may be considered a threshold, and A is deemed to satisfy the threshold if A=B or if A&#x3e;B, as determined using the ALU. In one or more embodiments of the invention, A and B may be vectors, and comparing A with B requires comparing the first element of vector A with the first element of vector B, the second element of vector A with the second element of vector B, etc. In one or more embodiments, if A and B are strings, the binary values of the strings may be compared.</p><p id="p-0115" num="0114">The computing system (<b>500</b>) in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> may implement and/or be connected to a data repository. For example, one type of data repository is a database. A database is a collection of information configured for ease of data retrieval, modification, re-organization, and deletion. A Database Management System (DBMS) is a software application that provides an interface for users to define, create, query, update, or administer databases.</p><p id="p-0116" num="0115">The user, or software application, may submit a statement or query into the DBMS. Then the DBMS interprets the statement. The statement may be a select statement to request information, update statement, create statement, delete statement, etc. Moreover, the statement may include parameters that specify data, or data container (database, table, record, column, view, etc.), identifier(s), conditions (comparison operators), functions (e.g., join, full join, count, average, etc.), sort (e.g., ascending, descending), or others. The DBMS may execute the statement. For example, the DBMS may access a memory buffer, a reference or index a file for read, write, deletion, or any combination thereof, for responding to the statement. The DBMS may load the data from persistent or non-persistent storage and perform computations to respond to the query. The DBMS may return the result(s) to the user or software application.</p><p id="p-0117" num="0116">The computing system (<b>500</b>) of <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> may include functionality to present raw and/or processed data, such as results of comparisons and other processing. For example, presenting data may be accomplished through various presenting methods. Specifically, data may be presented through a user interface provided by a computing device. The user interface may include a GUI that displays information on a display device, such as a computer monitor or a touchscreen on a handheld computer device. The GUI may include various GUI widgets that organize what data is shown as well as how data is presented to a user. Furthermore, the GUI may present data directly to the user, e.g., data presented as actual data values through text, or rendered by the computing device into a visual representation of the data, such as through visualizing a data model.</p><p id="p-0118" num="0117">For example, a GUI may first obtain a notification from a software application requesting that a particular data object be presented within the GUI. Next, the GUI may determine a data object type associated with the particular data object, e.g., by obtaining data from a data attribute within the data object that identifies the data object type. Then, the GUI may determine any rules designated for displaying that data object type, e.g., rules specified by a software framework for a data object class or according to any local parameters defined by the GUI for presenting that data object type. Finally, the GUI may obtain data values from the particular data object and render a visual representation of the data values within a display device according to the designated rules for that data object type.</p><p id="p-0119" num="0118">Data may also be presented through various audio methods. In particular, data may be rendered into an audio format and presented as sound through one or more speakers operably connected to a computing device.</p><p id="p-0120" num="0119">Data may also be presented to a user through haptic methods. For example, haptic methods may include vibrations or other physical signals generated by the computing system. For example, data may be presented to a user using a vibration generated by a handheld computer device with a predefined duration and intensity of the vibration to communicate the data.</p><p id="p-0121" num="0120">The above description of functions presents only a few examples of functions performed by the computing system (<b>500</b>) of <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> and the nodes (e.g., node X (<b>522</b>), node Y (<b>524</b>)) and/or client device (<b>526</b>) in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>. Other functions may be performed using one or more embodiments of the invention.</p><p id="p-0122" num="0121">While the invention has been described with respect to a limited number of embodiments, those skilled in the art, having benefit of this disclosure, will appreciate that other embodiments can be devised which do not depart from the scope of the invention as disclosed herein. Accordingly, the scope of the invention should be limited only by the attached claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>receiving a request with an identifier of an unidentified user;</claim-text><claim-text>generating sparse data from string information corresponding to the identifier;</claim-text><claim-text>filtering a plurality of preexisting identifiers to generate a list of candidate identifiers using the sparse data, wherein the plurality of preexisting identifiers correspond to a plurality of preexisting users;</claim-text><claim-text>selecting a core identifier by determining a match between the identifier and a preexisting identifier from the plurality of preexisting identifiers using distance information generated using the list of candidate identifiers; and</claim-text><claim-text>matching the core identifier to the identifier using the match to identify the unidentified user as a preexisting user from the plurality of preexisting users.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving the request as a registration request to register an account; and</claim-text><claim-text>denying the registration request using the match.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>presenting account information corresponding to the core identifier in response to the request.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>generating the sparse data by converting the string information to sparse matrices, wherein the sparse matrices form the sparse data.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>converting the string information to sparse matrices using a plurality of n-gram machine learning models.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a plurality of sparse models are trained, using training data, to convert strings, from the training data, into sparse matrices with columns corresponding to a plurality of n-grams.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>filtering the plurality of preexisting identifiers by:<claim-text>comparing a sparse matrix, from the sparse data and corresponding to the identifier, to a plurality of sparse matrices, from the sparse data and corresponding to the preexisting identifiers, to generate comparison data; and</claim-text><claim-text>identifying the list of candidate identifiers using the comparison data and a threshold.</claim-text></claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>generating the distance information, wherein the distance information includes string distances between strings from the string information, location distances between physical locations identified from identifying information, and numeric distances between digital profile values from the identifying information.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>selecting the core identifier by:<claim-text>generating, from the distance information, sets of probabilities corresponding to the candidate identifiers from the list of candidate identifiers.</claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>selecting the core identifier by:<claim-text>identifying a candidate identifier, from the list of candidate identifiers, as the core identifier when a selected probability from a set of probabilities, generated from the distance information, corresponds to a first category.</claim-text></claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>selecting the core identifier by:</claim-text><claim-text>generating the core identifier with a group identifier from a candidate identifier, from the list of candidate identifiers, when a selected probability from a set of probabilities, generated from the distance information, corresponds to a second category.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>selecting the core identifier by:<claim-text>generating the core identifier, which is different from the candidate identifiers of the list of candidate identifiers, when a selected probability from a set of probabilities, generated from the distance information, corresponds to a third category.</claim-text></claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising, wherein a plurality of ordinal models are trained, using training data, to generate training probabilities from training distance information extracted from the training data.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A server comprising:<claim-text>a plurality of sparse models;</claim-text><claim-text>a plurality of ordinal models;</claim-text><claim-text>an application;</claim-text><claim-text>the application executing on the server and configured for:<claim-text>receiving a request with an identifier of an unidentified user;</claim-text><claim-text>generating sparse data from string information corresponding to the identifier;</claim-text><claim-text>filtering a plurality of preexisting identifiers to generate a list of candidate identifiers using the plurality of sparse models and the sparse data, wherein the plurality of preexisting identifiers correspond to a plurality of preexisting users;</claim-text><claim-text>selecting a core identifier using the plurality of ordinal models by determining a match between the identifier and a preexisting identifier from the plurality of preexisting identifiers using distance information generated using the list of candidate identifiers; and</claim-text><claim-text>matching the core identifier to the identifier using the match to identify the unidentified user as a preexisting user from the plurality of preexisting users.</claim-text></claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The server of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the application is further configured for:<claim-text>receiving the request as a registration request to register an account; and</claim-text><claim-text>denying the registration request using the match.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The server of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the application is further configured for:<claim-text>presenting account information corresponding to the core identifier in response to the request.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The server of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the application is further configured for:<claim-text>generating the sparse data by converting the string information to sparse matrices, wherein the sparse matrices form the sparse data.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The server of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the application is further configured for:<claim-text>converting the string information to sparse matrices using a plurality of n-gram machine learning models.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The server of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the application is further configured for:<claim-text>training the plurality of sparse models, using training data, to convert strings, from the training data, into sparse matrices with columns corresponding to a plurality of n-grams.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A method comprising:<claim-text>training a plurality of sparse models, using training data, to convert strings, from the training data, into sparse matrices with columns corresponding to a plurality of n-grams;</claim-text><claim-text>training a plurality of ordinal models, using the training data, to generate training probabilities from training distance information extracted from the training data;</claim-text><claim-text>receiving an identifier;</claim-text><claim-text>filtering a plurality of preexisting identifiers to a list of candidate identifiers using sparse data and the plurality of sparse models; and</claim-text><claim-text>matching the identifier to a preexisting identifier from the plurality of preexisting identifiers using distance information and the ordinal models.</claim-text></claim-text></claim></claims></us-patent-application>
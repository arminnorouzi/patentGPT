<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005136A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005136</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17806156</doc-number><date>20220609</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>21183428.8</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>055</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>0012</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>055</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10081</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">DETERMINING A LOCATION AT WHICH A GIVEN FEATURE IS REPRESENTED IN MEDICAL IMAGING DATA</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Siemens Healthcare GmbH</orgname><address><city>Erlangen</city><country>DE</country></address></addressbook><residence><country>DE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Yerebakan</last-name><first-name>Halid</first-name><address><city>Carmel</city><state>IN</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Hermosillo Valadez</last-name><first-name>Gerardo</first-name><address><city>West Chester</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Shinagawa</last-name><first-name>Yoshihisa</first-name><address><city>Downingtown</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Wolf</last-name><first-name>Matthias</first-name><address><city>Coatesville</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Jerebko</last-name><first-name>Anna</first-name><address><city>Paoli</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Zhao</last-name><first-name>Yu</first-name><address><city>West Chester</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>Allen-Raffl</last-name><first-name>Simon</first-name><address><city>West Chester</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>Schmidler Burk</last-name><first-name>Katharina</first-name><address><city>Cedar City</city><state>UT</state><country>US</country></address></addressbook></inventor><inventor sequence="08" designation="us-only"><addressbook><last-name>Ranganath</last-name><first-name>Mahesh</first-name><address><city>Malvern</city><state>PA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A computer implemented method and apparatus for determining a location at which a given feature is represented in medical imaging data is disclosed. A first descriptor for a first location in first medical imaging data is obtained. The first location is the location within the first medical imaging data at which the given feature is represented. A second descriptor for each of a plurality of candidate second locations in second medical imaging data is obtained. A similarity metric indicating a degree of similarity with the first descriptor is calculated for each of the plurality of candidate second locations. A candidate second location is selected from among the plurality of candidate second locations based on the calculated similarity metrics. The location at which the given feature is represented in the second medical imaging data is determined based on the selected candidate second location.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="162.05mm" wi="111.93mm" file="US20230005136A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="180.68mm" wi="113.96mm" file="US20230005136A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="197.44mm" wi="152.74mm" file="US20230005136A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="203.62mm" wi="137.92mm" file="US20230005136A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="221.83mm" wi="155.02mm" file="US20230005136A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="208.20mm" wi="123.78mm" file="US20230005136A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="223.52mm" wi="120.99mm" file="US20230005136A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="201.08mm" wi="154.18mm" file="US20230005136A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="127.00mm" wi="47.41mm" file="US20230005136A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application claims the benefit of priority from European Patent Application No. 21183428.8, filed on Jul. 2, 2021, the contents of which are incorporated by reference.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present framework relates to a method and apparatus for determining a location at which a given feature is represented in medical imaging data.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Comparison of medical images occurs frequently in clinical settings. For example, in clinical decision making, the progression of a patient's disease over time can be as, if not more, important than the current status of that disease. In order to help assess the progression of a patient's disease, medical imaging, e.g., radiology, of a region of the patient's body including the disease may be performed at different points in time, for example several times over the course of a year. The resulting images may be compared, for example by a physician, in order to track the disease over time and hence assess the progression of the disease.</p><p id="p-0005" num="0004">However, differences in the images, for example differences resulting from the precise positioning of the patient relative to the imaging equipment when the images are captured, and/or the imaging modality or protocols according to which the images are captured, can make it difficult to locate a given feature (e.g., a particular tumor) represented in one image, in other ones of the images.</p><p id="p-0006" num="0005">Image registration and landmark detection are existing techniques that can help address this problem by attempting to spatially align different images (or imaging data sets) with one another.</p><p id="p-0007" num="0006">In image registration techniques, different sets of imaging data are transformed into one coordinate system. In a known image registration technique, a cost function for a given voxel-to-voxel mapping of one image to another image in voxel space is calculated, and the mapping is adjusted so as to minimize the cost function. As a result, the location of a given feature represented by the two images should be the same in the common coordinate system. However, this technique has drawbacks. For example, the ability of this technique to perform accurately and/or reliably is typically limited to cases where the two images both, as a whole, represent the same part or very similar parts of the patient's body and/or cases where the same or similar imaging modality or protocol is used. Moreover, as it is based on a voxel-to-voxel mapping of one image to another image, this technique is computationally demanding, and hence has a limited ability to provide real-time or near real time results without extensive pre-processing of the imaging data and/or without use of large computational resources.</p><p id="p-0008" num="0007">In landmark detection techniques, a landmark detector first identifies well known locations (&#x201c;landmarks&#x201d;) in the body by applying trained classifiers to both one image and another image. The identified landmarks are mapped between the two images. The images can be broadly spatially aligned according to the landmarks, and as a result a given feature represented in the two images should also be broadly aligned. However, this technique also suffers from drawbacks. For example, it relies on the images containing landmarks that can be detected by the trained classifiers. Moreover, the training of the classifiers to identify landmarks in images can be computationally demanding, and requires expert annotation of a large number of images to form a training data set, which is time consuming.</p><p id="p-0009" num="0008">It would be desirable to provide a technique for determining the location at which a given feature is represented in medical imaging data, but which mitigates at least some of the drawbacks of the prior art.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0010" num="0009">According to one aspect, there is provided a computer implemented method of determining a location at which a given feature is represented in medical imaging data. The medical imaging data includes an array of elements each having a value. A first descriptor for a first location in first medical imaging data is obtained, the first location being the location within the first medical imaging data at which the given feature is represented, the first descriptor being representative of values of elements of the first medical imaging data located relative to the first location according to a first predefined pattern. A second descriptor for each of a plurality of candidate second locations in second medical imaging data is obtained, each second descriptor being representative of values of elements of the second medical imaging data located relative to the respective candidate second location according to the first predefined pattern. For each of the plurality of candidate second locations, a similarity metric is calculated. The similarity metric indicates a degree of similarity between the first descriptor and the second descriptor for the candidate second location. A candidate second location is selected from among the plurality of candidate second locations based on the calculated similarity metrics. The location at which the given feature is represented in the second medical imaging data is determined based on the selected candidate second location.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is flow diagram illustrating a method according to an example;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating first medical imaging data according to an example;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating second medical imaging data according to an example;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating second medical imaging data according to another example;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating output data according to an example;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating first medical imaging data according to an example;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating output data according to another example;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a graph a plot of distance against sensitivity for the method disclosed herein according to examples as well as comparative methods;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating an apparatus according to an example;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating first/second medical imaging data according to a further example;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating first/second medical imaging data according to a further example;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating first/second descriptors according to a further example;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is flow diagram illustrating a method according to a further example;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is flow diagram illustrating a method according to a further example; and</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram illustrating a workflow according to an example.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0026" num="0025">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, there is illustrated a computer implemented method of determining a location at which a given feature is represented in medical imaging data.</p><p id="p-0027" num="0026">Representations of example medical imaging data with which the method may be used are illustrated in <figref idref="DRAWINGS">FIGS. <b>2</b> to <b>5</b></figref>. Medical imaging data may be that captured from performing medical imaging on a patient, for example Computed Tomography (CT), Magnetic Resonance Imaging (MRI), X-ray, or other imaging techniques. <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a representation of first medical imaging data <b>220</b>. <figref idref="DRAWINGS">FIGS. <b>3</b> to <b>5</b></figref> each illustrate a representation of second medical imaging data <b>330</b>. In each case, the medical imaging data comprises an array of elements each having a value. For example, the medical imaging data may comprise a 2-Dimensional array of pixels, each pixel having at least one value. As another example, the medical imaging data may comprise a 3-Dimensional array of voxels, each voxel having at least one value. The at least one value may correspond to or otherwise be representative of an output signal of the medical imaging technique used to generate the medical imaging data. For example, for X-ray imaging, the value of an element (e.g., pixel) may correspond to or represent a degree to which X-rays have been detected at the particular part of the imaging plane corresponding to the element. As another example, for Magnetic Resonance Imaging, the value of an element (e.g., voxel) may correspond to or represent a rate at which excited nuclei, in a region corresponding to the element, return to an equilibrium state. In some examples, each element may only have one value. However, in other examples, each element may have or otherwise be associated with multiple values. For example, the multiple values of a given element may represent the values of respective multiple signal channels. For example, each signal channel may represent a different medical imaging signal or property of the imaging subject. In some examples, the at least one value may comprise an element (e.g., pixel or voxel) intensity value. For example, an output signal from the medical imaging may be mapped onto a pixel or voxel intensity value, for example a value within a defined range of intensity values. For example, for a greyscale image, the intensity value may correspond to a value in the range 0 to 255, where 0 represents a &#x2018;black&#x2019; pixel and 255 represents a &#x2018;white&#x2019; pixel, for example. As another example, for example as in the case of USHORT medical imaging data, the intensity value may correspond to a value in the range 0 to 65536. As another example, in a color image (e.g., where different colors represent different properties of the imaging subject) each pixel/voxel may have three intensity values, e.g., one each for Red, Green, and Blue channels. It will be appreciated that other values may be used. In any case, the medical imaging data may be rendered into an image, for example as schematically illustrated in <figref idref="DRAWINGS">FIGS. <b>2</b> to <b>5</b></figref>. In the illustrated examples, the first medical imaging data <b>220</b> and the second medical imaging data <b>330</b> are data captured by performing medical imaging on the same patient, specifically the same region of the same patient, but at different times. In some examples, the modality (i.e., the medical imaging method by which the data was captured) and/or the protocol (i.e., the specific parameters by which a given method of medical imaging was performed) of the medical imaging may alternatively or additionally be different between the first medical imaging data <b>220</b> and the second medical imaging data <b>330</b>.</p><p id="p-0028" num="0027">In any case, as can be seen from <figref idref="DRAWINGS">FIGS. <b>2</b> to <b>5</b></figref>, the first medical imaging data <b>220</b> and the second medical imaging data <b>330</b> differ. Specifically, in this example, the data differ in the positioning of the region in which the imaging data was captured relative to the patient&#x2014;the region is offset to the right in the sense of the Figures in the second medical imaging data <b>330</b> of <figref idref="DRAWINGS">FIGS. <b>3</b> to <b>5</b></figref> as compared to the first medical imaging data <b>220</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Nonetheless, certain features <b>226</b>, <b>242</b> are represented in both the first medical imaging data <b>220</b> and the second medical imaging data <b>330</b>. In this example, a given feature <b>226</b> represented in the medical imaging data is a lesion <b>226</b> in the right lung of the patient. It will be appreciated however that in examples the given feature may be any feature, e.g., any particular part of the imaging subject (e.g., including internal cavities and the like), represented in the medical imaging data.</p><p id="p-0029" num="0028">In an example use case (referred to hereinafter for illustrative purposes), a physician may be reviewing the rendering of the first medical imaging data <b>330</b> (as per that illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The physician may be interested in assessing the progression of a given feature, e.g., the lesion <b>226</b>, since the previous, second medical imaging data <b>330</b> was captured. The location <b>224</b> at which the given feature <b>226</b> is represented in the first medical imaging data <b>220</b> is known. However, the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> is not known and may be difficult or burdensome for the physician to ascertain by visual inspection alone. The method illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> determines the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>.</p><p id="p-0030" num="0029">Referring again to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in broad overview, the method comprises:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0030">in step <b>102</b>, obtaining a first descriptor for a first location <b>224</b> in first medical imaging data <b>220</b>, the first location <b>224</b> being the location within the first medical imaging data <b>220</b> at which the given feature <b>226</b> is represented, the first descriptor being representative of values of elements <b>222</b> of the first medical imaging data <b>220</b> located relative to the first location <b>224</b> according to a first predefined pattern;</li>        <li id="ul0002-0002" num="0031">in step <b>104</b>, obtaining a second descriptor for each of a plurality of candidate second locations <b>334</b>, <b>340</b>, <b>440</b>, <b>448</b> in second medical imaging data <b>330</b>, each second descriptor being representative of values of elements <b>332</b>, <b>338</b> of the second medical imaging data <b>330</b> located relative to the respective candidate second location <b>334</b>, <b>340</b>, <b>440</b>, <b>448</b> according to the first predefined pattern;</li>        <li id="ul0002-0003" num="0032">in step <b>106</b>, calculating, for each of the plurality of candidate second locations <b>334</b>, <b>340</b>, <b>440</b>, <b>448</b> a similarity metric indicating a degree of similarity between the first descriptor and the second descriptor for the candidate second location <b>334</b>, <b>340</b>, <b>440</b>, <b>448</b>;</li>        <li id="ul0002-0004" num="0033">in step <b>108</b>, selecting a candidate second location <b>334</b>, <b>448</b> from among the plurality of candidate second locations <b>334</b>, <b>340</b>, <b>440</b>, <b>448</b> based on the calculated similarity metrics; and</li>        <li id="ul0002-0005" num="0034">in step <b>110</b>, determining the location <b>334</b>, <b>446</b> at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> based on the selected candidate second location <b>334</b>, <b>448</b>.</li>    </ul>    </li></ul></p><p id="p-0031" num="0035">Accordingly, a technique for determining the location <b>334</b>, <b>446</b> at which a given feature <b>226</b> is represented in medical imaging data <b>330</b> is provided for. Specifically, a known location at which a given feature <b>226</b> is represented in a first medical image <b>220</b> is used to determine the location at which the given feature is represented in a second, e.g., previous, medical image <b>330</b> of a patient. This may, for example, reduce the burden for a physician in finding the location at which the given feature <b>226</b> is represented in the second medical image <b>330</b>.</p><p id="p-0032" num="0036">Moreover, this determination is based on determining the similarity between descriptors for the known location at which the feature <b>226</b> is represented in the first medical image <b>220</b> and for each of plurality of candidate locations in the second medical image <b>330</b>. This may provide for fast, efficient, and/or flexible feature location.</p><p id="p-0033" num="0037">For example, determining similarity between the descriptors for the known first location <b>224</b> and the candidate second locations <b>334</b>, <b>340</b> may be significantly less computationally expensive as compared to Image Registration techniques where every pixel/voxel in one image is mapped to every pixel/voxel in another image by optimizing a cost function. Accordingly, for a given computational budget, the presently disclosed method may provide results significantly faster than Image Registration based methods. This may, in turn, allow for real-time or near real-time interaction with the image data.</p><p id="p-0034" num="0038">Basing the descriptor on element (e.g., pixel of voxel) values located relative to the given location <b>224</b> in a predetermined distribution pattern allows for the surroundings and spatial context of the feature <b>226</b> to be encoded into the descriptor. This provides for the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> to be determined in a reliable, efficient and/or flexible manner.</p><p id="p-0035" num="0039">For example, such descriptors may encode the surroundings of the feature and candidate locations of interest, rather than attempting to map every pixel of one image to a pixel of another image as per Image Registration techniques. Accordingly, even where the first <b>220</b> and second <b>330</b> images are relatively different (e.g., in the overall region of the body they depict), the location at which the given feature is represented in the second medical image may nonetheless be reliably determined (e.g., as compared to Image Registration techniques which, due to the attempt to map every pixel between images, are typically limited to images that are relatively similar). The presently disclosed technique may therefore provide accurate results for a broader range of first and second images, and hence may be more flexibly applied.</p><p id="p-0036" num="0040">As another example, determining similarity between the descriptors for the known first location <b>224</b> and the candidate second locations <b>334</b>, <b>340</b> need not rely on the presence in the medical images <b>220</b>, <b>330</b> of &#x2018;landmarks&#x2019; that classifiers have been trained to detect in the images, as per Landmark Detection based methods. According, the presently disclosed method may be more flexible with respect to the types of medical images to which it may be effectively applied. Moreover, by basing the location determination on a similarity between descriptors, the presently disclosed technique can be applied for any given feature, rather than e.g., a landmark on which a classifier has been trained as per landmark detection-based methods. The presently disclosed technique may therefore provide accurate results for a broader range features, and hence may be more flexibly applied. Determining the similarity between the descriptors allows for the location at which a given feature is represented in medical imaging data to be determined without the use of trained classifiers as per landmark detection based techniques, and hence the time and effort associated with preparing a training data set for the classifier, as well as the computational load of training the classifier, can be saved. Accordingly, the presently disclosed method may allow for determination of a location at which a given feature <b>226</b> is represented in medical imaging data in an efficient manner.</p><p id="p-0037" num="0041">As mentioned, the method comprises, in step <b>102</b>, obtaining the first descriptor for the first location <b>224</b> in first medical imaging data <b>220</b>. The first location <b>224</b> is the location within the first medical imaging data <b>220</b> at which the given feature <b>226</b> is represented. The first descriptor is representative of values of elements <b>222</b> of the first medical imaging data <b>220</b> located relative to the first location <b>224</b> according to a first predefined pattern.</p><p id="p-0038" num="0042">In some examples, the first descriptor may be output from a descriptor model applied to the first medical imaging data for the first location <b>224</b>. The descriptor model may be configured to calculate a descriptor for a given location <b>224</b> based on the values of elements located relative to the given location <b>224</b> according to the first predefined pattern.</p><p id="p-0039" num="0043">In some examples, the first descriptor may be obtained from a database (not shown). For example, the descriptor for the first location <b>224</b> may have already been calculated (for example by applying the descriptor model), and stored in the database, for example in association with the first location <b>224</b>. For example, the database may store a plurality of first descriptors each in association with the corresponding first location in the medical imaging data on the basis of which the first descriptor was determined. Accordingly, in some examples, the method may comprise selecting the first location <b>224</b> from among the plurality and extracting the first descriptor associated with the selected first location <b>224</b>.</p><p id="p-0040" num="0044">In either case, a descriptor for a given location <b>224</b> may be a vector comprising a plurality of entries, each entry being representative of values of a set of one or more elements, the sets of one or more elements being located relative to the given location <b>224</b> according to the first predefined pattern. For example, each entry may be representative of the values of the elements located within a respective one or more of a plurality <b>222</b> of predefined boxes <b>223</b> (i.e., rectangular regions) located relative to the given location <b>224</b> according to the first predefined pattern. It will be appreciated that, where the medical imaging data exits in three spatial dimensions, the term &#x2018;box&#x2019; as used herein may refer to a cuboidal region or volume.</p><p id="p-0041" num="0045">In some examples, each entry of the descriptor may be representative of the values of the elements located within a respective one of a plurality <b>222</b> of predefined boxes <b>223</b>. For example, each entry of the descriptor may be an average of the values of the elements located within a respective one of a plurality <b>222</b> of predefined boxes <b>223</b>. That is, each entry may be the sum of the values of the elements located within a particular box <b>223</b>, divided by the number of elements included in the box <b>223</b>. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, for the first location <b>224</b>, there are a plurality <b>222</b> of predefined boxes <b>223</b> (i.e., notional regions) distributed in the first medical imaging data <b>220</b> in a particular pattern <b>222</b>. The first descriptor for the first location <b>224</b> may be a vector, each entry of which is the average value of the elements of the first medical imaging data <b>220</b> located within a respective one of the boxes <b>223</b>. Using the average value (e.g., as compared to the sum) helps provide that each vector entry is within the same range, independent of the size of the box for which it is calculated. As described in more detail below, this may, in turn, help provide for robust and/or reliable determination of similarity between descriptors.</p><p id="p-0042" num="0046">In some examples, the predefined pattern and/or the predefined boxes (e.g., the size and/or aspect ratio of each box) may be randomly or pseudo-randomly generated. In some examples, a descriptor may be determined using many boxes <b>223</b>, for example 1000 boxes, and accordingly the descriptor may be a vector having many entries (e.g., 1000 entries). For example, referring briefly to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, there is presented, for illustrative purposes, a medical imaging data set <b>660</b> to which a large number of predefined boxes (shown as white rectangular outlines) have been applied in order to determine a descriptor for a given location (not shown) in the medical imaging data <b>660</b>.</p><p id="p-0043" num="0047">The descriptor may encode the spatial context of the given location <b>224</b> at which a given feature is represented, and hence in turn may provide a compact representation of the surroundings of a given feature. The calculation of such descriptors may be relatively computationally inexpensive and fast, for example as compared to comparatively dense feature representations, for example as may be used in a landmark detection technique. This may help allow, for example, for the method to be performed (and hence results returned) quickly.</p><p id="p-0044" num="0048">In some examples, the descriptor model that calculates the descriptor may be applied to &#x2018;raw&#x2019; medical imaging data. However, in other examples, the descriptor model may be applied to integral image data (also known as a summed area table) of the first medical imaging data. In integral image data, the value for a given element is the sum of values of all of the elements above and to the left of the given element in the image data. For example, integral image data for the first medical imaging data <b>220</b> may be generated and the first descriptor may be calculated on the basis of the integral image data for the first medical imaging data <b>220</b>. The use of integral image data allows for faster computation of the descriptors. In some examples, this may, in turn, help allow for the results of the method to be returned faster.</p><p id="p-0045" num="0049">In examples where an integral image is used, the sum of values of elements of a box <b>223</b> with opposite corner locations (x<sub>1</sub>,y<sub>1</sub>,z<sub>1</sub>), (x<sub>2</sub>,y<sub>2</sub>,z<sub>2</sub>) is given, in terms of the corresponding Integral image I, by (I(x<sub>2</sub>,y<sub>2</sub>,z<sub>2</sub>)+I(x<sub>2</sub>,y<sub>1</sub>,z<sub>1</sub>)+I(x<sub>1</sub>,y<sub>2</sub>,z<sub>1</sub>)+I(x<sub>1</sub>,y<sub>1</sub>,z<sub>2</sub>)&#x2212;(I(x<sub>1</sub>,y<sub>2</sub>,z<sub>2</sub>)+I(x<sub>2</sub>,y<sub>1</sub>,z<sub>2</sub>)+I(x<sub>2</sub>,y<sub>2</sub>,z<sub>1</sub>)+I(x<sub>1</sub>,y<sub>1</sub>,z<sub>1</sub>))). In this expression, I(x<sub>i</sub>,y<sub>j</sub>,z<sub>k</sub>) is the value of the element in the integral image I at the location x=i, y=j, and z=k, where i, j, and k are element indices. For a given box <b>223</b>, this sum may be divided by the total number of elements contained within the box <b>223</b> to calculate the average element value for the box <b>223</b>. The average element value for each box may be used as respective entry in a vector constituting the first descriptor.</p><p id="p-0046" num="0050">It will be appreciated that, in some examples, descriptors other than the specific example described above may be used. For example, in some examples, Haar-like descriptors may be used, i.e., a descriptor where each entry represents a difference between the sums of element values within each of a plurality of boxes defined in the image data. In some examples, the descriptor may be a gradient descriptor, for example in which each entry represents one or more image gradients in a respective one of a plurality of regions of the medical imaging data. For example, an image gradient for a given region may be based on a change in the values (e.g., intensity values) between elements within the given region. In some examples, the descriptor may be such that each entry is the value of a respective one of a plurality of elements randomly distributed in the medical imaging data relative to the first location <b>224</b>. In some examples, the descriptor for a given location may be such that each entry is the aggregate of the values of elements intersecting with a respective one of a plurality of randomly orientated rays, each ray originating from the given location. In each case, the descriptor for a given location is representative of values of elements of the medical imaging data located relative to the given location according to a first predefined pattern.</p><p id="p-0047" num="0051">Nonetheless, is noted that the inventors have identified that the use of a descriptor for a given location in which each entry is representative (e.g., an average) of the values of the elements located within a respective one of a plurality <b>222</b> of predefined boxes <b>223</b> located relative to the given location in a predefined (e.g., randomly generated) distribution pattern, provides for particularly fast yet accurate location determination.</p><p id="p-0048" num="0052">In some examples, the first location <b>224</b> for which the descriptor is calculated or otherwise obtained may be specified by a user. For example, a representation of the first medical imaging data <b>220</b> may be displayed to the user, and the user may specify the location <b>224</b> of a given feature <b>226</b> of interest, for example by clicking on the representation at the first location <b>224</b> at which the given feature <b>226</b> is represented. This user specified location may then be taken as the first location <b>224</b>. The first descriptor may then be calculated or otherwise obtained based on this first location <b>224</b>.</p><p id="p-0049" num="0053">In some examples, the first location <b>224</b> may be output from a computer implemented method. For example, the first medical imaging data <b>220</b> may have been pre-processed by a computer implemented method (not shown) to identify a given feature <b>226</b> in the first medical imaging data <b>220</b>, and output the first location <b>224</b> at which the given feature <b>226</b> is represented. This output may be provided directly, and/or stored in a database. The first descriptor may then be calculated or otherwise obtained based on this first location <b>224</b>.</p><p id="p-0050" num="0054">In some examples, the first location <b>224</b> may be obtained from a database (not shown). For example, the database may store one or more locations at which a respective one or more features are represented in one or more medical imaging data sets. The first medical imaging data <b>220</b> may be extracted from the database along with the one or more locations. A particular one of the locations may be selected as the first location <b>224</b>, for example based on a desire or instruction to determine the location at which the given feature <b>226</b> at that location is represented in second medical imaging data <b>330</b>. The first descriptor may then be calculated or otherwise obtained based on this first location <b>224</b>.</p><p id="p-0051" num="0055">In any case, the first descriptor for the first location <b>224</b> in the first medical imaging data <b>220</b> is obtained.</p><p id="p-0052" num="0056">As mentioned, in step <b>104</b>, the method comprises obtaining a second descriptor for each of a plurality of candidate second locations <b>334</b>, <b>340</b> in second medical imaging data <b>330</b>.</p><p id="p-0053" num="0057">Each second descriptor is representative of values of elements <b>332</b>, <b>338</b> of the second medical imaging data <b>330</b> located relative to the respective candidate second location <b>334</b>, <b>340</b> according to the first predefined pattern. The second descriptor may be the same as the first descriptor in the sense that, for a given location (e.g., the first location <b>224</b> or any one of the second candidate locations <b>334</b>, <b>340</b>), the descriptor is representative of values of given elements of the associated medical imaging data located relative to the given location according to the first predefined pattern. For example, the same descriptor model that was applied to the first medical imaging data <b>220</b> to generate the first descriptor for the first location <b>224</b> may be applied to the second medical imaging data <b>330</b> to generate the second descriptor for each of the plurality of candidate second locations <b>334</b>, <b>340</b>. For example, referring to <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>, the boxes <b>332</b>, <b>338</b> and the location of each of those boxes relative to each candidate second location <b>334</b>, <b>340</b> used to calculate the second descriptor for each of those candidate second locations <b>334</b>, <b>340</b> are the same as the boxes <b>222</b> and the location of each of those boxes relative to the first location <b>224</b> used to calculate the first descriptor for the first location <b>224</b>. Whichever type of descriptor is used, that descriptor for the first location <b>224</b> in the first medical imaging data <b>220</b> and that descriptor each of the plurality of second candidate locations <b>334</b>, <b>340</b> in the second medical imaging data <b>330</b> are obtained.</p><p id="p-0054" num="0058">As described in more detail below, in some examples (e.g., described below with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>), each candidate second location <b>334</b>, <b>340</b> may be a location at which a respective previously detected feature <b>226</b>, <b>242</b> is represented in the second medical imaging data <b>330</b>. In other examples, (e.g., as described below with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>) the candidate second locations <b>440</b> may be locations distributed through the second medical imaging data in a second predefined pattern.</p><p id="p-0055" num="0059">In any case, a second descriptor for each of a plurality of candidate second locations <b>334</b>, <b>340</b>, <b>440</b> in second medical imaging data <b>330</b> is obtained.</p><p id="p-0056" num="0060">As mentioned, the method comprises, in step <b>106</b> calculating, for each of the plurality of candidate second locations <b>334</b>, <b>340</b>, <b>440</b>, a similarity metric indicating a degree of similarity between the first descriptor and the second descriptor for the candidate second location <b>334</b>, <b>340</b>, <b>440</b>.</p><p id="p-0057" num="0061">In some examples, the similarity metric may comprise the normalized mutual information similarity between the first descriptor and the second descriptor. For example, the normalized mutual information similarity between the first descriptor and the second descriptor may be determined as follows. A first histogram is formed in which the entries in the first descriptor are placed into equally sized bins x between the minimum entry value and the maximum entry value of the first descriptor. The counts in first histogram are normalized to get the probability distribution Px(x) of the entries of the first descriptor across the bins x. A second histogram is formed in which the entries in the second descriptor are placed into equally sized bins y between the minimum entry value and the maximum entry value of the second descriptor. The counts in second histogram are normalized to get the probability distribution Py(y) of the entries of the second descriptor across the bins y. A joint histogram of the entries of the first descriptor and the second descriptor ranging between the respective minimum and maximum values is determined. Each bin of the joint histogram is an equally sized 2-dimensional bin, the first dimension X corresponding to the entry from the first descriptor, and the second dimension Y corresponding to the associated entry from the second descriptor. For example, if the first entry of the first descriptor was q and the first entry of the second descriptor was p, then the 2D bin x, y of the joint histogram which covers a range of first descriptor values including p and covers a range of second descriptor values including q, would receive a count. The counts in the joint histogram are normalized to get the probability distribution Pxy(x,y) of the entries of the first and second descriptors across the bins x, y. The mutual information similarity I between the first descriptor and the second descriptor may then be calculated as</p><p id="p-0058" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>I</mi>     <mo>=</mo>     <mrow>      <msub>       <mo>&#x2211;</mo>       <mi>y</mi>      </msub>      <mrow>       <msub>        <mo>&#x2211;</mo>        <mi>x</mi>       </msub>       <mrow>        <mrow>         <msub>          <mi>P</mi>          <mi>XY</mi>         </msub>         <mo>(</mo>         <mrow>          <mi>x</mi>          <mo>,</mo>          <mi>y</mi>         </mrow>         <mo>)</mo>        </mrow>        <mo>&#x2062;</mo>        <mtext>  </mtext>        <mi>log</mi>        <mo>&#x2062;</mo>        <mtext>  </mtext>        <mrow>         <mo>(</mo>         <mfrac>          <mrow>           <msub>            <mi>P</mi>            <mrow>             <mi>X</mi>             <mo>,</mo>             <mi>Y</mi>            </mrow>           </msub>           <mo>(</mo>           <mrow>            <mi>x</mi>            <mo>,</mo>            <mi>y</mi>           </mrow>           <mo>)</mo>          </mrow>          <mrow>           <mrow>            <msub>             <mi>P</mi>             <mi>X</mi>            </msub>            <mo>(</mo>            <mi>x</mi>            <mo>)</mo>           </mrow>           <mo>&#x2062;</mo>           <mrow>            <msub>             <mi>P</mi>             <mi>Y</mi>            </msub>            <mo>(</mo>            <mi>y</mi>            <mo>)</mo>           </mrow>          </mrow>         </mfrac>         <mo>)</mo>        </mrow>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0059" num="0062">The higher the mutual information similarity I, the higher the degree of similarity between the first descriptor and the second descriptor. Using normalized mutual information similarity may provide for robust, reliable and/or flexible determination of the similarity. For example, the mutual information similarity is independent of differences in relative scale of the entries of the first descriptor as compared to the second descriptor. For example, using mutual information, an accurate similarity metric may be determined even if the overall &#x2018;brightness&#x2019; (e.g., the intensities that are the values of the elements of the medical imaging data) differs between the first medical imaging data and the second medical imaging data. As another example, mutual information may provide an accurate similarity, even in cases where different protocols and/or modalities of medical imaging have been used (and e.g., accordingly different value ranges used or achieved) or for example where the medical images have been transformed, e.g., inverted or scaled. Accordingly, the use of mutual information similarity in this way may provide for determination of similarity that is robust to, e.g., non-structural variations between the first and second medical imagine data, which may in turn allow for the method to be applied reliably to a wider range of images, which in turn may provide more flexibility in the type of images with which the method may be provided.</p><p id="p-0060" num="0063">As mentioned, in some examples, the descriptor entries are representative of values of elements contained within associated boxes <b>223</b>, <b>333</b>, <b>339</b>. As mentioned, in these examples, each entry of the respective descriptors being an average of the values of elements contained within respective boxes <b>223</b>, <b>333</b>, <b>339</b> may help ensure the entries within a descriptor are within a certain range independent of box size. This, in turn, may facilitate the use of mutual information similarity, as the bin into which a given entry is placed is accordingly dependent on the average value of the elements within the box, but not on the size of the box.</p><p id="p-0061" num="0064">In some examples, other similarity metrics between the first descriptor and the second descriptor may be used. For example, cosine similarity, Euclidean distance, and/or cross correlation may alternatively or additionally be used. Nonetheless, the inventors have identified that the mutual information similarity metric may provide for particularly robust, reliable and/or flexible determination of the similarity metric, and accordingly for particularly robust, reliable and/or flexible determination of the location at which the given feature is represented in the second medical imaging data.</p><p id="p-0062" num="0065">In any case, for each second candidate location <b>334</b>, <b>340</b> a similarity metric indicating a degree of similarity between the first descriptor and the second descriptor for the candidate second location <b>334</b>, <b>340</b> is calculated.</p><p id="p-0063" num="0066">As mentioned, the method comprises, in step <b>108</b>, selecting a candidate second location <b>334</b> from among the plurality of candidate second locations <b>334</b>, <b>340</b> based on the calculated similarity metrics; and in step <b>110</b> determining the location <b>334</b> at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> based on the selected candidate second location <b>334</b>.</p><p id="p-0064" num="0067">In some examples, selecting the candidate second location <b>334</b> may comprise selecting the candidate second location <b>334</b> having the similarity metric indicating the highest degree of similarity among the similarity metrics of the plurality of candidate second locations <b>334</b>, <b>340</b>. For example, the candidate second location <b>334</b> with the highest mutual information similarity metric may be selected. In some examples, determining the location at which the given feature <b>226</b> is represented comprises determining, as the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>, the selected candidate second location <b>334</b>. In some examples, determining the location may be responsive to a determination that the similarity metric between the first descriptor for the first location and the second descriptor for the selected candidate second is above a threshold value. This may help ensure that the location at which the given feature is represented in the second medical imaging data <b>330</b> is only determined in cases where there is a certain degree of confidence in the determination. This may, in turn, help provide for reliable determination of the location at which the given feature is represented in the second medical imaging data <b>330</b>.</p><p id="p-0065" num="0068">As mentioned, in some examples (e.g., as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>), each candidate second location <b>334</b>, <b>340</b> may be a location at which a respective previously detected feature <b>226</b>, <b>242</b> is represented in the second medical imaging data <b>330</b>. In other examples, (e.g., as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) the candidate second locations <b>440</b> may be locations distributed through the second medical imaging data in a second predefined pattern. The way in which the location of the given feature may be determined in each of these examples scenarios is now described in more detail with reference to <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref>.</p><p id="p-0066" num="0069">Referring first to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, in this example scenario, the second medical imaging data <b>330</b> represents a first feature <b>226</b> and a second feature <b>242</b>. In this example, these features <b>226</b>, <b>242</b> have been detected in the second medical imaging data <b>330</b>, for example previously by a physician, or by an automated method. The respective locations <b>334</b>, <b>340</b> of these features <b>226</b>, <b>242</b> in the second medical imaging data <b>330</b> have been recorded as part of this previous detection. Accordingly, the respective locations <b>334</b>, <b>340</b> of these previously detected features <b>226</b>, <b>340</b> are known. However, it is not known which of these two locations <b>334</b>, <b>340</b> is the location at which the given feature <b>226</b> in the first medical imaging data <b>220</b> is represented in the second medical imaging data <b>330</b>. In other words, it is not known which of these features <b>226</b>, <b>224</b> corresponds to the given feature <b>226</b> represented in the first medical imaging data <b>220</b>. In these examples, the candidate second locations may therefore be taken as the locations <b>334</b>, <b>340</b> in the second medical imaging data <b>330</b> at which the previously detected features <b>226</b>, <b>242</b> are represented. A similarity metric between the second descriptors for each of the candidate second locations <b>334</b>, <b>340</b> and the first descriptor for the first location <b>224</b> may be calculated. In this example, the candidate second location <b>334</b> with the highest similarity metric may be selected, and the selected candidate second location <b>334</b> may be determined as the location <b>334</b> at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>.</p><p id="p-0067" num="0070">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the second medical imaging data <b>330</b> represents a first feature <b>226</b> and a second feature <b>242</b>. However, in the example scenario of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the locations at which these features <b>226</b>, <b>242</b> are represented in the second medical imaging data <b>330</b> is not known. In this example, the candidate second locations <b>440</b> are locations distributed through the second medical imaging data <b>330</b> in a second predefined pattern. In some examples, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the second predefined pattern may be a regular arrangement, with each second candidate location <b>440</b> (represented in <figref idref="DRAWINGS">FIG. <b>4</b></figref> by the open circles <b>440</b>) spaced apart from its neighbors in a grid. For example, this arrangement may span a region, for example the whole of, the second medical imaging data <b>330</b>. As such, the candidate second locations represent a spatially distributed sample of locations within the second medical imaging data <b>220</b> (and hence at which the given feature could be represented).</p><p id="p-0068" num="0071">The candidate second locations being distributed in the second predefined pattern may allow for the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> to be estimated in a computationally efficient way, for example as compared to determining a descriptor for every voxel of the second medical imaging data <b>330</b>.</p><p id="p-0069" num="0072">In the example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the similarity metric between the second descriptor for each one of the candidate second locations <b>440</b> and the first descriptor may be calculated. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the second descriptor for the candidate second location <b>448</b> closest to the represented feature <b>226</b> has the highest degree of similarity with the first descriptor. Accordingly, the candidate second location <b>448</b> is selected. The location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> may then be determined based on this selected candidate second location <b>448</b>.</p><p id="p-0070" num="0073">For example, in some examples, the selected candidate second location <b>448</b> may be taken as an estimate of the location at which the given feature <b>226</b> is represented in the second medical imaging data. However, in other examples, this estimate may be refined by defining further candidate locations <b>442</b>, <b>444</b> (based on the selected candidate second location <b>448</b>) in successively more fine-grained patterns (see e.g., the pattern of grey circles <b>442</b>, and subsequently of black circles <b>444</b>, in <figref idref="DRAWINGS">FIG. <b>4</b></figref>). Accordingly, an accurate yet efficient determination of the location at which a given feature <b>226</b> is represented in the second medical imaging data <b>330</b> ma be provided for, even where no locations of any features in the second medical imaging data <b>330</b> are known.</p><p id="p-0071" num="0074">Specifically, in these examples, determining the location <b>446</b> at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> may comprise: determining, based on the selected candidate second location <b>448</b>, a plurality of candidate third locations <b>442</b> in the second medical imaging data <b>330</b>. For example, the candidate third locations <b>442</b> may be defined as locations in the region of (i.e., local to) the selected candidate second location <b>448</b>. For example, the candidate third locations <b>442</b> may be locations distributed through the second medical image data <b>330</b> in a third predefined pattern in the region of the selected second location <b>448</b>. For example, the third predefined pattern may be the same as or similar to that of the second predefined pattern. However, in some examples (as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>), a distance between the candidate third locations <b>442</b> in the third predefined pattern may be less than a distance between the candidate second locations <b>440</b> in the second predefined pattern.</p><p id="p-0072" num="0075">The method may then comprise obtaining a third descriptor for each of the plurality of candidate third locations <b>442</b> in the second medical imaging data <b>330</b>, each third descriptor being representative of values of elements of the second medical imaging data <b>330</b> located relative to the respective candidate third location <b>442</b> according to the first predefined pattern. For example, the third descriptor may be the same as, i.e., may have been calculated in the same way as, the first and second descriptors as described above.</p><p id="p-0073" num="0076">In some examples, a scale of the first predefined pattern associated with the third descriptors may be reduced as compared to a scale of the first predefined pattern associated with the second descriptors. Taking a descriptor based on a plurality of boxes (not shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) arranged in the first predefined pattern as an example, while the shape and the spatial pattern of the boxes may be the same for the second descriptors and the third descriptors, the size of the boxes and/or the distances between each box and the respective location <b>442</b> for the third descriptor may be scaled down (i.e., reduced) as compared to the size of the boxes and/or the distances between each box and the respective location <b>440</b> for the second descriptor. This may provide that the third descriptors encode more fine-grained detail of the second medical image data <b>330</b> in the region of the selected candidate second location <b>448</b>. This may help provide for accurate determination of the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>.</p><p id="p-0074" num="0077">In these examples, the method may then comprise calculating, for each of the plurality of candidate third locations <b>442</b>, a similarity metric indicating a degree of similarity between the first descriptor and the third descriptor for the candidate third location <b>442</b>. For example, the similarity metric may be the same as, i.e., may be calculated in the same way as, the similarity metric as used between the first descriptor and the second descriptor. The method may then comprise selecting a candidate third location <b>448</b> from among the plurality of candidate third locations <b>442</b> based on the calculated similarity metrics indicating the degree of similarity between the first descriptor and the respective third descriptors. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the candidate third location <b>448</b> with the highest similarity metric may be selected. The method may then comprise determining the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> based on the selected candidate third location <b>448</b>.</p><p id="p-0075" num="0078">In some examples, the selected candidate third location <b>448</b> may be taken as an estimate of the location at which the given feature <b>226</b> is represented in the second medical imaging data. However, in other examples, this estimate may be further refined by defining further candidate locations <b>444</b> based on (e.g., in the region of) the selected third candidate location <b>448</b>, and repeating the above described method for these further candidate locations. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a further set of candidate locations <b>444</b> are defined in the region of the selected candidate third location <b>448</b>. In this example the further candidate location <b>446</b> will have a descriptor with the highest similarity metric with the first descriptor, and hence may be selected. The location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> may then be determined at the selected further candidate location <b>446</b>. It will be appreciated that although three levels of hierarchical granularity are shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, fewer or more levels of hierarchical granularity may be employed in order to determine the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>. Nonetheless, using such a hierarchical method may allow for the location to be accurately determined in a quick and efficient manner, even where no locations of any features in the second medical imaging data <b>330</b> are known.</p><p id="p-0076" num="0079">It is noted that the elements (e.g., boxes) according to which the respective second, third or further descriptors may calculated for each of the respective candidate second, third or further locations are not shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, for clarity.</p><p id="p-0077" num="0080">In any case, the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> is determined. In some examples, the method may further comprise generating output data indicating the determined location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>.</p><p id="p-0078" num="0081">For example, the output data may comprise a coordinate or pixel/voxel index corresponding to the determined location <b>334</b>, <b>446</b> within the second medical imaging data <b>330</b>. In some examples, the output data may further comprise a reference to the second medical imaging data <b>330</b> within which location has been determined. In some examples, the output data may comprise the second medical imaging data itself (or a portion thereof). In some examples, the output data may comprise an image (or data for an image) in which an indicator indicating the determined location is overlaid onto a rendering of the second medical imaging data <b>330</b>. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a representation of the second medical imaging data <b>330</b> is shown, and overlaid onto (or otherwise included in) the representation is an indicator <b>550</b> indicating the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>. In this example, the indicator is a box centered on the determined location. However in other examples other indicators may be used, such as a marker or dot or other symbol overlaid (or otherwise included) at the determined location; or for example an arrow or pointer or other label pointing at or connected or otherwise indicating the determined location. The output data may allow for an indication to be provided to a user, e.g., a physician, as to the determined location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>. The user may therefore, e.g., compare the representation of the given feature <b>226</b> in both the first medical image data <b>220</b> and the second medical image data <b>330</b>. As a result, the user may, for example, make an assessment as to the differences between the given feature <b>226</b>, e.g., make an assessment as to the progression of a disease of which the feature <b>226</b> may be an expression.</p><p id="p-0079" num="0082">In some examples, the output data may further comprise the first location and a reference to the first medical imaging data <b>220</b> or the medical imaging data <b>220</b> itself. This may allow for an association between the locations at which the given feature <b>226</b> is represented in both the first medical imaging data <b>220</b> and the second medical imaging data <b>330</b> to be determined. In some examples, the output data may be stored in a storage device. For example, the output data may be stored in a database. This may allow for the output data to be referred to, for example by a user or by an automated downstream process (not shown).</p><p id="p-0080" num="0083">In some examples, the method may comprise transmitting the output data to a display device to display a representation of the second medical image data <b>330</b> and an indicator <b>550</b> indicating, on the representation of the second medical image data, the determined location at which the given feature is represented. For example, the display device (not shown) may be a computer monitor or other display screen of a computer. For example, the displayed representation may be similar to that shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, where the indicator <b>550</b> is overlaid onto the representation of the second medical imaging data <b>330</b>. Any of the example indicators mentioned above may be used. This may allow for a user, e.g., a physician, to immediately and easily appreciate the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b>, which may, for example, allow for assessments based on the given feature to be made more quickly and with minimal burden.</p><p id="p-0081" num="0084">In the above examples, only one given feature <b>226</b> is referred to. However, in some examples, there may a plurality of given features represented in the first medical imaging data <b>220</b>. In these examples, it may be desirable to determine the location at which each of the plurality of given features is located in the second medical imaging data <b>330</b>. In some examples, the method according to any of the examples described with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>6</b></figref> may be employed sequentially to the plurality of given features, for example once for each of the plurality of given features. However, as described in more detail below, in some examples, the determination of each location may be performed concurrently.</p><p id="p-0082" num="0085">Referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, there is a representation of first medical imaging data <b>772</b>, and a representation of second medical imaging data <b>770</b>. The first medical imaging data <b>772</b> represents three given features A, B, C (shown only schematically in <figref idref="DRAWINGS">FIG. <b>7</b></figref>), and the second medical imaging data <b>770</b> represents three features D, E, F (shown only schematically in <figref idref="DRAWINGS">FIG. <b>7</b></figref>). In this example, all of the features A, B, C, D, E, F have been detected in the images, and the locations at which they are represented within the respective medical imaging data is known. However, it is not known which of the features D, E, F in the second medical imaging data <b>770</b> correspond to the given features A, B, C in the first medical imaging data. In this example, the locations at which the given features A, B, C are represented in the first medical imaging data <b>772</b> are the first locations, and the locations at which the features D, E, F are represented in the second medical imaging data <b>770</b> are the respective candidate second locations.</p><p id="p-0083" num="0086">In this example, a said first descriptor for a said first location (not shown) in the first medical imaging data <b>770</b> is obtained for each of the plurality of said given features A, B, C. In this example, the method may comprise calculating said similarity metric between the first descriptor and the second descriptor for all pairs of the first locations A, B, C and candidate second locations D, E, F. For example, the similarity metric according to any one of the examples described above may be determined between the descriptor for the first location of the given feature A and the descriptor for the second locations of each of the features D, E, F; and the same may be performed for the other given features B, C. For example, in this example, there will be nine similarity metrics calculated, one for each of the pairings A-D, A-E, A-F, B-D, B-E, B-F, C-D, C-E, C-F.</p><p id="p-0084" num="0087">The method may then comprise assigning each first location A, B, C a different one of the candidate second locations D, E, F based on the calculated similarity metrics between the pairs of first locations and candidate second locations. For example, the assignment may be by solving the maximal matching problem for a bipartite graph based on the similarity metrics of all of the pairs. For example, the assignments may be made using a Linear Sum Assignment algorithm, for example the &#x201c;linear sum assignment&#x201d; routine in a Python-NumPy library. For example, the assignment may be made by minimizing the function &#x3a3;<sub>i</sub>&#x3a3;<sub>j</sub>C<sub>ij</sub>X<sub>ij </sub>where C is a cost matrix where C[i,j] is the &#x2018;cost&#x2019; of assigning first location i a candidate second location j (e.g., inversely proportional to the similarity metric thereof), X is a Boolean matrix where X[i,j]=1 if row i is assigned to column j, and wherein the minimization is subject to the constraint that there is at most one candidate second location j assigned per first location i. For example, as a result of this process, the following assignments may be determined: A-D, B-E, C-F.</p><p id="p-0085" num="0088">In some examples, assigning a first location A, B, C a candidate second location D, E, F may be responsive to a determination that the similarity metric between the first descriptor for the first location A, B, C and the second descriptor for the candidate second location D, E, F is above a threshold value. For example, the threshold value could be set, for example, at 70% similarity. This may help ensure that there is a certain degree of confidence in the assignment. For example, while given feature A may have been assigned to feature D in the second medical imaging data <b>770</b> as part of the linear sum assignment, it may be determined that the similarity metric for this pair A-D is below the threshold value, and hence the assignment of D to A may not be made. However, the similarity metrics for the pairings B-E and C-F may be above the threshold, and hence these assignments may be made.</p><p id="p-0086" num="0089">The method may then comprise determining, for each said first location B, C, as the location at which the respective said given feature B, C is represented in the second medical imaging data <b>770</b>, the second candidate location E, F assigned to the first location. For example, according to the assignments B-E and C-F made in this example, the method may comprise determining the locations of features E and F as the location at which features B and C, respectively, are represented in the second medical imaging data <b>770</b>.</p><p id="p-0087" num="0090">The method described above with reference to <figref idref="DRAWINGS">FIG. <b>7</b></figref> may help prevent inconsistencies that could otherwise occur if the method described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>6</b></figref> were applied sequentially and separately to each of a plurality of given features. Accordingly, this may allow for more reliable determination of the location at which a given feature is represented in the second medical imaging data <b>770</b> in the case where there are a plurality of given features.</p><p id="p-0088" num="0091">In some examples, the output data may comprise associations or links <b>774</b>, <b>776</b> between each first location B, C and the candidate second location E, F that has been assigned to the first location B, C. For example, the output data may be similar that represented in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, where representations of the first medical imaging data <b>772</b> and the second medical imaging data <b>770</b> are presented adjacent to one another, and where there is a first link <b>774</b> drawn between the first location B and the candidate second location E to which it has been assigned, and a second link <b>776</b> drawn between the first location C and the candidate second location F to which it has been assigned. These links <b>774</b>, <b>776</b> may act as indicators of the locations E, F at which the given features B, C are represented in the second medical imaging data <b>770</b>. This output data may be stored and/or displayed, for example as described above. This may allow a user to immediately and easily identify the location at which each given feature B, C represented in the first medical imaging data <b>772</b> is represented in the second medical imaging data <b>770</b>, and indeed vice versa.</p><p id="p-0089" num="0092">To serve as an illustration of the performance of examples of the method disclosed herein, a study was performed. Specifically, a study was performed for examples described above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref> where a hierarchical search for the location at which the given feature <b>226</b> is represented in the second medical imaging data <b>330</b> is performed. In this study, the method was performed on a benchmark dataset of lung lesion pairs each across two images taken at different time points (i.e., first medical imaging data and second medical imaging data, respectively). In this study, the distance from the estimated location at which the given feature is represented in the second medical imaging data to the true location at which the given feature is represented in the second medical imaging data, was calculated, for each of the dataset pairs. The precision of the estimation under a series of distance thresholds was then calculated. This provides a measure of the sensitivity of the estimation as a function of the distance from the true location at which the given feature is represented in the second medical imaging data. <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a plot of this sensitivity as a function of the distance (in mm) for the above referenced example of the presently disclosed method (solid line <b>882</b>) as well as comparative methods (dashed line <b>884</b>, dotted line <b>880</b>, and black circles <b>886</b>) as applied to the dataset. The comparative methods were each Image Registration based methods. As can be seen from the plot in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the presently disclosed method can surpass the performance of the studied Image Registration based methods. Specifically, in about 92% of the cases, the studied example method was able to determine the location at which the given feature was represented in the second medical imaging data <b>330</b> to within 15 mm of its true location. In the studied example method, the location was not only able to be determined accurately, but also quickly, specifically in under a few seconds. According, the presently disclosed method can provide for fast and accurate determination of the location at which the given feature is represented in the second medical imaging data <b>330</b>.</p><p id="p-0090" num="0093">Referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, there is illustrated an apparatus <b>990</b> according to an example. The apparatus <b>990</b> comprises an input interface <b>996</b>, an output interface <b>998</b>, a processor <b>992</b>, and a memory device <b>994</b>. The processor <b>992</b> and the memory device <b>994</b> may be configured to perform the method according to any one of the examples described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>7</b></figref>. The memory device <b>994</b> may store instructions which, when executed by the processor <b>992</b>, cause the processor <b>992</b> to perform the operations of the method according to any one of the examples described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>7</b></figref>. The instructions may be stored on any computer readable medium, for example, one or more non-transitory computer readable media.</p><p id="p-0091" num="0094">For example, the input interface <b>996</b> may receive the first descriptor for a first location <b>224</b>, A, B, C in first medical imaging data <b>220</b>, <b>772</b> and a second descriptor for each of a plurality of candidate second locations <b>334</b>, <b>340</b>, <b>440</b>, D, E, F in second medical imaging data <b>330</b>, <b>770</b>, the processor <b>992</b> may implement the method according to any of the examples described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>7</b></figref>, and the processor <b>992</b> may output, via the output interface <b>998</b>, data indicating the determined location at which the given feature is represented in the second medical imaging data <b>330</b>, <b>330</b>, for example the output data as described above with reference to <figref idref="DRAWINGS">FIG. <b>5</b> or <b>7</b></figref>. In some examples, the output data may be transmitted to n storage (not shown) for example implementing a database, so that the output data is stored in the storage. In some examples, the output data may be transmitted to a display device (not shown) to allow a user to review the output data, for example as described above with reference to <figref idref="DRAWINGS">FIG. <b>5</b> or <b>7</b></figref>. In some examples, the output data may be stored, alternatively or additionally, in the memory device <b>994</b>.</p><p id="p-0092" num="0095">The apparatus <b>990</b> may be implemented as a processing system and/or a computer. It will be appreciated that the methods according to any one of the examples described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>7</b></figref> are computer implemented methods, and that these methods may be implemented by the apparatus <b>990</b>.</p><p id="p-0093" num="0096"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows another example for possible first and/or second predefined patterns. Specifically, the first predefined pattern may be a sampling grid <b>1001</b> comprising a plurality of grid points <b>1002</b>. The grid points <b>1002</b> are distributed in first or second medical imaging data <b>220</b>, <b>330</b>. The grid points <b>1002</b> are located relative to either the first location <b>224</b> or the candidate second locations <b>334</b>, <b>340</b>, <b>440</b>. For the sake of easy reference, the first location <b>224</b> or the candidate second locations <b>334</b>, <b>340</b>, <b>440</b> are together referred to as given location in the following. In particular, the sampling grid <b>1001</b> may be centered with respect to the given location, with the given location sitting in the center of the sampling grid <b>1001</b>.</p><p id="p-0094" num="0097">The sampling grid <b>1001</b> may be a regular grid which has one or more axis or planes of symmetry. The planes or axis of symmetry may run through the respective given location. Further one or more axis or planes of symmetry may intersect in the respective given location. According to some examples, the sampling grid <b>1001</b> respectively fully spans the respective imaging spaces of the first and second medical imaging data. According to some examples, the sampling grid <b>1001</b> may be two-dimensional. According to other examples, the sampling grid <b>1001</b> may be three-dimensional.</p><p id="p-0095" num="0098">Each sampling point <b>1002</b> of the sampling grid <b>1001</b> may correspond to an entry of a vector, the vector being the descriptor for the given location. Thereby, each entry may be based on the values of elements of the underlying image data located in the vicinity of the respective sampling point <b>1002</b>. Thus, in other words, the process may comprise calculating a first descriptor based on the sampling grid <b>1001</b> applied to first medical imaging data <b>220</b> with respect to the first location <b>224</b>. This first descriptor is then compared to a plurality of second descriptors of a plurality of candidate second locations <b>334</b>, <b>340</b>, <b>440</b> in a second medical imaging data set <b>220</b> as explained before. Thereby, the second descriptors may respectively be obtained by applying the sampling grid <b>1001</b> to the second medical imaging data <b>330</b> relative to the respective candidate second location <b>334</b>, <b>340</b>, <b>440</b>. Self-speaking this way of descriptor-extraction may also be combined with other aspects as explained above, e.g., the hierarchical refinement introduced in connection with <figref idref="DRAWINGS">FIG. <b>4</b></figref> and the third candidate locations <b>448</b>.</p><p id="p-0096" num="0099">As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the sampling points <b>1002</b> according to some examples are not equidistant, but the average distance between the sampling points <b>1002</b> increases with increasing distance to the given location. That is, the density of the sampling points per unit area or volume decreases with increasing distance to the given location.</p><p id="p-0097" num="0100">Further, each sampling point <b>1002</b> may be conceived as a center point or node of an associated sampling area <b>1003</b> defined around the respective sampling point <b>1002</b>. In a way, the sampling grid <b>1001</b> may be seen as comprising a regular pattern of sampling areas <b>1003</b> which respectively cover the first or second medical imaging data sets <b>220</b>, <b>330</b> if applied thereon. Sampling areas <b>1003</b> of neighboring sampling points may share a common border or margin (which may be a line or plane).</p><p id="p-0098" num="0101">If the distance between individual sampling points <b>1002</b> gets larger with increasing distance to the given location, this has the consequence that also the sampling areas get larger with increasing distance to the given location.</p><p id="p-0099" num="0102">According to some examples, the descriptor for any given location (e.g., the first location, or the candidate second locations, or the candidate third locations) is a vector comprising a plurality of entries, each entry being representative of the values of the elements located relative to a respective one of the plurality of grid points <b>1002</b>. Specifically, an entry may be based on an average property or feature of elements comprised in the respective sampling area <b>1003</b>. Specifically, the average may be based on the values of the elements. This is exemplified in <figref idref="DRAWINGS">FIGS. <b>11</b> and <b>12</b></figref>.</p><p id="p-0100" num="0103">In embodiments where the spacing between individual sampling points <b>1002</b> increases with increasing distance from the given location as in <figref idref="DRAWINGS">FIGS. <b>10</b> to <b>12</b></figref>, elements in the vicinity of the given location contribute to the descriptor to a greater extent than elements which are more distant. This is because the contributions of the latter are increasingly averaged out.</p><p id="p-0101" num="0104">The inventors have recognized that the usage of sampling grids for descriptor extraction constitutes a fast and at the same time very accurate way of encoding image information for feature matching. In particular, the usage of sampling grids <b>1001</b> spanning the entire relevant image space is computationally fast. The decrease in sampling point density may make sure that more relevant elements of a medical imaging data set contribute more than others.</p><p id="p-0102" num="0105">According to some examples, the sampling grids <b>1001</b> are defined based on generalized coordinates or world coordinates to take into account the fact that pixel spacings could be different in different studies. Therefore, descriptor voxel value offsets may be calculated for each volumetric image accounting for pixel spacings and specified scaling factors for the selected refinement level. Once the offset coordinates are computed, the descriptor may be based on pixel intensity values on those locations. Similar anatomical locations would produce similar descriptors with this approach.</p><p id="p-0103" num="0106">According to some examples, a number of different predetermined sampling grids <b>1001</b> may be provided. These sampling grids <b>1001</b> may be different in terms of the number and/or density of sampling points <b>1002</b>. The sampling grids <b>1001</b> may be suited for different use cases and/or contents and/or types of medical imaging data sets. For instance, there may be dedicated sampling grids <b>1001</b> for MRI medical imaging data sets and different dedicated sampling grids <b>1001</b> for CT medical imaging data sets. Further, there may be dedicated sampling grids for different body regions and or organs shown in the medical imaging data. Optionally, the sampling grid <b>1001</b> to be used for matching locations in first and second medical imaging data may be selected from the plurality of predetermined sampling grids <b>1001</b> based on the first and/or second medical imaging data. This may involve determining a type and or a content of the first and/or second medical imaging data and select the sampling grid <b>1001</b> from the plurality of sampling grids <b>1001</b> on that basis. With that, an optimized sampling grid <b>1001</b> may be selected for the respective use case.</p><p id="p-0104" num="0107">As an alternative, the sampling grid <b>1001</b> may be generated/adapted specifically for the respective image data. According to some examples, this may be carried out by a trained algorithm trained to generate (predefine) a sampling grid <b>1001</b> for the ensuing descriptor extraction.</p><p id="p-0105" num="0108">In <figref idref="DRAWINGS">FIG. <b>13</b></figref>, a schematic flow diagram depicting optional method steps is shown. <figref idref="DRAWINGS">FIG. <b>13</b></figref> is directed to a workflow for providing a starting point for the iterative search for the second location and/or verifying results obtained by way of finding similar descriptors as herein described.</p><p id="p-0106" num="0109">In a first step S<b>13</b>-<b>10</b>, an image registration between the first and second medical imaging data is determined.</p><p id="p-0107" num="0110">Providing at least one image registration, according to some examples, may in general comprise registering a target image (e.g., the first medical imaging data <b>220</b>) with a reference image (e.g., the second medical imaging data <b>330</b>). According to some examples, this may comprise obtaining a transformation function between target and reference image data that determines a relationship between the coordinate systems of the target image data and the reference image data such that each physiological location in the target image is mapped to the same physiological location in the reference image and vice versa. Thus, the transformation may comprise a plurality of individual displacement vectors respectively associated with the pixels or voxels (i.e., the elements) of the target image and the reference image.</p><p id="p-0108" num="0111">According to some examples, the registration may comprise a rigid registration. A rigid registration may comprise a registration in which the coordinates of pixels or voxels in one image data are subject to rotation and translation in order to register the image data to another image data. According to some examples, the registration may comprise an affine registration. An affine registration may comprise a registration in which the coordinates of data points in one image are subject to rotation, translation, scaling and/or shearing in order to register the image to another image. Thus, a rigid registration may be considered to be a particular type of affine registration. According to some examples, the registration may comprise a non-rigid registration. A non-rigid registration may provide different displacements for each pixel or voxel of the image data to be registered and can, for example, use non-linear transformations, in which the coordinates of pixels in one image are subject to flexible deformations in order to register the image to another image. Non-linear transformations may, according to some examples, be defined using vector fields such as warp fields, or other fields or functions, defining an individual displacement for each pixel/voxel in an image. Rigid image registration is very effective in cases when no deformations are expected. In comparison to rigid image registration, non-rigid image registration has a significantly greater flexibility, as non-rigid image registrations can manage local distortions between two image data sets but can be more complex to handle.</p><p id="p-0109" num="0112">In a second step S<b>13</b>-<b>20</b>, an estimated location of the given feature in the second medical imaging data <b>330</b> is determined based on the registration. Specifically, the first location <b>224</b> may be transformed into the coordinate space of the second medical imaging data <b>330</b> by subjecting it to the coordinate transformation obtained with the registration.</p><p id="p-0110" num="0113">The ensuing steps S<b>13</b>-<b>30</b>, S<b>13</b>-<b>40</b>, S<b>13</b>-<b>50</b> are directed to the usage of the registration in the location matching process. They are optional and may also be combined.</p><p id="p-0111" num="0114">At step S<b>13</b>-<b>30</b>, the estimated location may be used as candidate second location. In other words, the registration is used to provide an &#x201c;educated guess&#x201d; for the second location in order to reduce the number of iterations required to find the selected second location.</p><p id="p-0112" num="0115">At step S<b>13</b>-<b>40</b>, the estimated location may be used to verify the selected candidate second location. In particular, the distance between the estimated location and the selected candidate second location may be checked. If the selected candidate second location and the estimated location are too far apart, this may be an indication that the determination of the selected candidate second location via the discriminator extraction failed. In this regard, it should be noted that the registration is oftentimes more robust but may lead to less accurate results as compared to the feature extraction. Accordingly, the registration may allow for a good sanity check.</p><p id="p-0113" num="0116">Furthermore, the registration may be used as a fallback option. This is exploited at step S<b>13</b>-<b>50</b>, where the estimated location may be used as the selected candidate second location or, respectively, as the location at which the given feature is represented in the second medical imaging data <b>330</b>, e.g., if it is determined at step S<b>13</b>-<b>40</b> that the selected candidate second location determined by the descriptor matching cannot be quite right.</p><p id="p-0114" num="0117">A further way of optionally performing a sanity check is depicted in <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0115" num="0118">At a first step S<b>14</b>-<b>10</b>, a verification descriptor for each of a plurality of candidate verification locations in the first medical imaging data is obtained. Thereby, each verification descriptor is representative of values of elements of the first medical imaging data located relative to the respective candidate verification location according to the first predefined pattern. The predefined pattern and the descriptor extraction may be of the same types as explained in connection with <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>12</b></figref>.</p><p id="p-0116" num="0119">At a second step S<b>14</b>-<b>20</b> for each of the plurality of candidate verification locations, a similarity metric is calculated, the similarity metric indicating a degree of similarity between the second descriptor of the selected candidate second location and the verification descriptor for the candidate verification location. Thereby, essentially the same procedures may be applied as explained in connection with <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>12</b></figref>.</p><p id="p-0117" num="0120">At a third step S<b>14</b>-<b>30</b>, a candidate verification location is selected from among the plurality of candidate verification locations based on the calculated similarity metrics.</p><p id="p-0118" num="0121">At a fourth step S<b>14</b>-<b>40</b>, the quality of the location determination in the second medical imaging data is determined based on a comparison between the selected candidate verification location and the first location. If the determination of the selected candidate second location was sound, the selected candidate verification location and the first location should approximately lie at the same spot. If the selected candidate verification location and the first location are too far apart, this may be an indication that the location matching via the discriminator extraction failed for the particular first and second medical imaging data. In this case, a registration may be performed and used as a fallback as described in connection with <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0119" num="0122">In <figref idref="DRAWINGS">FIG. <b>15</b></figref>, a workflow is shown in which the location matching as herein described is used indirectly for determining like image regions in two medical imaging data sets.</p><p id="p-0120" num="0123">At step S<b>15</b>-<b>10</b>, a first region of interest in the first medical imaging data <b>220</b> is determined. The first region of interest may be seen as the image portion for which a corresponding portion is to be identified in the second medical imaging data <b>330</b>. The first region of interest may, in particular, be an image region the image data of which is not suited for the location matching based on extracting descriptors as herein described. This may be the case if the image pattern in the first region of interest does not have a sufficient discriminative strength to, e.g., sufficiently stand out against the background. For instance, this may happen if the first region of interest has a rather uniform appearance without any remarkable features.</p><p id="p-0121" num="0124">The first region of interest may represent an area within the first medical imaging data <b>220</b>, which is of specific interest for the user analyzing the first medical imaging data <b>220</b>. The first region of interest may be a part of the first medical imaging data <b>220</b>. As such, the first region of interest may have an arbitrary shape, preferably the region of interest is of circular or quadratic or box-like form. In any case, a first region of interest may be understood as a group of image elements like pixels or voxels within the first medical imaging data <b>220</b>.</p><p id="p-0122" num="0125">The first region of interest may be defined by a user or semi-automatically or (fully-) automatically by the computer-implemented method. Thus, obtaining the first region of interest may be based on processing one or more user inputs to designate the first region of interest in the first medical imaging data <b>220</b>. For instance, such user inputs may comprise scrolling to a target slice and/or defining a region of interest in the target slice.</p><p id="p-0123" num="0126">Further, obtaining the first region of interest may comprise automatically identifying an anatomical feature in the first medical imaging data <b>220</b> wherein the anatomical feature is indicative of a pathological condition of a patient. In particular, this may involve applying a detection function configured to identify anatomical features in medical imaging data.</p><p id="p-0124" num="0127">At step S<b>15</b>-<b>20</b>, the first location is selected. In particular, the first location may be at a different location than the first region of interest. The first location may relate to a given feature in the first medical imaging data <b>220</b> which can be easily recognized in both the first and second medical imaging data. In other words, the first location may be automatically selected so as to have a good discriminative strength in the first and/or the second medical imaging data. For instance, the selection may be related to a particularly bright image area or a particular image pattern.</p><p id="p-0125" num="0128">At step S<b>15</b>-<b>30</b>, an offset between the first region of interest and the first location is obtained. Optionally, this offset is provided in generalized or world coordinates that are equally applicable to the first and the second medical imaging data.</p><p id="p-0126" num="0129">At step S<b>15</b>-<b>40</b>, the selected second candidate location is obtained as described above. In other words, a location is identified in the second medical imaging data <b>330</b> that represents the given feature of the first location.</p><p id="p-0127" num="0130">At step S<b>15</b>-<b>50</b>, a second region of interest in the second medical imaging data <b>330</b> is determined based on the selected candidate second location and the offset. With that, a region is retrieved in the second medical imaging data <b>330</b> that corresponds to the first region of interest in the first medical imaging data <b>220</b>. The second region of interest is part of the second medical imaging data <b>330</b>. The second region of interest may have the same shape as the first region of interest. A second region of interest may be understood as a group of image elements like pixels or voxels within the second medical imaging data <b>330</b>.</p><p id="p-0128" num="0131">The above examples are to be understood as illustrative examples of the invention. It is to be understood that any feature described in relation to any one example may be used alone, or in combination with other features described, and may also be used in combination with one or more features of any other of the examples, or any combination of any other of the examples. Furthermore, equivalents and modifications not described above may also be employed without departing from the scope of the invention, which is defined in the accompanying claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230005136A1-20230105-M00001.NB"><img id="EMI-M00001" he="6.01mm" wi="76.20mm" file="US20230005136A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer implemented method of determining a location at which a given feature is represented in medical imaging data, the medical imaging data comprising an array of elements each having a value, the method comprising:<claim-text>obtaining a first descriptor for a first location in first medical imaging data, wherein the first location is the location within the first medical imaging data at which the given feature is represented, wherein the first descriptor is representative of values of elements of the first medical imaging data located relative to the first location according to a first predefined pattern;</claim-text><claim-text>obtaining a second descriptor for each of a plurality of candidate second locations in second medical imaging data, wherein each second descriptor is representative of values of elements of the second medical imaging data located relative to the respective candidate second location according to the first predefined pattern;</claim-text><claim-text>calculating, for each of the plurality of candidate second locations, a similarity metric indicating a degree of similarity between the first descriptor and the second descriptor for the candidate second location;</claim-text><claim-text>selecting a candidate second location from among the plurality of candidate second locations based on the calculated similarity metrics; and</claim-text><claim-text>determining the location at which the given feature is represented in the second medical imaging data based on the selected candidate second location.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the method further comprises:<claim-text>generating output data indicating the determined location at which the given feature is represented in the second medical imaging data.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer implemented method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the method further comprises:<claim-text>transmitting the output data to a display device to display a representation of the second medical imaging data and an indicator indicating, on the representation of the second medical imaging data, the determined location at which the given feature is represented.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the location at which the given feature is represented comprises determining, as the location at which the given feature is represented in the second medical imaging data, the selected candidate second location.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each candidate second location is a location at which a respective previously detected feature is represented in the second medical imaging data.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer implemented method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the first descriptor for the first location in the first medical imaging data is obtained for each of a plurality of said given features and wherein the method comprises:<claim-text>calculating said similarity metric between the first and second descriptors for pairs of the first locations and candidate second locations;</claim-text><claim-text>assigning each first location a different one of the candidate second locations based on the calculated similarity metrics between the pairs of the first locations and candidate second locations; and</claim-text><claim-text>determining, for each said first location, as the location at which the respective said given feature is represented in the second medical imaging data, the second candidate location assigned to the first location.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the candidate second locations are locations distributed through the second medical imaging data in a second predefined pattern.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer implemented method according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein determining the location at which the given feature is represented in the second medical imaging data comprises:<claim-text>determining, based on the selected candidate second location, a plurality of candidate third locations in the second medical imaging data,</claim-text><claim-text>obtaining a third descriptor for each of the plurality of candidate third locations in the second medical imaging data, each third descriptor being representative of values of elements of the second medical imaging data located relative to the respective candidate third location according to the first predefined pattern;</claim-text><claim-text>calculating, for each of the plurality of candidate third locations, a similarity metric indicating a degree of similarity between the first descriptor and the third descriptor for the candidate third location;</claim-text><claim-text>selecting a candidate third location from among the plurality of candidate third locations based on the calculated similarity metrics indicating the degree of similarity between the first descriptor and the respective third descriptors; and</claim-text><claim-text>determining the location at which the given feature is represented in the second medical imaging data based on the selected candidate third location.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computer implemented method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the candidate third locations are locations distributed through the second medical imaging data in a third predefined pattern in a region of the selected second location, wherein a distance between the candidate third locations in the third predefined pattern is less than a distance between the candidate second locations in the second predefined pattern.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a descriptor for a given location is a vector comprising a plurality of entries, each entry being representative of the values of the elements located within a respective one of a plurality of predefined boxes located relative to the given location according to the first pattern.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The computer implemented method according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein each entry of the plurality of entries of the vector is an average of the values of elements located within a respective one of the plurality of predefined boxes.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the first predefined pattern is a sampling grid comprising a plurality of grid points located relative to a given location, and</claim-text><claim-text>a descriptor for the given location is a vector comprising a plurality of entries, wherein each entry is representative of the values of the elements located relative to a respective one of the plurality of grid points.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The computer implemented method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein<claim-text>a density of grid points per elements of first and second medical imaging data decreases with increasing distance to the given location.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The computer implemented method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein<claim-text>each entry of the plurality of entries of the vector is an average of the values of elements located within a sampling area respectively defined around a respective one of the plurality of sampling points.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>obtaining a first region of interest in the first medical imaging data;</claim-text><claim-text>determining an offset between the first region of interest and the first location; and</claim-text><claim-text>determining a second region of interest in the second medical imaging data based on the location and the location and the offset.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the medical imaging data is integral image data.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The computer implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the similarity metric comprises a normalized mutual information similarity between the first descriptor and the second descriptor.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. An apparatus, comprising:<claim-text>a non-transitory memory device for storing computer readable program code; and</claim-text><claim-text>a processor in communication with the memory device, the processor being operative with the computer readable program code to perform operations for determining a location at which a given feature is represented in medical imaging data, the medical imaging data comprising an array of elements each having a value, the operations including<claim-text>obtaining a first descriptor for a first location in first medical imaging data, wherein the first location is the location within the first medical imaging data at which the given feature is represented, wherein the first descriptor is representative of values of elements of the first medical imaging data located relative to the first location according to a first predefined pattern;</claim-text><claim-text>obtaining a second descriptor for each of a plurality of candidate second locations in second medical imaging data, wherein each second descriptor is representative of values of elements of the second medical imaging data located relative to the respective candidate second location according to the first predefined pattern;</claim-text><claim-text>calculating, for each of the plurality of candidate second locations, a similarity metric indicating a degree of similarity between the first descriptor and the second descriptor for the candidate second location;</claim-text><claim-text>selecting a candidate second location from among the plurality of candidate second locations based on the calculated similarity metrics; and</claim-text><claim-text>determining the location at which the given feature is represented in the second medical imaging data based on the selected candidate second location.</claim-text></claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The apparatus of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the processor is operative with the computer readable program code to generate output data indicating the determined location at which the given feature is represented in the second medical imaging data.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. One or more non-transitory computer-readable media embodying instructions executable by machine to perform operations for determining a location at which a given feature is represented in medical imaging data, the medical imaging data comprising an array of elements each having a value, the operations comprising:<claim-text>obtaining a first descriptor for a first location in first medical imaging data, wherein the first location is the location within the first medical imaging data at which the given feature is represented, wherein the first descriptor is representative of values of elements of the first medical imaging data located relative to the first location according to a first predefined pattern;</claim-text><claim-text>obtaining a second descriptor for each of a plurality of candidate second locations in second medical imaging data, wherein each second descriptor is representative of values of elements of the second medical imaging data located relative to the respective candidate second location according to the first predefined pattern;</claim-text><claim-text>calculating, for each of the plurality of candidate second locations, a similarity metric indicating a degree of similarity between the first descriptor and the second descriptor for the candidate second location;</claim-text><claim-text>selecting a candidate second location from among the plurality of candidate second locations based on the calculated similarity metrics; and</claim-text><claim-text>determining the location at which the given feature is represented in the second medical imaging data based on the selected candidate second location.</claim-text></claim-text></claim></claims></us-patent-application>
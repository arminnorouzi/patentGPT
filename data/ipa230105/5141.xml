<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005142A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005142</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17903660</doc-number><date>20220906</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>3</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>30</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>77</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>30</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>0012</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>3</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>30</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>77</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>30</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10016</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10056</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20076</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20081</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20084</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30044</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">BOVINE EMBRYO EVALUATION USING AI/ML ANALYSIS OF REAL-TIME FRAME SPEED VIDEO FOR PREDICTING FEMALE-SEX OFFSPRING</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17688109</doc-number><date>20220307</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11455725</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17903660</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17687265</doc-number><date>20220304</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17688109</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17687319</doc-number><date>20220304</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17687265</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17687368</doc-number><date>20220304</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17687319</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17687416</doc-number><date>20220304</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17687368</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17687437</doc-number><date>20220304</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17687416</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/US2021/044423</doc-number><date>20210803</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17687437</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>63060554</doc-number><date>20200803</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Emgenisys, Inc.</orgname><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>WESSELS WELLS</last-name><first-name>Cara Elizabeth</first-name><address><city>Dripping Springs</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KILLINGSWORTH</last-name><first-name>Russell</first-name><address><city>Shamrock</city><state>TX</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Emgenisys, Inc.</orgname><role>02</role><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A computer-implemented system and method for predicting female sex bovine offspring to result from a bovine embryo by processing video image data of the embryo. The method includes receiving image data derived from video of a target embryo taken at substantially real-time frame speed during an embryo observation period of time. The video contains recorded morphokinetic movement of the target embryo occurring during the embryo observation period of time. The movement is represented in the received image data and the received image data is processed using a model generated utilizing machine learning and correlated embryo outcome data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="92.37mm" wi="158.75mm" file="US20230005142A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="192.53mm" wi="119.13mm" orientation="landscape" file="US20230005142A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="207.01mm" wi="117.77mm" orientation="landscape" file="US20230005142A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="177.63mm" wi="151.81mm" orientation="landscape" file="US20230005142A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="178.22mm" wi="152.57mm" orientation="landscape" file="US20230005142A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="217.25mm" wi="128.78mm" orientation="landscape" file="US20230005142A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="215.82mm" wi="105.41mm" orientation="landscape" file="US20230005142A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="216.07mm" wi="132.93mm" orientation="landscape" file="US20230005142A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="185.25mm" wi="147.24mm" orientation="landscape" file="US20230005142A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="218.78mm" wi="123.61mm" orientation="landscape" file="US20230005142A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="148.25mm" wi="149.44mm" orientation="landscape" file="US20230005142A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="215.82mm" wi="140.72mm" orientation="landscape" file="US20230005142A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present patent application is a continuation patent application of U.S. application Ser. No. 17/688,109 filed Mar. 7, 2022, which is a continuation patent application of each of the following pending patent applications:</p><p id="p-0003" num="0002">(a) U.S. application Ser. No. 17/687,265 filed Mar. 4, 2022, which is a continuation application of PCT/US2021/044423 filed Aug. 3, 2021, designating the United States and which claims the benefit of U.S. Provisional Patent Application No. 63/060,554, filed Aug. 3, 2020;</p><p id="p-0004" num="0003">(b) U.S. application Ser. No. 17/687,319 filed Mar. 4, 2022, which is a continuation application of PCT/US2021/044423 filed Aug. 3, 2021, designating the United States and which claims the benefit of U.S. Provisional Patent Application No. 63/060,554, filed Aug. 3, 2020;</p><p id="p-0005" num="0004">(c) U.S. application Ser. No. 17/687,368 filed Mar. 4, 2022, which is a continuation application of PCT/US2021/044423 filed Aug. 3, 2021, designating the United States and which claims the benefit of U.S. Provisional Patent Application No. 63/060,554, filed Aug. 3, 2020;</p><p id="p-0006" num="0005">(d) U.S. application Ser. No. 17/687,416 filed Mar. 4, 2022, which is a continuation application of PCT/US2021/044423 filed Aug. 3, 2021, designating the United States and which claims the benefit of U.S. Provisional Patent Application No. 63/060,554, filed Aug. 3, 2020;</p><p id="p-0007" num="0006">(e) U.S. application Ser. No. 17/687,437 filed Mar. 4, 2022, which is a continuation application of PCT/US2021/044423 filed Aug. 3, 2021, designating the United States and which claims the benefit of U.S. Provisional Patent Application No. 63/060,554, filed Aug. 3, 2020; and</p><p id="p-0008" num="0007">(f) International Patent Application No. PCT/US2021/044423 filed Aug. 3, 2021, designating the United States and which claims the benefit of U.S. Provisional Patent Application No. 63/060,554, filed Aug. 3, 2020.</p><p id="p-0009" num="0008">Each of the aforementioned patent applications is expressly incorporated herein by reference, in its entirety, without disclaimer.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0010" num="0009">Combining state-of-the-art artificial intelligence (AI), machine learning (ML), video image data processing and optics systems, practical insights from clinical embryologists and scientific input from data engineers, the present technology provides the world's most comprehensive embryo evaluation system for detecting and/or predicting embryo morphokinetics, viability and developmental potential in a single, easy to use system. The technology processes digital video image data from real-time video taken of an embryo proximate in time before transfer or storage such as by cryopreservation. The image data of the resulting signal is then processed to reveal information, heretofore hidden, to the operator and other interested parties. With this technology, model-processed real-time video image data of an embryo can predict, among other things: (1) the embryo's present viability at time of transfer, (2) the embryo's inviability at time of planned transfer, (3) the embryo's likelihood (qualitatively, quantitative and/or probabilistic) to result in pregnancy and produce live offspring, (4) the embryo's likelihood of producing a male offspring, (5) the embryo's likelihood of producing a female offspring, (6) genetic inferiority (likelihood to embody disease or genetic issue, and of what type) of the embryo and (7) genetic superiority (likelihood to produce desired traits in offspring) of the embryo. The instant deep learning model(s) can also rank a number (group) of embryos based on one or more predictive embryo characteristics or predicted offspring traits based on generated relative strengths (probability of occurrence) of the predicted characteristic among the group of blastocysts enabling an embryologist's selection and transfer of the most desirable embryos into recipient(s).</p><p id="p-0011" num="0010">In one embodiment, video image data is utilized to develop deep learning models that provide the basis for an AI/ML-based software package that enables a non-invasive, quantitative, non-subjective system and method to identify high-quality, viable embryos likely to result in pregnancy and healthy offspring as exemplified in <figref idref="DRAWINGS">FIG. <b>1</b></figref> of the accompanying drawings. Currently, embryologists have limited ability to evaluate embryo health and viability, making it all too common to unknowingly transfer dead or otherwise inviable embryos into recipients. The present technology allows a user to make more informed decisions about which embryo(s) to transfer and reduces the transfer of low-quality embryos which will not establish pregnancy. Technologies such as this that improve pregnancy outcomes of IVF beneficially affect patients both physically and psychologically, as well as having a positive financial impact on the industry as a whole through cost reduction. Another aim of this technology is to enhance the workflow of the user by enabling a single multi-embryo video/scan to provide immediate feedback through real time image data collection and processing. In the case of animal breeding and production, the technology is utilized to select the highest quality embryos that are most likely to achieve pregnancy and produce disease-free offspring that embody the most superior of desired traits, including sex.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> represents a goal of the presently disclosed technology which is, among others, predicting an embryo's competence to establish pregnancy and produce the live birth of a desired offspring as herein described;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts the outcome of video data processed using a model trained in accordance with the presently disclosed technology and which demonstrates: (1) a prediction accuracy rate of 91% for blastocysts that will not achieve pregnancy upon transfer and (2) a prediction accuracy rate of 100% for blastocysts that will achieve pregnancy upon transfer;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a series of 12 frames extracted from a video clip of a blastocyst using a microscope at 150&#xd7; magnification;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts the same 12 frames of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, but after being filtered using motion magnification software;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a graph showing that morphokinetic activity is predictive of a preimplantation embryo's likelihood to produce pregnancy;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a histogram depicting morphokinetic patterns of embryos that produced pregnancy;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a histogram depicting the range of embryo movement within subzonal space as being an indicator of embryo competency for producing pregnancy;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates components, area measurements and axial lines of measurement on a blastocyst that can be utilized to describe the blastocyst's morphokinetic activity;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>9</b></figref> superimposes lines of measure on an embryo for demonstrating movement of the inner cell mass within the zona pellucida of a blastocyst (an embryo) by assessing the varying distances therebetween;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a graph showing that high morphokinetic activity is predictive of a preimplantation embryo's likelihood not to produce pregnancy;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a schematic of an exemplary deep learning neural network useable for presently disclosed AI/ML model training, model generation and video image data processing using the generated models for predicting embryo traits and produced offspring characteristics; and</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts an exemplary processor-based computing system suitable for use as a platform for executing certain routines of the presently disclosed AI/ML modeling.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0024" num="0023">Users of the presently disclosed technology include reproductive endocrinologists, specialized OB/GYN's, embryologists, veterinarians, animal breeders and trained laboratory personnel, among others. In the realm of human reproduction, users of this technology include embryology lab directors and clinical embryologists who are practicing Assisted Reproductive Techniques (ART). ART patients, and in particular IVF (In Vitro Fertilization) patients, are prime influencers of this technology as they play a key role in selecting which fertility treatment(s) to employ that best assures a live birth out of their scarce and fragile inventory of gametes/oocytes/embryos. As a precursor to this technology's development, customer interviews were conducted with 231 interviewees during the 2018 National Science Foundation I-Corps National Atlanta Winter Cohort regarding needs in the industry. Based on the results of those interviews, the perspective became clear that there have not been any transformative technologies to predict embryo viability in nearly four decades.</p><p id="p-0025" num="0024">In practice, clinical embryologists and/or otherwise trained personnel are responsible for selecting the embryo to be transferred into the recipient and that responsible person often unknowingly selects and transfers non-viable embryo(s) into the recipient due to lack of accurate means to evaluate embryo health and quality. Embryologists' and fertility clinics' reputations are predominantly based on published pregnancy success rates, so there is active competition for the highest rankings, as high rankings best produce revenue. Poised for success, this technology is in a class of its own as the only embryo assessment tool that is NOT subjective (non-subjective), NOT invasive (non-invasive) and enables real-time assessment of presently existing embryo morphokinetics in both human and non-human mammals.</p><p id="p-0026" num="0025">Infertility in humans is classified as a disease by the World Health Organization and affects 48.5 million couples worldwide. In Vitro Fertilization is presently the most effective treatment of infertility, but the produced livebirth rate in 2018 was only 26%. Unfortunately, IVF is renowned for being expensive, stressful and generally unsuccessful, and which more often than not, delivers a disappointing experience.</p><p id="p-0027" num="0026">On the positive side however, ART is expanding the relevant market as it is no longer just a treatment of infertility but has the added the capability to extend fertility to others in many different situations though cryopreservation of eggs, sperm and embryos. One example is the preservation of healthy cells/gametes of cancer patients prior to undergoing chemotherapy in the event the patient is not able to produce them after such treatment. ART also enables single individuals and homosexual couples to enjoy biological families, which might otherwise not have been possible. For these reasons, as well as others, ART is becoming a routine method to start or extend a family, but improvements are definitely welcome.</p><p id="p-0028" num="0027">Since the birth of Louise Brown in 1978 by IVF, over 10 million babies have been born via IVF and Intracytoplasmic Sperm Injection (ICSI), worldwide. In the United States, babies born from IVF/ICSI comprise nearly 2% of the annual birth count. For IVF, a woman is given super-ovulatory hormones to encourage more eggs to develop in the ovaries at once. The woman's follicular development is closely monitored to time the egg retrieval in which the fertility specialist aspirates the eggs from the ovary. Each egg is fertilized with sperm and the fertilized eggs are permitted to develop into embryos over the course of five to six days. It is likely that multiple embryos will develop into seemingly healthy blastocysts. From them, the embryologist is responsible for choosing which embryo(s) to transfer into the patient. Any remaining embryos are typically frozen and can be used for subsequent transfer attempts. This process is referred to as a &#x201c;round&#x201d; of IVF and generally costs about $23,000. If a child is not produced in this first round, the patient can opt to undergo a frozen transfer, in which one or more of the remaining frozen embryos is thawed and transferred into the patient. Frozen embryos can be transferred until no more are available, in which case the entire process must start over. On average, patients undergo 2.7 rounds of IVF and spend $60,000 to achieve a pregnancy that survives to term. Unfortunately, a major contributor to the low success rate of IVF is an inability to discern and choose healthy, viable embryos at the time of transfer.</p><p id="p-0029" num="0028">There are approximately 450 IVF clinics in the United States, as well as donor egg banks that collaborate with over 150 of the IVF clinics. Out of those clinics, 271,398 human embryo transfer procedures were performed in 2018. Approximately 50% of those IVF procedures in women ages 35 and under resulted in a live birth. For women ages 42 and older, the number plumets to 3.9% of egg transfers that result in a birth. With that as background, it is clear that any technology that enables embryologists to select embryos most likely to produce a healthy birth and/or survive and thrive after cryopreservation has great prospect for adoption by the industry. Just considering human embryo transfers in the United States (excluding animal transfers), it is calculated that a 3% improvement in pregnancy outcomes would currently provide over $187,000,000 in annual patient savings. Additionally, technologies like this that improve pregnancy success on a per-transferred-embryo basis lessens the need to transfer multiple embryos into a single recipient which reduces the risk of undesired, multiple births. This clearly reduces costs, but equally important, it reduces complications to mothers and babies from simultaneous gestations.</p><p id="p-0030" num="0029">Embryo screening is limited by the requirement that embryos must survive the diagnostic process, unharmed. Many existing assessment methods such as staining and electron microscopy are only used in a research setting because the processes are lethal. The most commonly used method to assess the quality of embryos and oocytes for transfer is a morphological analysis using a light microscope. In this assessment, the technician examines the cells for visually apparent characteristics such as cell shape, size, symmetry and color. While this method is noninvasive and cost effective, it is subjective, relying solely on the examiner's discretion and does not include information about an embryo's biochemical content or genetic make-up. As an aid to morphological analysis, time lapse imaging systems, such as the EmbryoScope&#xae;, are available that link developmental events with the elapsed time at which the different events occur. However, in a recent report published in the Journal of Reproduction and Genetics, only 17% of surveyed labs had a time lapse imagining system. Moreover, a majority of surveyed lab directors responded that &#x201c;time lapse imaging will not become the standard of care because the technology is too expensive, there is no evidence it provides additional benefit and it is too time intensive and impractical.&#x201d;</p><p id="p-0031" num="0030">Today, genetic assessment requires a biopsy of cells from the embryo. The biopsied cells are sent to an off-site lab for genetic testing and the left-behind embryo must be frozen until lab results are received. Pre-implantation Genetic Testing (PGT) encompasses both pre-implantation genetic screening and pre-implantation genetic diagnosis, which can inform embryologists and patients of genetic abnormalities (such as aneuploidy or trisomy), genetic disease and embryo sex. PGT was designed for high-risk patients with a known condition or genetic trait, and not for the average IVF/ART patient. Disadvantages of PGT are its invasive nature, increased risk of cell death and it requires expensive equipment and highly trained personnel. The costs range from $4000-$7500, which are in addition to the base fees associated with IVF procedures. PGT data suggests there is no difference in pregnancy rate for patients under the age of 36 years old. Other reports claim PGT significantly increases pregnancy outcomes, but many physicians warn that it also increases the incidence of miscarriage, which indicates that the &#x201c;take home baby rate&#x201d; is likely unimproved. In contrast, the presently disclosed non-invasive embryo analysis system provides a newly-available superior standard of care, easily incorporated into current laboratory protocols and procedures.</p><p id="p-0032" num="0031">The solutions made possible by the present technology will quickly penetrate the $6.2 billion US market of the human clinical infertility sector. It also easily scales to service the $37.7 billion global infertility market. With fewer than half of the people suffering from infertility seeking care, technologies such as the present that reduce cost and increase success rates will undoubtedly expand and grow the already substantial infertility care market. As an example, one published market analysis indicates that a 50% reduction in the price of IVF services would translate into a 160% increase in the utilization of fertility services.</p><p id="p-0033" num="0032">Turning now from the human experience to the animal sciences, it is noted that the global population is expected to reach 9.5 billion by 2050, an approximately 20% increase over 2020. It is projected that the demand for animal derived protein will at least double, resulting in concerns over food security and sustainability. Current agricultural practices are already placing tremendous pressure on the earth's finite resources and are largely responsible for a vast proportion of greenhouse gas (GHG) emissions. Well managed cattle (also referred to herein as cows and/or bovine) production helps to meet food security and environmental goals, as beef and dairy products both provide nutrient-rich, high-quality protein to consumers. Cattle are particularly suited to meat production as they are a robust animal that adapt well to changes in climate and can graze on pastureland generally not suitable for crop production due to climate, soil and topographic limitations. Cows convert forage into high quality protein and excrete fertilizer as a beneficial by-product. Modern cattle production practices have been adapted to reduce the industry's carbon footprint and as a result methane output has declined approximately 40% since 1980. Genetic selection through progressive breeding strategies can further reduce GHG emissions from cattle production by improving animal efficiency, improving the feed conversion ratio, reducing dry matter intake and reducing enteric methane production. Selection for genetic superiority in cattle, among other animals, is enabled by the presently disclosed technology in which an appropriately trained AI/ML model(s) predicts the likelihood that a particular embryo will produce offspring having desired characteristic(s) based on processing digital video image data extracted from a real-time, short duration video typically taken right before transfer or storage (cryopreservation) of the embryo.</p><p id="p-0034" num="0033">As stated above, methane (CH4) is the major green-house gas emitted by ruminant production systems with CH4 from enteric fermentation accounting for 12% to 17% of that emission. Diet is a major factor (roughage and concentrate) contributing to methane emissions from ruminants. Dietary aspects known to reduce ruminant methane production include decreasing the proportion of cereal grains and legumes in the animals' diets and adding plant species that contain secondary metabolites such as tannins and saponins which affect methanogenesis in the rumen and reduce ruminant methane emissions. Effectiveness of feedlot programs implementing dietary improvements has improved the carbon footprint of beef production in Canada to as low as 17 kg of carbon dioxide equivalents (CO2e) per kg of food for feedlot finished beef as compared to grass-finished beef in Brazil that emit as much as 40 kg CO2e per kg of food. Despite the known advantages of certain plants, grassland renovation is often not practical as many of these plant species are weak competitors compared to native grasses and consequently is all-too-often not affordable or sustainable. Therefore, the most practical and rapid mitigation procedure is to reduce the per cow CH4 emission through animal breeding and genetic selection for feed efficiency, as those effects are permanent and cumulative.</p><p id="p-0035" num="0034">Genetic selection utilizing the present technology can reduce GHG emissions from beef and dairy cattle production systems because it: (1) enables increased production per animal which reduces the number of individual animals to produce the same amount of beef and dairy; (2) lowers emissions per unit of beef or dairy produced; and (3) reduces consumption of grain, concentrates, roughage, water and land. Embryo transfer and in vitro fertilization can further perpetuate genetic traits of superior animals because they enable genetically superior animals to produce more offspring in a single year than can be achieved in nature. Additionally, ART can help producers control the sex ratio to be favorable for the most desired sex for the operation. As an example, dairies have a preference for female cows because they produce milk and males do not. Potentiated bovine embryo transfer provides other economic advantages such as decreased calving intervals, more consistent calf crop production and maximized product value. Due to these benefits, ET and IVF have become routine breeding strategies in livestock operations and approximately 2.5 million cattle embryos are transferred in North America each year.</p><p id="p-0036" num="0035">To perform ET or IVF currently, superior female animals referred to as &#x201c;donors&#x201d; are stimulated with superovulatory hormones to produce an increased number of oocytes. The oocytes can be aspirated from the ovary by a veterinarian and fertilized in vitro or the animal can be artificially inseminated and fertilized embryos can be flushed from the uterus six to seven days later. Today, the veterinarian or embryologist examines the embryos under a light microscope and assigns a grade based on visible morphological characteristics. Highly graded, grade-1 and grade-2 embryos are transferred into recipients or frozen for use at a later date.</p><p id="p-0037" num="0036">Unfortunately, the success rates of ET and IVF in cattle are still very low. The success rate (pregnancy achieved) of ET today is less than 65% in cattle, and the success rate of conventional IVF is less than 30% in cattle. While causes of failed pregnancy are multi-factorial and can stem from embryonic, maternal and/or environmental stressors, it is estimated that 20% of transferred embryos are actually non-viable at the time of transfer and will never result in pregnancy.</p><p id="p-0038" num="0037">Technology that could increase pregnancy rates and optionally control sex ratio would be extremely valuable. For cattle, approximately $1200 is invested into each embryo transferred, regardless of whether it establishes a pregnancy or produces a calf of desired sex. With current pregnancy outcomes at less than 65% for conventional embryo transfer and less than 30% for IVF, technology such as that presently disclosed that improves pregnancy outcomes and provides significant savings to producers will be quickly adopted. Additionally, enabled selection for genetic superiority and desired sex adds further value. ET coupled with the use of the present technology is the fastest way to change and improve the genetics in a herd and maximize beef producer and dairy profitability.</p><p id="p-0039" num="0038">The presently disclosed technology facilitates the provision of a comprehensive, portable platform for obtaining, on-site, real-time embryo video clip(s), and while still on-site, processing the obtained video image data using an appropriately trained AI/ML model to make relevant predictions about a target embryo(s) and/or offspring produced therefrom.</p><p id="p-0040" num="0039">Aspects of the present technology that provide a competitive advantage include: (1) its non-invasive nature, (2) it is not subjective, (3) it utilizes quantitative analysis that incorporates artificial intelligence and deep learning algorithms, (4) it evaluates and/or predicts embryo growth, health, sex and many other embryo characteristics and/or traits of offspring produced therefrom by processing image data from real-time video and provides immediate diagnostic feedback (in minutes, if not seconds) to the user at an affordable price. This technology subjects the target embryo to essentially no additional risk, does not require biopsy or manipulation of cells and facilities the evaluation of multiple embryos at one time resulting in predictive data being available for each embryo in minutes, if not less. In an alternate configuration, the presently disclosed technology enables the user to &#x201c;see&#x201d; changes in embryo morphokinetics within the same time frame, if the diagnostic image data is optionally processed for magnification/amplification as herein described.</p><p id="p-0041" num="0040">At different times, real-time video image data has been collected from anywhere between 150 and 1000 bovine embryos for any one study. Real-time digital video image data is collected and processed from the bovine embryos, together with correlated pregnancy and/or offspring characteristic/trait data (correlated outcome data). The video from which the real-time video image data is derived must contain a video resolution sufficient to record morphokinetic movement of the target embryo. From the video image data, changes in embryo morphokinetics are observed in substantially real time. Another characteristic of the target embryo evidenced in the received image data is elasticity of the embryo's outer wall. Utilizing the correlated outcome data for model training, predictive model(s) have been generated regarding produced pregnancy and offspring outcomes.</p><p id="p-0042" num="0041">According to this disclosure, the origin of the digital video image data used for both AI/ML model training and predictive processing is real-time video taken of pre-implantation embryos that are typically in the blastocyst or morula stage of development, and which occurs between about five to nine days, post fertilization. The embryos can be the product of either in vitro (outside the donor) fertilization (&#x201c;IVF&#x201d;) or in vivo (within the donor) fertilization by artificial insemination. In the case of in vivo fertilization, the produced embryos are subsequently flushed from the host, typically for transfer into multiple individual recipients. In this specification, references to &#x201c;embryo&#x201d; include at least blastocyst and morula stage embryos and, vice versa, regardless of the embryo being the product of in vitro or in vivo fertilization.</p><p id="p-0043" num="0042">For taking the referenced video(s), one or more embryos are placed in a disposable, typically polystyrene container (dish) compatible with the employed video image and diagnostic equipment. Advantageously, such receiving dish can have a unique QR code compatible with the analytic software for embryo identification. In one configuration, the dish can comprise (include, but not be limited to) a plurality of pre-labeled wells, each intended to receive one embryo, and which among other things: (1) aids proper placement of the embryos in the technician's and/or camera's field of view, (2) provides an identify to each of several contained embryos, and (3) correlates generated predictions to the respective embryos.</p><p id="p-0044" num="0043">The real-time digital video clip(s) can be taken with a variety of video imaging equipment including, among others, digital cameras, action cameras, smartphone cameras, tablet cameras, board cameras and the like. In the instance of board cameras, also called printed circuit board (PCB) cameras, the included optical devices and image sensors are mounted directly on a circuit board, as is often the case in smartphones. An associated display can be optionally provided to a board camera, as is the case with a smartphone, and the image signals are relayed through an I/O of the PCB. As there are no analog controls, recording options are also controlled through the interface.</p><p id="p-0045" num="0044">It is desirable that each real-time video clip comprising image data used as training data (and subsequently, video-based target image data to be analyzed using resulting so-trained models) be relatively short. For example, the video clips advantageously extend from around fifteen seconds up to several minutes long in duration. It is not necessary that each clip be individually recorded. Multiple short duration clips can be excised out of a longer blastocyst video. The duration of the training clip is selected to correlate best to video image data that will be processed by the resulting model; therefore, utilizing training data source clips of similar duration subsequently enables more accurate predictions from the generated model.</p><p id="p-0046" num="0045">Using appropriately trained model(s), assessment is made of a blastocyst's movement recorded in one of these video clips of relatively short duration. The duration of the video clip is preferably 30 seconds or less (5, 10, 15, 20, 25, 30 seconds), but the duration of the clip can be as much as one minute, two minutes, 5 minutes or more, though such longer clips are less desirable given their increased amount of constituent data. Video described in this disclosure is referred to as real-time video, as compared to time-lapse video that is historically known for use in embryo evaluation and assessment. Time-lapse &#x201c;video&#x201d; is made-up of a series of consecutive still photos or &#x201c;frames&#x201d; that have substantial time-spacing (30 seconds or more, but typically minutes or hours) therebetween. Heretofore, relatively short duration, real-time video recordings of embryos have not been analyzed regarding existing embryo short, rapid morphokinetic movement because none was visibly detectable, even under typically employed microscope magnification.</p><p id="p-0047" num="0046">In fact, as described herein, significant morphokinetic movement has been revealed to be occurring in observed blastocysts over the short video time periods. In accordance with the present disclosure, this movement is recorded using real-time video taken via a microscope at a magnification power (e.g., 150&#xd7;) heretofore accepted as only being suitable for observing a &#x201c;static&#x201d; embryo (i.e., a &#x201c;snap-shot view&#x201d;). This was a reasonable deduction because technician-observation of a blastocyst under microscope magnification for the same amount of time as video is now taken does not reveal the morphokinetic movement that is occurring because even under microscope magnification, that movement is still humanly imperceptible. Now knowing that the blastocyst's morphokinetic movement is recorded in the image data of these real-time videos as described herein, even though not perceptible, the image data is suitable for model training and/or predictive processing using generated model(s).</p><p id="p-0048" num="0047">The presently described real-time video clips each comprise a series of consecutive, equal time-spaced digital image frames, and the duration of the time spacing is referred to as frame speed. A recorded blastocyst morphokinetic movement traverses a short distance, at a fast rate, and therefore has a commensurately short duration. Consequently, the frame speed utilized for the recordings should be of similar duration, and preferably faster. Exemplarily, frame speeds of ten frames-per-second (10 fps) and fifteen frames-per-second (15 fps) have been utilized to capture blastocyst movement. In practice, faster frame speeds have proven beneficial, particularly in training stages of the presently disclosed AI/ML analysis because the quick, short-distance morphokinetic movements made by the blastocyst are captured with greater accuracy, clarity and fidelity when faster frame speeds are used. Conversely, as video frame speed decreases and there is a greater time gap between consecutive frames, the blastocyst movement becomes less perceptible. At spacings greater than about two frames per second (2 fps), individual morphokinetic movements of the blastocyst can become unobservable. When the duration of a morphokinetic movement is less then the frame speed, that movement can be &#x201c;lost&#x201d; in the gap-space between two frames that &#x201c;straddle&#x201d; that movement, especially if the movement is a rebounding motion that at first occurs in one direction, and then elastically &#x201c;snaps back,&#x201d; all within the gap-space between two straddling frames.</p><p id="p-0049" num="0048">Whether being prepared as training data or as target data to be analyzed using generated model(s), preprocessing of the blastocyst image data can advantageously include normalizing the &#x201c;raw&#x201d; image data to that of a &#x201c;standard,&#x201d; comparable blastocyst. Though various known methods can be used to accomplish such normalization of video image data, here, the desired end result is to make each &#x201c;image&#x201d; of each blastocyst comparable to one another, with minimized &#x201c;noise&#x201d; caused by different setups used to take the various original videos. One example is to adjust each &#x201c;image&#x201d; of each blastocyst to the same &#x201c;size&#x201d; by scaling up (expanding) or scaling down (shrinking) the respective images to a &#x201c;standard size.&#x201d;</p><p id="p-0050" num="0049">In some instances, the view area of the videos is normalized to be the same, but not the size of each blastocyst image. This type of normalization is used when relative size drives a predictable outcome. For instance, relative size can be predictive of blastocyst viability and sex. Relatedly, relative blastocyst size can also be a determinative or desirable differentiating factor amongst a group of co-fertilized blastocysts (multiple eggs fertilized at the same time and grown for the same time period) that are being model-assessed for viability and/or sex, and relative size is predictive, or can at least be used to rank the blastocysts for certain predictable pregnancy characteristics and/or offspring traits amongst the group of embryos.</p><p id="p-0051" num="0050">During the training process, a model can be trained to predict among other things about the embryo: viability, likelihood to produce pregnancy, likelihood to result in a live birth, offspring sex probability (how likely to produce a male offspring or how likely to produce a female offspring), and the presence or absence of genetic anomalies and disease, such as diabetes, cancer, other cell growth and the like or the capability for passing along desired characteristic(s) to offspring, such as highly efficient feed utilization.</p><p id="p-0052" num="0051">As an adjunct, embryo video image data processing has been employed in accordance with the present disclosure to observe and evaluate embryo movement responsive to an induced environmental stressor and determined that the observed motion is predictive of related outcomes (good/bad) that are embodied in resulting embryos and/or offspring. This can be useful to determine early prognosis of cancer, metabolic profile, genetic defects and the like. Studying embryo homeostasis mechanisms by enabling visualization and/or other analysis of embryo response (typically movement) to environmental changes has been determined to be useful to optimize culture systems, media, materials, nutrients, and to evaluate cellular metabolites, ambient environment impacts (light, temperature, pressure and the like) and overall developmental competency. Relatedly, the development/testing of vaccines have been aided by the present technology. It has been noted that embryos experience predictive morphokinetic motion when inoculated with certain pathogens. It has also been observed that pathogen-carrying embryos (infected, but otherwise unaffected) experience predictive morphokinetic motion when exposed to vaccines, typically being tested for efficacy against the carried pathogen.</p><p id="p-0053" num="0052">As an example of that described above, it is known that cystic fibrosis (CF) is caused by a genetic mutation in the CF Transmembrane Conductance Regulator gene (CFTR gene) that regulates the movement of chloride in the body. Prospective parents can be screened to determine their carrier status, but the only way to determine whether the genetic mutation has been passed along to an embryo is through pre-implantation genetic diagnosis via biopsy. The expression of CF is an inability to regulate salt and water transport across epithelial tissue. In accordance with the teachings of the present disclosure, processed embryo video image data revealed that embryos embodying the CF genetic mutation experienced detectible reactive motion when exposed to chloride. In this case, clinical exposure was created by adding chloride-containing material (salt) to the liquid media containing the embryo. When an embryo carried the CFTR gene mutation, the addition of chloride stressed the embryo and caused responsive observable motion. In accordance with instant teachings, an appropriately trained model was used to process digital image data from video taken of the potentially affected embryo and predicted whether the CFTR gene mutation was present. The prediction was made in terms of the likelihood (probability) that a resulting offspring would suffer cystic fibrosis. Conversely, the videos of embryos that &#x201c;tolerated&#x201d; the addition of chloride to their containing media showed much less reactionary motion. The video image data of that motion was processed using the trained model and a likelihood was predicted that resulting offspring would not embody the CF genetic mutation. In summary, AI/ML models generated according to the teachings of the present disclosure have been demonstrated to competently process digital image data sourced from video taken of embryos responding to an induced stimuli indicative of the presence of a gene mutation in an embryo and predict the likelihood resulting offspring will embody the mutation.</p><p id="p-0054" num="0053">The protocol and process for predicting the presence of most genetic and metabolic diseases embodied in an embryo, and the likelihood of its expression in resulting offspring, follows that which is described above for cystic fibrosis. For example, reactionary motion by an embryo to glucose added to the containing media predicts diabetes, while potassium predicts Hyperkalemic Periodic Paralysis in horses, among others.</p><p id="p-0055" num="0054">As intimated above, the present technology facilitates non-invasive embryo sex selection. There is scientific evidence indicating that male embryos develop faster than female embryos. This is observed by total cell count at the blastocyst stage of development. The data is predominantly anecdotal because it is difficult to count cells non-invasively without harming the embryo. However, for there to be greater male cell count over a predetermined period of time, the number of cells in &#x201c;male&#x201d; embryos must multiply at a faster rate. In accordance with the present teachings, processing video image data utilizing appropriately trained models for predicting respective sex can be utilized to determine the likelihood that the target embryo will produce a male offspring or will produce a female offspring. In this regard, even though biological sex can be considered binary, because a model trained for predicting &#x201c;female&#x201d; offspring indicates a 70% likelihood of producing a female offspring does not necessarily mean that a correspondingly trained model for predicting &#x201c;male&#x201d; offspring will indicate a 30% likelihood of producing a male offspring. To fit user expectation, however, an exemplary resolution is to predict both likelihoods, but only express a preference when one sex is predicted with a likelihood greater than 50% and the other sex is predicted with a likelihood less than 50%. Instances such as this help to illustrate the benefits and uses of the present technology, but also highlight the importance of human review and participation in embryo transfer decisions.</p><p id="p-0056" num="0055">Typically, the videos of the blastocysts to be analyzed as described herein are taken in the &#x201c;field,&#x201d; which is considered to be wherever the blastocyst is evaluated for transfer or preservation. In this context, &#x201c;field&#x201d; when referring to animals can be a veterinary clinic, barn, stock trailer and/or otherwise outdoors, for example. When considering humans, &#x201c;field&#x201d; typically refers to a fertility clinic and the like. Therefore, to avoid the need to transmit the video (which can comprise a data file of substantial size) to a remote analysis site, the trained model can be located on a local processor (computer, specialized chip, tablet, smart phone and the like) where the desired predictions are made. Alternatively, the data file can be transmitted to a host's remote site where the video file is processed, and resulting predictions transmitted back to the user in the field.</p><p id="p-0057" num="0056">In practice, regardless of the field in which the blastocysts are collected, it is common for a plurality of blastocysts to be collected and suspended in nutritional media in a disposable receptacle such as a plastic or glass petri dish, organ culture dish or multi-well plate, as examples. Accordingly, a single video of a plurality of blastocysts in the receptacle can be taken and processed regarding each of the individual blastocysts for the characteristics which the model has been trained. An important aspect of the receptacle is that it has a transparent, substantially flat floor. An inverted microscope is exemplarily utilized to record a substantially distortion-free video of the blastocyst(s) from below the receptacle, through its clear, flat bottom surface. This creates a &#x201c;goggle effect&#x201d; and reduces &#x201c;noise&#x201d; in the sample from wave refraction caused by a rippling upper surface of the liquid media if observed from above. Exemplarily, an Iolight&#xae; brand compact inverted microscope has been utilized to record a video of the blastocyst(s). The magnification power is one-hundred and fifty times (150&#xd7;), the frame speed is 10 fps, the pixel density is 2592&#xd7;1944 and the microscope can connect to smartphones and/or tablets for sharing produced videos.</p><p id="p-0058" num="0057">The presently disclosed technology enables the user to collect or receive secondary data obtained close in time to when the video from which the real-time digital video image data is derived was taken. In one configuration, the presently disclosed technology enables the user to perform a specific gravity assessment of the target embryo within one hour, or less, of taking the video of the target embryo. The specific gravity assessment used to obtain this example of secondary data is dependent upon a descent rate of the target embryo through embryo culture media. Secondary data collected and processed at the proximate time as real-time digital video image data can be indicative of the target embryo's viability, among other things.</p><p id="p-0059" num="0058">In one exemplary implementation illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a convolutional neural network model was utilized that is known to persons skilled in the art as Xception, or Xception71, and which is seventy-one layers deep and can consider approximately twenty-three million parameters. In this example, the model was trained on 256 videos of bovine embryos. Each video was thirty-five seconds in duration, taken at a frame-speed of fifteen frames-per-second, thereby rendering 134,400 (256&#xd7;35&#xd7;15) frames per processed video. Supervised training of the model was conducted with the 256 videos and each video had pregnancy data associated therewith indicative of whether a pregnancy (bred) occurred or not (open). Xception was used to process the training data and generate a predictive model. Thereafter, upon processing twenty new videos (n=20) using the trained model, ten of eleven (90.9%) videoed embryos were accurately predicted to NOT establish a pregnancy (open). The model accurately predicted nine of nine (100%) videoed embryos would establish a pregnancy (bred).</p><p id="p-0060" num="0059">As an illustrative example, consider a dairy operation in which ten blastocysts have been flushed from a donor cow and deposited into a petri dish. There are only five available recipient cows, so the technician wishes to identify the five most viable, female-producing blastocysts. Video of the ten blastocysts is processed by a previously trained model that predicts and assigns, on an individual basis, a likelihood the particular blastocyst will produce a female calf. The comparable predictions (embryo outcome score) are then communicated back to the technician visually, or otherwise. In this way the technician can transfer the five blastocysts indicated to be most likely to produce female calves, in keeping with the goals of the dairy operation. In this way, desirable characteristics (or characteristics desired to be avoided) in mammalian offspring produced from a videoed embryo can be predicted for use in determining whether or not to transfer the particular embryo (blastocyst) into a recipient.</p><p id="p-0061" num="0060">Turning now to the microscopic nature of the morphokinetic movements of embryos, not even under a microscope are such movements humanly discernible. For the purpose of revealing and sometimes accentuating certain aspects of embryo movement, Video Motion Magnification (VMM) has been optionally employed in accordance with the teachings of this description. VMM uses standard digital video image data sequences as input and applies spatial decomposition followed by temporal filtering of the frames. The resulting signal is then amplified to reveal the embryo's morphokinetic movement that has heretofore been unobservable. VMM is a relatively new technology that has been utilized in select physiological diagnostic applications, including remote, non-invasive measurement of patient heart rates and infants' respiration. In essence, this software can take videos of seemingly static scenes and cause micro-motions captured therein to be rendered visually observable.</p><p id="p-0062" num="0061">As has been well documented, developing embryos are undergoing mitosis at an exponential rate. Early in the development of this technology, it was hypothesized that applying video motion magnification to real-time video image data of embryos might allow operators to directly observe embryo development, embryo decay, and detect the presence of genetic abnormalities, among other things. However, it came to be appreciated that application of VMM to embryo video image data can be an enhancement in certain situations to the AI/ML model creation and utilization as disclosed herein. One of the most appealing aspects of VMM's processing of embryo video image data is its revelation of embryo movement that is easily displayed for human observation. Still further, when embryo video image data is VMM pre-processed and then used to create AI/ML models as otherwise (without VMM treatment) described herein, the ensuing embryo analysis and prediction can be enhanced.</p><p id="p-0063" num="0062">In a study designed to determine the effectiveness of video motion magnification to amplify previously undetectable embryo morphokinetics, videos of bovine blastocysts were recorded at 150&#xd7; magnification for two minutes by a licensed veterinarian using an inverted microscope. Once recorded, the videos were &#x201c;filtered&#x201d; using the VMM software, Lambda Vue, and movement of both the inner cell mass and zona pellucida became visually discernible when displayed. Protrusions, bulges, depressions, pulses and changes in embryo shape became observable. The presently disclosed technology is the first known to optionally amplify, and then analyze recorded micro-motions and the morphokinetics of embryo growth and development utilizing real time video, and without the use of time lapse imaging. In this study, ImageJ software developed by the National Institute of Health was utilized to take certain measurements of the embryos at specific locations and specific predetermined time intervals to study changes in embryo shape and size over short periods of time as described herein.</p><p id="p-0064" num="0063">Even if not used for predictive purposes, amplification of the micro-motions of an embryo can be instructive (and comforting) to an operator as protrusions, bulges, depressions and shifts in the inner cell mass, trophectoderm and zona pellucida are made visible. Heretofore, it has been known, but not perceivable on a real-time basis, that blastomeres are actively dividing and increasing embryo mass until differentiation occurs at the blastocyst stage of development. Then, the blastomeres begin to arrange themselves into a distinct inner cell mass (developing fetus) and trophectoderm (developing placenta). In this regard, the human oocyte develops from a single cell into a blastocyst (&#x2dc;300 cells) in a span of five to six days. Previously, changes in blastomere arrangement, size, cell count and orientation were only demonstrated using time-lapse photography.</p><p id="p-0065" num="0064">Cells grow, but they also die, and in the process undergo certain physical changes. When a cell dies, membrane proteins lose structural integrity and cannot osmoregulate their intracellular environment. Constituents from the external environment permeate into the cell through osmosis and intracellular constituents leak out of the cell. Non-viable embryos that include dead or dying cells absorb water as equilibrium is attempted. This occurs because water is attracted to the cell's intracellular environment and causes a low degree of cellular (embryo) swelling. After a cell has become non-viable for several hours, larger intracellular constituents such as salts and proteins begin to exit the cell and leak through the membrane proteins. This can be observed as cellular fragmentation and degrading. These properties cause physical changes in the appearance of the embryo which occur over time. However, the minute physical changes (with respect to both distance, rate and duration of motion) associated with both healthy embryo cellular growth and embryo cellular death are not humanly visible, even with the aid of a microscope up to 150&#xd7; magnification. Applying video motion magnification filtering to embryo real-time video image data renders such motion visible to an operator and can optionally be included in the AI/ML modeling process described herein.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a series of twelve frames extracted from a video clip of a blastocyst (having a frame rate of 2 fps), without magnification (arranged left to right, top to bottom). Though it is known that blastocyst motion is occurring, it is not visible, even under the applied 150&#xd7; microscope magnification. However, <figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts the same 12 frames after motion magnification, and the consecutive frames clearly depict motion in that the frames are progressively different, indicative and illustrative of the blastocyst's real-time motion. In at least one instance, video motion magnification has been used to detect embryo rate of growth to forecast cell count that is non-invasively predictive of embryo sex.</p><p id="p-0067" num="0066">Another benefit of motion amplification is that the amplified image data can accentuate select motion characteristics being analyzed through vector weighting and other techniques (via computer vision, digital image processing or otherwise) during the training and model development stage, or afterward during utilization of the generated model for predictive purposes.</p><p id="p-0068" num="0067">In support of the discoveries disclosed herein regarding training and using AI/ML models to predict, among other things, embryo viability and certain offspring characteristics, reference is made to the disclosure of <figref idref="DRAWINGS">FIG. <b>5</b></figref>. Therein, a proxy for each of several embryo's morphokinetic activity has been quantified and plotted on the illustrative graph. For the quantification, a mean of average subzonal change was determined for each embryo, and which was considered to represent the embryo's morphokinetic activity. Each such value was divided by the particular embryo's inner cell mass area to calculate a standardized percent movement of that embryo, comparable with the other similarly &#x201c;normalized&#x201d; embryos. <figref idref="DRAWINGS">FIG. <b>5</b></figref> represents a study in which the standardized percent morphokinetic activity values for each of 94 bovine embryos were plotted on the displayed graph. From the graph it is gleaned that twenty-four embryos (24/94=25%) had morphokinetic changes outside (some above, some below) of 2 standard deviations from the mean, which is signified by the left and right &#x201c;tails&#x201d; of the illustrative bell-shaped plot. Of those 24 embryos, 17 (17/24=70%) did not establish pregnancies (&#x201c;open&#x201d;); still further, these 17 embryos represent 18%=17/94 of the 94 total embryos. This is confirmatory in that it coincides with what has been found in practice and predicted by the instant models; that is, approximately 20% of grade-1 and grade-2 technician-assessed embryos, though otherwise expected, fail to produce a pregnancy upon transfer.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a histogram that depicts, out of the same 94 bovine embryos plotted in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the standardized percent morphokinetic activity values for the 50 (of the 94) bovine embryos that produced pregnancy. Of these 50 embryos, 42 (84%) demonstrated morphokinetic activity values ranging from 0.07%-0.23% (that is, taken from the left, the first three bars). However, the distribution of embryos across those first three bars&#x2014;0.07%-0.12% {13 embryos}; 0.12%-0.18% {16 embryos} and 0.18%-0.23% {13 embryos}&#x2014;were not statistically significant (p&#x3e;0.05). Six embryos (12% of the 50 embryos that established pregnancies) demonstrated percent morphokinetic activity values of 0.23%-0.29% and one embryo (2% of the 50 embryos that established pregnancies) demonstrated a percent morphokinetic activity value of 0.29-0.34%. This is confirmatory of the position that embryos with hyperactive morphokinetic activity are less likely to produce pregnancy than those embryos having moderate morphokinetic activity, a position that has also been determined and predicted by the models of the present disclosure.</p><p id="p-0070" num="0069">The histogram of <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates and supports the proposition in this disclosure that determined inner cell mass range of motion within the subzonal space is indicative/predictive of the embryo's competence for establishing pregnancy. The histogram is based on measured radial distances of the gap spaces between the outer contours of the inner cell mass area and the zona pellucida at twelve indicated equal-spaced locations therearound every five seconds between 5 and 35 seconds (7 measurements) along the dashed lines depicted in <figref idref="DRAWINGS">FIGS. <b>8</b> and <b>9</b></figref>. For each of the 94 embryos, the measured amounts of motion over the 35 second period at each of the 12 locations were averaged for each of the 94 embryos that were transferred into recipients. The histogram of <figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts the 50 embryos that achieved pregnancy. Therein, it is revealed that embryos in the lower ranges of subzonal activity (bars toward the left) established pregnancies at a higher frequency than embryos with a high range of subzonal activity (bars toward the right) (p&#x3c;0.05). Out of the 50 embryos, 48 (96%) demonstrated average ranges of motion between 1.6 um and 12.7 um, whereas only 2 out of the 50 embryos (4%) demonstrated a range of motion higher than 12.7 um.</p><p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a graph that depicts distances between the outer contours of the inner cell mass area and the zona pellucida of each of the 94 embryos measured at the specific 12 locations indicated in <figref idref="DRAWINGS">FIGS. <b>8</b> and <b>9</b></figref> at five second intervals during a 35 second observatory period. The range of motion was calculated at each of the 12 locations over the 35 second duration and then averaged for each of the 94 embryos which were transferred into recipients. Nine of the 94 embryos (9.57%) demonstrated an average range of subzonal motion (activity) greater than 12.5 um, and seven of those nine embryos did not establish pregnancies, again indicating that embryos experiencing a high degree of subzonal activity are less likely to establish pregnancies than embryos experiencing a moderate range of motion.</p><p id="p-0072" num="0071">In another study, bovine oocytes were fertilized in vivo by a licensed veterinarian. The embryos were flushed from the donor and placed in holding media. Two-minute video recordings were taken on an inverted microscope at 150&#xd7; magnification. Confirmatory measurements were taken about each embryo using ImageJ Software. Among others, those measurements include: (1) Zona pellucida X axis diameter; (2) zona pellucida Y axis diameter; (3) mass X axis diameter; (4) mass Y axis diameter; (5) zona area; (6) mass area; (7) inner cell mass area and (8) rotational shift within the subzonal space. For each two-minute video, each of these measurements were made at the 0, 15, 30, 45, 60, 75, 90, 105 and 120 second time points. Immediately after their video was taken, each embryo was transferred into a recipient animal as a singleton (one embryo per recipient). Subsequent to this study, additional studies obtaining similar results have been conducted on embryo video clips that are 35 seconds long and were taken at ten frames per second (10 fps) prior to transfer into a recipient. Thereafter, pregnancy data, as outcome data, was obtained by trans-rectal ultrasound at forty days post transfer.</p><p id="p-0073" num="0072">In still another study, 150 grade-1 and grade-2 embryos were flushed from beef cattle by a licensed veterinarian. Two-minute video recordings were captured from each embryo with an Iolight&#xae; inverted microscope at 150&#xd7; in a standard culture of Vigro Holding Plus media. All embryos were transferred into eligible recipients. Videos were processed with Lambda Vue Video Motion Magnification Videoscope at 0.2-4 video frequency. Each amplified video was then assessed using ImageJ measuring software by taking measurements of the same embryo features at 15 second time intervals. The following measurements were made on each embryo, every 15 seconds: (1) Zona pellucida Y-axis diameter; (2) zona pelludica X-axis diameter; (3) mass Y-axis diameter; (4) mass X-Axis diameter; (5) zona pelludica area and (6) inner cell mass area and at twelve locations on the sub-zonal space as generally depicted in <figref idref="DRAWINGS">FIGS. <b>8</b> and <b>9</b></figref>. Observations were also made of bulges on the zona pellucida and bulges on the inner cell mass, when occurring.</p><p id="p-0074" num="0073">In yet another trial, videos of embryos were obtained and amplified using video motion magnification. Y-axis diameter of the inner cellular mass was measured using ImageJ software (National Institute of Health) and scaled to represent units in microns. Measurements were obtained at five second intervals from 0 to 35 seconds. Quantifiable changes in embryo inner cell mass diameter were observed, demonstrating morphokinetic changes in short observatory periods. These were observed visually as bulges, depressions and protrusions in the inner cell mass over time. These changes infer predictive information pertaining to embryo health and viability based on the other findings described herein.</p><p id="p-0075" num="0074">In a similar trial, videos of embryos were obtained and amplified using video motion magnification. Area of the inner cell mass was obtained using measurement tools available from ImageJ software (National Institute of Health) and scaled to represent units in microns. Measurements were obtained at five second intervals from 0 to 35 seconds. As before, quantifiable changes in inner cell mass area were observed, likewise demonstrating morphokinetic changes in short observatory periods. The measurements represent a 2-D area of the visible inner cell mass. It was observed that the cells were actively moving, likely due to mitosis and cellular division. It is believed that in some instances one cell mass overlapped another making the 2D area of the second cell mass appear to decrease, when it was not decreasing. The present technology demonstrates active development or cellular decay and does not depend on additive or subtractive trends as in time-lapse analysis. As revealed by the present technology, these cellular (embryo) changes evidence morphokinetic developmental characteristics that are in fact predictive of embryo health, viability, stress, and genetic characteristics, both inferior and superior compared to average or &#x201c;normal&#x201d;.</p><p id="p-0076" num="0075">This disclosure describes several different permutations of a computer-implemented method for predicting an embryo's outcome by processing video image data of the embryo. The method includes receiving image data derived from video of a target embryo taken at substantially real-time frame speed during an embryo observation period of time. The video contains recorded morphokinetic movement of the target embryo occurring during the embryo observation period of time and which is represented in the received image data. The received image data is processed using a model generated utilizing machine learning and correlated embryo outcome data.</p><p id="p-0077" num="0076">In a further aspect, the disclosed method predicts a correlating embryo outcome for the target embryo. In this sense, the predicted &#x201c;correlating outcome&#x201d; is of the same nature as the &#x201c;correlated outcome&#x201d; used to train the model. For instance, if a model is trained on images (image data) known to be of cats (the &#x201c;correlated outcome&#x201d;), in most instances, that so-trained model will be used to analyze (process) images (image data) and predict the likelihood (probability) the analyzed image is of a cat (the &#x201c;correlating outcome&#x201d;).</p><p id="p-0078" num="0077">In one option, the present method predicts a likelihood the target embryo will produce a specific sex offspring. In accordance with this disclosure, a trained model can be used to make such a prediction. In an initial step, machine learning is used to train a model using image data from video of each of a number of embryos. For each embryo, it is known whether that embryo produced a male or female offspring and data representing that fact is paired to the corresponding video. In this sense, the corresponding male/female data is &#x201c;correlated outcome data&#x201d; to the respective videos. That is, the male/female &#x201c;outcome data&#x201d; is &#x201c;correlated&#x201d; with the respective videos. Machine learning is then utilized to analyze the paired data (video image data with its matched offspring sex data) and determine characteristics in the video image data that are indicative of male sex offspring and characteristics in the video image data that are indicative of female sex offspring. Thereafter, to predict the likely sex of a produced offspring of a particular target embryo, received image data from real-time video taken of that embryo is processed using the trained model. The model outputs a &#x201c;correlating embryo outcome&#x201d; which is a prediction of the likelihood the target embryo will produce a male sex offspring and/or a prediction of the likelihood the target embryo will produce a female sex offspring.</p><p id="p-0079" num="0078">In general, the method described above for generating machine-learning-based models and utilizing such models to process data and make predictions therewith, applies to the other predictive scenarios described herein.</p><p id="p-0080" num="0079">As further options, the disclosed method can predict: (i) a likelihood the target embryo will produce human male offspring; (ii) a likelihood the target embryo will produce human female offspring; (iii) a likelihood the target embryo will produce bovine male offspring; or (iv) a likelihood the target embryo will produce bovine female offspring.</p><p id="p-0081" num="0080">In another option, the method predicts a likelihood of successful transfer of the target embryo into a recipient. In yet another option, the method predicts viability of the target embryo at the time of transfer. In still another option, the method predicts a likelihood the target embryo will produce a genetically inferior offspring compared to average or &#x201c;normal&#x201d;. In another option, the method predicts a likelihood the target embryo will produce a genetically superior offspring compared to average or &#x201c;normal&#x201d;.</p><p id="p-0082" num="0081">According to this technology, a predicted embryo outcome of the target embryo can be communicated to the originator of the received image data thereby assisting in a decision whether to transfer the target embryo into a recipient.</p><p id="p-0083" num="0082">In one option, the correlated embryo outcome data represents embryo transfers into recipients that established pregnancy. In another option, the correlated embryo outcome data represents embryo transfers into recipients that produced livebirth offspring. In still another option, the correlated embryo outcome data represents embryo transfers into recipients that produced livebirth male offspring. In yet another option, the correlated embryo outcome data represents embryo transfers into recipients that produced livebirth female offspring. In still another option, the correlated embryo outcome data represents embryo transfers into recipients that produced genetically inferior offspring compared to average or &#x201c;normal&#x201d;. In even another option, the correlated embryo outcome data represents embryo transfers into recipients that produced genetically superior offspring compared to average or &#x201c;normal&#x201d;.</p><p id="p-0084" num="0083">In a further aspect, the method includes receiving outcome data indicative of whether successful transfer of the target embryo into a recipient occurred, where successful transfer is indicated by the target embryo producing pregnancy in the recipient. In another aspect, the method includes receiving outcome data indicative of whether successful transfer of the target embryo into a recipient occurred, where successful transfer is indicated by the target embryo producing livebirth offspring out of the recipient.</p><p id="p-0085" num="0084">In one embodiment, the method includes utilizing a frame speed sufficiently fast to capture at least one individual embryo morphokinetic movement during the embryo observation period of time. In another embodiment, the method includes utilizing a speed sufficiently fast to capture a series of embryo morphokinetic movements during the embryo observation period of time. In one option, the method utilizes a frame speed at least as fast as fifteen frames per second. In another option, the method utilizes a frame speed of at least ten frames per second. In yet another option, the method utilizes a frame speed of at least two frames per second. In still another option, the method maintains substantially uniform frame speed during the embryo observation period of time.</p><p id="p-0086" num="0085">The presently described technology includes selecting a duration of image data received and determining the length of time of the embryo observation period of time based there upon. In one option, the embryo observation period of time is less than two minutes. In another option, the embryo observation period of time is less than thirty seconds. In one aspect, the method includes selecting an embryo observation period of time of less than two minutes. In another aspect, the method includes selecting an embryo observation period of time of less than thirty seconds.</p><p id="p-0087" num="0086">In one example, the presently described real-time video clips, from which the received image data is obtained, are taken using an inverted microscope camera from a perspective below the target embryo. In another example, the video from which the received image data is obtained is taken using an inverted microscope camera from a perspective below and through a petri dish containing the target embryo, and in which the bottom floor of the petri dish is substantially flat and clear enabling the video of the target embryo to be optically accurate. In yet another example, the video from which the received image data is obtained is taken using a smartphone camera. In still another example, the camera is directly connected to a circuit board of an inclusive platform.</p><p id="p-0088" num="0087">The present disclosure describes a method of receiving, from the same video, image data of each of a plurality of target embryos. In one embodiment, the method includes processing the image data for each of the plurality of target embryos utilizing the model and predicting an embryo outcome score for each of the plurality of target embryos. In accordance with this embodiment, the method includes communicating the predicted embryo outcome score of each of a plurality of the target embryos to an originator of the received image data, or otherwise user of the system, thereby assisting a decision of which embryos to transfer. Another embodiment includes communicating a ranking of the predicted embryo outcome scores to an originator of the received image data thereby assisting a decision of which embryos to transfer. In another embodiment, the method includes transmitting display data to a display observable by an originator of the received image data that causes ranked embryo outcome scores to be displayed in a spatial arrangement on the display that corresponds to an existing spatial arrangement of the target embryos.</p><p id="p-0089" num="0088">The present technology facilitates a method of amplifying at least a portion of image data from within the received image data that represents morphokinetic movement of the target embryo. In one embodiment, the morphokinetic movement of the target embryo is humanly imperceptible at 150&#xd7; magnification. In another embodiment, the method utilizes Eulerian video magnification to amplify the portion of image data from within the received image data that represents morphokinetic movement of the target embryo. In a further embodiment, the method utilizes the amplified data representing the morphokinetic movement of the target embryo to enable display of a moving image of the target embryo in which the movement is humanly perceptible.</p><p id="p-0090" num="0089">In one aspect, at least one characteristic of the target embryo evidenced in the received image data is elasticity of the embryo's outer wall.</p><p id="p-0091" num="0090">The present disclosure includes the method of receiving secondary data indicative of the target embryo's viability derived from a specific gravity assessment made of the embryo proximate in time to when the video from which the received image data is obtained was taken. In one option, the specific gravity assessment is made of the target embryo within one hour of taking the video of the target embryo. In another option, the specific gravity assessment is dependent upon a descent rate of the target embryo through embryo culture media.</p><p id="p-0092" num="0091">In one embodiment, the method uses machine learning that comprises utilization of an artificial neural network.</p><p id="p-0093" num="0092">In another aspect, the present disclosure describes a system containing one or more processors and a computer-readable medium, instructions stored within, which when executed by the one or more processors, cause the one or more processors to predict an embryo outcome by processing video image data of an embryo. The method includes receiving image data derived from video of a target embryo taken at substantially real-time frame speed during an embryo observation period of time. The video's resolution is sufficient (high enough) to record and does record morphokinetic movement of the target embryo occurring during the embryo observation period of time. The movement is represented in the received image data and the received image data is processed using a model generated utilizing machine learning and correlated embryo outcome data.</p><p id="p-0094" num="0093">In still another aspect, the present disclosure describes a non-transitory computer-readable storage medium containing computer-readable instructions, which when executed by a computing system, cause the computing system to predict an embryo outcome by processing video image data of an embryo. The method includes receiving image data derived from video of a target embryo taken at substantially real-time frame speed during an embryo observation period of time. The video's resolution is sufficient (high enough) to record and does record morphokinetic movement of the target embryo occurring during the embryo observation period of time. The movement is represented in the received image data. The received image data is processed using a model generated utilizing machine learning and correlated embryo outcome data.</p><heading id="h-0005" level="1">General Description of AI/ML and Exemplary System Configuration(s)</heading><p id="p-0095" num="0094">The disclosure set forth below provides general description of various configurations of the subject technology and is not intended to represent the only configurations in which the subject technology can be practiced. The appended drawings are incorporated herein and constitute a part of this specification. This description includes details for the purpose of providing a more thorough understanding of the subject technology. However, the subject technology is not limited to the specific details set forth therein and may be practiced with or without these details. In some instances, structures and components are shown in block diagram form so as to avoid obscuring the concepts of the subject technology.</p><p id="p-0096" num="0095">The disclosure now turns to additional discussion of models that can be used in the environments and techniques described herein. Specifically, <figref idref="DRAWINGS">FIG. <b>11</b></figref> is an illustrative example of a deep learning neural network <b>100</b>. These networks are referred to as &#x201c;neural&#x201d; networks because they reflect the behavior of the human brain. These neural networks, also referred to as artificial neural networks (ANNs) and/or simulated neural networks (SNNs), are subsets of machine learning (ML). The network has an input layer <b>120</b> that is configured to receive input data, which in the present case is the video image data of embryos. The neural network <b>100</b> includes multiple hidden layers <b>122</b><i>a</i>, <b>122</b><i>b</i>, through <b>122</b><i>n</i>. The hidden layers <b>122</b><i>a</i>, <b>122</b><i>b</i>, through <b>122</b><i>n </i>include &#x201c;n&#x201d; number of hidden layers, where &#x201c;n&#x201d; is an integer greater than or equal to one. The number of hidden layers can be made to include as many layers as needed for the given application. The neural network <b>100</b> further includes an output layer <b>121</b> that provides an output resulting from the processing performed by the hidden layers <b>122</b><i>a</i>, <b>122</b><i>b</i>, through <b>122</b><i>n</i>. It is the presence of the multiple hidden layers that gives rise to the &#x201c;deep learning&#x201d; description.</p><p id="p-0097" num="0096">The neural network <b>100</b> is a multi-layer neural network of interconnected nodes. Each node can represent a piece of information. Information associated with the nodes is shared among the different layers and each layer retains information as information is processed. In some cases, the neural network <b>100</b> can include a feed-forward network, in which case there are no feedback connections where outputs of the network are fed back into itself. In some cases, the neural network <b>100</b> can include a recurrent neural network, which can have loops that allow information to be carried across nodes while reading in input.</p><p id="p-0098" num="0097">Information can be exchanged between nodes through node-to-node interconnections between the various layers. Nodes of the input layer <b>120</b> can activate a set of nodes in the first hidden layer <b>122</b><i>a</i>. For example, as shown, each of the input nodes of the input layer <b>120</b> is connected to each of the nodes of the first hidden layer <b>122</b><i>a</i>. The nodes of the first hidden layer <b>122</b><i>a </i>can transform the information of each input node by applying activation functions to the input node information. The information derived from the transformation can then be passed to and can activate the nodes of the next hidden layer <b>122</b><i>b</i>, which can perform their own designated functions. Example functions include convolutional, up-sampling, data transformation, and/or any other suitable functions. The output of the hidden layer <b>122</b><i>b </i>can then activate nodes of the next hidden layer, and so on. The output of the last hidden layer <b>122</b><i>n </i>can activate one or more nodes of the output layer <b>121</b>, at which an output is provided. In some cases, while nodes in the neural network <b>100</b> are shown as having multiple output lines, a node can have a single output and all lines shown as being output from a node represent the same output value.</p><p id="p-0099" num="0098">In some cases, each node or interconnection between nodes can have a weight that is a set of parameters derived from the training of the neural network <b>100</b>. Once the neural network <b>100</b> is trained, it can be referred to as a trained neural network, which can be used to classify one or more activities. For example, an interconnection between nodes can represent a piece of information learned about the interconnected nodes. The interconnection can have a tunable numeric weight that can be tuned (e.g., based on a training dataset), allowing the neural network <b>100</b> to be adaptive to inputs and able to learn as more and more data is processed.</p><p id="p-0100" num="0099">The neural network <b>100</b> can be pre-trained to process the features from the data in the input layer <b>120</b> using the different hidden layers <b>122</b><i>a</i>, <b>122</b><i>b</i>, through <b>122</b><i>n </i>in order to provide the output through the output layer <b>121</b>.</p><p id="p-0101" num="0100">In some cases, the neural network <b>100</b> can adjust the weights of the nodes using a training process called backpropagation. As noted above, a backpropagation process can include a forward pass, a loss function, a backward pass, and a weight update. The forward pass, loss function, backward pass, and parameter update is performed for one training iteration. The process can be repeated for a certain number of iterations for each set of training data until the neural network <b>100</b> is trained well enough so that the weights of the layers are accurately tuned.</p><p id="p-0102" num="0101">In general, and as noted above, for a first training iteration for the neural network <b>100</b>, the output will likely include values that do not give preference to any particular class due to the weights being randomly selected at initialization. For example, if the output is a vector with probabilities that the object includes different classes, the probability value for each of the different classes may be equal or at least very similar (e.g., for ten possible classes, each class may have a probability value of 0.1). With the initial weights, the neural network <b>100</b> is unable to determine low level features and thus cannot make an accurate determination of what the classification of the object might be. A loss function can be used to analyze error in the output. Any suitable loss function definition can be used, such as a Cross-Entropy loss. Another example of a loss function includes the mean squared error (MSE), defined as E_total=&#x3a3;(&#xbd; (target&#x2212;output){circumflex over (&#x2003;)}2). The loss can be set to be equal to the value of E_total.</p><p id="p-0103" num="0102">Generally, a goal of training is to minimize the amount of loss so that the predicted output is the same as the training label. The neural network <b>100</b> can perform a backward pass by determining which inputs (weights) most contributed to the loss of the network, and can adjust the weights so that the loss decreases and is eventually minimized. A derivative of the loss with respect to the weights (denoted as dL/dW, where W are the weights at a particular layer) can be computed to determine the weights that contributed most to the loss of the network. After the derivative is computed, a weight update can be performed by updating all the weights of the filters. For example, the weights can be updated so that they change in the opposite direction of the gradient. The weight update can be denoted as w=w_&#x3b7; dL/dW, where w denotes a weight, w_i denotes the initial weight, and &#x3b7; denotes a learning rate. The learning rate can be set to any suitable value, with a high learning rate including larger weight updates and a lower value indicating smaller weight updates.</p><p id="p-0104" num="0103">The neural network <b>100</b> can include any suitable deep network. One example includes a convolutional neural network (CNN), which includes an input layer and an output layer, with multiple hidden layers between the input and out layers. The hidden layers of a CNN include a series of convolutional, nonlinear, pooling (for downsampling), and fully connected layers. The neural network <b>100</b> can include any other deep network other than a CNN, such as an autoencoder, a deep belief nets (DBNs), a Recurrent Neural Networks (RNNs), among others.</p><p id="p-0105" num="0104">As understood by those persons skilled in these arts, machine-learning based classification techniques can vary depending on the desired implementation. For example, machine-learning classification schemes can utilize one or more of the following, alone or in combination: hidden Markov models; recurrent neural networks; convolutional neural networks (CNNs); deep learning; Bayesian symbolic methods; generative adversarial networks (GANs); support vector machines; image registration methods; applicable rule-based system. Where regression algorithms are used, they may include but are not limited to: a Stochastic Gradient Descent Regressor, and/or a Passive Aggressive Regressor, and the like.</p><p id="p-0106" num="0105">Machine learning classification models can also be based on clustering algorithms (e.g., a Mini-batch K-means clustering algorithm), a recommendation algorithm (e.g., a Miniwise Hashing algorithm, or Euclidean Locality-Sensitive Hashing (LSH) algorithm), and/or an anomaly detection algorithm, such as a Local outlier factor. Additionally, machine-learning models can employ a dimensionality reduction approach, such as, one or more of: a Mini-batch Dictionary Learning algorithm, an Incremental Principal Component Analysis (PCA) algorithm, a Latent Dirichlet Allocation algorithm, and/or a Mini-batch K-means algorithm and the like.</p><p id="p-0107" num="0106">The disclosure now turns to <figref idref="DRAWINGS">FIG. <b>12</b></figref> which illustrates an example of a processor-based computing system <b>200</b> wherein the components of the system are in electrical communication with each other using a system bus <b>205</b>. The computing system <b>200</b> can include a processing unit (CPU or processor) <b>210</b> and a system bus <b>205</b> that may couple various system components including the system memory <b>215</b>, such as read only memory (ROM) <b>220</b> and random-access memory (RAM) <b>225</b>, to the processor <b>210</b>. The computing system <b>200</b> can include a cache <b>212</b> of high-speed memory connected directly with, in close proximity to, or integrated as part of the processor <b>210</b>. The computing system <b>200</b> can copy data from the memory <b>215</b>, ROM <b>220</b>, RAM <b>225</b>, and/or storage device <b>230</b> to the cache <b>212</b> for quick access by the processor <b>210</b>. In this way, the cache <b>212</b> can provide a performance boost that avoids processor delays while waiting for data. These and other modules can control the processor <b>210</b> to perform various actions. Other system memory <b>215</b> may be available for use as well. The memory <b>215</b> can include multiple different types of memory with different performance characteristics. The processor <b>210</b> can include any general-purpose processor and a hardware module or software module, such as module 1 <b>232</b>, module 2 <b>234</b>, and module 3 <b>236</b> stored in the storage device <b>230</b>, configured to control the processor <b>210</b> as well as a special-purpose processor where software instructions are incorporated into the actual processor design. The processor <b>210</b> may essentially be a completely self-contained computing system, containing multiple cores or processors, a system bus, memory controller, cache, etc. A multi-core processor may be symmetric or asymmetric.</p><p id="p-0108" num="0107">To enable user interaction with the computing system <b>200</b>, an input device <b>245</b> can represent any number of input mechanisms, such as a microphone for speech, a touch-protected screen for gesture or graphical input, keyboard, mouse, motion input, speech and so forth. An output device <b>235</b> can also be one or more of a number of output mechanisms known to those of skill in the art. In some instances, multimodal systems can enable a user to provide multiple types of input to communicate with the computing system <b>200</b>. The communications interface <b>240</b> can govern and manage the user input and system output. There may be no restriction on operating on any particular hardware arrangement and therefore the basic features here may easily be substituted for improved hardware or firmware arrangements as they are developed.</p><p id="p-0109" num="0108">The storage device <b>230</b> can be a non-volatile memory and can be a hard disk or other types of computer readable media which can store data that are accessible by a computer, such as magnetic cassettes, flash memory cards, solid state memory devices, digital versatile disks, cartridges, random access memory, read only memory, and hybrids thereof.</p><p id="p-0110" num="0109">As discussed above, the storage device <b>230</b> can include the software modules <b>232</b>, <b>234</b>, <b>236</b> for controlling the processor <b>210</b>. Other hardware or software modules are contemplated. The storage device <b>230</b> can be connected to the system bus <b>205</b>. In some embodiments, a hardware module that performs a particular function can include a software component stored in a computer-readable medium in connection with the necessary hardware components, such as the processor <b>210</b>, system bus <b>205</b>, output device <b>235</b>, and so forth, to carry out the function. For clarity of explanation, in some instances the present technology may be presented as including individual functional blocks including functional blocks comprising devices, device components, steps or routines in a method embodied in software, or combinations of hardware and software.</p><p id="p-0111" num="0110">In some embodiments the computer-readable storage devices, mediums, and memories can include a cable or wireless signal containing a bit stream and the like. However, when mentioned, non-transitory computer-readable storage media expressly exclude media such as energy, carrier signals, electromagnetic waves, and signals per se.</p><p id="p-0112" num="0111">Methods according to the above-described examples can be implemented using computer-executable instructions that are stored or otherwise available from computer readable media. Such instructions can comprise, for example, instructions and data which cause or otherwise configure a general-purpose computer, special purpose computer, or special purpose processing device to perform a certain function or group of functions. Portions of computer resources used can be accessible over a network. The computer executable instructions may be, for example, binaries, intermediate format instructions such as assembly language, firmware, or source code. Examples of computer-readable media that may be used to store instructions, information used, and/or information created during methods according to described examples include magnetic or optical disks, flash memory, USB devices provided with non-volatile memory, networked storage devices, and so on.</p><p id="p-0113" num="0112">Devices implementing methods according to these disclosures can comprise hardware, firmware and/or software, and can take any of a variety of form factors. Typical examples of such form factors include laptops, smart phones, small form factor personal computers, personal digital assistants, rackmount devices, standalone devices, and so on. Functionality described herein also can be embodied in peripherals or add-in cards. Such functionality can also be implemented on a circuit board among different chips or different processes executing in a single device, by way of further example.</p><p id="p-0114" num="0113">The instructions, media for conveying such instructions, computing resources for executing them, and other structures for supporting such computing resources are means for providing the functions described in these disclosures.</p><p id="p-0115" num="0114">Although a variety of examples and other information was used to explain aspects within the scope of the appended claims, no limitation of the claims should be implied based on particular features or arrangements in such examples, as one of ordinary skill would be able to use these examples to derive a wide variety of implementations. Further and although some subject matter may have been described in language specific to examples of structural features and/or method steps, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to these described features or acts. For example, such functionality can be distributed differently or performed in components other than those identified herein. Rather, the described features and steps are disclosed as examples of components of systems and methods within the scope of the appended claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for assessing a bovine embryo by processing video image data of the embryo, the method comprising:<claim-text>obtaining video of a target embryo having frame speed at least as fast as two frames per second, said video comprising image data representing morphokinetic movement of the target embryo; and</claim-text><claim-text>processing said image data using a trained machine learning model and thereby predicting a likelihood the target embryo will produce a female bovine offspring.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising predicting a likelihood the target embryo embodies a genetic anomaly.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising predicting a likelihood the target embryo will perpetuate desired traits in produced offspring.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said video is a continuous recording having a duration of ten minutes or less.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said video of the target embryo has a frame speed at least as fast as ten frames per second.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising predicting a likelihood the target embryo will produce pregnancy upon transfer into a recipient.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising predicting a likelihood the target embryo will produce undesired characteristics in produced offspring.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said model is trained utilizing machine learning and correlated pregnancy data to determine viability of the target embryo.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image data represents a plurality of target embryos.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising: processing image data representing each of the plurality of target embryos utilizing the model and thereby scoring each target embryo.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein processing the image data further comprises amplifying at least a portion of the image data representing the morphokinetic movement of the target embryo.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the amplification of image data is made utilizing Eulerian video magnification.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A system comprising:<claim-text>one or more processors; and</claim-text><claim-text>a computer-readable medium comprising instructions stored therein, which when executed by the one or more processors, cause the one or more processors to:</claim-text><claim-text>assess a bovine embryo by processing video image data of the embryo, said assessment comprising:<claim-text>receiving video of a target embryo having frame speed at least as fast as two frames per second, said video comprising image data representing morphokinetic movement of the target embryo; and</claim-text><claim-text>processing said image data using a trained machine learning model and thereby predicting a likelihood the target embryo will produce a female bovine offspring.</claim-text></claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the prediction further comprises a likelihood the target embryo embodies a genetic anomaly.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the prediction further comprises a likelihood the target embryo will perpetuate desired traits in produced offspring.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein said video is a continuous recording having a duration of ten minutes or less.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein said video of the target embryo has a frame speed at least as fast as ten frames per second.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising predicting a likelihood the target embryo will produce pregnancy upon transfer into a recipient.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the prediction further comprises a likelihood the target embryo will produce undesired characteristics in produced offspring.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein said model is trained utilizing machine learning and correlated pregnancy data to determine viability of the target embryo.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the image data represents a plurality of target embryos.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The system of <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising: processing image data representing each of the plurality of target embryos utilizing the model and thereby scoring each target embryo.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein processing the image data further comprises amplifying at least a portion of the image data representing the morphokinetic movement of the target embryo.</claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. A non-transitory computer-readable storage medium comprising computer-readable instructions, which when executed by a computing system, cause the computing system to process video image data of a bovine embryo comprising:<claim-text>receiving video of a target embryo having frame speed at least as fast as two frames per second, said video comprising image data representing morphokinetic movement of the target embryo; and</claim-text><claim-text>processing said image data using a trained machine learning model and thereby predicting a likelihood the target embryo will produce a female bovine offspring</claim-text></claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The storage medium of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the computer-readable instructions, upon execution, further cause the computing system to predict a likelihood the target embryo embodies a genetic anomaly.</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the computer-readable instructions, upon execution, further cause the computing system to predict a likelihood the target embryo will perpetuate desired traits in produced offspring.</claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The storage medium of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein said video is a continuous recording having a duration of ten minutes or less.</claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The storage medium of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein said video of the target embryo has a frame speed at least as fast as ten frames per second.</claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. The storage medium of <claim-ref idref="CLM-00024">claim 24</claim-ref>, further comprising predicting a likelihood the target embryo will produce pregnancy upon transfer into a recipient.</claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. The storage medium of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the computer-readable instructions, upon execution, further cause the computing system to predict a likelihood the target embryo will produce undesired characteristics in produced offspring.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003895A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003895</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931146</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-067522</doc-number><date>20200403</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>894</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>521</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>579</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>894</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>521</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>579</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10028</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30252</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>16</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD AND APPARATUS FOR CONTROLLING DISTANCE MEASUREMENT APPARATUS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/008435</doc-number><date>20210304</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17931146</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Panasonic Intellectual Property Management Co., Ltd.</orgname><address><city>Osaka</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KATO</last-name><first-name>YUMIKO</first-name><address><city>Osaka</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>INADA</last-name><first-name>YASUHISA</first-name><address><city>Osaka</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>NARUMI</last-name><first-name>KENJI</first-name><address><city>Osaka</city><country>JP</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>HISADA</last-name><first-name>KAZUYA</first-name><address><city>Nara</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for controlling a distance measurement apparatus including a light emitting device capable of changing a direction of emission of a light beam and a light receiving device that detects a reflected light beam includes acquiring data representing a plurality of images acquired at different points in time by an image sensor that acquires an image of a scene, determining, on the basis of the data representing the plurality of images, a degree of priority of distance measurement of one or more physical objects included in the plurality of images, and executing distance measurement of the one or more physical objects by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="148.08mm" wi="122.43mm" file="US20230003895A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="238.42mm" wi="168.49mm" orientation="landscape" file="US20230003895A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="97.96mm" wi="163.15mm" file="US20230003895A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="171.96mm" wi="160.61mm" file="US20230003895A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="222.25mm" wi="150.54mm" file="US20230003895A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="250.02mm" wi="165.35mm" file="US20230003895A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="242.23mm" wi="142.32mm" file="US20230003895A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="242.06mm" wi="144.36mm" orientation="landscape" file="US20230003895A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="240.71mm" wi="119.46mm" file="US20230003895A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="98.13mm" wi="93.90mm" file="US20230003895A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="248.16mm" wi="161.80mm" file="US20230003895A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="242.82mm" wi="166.03mm" file="US20230003895A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="224.96mm" wi="166.20mm" file="US20230003895A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="229.11mm" wi="112.61mm" file="US20230003895A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="170.60mm" wi="112.35mm" file="US20230003895A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="103.97mm" wi="115.15mm" file="US20230003895A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="246.63mm" wi="111.42mm" file="US20230003895A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="167.56mm" wi="162.56mm" file="US20230003895A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="168.23mm" wi="154.86mm" file="US20230003895A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="245.03mm" wi="169.76mm" file="US20230003895A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="228.26mm" wi="112.44mm" file="US20230003895A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="228.52mm" wi="112.35mm" file="US20230003895A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="228.52mm" wi="112.95mm" file="US20230003895A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="228.43mm" wi="114.47mm" file="US20230003895A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="216.32mm" wi="169.08mm" orientation="landscape" file="US20230003895A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="240.62mm" wi="136.82mm" file="US20230003895A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="159.26mm" wi="140.29mm" file="US20230003895A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="230.55mm" wi="149.94mm" file="US20230003895A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="228.35mm" wi="112.44mm" file="US20230003895A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00029" num="00029"><img id="EMI-D00029" he="170.69mm" wi="112.69mm" file="US20230003895A1-20230105-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00030" num="00030"><img id="EMI-D00030" he="162.31mm" wi="156.55mm" file="US20230003895A1-20230105-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00031" num="00031"><img id="EMI-D00031" he="227.67mm" wi="112.69mm" file="US20230003895A1-20230105-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00032" num="00032"><img id="EMI-D00032" he="169.93mm" wi="112.69mm" file="US20230003895A1-20230105-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00033" num="00033"><img id="EMI-D00033" he="228.26mm" wi="112.27mm" file="US20230003895A1-20230105-D00033.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00034" num="00034"><img id="EMI-D00034" he="170.69mm" wi="112.78mm" file="US20230003895A1-20230105-D00034.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00035" num="00035"><img id="EMI-D00035" he="167.72mm" wi="154.94mm" file="US20230003895A1-20230105-D00035.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00036" num="00036"><img id="EMI-D00036" he="228.26mm" wi="111.76mm" file="US20230003895A1-20230105-D00036.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00037" num="00037"><img id="EMI-D00037" he="228.26mm" wi="112.69mm" file="US20230003895A1-20230105-D00037.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00038" num="00038"><img id="EMI-D00038" he="228.77mm" wi="112.35mm" file="US20230003895A1-20230105-D00038.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00039" num="00039"><img id="EMI-D00039" he="228.26mm" wi="112.52mm" file="US20230003895A1-20230105-D00039.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00040" num="00040"><img id="EMI-D00040" he="228.09mm" wi="112.27mm" file="US20230003895A1-20230105-D00040.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00041" num="00041"><img id="EMI-D00041" he="227.67mm" wi="113.03mm" file="US20230003895A1-20230105-D00041.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00042" num="00042"><img id="EMI-D00042" he="222.76mm" wi="112.61mm" file="US20230003895A1-20230105-D00042.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00043" num="00043"><img id="EMI-D00043" he="222.33mm" wi="112.95mm" file="US20230003895A1-20230105-D00043.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00044" num="00044"><img id="EMI-D00044" he="227.41mm" wi="112.61mm" file="US20230003895A1-20230105-D00044.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00045" num="00045"><img id="EMI-D00045" he="219.29mm" wi="166.37mm" file="US20230003895A1-20230105-D00045.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00046" num="00046"><img id="EMI-D00046" he="170.52mm" wi="124.46mm" file="US20230003895A1-20230105-D00046.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><heading id="h-0002" level="1">1. Technical Field</heading><p id="p-0002" num="0001">The present disclosure relates to a method and apparatus for controlling a distance measurement apparatus.</p><heading id="h-0003" level="1">2. Description of the Related Art</heading><p id="p-0003" num="0002">It is important for a self-propelled system such as a self-guided vehicle and a self-propelled robot to avoid a collision with another vehicle, a person, or other objects. For that purpose, a system that carries out sensing of an external environment with a camera or a distance measurement apparatus has been used.</p><p id="p-0004" num="0003">As for distance measurement, there have been proposed a variety of devices each of which measures the distance to one or more objects present in a space. For example, Japanese Unexamined Patent Application Publication No. 2018-124271, Japanese Unexamined Patent Application Publication No. 2009-217680, and Japanese Unexamined Patent Application Publication No. 2018-049014 disclose systems each of which measures the distance to an object with a TOF (time-of-flight) technology.</p><p id="p-0005" num="0004">Japanese Unexamined Patent Application Publication No. 2018-124271 discloses a system that measures the distance to an object by detecting reflected light from the object. While changing the direction of a light beam in each of a plurality of frame periods, this system causes one or more light receiving elements of an image sensor to sequentially detect the reflected light. Such an operation successfully shortens the time required to acquire distance information on the entire target scene.</p><p id="p-0006" num="0005">Japanese Unexamined Patent Application Publication No. 2009-217680 discloses a method for detecting a traverse object that moves in a direction different from the direction of movement of an own vehicle. It is disclosed, for example, that a reduction in signal-to-noise ratio is achieved by increasing the intensity or number of emissions of an optical pulse from a light source.</p><p id="p-0007" num="0006">In order to obtain detailed distance information on a distant physical object, Japanese Unexamined Patent Application Publication No. 2018-049014 discloses providing, separately from a first distance measurement apparatus, a second distance measurement apparatus that emits a light beam to a distant physical object.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0008" num="0007">One non-limiting and exemplary embodiment provides a technology for more efficiently acquiring distance information on one or more physical objects that are present in a scene.</p><p id="p-0009" num="0008">In one general aspect, the techniques disclosed here feature a method for controlling a distance measurement apparatus including a light emitting device capable of changing a direction of emission of a light beam and a light receiving device that detects a reflected light beam produced by the emission of the light beam. The method includes acquiring data representing a plurality of images acquired at different points in time by an image sensor that acquires an image of a scene to be subjected to distance measurement, determining, on the basis of the data representing the plurality of images, a degree of priority of distance measurement of one or more physical objects included in the plurality of images, and executing distance measurement of the one or more physical objects by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam.</p><p id="p-0010" num="0009">It should be noted that general or specific aspects of the present disclosure may be implemented as a system, an apparatus, a method, an integrated circuit, a computer program, a storage medium such as a computer-readable storage disk, or any selective combination thereof. The computer-readable storage medium may include a nonvolatile storage medium such as a CD-ROM (compact disc-read-only memory). The apparatus may be constituted by one or more apparatuses. In a case where the apparatus is constituted by two or more apparatuses, the two or more apparatuses may be placed within one piece of equipment, or may be placed separately in each of two or more separate pieces of equipment. The term &#x201c;apparatus&#x201d; as used herein or in the claims may not only mean one apparatus but also mean a system composed of a plurality of apparatuses.</p><p id="p-0011" num="0010">An aspect of the present disclosure makes it possible to more efficiently acquire distance information on one or more physical objects that are present in a scene.</p><p id="p-0012" num="0011">Additional benefits and advantages of an aspect of the present disclosure will become apparent from the specification and drawings. The benefits and/or advantages may be individually obtained by the various aspects and features of the specification and drawings, which need not all be provided in order to obtain one or more of such benefits and/or advantages.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram schematically showing a distance measurement system according to an exemplary embodiment of the present disclosure;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram showing an example of a light emitting device;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a perspective view schematically showing another example of the light emitting device;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically showing an example of a structure of an optical waveguide element;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically showing an example of a phase shifter;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram for explaining an example of an indirect TOF distance measurement method;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram for explaining another example of an indirect TOF distance measurement method;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>8</b>A</figref> is a diagram showing an example of data that is stored in a first storage device;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>8</b>B</figref> is a diagram showing an example of data that is stored in the first storage device;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>8</b>C</figref> is a diagram showing an example of data that is stored in the first storage device;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>8</b>D</figref> is a diagram showing an example of data that is stored in the first storage device;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>9</b>A</figref> is a diagram showing an example of data that is stored in a second storage device;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>9</b>B</figref> is a diagram showing an example of data that is stored in the second storage device;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>9</b>C</figref> is a diagram showing an example of data that is stored in the second storage device;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>9</b>D</figref> is a diagram showing an example of data that is stored in the second storage device;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram showing an example of data that is stored in a third storage device;</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flow chart presenting an overview of an operation of the distance measurement system;</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>12</b>A</figref> is a diagram showing an example of a distance measurement method for each cluster;</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>12</b>B</figref> is a diagram showing an example of a distance measurement method for each cluster;</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>12</b>C</figref> is a diagram showing an example of a distance measurement method for each cluster;</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flow chart showing details of an action of step S<b>1400</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>;</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>14</b>A</figref> is a diagram showing an example of an immediately preceding frame f<b>0</b> of image;</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>14</b>B</figref> is a diagram showing an example of a current frame f<b>1</b> of image;</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>14</b>C</figref> is a diagram displaying motion vectors with the frames f<b>0</b> and f<b>1</b> of image superimposed on top of each other;</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>14</b>D</figref> is a diagram showing examples of motion vectors based on own-vehicle movement;</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>14</b>E</figref> is a diagram showing examples of relative velocity vectors;</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flow chart showing details of a process for calculating a motion vector based on own-vehicle movement in step S<b>1407</b>;</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>16</b>A</figref> is a diagram showing examples of apparent motion vectors in a case where the distance measurement system is placed at the front of a movable body and the movable body is traveling forward;</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>16</b>B</figref> is a diagram showing examples of apparent motion vectors in a case where the distance measurement system is placed at the right front of the movable body and the movable body is traveling forward;</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>16</b>C</figref> is a diagram showing examples of apparent motion vectors in a case where the distance measurement system is placed on the right side of the movable body and the movable body is traveling forward;</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>16</b>D</figref> is a diagram showing examples of apparent motion vectors in a case where the distance measurement system is placed at the center rear of the movable body and the movable body is traveling forward;</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flow chart showing details of a process of risk calculation in step S<b>1500</b>;</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a diagram for explaining an example of a process of step S<b>1503</b>;</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flow chart showing a detailed example of a method for calculating a degree of risk according to rate of acceleration in step S<b>1504</b>;</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>20</b>A</figref> is a first diagram for explaining a process for calculating an acceleration vector in a case where an own vehicle is traveling straight forward at a constant speed;</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>20</b>B</figref> is a second diagram for explaining the process for calculating an acceleration vector in a case where the own vehicle is traveling straight at a constant speed;</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>20</b>C</figref> is a third diagram for explaining the process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward at a constant speed;</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>21</b>A</figref> is a first diagram for explaining a process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward while accelerating;</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>21</b>B</figref> is a second diagram for explaining the process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward while accelerating;</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>21</b>C</figref> is a third diagram for explaining the process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward while accelerating;</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>22</b>A</figref> is a first diagram for explaining a process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward while decelerating;</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>22</b>B</figref> is a second diagram for explaining the process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward while decelerating;</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>22</b>C</figref> is a third diagram for explaining the process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward while decelerating;</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>23</b>A</figref> is a first diagram for explaining a process for calculating an acceleration vector in a case where the own vehicle turns right;</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>23</b>B</figref> is a second diagram for explaining the process for calculating an acceleration vector in a case where the own vehicle turns right;</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>23</b>C</figref> is a third diagram for explaining the process for calculating an acceleration vector in a case where the own vehicle turns right;</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a flow chart showing a detailed example of an operation of step S<b>1600</b>;</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>25</b></figref> is a flow chart showing a detailed example of an operation of distance measurement in step S<b>1700</b>;</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a flow chart showing a detailed example of a data integration process in step S<b>1800</b>;</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram showing an example of a coordinate system of the movable body;</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>28</b>A</figref> is a diagram showing an example of output data that is generated by a processing apparatus;</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>28</b>B</figref> is a diagram showing another example of output data;</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>29</b>A</figref> is a first diagram for explaining a process for generating a vector in a case where the distance measurement system is installed at the right front of the movable body;</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>29</b>B</figref> is a second diagram for explaining the process for generating a vector in a case where the distance measurement system is installed at the right front of the movable body;</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>29</b>C</figref> is a third diagram for explaining the process for generating a vector in a case where the distance measurement system is installed at the right front of the movable body;</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>29</b>D</figref> is a fourth diagram for explaining the process for generating a vector in a case where the distance measurement system is installed at the right front of the movable body;</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>29</b>E</figref> is a fifth diagram for explaining the process for generating a vector in a case where the distance measurement system is installed at the right front of the movable body;</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>30</b></figref> is a diagram showing an example of a predicted relative position of a physical object in a scene in a case where the distance measurement system is installed at the right front of the movable body;</p><p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. <b>31</b>A</figref> is a first diagram for explaining a process for generating a vector in a case where the distance measurement system is installed on the right side of the movable body;</p><p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. <b>31</b>B</figref> is a second diagram for explaining the process for generating a vector in a case where the distance measurement system is installed on the right side of the movable body;</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>31</b>C</figref> is a third diagram for explaining the process for generating a vector in a case where the distance measurement system is installed on the right side of the movable body;</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. <b>31</b>D</figref> is a fourth diagram for explaining the process for generating a vector in a case where the distance measurement system is installed on the right side of the movable body;</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>31</b>E</figref> is a fifth diagram for explaining the process for generating a vector in a case where the distance measurement system is installed on the right side of the movable body;</p><p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. <b>32</b>A</figref> is a first diagram for explaining a process for generating a vector in a case where the distance measurement system is installed at the center rear of the movable body;</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>32</b>B</figref> is a second diagram for explaining the process for generating a vector in a case where the distance measurement system is installed at the center rear of the movable body;</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. <b>32</b>C</figref> is a third diagram for explaining the process for generating a vector in a case where the distance measurement system is installed at the center rear of the movable body;</p><p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>32</b>D</figref> is a fourth diagram for explaining the process for generating a vector in a case where the distance measurement system is installed at the center rear of the movable body;</p><p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. <b>32</b>E</figref> is a fifth diagram for explaining the process for generating a vector in a case where the distance measurement system is installed at the center rear of the movable body;</p><p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. <b>33</b></figref> is a diagram showing an example of a predicted relative position of a physical object in a scene in a case where the distance measurement system is installed at the center rear of the movable body;</p><p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. <b>34</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0083" num="0082"><figref idref="DRAWINGS">FIG. <b>34</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. <b>34</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>35</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. <b>35</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0087" num="0086"><figref idref="DRAWINGS">FIG. <b>35</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. <b>36</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. <b>36</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. <b>36</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the right front of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. <b>37</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>37</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0093" num="0092"><figref idref="DRAWINGS">FIG. <b>37</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. <b>38</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0095" num="0094"><figref idref="DRAWINGS">FIG. <b>38</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. <b>38</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0097" num="0096"><figref idref="DRAWINGS">FIG. <b>39</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. <b>39</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. <b>39</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed on the right side of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0100" num="0099"><figref idref="DRAWINGS">FIG. <b>40</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. <b>40</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>40</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle is traveling straight forward while accelerating;</p><p id="p-0103" num="0102"><figref idref="DRAWINGS">FIG. <b>41</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0104" num="0103"><figref idref="DRAWINGS">FIG. <b>41</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0105" num="0104"><figref idref="DRAWINGS">FIG. <b>41</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle is traveling straight forward while decelerating;</p><p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. <b>42</b>A</figref> is a first diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0107" num="0106"><figref idref="DRAWINGS">FIG. <b>42</b>B</figref> is a second diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. <b>42</b>C</figref> is a third diagram showing an example of a process for calculating an acceleration vector in a case where the distance measurement system is installed at the center rear of the movable body and the own vehicle turns right while decelerating;</p><p id="p-0109" num="0108"><figref idref="DRAWINGS">FIG. <b>43</b></figref> is a block diagram showing an example configuration of the distance measurement apparatus according to a modification;</p><p id="p-0110" num="0109"><figref idref="DRAWINGS">FIG. <b>44</b></figref> is a diagram showing an example of data that is stored by a storage device in the distance measurement apparatus; and</p><p id="p-0111" num="0110"><figref idref="DRAWINGS">FIG. <b>45</b></figref> is a flow chart showing an operation of distance measurement according to the modification.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTIONS</heading><p id="p-0112" num="0111">In the present disclosure, all or some of the circuits, units, apparatuses, members, or sections or all or some of the functional blocks in the block diagrams may be implemented as one or more of electronic circuits including, but not limited to, a semiconductor device, a semiconductor integrated circuit (IC), or an LSI (large scale integration). The LSI or IC can be integrated into one chip, or also can be a combination of multiple chips. For example, functional blocks other than a memory may be integrated into one chip. The name used here is LSI or IC, but it may also be called system LSI, VLSI (very large scale integration), or VLSI (ultra large scale integration) depending on the degree of integration. A Field Programmable Gate Array (FPGA) that can be programmed after manufacturing an LSI or a reconfigurable logic device that allows reconfiguration of the connection or setup of circuit cells inside the LSI can be used for the same purpose.</p><p id="p-0113" num="0112">Further, it is also possible that all or some of the functions or operations of the circuits, units, apparatuses, members, or sections are implemented by executing software. In such a case, the software is stored on one or more non-transitory storage media such as a ROM, an optical disk, or a hard disk drive, and when the software is executed by a processor, the software causes the processor together with peripheral devices to execute the functions specified in the software. A system or device may include such one or more non-transitory storage media on which the software is stored and a processor together with necessary hardware devices such as an interface.</p><p id="p-0114" num="0113">In order to measure distances to a plurality of objects scattered about over a wide range in a scene, a conventional distance measurement apparatus uses a method for illuminating the scene thoroughly with a light beam, for example, by raster scanning. With such a method, even an area where no object is present is illuminated with the light beam, and the light beam is emitted in a predetermined order. Therefore, even in the presence of a dangerous or important object in the scene, it is impossible to preferentially emit the object with the light beam. In order to emit the light beam preferentially in a particular direction regardless of order of light emission of scanning, it is necessary to, as disclosed, for example, in Japanese Unexamined Patent Application Publication No. 2018-049014, add a distance measurement apparatus that performs distance measurement preferentially in a certain direction.</p><p id="p-0115" num="0114">Embodiments of the present disclosure provide technologies that make it possible to efficiently acquire distance information on an object without adding a distance measurement apparatus. The following gives a brief overview of the embodiments of the present disclosure.</p><p id="p-0116" num="0115">A control method according to an exemplary embodiment of the present disclosure is a method for controlling a distance measurement apparatus including a light emitting device capable of changing a direction of emission of a light beam and a light receiving device that detects a reflected light beam produced by the emission of the light beam. The method includes acquiring data representing a plurality of images acquired at different points in time by an image sensor that acquires an image of a scene to be subjected to distance measurement, determining, on the basis of the data representing the plurality of images, a degree of priority of distance measurement of one or more physical objects included in the plurality of images, and executing distance measurement of the one or more physical objects by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam.</p><p id="p-0117" num="0116">According to the foregoing method, a degree of priority of distance measurement of one or more physical objects included in the plurality of images is determined on the basis of the data representing the plurality of images, and distance measurement of the one or more physical objects is executed by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam. Such control makes it possible to efficiently execute distance measurement of a particular physical object having a high degree of priority.</p><p id="p-0118" num="0117">The distance measurement apparatus may be mounted on board a movable body. The method may include acquiring, from the movable body, data representing a movement of the movable body. The degree of priority may be determined on the basis of the data representing the plurality of images and the data representing the movement of the movable body.</p><p id="p-0119" num="0118">The foregoing method makes it possible to determine the degree of priority of the physical object according to a state of movement of the movable body. The movable body may be a vehicle such as an automobile or a two-wheeler. The data representing the movement of the movable body may contain, for example, information such as the velocity, rate of acceleration, or rate of angular acceleration of the movable body. The degree of priority of the physical object cam be more appropriately determine by using not only the data representing the plurality of images but also the data representing the movement of the movable body. For example, on the basis of the velocity or rate of acceleration of the own vehicle and a motion vector of a physical object computed from the plurality of images, the degree of risk of the physical object can be estimated. Flexible control such as setting a high degree of priority for a physical object having a high degree of risk is possible.</p><p id="p-0120" num="0119">Determining the degree of priority may include generating a motion vector of the one or more physical objects on the basis of the plurality of images, generating, on the basis of the data representing the movement of the movable body, a motion vector of a stationary object that is generated due to the movement of the movable body, and determining the degree of priority on the basis of a relative velocity vector that is a difference between the motion vector of the physical object and the motion vector of the stationary object.</p><p id="p-0121" num="0120">According to the foregoing method, for example, as the relative velocity vector becomes greater, the degree of risk of the physical object becomes higher, so that the degree of priority can be made higher. As a result, a dangerous physical object can be intensively and efficiently subjected to distance measurement.</p><p id="p-0122" num="0121">The method may further include, after having executed the distance measurement, outputting, to the movable body, data containing information identifying the physical object and information indicating a distance to the physical object. This allows the movable body to perform an action of, for example, avoiding the physical object.</p><p id="p-0123" num="0122">The degree of priority may be determined on the basis of a magnitude of a time change in the relative velocity vector. The time change in the relative velocity vector represents the rate of acceleration of the physical object. A physical object having a higher rate of acceleration can be determined to be more dangerous and have higher priority. The degree of priority may be determined on the basis of a magnitude of the relative velocity vector.</p><p id="p-0124" num="0123">Acquiring the data representing the plurality of images may include acquiring data representing first, second and third images consecutively acquired by the image sensor. Determining the degree of priority may include generating a first motion vector of the physical object on the basis of the first image and the second image, generating a second motion vector of the physical object on the basis of the second image and the third image, generating, on the basis of the data representing the movement of the movable body, a motion vector of a stationary object that is generated due to the movement of the movable body, generating a first relative velocity vector that is a difference between the first motion vector and the motion vector of the stationary object, generating a second relative velocity vector that is a difference between the second motion vector and the motion vector of the stationary object, and determining the degree of priority on the basis of a difference between the first relative velocity vector and the second relative velocity vector. Such an action makes it possible to determine the degree of priority as appropriate according to a time change in motion vector.</p><p id="p-0125" num="0124">The method may further include repeating more than once a cycle including acquiring the data representing the images, determining the degree of priority of distance measurement of the physical object, and executing the distance measurement of the physical object. A plurality of the cycles may be repeated at regular short time intervals (e.g. approximately few microseconds to few seconds). By repeating determination of the degree of priority and distance measurement, distance measurement of a physical object having a high degree of risk or degree of importance can be appropriately executed even in a traffic environment that changes very rapidly with the passage of time.</p><p id="p-0126" num="0125">For a physical object on which the distance measurement was executed in a cycle, the distance measurement may be continued in a next cycle without determining the degree of priority. In general, it is preferable that distance measurement of a physical object determined to have high priority be continued in the next and subsequent cycles. The foregoing method makes it possible to track the object by skipping determination of the degree of priority and continuing the distance measurement.</p><p id="p-0127" num="0126">The method may further include determining a duration of illumination with the light beam according to the degree of priority. For example, a physical object having a higher degree of priority may be illuminated with the light beam for a longer time. In a case where an indirect TOF method is used as the distance measurement method, the measurable range of distances can be made larger as the duration of illumination with the light beam and the period of exposure of the light receiving device are made longer. For this reason, by lengthening the duration of illumination with the light beam of a physical object having a high degree of priority, the measurable range of distances to the physical object can be extended.</p><p id="p-0128" num="0127">The method may further include determining a number of occurrences of the emission of the light beam and detection of the reflected light beam according to the degree of priority. For example, the number of occurrences may be increased for a physical object having a higher degree of priority. Accuracy of distance measurement can be increased by increasing the number of occurrences. For example, errors in distance measurement can reduced by a process of, for example, averaging results of more than one occurrence of distance measurement.</p><p id="p-0129" num="0128">The light receiving device may include the image sensor. Alternatively, the image sensor may be a device that is independent of the light receiving device.</p><p id="p-0130" num="0129">The image sensor may be configured to acquire the images from light emitted by the light emitting device. In that case, the light emitting device may be configured to emit, separately from the light beam, flush light that illuminates a wide range.</p><p id="p-0131" num="0130">A control apparatus according to another embodiment of the present disclosure controls a distance measurement apparatus including a light emitting device capable of changing a direction of emission of a light beam and a light receiving device that detects a reflected light beam produced by the emission of the light beam. The control apparatus includes a processor and a storage medium having stored thereon a computer program that is executed by the processor. The computer program causes the processor to execute operations including acquiring data representing a plurality of images acquired at different points in time by an image sensor that acquires an image of a scene to be subjected to distance measurement, determining, on the basis of the data representing the plurality of images, a degree of priority of distance measurement of one or more physical objects included in the plurality of images, and executing distance measurement of the one or more physical objects by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam.</p><p id="p-0132" num="0131">A system according to still another embodiment of the present disclosure includes the control apparatus, the light emitting device, and the control apparatus.</p><p id="p-0133" num="0132">A computer program according to still another embodiment of the present disclosure is executed by a processor that controls a distance measurement apparatus including a light emitting device capable of changing a direction of emission of a light beam and a light receiving device that detects a reflected light beam produced by the emission of the light beam. The computer program causes the processor to execute operations including acquiring data representing a plurality of images acquired at different points in time by an image sensor that acquires an image of a scene to be subjected to distance measurement, determining, on the basis of the data representing the plurality of images, a degree of priority of distance measurement of one or more physical objects included in the plurality of images, and executing distance measurement of the one or more physical objects by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam.</p><p id="p-0134" num="0133">The following describes an exemplary embodiment of the present disclosure. It should be noted that the embodiment to be described below illustrates a general or specific examples. The numerical values, shapes, constituent elements, placement and topology of constituent elements, steps, orders of steps, or other features that are shown in the following embodiment are merely examples and are not intended to limit the present disclosure. Further, those of the constituent elements in the following embodiment which are not recited in an independent claim representing the most generic concept are described as optional constituent elements. Further, the drawings are schematic views and are not necessarily strict illustrations. Furthermore, in the drawings, substantially the same components are given the same reference signs, and a repeated description may be omitted or simplified.</p><heading id="h-0007" level="1">Embodiment 1</heading><p id="p-0135" num="0134">A configuration and operation of a distance measurement system according to exemplary Embodiment 1 of the present disclosure are described.</p><heading id="h-0008" level="1">1-1. Configuration</heading><p id="p-0136" num="0135"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram schematically showing a distance measurement system <b>10</b> according to exemplary Embodiment 1 of the present disclosure. The distance measurement system <b>1</b> may be mounted on board a movable body such as a self-guided vehicle. The movable body includes a control apparatus <b>400</b> that controls mechanisms such as an engine, a steering, a brake, and an accelerator. The distance measurement system <b>10</b> acquires information on the movement of the movable body and a plan of movement of the movable body from the control apparatus <b>400</b> of the movable body and outputs, to the control apparatus <b>400</b>, information generated regarding a surrounding environment.</p><p id="p-0137" num="0136">The distance measurement system <b>10</b> includes an imaging apparatus <b>100</b>, a distance measurement apparatus <b>200</b>, and a processing apparatus <b>300</b>. The imaging apparatus <b>100</b> acquires a two-dimensional image by imaging a scene. The distance measurement apparatus <b>200</b> emits light, detects reflected light produced by the light thus emitted being reflected by a physical object, and thereby measures the distance to the physical object. The processing apparatus <b>300</b> acquires image information acquired by the imaging apparatus <b>100</b>, distance information acquired by the distance measurement apparatus <b>200</b>, and movement information and movement plan information that are sent from the control apparatus <b>400</b> of the movable body. The processing apparatus <b>300</b> generates, on the basis of those pieces of information thus acquired, information regarding the surrounding environment and outputs, to the control apparatus <b>400</b>, the information regarding the surrounding environment. The information regarding the surrounding environment is hereinafter referred to as &#x201c;surrounding information&#x201d;.</p><heading id="h-0009" level="1">1-1-1. Imaging Device</heading><p id="p-0138" num="0137">The imaging apparatus <b>100</b> includes an optical system <b>110</b> and an image sensor <b>120</b>. The optical system <b>110</b> includes one or more lenses and forms an image on a photosensitive surface of the image sensor <b>120</b>. The image sensor <b>120</b> is a sensor, such as a CMOS(complementary metal-oxide semiconductor) or a CCD(charge-coupled device), that generates and outputs two-dimensional image data.</p><p id="p-0139" num="0138">The imaging apparatus <b>100</b> acquires a luminance image of a scene in the same direction as the distance measurement apparatus <b>200</b>. The luminance image may be a color image or a black-and-white image. The imaging apparatus <b>100</b> may image a scene by means of outside light or may image a scene by illuminating the scene with light from a light source. The light emitted from the light source may be a diffused light, or the whole scene may be imaged by sequentially illuminating the scene with a light beam. The imaging apparatus <b>100</b> is not limited to a visible-light camera but may be an infrared camera.</p><p id="p-0140" num="0139">The imaging apparatus <b>100</b> performs continuous imaging and generates moving image data in accordance with instructions from the processing apparatus <b>300</b>.</p><heading id="h-0010" level="1">1-1-2. Distance Measurement Apparatus</heading><p id="p-0141" num="0140">The distance measurement apparatus <b>200</b> includes a light emitting device <b>210</b>, a light receiving device <b>220</b>, a control circuit <b>230</b>, and a processing circuit <b>240</b>. The light emitting device <b>210</b> can emit a light beam in any direction within a predetermined range. The light receiving device <b>220</b> receives a reflected light beam produced by the light beam emitted by the light emitting device <b>210</b> being reflected by a physical object in a scene. The light receiving device <b>220</b> includes an image sensor or one or more photodetectors that detect the reflected light beam. The control circuit <b>230</b> controls the timing and direction of emission of the light beam that is emitted from the light emitting device <b>210</b> and the timing of exposure of the light receiving device <b>220</b>. The processing circuit <b>240</b> calculates, on the basis of a signal outputted from the light receiving device <b>220</b>, a distance to an object illuminated with the light beam. The distance can be measured by measuring or calculating the time from emission to reception of the light beam. It should be noted that the control circuit <b>230</b> and the processing circuit <b>240</b> may be implemented by one integrated circuit.</p><p id="p-0142" num="0141">The light emitting device <b>210</b> is a beam scanner capable of changing the direction of emission of the light beam under control of the control circuit <b>230</b>. The light emitting device <b>210</b> can sequentially illuminate some areas within a distance measurement target scene with the light beam. The wavelength of the light beam that is emitted from the light emitting device <b>210</b> is not limited to particular wavelengths, but may for example be any wavelength that falls within a visible to infrared range.</p><p id="p-0143" num="0142"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram showing an example of the light emitting device <b>210</b>. In this example, the light emitting device <b>210</b> includes a light source that emits a light beam such as a laser and at least one movable mirror, e.g. MEMS mirror. Light emitted from the light source is reflected by the movable mirror and travels toward a predetermined area within a target area (indicated by a rectangle in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The control circuit <b>230</b> drives the movable mirror to effect a change in direction of the light emitted from the light emitting device <b>210</b>. This makes it possible to scan the target area with the light, for example, as indicated by dotted arrows in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0144" num="0143">A light source capable of changing the direction of emission of light by means of a structure different from a light emitting device having a movable mirror may be used. For example, as disclosed in Japanese Unexamined Patent Application Publication No. 2018-124271, a light emitting device including a reflective waveguide may be used. Alternatively, a light emitting device that, by adjusting the phase of light that is outputted from each antenna by an antenna array, changes the direction of light of the whole array.</p><p id="p-0145" num="0144"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a perspective view schematically showing another example of the light emitting device <b>210</b>. For reference, X, Y, and Z axes orthogonal to one another are schematically shown. The light emitting device <b>210</b> includes an optical waveguide array <b>80</b>A, a phase shifter array <b>20</b>A, an optical divider <b>30</b>, and a substrate <b>40</b> on which the optical waveguide array <b>80</b>A, the phase shifter array <b>20</b>A, the optical divider <b>30</b> are integrated. The optical waveguide array <b>80</b>A includes a plurality of optical waveguide elements <b>80</b> arrayed in a Y direction. Each of the optical waveguide elements <b>80</b> extends in an X direction. The phase shifter array <b>20</b> includes a plurality of phase shifters <b>20</b> arrayed in the Y direction. Each of the phase shifters <b>20</b> includes an optical waveguide extending in the X direction. The plurality of optical waveguide elements <b>80</b> of the optical waveguide array <b>80</b>A are connected separately to each of the plurality of phase shifters <b>20</b> of the phase shifter array <b>20</b>. The optical divider <b>30</b> is connected to the phase shifter array <b>20</b>A.</p><p id="p-0146" num="0145">Light L<b>0</b> emitted from a light source such as a laser element is inputted to the plurality of phase shifters <b>20</b> of the phase shifter array <b>20</b>A via the optical divider <b>30</b>. Light having passed through the plurality of phase shifters <b>20</b> of the phase shifter array <b>20</b>A is inputted to each of the plurality of optical waveguide elements <b>80</b> of the optical waveguide array <b>80</b>A with its phase shifted by certain amounts in the Y direction. Light inputted to each of the plurality of optical waveguide elements <b>80</b> of the optical waveguide array <b>80</b>A is emitted as a light beam L<b>2</b> from a light exit surface <b>80</b><i>s </i>parallel to an X-Y plane in a direction intersecting the light exit surface <b>80</b><i>s. </i></p><p id="p-0147" num="0146"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically showing an example of a structure of an optical waveguide element <b>80</b>. The optical waveguide element <b>80</b> includes a first mirror <b>11</b> and a second mirror <b>12</b> that face each other, an optical waveguide layer <b>15</b> located between the first mirror <b>11</b> and the second mirror <b>12</b>, and a pair of electrodes <b>13</b> and <b>14</b> through which a driving voltage is applied to the optical waveguide layer <b>15</b>. The optical waveguide layer <b>15</b> may be constituted by a material, such as a liquid crystal material or an electro-optic material, whose refractive index changes through the application of a voltage. The transmissivity of the first mirror <b>11</b> is higher than the transmissivity of the second mirror <b>12</b>. The first mirror <b>11</b> and the second mirror <b>12</b> may each be formed, for example, from a multilayer reflecting film in which a plurality of high-refractive-index layers and a plurality of low-refractive-index layers are alternately stacked.</p><p id="p-0148" num="0147">Light inputted to the optical waveguide layer <b>15</b> propagates along the X direction through the optical waveguide layer <b>15</b> while being reflected by the first mirror <b>11</b> and the second mirror <b>12</b>. An arrow in <figref idref="DRAWINGS">FIG. <b>4</b></figref> schematically represents how the light propagates. A portion of the light propagating through the optical waveguide layer <b>15</b> is emitted outward through the first mirror <b>11</b>.</p><p id="p-0149" num="0148">Applying the driving voltage to the electrodes <b>13</b> and <b>14</b> causes the refractive index of the optical waveguide layer <b>15</b> to change, so that the direction of light that is emitted outward from the optical waveguide element <b>80</b> changes. According to changes in the driving voltage, the direction of the light beam L<b>2</b>, which is emitted from the optical waveguide array <b>80</b>A, changes. Specifically, the direction of emission of the light beam L<b>2</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> can be changed along a first direction D1 parallel with the X axis.</p><p id="p-0150" num="0149"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram schematically showing an example of a phase shifter <b>20</b>. The phase shifter <b>20</b> includes a total reflection waveguide <b>21</b> containing a thermo-optic material whose refractive index changes by heat, a heater <b>22</b> that makes thermal contact with the total reflection waveguide <b>21</b>, and a pair of electrodes <b>23</b> and <b>24</b> through which a driving voltage is applied to the heater <b>22</b>. The refractive index of the total reflection waveguide <b>21</b> is higher than the refractive indices of the heater <b>22</b>, the substrate <b>40</b>, and air. The difference in refractive index causes light inputted to the total reflection waveguide <b>21</b> to propagate along the X direction through the total reflection waveguide <b>21</b> while being totally reflected.</p><p id="p-0151" num="0150">Applying the driving voltage to the pair of electrodes <b>23</b> and <b>24</b> causes the total reflection waveguide <b>21</b> to be heated by the heater <b>22</b>. This results in a change in the refractive index of the total reflection waveguide <b>21</b>, so that there is a shift in the phase of light that is emitted from an end of the total reflection waveguide <b>21</b>. Changing the phase difference in light that is outputted from two adjacent phase shifters <b>20</b> of the plurality of phase shifters <b>20</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> allows the direction of emission of the light beam L<b>2</b> to change along a second direction D2 parallel with the Y axis.</p><p id="p-0152" num="0151">The foregoing configuration allows the light emitting device <b>210</b> to two-dimensionally change the direction of emission of the light beam L<b>2</b>. Details such as the principle of operation and method of operation of such a light emitting device <b>210</b> are disclosed in Japanese Unexamined Patent Application Publication No. 2018-124271, the entire contents of which are hereby incorporated by reference.</p><p id="p-0153" num="0152">Next, an example configuration of the image sensor of the light receiving device <b>220</b> is described. The image sensor includes a plurality of light receiving elements two-dimensionally arrayed along a photosensitive surface. The image sensor may be provided with an optical component facing the photosensitive surface of the image sensor. The optical component may include, for example, at least one lens. The optical component may include another optical element such as a prism or a mirror. The optical component may be designed so that light having diffused from one point on an object in a scene converges at one point on the photosensitive surface of the image sensor.</p><p id="p-0154" num="0153">The image sensor may for example be a CCD (charge-coupled device) sensor, a CMOS (complementary metal-oxide semiconductor) sensor, or an infrared array sensor. Each of the light receiving elements includes a photoelectric conversion element such as a photodiode and one or more charge accumulators. Electric charge produced by photoelectric conversion is accumulated in the charge accumulators during an exposure period. The electric charge accumulated in the charge accumulator is outputted after the end of the exposure period. In this way, each of the light receiving elements outputs an electric signal corresponding to the amount of light received during the exposure period. This electric signal may be referred to as &#x201c;detection signal&#x201d;. The image sensor may be a monochrome imaging element, or may be a color imaging element. For example, a color imaging element having an R/G/B, R/G/B/IR or R/G/B/W filter may be used. The image sensor may have detection sensitivity not only to a visible wavelength range but also to a range of wavelengths such as ultraviolet, near-infrared, mid-infrared, or far-infrared wavelengths. The image sensor may be a sensor including a SPAD (single-photon avalanche diode). The image sensor may include an electronic shutter of a mode by which all pixels are exposed en bloc, i.e. a global shutter mechanism. The electronic shutter may be of a rolling-shutter mode by which an exposure is made for each row or of an area shutter mode by which only some areas adjusted to a range of illumination with a light beam are exposed.</p><p id="p-0155" num="0154">With reference to the timing of emission of light from the light emitting device <b>210</b>, the image sensor receives reflected light in each of a plurality of exposure periods differing in timing of start and end from one each other and outputs, for each exposure period, a signal indicating the amount of light received.</p><p id="p-0156" num="0155">The control circuit <b>230</b> determines the direction and timing of emission of light by the light emitting device <b>210</b> and outputs a control signal to the light emitting device <b>210</b> to instruct the light emitting device <b>210</b> to emit light. Furthermore, the control circuit <b>230</b> determines the timing of exposure of the light receiving device <b>220</b> and outputs a control signal to the light receiving device <b>220</b> to instruct the light receiving device <b>220</b> to make an exposure and output a signal.</p><p id="p-0157" num="0156">The processing circuit <b>240</b> acquires signals, outputted from the light receiving device <b>220</b>, that indicate electric charge accumulated during a plurality of different exposure periods and, on the basis of those signals, calculates a distance to a physical object. The processing circuit <b>240</b> calculates, on the basis of ratios of electric charge accumulated separately in each of the plurality of exposure periods, the time from emission of the light beam from the light emitting device <b>210</b> to reception of the reflected light beam by the light receiving device <b>220</b> and calculates a distance from the time thus calculated. Such a distance measurement method is referred to as &#x201c;indirect TOF method&#x201d;.</p><p id="p-0158" num="0157"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram showing examples of the timing of light emission, the timing of arrival of reflected light, and the timings of two exposures in an indirect TOF distance measurement method. The horizontal axis represents time. The rectangular portions represent the respective periods of light emission, arrival of reflected light, and two exposures. For simplicity, this example illustrates an example of a case where one light beam is emitted and a light receiving element that received reflected light produced by the light beam makes two consecutive exposures. (a) of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the timing of emission of light from the light source. T<b>0</b> denotes the pulse duration of a light beam for use in distance measurement. (b) of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the period of arrival at the image sensor of the light beam emitted from the light source and reflected off an object. Td denotes the time of flight of the light beam. In the example shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the reflected light arrives at the image sensor in a time Td that is shorter than the time duration T<b>0</b> of the light pulse. (c) of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a first exposure period of the image sensor. In this example, an exposure is started at the same time as the start of light emission and ends at the same time as the end of light emission. In the first exposure period, a portion of the reflected light having returned early is photoelectrically converted, and the resulting electric charge is accumulated. Q<b>1</b> denotes the energy of the light photoelectrically converted during the first exposure period. The energy Q<b>1</b> is proportional to the amount of electric charge accumulated during the first exposure period. (d) of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a second exposure period of the image sensor. In this example, the second exposure period starts at the same time as the end of light emission and ends at a point in time where a period of time equal in length to the pulse duration T<b>0</b> of the light beam, i.e. a period of time equal in length to the first exposure period, has elapsed. Q<b>2</b> denotes the energy of light photoelectrically converted during the second exposure period. The energy Q<b>2</b> is proportional to the amount of electric charge accumulated during the second exposure period. In the second exposure period, a portion of the reflected light having arrived after the end of the first exposure period is received. Since the first exposure period is equal in length to the pulse duration T<b>0</b> of the light beam, the time duration of the reflected light that is received in the second exposure period is equal to the time of flight Td.</p><p id="p-0159" num="0158">Let it be assumed here that Cfd1 is the integral capacitance of electric charge that is accumulated in the light receiving element during the first exposure period, Cfd2 is the integral capacitance of electric charge that is accumulated in the light receiving element during the second exposure period, Iph is a photoelectric current, and N is a charge transfer clock number. The output voltage of the light receiving element in the first exposure period is expressed by Vout1 as follows:</p><p id="p-0160" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Vout1<i>=Q</i>1<i>/Cfd</i>1<i>=N&#xd7;Iph</i>&#xd7;(<i>T</i>0<i>&#x2212;Td</i>)/<i>Cfd</i>1<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0161" num="0159">The output voltage of the light receiving element in the second exposure period is expressed by Vout2 as follows:</p><p id="p-0162" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Vout2<i>=Q</i>2<i>/Cfd</i>2<i>=N&#xd7;Iph&#xd7;Td/Cfd</i>2<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0163" num="0160">In the example shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, since the time length of the first exposure period is equal to the time length of the second exposure period, Cfd1=Cfd2. Accordingly, Td can be expressed by the following formula:</p><p id="p-0164" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Td</i>={Vout2/(Vout1+Vout2)}&#xd7;<i>T</i>0<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0165" num="0161">Assuming that C is the velocity of light (&#x2248;3&#xd7;10<sup>8 </sup>m/s), the distance L between the device and the object is expressed by the following formula:</p><p id="p-0166" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>L=</i>1/2<i>&#xd7;C&#xd7;Td</i>=1/2<i>&#xd7;C</i>&#xd7;{Vout2/(Vout1+Vout2)}&#xd7;<i>T</i>0<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0167" num="0162">The image sensor, which in actuality outputs electric charge accumulated during an exposure period, may be unable, in terms of time, to make two consecutive exposures. In such a case, for example, a method shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> is may be used.</p><p id="p-0168" num="0163"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram schematically showing the timings of light emission, exposure, and charge output in a case where two consecutive exposure periods cannot be provided. In the example shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, first, the image sensor starts an exposure at the same time as the light source starts emitting light, and the image sensor ends the exposure at the same time as the light source finishes emitting the light. This exposure period is equivalent to &#x201c;EXPOSURE PERIOD 1&#x201d; in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. Immediately after the exposure, the image sensor outputs electric charge accumulated during this exposure period. This amount of electric charge is equivalent to the energy Q<b>1</b> of the light received. Next, the light source starts emitting light again and, when a time T<b>0</b> equal in length to the first light emission elapses, finishes emitting the light. The image sensor starts an exposure at the same time as the light source finishes emitting the light and, when a time length equal to the first exposure period elapses, finishes the exposure. This exposure period is equivalent to &#x201c;EXPOSURE PERIOD 2&#x201d; in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. Immediately after the exposure, the image sensor outputs electric charge accumulated during this exposure period. This amount of electric charge is equivalent to the energy Q<b>2</b> of the light received.</p><p id="p-0169" num="0164">Thus, in the example shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, for the acquisition of signals for the foregoing distance calculation, the light source emits light twice, and the image sensor makes exposures at different timings separately in response to each of those beams of light. This makes it possible to acquire a voltage for each exposure period even in a case where two consecutive exposure periods cannot be provided in terms of time. Thus, in an image sensor that outputs electric charge for each exposure period, information on electric charge that is accumulated during each of a plurality of exposure periods set in advance is obtained by emitting light under the same conditions as many times as the number of exposure periods set.</p><p id="p-0170" num="0165">It should be noted that in actual distance measurement, the image sensor may receive not only light emitted from the light source and reflected by an object but also background light, i.e. extraneous light such as sunlight or surround lighting. Accordingly, in general, an exposure period is provided so that accumulated charge generated by background light falling on the image sensor with no light beam being emitted can be measured in the exposure period. By subtracting, from the amount of electric charge that is measured when a reflection of a light beam is received, the amount of electric charge measured in a background exposure period, the amount of electric charge in a case where the only the reflection of the light beam is received can be obtained. For simplicity, the present embodiment omits a description of an operation concerning background light.</p><p id="p-0171" num="0166">Although, in this example, indirect TOF distance measurement is performed, direct TOF distance measurement may alternatively be performed. In a case where direct TOF distance measurement is performed, the light receiving device <b>220</b> includes a sensor including light receiving elements equipped with timer counters and two-dimensionally arranged along a photosensitive surface. The timer counters start measuring time at the start of an exposure and finish measuring time at a point in time where the light receiving elements have received reflected light. In this way, the timer counters measure time separately for each of the light receiving elements to directly measure the time of flight of the light. The processing circuit <b>240</b> calculates a distance from the time of flight thus measured of the light.</p><p id="p-0172" num="0167">In the present embodiment, the imaging apparatus <b>100</b> and the distance measurement apparatus <b>200</b> are separate apparatuses, the functions of the imaging apparatus <b>100</b> and the distance measurement apparatus <b>200</b> may be integrated into one apparatus. For example, it is possible to use the light receiving device <b>220</b> of the distance measurement apparatus <b>200</b> instead of the imaging apparatus <b>100</b> to acquire a luminance image. The light receiving device <b>220</b> may acquire a luminance image without light being emitted from the light emitting device <b>210</b>, or may acquire a luminance image formed by light emitted from the light emitting device <b>210</b>. In a case where the light emitting device <b>210</b> emits the light beam, a luminance image of the whole scene may be generated by storing luminance images of parts of the scene as sequentially acquired by a plurality of the light beams and integrating the luminance images. Alternatively, a luminance image of the whole scene may be generated by making a continuous exposure while sequentially emitting the light beam. The light emitting device <b>210</b> may emit, separately from the light beam, light that diffuses over a wide range, whereby the light receiving device <b>220</b> may acquire a luminance image.</p><heading id="h-0011" level="1">1-1-3. Processing Apparatus</heading><p id="p-0173" num="0168">The processing apparatus <b>300</b> is a computer connected to the imaging apparatus <b>100</b>, the distance measurement apparatus <b>200</b>, and the control apparatus <b>400</b>. The processing apparatus <b>300</b> includes a first storage device <b>320</b>, a second storage device <b>330</b>, a third storage device <b>350</b>, an image processing module <b>310</b>, a risk calculation module <b>340</b>, an own-vehicle movement processing module <b>360</b>, and a surrounding information generation module <b>370</b>. The image processing module <b>310</b>, the risk calculation module <b>340</b>, the own-vehicle movement processing module <b>360</b>, and the surrounding information generation module <b>370</b> may be implemented by one or more processors. By executing a computer program stored on a storage medium, a processor of the processing apparatus <b>300</b> may function as the image processing module <b>310</b>, the risk calculation module <b>340</b>, the own-vehicle movement processing module <b>360</b>, and the surrounding information generation module <b>370</b>.</p><p id="p-0174" num="0169">The image processing module <b>310</b> processes an image outputted by the imaging apparatus <b>100</b>. The first storage device <b>320</b> has stored therein data such as an image acquired by the imaging apparatus <b>100</b> and a processing result generated by the processing apparatus <b>300</b>, with the image and the processing result being associated with each other. The processing result contains, for example, information such as the degree of risk of an object in a scene. The second storage device <b>330</b> has stored therein a predetermined conversion table or function that is used in a process that is executed by the risk calculation module <b>340</b>. The risk calculation module <b>340</b> calculates the degree of risk of an object in a scene with reference to the conversion table or function stored in the second storage device <b>330</b>. The risk calculation module <b>340</b> calculates the degree of risk of an object on the basis of the relative velocity vector and acceleration vector of the object. The own-vehicle movement processing module <b>360</b> generates, on the basis of an image processing result and a risk calculation result stored in the first storage device <b>320</b> and movement information and movement plan information acquired from the movable body and with reference to data stored in the third storage device <b>350</b>, information regarding the movement and processing of the movable body. The surrounding information generation module <b>370</b> generates surrounding information on the basis of an image processing result stored in the first storage device <b>320</b>, a risk calculation result, and information regarding the movement and processing of the movable body.</p><p id="p-0175" num="0170">The image processing module <b>310</b> includes a preprocessing module <b>311</b>, a relative velocity vector module <b>312</b>, and a recognition processing module <b>313</b>. The preprocessing module <b>311</b> performs an initial signal process on image data generated by the imaging apparatus <b>100</b>. The relative velocity vector module <b>312</b> calculates the motion vector of a physical object in a scene on the basis of an image acquired by the imaging apparatus <b>100</b>. The relative velocity vector module <b>312</b> further generates the relative velocity vector of the physical object from the motion vector thus calculated and an apparent motion vector based on own-vehicle movement. The recognition processing module <b>313</b> recognizes one or more physical objects from an image processed by the preprocessing module <b>311</b>.</p><p id="p-0176" num="0171">In the example shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the first storage device <b>320</b>, the second storage device <b>330</b>, and the third storage device <b>350</b> are expressed as three separate storage devices. However, these storage devices <b>320</b>, <b>330</b>, and <b>350</b> may be implemented by a single storage device, or may be implemented by two or four or more storage devices. Further, although, in this example, the processing circuit <b>240</b> and the processing apparatus <b>300</b> are separate from each other, they may be implemented by one apparatus or circuit. Furthermore, the processing circuit <b>240</b> and the processing apparatus <b>300</b> may each be a constituent element of the movable body. The processing circuit <b>240</b> and the processing apparatus <b>300</b> may each be implemented by an aggregate of a plurality of circuits.</p><p id="p-0177" num="0172">The following describes a configuration of the processing apparatus <b>300</b> in more detail.</p><p id="p-0178" num="0173">The preprocessing module <b>311</b> performs signal processes such as noise reduction, edge extraction, and signal enhancement on a series of image data generated by the imaging apparatus <b>100</b>. These signal processes are referred to as &#x201c;preprocessing&#x201d;.</p><p id="p-0179" num="0174">The relative velocity vector <b>312</b> calculates the respective motion vectors of one or more physical objects in a scene on the basis of a series of image data subjected to preprocessing. The relative velocity vector module <b>312</b> calculates a motion victor for each physical object in a scene on the basis of a plurality of images acquired at different points in time within a certain period of time, i.e. a plurality of frames of image at different timings in a moving image. The relative velocity vector module <b>312</b> generates a movement vector based on the movable body that was generated by the own-vehicle movement processing module <b>360</b>. The movement vector based on the movable body is the apparent movement vector of a stationary object that is generated due to the movement of the movable body. The relative velocity vector module <b>312</b> generates a relative velocity vector from the difference between a motion vector calculated for each physical object in a scene and an apparent movement vector based on the movement of the own vehicle. The relative velocity vector may be generated, for example, for each feature point such as a point of inflection on an edge of each physical object.</p><p id="p-0180" num="0175">The recognition processing module <b>313</b> recognizes one or more physical objects from each frame of image processed by the preprocessing module <b>311</b>. This recognition processing may include a process of extracting a movable object such as a vehicle, a person, or a bicycle or a stationary object in a scene, for example, from an image and outputting an area of the image as a rectangular area. As a method of recognition, any method such as machine learning or pattern matching may be used. An algorithm for the recognition processing is not limited to a particular one, but any algorithm may be used. For example, in a case where learning and recognition of a physical object by machine learning are performed, a previously-trained learned model is stored on a storage medium. Applying the learned model to each frame of image data inputted makes it possible to extract a physical object such as a vehicle, a person, or a bicycle.</p><p id="p-0181" num="0176">The storage device <b>320</b> has stored therein a variety of data generated by the imaging apparatus <b>100</b>, the distance measurement apparatus <b>200</b>, and the processing apparatus <b>300</b>. For example, the storage device <b>320</b> has stored therein the following data:</p><p id="p-0182" num="0000">Image data generated by the imaging apparatus <b>100</b>.<br/>Preprocessed image data, data on a relative velocity vector, and data representing a result<br/>of recognition of a physical object; generated by the image processing module <b>310</b>. Data representing a degree of risk for each physical object calculated by the risk calculation module <b>340</b>.<br/>Distance data for each physical object generated by the distance measurement apparatus <b>200</b>.</p><p id="p-0183" num="0177"><figref idref="DRAWINGS">FIGS. <b>8</b>A to <b>8</b>D</figref> are diagrams each showing an example of data that is stored in the first storage device <b>320</b>. In this example, a database is created with reference to frames of moving image acquired by the imaging apparatus <b>100</b> and clusters, generated by the processing apparatus <b>300</b>, each of which indicates an area of a physical object recognized in an image. <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> shows a plurality of frames of moving image generated by the imaging apparatus <b>100</b>. <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> shows a plurality of edge images generated by the preprocessing module <b>311</b> performing preprocessing on the plurality of frames. <figref idref="DRAWINGS">FIG. <b>8</b>C</figref> shows a table of number of each frame, number of image data generated by the imaging apparatus <b>100</b>, number of edge image generated by the preprocessing module <b>311</b>, and number of clusters each representing area of physical object in image. <figref idref="DRAWINGS">FIG. <b>8</b>D</figref> shows a table of number of each frame, identification number of each cluster, coordinates of feature point (such as a point of inflection on an edge) included in each cluster, coordinates of initial and terminal points of relative velocity vector for each feature point, degree of risk calculated for each cluster, distance calculated for each cluster, and ID of physical object recognized.</p><p id="p-0184" num="0178">The storage device <b>330</b> has stored therein a predetermined correspondence table or function for risk calculation and parameters thereof. <figref idref="DRAWINGS">FIGS. <b>9</b>A to <b>9</b>D</figref> are diagrams each showing an example of data that is stored in the storage device <b>330</b>. <figref idref="DRAWINGS">FIG. <b>9</b>A</figref> shows a correspondence table of predicted relative position and degree of risk. <figref idref="DRAWINGS">FIG. <b>9</b>B</figref> shows a correspondence table of rate of acceleration of forward movement during acceleration and during deceleration and degree of risk. <figref idref="DRAWINGS">FIG. <b>9</b>C</figref> shows a correspondence table of rate of acceleration during right turn and degree of risk. <figref idref="DRAWINGS">FIG. <b>9</b>D</figref> shows a correspondence table of rate of acceleration during left turn and degree of risk. The risk calculation module <b>340</b> calculates a degree of risk from the predicted relative position and rate of acceleration of each physical object in a scene with reference to the correspondence relationship between position and degree of risk and the correspondence relationship between rate of acceleration and degree of risk stored in the storage device <b>330</b>. It should be noted that the storage device <b>330</b> may have stored therein in the form of functions as well as in the form of correspondence tables the correspondence relationship between position and degree of risk and the correspondence relationship between rate of acceleration and degree of risk.</p><p id="p-0185" num="0179">The risk calculation module <b>340</b> estimates, according to a relative velocity vector for each edge feature point calculated by the relative velocity vector module <b>312</b>, the predicted relative position of a physical object including an edge feature point. The predicted relative position is a position where the physical object will be present after a predetermined period of time. The predetermined period of time may for example be set to be equal in length of time to an inter-frame spacing. The risk calculation module <b>340</b> determines, on the basis of the correspondence table of predicted relative position and degree of risk stored in the storage device <b>330</b> and the magnitude of the relative velocity vector, a degree of risk corresponding to the predicted relative position thus calculated. Meanwhile, the risk calculation module <b>340</b> calculates the acceleration vector of own-vehicle movement on the basis of a plan of movement of the own vehicle generated by the own-vehicle movement processing module <b>360</b>. In a case where the absolute value of the acceleration vector is greater than a predetermined magnitude, the risk calculation module <b>340</b> calculates a degree of risk entailed in the turning and acceleration/deceleration of the own vehicle. The risk calculation module <b>340</b> obtains an orthogonal component and a straight-forward component of the acceleration vector. In a case where the absolute value of the orthogonal component is greater than a predetermined threshold, the risk calculation module <b>340</b> refers to the correspondence table shown in <figref idref="DRAWINGS">FIG. <b>9</b>C or <b>9</b>D</figref>, extracts a degree of risk concerning a component of the relative velocity vector acting in the direction in which acceleration turns, and combines the degree of risk with the degree of risk determined according to the predicted relative position. On the other hand, in a case where the absolute value of the straight-forward component of the acceleration vector is greater than a predetermined threshold, the risk calculation module <b>340</b> refers to the correspondence table shown in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, extracts a degree of risk concerning the value of a component of the relative velocity vector acting toward the own vehicle, and combines the degree of risk with the degree of risk determined according to the predicted relative position.</p><p id="p-0186" num="0180">The storage device <b>350</b> has stored therein a correspondence table showing a relationship between position of physical object in image and magnitude of apparent motion vector. <figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram showing an example of a correspondence table that is stored in the storage device <b>350</b>. In the example shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the storage device <b>350</b> has stored therein the coordinates of a point corresponding to a vanishing point of a one-point perspective view in an image acquired by the imaging apparatus <b>100</b> and a correspondence table of distance from coordinates to physical object and magnitude of motion vector. Although, in this example, the relationship between distance from vanishing point and magnitude of motion vector is stored in the form of a table, the relationship may be stored in the form of a relational expression.</p><p id="p-0187" num="0181">The own-vehicle movement processing module <b>360</b> acquires, from the control apparatus <b>400</b> of the movable body mounted with the distance measurement system <b>10</b>, movement information on the movement of the movable body made between a preceding frame f<b>0</b> and a current frame f<b>1</b> and movement plan information. The movement information contains information on the velocity or rate of acceleration of the movable body. The movement plan information contains information indicating a future movement of the movable body, e.g. information such as forward movement, a right turn, a left turn, acceleration, or deceleration. The own-vehicle movement processing module <b>360</b> generates, with reference to the data stored in the storage device <b>350</b> and from the movement information thus acquired, an apparent motion vector that is generated by the movement of the movable body. Further, the own-vehicle movement processing module <b>360</b> generates, from the movement plan information thus acquired, the acceleration vector of the own vehicle in a next frame f<b>2</b>. The own-vehicle movement processing module <b>360</b> outputs, to the risk calculation module <b>340</b>, the apparent motion vector thus generated and the acceleration vector thus generated of the own vehicle.</p><p id="p-0188" num="0182">The control apparatus <b>400</b> acquires movement information and movement plan information from a self-guided vehicle system, a navigation system, or other various on-board sensors mounted on board the own vehicle. The other on-board sensors may include a steering sensor, a velocity sensor, an acceleration sensor, a GPS, and a driver monitoring sensor. The movement plane information is for example information that indicates a next movement of the own vehicle that is determined by the self-guided vehicle system. Another example of the movement plan information is information that indicates a next movement of the own vehicle predicted on the basis of a scheduled traveling route acquired from the navigation system and information from the other on-board sensors.</p><heading id="h-0012" level="1">1-2. Operation</heading><p id="p-0189" num="0183">Next, an operation of the distance measurement system <b>10</b> is described in more detail.</p><p id="p-0190" num="0184"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flow chart presenting an overview of an operation of the distance measurement system <b>10</b> according to the present embodiment. The distance measurement system <b>10</b> executes an operation made up of steps S<b>1100</b> to S<b>1900</b> shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. The following describes the action of each step.</p><heading id="h-0013" level="1">Step S<b>1100</b></heading><p id="p-0191" num="0185">The processing apparatus <b>300</b> determines whether an end signal has been inputted from input means, e.g. the control apparatus <b>400</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> or an input device (not illustrated). In a case where an end signal has been inputted, the processing apparatus <b>300</b> ends the operation. In a case where no end signal has been inputted, the operation proceeds to step S<b>1200</b>.</p><heading id="h-0014" level="1">Step S<b>1200</b></heading><p id="p-0192" num="0186">The processing apparatus <b>300</b> instructs the imaging apparatus <b>100</b> to take a two-dimensional image of a scene. The imaging apparatus <b>100</b> generates two-dimensional image data and outputs it to the storage device <b>320</b> of the processing apparatus <b>300</b>. As shown in <figref idref="DRAWINGS">FIG. <b>8</b>C</figref>, the storage device <b>320</b> stores, in association with a frame number, the two-dimensional image data thus acquired.</p><heading id="h-0015" level="1">Step S<b>1300</b></heading><p id="p-0193" num="0187">The preprocessing module <b>311</b> of the processing apparatus <b>300</b> performs preprocessing of the two-dimensional image acquired by the imaging apparatus <b>100</b> and stored in the storage device <b>320</b> in step S<b>1200</b>. The preprocessing includes, for example, a filter noise reduction process, an edge extraction process, and an edge enhancement process. The preprocessing may be a process other than these processes. The preprocessing module <b>311</b> stores a result of the preprocessing in the storage device <b>320</b>. In the examples shown in <figref idref="DRAWINGS">FIGS. <b>8</b>B and <b>8</b>C</figref>, the preprocessing module <b>311</b> generates an edge image by preprocessing. The storage device <b>320</b> stores the edge image in association with the frame number. The preprocessing module <b>311</b> also extracts one or more feature points from an edge in the edge image and stores the feature points in association with the frame number. The feature points may for example be points of inflection on the edge in the edge image.</p><heading id="h-0016" level="1">Step S<b>1400</b></heading><p id="p-0194" num="0188">The relative velocity vector module <b>312</b> of the processing apparatus <b>300</b> generates a relative velocity vector using a most recent frame f<b>1</b> of two-dimensional image processed in step S<b>1300</b> and an immediately preceding frame f<b>0</b> of two-dimensional image processed in step S<b>1300</b>. The relative velocity vector module <b>312</b> performs matching between a feature point set in the most recent frame f<b>1</b> of image and stored in the storage device <b>320</b> and a feature point set in the immediately preceding frame f<b>0</b> of image and stored in the storage device <b>320</b>. For the feature points thus matched, a vector connecting the position of the feature point in the frame f<b>0</b> with the position of the feature point in the frame f<b>1</b> is extracted as a motion vector. The relative velocity vector module <b>312</b> calculates a relative velocity vector by subtracting, from the motion vector, a vector based on own-vehicle movement calculated by the own-vehicle movement processing module <b>360</b>. The relative velocity vector thus calculated is associated with the feature point in the frame f<b>1</b> used for the calculation of the relative velocity vector, and is stored in the storage device <b>320</b> in such a form as to describe the coordinates of the initial and terminal points of the vector. A method for calculating a relative velocity vector will be described in detail later.</p><heading id="h-0017" level="1">Step S<b>1450</b></heading><p id="p-0195" num="0189">The relative velocity vector module <b>312</b> conducts a clustering of a plurality of relative velocity vectors calculated in step S<b>1400</b>. This clustering is based on the directions and magnitudes of the vectors. For example, the relative velocity vector module <b>312</b> conducts the clustering on the basis of the differences between the initial and terminal points of the vectors in an x-axis direction and the differences between the initial and terminal points of the vectors in an y-axis direction. The relative velocity vector module <b>312</b> assigns a number to an extracted cluster and associates the cluster with the current frame f<b>1</b>. As shown in <figref idref="DRAWINGS">FIG. <b>8</b>D</figref>, an extracted cluster is stored in the storage device <b>320</b> in such a form as to be associated with the relative velocity vector of the cluster. Each cluster corresponds to one physical object.</p><heading id="h-0018" level="1">Step S<b>1500</b></heading><p id="p-0196" num="0190">The risk calculation module <b>340</b> of the processing apparatus <b>300</b> calculates a predicted relative position in the next frame f<b>2</b> on the basis of a relative velocity vector stored in the storage device <b>320</b>. The risk calculation module <b>340</b> calculates a degree of risk using a relative velocity vector in the same cluster whose predicted relative position is nearest to the position of the own vehicle. According to the predicted relative position, the risk calculation module <b>340</b> calculates a degree of risk with reference to the storage device <b>330</b>. Meanwhile, the risk calculation module <b>340</b> generates an acceleration vector on the basis of a plan of movement of the own vehicle inputted from the control apparatus <b>400</b> of the movable body and calculates a degree of risk according to the acceleration vector. The risk calculation module <b>340</b> calculates an overall degree of risk of the cluster by integrating the degree of risk calculated on the basis of the predicted relative position and the degree of risk calculated on the basis of the acceleration vector. As shown in <figref idref="DRAWINGS">FIG. <b>8</b>D</figref>, the storage device <b>320</b> stores the degree of risk for each cluster. A method for calculating a degree of risk will be described in detail later.</p><heading id="h-0019" level="1">Step S<b>1600</b></heading><p id="p-0197" num="0191">The control circuit <b>230</b> of the distance measurement apparatus <b>200</b> refers to the storage device <b>320</b> and determines the presence or absence of a distance measurement target according to a degree of risk for each cluster. For example, in a case where there is a cluster whose degree of risk is higher than a threshold, the presence of a distance measurement target is determined. In the absence of a distance measurement target, the operation returns to step S<b>1100</b>. In the presence of one or more distance measurement targets, the operation proceeds to step S<b>1650</b>. For clusters associated with the current frame f<b>1</b>, distance measurement of a cluster, i.e. a physical object, having a relative velocity vector with a high degree of risk is preferentially performed. For example, the processing apparatus <b>300</b> determines, as a distance measurement target, a range of positions in a next frame as predicted from the relative velocity vector of each cluster to be subjected to distance measurement. As distance measurement targets, for example, a given number of clusters may be determined in descending order of degree of risk. Alternatively, a plurality of clusters may be determined in descending order of degree of risk until the proportion of a total of ranges of predicted positions of clusters to a two-dimensional space serving as a range of imaging of the light receiving device <b>220</b> exceeds a certain value.</p><heading id="h-0020" level="1">Step S<b>1650</b></heading><p id="p-0198" num="0192">The control circuit <b>230</b> determines whether distance measurement has been completed for all clusters to be subjected to distance measurement. In a case where distance measurement has not been completed for all clusters to be subjected to distance measurement, the operation proceeds to step S<b>1700</b>. In a case where distance measurement has been completed for all clusters to be subjected to distance measurement, the operation proceeds to step S<b>1800</b>.</p><heading id="h-0021" level="1">Step S<b>1700</b></heading><p id="p-0199" num="0193">The control circuit <b>230</b> executes distance measurement for one of the clusters determined as distance measurement targets in step S<b>1600</b> that is yet to be subjected to distance measurement. For example, of the clusters determined as distance measurement targets and yet to be subjected to distance measurement, a cluster, i.e. a physical object, having the highest degree of risk may be determined as a distance measurement target. The control circuit <b>230</b> sets the direction of emission of the light beam so that a range corresponding to the cluster is illuminated. For example, a direction toward a predicted relative position corresponding to a feature point in the cluster may be set as the direction of emission of the light beam. The control circuit <b>230</b> sets the timing of emission of the light beam from the light emitting device <b>210</b> and the timing of exposure of the light receiving device <b>220</b> and outputs the respective control signals to the light emitting device <b>210</b> and the light receiving device <b>220</b>. Upon receiving the control signal, the light emitting device <b>210</b> emits the light beam in a direction indicated by the control signal. Upon receiving the control signal, the light receiving device <b>220</b> starts an exposure and detects reflected light from the physical object. Each light receiving element of the image sensor of the light receiving device <b>220</b> outputs, to the processing circuit <b>240</b>, a signal indicating electric charge accumulated within each exposure period. The processing circuit <b>240</b> calculates a distance by the aforementioned method for a pixel, included in the range of illumination with the light beam, in which electric charge was accumulated during an exposure period.</p><p id="p-0200" num="0194">The processing circuit <b>240</b> outputs the distance thus calculated to the storage device <b>320</b> in association with a cluster number. As shown in <figref idref="DRAWINGS">FIG. <b>8</b>D</figref>, the storage device <b>320</b> stores a result of distance measurement in such a form that the result of distance measurement is associated with a cluster. After completion of distance measurement and data storage in step S<b>1700</b>, the operation returns to step S<b>1650</b>.</p><p id="p-0201" num="0195"><figref idref="DRAWINGS">FIGS. <b>12</b>A to <b>12</b>C</figref> are diagrams each showing an example of a distance measurement method for each cluster. In the example described above, as shown in <figref idref="DRAWINGS">FIG. <b>12</b>A</figref>, one feature point <b>510</b> is selected for each cluster <b>500</b>, and the light beam is emitted in that direction. In a case where a range corresponding to a cluster <b>500</b> exceeds a range of illumination with a single light beam, a two-dimensional region of each cluster <b>500</b> may be divided into a plurality of partial areas as shown in <figref idref="DRAWINGS">FIG. <b>12</b>B</figref> so that the partial areas may each be separately illuminated with the light beam. Such a method makes it possible to measure distances separately for each of the partial areas. The order in which the partial areas thus divided are each separately illuminated with the light beam may be arbitrarily determined. Alternatively, as shown in <figref idref="DRAWINGS">FIG. <b>12</b>C</figref>, a range corresponding to a two-dimensional region of each cluster <b>500</b> may be scanned with the light beam. A scan direction and a scan trajectory may be arbitrarily determined. Such a method makes it possible to measure a distance for each pixel corresponding to the scan trajectory.</p><heading id="h-0022" level="1">Step S<b>1800</b></heading><p id="p-0202" num="0196">The surrounding information generation module <b>370</b> of the processing apparatus <b>300</b> refers to the storage device <b>320</b> and integrates, for each cluster, a result of image recognition by the recognition processing module <b>313</b> and a distance stored for each cluster. A method for integrating data will be described in detail later.</p><heading id="h-0023" level="1">Step S<b>1900</b></heading><p id="p-0203" num="0197">The surrounding information generation module <b>370</b> converts the data integrated in step S<b>1800</b> into output data and outputs the output data to the control apparatus <b>400</b> of the movable body. The output data will be described in detail later. This output data is referred to as &#x201c;surrounding information&#x201d;. After the data output, the operation returns to step S<b>1100</b>.</p><p id="p-0204" num="0198">By repeating the operation from step S<b>1100</b> to step S<b>1900</b>, the distance measurement system <b>10</b> repeatedly generates information on the surrounding environment that is used for the movable body to move.</p><p id="p-0205" num="0199">The control apparatus <b>400</b> of the movable body executes control of the movable body on the basis of the surrounding information outputted by the distance measurement system <b>10</b>. An example of the control of the movable body is automatically controlling mechanisms such as an engine, a motor, a steering, a brake, and an accelerator of the movable body. The control of the movable body may be providing, to a driver who drives the movable body, information needed for driving or may be alerting the driver. The information may be provided to the driver by an output device, such as a head-up display or a speaker, mounted on board the movable body.</p><p id="p-0206" num="0200">In the example shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the distance measurement system <b>10</b> performs the operation from step S<b>1100</b> to step S<b>1900</b> for each frame that the imaging apparatus <b>100</b> generates. However, the operation of information generation by distance measurement may be performed once per multiple frames. For example, the action of step S<b>1400</b> may be followed by an additional step of determining whether to execute the subsequent actions. For example, distance measurement and generation of surrounding information may be performed only in a case where the rate of acceleration of a physical object is higher than or equal to a predetermined value. More specifically, the processing apparatus <b>300</b> may compare a relative velocity vector in a scene calculated in the current frame f<b>1</b> with a relative velocity vector in a scene calculated for the immediately preceding frame f<b>0</b>. In a case where for all clusters in the frame f<b>1</b>, the difference in magnitude of a relative velocity vector corresponding to the same cluster in the frame f<b>0</b> is smaller than a predetermined value, the operation from step S<b>1450</b> to step S<b>1800</b> may be skipped. In that case, the operation may return to step S<b>1100</b> on the assumption that there is no change in the surrounding situation, or the operation may return to step S<b>1100</b> after only relative velocity vector information has been outputted to the control apparatus <b>400</b> of the movable body.</p><heading id="h-0024" level="1">1-2-1. Calculation of Relative Velocity Vector</heading><p id="p-0207" num="0201">Next, the calculation of a relative velocity vector in step S<b>1400</b> is described in detail.</p><p id="p-0208" num="0202"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flow chart showing details of the action of step S<b>1400</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. Step S<b>1400</b> includes an operation made up of steps S<b>1401</b> to S<b>1408</b> shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. The following describes the action of each step.</p><heading id="h-0025" level="1">Step S<b>1401</b></heading><p id="p-0209" num="0203">The own-vehicle movement processing module <b>360</b> of the processing apparatus <b>300</b> acquires, from the control apparatus <b>400</b> of the movable body, information on the movement of the movable body during a period from the time of acquisition of the immediately preceding frame f<b>0</b> to the time of acquisition of the current frame f<b>1</b>. The information on the movement may contain, for example, the travel speed of the vehicle and information on the direction and distance of movement during the period from the timing of the immediately preceding frame f<b>0</b> to the timing of the current frame f<b>1</b>. Furthermore, the own-vehicle movement processing module <b>360</b> acquires, from the control apparatus <b>400</b>, information indicating a plan of movement of the movable body during a period from the timing of the current frame f<b>1</b> to the timing of the next frame f<b>2</b>, e.g. a control signal to an actuator. The control signal to the actuator may for example be a signal that gives an instruction to perform an action such as acceleration, deceleration, a right turn, or a left turn.</p><heading id="h-0026" level="1">Step S<b>1402</b></heading><p id="p-0210" num="0204">The relative velocity vector module <b>312</b> of the processing apparatus <b>300</b> refers to the storage device <b>320</b> and determines whether a matching process has been completed for all feature points in the immediately preceding frame f<b>0</b> of image and all feature points in the current frame f<b>1</b> of image. In a case where the matching process has been completed for all feature points, the operation proceeds to step S<b>1450</b>. In a case where the matching process has not been completed for all feature points, the operation proceeds to step S<b>1403</b>.</p><heading id="h-0027" level="1">Step S<b>1403</b></heading><p id="p-0211" num="0205">The relative velocity vector module <b>312</b> selects, from among the feature points extracted in the current frame f<b>0</b> of image and stored in the storage device <b>320</b> and the feature points extracted in the current frame f<b>1</b> of image and stored in the storage device <b>320</b>, a point yet to be subjected to the matching process. The selection is preferentially carried out for the feature points in the immediately preceding frame f<b>0</b>.</p><heading id="h-0028" level="1">Step S<b>1404</b></heading><p id="p-0212" num="0206">The relative velocity vector module <b>312</b> performs matching between the feature point selected in step S<b>1403</b> and a feature point in a frame different from the image in which the feature point is included. The relative velocity vector module <b>312</b> determines whether in the period of time from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b>, a physical object having the feature point or the position on a physical object that corresponds to the feature point has gone out of sight of the imaging apparatus <b>100</b>, i.e. the angle of view of the image sensor. In a case where the feature point selected in step S<b>1403</b> is a feature point in the immediately preceding frame f<b>0</b> of image and there is no corresponding feature point among the feature points in the current frame f<b>1</b> of image, the determination is &#x201c;yes&#x201d; in step S<b>1404</b>. That is, in a case where there is no feature point in the current frame f<b>1</b> of image that corresponds to a feature point in the immediately preceding frame f<b>0</b> of image, it is determined that a position corresponding to the feature point has gone out of sight of the imaging apparatus <b>100</b> in the period of time from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b>. In that case, the operation returns to step S<b>1402</b>. On the other hand, in a case where the feature point selected in step S<b>1403</b> is not a feature point in the immediately preceding frame f<b>0</b> of image or in a case where the feature point selected is a feature point in the immediately preceding frame f<b>0</b> of image and there is a corresponding feature point in the current frame f<b>1</b> of image, the operation proceeds to step S<b>1405</b>.</p><heading id="h-0029" level="1">Step S<b>1405</b></heading><p id="p-0213" num="0207">The relative velocity vector module <b>312</b> performs matching between the feature point selected in step S<b>1403</b> and a feature point in a frame different from the image in which the feature point is included. The relative velocity vector module <b>312</b> determines whether in the period of time from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b>, a physical object having the feature point or the position on a physical object that corresponds to the feature point has come into sight of the imaging apparatus <b>100</b> or has come to occupy a discriminably-large area. In a case where the feature point selected in step S<b>1403</b> is a feature point in the current frame f<b>1</b> of image and there is no corresponding feature point in the immediately preceding frame f<b>0</b> of image, the determination is &#x201c;yes&#x201d; in step S<b>1405</b>. That is, in a case where there is no feature point in the immediately preceding frame f<b>0</b> of image that corresponds to a feature point in the current frame f<b>1</b> of image, it is determined that the feature point is a feature point of a physical object having first appeared in sight of the imaging apparatus <b>100</b> in the current frame f<b>1</b>. In that case, the operation returns to step S<b>1402</b>. On the other hand, in the case of successful matching between a feature point in the current frame f<b>1</b> of image and a feature point in the immediately preceding frame f<b>0</b> of image, the operation proceeds to step S<b>1406</b>.</p><heading id="h-0030" level="1">Step S<b>1406</b></heading><p id="p-0214" num="0208">The relative velocity vector module <b>312</b> generates a motion vector for a feature point selected in step S<b>1403</b> and identified as a specific feature point included in the same physical object in both the current and immediately preceding frames f<b>1</b> and f<b>0</b> of image. The motion vector is a vector connecting the position of the feature point in the immediately preceding frame f<b>0</b> of image with the position of the corresponding feature point in the current frame f<b>1</b> of image.</p><p id="p-0215" num="0209"><figref idref="DRAWINGS">FIGS. <b>14</b>A to <b>14</b>C</figref> are diagrams each schematically showing the action of step S<b>1406</b>. <figref idref="DRAWINGS">FIG. <b>14</b>A</figref> is a diagram showing an example of the immediately preceding frame f<b>0</b> of image. <figref idref="DRAWINGS">FIG. <b>14</b>B</figref> is a diagram showing an example of the current frame f<b>1</b> of image. <figref idref="DRAWINGS">FIG. <b>14</b>C</figref> is a diagram with the frames f<b>0</b> and f<b>1</b> of image superimposed on top of each other. Arrows in <figref idref="DRAWINGS">FIG. <b>14</b>C</figref> represent motion vectors. Matching between streetlights, pedestrians, white lines on the road, a vehicle ahead, and a vehicle on an intersecting road in the frame f<b>0</b> of image and corresponding points in the frame f<b>1</b> of image gives motion vectors whose initial points are positioned in the frame f<b>0</b> and whose terminal points are positioned in the frame f<b>1</b>.</p><p id="p-0216" num="0210">The matching process may be performed by a method of template matching typified, for example, by sum of squared difference(SSD) or sum of absolute difference(SAD). In the present embodiment, a figure of an edge including a feature point serves as a template image, and a portion in an image differing less from this template image is extracted. Matching may involve the use of a method other than this.</p><heading id="h-0031" level="1">Step S<b>1407</b></heading><p id="p-0217" num="0211">The relative velocity vector module <b>312</b> generates a motion vector based on own-vehicle movement. The motion vector based on own-vehicle movement represents a relative movement, i.e. apparent movement, of a stationary object as seen from the own vehicle. The relative velocity vector module <b>312</b> generates a motion vector based on own-vehicle movement at the initial point of each motion vector generated in step S<b>1406</b>. The motion vector based on own-vehicle movement is generated on the basis of the information acquired in step S<b>1401</b> on the direction and distance of movement during the period from the timing of the immediately preceding frame f<b>0</b> to the timing of the current frame f<b>1</b> and information on the correspondence relationship between coordinates of vanishing point of motion vector based on own-vehicle movement, distance from vanishing point, and magnitude of vector stored in the storage device <b>350</b> as shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. The motion vector based on own-vehicle movement is a vector pointing in a direction opposite to the direction of movement of the own vehicle. <figref idref="DRAWINGS">FIG. <b>14</b>D</figref> is a diagram showing examples of motion vectors based on own-vehicle movement. A more detailed process in step S<b>1407</b> will be described later.</p><heading id="h-0032" level="1">Step S<b>1408</b></heading><p id="p-0218" num="0212">The relative velocity vector module <b>312</b> generates a relative velocity vector that is the difference between the motion vector of each feature point generated in step S<b>1406</b> and an apparent motion vector based on own-vehicle movement generated in step S<b>1407</b>. The relative velocity vector module <b>312</b> stores, in the storage device <b>320</b>, the coordinates of the initial and terminal points of the relative velocity vector thus generated. As shown in <figref idref="DRAWINGS">FIG. <b>8</b>D</figref>, the relative velocity vector is stored in such a form as to correspond to each feature point in the current frame. <figref idref="DRAWINGS">FIG. <b>14</b>E</figref> shows examples of relative velocity vectors. The relative velocity vectors are generated by subtracting the motion vectors based on own-vehicle movement shown in <figref idref="DRAWINGS">FIG. <b>14</b>D</figref> from the motion vectors shown in <figref idref="DRAWINGS">FIG. <b>14</b>C</figref>. For the streetlights and the white lines, which are standing still, and the pedestrians, who are standing almost still, the relative velocity vectors are substantially 0. On the other hand, for the vehicle ahead and the vehicle on the intersecting road, relative velocity vectors whose lengths are greater than 0 are obtained. In the example shown in <figref idref="DRAWINGS">FIG. <b>14</b>E</figref>, a vector V<b>1</b> generated by subtracting a motion vector based on own-vehicle movement from the motion vector of the vehicle ahead is a vector indicating a direction away from the own vehicle. Meanwhile, a vector V<b>2</b> generated by subtracting an apparent motion vector based on own-vehicle movement from the motion vector of the vehicle on the intersecting road is a vector indicating a direction toward the own vehicle. After step S<b>1408</b>, the operation returns to step S<b>1402</b>.</p><p id="p-0219" num="0213">By repeating the operation from step S<b>1402</b> to step S<b>1408</b>, the processing apparatus <b>300</b> generates relative velocity vectors for all feature points in the frames.</p><p id="p-0220" num="0214"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flow chart showing details of a process for calculating a motion vector based on own-vehicle movement in step S<b>1407</b>. Step S<b>1407</b> includes steps S<b>1471</b> to S<b>1473</b> shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. The following describes the action of each of these steps.</p><heading id="h-0033" level="1">Step S<b>1471</b></heading><p id="p-0221" num="0215">The relative velocity vector module <b>312</b> of the processing apparatus <b>300</b> determines the velocity of the own vehicle from the distance of movement during the period from the timing of the immediately preceding frame f<b>0</b> and the timing of the current frame f<b>1</b> that was acquired in step S<b>1401</b> and a time interval between the frames.</p><heading id="h-0034" level="1">Step S<b>1472</b></heading><p id="p-0222" num="0216">The relative velocity vector module <b>312</b> refers to the storage device <b>350</b> and acquires the coordinates of a vanishing point in an image. The relative velocity vector module <b>312</b> regards the initial point of each motion vector generated in step S<b>1406</b> as the initial point of an apparent motion vector based on own-vehicle movement. In a case where the movable body mounted with the distance measurement system <b>10</b> travels substantially in the direction of the vanishing point, the direction from the vanishing point toward the initial point of the motion vector is regarded as the direction of the apparent motion vector based on own-vehicle movement.</p><p id="p-0223" num="0217"><figref idref="DRAWINGS">FIGS. <b>16</b>A to <b>16</b>D</figref> are diagrams each showing examples of the coordinates of a vanishing point and apparent motion vectors based on own-vehicle movement. <figref idref="DRAWINGS">FIG. <b>16</b>A</figref> shows examples of apparent motion vectors in a case where the distance measurement system <b>10</b> is placed at the front of the movable body and the movable body is traveling forward. <figref idref="DRAWINGS">FIG. <b>16</b>B</figref> shows examples of apparent motion vectors in a case where the distance measurement system <b>10</b> is placed at the right front of the movable body and the movable body is traveling forward. For the examples shown in <figref idref="DRAWINGS">FIGS. <b>16</b>A and <b>16</b>B</figref>, the directions of the apparent motion vectors based on own-vehicle movement are determined by the aforementioned method. <figref idref="DRAWINGS">FIG. <b>16</b>C</figref> shows examples of apparent motion vectors in a case where the distance measurement system <b>10</b> is placed on the right side of the movable body and the movable body is traveling forward. In the example shown in <figref idref="DRAWINGS">FIG. <b>16</b>C</figref>, the path of the movable body mounted with the distance measurement system <b>10</b> is not within the viewing angle of imaging or distance measurement by the distance measurement system <b>10</b> but orthogonal to the line of sight of the distance measurement system <b>10</b>. In such a case, the line of sight of the distance measurement system <b>10</b> is translated along the direction of movement of the movable body. For this reason, a direction opposite to the direction of movement of the movable body is the direction of a motion vector regardless of a vanishing point in the field of view of the distance measurement system <b>10</b>. <figref idref="DRAWINGS">FIG. <b>16</b>D</figref> shows examples of apparent motion vectors in a case where the distance measurement system <b>10</b> is placed at the center rear of the movable body and the movable body is traveling forward. In the example shown in <figref idref="DRAWINGS">FIG. <b>16</b>D</figref>, the direction of travel of the movable body is expressed by a vector pointing in a direction opposite to that in which an example shown in <figref idref="DRAWINGS">FIG. <b>16</b>A</figref> points, and the direction of an apparent motion vector is opposite to that of an example shown in <figref idref="DRAWINGS">FIG. <b>16</b>A</figref>.</p><heading id="h-0035" level="1">Step S<b>1473</b></heading><p id="p-0224" num="0218">The relative velocity vector module <b>312</b> refers to the storage device <b>350</b> and sets the magnitude of the vector according to the distance from the vanishing point to the initial point of the motion vector. Then, the relative velocity vector module <b>312</b> adds a correction according to the velocity of the movable body calculated in step S<b>1471</b> and determines the magnitude of the vector. Through the foregoing process, a motion vector based on own-vehicle movement is determined.</p><heading id="h-0036" level="1">1-2-2. Risk Calculation</heading><p id="p-0225" num="0219">Next, an operation that is performed by the risk calculation module <b>340</b> of the processing apparatus <b>300</b> is described in detail.</p><p id="p-0226" num="0220"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flow chart showing details of a process of risk calculation in step S<b>1500</b>. Step S<b>1500</b> includes steps S<b>1501</b> to S<b>1505</b> shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref>. The following describes the action of each step.</p><heading id="h-0037" level="1">Step S<b>1501</b></heading><p id="p-0227" num="0221">The risk calculation module <b>340</b> refers to the storage device <b>320</b> and determines whether the calculation of a degree of risk has been completed for all clusters generated and associated with the current frame f<b>1</b> in step S<b>1450</b>. In a case where the calculation of a degree of risk has been completed for all clusters, the process proceeds to step S<b>1600</b>. In a case where the calculation of a degree of risk has not been completed for all clusters, the process proceeds to step S<b>1502</b>.</p><heading id="h-0038" level="1">Step S<b>1502</b></heading><p id="p-0228" num="0222">The risk calculation module <b>340</b> selects, from among the clusters associated with the current frame f<b>1</b>, a cluster for which the calculation of a degree of risk has not been completed. The risk calculation module <b>340</b> refers to the storage device <b>320</b> and selects, from among the relative velocity vectors associated with the feature points included in the cluster thus selected and as the relative velocity vector of the cluster, a vector having a terminal point whose coordinates are nearest to the own-vehicle position.</p><heading id="h-0039" level="1">Step S<b>1503</b></heading><p id="p-0229" num="0223">The risk calculation module <b>340</b> resolves the vector selected in step S<b>1502</b> into the following two components. One of the two components is an own-vehicle direction vector component, i.e. a vector component pointing toward the position of the own vehicle or the imaging apparatus <b>100</b>. For example, in an image of a scene generated by the imaging apparatus <b>100</b>, this vector component is a component pointing toward the middle of the lower side of the image. The other of the two components is a vector component orthogonal to a direction toward the own vehicle. The terminal point of a vector twice as great in magnitude as the own-vehicle direction vector component is calculated as a relative position that the feature point in the frame f<b>2</b> following the current frame f<b>1</b> may assume with respect to the own vehicle. Furthermore, the risk calculation module <b>340</b> determines, with reference to the storage device <b>330</b>, a degree of risk corresponding to the relative position, obtained from the relative velocity vector, that the feature point may assume with respect to the own vehicle.</p><p id="p-0230" num="0224"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a diagram for explaining an example of a process of step S<b>1503</b>. The relative positions of feature points with respect to the own vehicle at the timing of the next frame f<b>2</b> are indicated by stars, and the positions are obtained by applying the process of step S<b>1503</b> to the relative velocity vectors shown in <figref idref="DRAWINGS">FIG. <b>14</b>E</figref>. As in the case of this example, the position of a feature point of each cluster, i.e. physical object, in the next frame f<b>2</b> is estimated, and a degree of risk according to the position is determined.</p><heading id="h-0040" level="1">Step S<b>1504</b></heading><p id="p-0231" num="0225">The risk calculation module <b>340</b> calculates, on the basis of the movement plan information acquired in step S<b>1401</b>, calculates a degree of risk according to rate of acceleration. The risk calculation module <b>340</b> refers to the storage device <b>320</b> and generates an acceleration vector from the difference between a relative velocity vector from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b> and a relative velocity vector from the current frame f<b>1</b> to the next frame f<b>2</b>. The risk calculation module <b>340</b> determines a degree of risk according to acceleration vector with reference to the correspondence table of acceleration vector and degree of risk stored in the storage device <b>330</b>.</p><heading id="h-0041" level="1">Step S<b>1505</b></heading><p id="p-0232" num="0226">The risk calculation module <b>340</b> integrates the degree of risk according to predicted position calculated in step S<b>1503</b> and the degree of risk according to rate of acceleration calculated in step S<b>1504</b>. The risk calculation module <b>340</b> calculates an overall degree of risk by multiplying the degree of risk according to predicted position by the degree of risk according to rate of acceleration. After step S<b>1505</b>, the process returns to step S<b>1501</b>.</p><p id="p-0233" num="0227">By repeating the operation from step S<b>1501</b> to step S<b>1505</b>, an overall degree of risk is calculated for all clusters.</p><p id="p-0234" num="0228">Next, a more detailed example of a method for calculating a degree of risk according to rate of acceleration in step S<b>1504</b> is described.</p><p id="p-0235" num="0229"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flow chart showing a detailed example of a method for calculating a degree of risk according to rate of acceleration in step S<b>1504</b>. Step S<b>1504</b> includes steps S<b>1541</b> to S<b>1549</b> shown in <figref idref="DRAWINGS">FIG. <b>19</b></figref>. The following describes the action of each step. It should be noted that the following description assumes that the imaging apparatus <b>100</b> and the distance measurement apparatus <b>200</b> are placed at the front of the vehicle. Examples of processes in cases where the imaging apparatus <b>100</b> and the distance measurement apparatus <b>200</b> are placed at other sites of the vehicle will be described later.</p><heading id="h-0042" level="1">Step S<b>1541</b></heading><p id="p-0236" num="0230">The risk calculation module <b>340</b> calculates the acceleration vector of the own vehicle on the basis of the movement plan information acquired in step S<b>1401</b>. <figref idref="DRAWINGS">FIGS. <b>20</b>A to <b>20</b>C</figref> are diagrams showing an example of a process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward at a constant speed. <figref idref="DRAWINGS">FIGS. <b>21</b>A to <b>21</b>C</figref> are diagrams showing an example of a process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward while accelerating. <figref idref="DRAWINGS">FIGS. <b>22</b>A to <b>22</b>C</figref> are diagrams showing an example of a process for calculating an acceleration vector in a case where the own vehicle is traveling straight forward while decelerating. <figref idref="DRAWINGS">FIGS. <b>23</b>A to <b>23</b>C</figref> are diagrams showing an example of a process for calculating an acceleration vector in a case where the own vehicle turns right. The movement plan information indicates, for example, the movement of the own vehicle during a period from the current frame f<b>1</b> to the next frame f<b>2</b>. A vector corresponding to this movement is a vector whose initial point is at the position of the own vehicle in the current frame f<b>1</b> and whose terminal point is at the predicted position of the own vehicle in the next frame f<b>2</b>. This vector is obtained by a process that is similar to that of step S<b>1503</b>. <figref idref="DRAWINGS">FIGS. <b>20</b>A, <b>21</b>A, <b>22</b>A, and <b>23</b>A</figref> show examples of vectors each indicating the movement of the own vehicle during the period from the current frame f<b>1</b> to the next frame f<b>2</b>. Meanwhile, the movement of the own vehicle during the period from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b> is expressed by a vector whose initial point is at the own-vehicle position and that points toward the coordinates of a vanishing point stored in the storage device <b>350</b>. The magnitude of the vector depends on the distance between the position of the own vehicle and the coordinates of the vanishing point. <figref idref="DRAWINGS">FIGS. <b>20</b>B, <b>21</b>B, <b>22</b>B, and <b>23</b>B</figref> show examples of vectors each indicating the movement of the own vehicle during the period from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b>. The acceleration vector of the own vehicle is obtained by subtracting, from a vector representing the plan of movement of the own vehicle during the period from the current frame f<b>1</b> to the next frame f<b>2</b>, a vector representing the movement of the own vehicle during the period from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b>. <figref idref="DRAWINGS">FIGS. <b>20</b>C, <b>21</b>C, <b>22</b>C, and <b>23</b>C</figref> show examples of acceleration vectors that are calculated. In the example shown in <figref idref="DRAWINGS">FIG. <b>20</b>C</figref>, the acceleration vector is 0, as no rate of acceleration is generated.</p><heading id="h-0043" level="1">Step S<b>1542</b></heading><p id="p-0237" num="0231">The risk calculation module <b>340</b> resolves the acceleration vector of the own vehicle obtained in step S<b>1541</b> into a component acting in the direction of forward movement of the own vehicle and a component acting in an orthogonal direction. The component acting in the direction of forward movement is a component acting in a vertical direction in the drawings, and the component acting in an orthogonal direction is a component acting in a horizontal direction in the drawings. In each of the examples shown in <figref idref="DRAWINGS">FIGS. <b>20</b>C, <b>21</b>C, and <b>22</b>C</figref>, the acceleration vector has only a component acting in the direction of forward movement. In the example shown in <figref idref="DRAWINGS">FIG. <b>23</b>C</figref>, the acceleration vector has both a component acting in the direction of forward movement and a component acting in an orthogonal direction. It is in a case where the movable body changes direction that the acceleration vector has a component acting in an orthogonal direction.</p><heading id="h-0044" level="1">Step S<b>1543</b></heading><p id="p-0238" num="0232">The risk calculation module <b>340</b> determines whether the absolute value of one of the components into which the acceleration vector was resolved in step S<b>1542</b> that acts in an orthogonal direction exceeds a predetermined value Th1. In a case where the magnitude of the component acting in an orthogonal direction exceeds Th1, the process proceeds to step S<b>1544</b>. In a case where the magnitude of the component acting in an orthogonal direction does not exceed Th1, the process proceeds to step S<b>1545</b>.</p><heading id="h-0045" level="1">Step S<b>1544</b></heading><p id="p-0239" num="0233">The risk calculation module <b>340</b> refers to the storage device <b>320</b> and calculates, for the relative velocity vector in the frame f<b>1</b>, the magnitude of a component acting in the same direction as the orthogonal component of the acceleration vector extracted in step S<b>1542</b>. The risk calculation module <b>340</b> refers to the storage device <b>330</b> and determines a degree of risk from the orthogonal component of the acceleration vector.</p><heading id="h-0046" level="1">Step S<b>1545</b></heading><p id="p-0240" num="0234">The risk calculation module <b>340</b> determines whether the absolute value of one of the components into which the acceleration vector was resolved in step S<b>1542</b> that acts in the direction of forward movement falls below a predetermined value Th2. In a case where the magnitude of the component acting in the direction of forward movement is less than Th2, the process proceeds to step S<b>1505</b>. In a case where the magnitude of the component acting in the direction of forward movement is greater than equal to Th2, the process proceeds to step S<b>1546</b>. A state where the magnitude of the component acting in the direction of forward movement is less than a certain value indicates that there is no rapid acceleration or deceleration. A state where the magnitude of the component acting in the direction of forward movement is greater than or equal to a certain value indicates that there is a certain degree of rapid acceleration or deceleration. In this example, a degree of risk according to rate of acceleration is not calculated in the case of poor acceleration or deceleration.</p><heading id="h-0047" level="1">Step S<b>1546</b></heading><p id="p-0241" num="0235">The risk calculation module <b>340</b> refers to the storage device <b>320</b> and calculates, for the relative velocity vector in the current frame f<b>1</b>, the magnitude of a component acting in a direction toward the own vehicle.</p><heading id="h-0048" level="1">Step S<b>1547</b></heading><p id="p-0242" num="0236">The risk calculation module <b>340</b> determines whether one of the components into which the acceleration vector was resolved in step S<b>1542</b> that acts in the direction of forward movement is less than or equal to a predetermined value &#x2212;Th2. In a case where the component acting in the direction of forward movement is less than or equal to &#x2212;Th2, the process proceeds to step S<b>1548</b>. In a case where the component acting in the direction of forward movement is greater than &#x2212;Th2, the process proceeds to step S<b>1549</b>. Note here that Th2 is a positive value. Accordingly, a state where the component of the acceleration vector acting in the direction of forward movement is less than or equal to &#x2212;Th2 shows that there is a certain degree of rapid deceleration.</p><heading id="h-0049" level="1">Step S<b>1548</b></heading><p id="p-0243" num="0237">The risk calculation module <b>340</b> refers to the storage device <b>320</b> and, for a relative velocity vector associated with the frame f<b>1</b>, multiplies the magnitude, calculated in step S<b>1546</b>, of a component acting toward the own vehicle by a coefficient of deceleration. The coefficient of deceleration is a value less than 1, and may be set as a value that is in inverse proportion to the absolute value of the rate of acceleration of forward movement calculated in step S<b>1542</b>. The risk calculation module <b>340</b> refers to the storage device <b>330</b> and determines a degree of risk from the straight-forward component of the acceleration vector.</p><heading id="h-0050" level="1">Step S<b>1549</b></heading><p id="p-0244" num="0238">The risk calculation module <b>340</b> refers to the storage device <b>320</b> and, for a relative velocity vector associated with the frame f<b>1</b>, multiplies the magnitude, calculated in step S<b>1546</b>, of a component acting toward the own vehicle by a coefficient of acceleration. The coefficient of acceleration is a value greater than 1, and may be set as a value that is in proportion to the absolute value of the rate of acceleration of forward movement calculated in step S<b>1542</b>. The risk calculation module <b>340</b> refers to the storage device <b>330</b> and determines a degree of risk from the straight-forward component of the acceleration vector.</p><heading id="h-0051" level="1">1-2-3. Determination of Distance Measurement Target on Basis of Degree of Risk</heading><p id="p-0245" num="0239">Next, a detailed example of an operation of step S<b>1600</b> is described.</p><p id="p-0246" num="0240"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a flow chart showing a detailed example of the operation of step S<b>1600</b>. Step S<b>1600</b> includes steps S<b>1601</b> to S<b>1606</b> shown in <figref idref="DRAWINGS">FIG. <b>24</b></figref>. The following describes the action of each step. The control circuit <b>230</b> of the distance measurement apparatus <b>200</b> determines a distance measurement target in accordance with a degree of risk for each cluster determined in step S<b>1500</b> and determines the presence or absence of a distance measurement target.</p><heading id="h-0052" level="1">Step S<b>1601</b></heading><p id="p-0247" num="0241">The control circuit <b>230</b> determines whether the number of clusters selected exceeds a predetermined value C1. In a case where the number of clusters selected as distance measurement targets exceeds C1, the operation proceeds to step S<b>1650</b>. In a case where the number of clusters selected as distance measurement targets is less than or equal to C1, the operation proceeds to step S<b>1602</b>.</p><heading id="h-0053" level="1">Step S<b>1602</b></heading><p id="p-0248" num="0242">The control circuit <b>230</b> refers to the storage device <b>320</b> and determines whether a determination of a distance measurement target has been completed for all relative velocity vectors of the frame. In a case where a determination of a distance measurement target has been completed for all relative velocity vectors of the frame, the operation proceeds to step S<b>1606</b>. In a case where a determination of a distance measurement target has not been completed for all relative velocity vectors of the frame, the operation proceeds to step S<b>1603</b>.</p><heading id="h-0054" level="1">Step S<b>1603</b></heading><p id="p-0249" num="0243">The control circuit <b>230</b> refers to the storage device <b>320</b> and extracts, from among the relative velocity vectors of the frame, vectors for which a determination of a distance measurement target has not been completed. In this example, a vector with the highest degree of risk is selected from among the vectors for which a determination of a distance measurement target has not been completed.</p><heading id="h-0055" level="1">Step S<b>1604</b></heading><p id="p-0250" num="0244">The control circuit <b>230</b> determines whether the degree of risk of the relative velocity vector selected in step S<b>1603</b> falls below a predetermined standard Th4. In a case where the degree of risk of the vector falls below Th4, the operation proceeds to step S<b>1650</b>. In a case where the degree of risk of the vector is greater than or equal to Th4, the operation proceeds to step S<b>1605</b>.</p><heading id="h-0056" level="1">Step S<b>1605</b></heading><p id="p-0251" num="0245">The control circuit <b>230</b> determines, as a cluster to be subjected to distance measurement, a cluster including the vectors selected in step S<b>1603</b> and determines that a determination of a distance measurement target has been completed for all vectors included in the cluster. After step S<b>1605</b>, the operation proceeds to step S<b>1601</b>.</p><heading id="h-0057" level="1">Step S<b>1606</b></heading><p id="p-0252" num="0246">The control circuit <b>230</b> determines whether one or more clusters to be subjected to distance measurement have been extracted. In a case where no one cluster to be subjected to distance measurement has been extracted, the operation returns to step S<b>1100</b>. In a case where one or more clusters to be subjected to distance measurement have been extracted, the operation proceeds to step S<b>1650</b>.</p><p id="p-0253" num="0247">By repeating steps S<b>1601</b> to S<b>1606</b>, the control circuit <b>230</b> selects all clusters to be subjected to distance measurement. Although, in the present embodiment, the control circuit <b>230</b> executes the operation of step S<b>1600</b>, the processing apparatus <b>300</b> may execute the operation of step S<b>1600</b> in place of the control circuit <b>230</b>.</p><heading id="h-0058" level="1">1-2-4. Distance Measurement</heading><p id="p-0254" num="0248">Next, a specific example of an operation of distance measurement in step S<b>1700</b> is described.</p><p id="p-0255" num="0249"><figref idref="DRAWINGS">FIG. <b>25</b></figref> is a flow chart showing a detailed example of the operation of distance measurement in step S<b>1700</b>. Step S<b>1700</b> includes steps S<b>1701</b> to S<b>1703</b> shown in <figref idref="DRAWINGS">FIG. <b>25</b></figref> The following describes the action of each step. For a cluster determined as a distance measurement target in step S<b>1600</b>, the control circuit <b>230</b> determines the direction of emission of the light beam on the basis of positional information in the next frame f<b>2</b> that is predicted from relative velocity vectors within the cluster, and performs distance measurement.</p><heading id="h-0059" level="1">Step S<b>1701</b></heading><p id="p-0256" num="0250">The control circuit <b>230</b> selects, from among the clusters selected in step S<b>1600</b>, a cluster yet to be subjected to distance measurement.</p><heading id="h-0060" level="1">Step S<b>1702</b></heading><p id="p-0257" num="0251">The control circuit <b>230</b> refers to the storage device <b>320</b> and extracts a predetermined number of relative velocity vectors, e.g. not more than five relative velocity vectors, from among one or more relative velocity vectors corresponding to the cluster selected in step S<b>1701</b>. As a standard of extraction, for example, five relative velocity vectors that include a relative velocity vector with the highest degree of risk and whose terminal points are furthest away from one another may be selected.</p><heading id="h-0061" level="1">Step S<b>1703</b></heading><p id="p-0258" num="0252">As shown in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, as in the case of the risk calculation process of step S<b>1503</b> shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref>, for a relative velocity vector selected in step S<b>1702</b>, the control circuit <b>230</b> identifies, as the predicted position of the physical object, the position of the terminal point of a vector twice as great in magnitude as an own-vehicle direction component of the relative velocity vector. The control circuit <b>230</b> determines the direction of emission of the light beam so that the predicted position in the next frame f<b>2</b> thus identified is illuminated with the light beam.</p><heading id="h-0062" level="1">Step S<b>1704</b></heading><p id="p-0259" num="0253">The control circuit <b>230</b> outputs, to the light emitting device <b>210</b> and the light receiving device <b>220</b>, controls signals that control, for example, the direction of emission of the light beam determined in step S<b>1703</b>, the timing of emission, the timing of exposure of the light receiving device <b>220</b>, and the timing of data readout. Upon receiving the control signal, the light emitting device <b>210</b> emits the light beam. Upon receiving the control signal, the light receiving device <b>220</b> performs exposures and data output. Upon receiving a signal indicating a result of detection by the light receiving device <b>220</b>, the processing circuit <b>240</b> calculates a distance to the physical object by the aforementioned method.</p><heading id="h-0063" level="1">1-2-5. Data Integration and Output</heading><p id="p-0260" num="0254">Next, a specific example of a data integration process in step S<b>1800</b> is described.</p><p id="p-0261" num="0255"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a flow chart showing a detailed example of the data integration process in step S<b>1800</b>. Step S<b>1800</b> includes steps S<b>1801</b> to S<b>1804</b> shown in <figref idref="DRAWINGS">FIG. <b>26</b></figref>. The following describes the action of each step. The surrounding information generation module <b>370</b> of the processing apparatus <b>300</b> integrates data representing an area of a cluster indicating a physical object, a distance distribution within the cluster, and a result of recognition processing and outputs the data to the control apparatus <b>400</b>.</p><heading id="h-0064" level="1">Step S<b>1801</b></heading><p id="p-0262" num="0256">The surrounding information generation module <b>370</b> refers to the storage device <b>320</b> and extracts, from the data shown in <figref idref="DRAWINGS">FIG. <b>8</b>D</figref>, a cluster subjected to distance measurement in step S<b>1700</b>.</p><heading id="h-0065" level="1">Step S<b>1802</b></heading><p id="p-0263" num="0257">The surrounding information generation module <b>370</b> refers to the storage device <b>320</b> and extracts, from the data shown in <figref idref="DRAWINGS">FIG. <b>8</b>D</figref>, a result of image recognition corresponding to the cluster extracted in step S<b>1801</b>.</p><heading id="h-0066" level="1">Step S<b>1803</b></heading><p id="p-0264" num="0258">The surrounding information generation module <b>370</b> refers to the storage device <b>320</b> and extracts, from the data shown in <figref idref="DRAWINGS">FIG. <b>8</b>D</figref>, a distance corresponding to the cluster extracted in step S<b>1801</b>. At this point in time, information on a distance, measured in step S<b>1700</b>, that corresponds to one or more relative velocity vectors within the cluster is extracted. In the case of a different distance for each relative velocity vector, the shortest distance may for example be adopted as the distance of the cluster. Alternatively, a representative value other than the minimum value, such the average or median of the plurality of distances, may be used as the distance of the cluster.</p><heading id="h-0067" level="1">Step S<b>1804</b></heading><p id="p-0265" num="0259">On the basis of information on the position and angle of view of the image sensor stored in advance in the storage device <b>350</b>, the surrounding information generation module <b>370</b> converts, into data expressed in a coordinate system of the movable body mounted with the distance measurement system <b>10</b>, coordinate data representing an area of the cluster extracted in step S<b>1801</b> and the distance data determined in step S<b>1803</b>. <figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram showing an example of a coordinate system of the movable body. The coordinate system of the movable body in this example is a three-dimensional coordinate system that is expressed by a horizontal angle, a height, and a distance from the origin in a horizontal direction with the center of the movable body being the origin and the front of the movable body being at 0 degree. On the other hand, for example, as shown in <figref idref="DRAWINGS">FIG. <b>27</b></figref> as a coordinate system having its origin at the right front of the movable body, a coordinate system of the distance measurement system <b>10</b> is a three-dimensional coordinate system constituted by an x-y coordinate and a distance. On the basis of the information on the position and angle of view of the sensor stored in the storage device <b>350</b>, the surrounding information generation module <b>370</b> converts, into data expressed by the coordinate system of the movable body, data on a cluster range and a distance stored in the coordinate system of the distance measurement system <b>10</b>.</p><p id="p-0266" num="0260"><figref idref="DRAWINGS">FIG. <b>28</b>A</figref> is a diagram showing an example of output data that is generated by the processing apparatus <b>300</b>. The output data in this example is data associating an area of each cluster with a distance, a result of recognition, and a degree of risk. The processing apparatus <b>300</b> generates such data and outputs it to the control apparatus <b>400</b> of the movable body. <figref idref="DRAWINGS">FIG. <b>28</b>B</figref> is a diagram showing another example of output data. In this example, codes are assigned to contents of recognition, and the processing apparatus <b>300</b> adds a correspondence table of code and content of recognition to the beginning of the data and generates data in such a manner as to store only a code as a content of recognition in data for each cluster. Alternatively, in a case where a correspondence table of result of recognition and code is retained in advance in a storage device of the movable body, the processing apparatus <b>300</b> may output only a code serving as a result of recognition.</p><heading id="h-0068" level="1">1-3. Effects</heading><p id="p-0267" num="0261">As noted above, a distance measurement system <b>10</b> of the present embodiment includes an imaging apparatus <b>100</b>, a distance measurement apparatus <b>200</b>, and a processing apparatus <b>300</b>. The distance measurement apparatus <b>200</b> includes a light emitting device <b>210</b> capable of changing a direction of emission of a light beam along a horizontal direction and a vertical direction, a light receiving device <b>220</b> including an image sensor, a control circuit <b>230</b>, and a processing circuit <b>240</b>. The processing apparatus <b>300</b> generates a motion vector of one or more physical objects in a scene from a plurality of two-dimensional luminance images acquired by the imaging apparatus <b>100</b> taking a series of consecutive shots. The processing apparatus <b>300</b> calculates a degree of risk of the physical object on the basis of the motion vector and own-vehicle movement information acquired from the movable body including the distance measurement system <b>10</b>. The control circuit <b>230</b> selects, on the basis of the degree of risk calculated by the processing apparatus <b>300</b>, a physical object to be subjected to distance measurement. By emitting the light beam in a direction toward the physical object thus selected, the distance measurement apparatus <b>200</b> measures a distance to the physical object. The processing apparatus <b>300</b> outputs, to the control apparatus <b>400</b> of the movable body, data containing information on a range of coordinates of the physical object and a distance to the physical object.</p><p id="p-0268" num="0262">The foregoing configuration makes it possible to select, in a scene to be subjected to distance measurement by the distance measurement system <b>10</b>, a physical object having a high degree of risk such as collision and measure the distance to the physical object. This makes it possible, with a few distance measurement actions, acquire distance information that is effective in risk avoidance.</p><heading id="h-0069" level="1">1-4. Modifications</heading><p id="p-0269" num="0263">Although, in Embodiment 1, the distance measurement system <b>10</b> includes an imaging apparatus <b>100</b> that acquires a luminance image, a distance measurement apparatus <b>200</b> that performs distance measurement, and a processing apparatus <b>300</b> that calculates a degree of risk, the present disclosure is not limited to such a configuration. For example, the processing apparatus <b>300</b> may be a constituent element of a movable body including the distance measurement system <b>10</b>. In that case, the distance measurement system <b>10</b> includes an imaging apparatus <b>100</b> and a distance measurement apparatus <b>200</b>. The imaging apparatus <b>100</b> acquires an image and outputs it to the processing apparatus <b>300</b> of the movable body. The processing apparatus <b>300</b> calculates, on the basis of the image acquired from the imaging apparatus <b>100</b>, a degree of risk of one or more physical objects in the image, identifies a physical object to be subjected to distance measurement, and outputs, to the distance measurement apparatus <b>200</b>, information indicating a predicted position of the physical object. The control circuit <b>230</b> of the distance measurement apparatus <b>200</b> controls the light emitting device <b>210</b> and the light receiving device <b>220</b> on the basis of the information on the predicted position of the physical object acquired from the processing apparatus <b>300</b>. The control circuit <b>230</b> outputs, to the light emitting device <b>210</b>, a control signal that controls the direction and timing of emission of a light beam, and outputs, to the light receiving device <b>220</b>, a control signal that controls the timing of exposure. The light emitting device <b>210</b> emits the light beam in a direction toward the physical object in accordance with the control signal. The light receiving device <b>220</b> makes exposures for each separate pixel in accordance with the control signal and outputs, to the processing circuit <b>240</b>, a signal indicating electric charge accumulated during each exposure period. The processing circuit <b>240</b> generates distance information on the physical object by calculating distances for each separate pixel on the basis of the signal.</p><p id="p-0270" num="0264">The functions of the processing apparatus <b>300</b> and the control circuit <b>230</b> and processing circuit <b>240</b> of the distance measurement apparatus <b>200</b> may be integrated into a processing apparatus (e.g. the aforementioned control apparatus <b>400</b>) of the movable body. In that case, the distance measurement system <b>10</b> includes an imaging apparatus <b>100</b>, a light emitting device <b>210</b>, and a light receiving device <b>220</b>. The imaging apparatus <b>100</b> acquires an image and outputs it to the processing apparatus of the movable body. The processing apparatus of the movable body calculates, on the basis of the image acquired from the imaging apparatus <b>100</b>, a degree of risk of one or more physical objects in the image, identifies a physical object to be subjected to distance measurement, and controls the light emitting device <b>210</b> and the light receiving device <b>220</b> so that the physical object is subjected to distance measurement. The processing apparatus outputs, to the light emitting device <b>210</b>, a control signal that controls the direction and timing of emission of a light beam, and outputs, to the light receiving device <b>220</b>, a control signal that controls the timing of exposure. The light emitting device <b>210</b> emits the light beam in a direction toward the physical object in accordance with the control signal. The light receiving device <b>220</b> makes exposures for each separate pixel in accordance with the control signal and outputs, to the processing apparatus of the movable body, a signal indicating electric charge accumulated during each exposure period. The processing apparatus generates distance information on the physical object by calculating distances for each separate pixel on the basis of the signal.</p><p id="p-0271" num="0265">In Embodiment 1, the operation from step S<b>1100</b> to S<b>1900</b> shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref> is executed for each of frames that the imaging apparatus <b>100</b> consecutively generates. However, it is not necessary to execute all of the operation from step S<b>1100</b> to S<b>1900</b> in all frames. For example, a physical object determined as a distance measurement target in step S<b>1600</b> may continue to be a distance measurement target in a subsequent frame without making, on the basis of an image acquired from the imaging apparatus <b>100</b>, a determination as to whether the physical object is a distance measurement target. In other words, a physical object once determined as a distance measurement target may be stored as a target of tracking in a subsequent frame, and the process from step S<b>1400</b> to step S<b>1600</b> may be skipped. In this case, the end of tracking may be determined, for example, according to the following conditions:</p><p id="p-0272" num="0000">Case where the physical object has gone out of the angle of view of the imaging apparatus <b>100</b>, or<br/>Case where a measured distance to the physical object has exceeded a predetermined value.</p><p id="p-0273" num="0266">The tracking may be refreshed every two or more predetermined fames. Alternatively, in a case where the rate of acceleration of forward movement is greater than the threshold Th1 in step S<b>1543</b> shown in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the tracking may be refreshed by calculating a degree of risk for a cluster to be tracked.</p><p id="p-0274" num="0267">Embodiment 1 has been described with a focus on a case where the distance measurement system <b>10</b> is installed at the center front of the movable body. The following describes examples of the process of relative velocity vector calculation in step S<b>1400</b> in a case where the distance measurement system <b>10</b> is installed at the right front of the movable body, a case where the distance measurement system <b>10</b> is installed on the right side of the movable body, and a case where the distance measurement system <b>10</b> is installed at the center rear of the movable body.</p><p id="p-0275" num="0268"><figref idref="DRAWINGS">FIGS. <b>29</b>A to <b>29</b>E</figref> are diagrams each schematically showing an example of a scene on which the distance measurement system <b>10</b> performs imaging and distance measurement in a case where the distance measurement system <b>10</b> is installed at the right front of the movable body. <figref idref="DRAWINGS">FIG. <b>29</b>A</figref> is a diagram showing an example of an immediately preceding frame f<b>0</b> of image. <figref idref="DRAWINGS">FIG. <b>29</b>B</figref> is a diagram showing an example of a current frame f<b>1</b> of image. <figref idref="DRAWINGS">FIG. <b>29</b>C</figref> is a diagram with the frames f<b>0</b> and f<b>1</b> of image superimposed on top of each other. Arrows in <figref idref="DRAWINGS">FIG. <b>29</b>C</figref> represent motion vectors. <figref idref="DRAWINGS">FIG. <b>29</b>D</figref> is a diagram showing examples of motion vectors based on own-vehicle movement. <figref idref="DRAWINGS">FIG. <b>29</b>E</figref> is a diagram showing examples of relative velocity vectors. The processing apparatus <b>300</b> generates a relative velocity vector using a current frame f<b>1</b> of two-dimensional image processed in step S<b>1300</b> and an immediately preceding frame f<b>0</b> of two-dimensional image processed in step S<b>1300</b>. The processing apparatus <b>300</b> performs matching between a feature point in the current frame f<b>1</b> and a feature point in the immediately preceding frame f<b>0</b>. For the feature points thus matched, as illustrated in <figref idref="DRAWINGS">FIG. <b>29</b>C</figref>, a motion vector connecting the position of the feature point in the frame f<b>0</b> with the position of the feature point in the frame f<b>1</b> is generated. The processing apparatus <b>300</b> calculates a relative velocity vector by subtracting, from the motion vector thus generated, a vector based on own-vehicle movement shown in <figref idref="DRAWINGS">FIG. <b>29</b>D</figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>29</b>E</figref>, the relative velocity vector is associated with the feature point in the frame f<b>1</b> used for the calculation of the relative velocity vector, and is stored in the storage device <b>320</b> in such a form as to describe the coordinates of the initial and terminal points of the vector. <figref idref="DRAWINGS">FIG. <b>30</b></figref> is a diagram showing an example of a predicted relative position of a physical object in a scene in a case where the distance measurement system <b>10</b> is installed at the right front of the movable body. As in the case of the example shown in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, the processing apparatus <b>300</b> identifies the position of the terminal point of a vector twice as great in magnitude as an own-vehicle direction component of the relative velocity vector. The processing apparatus <b>300</b> identifies the position of the terminal point as a predicted relative position in the next frame f<b>2</b> and determines the direction of emission so that the position is illuminated with the light beam.</p><p id="p-0276" num="0269"><figref idref="DRAWINGS">FIGS. <b>31</b>A to <b>31</b>E</figref> are diagrams each schematically showing an example of a scene on which the distance measurement system <b>10</b> performs imaging and distance measurement in a case where the distance measurement system <b>10</b> is installed on the right side of the movable body. <figref idref="DRAWINGS">FIG. <b>31</b>A</figref> is a diagram showing an example of an immediately preceding frame f<b>0</b> of image. <figref idref="DRAWINGS">FIG. <b>31</b>B</figref> is a diagram showing an example of a current frame f<b>1</b> of image. <figref idref="DRAWINGS">FIG. <b>31</b>C</figref> is a diagram with the frames f<b>0</b> and f<b>1</b> of image superimposed on top of each other. Arrows in <figref idref="DRAWINGS">FIG. <b>31</b>C</figref> represent motion vectors. <figref idref="DRAWINGS">FIG. <b>31</b>D</figref> is a diagram showing examples of motion vectors based on own-vehicle movement. <figref idref="DRAWINGS">FIG. <b>31</b>E</figref> is a diagram showing an example of a relative velocity vector. In this example too, the processing apparatus <b>300</b> generates a relative velocity vector using a current frame f<b>1</b> of two-dimensional image and an immediately preceding frame f<b>0</b> of two-dimensional image. The processing apparatus <b>300</b> performs matching between a feature point in the current frame f<b>1</b> and a feature point in the immediately preceding frame f<b>0</b>. For the feature points thus matched, as illustrated in <figref idref="DRAWINGS">FIG. <b>31</b>C</figref>, a motion vector connecting the position of the feature point in the frame f<b>0</b> with the position of the feature point in the frame f<b>1</b> is generated. The processing apparatus <b>300</b> calculates a relative velocity vector by subtracting, from the motion vector thus generated, a vector based on own-vehicle movement shown in <figref idref="DRAWINGS">FIG. <b>31</b>D</figref>. In the example shown in <figref idref="DRAWINGS">FIG. <b>31</b>E</figref>, when associated with the feature point in the frame f<b>1</b>, the relative velocity vector thus calculated becomes so great as to go beyond the right edge of the scene. For this reason, the predicted position in the next frame f<b>2</b> based on the relative velocity vector is out of the angle of view of the distance measurement system <b>10</b>. For this reason, the object corresponding to the feature point is not a target of illumination in the next frame f<b>2</b>. Further, the relative velocity vector shown in <figref idref="DRAWINGS">FIG. <b>31</b>E</figref> is parallel to the vector based on own-vehicle movement and has no own-vehicle direction component. Therefore, the own-vehicle direction predicted relative position in the next frame f<b>2</b> is the same as that in the current frame f<b>1</b>, so that there is no increase in degree of risk.</p><p id="p-0277" num="0270"><figref idref="DRAWINGS">FIGS. <b>32</b>A to <b>32</b>E</figref> are diagrams each schematically showing an example of a scene on which the distance measurement system <b>10</b> performs imaging and distance measurement in a case where the distance measurement system <b>10</b> is installed at the center rear of the movable body. <figref idref="DRAWINGS">FIG. <b>32</b>A</figref> is a diagram showing an example of an immediately preceding frame f<b>0</b> of image. <figref idref="DRAWINGS">FIG. <b>32</b>B</figref> is a diagram showing an example of a current frame f<b>1</b> of image. <figref idref="DRAWINGS">FIG. <b>32</b>C</figref> is a diagram with the frames f<b>0</b> and f<b>1</b> of image superimposed on top of each other. Arrows in <figref idref="DRAWINGS">FIG. <b>32</b>C</figref> represent motion vectors. <figref idref="DRAWINGS">FIG. <b>32</b>D</figref> is a diagram showing examples of motion vectors based on own-vehicle movement. <figref idref="DRAWINGS">FIG. <b>32</b>E</figref> is a diagram showing examples of relative velocity vectors. In this example too, the processing apparatus <b>300</b> generates a relative velocity vector using a current frame f<b>1</b> of two-dimensional image and an immediately preceding frame f<b>0</b> of two-dimensional image. The processing apparatus <b>300</b> performs matching between a feature point in the current frame f<b>1</b> and a feature point in the immediately preceding frame f<b>0</b>. For the feature points thus matched, as illustrated in <figref idref="DRAWINGS">FIG. <b>32</b>C</figref>, a motion vector connecting the position of the feature point in the frame f<b>0</b> with the position of the feature point in the frame f<b>1</b> is generated. The processing apparatus <b>300</b> calculates a relative velocity vector by subtracting, from the motion vector thus generated, a vector based on own-vehicle movement shown in <figref idref="DRAWINGS">FIG. <b>32</b>D</figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>32</b>E</figref>, the relative velocity vector is associated with the feature point in the frame f<b>1</b> used for the calculation of the relative velocity vector, and is stored in the storage device <b>320</b> in such a form as to describe the coordinates of the initial and terminal points of the vector. <figref idref="DRAWINGS">FIG. <b>33</b></figref> is a diagram showing an example of a predicted relative position of a physical object in a scene in a case where the distance measurement system <b>10</b> is installed at the center rear of the movable body. As in the case of the example shown in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, the processing apparatus <b>300</b> identifies the position of the terminal point of a vector twice as great in magnitude as an own-vehicle direction component of the relative velocity vector. The processing apparatus <b>300</b> identifies the position of the terminal point as a predicted relative position in the next frame f<b>2</b> and determines the direction of emission so that the position is illuminated with the light beam.</p><p id="p-0278" num="0271">The following describes examples of the process for calculating a degree of risk according to rate of acceleration in step S<b>1504</b> shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref> in a case where the distance measurement system <b>10</b> is installed at the right front of the movable body, a case where the distance measurement system <b>10</b> is installed on the right side of the movable body, and a case where the distance measurement system <b>10</b> is installed at the center rear of the movable body.</p><p id="p-0279" num="0272"><figref idref="DRAWINGS">FIGS. <b>34</b>A to <b>34</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed at the right front of the movable body and the own vehicle is traveling straight forward while accelerating. <figref idref="DRAWINGS">FIGS. <b>35</b>A to <b>35</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed at the right front of the movable body and the own vehicle is traveling straight forward while decelerating. <figref idref="DRAWINGS">FIGS. <b>36</b>A to <b>36</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed at the right front of the movable body and the own vehicle turns right while decelerating.</p><p id="p-0280" num="0273"><figref idref="DRAWINGS">FIGS. <b>37</b>A to <b>37</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed on the right side of the movable body and the own vehicle is traveling straight forward while accelerating. <figref idref="DRAWINGS">FIGS. <b>38</b>A to <b>38</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed on the right side of the movable body and the own vehicle is traveling straight forward while decelerating. <figref idref="DRAWINGS">FIGS. <b>39</b>A to <b>39</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed on the right side of the movable body and the own vehicle turns right while decelerating.</p><p id="p-0281" num="0274"><figref idref="DRAWINGS">FIGS. <b>40</b>A to <b>40</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed at the center rear of the movable body and the own vehicle is traveling straight forward while accelerating. <figref idref="DRAWINGS">FIGS. <b>41</b>A to <b>41</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed at the center rear of the movable body and the own vehicle is traveling straight forward while decelerating. <figref idref="DRAWINGS">FIGS. <b>42</b>A to <b>42</b>C</figref> are diagrams each showing an example of a process for calculating an acceleration vector in a case where the distance measurement system <b>10</b> is installed at the center rear of the movable body and the own vehicle turns right while decelerating.</p><p id="p-0282" num="0275">In each of these examples, the processing apparatus <b>300</b> calculates, on the basis of the movement plan information acquired in step S<b>1401</b>, a degree of risk according to rate of acceleration. The processing apparatus <b>300</b> refers to the storage device <b>320</b>, obtains the difference between a vector representing the movement of the own vehicle during the period from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b> and a vector representing the movement of the own vehicle during the period from the current frame f<b>1</b> to the next frame f<b>2</b>, and generates an acceleration vector. <figref idref="DRAWINGS">FIGS. <b>34</b>B, <b>35</b>B, <b>36</b>B, <b>37</b>B, <b>38</b>B, <b>39</b>B, <b>40</b>B, <b>41</b>B, and <b>42</b>B</figref> show examples of vectors each indicating the movement of the own vehicle during the period from the immediately preceding frame f<b>0</b> to the current frame f<b>1</b>. <figref idref="DRAWINGS">FIGS. <b>34</b>A, <b>35</b>A, <b>36</b>A, <b>37</b>A, <b>38</b>A, <b>39</b>A, <b>40</b>A, <b>41</b>A, and <b>42</b>A</figref> show examples of vectors each indicating the movement of the own vehicle during the period from the current frame f<b>1</b> to the next frame f<b>2</b>. <figref idref="DRAWINGS">FIGS. <b>34</b>C, <b>35</b>C, <b>36</b>C, <b>37</b>C, <b>38</b>C, <b>39</b>C, <b>40</b>C, <b>41</b>C, and <b>42</b>C</figref> show examples of acceleration vectors that are generated. The processing apparatus <b>300</b> determines a degree of risk according to acceleration vector with reference to the correspondence table of acceleration vector and degree of risk stored in the storage device <b>330</b>. It should be noted that in a case where the distance measurement system <b>10</b> is situated at the rear of the movable body, the relationship between rate of acceleration of forward movement and degree of risk shown in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref> is inverted. In a case where the distance measurement system <b>10</b> is situated at the rear of the movable body, a correspondence table in which the sign of a rate of acceleration of forward movement in a case where the distance measurement system <b>10</b> is situated at the front of the movable body is inverted, or the processing apparatus <b>300</b> may obtain a degree of risk by inverting the sign of a rate of acceleration of forward movement.</p><p id="p-0283" num="0276">In the foregoing embodiment, the processing apparatus <b>300</b> obtains a relative velocity vector and a relative position with respect to a physical object on the basis of a plurality of images acquired at different times by the imaging apparatus <b>100</b>. Furthermore, the processing apparatus <b>300</b> obtains the rate of acceleration of the movable body on the basis of a plan of movement of the movable body including the distance measurement system <b>10</b> and determines the degree of risk of a physical object on the basis of the rate of acceleration. The distance measurement apparatus measures distances to physical objects in priority order of decreasing degree of risk. In order to measure a distance for each physical object, the distance measurement apparatus <b>200</b> configures the settings so that the light emitting device <b>210</b> emits the light beam in a direction toward each physical object.</p><p id="p-0284" num="0277">In the foregoing operation, the distance measurement apparatus <b>200</b> may determine the numbers of occurrences of emission of the light beam and exposure during the distance measurement operation according to how high the degree of risk is. Alternatively, the distance measurement apparatus <b>200</b> may determine the time length of emission of the light beam and the time length of exposure during the distance measurement operation according to how high the degree of risk is. Such an operation makes it possible to adjust the accuracy of distance measurement or the distance range on the basis of the degree of risk.</p><p id="p-0285" num="0278"><figref idref="DRAWINGS">FIG. <b>43</b></figref> is a block diagram showing an example configuration of the distance measurement apparatus <b>200</b> for achieving the foregoing operation. In this example, the distance measurement apparatus <b>200</b> includes a storage device <b>250</b> in addition to the constituent elements shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The storage device <b>250</b> has stored therein data defining a correspondence relationship between numbers of occurrences of emission of light beam and exposure and time lengths of emission of light beam and exposure according to degree of risk for each cluster, i.e. physical object, determined by the processing apparatus <b>300</b>.</p><p id="p-0286" num="0279">The control circuit <b>230</b> refers to the storage device <b>250</b> and determines, according to a degree of risk calculated by the processing apparatus <b>300</b>, the time length of the light beam that the light emitting device <b>210</b> emits and the number of occurrences of emission. Furthermore, the control circuit <b>230</b> determines the time length of exposure of the light receiving device <b>220</b> and the number of occurrences of exposure according to the degree of risk. With this, the control circuit <b>230</b> controls the operation of distance measurement and adjusts the accuracy of distance measurement and the distance range.</p><p id="p-0287" num="0280"><figref idref="DRAWINGS">FIG. <b>44</b></figref> is a diagram showing an example of data that is stored by the storage device <b>250</b>. In the example shown in <figref idref="DRAWINGS">FIG. <b>44</b></figref>, a correspondence table of range of degrees of risk, distance range, and accuracy is stored. Instead of the correspondence table, the storage device <b>250</b> may have stored therein a function for determining a distance range or accuracy from a degree of risk. Adjustment of the distance range can be achieved by adjusting the time length T<b>0</b> of a light pulse and each exposure period in distance measurement based on an indirect TOF method illustrated, for example, in <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref>. The longer T<b>0</b> is made, the more the measurable distance range can be extended. Further, the measurable distance range can be shifted by adjusting the timing of the exposure period 1 shown in (c) of <figref idref="DRAWINGS">FIG. <b>6</b></figref> and the timing of the exposure period 2 shown in (d) of <figref idref="DRAWINGS">FIG. <b>6</b></figref>. For example, the measurable distance range can be shifted toward a long-distance side by making the exposure period 1 later than the start of light emission instead of starting the exposure period 1 at the same time as the start of light emission. Note, however, that in this case, it is impossible to perform raging at such a short distance that the reflected light reaches the light receiving device <b>220</b> before the start of the exposure period 1. Even in a case where the start of the exposure period 1 is delayed, the time lengths of the exposure period 1 and the exposure period 2 are equal to the time length of light emission, and the exposure period 2 starts at the same time as the exposure period 1 ends. Further, the accuracy of distance measurement depends of the number or occurrences of distance measurement. Errors in distance measurement can reduced by a process of, for example, averaging results of more than one occurrence of distance measurement. By making the number of occurrences larger as the degree of risk becomes higher, the accuracy of distance measurement of a dangerous vehicle can be improved.</p><p id="p-0288" num="0281">In the aforementioned embodiment, as shown in <figref idref="DRAWINGS">FIG. <b>8</b>D</figref>, the storage device <b>320</b> has stored therein only the overall degree of risk obtained by integrating the degree of risk according to predicted relative position calculated in step S<b>1503</b> and the degree of risk according to rate of acceleration calculated in step S<b>1504</b>. In this case, the storage device <b>250</b> has stored therein data defining correspondence among overall degree of risk, distance range, and accuracy. Meanwhile, the storage device <b>320</b> may have stored therein both the degree of risk according to predicted relative position and the degree of risk according to rate of acceleration. In that case, the storage device <b>250</b> may have stored therein a correspondence table or function for determining the distance range and accuracy of distance measurement from the degree of risk according to predicted relative position and the degree of risk according to rate of acceleration.</p><p id="p-0289" num="0282"><figref idref="DRAWINGS">FIG. <b>45</b></figref> is a flow chart showing an operation of distance measurement according to the modification that adjust the distance range of distance measurement and the number of occurrences according to the degree of risk. The flow chart shown in <figref idref="DRAWINGS">FIG. <b>45</b></figref> has steps S<b>1711</b> and S<b>1712</b> added between steps S<b>1703</b> and S<b>1704</b> of the flow chart shown in <figref idref="DRAWINGS">FIG. <b>25</b></figref>. Further, emission and detection of the light beam is repeated the number of occurrences set. For the rest, the operation is the same as that of the aforementioned embodiment. The following describes points of differences from the operation of the aforementioned embodiment.</p><heading id="h-0070" level="1">Step S<b>1711</b></heading><p id="p-0290" num="0283">The control circuit <b>320</b> refers to the storage device <b>320</b> and extracts a degree of risk corresponding to the cluster selected in step S<b>1701</b>. The control circuit <b>230</b> refers to the storage device <b>250</b> and determines a distance range corresponding to the degree of risk, i.e. the time length for which to emit the light beam and the time length of a period of exposure of the light receiving device <b>220</b>. For example, the settings are configured so that the higher the degree of risk is, the shorter and longer distances the distance range includes. That is, the higher the degree of risk is, the longer the time length of emission of the light beam that is emitted from the light emitting device <b>210</b> and the time length of exposure of the light receiving device <b>220</b> become.</p><heading id="h-0071" level="1">Step S<b>1712</b></heading><p id="p-0291" num="0284">The control circuit <b>230</b> refers to the storage device <b>250</b> and determines, on the basis of the degree of risk extracted in step S<b>1711</b>, the distance measurement accuracy corresponding to the degree of risk, i.e. the number of occurrences of an operation of emission and exposure. For example, the settings are configured such that the distance measurement accuracy is increased as the degree of risk becomes higher. That is, the number of occurrences of an operation of emission and light reception is increased as the degree of risk becomes higher.</p><heading id="h-0072" level="1">Step S<b>1704</b></heading><p id="p-0292" num="0285">The control circuit <b>230</b> outputs, to the light emitting device <b>210</b> and the light receiving device <b>220</b>, control signals that control the direction of emission of the beam determined in step S<b>1703</b>, the timing and time length of emission determined in step S<b>1711</b>, the timing and time length of exposure of the light receiving device <b>220</b> determined in step S<b>1711</b>, and the number of occurrences of a combined operation of emission and exposure determined in step S<b>1712</b> and performs distance measurement. The method of distance measurement is as mentioned above.</p><p id="p-0293" num="0286">According to the present modification, a physical object having a higher degree of risk can be subjected to distance measurement over a wider range and with a higher degree of accuracy. For distance measurement over a wide range and with a high degree of accuracy, a longer measurement time is required. For distance measurement of a plurality of physical objects within a certain period of time, for example, the duration of distance measurement of a physical object having a high degree of risk may be made relatively long, and the duration of distance measurement of a physical object having a low degree of risk may be made relatively short. Such an operation makes it possible to appropriately adjust the duration of a distance measurement operation as a whole.</p><p id="p-0294" num="0287">The technologies disclosed here are widely applicable to distance measurement apparatuses or systems. For example, the technologies disclosed here may be used as constituent elements of a lidar (laser direction and distance measurement) system.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for controlling a distance measurement apparatus including a light emitting device configured to change a direction of emission of a light beam and a light receiving device that detects a reflected light beam produced by the emission of the light beam, the method comprising:<claim-text>acquiring data representing a plurality of images acquired at different points in time by an image sensor that acquires an image of a scene;</claim-text><claim-text>determining, based on the data representing the plurality of images, a degree of priority of distance measurement of one or more physical objects included in the plurality of images; and</claim-text><claim-text>executing distance measurement of the one or more physical objects by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the distance measurement apparatus is mounted on a movable body,</claim-text><claim-text>the method includes acquiring, from the movable body, data representing a movement of the movable body, and</claim-text><claim-text>the degree of priority is determined based on the data representing the plurality of images and the data representing the movement of the movable body.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein determining the degree of priority includes<claim-text>generating a motion vector of the one or more physical objects based on the plurality of images,</claim-text><claim-text>generating, based on the data representing the movement of the movable body, a motion vector of a stationary object that is generated due to the movement of the movable body, and</claim-text><claim-text>determining the degree of priority based on a relative velocity vector that is a difference between the motion vector of the physical object and the motion vector of the stationary object.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising, after having executed the distance measurement, outputting, to the movable body, data containing information identifying the physical object and information indicating a distance to the physical object.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the degree of priority is determined based on a magnitude of a time change in the relative velocity vector.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>acquiring the data representing the plurality of images includes acquiring data representing first, second and third images consecutively acquired by the image sensor, and</claim-text><claim-text>determining the degree of priority includes<claim-text>generating a first motion vector of the physical object based on the first image and the second image,</claim-text><claim-text>generating a second motion vector of the physical object based on the second image and the third image,</claim-text><claim-text>generating, based on the data representing the movement of the movable body, a motion vector of a stationary object that is generated due to the movement of the movable body,</claim-text><claim-text>generating a first relative velocity vector that is a difference between the first motion vector and the motion vector of the stationary object,</claim-text><claim-text>generating a second relative velocity vector that is a difference between the second motion vector and the motion vector of the stationary object, and</claim-text><claim-text>determining the degree of priority based on a difference between the first relative velocity vector and the second relative velocity vector.</claim-text></claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising repeating more than once a cycle including acquiring the data representing the images, determining the degree of priority of distance measurement of the physical object, and executing the distance measurement of the physical object.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein for a physical object on which the distance measurement was executed in a cycle, the distance measurement is continued in a next cycle without determining the degree of priority.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining a duration of illumination with the light beam according to the degree of priority.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining a number of occurrences of the emission of the light beam and detection of the reflected light beam according to the degree of priority.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the light receiving device include the image sensor.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the image sensor acquires the images from light emitted by the light emitting device.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the distance measurement apparatus is mounted on board a movable body, and</claim-text><claim-text>determining the degree of priority includes<claim-text>extracting a vector component of a relative velocity vector acting toward the movable body, the relative velocity vector being a difference between a motion vector of the physical object and a motion vector of a stationary object, and</claim-text><claim-text>determining the degree of priority based on a magnitude of the vector component acting toward the movable body.</claim-text></claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the magnitude of the vector component acting toward the movable body assumes a value obtained by multiplying the vector component acting toward the movable body by a coefficient corresponding to a straight-forward component of an acceleration vector of the movable body.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the vector component acting toward the movable body is multiplied by the coefficient when a magnitude of the straight-forward component of the acceleration vector of the movable body is greater than or equal to a threshold.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein determining the degree of priority includes<claim-text>extracting an orthogonal component of an acceleration vector of the movement body acting orthogonally to a forward movement of the movable body, and</claim-text><claim-text>determining the degree of priority based on a magnitude of a vector component of the relative velocity vector of the physical object that is identical to the orthogonal component.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A control apparatus for controlling a distance measurement apparatus including a light emitting device capable of changing a direction of emission of a light beam and a light receiving device that detects a reflected light beam produced by the emission of the light beam, the control apparatus comprising:<claim-text>a processor; and</claim-text><claim-text>a non-transitory computer-readable storage medium having stored thereon a computer program that is executed by the processor, the computer program causing the processor to execute operations including<claim-text>acquiring data representing a plurality of images acquired at different points in time by an image sensor that acquires an image of a scene,</claim-text><claim-text>determining, based on the data representing the plurality of images, a degree of priority of distance measurement of one or more physical objects included in the plurality of images, and</claim-text><claim-text>executing distance measurement of the one or more physical objects by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam.</claim-text></claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A system comprising:<claim-text>the control apparatus according to <claim-ref idref="CLM-00017">claim 17</claim-ref>; and</claim-text><claim-text>the light emitting device.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A non-transitory computer-readable storage medium having stored thereon a computer program that is executed by a processor that controls a distance measurement apparatus including a light emitting device capable of changing a direction of emission of a light beam and a light receiving device that detects a reflected light beam produced by the emission of the light beam, the computer program causing the processor to execute operations comprising:<claim-text>acquiring data representing a plurality of images acquired at different points in time by an image sensor that acquires an image of a scene;</claim-text><claim-text>determining, based on the data representing the plurality of images, a degree of priority of distance measurement of one or more physical objects included in the plurality of images; and</claim-text><claim-text>executing distance measurement of the one or more physical objects by causing the light emitting device to emit the light beam in a direction corresponding to the degree of priority and in an order corresponding to the degree of priority and causing the light receiving device to detect the reflected light beam.</claim-text></claim-text></claim></claims></us-patent-application>
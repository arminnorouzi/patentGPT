<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000351A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000351</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17779857</doc-number><date>20191205</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>002</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>0004</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Monitoring System, Monitoring Method, and Monitoring Program</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Nippon Telegraph and Telephone Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Ogasawara</last-name><first-name>Takayuki</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Matsunaga</last-name><first-name>Kenichi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Sato</last-name><first-name>Rieko</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2019/047634</doc-number><date>20191205</date></document-id><us-371c12-date><date>20220525</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A monitoring system includes a first acquisition unit that acquires identification information unique to a user, a second acquisition unit that acquires position information of the user, an action history calculation unit that obtains an action history of the user from the identification information of the user acquired by the first acquisition unit and the position information acquired by the second acquisition unit, and a presentation unit that presents the action history of the user calculated by the action history calculation unit, wherein the action history includes at least one of a period for which and a frequency at which the user stayed at a position indicated by the position information.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="137.41mm" wi="144.36mm" file="US20230000351A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="188.98mm" wi="150.54mm" file="US20230000351A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="149.01mm" wi="146.39mm" file="US20230000351A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="197.44mm" wi="137.67mm" file="US20230000351A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="187.11mm" wi="158.16mm" file="US20230000351A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="193.12mm" wi="159.09mm" file="US20230000351A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="148.17mm" wi="156.29mm" file="US20230000351A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="149.52mm" wi="74.85mm" file="US20230000351A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="181.44mm" wi="149.10mm" file="US20230000351A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="148.08mm" wi="155.53mm" file="US20230000351A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="156.89mm" wi="155.87mm" file="US20230000351A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This patent application is a national phase filing under section 371 of PCT application no. PCT/JP2019/047634, filed on Dec. 5, 2019, which application is hereby incorporated herein by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present invention relates to a monitoring system, a monitoring method, and a monitoring program, and particularly to a technique for watching over a patient in medical care and long-term care.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Conventionally, there has been proposed a monitoring system that enables monitoring of a patient using a sensor, and focuses on the daily life rhythm of the patient for medical care and long-term care facilities (see Non-Patent Literature 1). <figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram showing an overview of the conventional monitoring system disclosed in Non-Patent Literature 1.</p><p id="p-0005" num="0004">As shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, in the conventional monitoring system, a user such as a patient wears rehabilitation wear that is a wearable device, and data of the electrocardiographic potential and acceleration of the user for 24 hours is acquired by the wearable device. The rehabilitation wear is provided with a transmitter, and information on the electrocardiographic potential and acceleration of the user is transmitted from the transmitter to a relay terminal device such as a smartphone or an IoT gate.</p><p id="p-0006" num="0005">The data of the electrocardiographic potential and acceleration of the user is subjected to data storage, accumulation, and analysis processing in an external terminal device such as a server connected via a network. The analysis result is output based on biological information of the user analyzed in the external terminal device, and is notified to medical personnel responsible for the medical care and nursing care for the user, such as doctors, therapists, and nurses, through a viewer.</p><p id="p-0007" num="0006">From the notified analysis result and report, the doctors, therapists, nurses, and others can provide more suitable care to the user when treating or caring for the user whom they are responsible for.</p><p id="p-0008" num="0007">However, information obtained from the electrocardiographic potential and acceleration information of the user for 24 hours in the conventional monitoring system described in Non-Patent Literature 1 is a measurement result of sensor data, and its typical content is information indicating that the user's posture was a lying posture and the heart rate decreased. Even though such a change in the user's posture and heart rate indicates abnormality in biological information and activity information of the user, it does not directly indicate the cause of the abnormality, so, for example, it may be difficult to provide appropriate guidance in life to users whose amount of activity is low.</p><p id="p-0009" num="0008">The activity of a user such as a patient is often determined by the user's whereabouts as their living environment. For example, if the user is led to spend their time in a small hospital room, they have no choice but to spend most of their time lying down or sitting on the bed or the like. In such a case, the user's posture is often a lying posture, and the heart rate also decreases, which are as indicated by the biological information and activity information of the user obtained by the conventional monitoring system.</p><heading id="h-0004" level="1">CITATION LIST</heading><heading id="h-0005" level="1">Non-Patent Literature</heading><p id="p-0010" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0009">Non-Patent Literature 1: Ogasawara Takayuki, Matsunaga Kenichi, Ito Hiroki, Oshima Shoichi, Mukaino Masahiko, &#x201c;Efforts to Support Rehabilitation by Applying Wearable Material hitoe (R)&#x201d;, NIT Technical Journal 2018.7 (pp. 10-14, <figref idref="DRAWINGS">FIG. <b>3</b></figref>).</li></ul></p><heading id="h-0006" level="1">SUMMARY</heading><heading id="h-0007" level="1">Technical Problem</heading><p id="p-0011" num="0010">If the action history of the user such as where, how often, and how much time the user spent can be grasped by grasping the user's whereabouts, it becomes possible to support improvement of the user's life more concretely and appropriately when trying to increase the amount of activity of the user, for example.</p><p id="p-0012" num="0011">Embodiments of the present invention has been made to solve the above problems, and aims to grasp the action history of a user.</p><heading id="h-0008" level="1">Means for Solving the Problem</heading><p id="p-0013" num="0012">In order to solve the above problems, a monitoring system according to embodiments of the present invention includes: a first acquisition unit that acquires identification information unique to a user; a second acquisition unit that acquires position information of the user; a calculation unit that obtains an action history of the user from the identification information of the user acquired by the first acquisition unit and the position information acquired by the second acquisition unit; and a presentation unit that presents the action history of the user calculated by the calculation unit, wherein the action history includes at least one of a period for which and a frequency at which the user stayed at a position indicated by the position information.</p><p id="p-0014" num="0013">In order to solve the above problems, a monitoring system according to embodiments of the present invention includes: a sensor terminal device that is attached to a user, and outputs first identification information, which is identification information unique to the sensor terminal device, to outside; a relay terminal device that is arranged at a predetermined position within an area, receives the first identification information output from the sensor terminal device, and outputs the first identification information and second identification information, which is identification information unique to the relay terminal device, to outside; and an external terminal device that receives the first identification information and the second identification information output from the relay terminal device and stores the first identification information and the second identification information in a storage device, wherein the external terminal device includes a first acquisition unit that acquires the first identification information as identification information unique to the user, a second acquisition unit that acquires the second identification information as position information of the user, a calculation unit that obtains an action history of the user from the identification information of the user acquired by the first acquisition unit and the position information acquired by the second acquisition unit, and a presentation unit that presents the action history of the user obtained by the calculation unit, and the action history includes at least one of a period for which and a frequency at which the user stayed at a position indicated by the position information.</p><p id="p-0015" num="0014">In order to solve the above problems, a monitoring method according to embodiments of the present invention includes: a first step of acquiring identification information unique to a user; a second step of acquiring position information of the user; a third step of obtaining an action history of the user from the identification information of the user acquired in the first step and the position information acquired in the second step; and a fourth step of presenting the action history of the user calculated in the third step, wherein the action history includes at least one of a period for which and a frequency at which the user stayed at a position indicated by the position information.</p><p id="p-0016" num="0015">In order to solve the above problems, a monitoring program according to embodiments of the present invention causes a computer to execute the above monitoring method.</p><heading id="h-0009" level="1">Effects of Embodiments of the Invention</heading><p id="p-0017" num="0016">According to embodiments of the present invention, since an action history of a user is obtained and presented from identification information unique to the user acquired by the first acquisition unit, and position information of the user acquired by the second acquisition unit, it is possible to grasp the action history of the user.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0010" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram showing a functional configuration of a monitoring system according to a first embodiment of the present invention.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram showing an example of a computer configuration that implements the monitoring system according to the first embodiment.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart for describing a monitoring method according to the first embodiment.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram for describing an interpolation unit according to the first embodiment.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram for describing an overview of an example configuration of the monitoring system according to the first embodiment.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram showing an example configuration of the monitoring system according to the first embodiment.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram showing a configuration of a monitoring system according to a second embodiment.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic diagram for describing operation of the monitoring system according to the second embodiment.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram for describing an interpolation unit according to the second embodiment.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram for describing the interpolation unit according to the second embodiment.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram showing a configuration of a monitoring system according to a third embodiment.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart showing a monitoring method according to the third embodiment.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram for describing an estimation unit according to the third embodiment.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram for describing the estimation unit according to the third embodiment.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a block diagram showing an example configuration of the monitoring system according to the third embodiment.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram for describing an overview of a conventional monitoring system.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0011" level="1">DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS</heading><p id="p-0034" num="0033">Hereinafter, preferred embodiments of the present invention will be described in detail with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>15</b></figref>.</p><heading id="h-0012" level="1">Overview of Embodiments of the Invention</heading><p id="p-0035" num="0034">First, an overview of monitoring systems according to the embodiments of the present invention will be described. The monitoring systems according to the embodiments identify individual users such as users who perform rehabilitation in a long-term care facility and hospitalized patients, and also identify the position of each user in the facility. In addition, the monitoring systems according to the embodiments calculate an action history of the user including the staying time of the user at the identified position. Furthermore, when a period in which the position of the user cannot be identified has occurred and data of the action history has been lost, the monitoring systems according to the embodiments interpolate the action history of the user from identification information and position information of the user acquired before and after the lost period.</p><heading id="h-0013" level="1">First Embodiment</heading><p id="p-0036" num="0035">First, an overview of a configuration of a monitoring system according to a first embodiment of the present invention will be described. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram showing a functional configuration of the monitoring system.</p><p id="p-0037" num="0036">Functional Blocks of Monitoring System</p><p id="p-0038" num="0037">The monitoring system includes a first acquisition unit <b>10</b>, a second acquisition unit <b>11</b>, a user identification unit <b>12</b>, a position identification unit <b>13</b>, an action history calculation unit (calculation unit) <b>14</b>, an interpolation unit <b>15</b>, a storage unit <b>16</b>, and a presentation unit <b>17</b>.</p><p id="p-0039" num="0038">The first acquisition unit <b>10</b> acquires identification information unique to a user. For example, from a tag or a sensor terminal device <b>200</b> described later attached to the user, the first acquisition unit <b>10</b> acquires identification information of the device such as a MAC address, an IP address, or a serial number assigned to the sensor terminal device <b>200</b> as identification information of the user. The identification information of the device attached to the user such as the tag or the sensor terminal device <b>200</b> and the identification information of the user are stored in advance in the storage unit <b>16</b> in association with each other.</p><p id="p-0040" num="0039">The second acquisition unit <b>11</b> acquires position information of the user. For example, the second acquisition unit <b>11</b> acquires identification information of a point arranged at a determined position within a facility or unique identification information owned by a relay terminal device <b>300</b> described later arranged within the facility as the position information of the user.</p><p id="p-0041" num="0040">The user identification unit <b>12</b> identifies an individual user from the identification information unique to the user that is acquired by the first acquisition unit <b>10</b>. The user identification unit <b>12</b> refers to the storage unit <b>16</b>, and identifies the user corresponding to the identification information acquired by the first acquisition unit <b>10</b>.</p><p id="p-0042" num="0041">The position identification unit <b>13</b> identifies the position of the user from the position information acquired by the second acquisition unit <b>11</b>. The position identification unit <b>13</b> identifies the position of the user at a certain cycle, and the position identification unit <b>13</b> outputs the identified position of the user for each time. For example, the position information in the facility and the identification information of the point or the relay terminal device <b>300</b> are stored in advance in the storage unit <b>16</b> in association with each other. The position identification unit <b>13</b> can refer to the storage unit <b>16</b>, and identify the position in the facility that is linked to the position information acquired by the second acquisition unit <b>11</b>, such as a &#x201c;rehabilitation room&#x201d; or a &#x201c;cafeteria&#x201d;.</p><p id="p-0043" num="0042">The action history calculation unit <b>14</b> obtains an action history of the user from the user and the position of the user identified by the user identification unit <b>12</b> and the position identification unit <b>13</b>. The action history is information on the position of the user in the facility according to the passage of time. The action history includes the period for which and the frequency at which the user stayed at the position identified by the position identification unit <b>13</b>. For example, the action history calculation unit <b>14</b> can output information indicating that a &#x201c;user A&#x201d; stayed at a &#x201c;cafeteria&#x201d; once for one hour as the action history.</p><p id="p-0044" num="0043">In addition, the action history calculation unit <b>14</b> can also obtain a time series of positions representing movements of the user in the facility, in addition to the period for which and the frequency at which they stayed at a specific position in the facility. The action history calculation unit <b>14</b> obtains the action history of the user at a certain cycle. For example, the action history of the user can be updated according to the cycle at which the second acquisition unit <b>11</b> acquires the position information of the user. The action history of the user obtained by the action history calculation unit <b>14</b> is stored in the storage unit <b>16</b>.</p><p id="p-0045" num="0044">When the action history of the user calculated by the action history calculation unit <b>14</b> includes a data loss period, the interpolation unit <b>15</b> confirms whether the pieces of position information of the user immediately before and after the loss period match each other. When the pieces of position information of the user immediately before and after the loss period included in the action history match each other, the interpolation unit <b>15</b> interpolates data of the action history of the user using the pieces of position information immediately therebefore and thereafter.</p><p id="p-0046" num="0045">As described before, the action history calculation unit <b>14</b> cannot obtain the action history of the user unless both the identification information unique to the user and the position information are acquired. When the action history calculation unit <b>14</b> cannot obtain the action history of the user in a period of time, the time series of the action history of the user will include a loss period.</p><p id="p-0047" num="0046">For example, suppose that the actual position of the user is the same throughout one hour, but two momentary losses have occurred in the action history of the user for one hour, and there have occurred loss periods during which the identification information and the position information of the user cannot be acquired. Originally, the fact that the user stayed at the same position at a frequency of once for about one hour should be obtained as the action history. However, when loss periods have occurred in the action history, the action history calculation unit <b>14</b> incorrectly calculates that the user stayed at the same place at a frequency of three times and stayed for a period shorter than one hour when obtaining the staying frequency (the number of stays) of the user, though it is originally once.</p><p id="p-0048" num="0047">When a loss period has occurred in the action history of the user, the interpolation unit <b>15</b> detects the loss period, and, when the user and the position of the user identified by the user identification unit <b>12</b> and the position identification unit <b>13</b> before and after the loss period match each other, interpolates the action history by assuming that the position of the user during the loss period did not change before and after the loss period and during the loss period.</p><p id="p-0049" num="0048">The storage unit <b>16</b> stores the identification information unique to the user. The storage unit <b>16</b> stores, for example, the user's name or ID number, the identification information unique to the device, such as a MAC address, an IP address, or a serial number assigned in advance to the device, carried and moved by the user, such as the sensor terminal device <b>200</b> assigned to the user, and user information in association with each other.</p><p id="p-0050" num="0049">Further, the storage unit <b>16</b> stores identification information of a device from which the position information of the user is acquired, such as identification information of a point arranged in the facility or identification information such as a MAC address or an IP address of the relay terminal device <b>300</b> described later, and information indicating the position where the device is arranged in the facility in association with each other. For example, the position coordinate at which the relay terminal device <b>300</b> having a predetermined communication area is installed in the long-term care facility, or the name of a room covered by the communication area, such as &#x201c;cafeteria&#x201d;, &#x201c;entrance&#x201d;, or &#x201c;washroom&#x201d;, and identification information, such as a MAC address, and position information of the relay terminal device <b>300</b> are stored in association with each other.</p><p id="p-0051" num="0050">Further, the storage unit <b>16</b> stores the action history of the user obtained by the action history calculation unit <b>14</b>. The action history of the user is, for example, data indicating a time series of position information and a staying time and staying frequency at each position for each user.</p><p id="p-0052" num="0051">The presentation unit <b>17</b> presents the action history of the user obtained by the action history calculation unit <b>14</b>. For example, the presentation unit <b>17</b> can display the action history of the user on a display screen of a display device <b>109</b> described later.</p><p id="p-0053" num="0052">Hardware Configuration of Monitoring System</p><p id="p-0054" num="0053">Next, an example of a computer configuration that implements the monitoring system having the above functions will be described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0055" num="0054">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the monitoring system can be implemented by, for example, a computer including a processor <b>102</b>, a main storage device <b>103</b>, a communication I/F <b>104</b>, an auxiliary storage device <b>106</b>, a clock <b>107</b>, and an input/output I/O <b>108</b> connected via a bus <b>101</b>, and a program that controls these hardware resources. For example, each of a sensor <b>105</b> and a display device <b>109</b> that are provided externally is connected to the monitoring system via the bus <b>101</b>.</p><p id="p-0056" num="0055">The main storage device <b>103</b> stores in advance programs for the processor <b>102</b> to perform various types of control and calculation. The processor <b>102</b> and the main storage device <b>103</b> implement the functions of the monitoring system including the user identification unit <b>12</b>, the position identification unit <b>13</b>, the action history calculation unit <b>14</b>, and the interpolation unit <b>15</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0057" num="0056">The communication I/F <b>104</b> is an interface circuit for communicating with various types of external electronic equipment via a communication network NW.</p><p id="p-0058" num="0057">As the communication I/F <b>104</b>, for example, a communication control circuit and an antenna supporting wireless data communication standards such as 3G, 4G, 5G, wireless LAN, Bluetooth (R), and Bluetooth Low Energy are used. The communication I/F <b>104</b> implements the first acquisition unit <b>10</b> and the second acquisition unit <b>11</b> described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0059" num="0058">The sensor <b>105</b> includes, for example, an electrocardiograph and a triaxial acceleration sensor. The sensor <b>105</b> can further include, for example, a sensor for measuring biological information and physical information of the user such as a sphygmomanometer, a pulse meter, a respiration sensor, a thermometer, and a brain wave sensor. When the presentation unit <b>17</b> described in <figref idref="DRAWINGS">FIG. <b>1</b></figref> displays the action history of the user on the display screen, a time series of biological information of the user measured by the sensor <b>105</b> can be displayed together with the action history.</p><p id="p-0060" num="0059">The auxiliary storage device <b>106</b> includes a readable and writable storage medium and a driving device for reading/writing various types of information such as programs and data from/to the storage medium. For the auxiliary storage device <b>106</b>, a semiconductor memory such as a hard disk or a flash memory can be used as a storage medium.</p><p id="p-0061" num="0060">The auxiliary storage device <b>106</b> has a program storage area that stores programs for the monitoring system to calculate the action history and perform interpolation processing of data of the action history and monitoring programs. The auxiliary storage device <b>106</b> implements the storage unit <b>16</b> described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The auxiliary storage device <b>106</b> may have a storage area for storing biological information of the user measured by the sensor <b>105</b>, and also, for example, a backup area for backing up the above-mentioned data and programs.</p><p id="p-0062" num="0061">The clock <b>107</b> includes an internal clock built in the computer or the like, and measures the time. Alternatively, the clock <b>107</b> may acquire time information from a time server not shown.</p><p id="p-0063" num="0062">The input/output I/O <b>108</b> includes an I/O terminal that receives a signal from external equipment as input, and outputs a signal to external equipment.</p><p id="p-0064" num="0063">The display device <b>109</b> is implemented by a liquid crystal display or the like. The display device <b>109</b> implements the presentation unit <b>17</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0065" num="0064">Monitoring Method</p><p id="p-0066" num="0065">Next, operation of the monitoring system having the above-described configuration will be described using a flowchart in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In the following, it is assumed that the storage unit <b>16</b> stores user information (e.g., the user's name or patient ID) and identification information unique to a wearable device assigned to the user (e.g., a MAC address or an IP address) in association with each other. Further, it is assumed that the storage unit <b>16</b> stores unique identification information (e.g., a MAC address or an IP address) of a point arranged at a fixed position in the facility, the relay terminal device <b>300</b> or other devices, and information indicating the arrangement position (e.g., a name such as &#x201c;cafeteria&#x201d; or &#x201c;entrance&#x201d;) in association with each other.</p><p id="p-0067" num="0066">As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the first acquisition unit <b>10</b> first acquires identification information unique to the user (step S<b>1</b>). For example, the first acquisition unit <b>10</b> acquires unique identification information assigned to a wearable device attached to the user.</p><p id="p-0068" num="0067">Next, the second acquisition unit <b>11</b> acquires position information of the user (step S<b>2</b>). For example, from a point or IoT gate in the facility that has established communication with the wearable devices worn by the user, the second acquisition unit <b>11</b> acquires unique identification information assigned to these devices. Further, the second acquisition unit <b>11</b> can acquire the position information of the user at a certain cycle.</p><p id="p-0069" num="0068">Next, the user identification unit <b>12</b> identifies the user from the identification information of the user acquired by the first acquisition unit <b>10</b> (step S<b>3</b>). Next, the position identification unit <b>13</b> identifies the position of the user from the position information acquired by the second acquisition unit <b>11</b> (step S<b>4</b>). The user identification unit <b>12</b> and the position identification unit <b>13</b> identify the user and the position of the user from the information stored in advance in the storage unit <b>16</b>.</p><p id="p-0070" num="0069">Next, the action history calculation unit <b>14</b> obtains an action history of the user (step S<b>5</b>). For example, the action history calculation unit <b>14</b> calculates the frequency (the number of times) at which and the period for which the user stayed at the identified position in the facility.</p><p id="p-0071" num="0070">Next, when the action history calculated by the action history calculation unit <b>14</b> includes a loss period (step S<b>6</b>: YES), the interpolation unit <b>15</b> performs interpolation processing (step S<b>7</b>). More specifically, the interpolation unit <b>15</b> detects that there is a loss period in the action history, and, when the position of the user identified in step S<b>4</b> immediately before the loss period is the same as the position of the user identified in step S<b>4</b> immediately after the loss period, regards the position information of the user during the loss period as the same as the pieces of position information immediately before and after the loss period.</p><p id="p-0072" num="0071">After that, the presentation unit <b>17</b> displays the action history interpolated by the interpolation unit <b>15</b> on, for example, the display screen of the display device <b>109</b> (step S<b>8</b>). On the other hand, when a loss period in the action history is not detected in step S<b>6</b> (step S<b>6</b>: NO), the interpolation processing by the interpolation unit <b>15</b> is not executed, and the action history of the user obtained in step S<b>5</b> is presented by the presentation unit <b>17</b> (step S<b>8</b>). At this time, the presentation unit <b>17</b> can present the heart rate or the like of the user measured by the sensor <b>105</b> together with the action history of the user.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a graph showing the effect of the interpolation processing by the interpolation unit <b>15</b> according to this embodiment. The bar graph on the left side of <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows the number of data losses that have occurred in the action history in a certain period, and about 1,000 data losses have occurred intermittently. On the other hand, the bar graph on the right side of <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows the number of cases of interpolation processing when the interpolation unit <b>15</b> performed interpolation for data losses for a period of 5 minutes or less in the same period of time. From this, it can be seen that by the monitoring system being provided with the interpolation unit <b>15</b>, the data is improved by about 300 pieces by the interpolation processing. Thus, the monitoring system according to this embodiment can obtain the action history of the user with higher reliability by having the interpolation unit <b>15</b>.</p><p id="p-0074" num="0073">Specific Configuration of Monitoring System</p><p id="p-0075" num="0074">Next, an example specific configuration of the monitoring system having the above-described configuration will be described with reference to <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>. For example, as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the monitoring system includes, for example, the sensor terminal device <b>200</b> attached to a user who performs rehabilitation, the relay terminal device <b>300</b>, and an external terminal device <b>400</b>.</p><p id="p-0076" num="0075">The sensor terminal device <b>200</b> includes a wearable device or the like, and is attached to the user to move together with the user in a facility such as a rehabilitation facility. The sensor terminal device <b>200</b> has unique identification information, and the identification information of the sensor terminal device <b>200</b> makes it possible to identify which user the user is.</p><p id="p-0077" num="0076">As the relay terminal device <b>300</b>, for example, a smart phone, a tablet terminal, a laptop, and a small computer typified Raspberry Pi (R) and OpenBlocks (R) can be used. The relay terminal device <b>300</b> is arranged at a fixed position in a facility to be monitored. A plurality of relay terminal devices <b>300</b> are arranged in advance in the facility.</p><p id="p-0078" num="0077">The relay terminal device <b>300</b> has its own communication area. When the sensor terminal device <b>200</b> attached to the user has entered the communication area of the relay terminal device <b>300</b>, the sensor terminal device <b>200</b> permitted in advance to perform communication can perform wireless communication with the relay terminal device <b>300</b>. The identification information unique to the relay terminal device <b>300</b> and the position information indicating the position where the relay terminal device <b>300</b> is arranged in the facility are registered in advance in association with each other. The identification information of the relay terminal device <b>300</b> makes it possible to identify the position information of the user.</p><p id="p-0079" num="0078">As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the relay terminal device <b>300</b> is arranged on the ceiling or a wall of a room in the facility. Further, it is assumed in this embodiment that the communication area of the relay terminal device <b>300</b> is treated as the position of one point in the facility.</p><p id="p-0080" num="0079">As with the relay terminal device <b>300</b>, as the external terminal device <b>400</b>, for example, a smart phone, a tablet terminal, a laptop, and a small computer typified by Raspberry Pi (R) and OpenBlocks (R) are used.</p><p id="p-0081" num="0080">The external terminal device <b>400</b> is provided with the functions of the monitoring system described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and performs wired or wireless communication with the relay terminal device <b>300</b>.</p><p id="p-0082" num="0081">Configuration of Sensor Terminal Device</p><p id="p-0083" num="0082">As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the sensor terminal device <b>200</b> includes a sensor <b>201</b>, a sensor data acquisition unit <b>202</b>, a storage unit <b>203</b>, and a transmission unit <b>204</b>. The sensor terminal device <b>200</b> is, for example, arranged on the user's body trunk to move together with the user in the facility to be monitored. When the sensor terminal device <b>200</b> has entered the communication area of the relay terminal device <b>300</b>, it establishes wireless communication with the relay terminal device <b>300</b>, and transmits unique identification information such as a MAC address or an IP address assigned to the sensor terminal device <b>200</b>.</p><p id="p-0084" num="0083">The sensor <b>201</b> is implemented by, for example, an electrocardiograph and a triaxial acceleration sensor. For the three axes of the acceleration sensor provided in the sensor <b>201</b>, for example, as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the X-axis is provided in parallel with the left-right direction of the body, the Y-axis in the front-rear direction of the body, and the Z-axis in the up-down direction of the body. The sensor <b>201</b> corresponds to the sensor <b>105</b> described in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0085" num="0084">The sensor data acquisition unit <b>202</b> acquires biological information of the user measured by the sensor <b>201</b>. More specifically, the sensor data acquisition unit <b>202</b> performs noise removal and sampling processing for the acquired electrocardiographic potential, acceleration and the like to obtain time series of an electrocardiographic waveform, a heart rate, and acceleration in the form of digital signals.</p><p id="p-0086" num="0085">The storage unit <b>203</b> stores the time-series data of the biological information of the user measured by the sensor <b>201</b>. Further, the storage unit <b>203</b> stores the identification information of its own device. The storage unit <b>203</b> corresponds to the storage unit <b>16</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>).</p><p id="p-0087" num="0086">The transmission unit <b>204</b> transmits the biological information such as the heart rate of the user and the identification information (first identification information) of its own device that are stored in the storage unit <b>203</b> to the relay terminal device <b>300</b> in the communication area. The transmission unit <b>204</b> is provided with a communication circuit for performing wireless communication supporting wireless data communication standards such as LTE, 3G, 4G, 5G, wireless LAN (Local Area Network), Bluetooth (R), and Bluetooth Low Energy.</p><p id="p-0088" num="0087">Configuration of Relay Terminal Device</p><p id="p-0089" num="0088">The relay terminal device <b>300</b> includes a reception unit <b>301</b>, a storage unit <b>302</b>, and a transmission unit <b>303</b>. The relay terminal device <b>300</b> transmits the identification information of the sensor terminal device <b>200</b> and the biological information of the user measured by the sensor terminal device <b>200</b> that are received from the sensor terminal device <b>200</b>, and the identification information (second identification information) of the relay terminal device <b>300</b> to the external terminal device <b>400</b> via the communication network NW.</p><p id="p-0090" num="0089">The reception unit <b>301</b> receives the identification information of the sensor terminal device <b>200</b> from the sensor terminal device <b>200</b> via the communication network NW.</p><p id="p-0091" num="0090">The storage unit <b>302</b> stores the identification information of the sensor terminal device <b>200</b> received by the reception unit <b>301</b>. Further, the storage unit <b>302</b> temporarily stores the biological information of the user measured by the sensor terminal device <b>200</b>. The storage unit <b>302</b> stores identification information unique to its own device.</p><p id="p-0092" num="0091">The transmission unit <b>303</b> transmits the identification information of the device received from the sensor terminal device <b>200</b> and the identification information of the relay terminal device <b>300</b> to the external terminal device <b>400</b> via the communication network NW. Note that the transmission unit <b>303</b> can also transmit the biological information of the user measured by the sensor terminal device <b>200</b>.</p><p id="p-0093" num="0092">Configuration of External Terminal Device</p><p id="p-0094" num="0093">The external terminal device <b>400</b> includes a reception unit <b>401</b>, a data analysis unit <b>402</b>, a storage unit <b>403</b>, and a presentation unit <b>404</b>. The external terminal device <b>400</b> obtains and presents the action history of the user. Note that the data analysis unit <b>402</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref> includes the first acquisition unit <b>10</b>, the second acquisition unit <b>11</b>, the user identification unit <b>12</b>, the position identification unit <b>13</b>, the action history calculation unit <b>14</b>, and the interpolation unit <b>15</b> described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0095" num="0094">The external terminal device <b>400</b> is used by, for example, medical care staffs and long-term care staffs who are responsible for care of the user such as rehabilitation and treatment.</p><p id="p-0096" num="0095">The reception unit <b>401</b> receives the identification information of the sensor terminal device <b>200</b> and the identification information of the relay terminal device <b>300</b> from the relay terminal device <b>300</b> via the communication network NW. The reception unit <b>401</b> can also receive the biological information of the user measured by the sensor terminal device <b>200</b>.</p><p id="p-0097" num="0096">The data analysis unit <b>402</b> obtains the action history of the user from the identification information of the sensor terminal device <b>200</b> and the identification information of the relay terminal device <b>300</b>, and, when detecting a loss period in the action history, interpolates data of the action history from the pieces of identification information of the relay terminal device <b>300</b> immediately before and after the loss period.</p><p id="p-0098" num="0097">The storage unit <b>403</b> corresponds to the storage unit <b>16</b> described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and stores the user information and the identification information of the sensor terminal device <b>200</b> in association with each other. Further, the storage unit <b>403</b> stores the identification information of the relay terminal device <b>300</b> and the information indicating the arrangement position in the facility where the relay terminal device <b>300</b> is arranged in association with each other.</p><p id="p-0099" num="0098">The presentation unit <b>404</b> corresponds to the presentation unit <b>17</b> described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The presentation unit <b>404</b> can display the action history of each user and the biological information of the user measured by the sensor terminal device <b>200</b> on the display screen.</p><p id="p-0100" num="0099">As described above, according to the monitoring system of the first embodiment, the action history of the user is obtained based on the identification information of the sensor terminal device <b>200</b> that identifies the user and the identification information of the relay terminal device <b>300</b> that indicates the position information of the user. Further, when the time series of the action history of the user includes a loss period, the monitoring system interpolates the action history of the user from the pieces of position information of the user immediately before and after the loss period.</p><p id="p-0101" num="0100">Therefore, not only can the action history of the user be grasped, but also an accurate action history can be obtained by performing interpolation processing even when the data includes a loss period. As a result, it becomes possible to give more concrete and appropriate advice for improving life to the user.</p><p id="p-0102" num="0101">For example, when it is found out from the action history of the user that the user spends most of daytime hours of the day at the same position, medical care staffs and others can advise the user to walk to a specific position in the facility in order to encourage the user to increase their amount of activity.</p><heading id="h-0014" level="1">Second Embodiment</heading><p id="p-0103" num="0102">Next, a second embodiment of the present invention will be described. Note that in the following description, the same components as those in the first embodiment described above are given the same reference numerals, and the description thereof will be omitted.</p><p id="p-0104" num="0103">The first embodiment has described a case where the position information of the user in the facility is acquired and the action history of the user is obtained from the identification information and the position information of the user. In contrast, in the second embodiment, the position information of the user in the facility is given metadata indicating an attribute of the position information, and the action history of the user is obtained based on a common attribute of the pieces of position information.</p><p id="p-0105" num="0104">Functional Blocks of Monitoring System</p><p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram showing a configuration of a monitoring system according to the second embodiment. The monitoring system includes the first acquisition unit <b>10</b>, the second acquisition unit <b>11</b>, the user identification unit <b>12</b>, the position identification unit <b>13</b>, the action history calculation unit <b>14</b>, the interpolation unit <b>15</b>, the storage unit <b>16</b>, the presentation unit <b>17</b>, and a metadata giving unit <b>18</b>. The monitoring system according to this embodiment is different from that in the first embodiment in that the metadata giving unit <b>18</b> is provided. Hereinafter, configurations different from those of the first embodiment will be described mainly.</p><p id="p-0107" num="0106">The metadata giving unit <b>18</b> gives the position information of the user acquired by the second acquisition unit <b>11</b> metadata describing an attribute representing the position information.</p><p id="p-0108" num="0107">Here, an example of the metadata will be described with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Note that <figref idref="DRAWINGS">FIG. <b>8</b></figref> will be described using an example configuration in which the monitoring system includes the sensor terminal device <b>200</b>, the relay terminal device <b>300</b>, and the external terminal device <b>400</b> described in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0109" num="0108">As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, for example, three relay terminal devices <b>300</b> are arranged at certain intervals so as to be able to cover a relatively large cafeteria area. The relay terminal devices <b>300</b> have their respective pieces of unique identification information, which identify a &#x201c;cafeteria <b>1</b>&#x201d;, a &#x201c;cafeteria <b>2</b>&#x201d;, and a &#x201c;cafeteria <b>3</b>&#x201d;, indicating more detailed positions in the entire &#x201c;cafeteria&#x201d;.</p><p id="p-0110" num="0109">For example, when it is desired to simply grasp the period for which and the frequency at which the user was in the cafeteria as the action history of the user, the pieces of identification information that identify the detailed positions in the cafeteria as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> have no value from the point of view of identifying only the position of the cafeteria. Therefore, when the pieces of identification information indicating the pieces of position information have a common attribute in obtaining the action history of the user, the metadata giving unit <b>18</b> gives metadata to the pieces of position information acquired by the second acquisition unit <b>11</b>. In the example of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the three pieces of position information are given an attribute of &#x201c;cafeteria&#x201d; as a common attribute.</p><p id="p-0111" num="0110">As a method for the metadata giving unit <b>18</b> to give metadata to the position information of the user, an algorithm such as clustering can be used. Alternatively, the metadata giving unit <b>18</b> can also give metadata to the position information acquired by the second acquisition unit <b>11</b> in accordance with an operational input from the outside that is received by an input device not shown.</p><p id="p-0112" num="0111">The action history calculation unit <b>14</b> obtains the action history of the user based on the identification information unique to the user acquired by the first acquisition unit <b>10</b> and the metadata given to the position information of the user acquired by the second acquisition unit <b>11</b>. Using the example in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, even when the second acquisition unit <b>11</b> has acquired any position information of &#x201c;cafeteria <b>1</b>&#x201d;, &#x201c;cafeteria <b>2</b>&#x201d;, and &#x201c;cafeteria <b>3</b>&#x201d;, the staying period and staying frequency of the user in the &#x201c;cafeteria&#x201d; are obtained based on the metadata &#x201c;cafeteria <b>1</b>&#x201d; given to them.</p><p id="p-0113" num="0112">When a loss period is detected in the time series of the action history of the user and the metadata given to the pieces of position information immediately before and after the loss period match each other, the interpolation unit <b>15</b> interpolates the action history of the user using the value of the metadata. According to the above example, even when the position information immediately before the loss period is &#x201c;cafeteria <b>1</b>&#x201d; and the position information immediately thereafter is &#x201c;cafeteria <b>3</b>&#x201d;, metadata &#x201c;cafeteria&#x201d; assigned to them match each other. Therefore, it can be considered that the user was in the &#x201c;cafeteria&#x201d; during the loss period.</p><p id="p-0114" num="0113"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram for describing the effect of the interpolation unit <b>15</b> according to this embodiment. The bar graph on the left side of <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the number of losses included in the action history data over a period of time when the interpolation processing is not performed, and shows that about 1,000 data losses have occurred. The bar graph in the middle of <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the effect of the interpolation unit <b>15</b> according to the first embodiment. The bar graph in the middle of <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the number of cases of interpolation processing of the action history when the interpolation processing is performed for losses that occurred for a period of 5 minutes or less over the same period of time based on more detailed position information, and the action history data is improved by about 300 pieces by the interpolation processing.</p><p id="p-0115" num="0114">The bar graph on the right side of <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the number of cases of interpolation processing of the action history when the interpolation processing is performed for losses of the action history data that occurred for a period of 5 minutes or less based on the metadata of the position information, and the action history data is improved by more than 400 pieces by the interpolation processing. As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, it can be seen that a more accurate action history of the user is obtained when the interpolation processing is performed based on the metadata given to the position information.</p><p id="p-0116" num="0115">Although <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows a case where the interpolation processing is performed for data losses that occurred for a period of 5 minutes or less, the interpolation unit <b>15</b> may perform division into cases as to whether or not to perform interpolation based on, for example, the length of a loss period in the action history of the user. For example, when a loss period included in the action history is relatively long, the user may intentionally have moved out of (e.g., gone out of) the communication area covered by the relay terminal device <b>300</b>.</p><p id="p-0117" num="0116">Therefore, by detecting a loss period with a length according to the user's daily life of and the level of activity amount and performing the interpolation processing of the action history, generation of an incorrect action history by the interpolation processing is prevented. For example, from the relationship between the number of cases of interpolation processing and the lengths of loss periods shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the interpolation unit <b>15</b> can determine loss periods to be subjected to interpolation processing.</p><p id="p-0118" num="0117">As described above, according to the second embodiment, the pieces of position information of the user are given metadata representing an attribute common to the pieces of position information, and calculation and interpolation processing of the action history of the user are performed based on the metadata of the pieces of position information. Therefore, it becomes possible to more accurately grasp the action history of the user in their daily life.</p><heading id="h-0015" level="1">Third Embodiment</heading><p id="p-0119" num="0118">Next, a third embodiment of the present invention will be described. Note that in the following description, the same components as those in the first and second embodiments described above are given the same reference numerals, and the description thereof will be omitted.</p><p id="p-0120" num="0119">The first and second embodiments have described a case where the time series of the action history of the user is obtained and the heart rate or the like measured by the sensor <b>105</b> attached to the user is presented together with the action history of the user. On the other hand, in the third embodiment, a specific activity performed by the user is estimated based on the biological information of the user measured by the sensor <b>105</b> and the action history of the user.</p><p id="p-0121" num="0120">Functional Blocks of Monitoring System</p><p id="p-0122" num="0121"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram illustrating a configuration of a monitoring system according to this embodiment. The monitoring system according to this embodiment is different from those in the first and second embodiments in that it further includes a third acquisition unit <b>19</b> that acquires sensor data from the sensor <b>105</b> and an estimation unit <b>20</b> that estimates the activity of the user. Hereinafter, configurations different from those of the first and second embodiments will be described mainly.</p><p id="p-0123" num="0122">As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the monitoring system includes the first acquisition unit <b>10</b>, the second acquisition unit <b>11</b>, the user identification unit <b>12</b>, the position identification unit <b>13</b>, the action history calculation unit <b>14</b>, the interpolation unit <b>15</b>, the storage unit <b>16</b>, the presentation unit <b>17</b>, the metadata giving unit <b>18</b>, the third acquisition unit <b>19</b>, and the estimation unit <b>20</b>.</p><p id="p-0124" num="0123">The third acquisition unit <b>19</b> acquires biological information of the user from the sensor <b>105</b> including, for example, a triaxial acceleration sensor and a heart rate monitor. The biological information includes physiological information such as the heart rate and blood pressure of the user, and physical information such as the acceleration and angular velocity of the user. The third acquisition unit <b>19</b> converts the acquired analog signal into a digital signal at a predetermined sampling rate. Further, the third acquisition unit <b>19</b> can perform well known signal processing such as noise removal and amplification for an acceleration signal, an electrocardiographic signal, and the like if necessary.</p><p id="p-0125" num="0124">The estimation unit <b>20</b> estimates the specific activity performed by the user based on the biological information of the user acquired by the third acquisition unit <b>19</b> and the action history of the user obtained by the action history calculation unit <b>14</b>.</p><p id="p-0126" num="0125">For example, when a heart rate monitor and an acceleration sensor are used as the sensor <b>105</b> and when the position of the user for a certain period according to the action history obtained by the action history calculation unit <b>14</b> was, for example, in a living room in the facility, it is assumed that the heart rate of the user exceeded a predetermined threshold (e.g., 120 [bpm]) and the state continued for 5 minutes or more. In general, it is considered that a user often rests in a living room, but, for example, in a hospital or a long-term care site, it is rather more natural to recognize that the user is getting exercise such as some kind of activity. For example, it is also possible to think that the user is performing voluntary training or recreational activity in the living room.</p><p id="p-0127" num="0126">Therefore, the metadata of the specific activity, such as &#x201c;exercise&#x201d;, of the user is stored in advance in the storage unit <b>16</b>. The storage unit <b>16</b> can store, for example, the position in the facility (e.g., a living room), a heart rate threshold (120 [bpm]), and the duration (e.g., 5 [minutes]) of the state in which the heart rate exceeds the threshold at that position in association with each other. The specific activity of the user is not limited to &#x201c;exercise&#x201d;, and it is possible to generate metadata about a desired activity of the user such as &#x201c;sleep&#x201d; or &#x201c;walking&#x201d; into which &#x201c;exercise&#x201d; is further classified, and store it in the storage unit <b>16</b> in advance.</p><p id="p-0128" num="0127">The estimation unit <b>20</b> refers to the storage unit <b>16</b> to estimate the occurrence of the specific activity such as &#x201c;exercise&#x201d;, the period of occurrence of the specific activity, and the frequency of occurrence from the action history of the user and the biological information of the user. Using the above specific example, the estimation unit <b>20</b> estimates from the action history of the user that the user performed &#x201c;exercise&#x201d; for 6 minutes once in the living room when the heart rate exceeded 120 [bpm] for 6 minutes while the user is in the living room.</p><p id="p-0129" num="0128">The presentation unit <b>17</b> displays an estimation result by the estimation unit <b>20</b> on, for example, the display screen of the display device <b>109</b>.</p><p id="p-0130" num="0129">Monitoring Method</p><p id="p-0131" num="0130">Next, operation of the monitoring system having the above-described configuration will be described using a flowchart in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. In the following, user information (e.g., the user's name or patient ID) and unique identification information (e.g., a MAC address or an IP address) of the wearable device attached to the user are registered in the storage unit <b>16</b>.</p><p id="p-0132" num="0131">Further, the storage unit <b>16</b> stores identification information (e.g., a MAC address or an IP address) of a point arranged at a fixed position in the facility or the relay terminal device <b>300</b> and information indicating the arrangement position (e.g., the name such as &#x201c;cafeteria&#x201d; or &#x201c;living room&#x201d;) in association with each other. Furthermore, the storage unit <b>16</b> stores position information (e.g., a &#x201c;living room&#x201d;) and conditions such as thresholds (e.g., 120 [bpm] for 5 minutes or more) set for biological information (e.g., the heart rate) of the user in association with each other as information indicating the occurrence of the specific activity, such as &#x201c;exercise&#x201d;, of the user. The storage unit <b>16</b> can store a different threshold for the biological information such as the heart rate depending on the position information.</p><p id="p-0133" num="0132">First, when the sensor <b>105</b> including a heart rate monitor and a triaxial acceleration sensor is attached to the user and measurement of the heart rate and triaxial acceleration of the user is started, the following processing is executed.</p><p id="p-0134" num="0133">First, the third acquisition unit <b>19</b> acquires the biological information of the user from the sensor <b>105</b> (step S<b>1</b><i>n</i>). The third acquisition unit <b>19</b> performs signal processing of the acquired biological information including the heart rate and triaxial acceleration of the user to output a time series of the biological information.</p><p id="p-0135" num="0134">Next, the first acquisition unit <b>10</b> acquires the identification information unique to the user (step S<b>11</b>). Then, the second acquisition unit <b>11</b> acquires the position information of the user (step S<b>12</b>). For example, the second acquisition unit <b>11</b> can acquire the position information of the user at a preset cycle.</p><p id="p-0136" num="0135">Next, the user identification unit <b>12</b> identifies the user from the identification information of the user acquired by the first acquisition unit <b>10</b> (step S<b>13</b>). Next, the position identification unit <b>13</b> identifies the position of the user from the position information acquired by the second acquisition unit <b>11</b> (step S<b>14</b>).</p><p id="p-0137" num="0136">Next, the action history calculation unit <b>14</b> obtains the action history of the user (step S<b>15</b>). More specifically, the action history calculation unit <b>14</b> calculates the frequency at which and the period for which the user stayed at the identified position in the facility.</p><p id="p-0138" num="0137">Thereafter, the estimation unit <b>20</b> estimates the specific activity performed by the user based on the action history of the user obtained in step S<b>15</b> and the biological information of the user acquired in step S<b>1</b><i>n </i>(step S<b>16</b>). For example, when a period of 5 minutes for which the heart rate exceeded the threshold (120 [bpm]) is detected in the period during which the user stayed in the living room, the estimation unit <b>20</b> estimates that the user performed &#x201c;exercise&#x201d;, which is the specific activity. Thus, the estimation unit <b>20</b> outputs an estimation result indicating that the user performed &#x201c;exercise&#x201d; for 5 minutes once.</p><p id="p-0139" num="0138">The estimation unit <b>20</b> can also estimate that the user performed the specific activity based not only on the biological information such as the heart rate but also on the acceleration of the user measured by the triaxial acceleration sensor, for example. Hereinafter, a case will be described as an example where it is estimated that the user performed the specific activity based on the acceleration of the user and the action history of the user.</p><p id="p-0140" num="0139">The estimation unit <b>20</b> obtains the average value or standard deviation per unit time of the acceleration amplitudes in the three axes of the user or the norm of the acceleration values in the three axes acquired by the third acquisition unit <b>19</b> from the sensor <b>105</b> including the triaxial acceleration sensor as body motion, and, when these values have exceeded a set threshold, estimates, for example, that the user is performing &#x201c;exercise&#x201d;. In this case, the storage unit <b>16</b> stores the position information in the facility, the magnitude of the body motion of the user, and the estimated activity such as &#x201c;exercise&#x201d; or an activity into which &#x201c;exercise&#x201d; is further classified in association with each other. For example, it is possible to use &#x201c;mild exercise&#x201d;, &#x201c;moderate exercise&#x201d;, and &#x201c;intense exercise&#x201d;, into which &#x201c;exercise&#x201d; is classified by levels according to the magnitude of body motion.</p><p id="p-0141" num="0140">Further, even when the body motions having the same magnitude are calculated, the actual activities of the user may differ depending on whether the user is in the rehabilitation room or the washroom. For example, even in a case where &#x201c;intense exercise&#x201d; is estimated from the value of the body motion when the position of the user is in the rehabilitation room according to the action history of the user, &#x201c;the possibility of falling down&#x201d; can be estimated when the position of the user is in the washroom.</p><p id="p-0142" num="0141">For example, <figref idref="DRAWINGS">FIG. <b>13</b></figref> shows the magnitude [G] of body motion of the user at the measurement time. The example in <figref idref="DRAWINGS">FIG. <b>13</b></figref> shows body motions corresponding to activities of the user that occurred while the user was lying in bed. In the example of <figref idref="DRAWINGS">FIG. <b>13</b></figref>, a body motion at about 1.5 [G] is measured for rolling over, and a body motion at about 5 [G] is measured for falling from the bed. For example, when a body motion exceeding 5 [G] occurred once while the user was sleeping in the hospital room, even if a body motion equivalent to &#x201c;exercise&#x201d; occurred, it is presumed that exercise contrary to the intention of the user, such as falling from the bed, occurred rather than &#x201c;exercise&#x201d; from their own will.</p><p id="p-0143" num="0142">In this way, the estimation unit <b>20</b> estimates that the user performed the specific activity and its frequency and period based on the position information of the user and the magnitude of body motion. Further, the estimation unit <b>20</b> may make an estimation in consideration of the user's life at night and in the daytime by further using time information measured by the clock <b>107</b>.</p><p id="p-0144" num="0143">To give another example, the estimation unit <b>20</b> can calculate the user's posture from the accelerations in the three axes of the user, and estimate that the user is performing the specific activity from the action history of the user and a change in the posture. More specifically, the sensor <b>105</b> measures the accelerations in three directions along the XYZ axes that are orthogonal to each other, as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. The third acquisition unit <b>19</b> acquires the accelerations measured by the sensor <b>105</b> at a sampling rate of, for example, 25 Hz to obtain time series of accelerations.</p><p id="p-0145" num="0144">The estimation unit <b>20</b> calculates the user's posture from the accelerations in the three axes of the user acquired by the third acquisition unit <b>19</b>. More specifically, the estimation unit <b>20</b> obtains the angle of tilt of the user's upper body from the accelerations of the user. The estimation unit <b>20</b> calculates, for example, the tilts &#x3b8; and &#x3d5; [degrees] of the sensor <b>105</b> on the accelerations with respect to the gravitational acceleration, as disclosed in Reference <b>1</b> (International Publication No. WO 2018139398). Here, &#x3b8; (&#x2212;90&#x2264;&#x3b8;&#x3c;270) is the tilt of the Z-axis of the sensor <b>105</b> with respect to the vertical direction, and &#x3d5; (&#x2212;90&#x2264;&#x3d5;&#x3c;270) is the tilt of the X-axis of the sensor <b>105</b> with respect to the vertical direction.</p><p id="p-0146" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mi>Expressions</mi>  <mo>&#x2062;</mo>  <mtext>   </mtext>  <mrow>   <mo>(</mo>   <mn>1</mn>   <mo>)</mo>  </mrow>  <mo>&#x2062;</mo>  <mtext>   </mtext>  <mi>and</mi>  <mo>&#x2062;</mo>  <mtext>   </mtext>  <mrow>   <mo>(</mo>   <mn>2</mn>   <mo>)</mo>  </mrow> </mrow></math></maths><maths id="MATH-US-00001-2" num="00001.2"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>&#x3b8;</mi>      <mo>=</mo>      <mrow>       <mrow>        <mfrac>         <mn>180</mn>         <mi>&#x3c0;</mi>        </mfrac>        <mo>&#x2062;</mo>        <mrow>         <msup>          <mi>cos</mi>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </msup>         <mo>(</mo>         <mfrac>          <msub>           <mi>A</mi>           <mi>z</mi>          </msub>          <msqrt>           <mrow>            <msubsup>             <mi>A</mi>             <mi>x</mi>             <mn>2</mn>            </msubsup>            <mo>+</mo>            <msubsup>             <mi>A</mi>             <mi>y</mi>             <mn>2</mn>            </msubsup>            <mo>+</mo>            <msubsup>             <mi>A</mi>             <mi>z</mi>             <mn>2</mn>            </msubsup>           </mrow>          </msqrt>         </mfrac>         <mo>)</mo>        </mrow>       </mrow>       <mo>+</mo>       <mrow>        <mn>90</mn>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mo>&#x2026;</mo>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <mo>(</mo>         <mrow>          <mrow>           <mi>for</mi>           <mo>&#x2062;</mo>           <mtext>   </mtext>           <msub>            <mi>A</mi>            <mi>y</mi>           </msub>          </mrow>          <mo>&#x2265;</mo>          <mn>0</mn>         </mrow>         <mo>)</mo>        </mrow>       </mrow>      </mrow>     </mrow>     <mo>&#x2062;</mo>     <mtext></mtext>     <mrow>      <mi>&#x3b8;</mi>      <mo>=</mo>      <mrow>       <mrow>        <mrow>         <mo>-</mo>         <mfrac>          <mn>180</mn>          <mi>&#x3c0;</mi>         </mfrac>        </mrow>        <mo>&#x2062;</mo>        <mrow>         <msup>          <mi>cos</mi>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </msup>         <mo>(</mo>         <mfrac>          <msub>           <mi>A</mi>           <mi>z</mi>          </msub>          <msqrt>           <mrow>            <msubsup>             <mi>A</mi>             <mi>x</mi>             <mn>2</mn>            </msubsup>            <mo>+</mo>            <msubsup>             <mi>A</mi>             <mi>y</mi>             <mn>2</mn>            </msubsup>            <mo>+</mo>            <msubsup>             <mi>A</mi>             <mi>z</mi>             <mn>2</mn>            </msubsup>           </mrow>          </msqrt>         </mfrac>         <mo>)</mo>        </mrow>       </mrow>       <mo>+</mo>       <mrow>        <mn>90</mn>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mo>&#x2026;</mo>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <mo>(</mo>         <mrow>          <mrow>           <mi>for</mi>           <mo>&#x2062;</mo>           <mtext>   </mtext>           <mi>Ay</mi>          </mrow>          <mo>&#x3c;</mo>          <mn>0</mn>         </mrow>         <mo>)</mo>        </mrow>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00001-3" num="00001.3"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>&#x3d5;</mi>      <mo>=</mo>      <mrow>       <mrow>        <mfrac>         <mn>180</mn>         <mi>&#x3c0;</mi>        </mfrac>        <mo>&#x2062;</mo>        <mrow>         <msup>          <mi>cos</mi>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </msup>         <mo>(</mo>         <mfrac>          <msub>           <mi>A</mi>           <mi>x</mi>          </msub>          <msqrt>           <mrow>            <msubsup>             <mi>A</mi>             <mi>x</mi>             <mn>2</mn>            </msubsup>            <mo>+</mo>            <msubsup>             <mi>A</mi>             <mi>y</mi>             <mn>2</mn>            </msubsup>            <mo>+</mo>            <msubsup>             <mi>A</mi>             <mi>z</mi>             <mn>2</mn>            </msubsup>           </mrow>          </msqrt>         </mfrac>         <mo>)</mo>        </mrow>       </mrow>       <mo>+</mo>       <mrow>        <mn>90</mn>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mo>&#x2026;</mo>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <mo>(</mo>         <mrow>          <mrow>           <mi>for</mi>           <mo>&#x2062;</mo>           <mtext>   </mtext>           <msub>            <mi>A</mi>            <mi>y</mi>           </msub>          </mrow>          <mo>&#x2265;</mo>          <mn>0</mn>         </mrow>         <mo>)</mo>        </mrow>       </mrow>      </mrow>     </mrow>     <mo>&#x2062;</mo>     <mtext></mtext>     <mrow>      <mi>&#x3d5;</mi>      <mo>=</mo>      <mrow>       <mrow>        <mfrac>         <mn>180</mn>         <mi>&#x3c0;</mi>        </mfrac>        <mo>&#x2062;</mo>        <mrow>         <msup>          <mi>cos</mi>          <mrow>           <mo>-</mo>           <mn>1</mn>          </mrow>         </msup>         <mo>(</mo>         <mfrac>          <msub>           <mi>A</mi>           <mi>x</mi>          </msub>          <msqrt>           <mrow>            <msubsup>             <mi>A</mi>             <mi>x</mi>             <mn>2</mn>            </msubsup>            <mo>+</mo>            <msubsup>             <mi>A</mi>             <mi>y</mi>             <mn>2</mn>            </msubsup>            <mo>+</mo>            <msubsup>             <mi>A</mi>             <mi>z</mi>             <mn>2</mn>            </msubsup>           </mrow>          </msqrt>         </mfrac>         <mo>)</mo>        </mrow>       </mrow>       <mo>+</mo>       <mrow>        <mn>90</mn>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mo>&#x2026;</mo>        <mo>&#x2062;</mo>        <mtext>   </mtext>        <mrow>         <mo>(</mo>         <mrow>          <mrow>           <mi>for</mi>           <mo>&#x2062;</mo>           <mtext>   </mtext>           <mi>Ay</mi>          </mrow>          <mo>&#x3c;</mo>          <mn>0</mn>         </mrow>         <mo>)</mo>        </mrow>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0147" num="0145">Ax, Ay, and Az are the accelerations in the X, Y, and Z-axis directions measured by the sensor <b>105</b>, respectively, and the unit is the gravitational acceleration G (1.0 G&#x2248;9.8 m/s<sup>2</sup>). In Expressions (1) and (2), by obtaining the ratio of the measured value in a single axis with respect to the norm, which is the magnitude of the composite vector of the accelerations in the X, Y, and Z axis directions measured by the sensor <b>105</b>, and further obtaining the inverse function of the cosine, the tilt of the sensor <b>105</b> (the sensor terminal device <b>200</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>) is calculated as a value having the dimension of angle.</p><p id="p-0148" num="0146">The estimation unit <b>20</b> determines the user's posture from the obtained tilts of the sensor <b>105</b>. For example, the estimation unit <b>20</b> determines the posture by comparing the values of &#x3b8; and &#x3d5; calculated by Expressions (1) and (2) with thresholds. The tilt of the sensor <b>105</b> reflects the tilt of the upper body of the user wearing the sensor terminal device <b>200</b> (the sensor <b>105</b>) equipped with the sensor <b>105</b>.</p><p id="p-0149" num="0147">The estimation unit <b>20</b> can determine the user's posture using the division of the ranges of values of &#x3b8; and &#x3d5; into cases described in Reference <b>1</b>. Specifically, the values of &#x3b8; and &#x3d5; are classified so that the user's posture is classified into six types: upright, inverted, supine, prone, right lateral recumbent, and left lateral recumbent. For example, the estimation unit <b>20</b> determines that the user is in supine posture when [130&#x2264;&#x3d5;&#x2264;230] and [&#x2212;40&#x2264;&#x3b8;&#x3c;30], or when [1.30&#x2264;&#x3d5;&#x2264;230] and [140&#x3c;&#x3b8;&#x3c;220].</p><p id="p-0150" num="0148">Further, the estimation unit <b>20</b> determines that the user's posture is upright when [30&#x2264;&#x3b8;&#x3c;140].</p><p id="p-0151" num="0149">Alternatively, the estimation unit <b>20</b> can also determine the user's posture by classifying the values of &#x3b8; and &#x3d5; into two types: a wake-up state and a lying-down state.</p><p id="p-0152" num="0150"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram showing changes in posture when the user's posture is classified into six types. <figref idref="DRAWINGS">FIG. <b>14</b></figref> shows changes in posture when the user is lying on the bed and resting, and &#x201c;a&#x201d; indicates a change in posture when the user rolled over. &#x201c;b&#x201d; indicates a change in posture when the user fell from the bed, and &#x201c;c&#x201d; indicates a change in posture when the user performed a rising action.</p><p id="p-0153" num="0151">As shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, when the user performs a rising action (&#x201c;c&#x201d; in <figref idref="DRAWINGS">FIG. <b>14</b></figref>), the posture transitions from supine to upright. On the other hand, at the time of rolling over (&#x201c;a&#x201d; in <figref idref="DRAWINGS">FIG. <b>14</b></figref>), it transitions from supine to prone or from prone to supine. From this, it is possible to distinguish and estimate a specific motion of the user such as rolling over or rising based on the change pattern of the posture.</p><p id="p-0154" num="0152">The estimation unit <b>20</b> estimates that the user performed a specific action when the change in the user's posture has a set change pattern. Furthermore, when the change in the user's posture became the change pattern of a specific posture at a specific position at a certain frequency according to the action history of the user, the estimation unit <b>20</b> estimates the occurrence of a particular exercise corresponding to the change pattern of the posture and its period and frequency.</p><p id="p-0155" num="0153">For example, when the user's posture has changed from supine to upright ten times in the rehabilitation room, the estimation unit <b>20</b> can estimate that the user is performing &#x201c;rehabilitation exercise&#x201d; in the rehabilitation room, and can further output the period and frequency of occurrence of the changes in posture.</p><p id="p-0156" num="0154">In this way, the estimation unit <b>20</b> estimates that the user performed the specific activity based on the biological information of the user and the position information of the user.</p><p id="p-0157" num="0155"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram showing the entire monitoring system according to this embodiment, which includes the sensor terminal device <b>200</b> implemented by a wearable device attached to the user, the relay terminal device <b>300</b>, and the external terminal device <b>400</b>. The relay terminal device <b>300</b> receives the biological information of the user and the identification information unique to the sensor terminal device <b>200</b> from the sensor terminal device <b>200</b>, and transmits them to the external terminal device <b>400</b>. The external terminal device <b>400</b> receives the identification information of the relay terminal device <b>300</b>, the biological information of the user, and the identification information of the sensor terminal device <b>200</b> from the relay terminal device <b>300</b> via the communication network NW, and estimates the action history of the user and the activity of the user.</p><p id="p-0158" num="0156">The specific activity and the action history of the user estimated by the external terminal device <b>400</b> can be presented to, for example, a communication terminal device such as an external smart speaker or a smartphone. As shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, in a medical care facility and a long-term care facility, medical care staffs and long-term care staffs responsible for the treatment and care for the user can grasp the estimated user's activity and action history. From the estimated user's activity and user's action history, the medical care staffs and long-term care staffs can give more concrete and appropriate guidance for improving their life when trying to increase the amount of activity of the user, for example.</p><p id="p-0159" num="0157">As described above, according to the third embodiment, it is estimated that the user performed the specific activity based on the biological information of the user measured by the sensor <b>105</b> and the action history of the user. For example, it is possible not only to estimate occurrence of the specific activity, which is more likely to occur when the user stays in a room where the specific activity is performed such as a rehabilitation room, but also to estimate that the user is performing the specific activity such as exercise even in a place where exercise is not performed originally.</p><p id="p-0160" num="0158">Note that in the third embodiment described above as well, the interpolation unit <b>15</b> can perform the interpolation processing of the action history. Furthermore, the action history can be obtained based on the metadata given to the position information by the metadata giving unit <b>18</b>.</p><p id="p-0161" num="0159">Further, the above-described embodiments have illustrated and described cases where one sensor terminal device <b>200</b> is provided. However, there may be a plurality of users.</p><p id="p-0162" num="0160">Although the monitoring system, the monitoring method, and the monitoring program of embodiments of the present invention have been described above, the present invention is not limited to the described embodiments, and it is possible to make various modifications that can be envisaged by those skilled in the art within the scope of the invention described in the claims. For example, the first to third embodiments described above can be implemented in any combination. Further, the order of the steps of the monitoring method is not limited to the order described above.</p><heading id="h-0016" level="1">REFERENCE SIGNS LIST</heading><p id="p-0163" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0000">    <ul id="ul0003" list-style="none">        <li id="ul0003-0001" num="0161"><b>10</b> First acquisition unit</li>        <li id="ul0003-0002" num="0162"><b>11</b> Second acquisition unit</li>        <li id="ul0003-0003" num="0163"><b>12</b> User identification unit</li>        <li id="ul0003-0004" num="0164"><b>13</b> Position identification unit</li>        <li id="ul0003-0005" num="0165"><b>14</b> Action history calculation unit</li>        <li id="ul0003-0006" num="0166"><b>15</b> Interpolation unit</li>        <li id="ul0003-0007" num="0167"><b>16</b>, <b>203</b>, <b>302</b>, <b>403</b> Storage unit</li>        <li id="ul0003-0008" num="0168"><b>17</b>, <b>404</b> Presentation unit, data analysis unit</li>        <li id="ul0003-0009" num="0169"><b>12</b>, <b>304</b> Imaging control unit</li>        <li id="ul0003-0010" num="0170"><b>13</b>, <b>402</b> Imaging data acquisition unit</li>        <li id="ul0003-0011" num="0171"><b>101</b> Bus</li>        <li id="ul0003-0012" num="0172"><b>102</b> Processor</li>        <li id="ul0003-0013" num="0173"><b>103</b> Main storage device</li>        <li id="ul0003-0014" num="0174"><b>104</b> Communication I/F</li>        <li id="ul0003-0015" num="0175"><b>105</b>, <b>201</b> Sensor</li>        <li id="ul0003-0016" num="0176"><b>106</b> Auxiliary storage device</li>        <li id="ul0003-0017" num="0177"><b>107</b> Clock</li>        <li id="ul0003-0018" num="0178"><b>108</b> Input/output I/O</li>        <li id="ul0003-0019" num="0179"><b>109</b> Display device</li>        <li id="ul0003-0020" num="0180"><b>200</b> Sensor terminal device</li>        <li id="ul0003-0021" num="0181"><b>202</b> Sensor data acquisition unit</li>        <li id="ul0003-0022" num="0182"><b>300</b> Relay terminal device</li>        <li id="ul0003-0023" num="0183"><b>400</b> External terminal device</li>        <li id="ul0003-0024" num="0184"><b>204</b>, <b>303</b>, <b>404</b> Transmission unit</li>        <li id="ul0003-0025" num="0185"><b>301</b>, <b>401</b> Reception unit</li>        <li id="ul0003-0026" num="0186"><b>402</b> Data analysis unit</li>    </ul>    </li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001 MATH-US-00001-2 MATH-US-00001-3" nb-file="US20230000351A1-20230105-M00001.NB"><img id="EMI-M00001" he="39.12mm" wi="76.20mm" file="US20230000351A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-001-8" num="001-8"><claim-text><b>1</b>-<b>8</b>. (canceled)</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A monitoring system comprising:<claim-text>a first acquirer configured to acquire identification information unique to a user;</claim-text><claim-text>a second acquirer configured to acquire position information of the user;</claim-text><claim-text>a calculator configured to obtain an action history of the user from the identification information of the user acquired by the first acquirer and the position information acquired by the second acquirer; and</claim-text><claim-text>a presenter configured to present the action history of the user calculated by the calculator, wherein the action history comprises a period for which or a frequency at which the user stayed at a position indicated by the position information.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The monitoring system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising an interpolator configured to, when a loss period of data is included in the action history of the user obtained by the calculator and the position information of the user immediately before the loss period matches the position information of the user immediately after the loss period, interpolate the action history of the user including the loss period based on the matched position information.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The monitoring system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the presenter is configured to present the action history of the user interpolated by the interpolator.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The monitoring system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising a metadata provider configured to give metadata describing an attribute representing the position information to the position information, wherein the calculator is configured to calculate the action history of the user based on the identification information of the user acquired by the first acquirer and the metadata given to the position information acquired by the second acquirer.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The monitoring system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising:<claim-text>a sensor data acquirer is configured to acquire biological information of the user; and</claim-text><claim-text>an estimator configured to estimate a specific activity performed by the user based on the acquired biological information and the action history of the user.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The monitoring system according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the presenter is configured to present an estimation result by the estimator.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A monitoring system comprising:<claim-text>a sensor terminal device configured to be attached to a user and to output first identification information to outside, wherein the first identification information is unique to the sensor terminal device;</claim-text><claim-text>a relay terminal device configured to be arranged at a predetermined position within an area, to receive the first identification information output from the sensor terminal device, and to output the first identification information and second identification information to the outside, wherein the second identification information is unique to the relay terminal device; and</claim-text><claim-text>an external terminal device configured to receive the first identification information and the second identification information output from the relay terminal device and to store the first identification information and the second identification information in a storage device, wherein the external terminal device comprises:<claim-text>a first acquirer configured to acquire the first identification information as identification information unique to the user;</claim-text><claim-text>a second acquirer configured to acquire the second identification information as position information of the user;</claim-text><claim-text>a calculator configured to obtain an action history of the user from the identification information of the user acquired by the first acquirer and the position information acquired by the second acquirer; and</claim-text><claim-text>a presenter configured to present the action history of the user obtained by the calculator, wherein the action history comprises at least one of a period for which or a frequency at which the user stayed at a position indicated by the position information.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A monitoring method comprising:<claim-text>acquiring identification information unique to a user;</claim-text><claim-text>acquiring position information of the user;</claim-text><claim-text>obtaining an action history of the user from the identification information of the user and the position information; and</claim-text><claim-text>presenting the action history of the user, wherein the action history comprises at least one of a period for which or a frequency at which the user stayed at a position indicated by the position information.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The monitoring method according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising, when a loss period of data is included in the action history of the user and the position information of the user immediately before the loss period matches the position information of the user immediately after the loss period, interpolating the action history of the user including the loss period based on the matched position information.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The monitoring method according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein presenting the action history of the user comprises presenting the interpolated action history of the user.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A monitoring program for causing a computer to execute the monitoring method according to <claim-ref idref="CLM-00016">claim 16</claim-ref>.</claim-text></claim></claims></us-patent-application>
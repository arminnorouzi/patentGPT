<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007168A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007168</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17854954</doc-number><date>20220630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-110512</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23222</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23219</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180801</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232933</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">IMAGING APPARATUS, METHOD FOR CONTROLLING IMAGING APPARATUS, RECORDING MEDIUM, AND INFORMATION PROCESSING APPARATUS</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>CANON KABUSHIKI KAISHA</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Kamba</last-name><first-name>Masaki</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system control unit controls an imaging operation of an imaging unit based on an instruction from a user. Further, the system control unit detects a subject in an imaging range, The system control unit records the contents of the control of the operation of the imaging unit based on the instruction from the user in chronological order as operation information. The system control unit records information corresponding to a result of the detection of the subject in chronological order as detection information in association with the operation information. The system control unit reproduces the contents of the control of the operation of the imaging unit in chronological order based on the recorded operation information. Further, the system control unit controls a speed of the reproduction based on the recorded information.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="93.64mm" wi="156.04mm" file="US20230007168A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="132.59mm" wi="154.43mm" file="US20230007168A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="152.91mm" wi="158.24mm" file="US20230007168A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="135.64mm" wi="105.49mm" file="US20230007168A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="192.62mm" wi="119.04mm" file="US20230007168A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="175.94mm" wi="119.21mm" file="US20230007168A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="130.39mm" wi="122.09mm" file="US20230007168A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="176.53mm" wi="146.13mm" file="US20230007168A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="191.35mm" wi="124.38mm" file="US20230007168A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="219.37mm" wi="119.04mm" file="US20230007168A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="230.04mm" wi="134.45mm" file="US20230007168A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="107.78mm" wi="158.07mm" file="US20230007168A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="159.60mm" wi="105.66mm" file="US20230007168A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND OF THE DISCLOSURE</heading><heading id="h-0002" level="1">Field of the Disclosure</heading><p id="p-0002" num="0001">The present disclosure relates to an imaging apparatus, a method for controlling an imaging apparatus, a recording medium, and an information processing apparatus.</p><heading id="h-0003" level="1">Description of the Related Art</heading><p id="p-0003" num="0002">As the market of streaming services has increased in recent years, various systems for imaging events such as weddings and lectures using imaging apparatuses (e.g., network cameras) capable of capturing moving images by remote control via a network have been developed. Particularly imaging apparatuses that can be operated remotely from a mobile terminal such as a smartphone or a personal computer (PC) by installing an application into the mobile terminal or the PC have been developed in recent years. An example of remote operations is pan/tilt/zoom (PTZ) operations of an imaging apparatus. Further, the imaging apparatuses include a preset function of controlling an angle of view to a preset angle of view and/or a trace function of reproducing an operation based on an operation received from a user at a subsequent time by recording information about the received operation. Japanese Patent No. 4745769 discusses an example of a technology for automatically tracking a subject by camera platform operations.</p><p id="p-0004" num="0003">Meanwhile, in reproducing operations of an imaging apparatus under a situation where the operations of the imaging apparatus are controlled correspondingly to a movement of a subject using the trace function, the subject may not move in the same way as in the recording of the operations of the imaging apparatus. In this case, it is sometimes difficult to control the operations of the imaging apparatus correspondingly to the movement of the subject of interest as in the recording of the operations of the imaging apparatus in reproducing the operations of the imaging apparatus.</p><heading id="h-0004" level="1">SUMMARY OF THE DISCLOSURE</heading><p id="p-0005" num="0004">According to an aspect of the present disclosure, in order to reproduce a previously-performed imaging operation at a subsequent time in a more suitable form for a subject movement at that time, an imaging apparatus includes an imaging unit, a control unit configured to control an imaging operation of the imaging unit based on an instruction from a user, a detection unit configured to detect a subject in an imaging range of the imaging unit, a first recording unit configured to record contents of the control of the operation of the imaging unit based on the instruction from the user in chronological order as first information, a second recording unit configured to record information corresponding to a result of the detection of the subject in chronological order as second information in association with the first information, and a reproduction unit configured to reproduce the contents of the control of the operation of the imaging unit in chronological order based on the first information, wherein the reproduction unit controls a speed of the reproduction based on the second information.</p><p id="p-0006" num="0005">Further features of the present disclosure will become apparent from the following description of exemplary embodiments with reference to the attached drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a view illustrating an example of a system configuration of an imaging system.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of a configuration of an imaging apparatus.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of a configuration of a client apparatus.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example of a trace recording process.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating an example of a trace reproduction process.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a view illustrating an example of a use case of an imaging system.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> are diagrams illustrating an example of a change in subject movement in trace reproduction.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> are views illustrating an example of an angle of view of an imaging apparatus.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of a process of an imaging system.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart illustrating an example of a process of an imaging system.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a view illustrating an example of a user interface (UI) of an imaging system.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a view illustrating an example of a UI of an imaging system.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF THE EMBODIMENTS</heading><p id="p-0019" num="0018">Various exemplary embodiments of the present disclosure will be described in detail below with reference to the attached drawings.</p><p id="p-0020" num="0019">Components having substantially the same function and/or configuration are given the same reference numeral in the present specification and the drawings to omit redundant descriptions thereof.</p><heading id="h-0007" level="2">&#x3c;System Configuration&#x3e;</heading><p id="p-0021" num="0020">An example of a system configuration of an imaging system according to an exemplary embodiment of the present disclosure will be described below with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The imaging system according to the present exemplary embodiment includes an imaging apparatus <b>101</b> and a terminal apparatus <b>102</b>. The terminal apparatus <b>102</b> is used to control operations of the imaging apparatus <b>101</b>. The imaging apparatus <b>101</b> and the terminal apparatus <b>102</b> are connected to transmit and receive information to and from each other via a network <b>105</b>. Further, the plurality of terminal apparatuses <b>102</b> can be connected to the imaging apparatus <b>101</b> via the network <b>105</b>. Further, a controller <b>104</b> can be applied in place of at least part of the terminal apparatuses <b>102</b>. Further, an input apparatus <b>103</b> for receiving operations of controlling the operation of the imaging apparatus <b>101</b> from a user can be connected to at least part of the terminal apparatuses <b>102</b>.</p><p id="p-0022" num="0021">The imaging apparatus <b>101</b> can image portions in an imaging range based on an instruction from another apparatus (e.g., terminal apparatus <b>102</b>, or controller <b>104</b>) via the network <b>105</b>. Further, the imaging apparatus <b>101</b> can control the imaging condition (e.g., focus, aperture, shutter speed, or gain) based on an instruction from another apparatus via the network <b>105</b>. Further, the imaging apparatus <b>101</b> can transmit still image data and/or moving image data corresponding to imaging results to another apparatus based on an instruction from the other apparatus via the network <b>105</b>. Hereinafter, unless specifically discriminated, a still image and a moving image are each referred to also as &#x201c;image&#x201d; for convenience.</p><p id="p-0023" num="0022">Further, hereinafter, unless specifically discriminated, still image data and moving image data are each referred to also as &#x201c;image data&#x201d; for convenience.</p><p id="p-0024" num="0023">The terminal apparatus <b>102</b> is realized by an information processing apparatus having a communication function, such as a personal computer (PC), a tablet terminal, or a smartphone. Further, the terminal apparatus <b>102</b> includes an output device, such as a display, and an input device, such as a touch panel. The output device presents information to the user, and the input apparatus receives instructions from the user. At least one of the output device and the input device can be realized as an external device attached to the terminal apparatus <b>102</b>.</p><p id="p-0025" num="0024">For example, the input apparatus <b>103</b> is an example of an external input device attached to the terminal apparatus <b>102</b>. The input apparatus <b>103</b> can be connected to the terminal apparatus <b>102</b> via, for example, a universal serial bus (USB) or Bluetooth&#xae; transmission path. An input apparatus such as a joystick for realizing smooth pan/tilt/zoom (PTZ) operations that are difficult to realize singly with a graphical user interface (GUI) presented by an application can be applied to the input apparatus <b>103</b>.</p><p id="p-0026" num="0025">The controller <b>104</b> schematically illustrates hardware including an input interface for operating the imaging apparatus <b>101</b>. While the controller <b>104</b> is connected to the imaging apparatus <b>101</b> via the network <b>105</b> in the example illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, this is not necessarily intended to limit a connection method between the controller <b>104</b> and the imaging apparatus <b>101</b>. Specifically, for example, the controller <b>104</b> can be connected to the imaging apparatus <b>101</b> using a connection method such as a serial connection.</p><p id="p-0027" num="0026">The network <b>105</b> is not particularly limited and can be of any type via which the imaging apparatus <b>101</b> can establish communication with the terminal apparatus <b>102</b> and the controller <b>104</b>. Specifically, for example, a network compliant with a communication standard such as Ethernet&#xae; can be applied to the network <b>105</b>. In this case, the network <b>105</b> can be realized by a router, a switch, and a cable that are compliant with the communication standard. Further, as another example, a network that is compliant with a wireless communication standard such as Wi-Fi&#xae;, Bluetooth&#xae;, Long Term Evolution (LIE), or fifth generation (5G) can be applied to the network <b>105</b>. Further, the network <b>105</b> can be realized by a plurality of networks. In this case, the plurality of networks can include two or more networks of different types from each other. Further, the imaging apparatus <b>101</b> can communicate with the terminal apparatus <b>102</b> and the controller <b>104</b> via another communication apparatus.</p><p id="p-0028" num="0027">The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a mere example and is not necessarily intended to limit the system configuration of the imaging system according to the present exemplary embodiment. Specifically, for example, the imaging apparatus <b>101</b> can be realized as a stand-alone apparatus. In this case, the imaging apparatus <b>101</b> can be provided with an input device for receiving instructions from the user and an output device for presenting information to the user. Further, even in this case, at least one of the input device and the output device can be realized as an external device attached to the imaging apparatus <b>101</b>.</p><heading id="h-0008" level="2">&#x3c;Configuration&#x3e;</heading><p id="p-0029" num="0028">An example of a configuration of the imaging system according to the present exemplary embodiment will be described below with a focus on particularly each of the imaging apparatus <b>101</b> and the terminal apparatus <b>102</b>.</p><p id="p-0030" num="0029">First, an example of a configuration of the imaging apparatus <b>101</b> will be described below with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The imaging apparatus <b>101</b> includes a system control unit <b>201</b>, an imaging unit <b>202</b>, an image processing unit <b>203</b>, a lens driving unit <b>204</b>, an imaging angle-of-view control unit <b>205</b>, a focus control unit <b>206</b>, a pan driving unit <b>207</b>, a tilt driving unit <b>208</b>, and a pan/tilt control unit <b>209</b>. Further, the imaging apparatus <b>101</b> can include a storage unit <b>210</b> and a program memory <b>211</b>. Further, the imaging apparatus <b>101</b> can include a communication unit <b>220</b>.</p><p id="p-0031" num="0030">The system control unit <b>201</b> controls various operations (particularly, imaging operation) of the imaging apparatus <b>101</b> by instructing the components of the imaging apparatus <b>101</b>. The system control unit <b>201</b> can be realized by an arithmetic device such as a central processing unit (CPU) or a microprocessor unit (MPU).</p><p id="p-0032" num="0031">Further, the system control unit <b>201</b> can transmit and receive various types of information to and from other apparatuses (e.g., terminal apparatus <b>102</b>) via the network <b>105</b> by controlling operations of the communication unit <b>220</b> described below. Specifically, for example, the system control unit <b>201</b> can receive a control command relating to imaging from the terminal apparatus <b>102</b> via the network <b>105</b> and analyze the control command to perform processing based on the control command. Hereinafter, the control command relating to imaging is also referred to as &#x201c;camera control command&#x201d; for convenience.</p><p id="p-0033" num="0032">The camera control command includes a request command and a setting command. The request command is a command for requesting the imaging apparatus <b>101</b> to transmit image data and various setting values. The setting command is a command for specifying the setting values.</p><p id="p-0034" num="0033">For example, the system control unit <b>201</b> can receive a request command for transmitting image data from the terminal apparatus <b>102</b>. In this case, the system control unit <b>201</b> instructs the communication unit <b>220</b> to transmit image data generated by the image processing unit <b>203</b> to the terminal apparatus <b>102</b> via the network <b>105</b>.</p><p id="p-0035" num="0034">Further, as another example, the system control unit <b>201</b> can receive a request command for transmitting setting values relating to imaging, such as focus, zoom, pan, and tilt setting values, from the terminal apparatus <b>102</b>. In this case, the system control unit <b>201</b> can acquire the setting values specified by the request command from components managing the specified setting values and can instruct the communication unit <b>220</b> to transmit the acquired information to the terminal apparatus <b>102</b> via the network <b>105</b>. Examples of candidates for the components managing various setting values are the image processing unit <b>203</b>, the imaging angle-of-view control unit <b>205</b>, the focus control unit <b>206</b>, and the pan/tilt control unit <b>209</b>. Further, the system control unit <b>201</b> can transmit not only currently-set values but also, for example, settable range information about the values as setting value information relating to imaging to the terminal apparatus <b>102</b> via the network <b>105</b>.</p><p id="p-0036" num="0035">Further, the system control unit <b>201</b> can receive a setting command for specifying setting values relating to imaging from the terminal apparatus <b>102</b>. In this case, the system control unit <b>201</b> instructs components corresponding to the setting values specified by the setting command to perform control based on the specified setting values. Examples of candidates for the components are the image processing unit <b>203</b>, the imaging angle-of-view control unit <b>205</b>, the focus control unit <b>206</b>, and the pan/tilt control unit <b>209</b>. Further, the control of operations of, for example, the imaging unit <b>202</b>, the lens driving unit <b>204</b>, the pan driving unit <b>207</b>, and the tilt driving unit <b>208</b> by the components realizes the operation of the imaging apparatus <b>101</b> based on the setting values specified by the terminal apparatus <b>102</b>.</p><p id="p-0037" num="0036">The imaging unit <b>202</b> includes an imaging optical system, such as a lens, and an image sensor. An optical image (subject image) formed by the imaging optical system is guided to the image sensor and focused, and the image sensor photoelectrically converts the optical image into an electric signal. Then, for example, gain adjustment is performed on the electric signal (image signal) obtained by photoelectrically converting the optical image, and the resulting electric signal is converted from an analog signal to a digital signal by an analog/digital (A/D) converter. Then, the digital signal is output to the image processing unit <b>203</b>.</p><p id="p-0038" num="0037">The image processing unit <b>203</b> applies various types of image processing, resolution conversion processing, and compression encoding processing to the image signal output from the imaging unit <b>202</b> and generates image data. The image data generated by the image processing unit <b>203</b> can be stored in, for example, the storage unit <b>210</b> described below. Further, as another example, the image data can be transmitted to another apparatus (e.g., terminal apparatus <b>102</b>) via the network <b>105</b> by the communication unit <b>220</b>.</p><p id="p-0039" num="0038">The lens driving unit <b>204</b> includes a driving system and a motor. The driving system controls positions of at least some of a series of optical members of the imaging optical system of the imaging unit <b>202</b>. The motor is a driving source of the driving system. According to the present exemplary embodiment, the optical members that are a position control target of the lens driving unit <b>204</b> include an optical member for focus control (hereinafter, the optical member is also referred to as &#x201c;focus lens&#x201d;) and an optical member for angle-of-view control (hereinafter, the optical member is also referred to as &#x201c;zoom lens&#x201d;), Operations of the lens driving unit <b>204</b> are controlled by the imaging angle-of-view control unit <b>205</b> and the focus control unit <b>206</b>.</p><p id="p-0040" num="0039">The imaging angle-of-view control unit <b>205</b> instructs the lens driving unit <b>204</b> to control a position of the zoom lens based on zoom setting values output from the system control unit <b>201</b>. Examples of the zoom setting values include a focal length setting value.</p><p id="p-0041" num="0040">The focus control unit <b>206</b> instructs the lens driving unit <b>204</b> to control a position of the focus lens based on focus setting values output from the system control unit <b>201</b>. The control of the position of the focus lens controls a position (focus position) on which the focus lens focuses in the imaging range.</p><p id="p-0042" num="0041">At least some of the series of imaging operations of the imaging apparatus <b>101</b> can be controlled automatically based on various conditions such as an imaging environment.</p><p id="p-0043" num="0042">Specifically, for example, in autofocusing (AF), an evaluation value is calculated from a contrast of an image based on a result of imaging by the imaging unit <b>202</b>, and the focus control unit <b>206</b> controls the position of the focus lens based on the evaluation value. This controls the focus of the imaging unit <b>202</b> so that a subject in the imaging range is brought into focus.</p><p id="p-0044" num="0043">Further, automatic control can be applied to not only the focus control but also, for example, exposure (aperture, shutter speed, gain, and neutral-density (ND) filter), white balance, noise reduction, and gamma control. These different types of automatic control can be performed by different components as appropriate. Specifically, for example, the noise reduction and the gamma control can be performed by the image processing unit <b>203</b>.</p><p id="p-0045" num="0044">The pan driving unit <b>207</b> includes a driving system and a motor. The driving system realizes a pan operation of controlling an imaging direction of the imaging unit <b>202</b> in a pan direction. The motor is a driving source of the driving system. Operations of the pan driving unit <b>207</b> are controlled by the pan/tilt control unit <b>209</b>.</p><p id="p-0046" num="0045">The tilt driving unit <b>208</b> includes a driving system and a motor. The driving system realizes a so-called tilt operation of controlling the imaging direction of the imaging unit <b>202</b> in a tilt direction. The motor is a driving source of the driving system. Operations of the tilt driving unit <b>208</b> are controlled by the pan/tilt control unit <b>209</b>.</p><p id="p-0047" num="0046">The pan/tilt control unit <b>209</b> instructs at least one of the pan driving unit <b>207</b> and the tilt driving unit <b>208</b> to control the imaging directions (control of pan/tilt operations) based on pan and tilt setting values output from the system control unit <b>201</b>.</p><p id="p-0048" num="0047">The storage unit <b>210</b> stores various types of data (e.g., image data) in at least one of an internal storage and an external storage. Further, the storage unit <b>210</b> can read various types of data stored in the internal storage and the external storage. The external storage and the internal storage can he realized by a non-volatile memory such as a hard disk drive (HDD) or a solid state drive (SDD).</p><p id="p-0049" num="0048">The program memory <b>211</b> is a storage area for storing programs for controlling the operation of the imaging apparatus <b>101</b>. The system control unit <b>201</b> realizes various operations of the imaging apparatus <b>101</b> by loading the programs stored in the program memory <b>211</b> and executing the loaded programs.</p><p id="p-0050" num="0049">The communication unit <b>220</b> is a communication interface via which the components (e.g., system control unit <b>201</b>) of the imaging apparatus <b>101</b> transmit and receive various types of information to and from other apparatuses (e.g., terminal apparatus <b>102</b>) via the network <b>105</b>. For example, the communication unit <b>220</b> can receive a camera control command from the terminal apparatus <b>102</b> via the network <b>105</b> and can output the camera control command to the system control unit <b>201</b>. In this case, the communication unit <b>220</b> can transmit a response to the camera control command to the terminal apparatus <b>102</b> via the network <b>105</b> based on an instruction from the system control unit <b>201</b>. The camera control command is as described above, so that redundant detailed descriptions thereof are omitted.</p><p id="p-0051" num="0050">The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a mere example and is not intended to limit the configuration of the imaging apparatus <b>101</b> according to the present exemplary embodiment. For example, the configuration illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> can be realized by a plurality of devices cooperating together.</p><p id="p-0052" num="0051">Specifically, for example, some of the components of the imaging apparatus <b>101</b> can be provided to another apparatus. Specifically, for example, the components corresponding to the system control unit <b>201</b>, the storage unit <b>210</b>, and the program memory <b>211</b> can he provided to another apparatus capable of transmitting and receiving information to and from the imaging apparatus <b>101</b> via a predetermined transmission path. In this case, the other apparatus corresponds to an example of an &#x201c;information processing apparatus&#x201d; that controls the operations of the imaging apparatus <b>101</b>.</p><p id="p-0053" num="0052">Further, as another example, processing loads of at least some of the components of the imaging apparatus <b>101</b> can be distributed to a plurality of apparatuses.</p><p id="p-0054" num="0053">Next, an example of a configuration of a client apparatus will be described below with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The client apparatus corresponds to an apparatus that is used to control the operations of the imaging apparatus <b>101</b>, such as the terminal apparatus <b>102</b> and the controller <b>104</b>. The client apparatus includes a system control unit <b>301</b>, a communication unit <b>302</b>, a storage unit <b>303</b>, and a program memory <b>305</b>. Further, the client apparatus can include an input unit <b>304</b>.</p><p id="p-0055" num="0054">The system control unit <b>301</b> controls various operations of the client apparatus by instructing the components of the client apparatus. The system control unit <b>301</b> can be realized by an arithmetic device such as a CPU.</p><p id="p-0056" num="0055">For example, the system control unit <b>301</b> can generate a camera control command based on an operation received from the user by the input unit <b>304</b> and can instruct the communication unit <b>302</b> to transmit the camera control command to the imaging apparatus <b>101</b> via the network <b>105</b>. With this system of transmitting the camera control command from the client apparatus to the imaging apparatus <b>101</b>, the imaging apparatus <b>101</b> can be operated remotely through the client apparatus.</p><p id="p-0057" num="0056">Further, the system control unit <b>301</b> can instruct the imaging apparatus <b>101</b> to record information about contents of control of an operation and to reproduce the operation (to reproduce the contents of the control) subsequently based on the recorded information. Hereinafter, the foregoing series of functions of recording the information about the contents of the control of the operation of the imaging apparatus <b>101</b> and reproducing the operation of the imaging apparatus <b>101</b> subsequently based on the information is also referred to as &#x201c;trace function&#x201d; for convenience. Further, the function of recording the information about the contents of the control of the operation of the imaging apparatus <b>101</b> in the trace function is also referred to as &#x201c;trace recording&#x201d;, and the function of reproducing the operation of the imaging apparatus <b>101</b> (reproducing the contents of the control) subsequently based on the recorded information is also referred to as &#x201c;trace reproduction&#x201d;.</p><p id="p-0058" num="0057">Further, in a case where the communication unit <b>302</b> receives a response from the imaging apparatus <b>101</b>, the system control unit <b>301</b> can analyze the response and perform processing based on the response.</p><p id="p-0059" num="0058">The communication unit <b>302</b> is a communication interface via which the components (e.g., system control unit <b>301</b>) of the client apparatus transmit and receive various types of information to and from other apparatuses (e.g., imaging apparatus <b>101</b>) via the network <b>105</b>. For example, the communication unit <b>302</b> can transmit a camera control command to the imaging apparatus <b>101</b> via the network <b>105</b> and can receive a response to the camera control command from the imaging apparatus <b>101</b>. The camera control command is as described above, so that redundant detailed descriptions thereof are omitted.</p><p id="p-0060" num="0059">The storage unit <b>303</b> stores various types of data (e.g., image data) in at least one of an internal storage and an external storage. Further, the storage unit <b>303</b> can read various types of data stored in the internal storage and the external storage. The external storage and the internal storage can be realized by a non-volatile memory such as a HDD or a SDD.</p><p id="p-0061" num="0060">The program memory <b>305</b> is a storage area for storing programs (e.g., programs of various applications) for controlling operations of the client apparatus. The system control unit <b>301</b> realizes various operations of the client apparatus by loading the programs stored in the program memory <b>305</b> and executing the loaded programs.</p><p id="p-0062" num="0061">The input unit <b>304</b> is an input interface for receiving instructions from the user.</p><p id="p-0063" num="0062">The input unit <b>304</b> can be realized by input devices of the client apparatus, such as a button, a keyboard, a pointing device, and a joystick. Further, as another example, the input unit <b>304</b> can be realized by a touch panel of a display unit (not illustrated) such as a display.</p><p id="p-0064" num="0063">The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a mere example and is not intended to limit the configuration of the client apparatus according to the present exemplary embodiment.</p><p id="p-0065" num="0064">For example, while the example illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> does not include an illustration of a component corresponding to the display unit such as a display, the client apparatus can include a component corresponding to the display unit. With the component corresponding to the display unit of the client apparatus, for example, an image based on a result of imaging by the imaging apparatus <b>101</b> and a setting value applied to an imaging operation of the imaging apparatus <b>101</b> can be presented to the user.</p><p id="p-0066" num="0065">Further, the configuration illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> can be realized by a plurality of devices cooperating together.</p><p id="p-0067" num="0066">Specifically, for example, some of the components of the client apparatus can be provided to another apparatus. Specifically, for example, the components corresponding to the input unit <b>304</b> and the storage unit <b>303</b> can be provided to another apparatus capable of transmitting and receiving information to and from the client apparatus via a predetermined transmission path.</p><p id="p-0068" num="0067">Further, as another example, processing loads of at least some of the components of the client apparatus can be distributed to a plurality of apparatuses.</p><p id="p-0069" num="0068">For convenience, a case where the terminal apparatus <b>102</b> is used as the client apparatus will be described below.</p><heading id="h-0009" level="1">COMPARATIVE EXAMPLE</heading><p id="p-0070" num="0069">First, an example of a process for realizing the trace function will be described below with reference to <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref> as a comparative example to facilitate understanding of a feature of the imaging system according to the present exemplary embodiment.</p><p id="p-0071" num="0070">First, an example of a process of the trace recording will be described below with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0072" num="0071">In step S<b>401</b>, the system control unit <b>201</b> of the imaging apparatus <b>101</b> starts a series of processes of the trace recording based on an instruction from the terminal apparatus <b>102</b>.</p><p id="p-0073" num="0072">First, in step S<b>402</b>, the system control unit <b>201</b> records information about a current state (e.g., imaging direction, and imaging condition) of the imaging apparatus <b>101</b> in a predetermined storage area at the beginning of the trace recording. Hereinafter, the information about the state of the imaging apparatus <b>101</b> is also referred to as &#x201c;camera information&#x201d; for convenience. Further, the storage unit <b>210</b> of the imaging apparatus <b>101</b> or the storage unit <b>303</b> of the terminal apparatus <b>102</b> can be used as the storage area. In a case where the storage unit <b>303</b> of the terminal apparatus <b>102</b> is used as the storage area, the system control unit <b>201</b> transmits the camera information to the terminal apparatus <b>102</b> via the network <b>105</b>.</p><p id="p-0074" num="0073">For convenience, a case where the storage unit <b>210</b> of the imaging apparatus <b>101</b> is used as the storage area will be described below.</p><p id="p-0075" num="0074">In step S<b>403</b>, the system control unit <b>201</b> determines whether an operation from the user is received by the terminal apparatus <b>102</b> (i.e., whether an instruction from the user is received).</p><p id="p-0076" num="0075">In a case where the system control unit <b>201</b> determines that an operation from the user is received by the terminal apparatus <b>102</b> (YES in step S<b>403</b>), the processing proceeds to step S<b>404</b>. In this case, in step S<b>404</b>, the system control unit <b>201</b> records information (hereinafter, also referred to as &#x201c;operation information&#x201d;) about the content of the operation received from the user by the terminal apparatus <b>102</b> in the storage unit <b>210</b> from the terminal apparatus <b>102</b> via the network <b>105</b>. At this time, the system control unit <b>201</b> can record time information in association with the operation information.</p><p id="p-0077" num="0076">On the other hand, in a case where the system control unit <b>201</b> determines that no operation from the user is received by the terminal apparatus <b>102</b> (NO in step S<b>403</b>), the processing proceeds to step S<b>405</b>. In this case, step S<b>404</b> is skipped.</p><p id="p-0078" num="0077">In step S<b>405</b>, the system control unit <b>201</b> determines whether to end the trace recording. Specifically, for example, the system control unit <b>201</b> can determine whether to end the trace recording based on whether an instruction to end the trace recording is received from the user.</p><p id="p-0079" num="0078">In a case where the system control unit <b>201</b> determines not to end the trace recording (NO in step S<b>405</b>), the processing proceeds to step S<b>403</b>. In this case, step S<b>403</b> and subsequent steps are performed again. As a result, the operation information is sequentially recorded in chronological order. Hereinafter, data of the operation information recorded sequentially in chronological order by the trace recording is also referred to as &#x201c;trace data&#x201d;.</p><p id="p-0080" num="0079">On the other hand, in a case where the system control unit <b>201</b> determines to end the trace recording (YES in step S<b>405</b>), the processing proceeds to step S<b>406</b>.</p><p id="p-0081" num="0080">In step S<b>406</b>, the system control unit <b>201</b> ends the control of the trace recording (e.g., control of the recording of the operation information).</p><p id="p-0082" num="0081">Then, in step S<b>407</b>, the system control unit <b>201</b> records camera information about the state of the imaging apparatus <b>101</b> at the end of the trace recording in the storage unit <b>210</b>, and then the process illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> ends.</p><p id="p-0083" num="0082">Next, an example of a process of the trace reproduction will be described below with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0084" num="0083">In step S<b>501</b>, the system control unit <b>201</b> of the imaging apparatus <b>101</b> starts a series of processes of the trace reproduction based on an instruction from the terminal apparatus <b>102</b>.</p><p id="p-0085" num="0084">In step S<b>502</b>, the system control unit <b>201</b> controls the state of the imaging apparatus <b>101</b> based on the camera information about the state of the imaging apparatus <b>101</b> at the beginning of the trace recording that is recorded in the storage unit <b>210</b> to change the state of the imaging apparatus <b>101</b> to the state at the beginning of the trace recording. As a result, the state of the imaging apparatus <b>101</b> (e.g., imaging direction, imaging condition) is substantially the same as the state at the beginning of the trace recording (at the time of performing step S<b>402</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>).</p><p id="p-0086" num="0085">In step S<b>503</b>, the system control unit <b>201</b> acquires the trace data (i.e., operation information) recorded in the trace recording from the storage unit <b>210</b>. At this time, the system control unit <b>201</b> acquires information recorded earlier among the information not having been acquired at this time point from the storage unit <b>210</b>.</p><p id="p-0087" num="0086">In step S<b>504</b>, the system control unit <b>201</b> controls operations of the imaging apparatus <b>101</b> based on the trace data (operation information) acquired in step S<b>503</b>.</p><p id="p-0088" num="0087">In step S<b>505</b>, the system control unit <b>201</b> determines whether an instruction to stop the trace reproduction is received or the trace reproduction is performed to the last one of the series of pieces of information recorded in the trace recording.</p><p id="p-0089" num="0088">In a case where the system control unit <b>201</b> determines that no instruction to stop the trace reproduction is received and the trace reproduction is not performed to the last (No in step S<b>505</b>), the processing proceeds to step S<b>503</b>. In this case, step S<b>503</b> and subsequent steps are performed again on information not having been acquired by the process of step S<b>503</b> among the information recorded in the storage unit <b>210</b> in the trace recording.</p><p id="p-0090" num="0089">On the other hand, in a case where the system control unit <b>201</b> determines that an instruction to stop the trace reproduction is received or the trace reproduction is performed to the last (YES in step S<b>505</b>), the processing proceeds to step S<b>506</b>.</p><p id="p-0091" num="0090">In step S<b>506</b>, the system control unit <b>201</b> ends the series of processes of the trace reproduction. As a result, the process illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is ended.</p><p id="p-0092" num="0091">An outline of a technical issue of a case where an operation of the imaging apparatus <b>101</b> in the trace recording is reproduced using the trace function according to the comparative example will be described below with reference to <figref idref="DRAWINGS">FIGS. <b>6</b>, <b>7</b>A, and <b>7</b>B</figref>.</p><p id="p-0093" num="0092">For example, <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a view illustrating an example of a use case of the imaging system according to the present exemplary embodiment. <figref idref="DRAWINGS">FIG. <b>6</b></figref> schematically illustrates a state of imaging a venue of a wedding by the imaging apparatus <b>101</b> during the wedding. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a scene where a person <b>601</b> as a main subject walks in a direction specified by an arrow is illustrated. The imaging apparatus <b>101</b> is situated to face the person <b>601</b>, and various types of control including PTZ control and imaging control are performed by remote operations.</p><p id="p-0094" num="0093"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> are graphs illustrating a transition of the position of the subject (i.e., subject movement) in the trace recording and a transition of the position of the subject in the trace reproduction in the scene illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. In the examples illustrated in <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref>, a change in the focus position (the position on which the focus lens focuses in the imaging range) in a case where the subject is brought into focus by the autofocus control is illustrated as a transition of the position of the subject in chronological order. In each of the graphs illustrated in <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref>, a horizontal axis represents time whereas a vertical axis represents subject position (i.e., focus position) in a depth direction.</p><p id="p-0095" num="0094">Each graph C<b>701</b> in <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> illustrates a transition of the position of the subject in the trace recording (i.e., a change in the position of the subject in chronological order). As illustrated by the graph C<b>701</b>, the person <b>601</b> as the subject moves towards the imaging apparatus <b>101</b> over time in the trace recording.</p><p id="p-0096" num="0095">On the contrary, a graph C<b>702</b> in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> illustrates an example of a transition of the position of the subject in the trace reproduction. A comparison of the graph C<b>702</b> with the graph C<b>701</b> indicates that the chronological change in the position of the person <b>601</b> as the subject is slower in the trace reproduction than in the trace recording in the example illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>.</p><p id="p-0097" num="0096">Further, a graph C<b>703</b> in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> illustrates another example of a transition of the position of the subject in the trace reproduction. A comparison of the graph C<b>703</b> with the graph C<b>701</b> indicates that the chronological change in the position of the person <b>601</b> as the subject is faster in the trace reproduction than in the trace recording in the example illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>.</p><p id="p-0098" num="0097">As illustrated in <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref>, there are cases where the chronological change in the position of the subject in the trace recording and the chronological change in the position of the subject in the trace reproduction differ. Examples of a possible cause of the difference are a difference in speed of the movement of the subject between the trace recording and the trace reproduction and an effect of a gap in timing of starting the trace reproduction.</p><p id="p-0099" num="0098">Considering the above-described situation, the imaging system according to the present exemplary embodiment records information (hereinafter, also referred to as &#x201c;detection information&#x201d;) corresponding to a subject detection result in the trace recording and controls the speed of the trace reproduction based on a difference between the recorded detection information and detection information in the trace reproduction.</p><p id="p-0100" num="0099">Features of the imaging system according to the present exemplary embodiment will be described in more detail below.</p><heading id="h-0010" level="2">&#x3c;Outline of Function&#x3e;</heading><p id="p-0101" num="0100">An outline of a function of controlling the speed of the trace reproduction of the imaging system according to the present exemplary embodiment will be described below with reference to <figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref>. <figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> are views schematically illustrating an angle of view of the imaging apparatus <b>101</b> in the use case described above with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0102" num="0101">First, <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> will be described below. <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> schematically illustrates a situation where the angle of view is set to a wider angle to image a wider range of a scene immediately before the person <b>601</b> as the main subject starts walking in a direction specified by an arrow. A detection frame R<b>801</b> schematically illustrates a detection frame presented based on a result of detecting a face of a person by a so-called face detection function. The detection frame R<b>801</b> is managed based on, for example, coordinate information about a position at which a detection target is detected with respect to a current angle-of-view.</p><p id="p-0103" num="0102">The coordinate information is not particularly limited and can be of any type that can specify a range of the detection frame R<b>801</b> within the angle of view, Specifically, for example, in a case where the detection frame R<b>801</b> is a rectangle, coordinates of upper-left and lower-right vertices of the rectangle can be managed as the coordinate information, or information about the coordinates of the upper-left vertex and height and width information can be managed as the coordinate information. A shape of the detection frame R<b>801</b> is not particularly limited, and the type of the coordinate information can be changed appropriately for the shape.</p><p id="p-0104" num="0103">Further, while the face of the person <b>601</b> as the main subject is a target of detection by the face detection function in the example illustrated in <figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref>, functions for use in the detection are not particularly limited, and any functions that can detect a subject in the imaging range can be used. Specifically, for example, human body detection, moving object detection, and object detection functions can be used in subject detection. Further, detection target subjects are not limited to persons, and a function for use in detecting a detection target subject can be changed appropriately for the type of the detection target subject.</p><p id="p-0105" num="0104">Next. <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> will be described below. <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> schematically illustrates a situation where a scene after the person <b>601</b> has moved forward in the arrow direction from the state illustrated in <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> is imaged at a zoomed-in angle of view to emphasize the person <b>601</b> as a main person (main subject). Similarly to the detection frame R<b>801</b>, a detection frame R<b>802</b> schematically illustrates a detection frame presented based on a result of detecting a face of a person by the face detection function. In the scene illustrated in <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>, the person <b>601</b> is situated closer to the imaging apparatus <b>101</b> and, furthermore, zoom-in control is performed, compared to the scene illustrated in <figref idref="DRAWINGS">FIG. <b>8</b>A</figref>. Thus, the detection frame R<b>802</b> occupies a wider range in the angle of view than the detection frame R<b>801</b> does. Specifically, the detection frame R<b>802</b> is larger in size than the detection frame R<b>801</b> due to effects of differences between the scenes and differences between the imaging conditions.</p><p id="p-0106" num="0105">The imaging system according to the present exemplary embodiment records information about the contents of the control of the operation of the imaging apparatus <b>101</b> (e.g., contents of PTZ control and focus position control) in chronological order in association with detection information corresponding to the subject detection result described as an example with reference to <figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> in the trace recording. Further, the imaging system determines a difference in subject movement (e.g., whether the subject movement is faster or slower than the subject movement in the trace recording) by comparing the detection information corresponding to the subject detection result and the detection information recorded in the trace recording in the trace reproduction. Then, the imaging system controls the speed of reproducing the contents of the control of the operation of the imaging apparatus <b>101</b> in the trace reproduction based on a result of the determination of the difference in subject movement between the trace recording and the trace reproduction (e.g., the difference in transitions of the subject position).</p><p id="p-0107" num="0106">Specifically, for example, in a case where the subject movement is slower than the subject movement in the trace recording, the imaging system can control the speed to reproduce the contents of the control of the operation of the imaging apparatus <b>101</b> at a decreased speed. Further, as another example, in a case where the subject movement is faster than the subject movement in the trace recording, the imaging system can control the speed to reproduce the contents of the control of the operation of the imaging apparatus <b>101</b> at an increased speed.</p><p id="p-0108" num="0107">Application of the above-described control makes it possible to reproduce a previously-performed imaging operation of the imaging apparatus <b>101</b> (e.g., operation based on PTZ control and focus position control) at a subsequent time in a more suitable form for a subject movement at that time.</p><heading id="h-0011" level="2">&#x3c;Process&#x3e;</heading><p id="p-0109" num="0108">An example of a process of the imaging system according to the present exemplary embodiment will be described below with reference to <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref>.</p><p id="p-0110" num="0109">First, an example of a process of the trace recording will be described below with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>. The example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref> is different from the example illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> in that a process for recording detection information is added. The following descriptions of the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref> focus particularly on differences from the example illustrated <figref idref="DRAWINGS">FIG. <b>4</b></figref>, and detailed descriptions of parts substantially similar to those of the example illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> are omitted.</p><p id="p-0111" num="0110">Steps S<b>901</b> to S<b>904</b> are substantially similar to steps S<b>101</b> to S<b>404</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Specifically, the system control unit <b>201</b> of the imaging apparatus <b>101</b> records information about a current state of the imaging apparatus <b>101</b> at the beginning of the trace recording and thereafter records operation information about the content of an operation received from the user.</p><p id="p-0112" num="0111">The operation information corresponds to an example of &#x201c;first information&#x201d;, and the process of recording the operation information that is described as step S<b>904</b> corresponds to an example of &#x201c;first recording process&#x201d;.</p><p id="p-0113" num="0112">In step S<b>905</b>, the system control unit <b>201</b> performs a process of detecting a subject in the imaging range of the imaging apparatus <b>101</b> and determines whether a subject (e.g., main subject) is detected. In detecting a subject, for example, a detection range can be preset. This makes it possible to limit a target of the subject detection to a subject of interest (e.g., main subject) among a series of subjects in the imaging range.</p><p id="p-0114" num="0113">Further, as another example, some of a series of subjects detected by the subject detection can be selected as a main subject based on an instruction from the user.</p><p id="p-0115" num="0114">In a case where the system control unit <b>201</b> determines that a subject is detected (YES in step S<b>905</b>), the processing proceeds to step S<b>906</b>. In step S<b>906</b>, the system control unit <b>201</b> records the detection information corresponding to the subject detection result in step S<b>905</b> in the storage unit <b>210</b>. The detection information includes, for example, information about a focus position at the time the subject is detected, a position of the detected subject, a distance to the detected subject, and a size of the detected subject. In a case where the operation information is recorded in step S<b>904</b>, the detection information is added following the operation information, and this associates the operation information with the detection information. Further, the detection information corresponds to an example of &#x201c;second information&#x201d;, and the process of recording the detection information that is described as step S<b>906</b> corresponds to an example of &#x201c;second recording process&#x201d;.</p><p id="p-0116" num="0115">On the other hand, in a case where the system control unit <b>201</b> determines that no subject is detected (NO in step S<b>905</b>), the processing proceeds to step S<b>907</b>. In this case, step S<b>906</b> is skipped.</p><p id="p-0117" num="0116">In step S<b>907</b>, the system control unit <b>201</b> determines whether to end the trace recording.</p><p id="p-0118" num="0117">In a case where the system control unit <b>201</b> determines not to end the trace recording (NO in step S<b>907</b>), the processing proceeds to step S<b>903</b>. In this case, step S<b>903</b> and subsequent steps are performed again. As a result, the operation information and the detection information are sequentially recorded in chronological order. According to the present exemplary embodiment, data of the operation information and the detection information that are recorded sequentially in chronological order by the trace recording corresponds to &#x201c;trace data&#x201d;.</p><p id="p-0119" num="0118">On the other hand, in a case where the system control unit <b>201</b> determines to end the trace recording (YES in step S<b>907</b>), the processing proceeds to step S<b>908</b>.</p><p id="p-0120" num="0119">In step S<b>908</b>, the system control unit <b>201</b> ends the control of the trace recording (e.g., the control of the recording of the operation information and the detection information).</p><p id="p-0121" num="0120">Then, in step S<b>909</b>, the system control unit <b>201</b> records the camera information about the state of the imaging apparatus <b>101</b> at the end of the trace recording in the storage unit <b>210</b>, and then the process in <figref idref="DRAWINGS">FIG. <b>9</b></figref> ends.</p><p id="p-0122" num="0121">Next, an example of a process of the trace reproduction will be described below with reference to <figref idref="DRAWINGS">FIG. <b>10</b></figref>. The example illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> is different from the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> in that a process for controlling the speed of reproducing the contents of the control of the operation of the imaging apparatus <b>101</b> based on the detection information is added. The following descriptions of the example illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> focus particularly on differences from the example illustrated <figref idref="DRAWINGS">FIG. <b>5</b></figref>, and detailed descriptions of parts substantially similar to those of the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> are omitted.</p><p id="p-0123" num="0122">Steps S<b>1001</b> to S<b>1003</b> are substantially similar to steps S<b>501</b> to S<b>503</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. Specifically, at the beginning of the trace reproduction, the system control unit <b>201</b> of the imaging apparatus <b>101</b> controls the state of the imaging apparatus <b>101</b> based on the camera information at the beginning of the trace recording to change the state of the imaging apparatus <b>101</b> to the state at the beginning of the trace recording and acquires the trace data from the storage unit <b>210</b>. In the trace data acquisition, the system control unit <b>201</b> acquires information recorded earlier among the information not having been acquired at this time point from the storage unit <b>210</b>.</p><p id="p-0124" num="0123">In step S<b>1004</b>, the system control unit <b>201</b> controls the operations of the imaging apparatus <b>101</b> (particularly, imaging operation) based on the trace data (e.g., operation information) acquired in step S<b>1003</b>.</p><p id="p-0125" num="0124">Specifically, for example, the system control unit <b>201</b> can output information about the distance to the subject and information about the focus control (e.g., information about the focus position) to the focus control unit <b>206</b> among the information included in the trace data. The focus control unit <b>206</b> drives the lens driving unit <b>204</b> based on the information output from the system control unit <b>201</b> so that the focus control in the trace recording is reproduced.</p><p id="p-0126" num="0125">Further, the system control unit <b>201</b> can output information about the pan control and the tilt control (e.g., information about positions in the pan and tilt directions) to the pan/tilt control unit <b>209</b> among the information included in the trace data. The pan/tilt control unit <b>209</b> drives the pan driving unit <b>207</b> and the tilt driving unit <b>208</b> based on the information output from the system control unit <b>201</b> so that the pan control and the tilt control in the trace recording are reproduced.</p><p id="p-0127" num="0126">Further, the system control unit <b>201</b> can output information about the zoom control (e.g., zoom magnification information) to the imaging angle-of-view control unit <b>205</b> among the information included in the trace data. With the information, the imaging angle-of-view control unit <b>205</b> reproduces the zoom control in the trace recording.</p><p id="p-0128" num="0127">Further, the system control unit <b>201</b> can output information about the image processing (e.g., information about image quality settings) to the image processing unit <b>203</b> among the information included in the trace data.</p><p id="p-0129" num="0128">With the information, the image processing unit <b>203</b> applies the image processing to an image corresponding to a result of imaging by the imaging unit <b>202</b> based on a condition similar to that in the trace recording.</p><p id="p-0130" num="0129">In step S<b>1005</b>, the system control unit <b>201</b> outputs the detection information included in the trace data to the image processing unit <b>203</b> and then instructs the image processing unit <b>203</b> to perform the subject detection process. The image processing unit <b>203</b> performs the process of detecting a subject from the image corresponding to the result of imaging by the imaging unit <b>202</b> based on the detection information output from the system control unit <b>201</b>. This enables the image processing unit <b>203</b> to perform the process of detecting a subject from the image corresponding to the result of imaging by the imaging unit <b>202</b> based on a condition similar to that in the trace recording.</p><p id="p-0131" num="0130">Specifically, for example, in a case where the subject detection range is limited in the trace recording, the image processing unit <b>203</b> limits the subject detection range as in the trace recording and then performs the subject detection process.</p><p id="p-0132" num="0131">Further, as another example, in a case where some of the series of detected subjects are selected in the trace recording, the image processing unit <b>203</b> can select some of a series of subjects detected from the image based on a condition similar to that in the trace recording.</p><p id="p-0133" num="0132">In step S<b>1006</b>, the image processing unit <b>203</b> compares the detection information corresponding to the result of the subject detection from the image corresponding to the result of imaging by the imaging unit <b>202</b> in step S<b>1005</b> and the detection information recorded in the trace recording and notifies the system control unit <b>201</b> of the comparison result. The system control unit <b>201</b> determines whether there is a difference between the detection information in the trace recording and the current detection information (i.e., detection information in the trace reproduction) based on the detection information comparison result notified from the image processing unit <b>203</b>. Specifically, for example, the system control unit <b>201</b> can determine whether there is a difference between the position at which the subject is detected, the size of the subject, the distance to the subject, and the focus position in the trace recording and those at the current time based on the detection information comparison result notified from the image processing unit <b>203</b>.</p><p id="p-0134" num="0133">In a case where the system control unit <b>201</b> determines that there is a difference between the pieces of detection information that are compared (YES in step S<b>1006</b>), the processing proceeds to step S<b>1007</b>. In step S<b>1007</b>, the system control unit <b>201</b> controls the speed of the trace reproduction, i.e., the speed of reproduction of the contents of the control of the operations of the imaging apparatus <b>101</b>, based on the result of comparing the detection information in the trace recording and the current detection information in step S<b>1006</b>. Specifically, for example, the system control unit <b>201</b> can control the speed of the trace reproduction to reduce the difference in chronological transitions between the detection information in the trace recording and the current detection information.</p><p id="p-0135" num="0134">A specific example of the control of the speed of the trace reproduction will be described below, focusing on a case where the speed of the trace reproduction is controlled to reduce the difference in chronological transitions between the detection information in the trace recording and the detection information in the trace reproduction.</p><p id="p-0136" num="0135">For example, in a case where the speed of the chronological transition of the detection information in the trace reproduction is slower than the speed of the chronological transition of the detection information in the trace recording, the system control unit <b>201</b> can control the speed of the trace reproduction to a slower speed.</p><p id="p-0137" num="0136">In this case, the system control unit <b>201</b> can realize more smooth trace reproduction by, for example, adding another new frame between a plurality of chronologically consecutive frames among a series of frames on which the trace data is recorded.</p><p id="p-0138" num="0137">For example, the system control unit <b>201</b> can perform the trace reproduction after interpolating the contents of the control of the operations of the imaging apparatus <b>101</b> for the other frame based on the trace data corresponding to the previous frame and the trace data corresponding to the subsequent frame. Specifically, for example, the system control unit <b>201</b> can perform the trace reproduction after interpolating information about the imaging direction, the imaging range, and the focus control for the other frame based on the contents of the PTZ control and the focus position on the previous and subsequent frames. This makes it possible to maintain the frame rate by, for example, frame interpolation even in a case where the speed of the trace reproduction is decreased, so that the operations of the imaging apparatus <b>101</b> for the trace reproduction are controlled to be more smoothly.</p><p id="p-0139" num="0138">Any methods can be used to interpolate the information (e.g., the contents of the control of the operations of the imaging apparatus <b>101</b>) for adding the other frame. Specifically, for example, linear interpolation can be used. Further, as another example, the information can be interpolated based on the difference between the position at which the subject is detected in the previous frame of the frame to be added and the position at which the subject is detected in the subsequent frame of the frame to be added.</p><p id="p-0140" num="0139">Further, as another example, the system control unit <b>201</b> can control the speed of the trace reproduction to a slower speed by inserting a wait period (e.g., a frame for stopping the trace reproduction) for temporarily stopping the trace reproduction between the consecutive frames.</p><p id="p-0141" num="0140">As described above, the speed of the trace reproduction is controlled to a slower speed so that the relative speed of controlling the operations of the imaging unit <b>202</b> with respect to the speed of the subject moving at a speed slower than that in the trace recording substantially matches the speed in the trace recording. Specifically, for example, in a case where the an control is brought into focus and the speed of the subject movement is slower than the speed in the trace recording, the speed of swinging the imaging unit <b>202</b> in the pan direction is controlled to a slower speed corresponding to the speed of the subject. Specifically, the operations of the imaging unit <b>202</b> for the trace reproduction are controlled correspondingly to the movement of the subject moving at a speed slower than the speed in the trace recording so that a scene imaged in the trace recording and a scene imaged in the trace reproduction substantially match.</p><p id="p-0142" num="0141">Further, in a case where the speed of the chronological transition of the detection information in the trace reproduction is faster than the speed of the chronological transition of the detection information in the trace recording, the system control unit <b>201</b> can control the speed of the trace reproduction to a faster speed.</p><p id="p-0143" num="0142">In this case, the system control unit <b>201</b> can control the speed of the trace reproduction to a faster speed by, for example, skipping the control based on the trace data corresponding to some of the series of frames on which the trace data is recorded.</p><p id="p-0144" num="0143">Further, as another example, the system control unit <b>201</b> can interpolate the contents of the control of the operations of the imaging apparatus <b>101</b> for subsequent frames based on differences in detection information between the pieces of trace data corresponding to the plurality of chronologically consecutive frames.</p><p id="p-0145" num="0144">As described above, the speed of the trace reproduction is controlled to a faster speed so that the relative speed of the control of the operations of the imaging unit <b>202</b> with respect to the speed of the subject moving at a speed faster than the speed in the trace recording is controlled to substantially match the speed in the trace recording. Specifically, for example, in a case where the pan control is brought into focus and the speed of the subject movement is faster than the speed in the trace recording, the speed of swinging the imaging unit <b>202</b> in the pan direction is controlled to a faster speed correspondingly to the speed of the subject. Specifically, the operations of the imaging unit <b>202</b> for the trace reproduction are controlled correspondingly to the movement of the subject moving at a speed faster than the speed in the trace recording so that a scene imaged in the trace recording and a scene imaged in the trace reproduction substantially match.</p><p id="p-0146" num="0145">The description of <figref idref="DRAWINGS">FIG. <b>10</b></figref> will be resumed below.</p><p id="p-0147" num="0146">In step S<b>1008</b>, the system control unit <b>201</b> determines whether an instruction to stop the trace reproduction is received or the trace reproduction is performed to the last one of the series of pieces of information recorded in the trace recording.</p><p id="p-0148" num="0147">In a case where the system control unit <b>201</b> determines that no instruction to stop the trace reproduction is received and the trace reproduction is not performed to the last (NO in step S<b>1008</b>), the processing proceeds to step S<b>1003</b>. In this case, step S<b>1003</b> and subsequent steps arc performed again on information not having been acquired by the process of step S<b>1003</b> among the information recorded in the storage unit <b>210</b> in the trace recording.</p><p id="p-0149" num="0148">On the other hand, in a case where the system control unit <b>201</b> determines that an instruction to stop the trace reproduction is received or the trace reproduction is performed to the last (YES in step S<b>1008</b>), the processing proceeds to step S<b>1009</b>.</p><p id="p-0150" num="0149">In step S<b>1009</b>, the system control unit <b>201</b> ends the series of processes of the trace reproduction. As a result, the process illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> ends.</p><p id="p-0151" num="0150">While the processes of the trace recording and the trace reproduction are performed by the imaging apparatus <b>101</b> in the example described with reference to <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref>, this is not necessarily intended to limit the processes of the imaging system according to the present exemplary embodiment. Specifically, for example, another apparatus such as the terminal apparatus <b>102</b> can perform the processes of the trace recording and the trace reproduction based on communication with the imaging apparatus <b>101</b> via the network <b>105</b>. In this case, the trace data can be recorded in an internal storage or an external storage of the other apparatus.</p><p id="p-0152" num="0151">Application of the above-described control makes it possible to reproduce the operation of the imaging apparatus <b>101</b> in the trace recording correspondingly to the subject movement in the trace reproduction even in a case where, for example, there is a difference between the speed of the subject movement in the trace recording and the speed of the subject movement in the trace reproduction. Specifically, the imaging system according to the present exemplary embodiment reproduces a previously-performed imaging operation at a subsequent time in a more suitable form for a subject movement at that time.</p><heading id="h-0012" level="1">MODIFIED EXAMPLE</heading><p id="p-0153" num="0152">A modified example of the imaging system according to the present exemplary embodiment will be described below with reference to <figref idref="DRAWINGS">FIGS. <b>11</b> and <b>12</b></figref>. In the present modified example, an example of a system for presenting information for use in monitoring the control of the trace recording and the control of the trace reproduction by the user in performing the trace recording and the trace reproduction will be described below. The following descriptions of the imaging system according to the present modified example focus on differences from the imaging system according to the exemplary embodiment described above, and detailed descriptions of parts substantially similar to those of the imaging system according to the exemplary embodiment described above are omitted.</p><p id="p-0154" num="0153">First, <figref idref="DRAWINGS">FIG. <b>11</b></figref> will be described below. <figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates an example of a user interface (UI) of the imaging system according to the present modified example. Specifically, an operation screen <b>1100</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates an example of a UI for receiving instructions for the control of the operations (particularly, imaging operation) of the imaging apparatus <b>101</b> from the user. The operation screen <b>1100</b> is presented to the user via an output unit of the terminal apparatus <b>102</b> through, for example, execution of a predetermined application by the terminal apparatus <b>102</b>. The operation screen <b>1100</b> plays a role as an output interface for presenting images corresponding to results of imaging by the imaging apparatus <b>101</b> to the user and as an input interface for receiving instructions for operations (e.g., remote operation) of the imaging apparatus <b>101</b> from the user.</p><p id="p-0155" num="0154">The operation screen <b>1100</b> includes an image display region <b>1101</b>, a PTZ bar <b>1102</b>, a focus mode operation section <b>1103</b>, and a manual focus (MF) operation section <b>1104</b>. Further, the operation screen <b>1100</b> includes, as a UI for the trace function, a trace number setting section <b>1105</b>, a record button <b>1106</b>, a reproduce button <b>1107</b>, and a monitor button <b>1108</b>.</p><p id="p-0156" num="0155">The image display region <b>1101</b> is a display region for displaying an image corresponding to a result of imaging by the imaging apparatus <b>101</b>. With the image displayed in the image display region <b>1101</b>, the user can remotely operate the imaging apparatus <b>101</b> while checking the image.</p><p id="p-0157" num="0156">The PTZ bar <b>1102</b> is an input interface for receiving instructions for the pan, tilt, and zoom control from the user.</p><p id="p-0158" num="0157">The focus mode operation section <b>1103</b> is an input interface for receiving designation of an operation mode of the focus control from the user. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, AF or MF can be selected as the operation mode of the focus control via the focus mode operation section <b>1103</b>.</p><p id="p-0159" num="0158">The MF operation section <b>1104</b> is an input interface for receiving instructions to adjust the focus position from the user in a case where the operation mode of the focus control is set to MF. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, an input interface for controlling the focus position to a FAR direction and a NEAR direction is provided as the MF operation section <b>1104</b>.</p><p id="p-0160" num="0159">The PTZ bar <b>1102</b> and the focus mode operation section <b>1103</b> can be provided with a function of presenting values currently set for the imaging apparatus <b>101</b>.</p><p id="p-0161" num="0160">The trace number setting section <b>1105</b> is an input interface for receiving designation of identification information for identifying the trace data (operation information and detection information) that is a target of the trace recording, the trace reproduction, and a monitoring from the user. Hereinafter, the identification information is also referred to as &#x201c;trace No.&#x201d;.</p><p id="p-0162" num="0161">The record button <b>1106</b> is an input interface for receiving instructions for the trace recording from the user. At the press of the record button <b>1106</b>, the process of the trace recording described above with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref> is started. Thereafter, at the press of the record button <b>1106</b>, the started process of the trace recording ends. Then, the process of the trace recording is performed so that the trace number designated via the trace number setting section <b>1105</b> is assigned to the recorded trace data (operation information and detection information).</p><p id="p-0163" num="0162">The reproduce button <b>1107</b> is an input interface for receiving instructions for the trace reproduction from the user. At the press of the reproduce button <b>1107</b>, the process of the trace reproduction described above with reference to <figref idref="DRAWINGS">FIG. <b>10</b></figref> is started based on the trace data (operation information and detection information) to which the trace number designated via the trace number setting section <b>1105</b> is assigned. Thereafter, at the press of the reproduce button <b>1107</b>, the started process of the trace reproduction ends.</p><p id="p-0164" num="0163">The monitor button <b>1108</b> is an input interface for receiving instructions from the user for presenting a UI via which the user checks the transition of the subject position in the trace recording based on the recorded trace data and the transition of the subject position in the trace reproduction. At the press of the monitor button <b>1108</b>, a trace monitor screen <b>1200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref> is displayed to present the trace data with the trace number designated via the trace number setting section <b>1105</b> as information in the trace recording.</p><p id="p-0165" num="0164">The trace monitor screen <b>1200</b> will be described below with reference to <figref idref="DRAWINGS">FIG. <b>12</b></figref>. The trace monitor screen <b>1200</b> is a screen used to present the status of the control of the trace reproduction (e.g., the control of the speed of the trace reproduction) by the imaging apparatus <b>101</b> to the user.</p><p id="p-0166" num="0165">The trace monitor screen <b>1200</b> presents the following information to the user. Specifically, information indicating the transition of the subject position in the trace recording based on the detection information included in the trace data and information indicating the transition of the subject position detected in the trace reproduction based on the trace data are presented in chronological order to the user. Further, the trace monitor screen <b>1200</b> can receive instructions for control in a case where no subject is detected during the trace reproduction. The trace monitor screen <b>1200</b> includes a trace number display section <b>1201</b>, a trace data display section <b>1202</b>, radio buttons <b>1203</b> to <b>1205</b>, and an end button <b>1206</b>.</p><p id="p-0167" num="0166">The trace number display section <b>1201</b> is a region where the trace number assigned to the trace data designated as the trace reproduction target is displayed. For example, the trace number display section <b>1201</b> displays the trace number designated via the trace number setting section <b>1105</b> of the operation screen <b>1100</b>.</p><p id="p-0168" num="0167">The trace data display section <b>1202</b> is a region where information about the transition of the subject position (i.e., subject movement) detected in the trace recording and information about the transition of the subject position detected in the trace reproduction are displayed. For example, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, as in the example described above with reference to <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref>, the transition of the subject position in the trace recording and the transition of the subject position in the trace reproduction are graphed. Further, the information about the transition of the subject position in the trace recording is displayed based on the detection information included in the trace data designated as a monitoring target.</p><p id="p-0169" num="0168">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, in a case where the detection target subject moves in the trace reproduction as in the trace recording, the graph showing the transition of the subject position coincides with the graph showing the transition of the subject position in the trace recording. On the other hand, in a case where the movement of the detection target subject in the trace reproduction is different from the movement of the subject in the trace recording, the graph showing the transition of the subject position in the trace reproduction differs from the graph showing the transition of the subject position in the trace recording. Specifically, for example, in a case where the speed of the transition of the subject position in the trace reproduction is different from the speed of the transition of the subject position in the trace recording, a gap corresponding to the difference in speed may be formed between the graphs corresponding to the cases.</p><p id="p-0170" num="0169">The imaging apparatus <b>101</b> monitors a difference between the transition of the subject position in the trace recording and the transition of the subject position in the trace reproduction, and in a case where there is a difference, the imaging apparatus <b>101</b> controls the speed of the trace reproduction. By applying the control, for example, the imaging apparatus <b>101</b> adjusts the transition of the subject transition of the subject position) in the angle of view in the trace reproduction so that the adjusted transition is closer to the transition of the subject in the angle of view in the trace recording. In other words, the imaging apparatus <b>101</b> applies the control so that a scene imaged during the trace reproduction becomes close to a scene imaged in the trace recording.</p><p id="p-0171" num="0170">While not illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, information (e.g., reproduction speed adjustment information) about the control of the speed of the trace reproduction by the imaging apparatus <b>101</b> can be displayed on the trace monitor screen <b>1200</b>.</p><p id="p-0172" num="0171">Candidate controls to be applied in a case where no subjects are detected in the trace reproduction are assigned to the radio buttons <b>1203</b> to <b>1205</b>.</p><p id="p-0173" num="0172">Specifically, for example, a control to maintain the speed of the trace reproduction at the current reproduction speed in a case where no subjects are detected is assigned to the radio button <b>1203</b>.</p><p id="p-0174" num="0173">Further, a control to change the speed of the trace reproduction to a reproduction speed preset as a default value in a case where no subjects are detected is assigned to the radio button <b>1204</b>. Further, a control to stop the trace reproduction in a case where no subjects are detected is assigned to the radio button <b>1205</b>. As to the control to stop the trace reproduction, a control to stop the series of operations of the trace reproduction can be applied, or a control to stop the trace reproduction temporarily until a subject is detected can be applied.</p><p id="p-0175" num="0174">In a case where one of the radio buttons <b>1203</b> to <b>1205</b> is selected, the control assigned to the selected radio button is applied.</p><p id="p-0176" num="0175">The end button <b>1206</b> is an input interface for receiving an instruction to end the monitoring of the status of the control of the trace reproduction by the imaging apparatus <b>101</b> from the user.</p><p id="p-0177" num="0176">In a case where the end button <b>1206</b> is pressed, the series of processes of the monitoring ends, and the trace monitor screen <b>1200</b> is closed.</p><p id="p-0178" num="0177">The above-described controls are applied so that in a case where there is a difference between the transition of the subject position in the trace reproduction and the transition of the subject position in the trace recording, the user can recognize the difference via the UI (trace monitor screen <b>1200</b>).</p><p id="p-0179" num="0178">Further, as described above, in a case where there is a difference between the subject detection result in the trace recording and the subject detection result in the trace reproduction, the imaging system according to the present exemplary embodiment performs the control of the speed of the trace reproduction to reduce the difference. Even in this case, feedback of the result of the control of the speed of the trace reproduction is provided to the UI. Thus, the user can recognize via the UI whether the control of the trace reproduction is performed in a suitable form for the subject movement in the trace reproduction.</p><heading id="h-0013" level="2">&#x3c;Other Exemplary Embodiments&#x3e;</heading><p id="p-0180" num="0179">The present disclosure can be realized also by the following process. Specifically, a program for realizing one or more functions of the above-described exemplary embodiments is supplied to a system or an apparatus via a network or a recording medium, and one or more processors of a computer of the system or the apparatus read the program and execute the read program. Further, the present disclosure can be realized also by a circuit (e.g., application-specific integrated circuit (ASIC)) that realizes one or more functions of the above-described exemplary embodiments.</p><p id="p-0181" num="0180">According to each of the exemplary embodiments described above, a previously-performed imaging operation is reproduced at a subsequent time in a more suitable form for a subject movement at that time.</p><heading id="h-0014" level="2">Other Embodiments</heading><p id="p-0182" num="0181">Embodiment(s) of the present disclosure can also be realized by a computer of a system or apparatus that reads out and executes computer executable instructions (e.g., one or more programs) recorded on a storage medium (which may also be referred to more fully as a &#x2018;non-transitory computer-readable storage medium&#x2019;) to perform the functions of one or more of the above-described embodiment(s) and/or that includes one or more circuits (e.g., application specific integrated circuit (ASIC)) for performing the functions of one or more of the above-described embodiment(s), and by a method performed by the computer of the system or apparatus by, for example, reading out and executing the computer executable instructions from the storage medium to perform the functions of one or more of the above-described embodiment(s) and/or controlling the one or more circuits to perform the functions of one or more of the above-described embodiment(s). The computer may comprise one or more processors (e.g., central processing unit (CPU), micro processing unit (MPU)) and may include a network of separate computers or separate processors to read out and execute the computer executable instructions. The computer executable instructions may be provided to the computer, for example, from a network or the storage medium. The storage medium may include, for example, one or more of a hard disk, a random-access memory (RAM), a read only memory (ROM), a storage of distributed computing systems, an optical disk (such as a compact disc (CD), digital versatile disc (DVD), or Blu-ray Disc (BD)?), a flash memory device, a memory card, and the like.</p><p id="p-0183" num="0182">While the present disclosure has been described with reference to exemplary embodiments, it is to be understood that the disclosure is not limited to the disclosed exemplary embodiments. The scope of the following claims is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures and functions.</p><p id="p-0184" num="0183">This application claims the benefit of Japanese Patent Application No. 2021-110512, filed Jul. 2, 2021, which is hereby incorporated by reference herein in its entirety</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An imaging apparatus comprising a processor executing instructions that, when executed by the processor, cause the processor to function as:<claim-text>a control device configured to control an imaging unit;</claim-text><claim-text>a control unit configured to control an imaging operation of the imaging unit based on an instruction from a user;</claim-text><claim-text>a detection unit configured to detect a subject in an imaging range of the imaging unit;</claim-text><claim-text>a first recording unit configured to record contents of the control of the operation of the imaging unit based on the instruction from the user in chronological order as first information;</claim-text><claim-text>a second recording unit configured to record information corresponding to a result of the detection of the subject in chronological order as second information in association with the first information; and</claim-text><claim-text>a reproduction unit configured to reproduce the contents of the control of the operation of the imaging unit in chronological order based on the first information,</claim-text><claim-text>wherein the reproduction unit controls a speed of the reproduction based on the second information.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The imaging apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the detection unit detects the subject based on at least one of face detection, human body detection, moving object detection, or object detection.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The imaging apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the information corresponding to the result of the detection of the subject includes information about at least one of a focus position, a position of the detected subject, a distance to the detected subject, or a size of the detected subject.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The imaging apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the reproduction unit controls the speed of die reproduction to reduce a difference between a chronological transition of the information corresponding to the result of the detection of the subject in the reproduction and a chronological transition of the information corresponding to the result of the detection of the subject that is specified by the second information.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The imaging apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein in a case where a speed of the chronological transition of the information corresponding to the result of the detection of the subject in the reproduction is slower than a speed of the chronological transition of the information corresponding to the result of the detection of the subject that is specified by the second information, the reproduction unit controls the speed of the reproduction to a slower speed.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The imaging apparatus according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the reproduction unit adds another frame into which at least one of the contents of the control of the operation of the imaging unit or the information about the subject is interpolated, the other frame inserted between a plurality of chronologically consecutive frames among a series of frames on which the second information is recorded based on pieces of the second information corresponding to the plurality of frames.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The imaging apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein in a case where a speed of the chronological transition of the information corresponding to the result of the detection of the subject in the reproduction is faster than a speed of the chronological transition of the information corresponding to the result of the detection of the subject that is specified by the second information, the reproduction unit controls the speed of the reproduction to a faster speed.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The imaging apparatus according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the reproduction unit skips a control of the reproduction based on information corresponding to a frame that is included in information corresponding to a series of frames on which the second information is recorded.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A method for controlling an imaging apparatus, the method comprising:<claim-text>controlling an imaging operation of an imaging unit based on an instruction from a user;</claim-text><claim-text>detecting a subject in an imaging range of the imaging unit;</claim-text><claim-text>recording, as first recording, contents of the control of the operation of the imaging unit based on the instruction from the user in chronological order as first information;</claim-text><claim-text>recording, as second recording, information corresponding to a result of the detection of the subject in chronological order as second information in association with the first information; and</claim-text><claim-text>reproducing the contents of the control of the operation of the imaging unit in chronological order based on the first information,</claim-text><claim-text>wherein a speed of the reproduction is controlled based on the second information.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A non-transitory computer-readable recording medium that stores a program for causing a computer to perform a method for controlling an imaging unit, the method comprising:<claim-text>controlling an imaging operation of an imaging unit based on an instruction from a user;</claim-text><claim-text>detecting a subject in an imaging range of the imaging unit;</claim-text><claim-text>recording, as first recording, contents of the control of the operation of the imaging unit based on the instruction from the user in chronological order as first information;</claim-text><claim-text>recording, as second recording, information corresponding to a result of the detection of the subject in chronological order as second information in association with the first information; and</claim-text><claim-text>reproducing the contents of the control of the operation of the imaging unit chronological order based on the first information,</claim-text><claim-text>wherein a speed of the reproduction is controlled based on the second information.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An information processing apparatus comprising:<claim-text>a first recording unit configured to record contents of a control of an operation of an imaging unit based on an instruction from a user in chronological order as first information;</claim-text><claim-text>a second recording unit configured to record information corresponding to a subject detection result in chronological order as second information in association with the first information; and</claim-text><claim-text>a reproduction unit configured to reproduce the contents of the control of the operation of the imaging unit in chronological order based on the first information,</claim-text><claim-text>wherein the reproduction unit controls a speed of the reproduction based on the second information.</claim-text></claim-text></claim></claims></us-patent-application>
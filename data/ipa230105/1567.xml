<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001568A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001568</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17856851</doc-number><date>20220701</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>25</class><subclass>J</subclass><main-group>13</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>25</class><subclass>J</subclass><main-group>19</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>0081</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>13</main-group><subgroup>081</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>19</main-group><subgroup>063</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>13</main-group><subgroup>086</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>B</subclass><main-group>2219</main-group><subgroup>39384</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>B</subclass><main-group>2219</main-group><subgroup>39001</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Safety System for Hand-Guiding a Robot</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63218484</doc-number><date>20210705</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Mantis Robotics, Inc.</orgname><address><city>Danville</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Vannuffelen</last-name><first-name>Gerry</first-name><address><city>Danville</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Wang</last-name><first-name>Pei Jui</first-name><address><city>New Taipei City</city><country>TW</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A safety system for allowing a robot having a controller and at least one movable member to be manually guided by a user includes a sensor module is disposed on a surface of the robot that comprises a user-interaction sensor that produces a sensing signal. The sensor module further includes a resilient member having an outer surface. A motion control module is adapted to move the robot through the controller according to a first threshold of the sensing signal. A safety module is adapted for stopping movement of the robot through the controller according to a second threshold of the sensing signal and represents a potential threat of harm to the user.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="95.93mm" wi="94.74mm" file="US20230001568A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="206.76mm" wi="116.67mm" file="US20230001568A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="206.67mm" wi="127.51mm" file="US20230001568A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="212.51mm" wi="96.77mm" file="US20230001568A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="194.73mm" wi="132.76mm" orientation="landscape" file="US20230001568A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="183.64mm" wi="125.48mm" orientation="landscape" file="US20230001568A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="185.76mm" wi="135.64mm" orientation="landscape" file="US20230001568A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="174.41mm" wi="128.44mm" orientation="landscape" file="US20230001568A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="183.98mm" wi="136.65mm" orientation="landscape" file="US20230001568A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="185.17mm" wi="127.51mm" orientation="landscape" file="US20230001568A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="155.19mm" wi="129.29mm" file="US20230001568A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="195.75mm" wi="134.03mm" orientation="landscape" file="US20230001568A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="198.88mm" wi="130.47mm" orientation="landscape" file="US20230001568A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><p id="p-0002" num="0001">This application claims the benefit of U.S. Provisional Patent Application No. 63/218,484, filed Jul. 5, 2021, which is hereby incorporated by reference herein in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD</heading><p id="p-0003" num="0002">This disclosure relates to robotics, and more particularly to robotic safety systems.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Robotic systems are often used for industrial purposes. Such robotic systems include industrial robots. Care should be taken to ensure that industrial robots operate safely when in close proximity to humans (users).</p><p id="p-0005" num="0004">Industrial robots often equip with a 3-position enabling switch in a teaching pendant for a user to continuously press in a middle position to enable a teaching action (jog) of the robot. If the user fully releases the switch or fully presses the switch, the robot will stop safely. With the introduction of collaborative robots, which typically have a hand guide function to drag the robot in the tool end or the body to move the robot into a desired pose, it becomes inconvenient for a user to hold an enabling switch when performing hand guidance, as the user will only have a single hand free to perform the movement. Furthermore, enabling switches were originally designed to be used when the user jogs the robot from the teaching pendant, whereas in hand-guide implementations the user must put their hand on the robot, even with an enabling switch held presumably by the other hand. The risk that the robot injures the user's hand is much higher in a hand-guide mode than when jogging a robot from a distance with a remote interface, such as on a tablet computer or the like.</p><p id="p-0006" num="0005">Hence, other than the ability to practically hand-guide the robot, integration of a power and force limiting (PFL) function when hand-guiding may also be desirable.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0007" num="0006">A safety system is provided for hand guiding a robot that includes multiple movable parts, driven by actuators, and controlled by one or more processor.</p><p id="p-0008" num="0007">The safety system may include a safety cover for the robot that is mounted to one or more of the movable parts. The safety cover may include a sensor disposed on a surface of one of the movable parts. The sensor may include at least one sensor layer. The sensor may include additional layers such as one or more resilient layers and/or a cover layer. In implementations with multiple resilient layers, the resilient layers may have different rigidities. The sensor layer may contact with the movable part, may be interposed between and/or contact the resilient layers, and/or may form the cover layer (e.g., at an exterior or outer surface of the sensor).</p><p id="p-0009" num="0008">The sensor layer may generate sensor signals. The sensor signals may be indicative of an external object that applies a force to the sensor. The external object may, for example, be a body part such as a hand of a user. The external object may approach, contact, and/or apply pressure to one or more of the movable parts to teach or instruct a motion or pose of the movable to the robot. The sensor may detect a distance between the external object and the sensor layer. This distance may be detected via force, pressure, contact, proximity, optical, and/or ultrasonic sensing. The sensor layer may therefore include a force sensor layer, a contact sensor layer, a pressure sensor layer, a proximity sensor layer, an optical sensor layer, and/or a layer used to detect ultrasonic waveforms. If desired, the sensor may include multiple sensor layers of different types, such as an underlying force sensor and an overlying contact sensor.</p><p id="p-0010" num="0009">As an example, the sensor may detect a depression of a layer in the sensor relative to the underlying movable part as produced by contact and/or force applied to the sensor by the external object. The layer may be the sensor layer itself, one or more of the resilient layers, and/or a cover layer. As the amount of force applied by the external object increases, the amount of depression of the layer increases and the sensed distance between the external object and the sensor layer decreases accordingly. The sensor signal generated by the sensor layer may be indicative of the distance between the external object and the sensor layer (or equivalently the amount of depression of the layer). The sensor may pass the sensor signal to one or more processors such as one or more processors used to implement a motion control module and a safety module.</p><p id="p-0011" num="0010">When the sensor signals are indicative of the external object being within a predetermined range of distances from the sensor layer or, equivalently, are indicative of the amount of depression of the layer being within a predetermined range of depressions (e.g., when the sensor signals have a value within a range between a first threshold and a second threshold), the motion control module may control the robot to move one or more of the movable parts. The motion control module may, for example, control the robot to move at least the movable part underlying the sensor according to the motion that the external object is attempting to teach the robot (e.g., according to a manual instruction of guiding being applied to the movable part by the external object). When the sensor signals are indicative of the external object being outside the predetermined range of distances or, equivalently, are indicative of the amount of depression being outside the predetermined range of depressions (e.g., when the sensor signals have a value outside the range between the first and second thresholds, greater than the first threshold, less than the second threshold, etc.), the safety module may perform a safety operation to safely stop movement of the robot (e.g., by cutting power, slowing the motion, etc.).</p><p id="p-0012" num="0011">Multiple embodiments are provided, include different types of sensor that may be used to construct the user-interaction sensor, different types and structures of the resilient member that may present different effects of the safety system for hand guiding a robot. Furthermore, a robot adopted with the safety system that may provide a PFL function during the hand guiding is also introduced. Finally, multiple embodiments of the possible design of the resilient member are disclosed.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of an illustrative robot system in accordance with some embodiments.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of an illustrative robot system in accordance with some embodiments.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating how a user may teach a robot using a user interface having an enabling switch in accordance with some embodiments.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating how a user may manually teach a robot in a hand-guide mode with an enabling switch on a teaching pendant in accordance with some embodiments.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating how a user may manually teach a robot in a hand-guide mode through holding a tool end of the robot in accordance with some embodiments.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating how a user may manually teach a robot in a hand-guide mode through pressing a movable member of the robot in accordance with some embodiments.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a cross-sectional side view of an illustrative sensor module including a contact or force sensor mounted to a resilient member in accordance with some embodiments.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a chart of an illustrative sensing signal produced by a sensor module of the type shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, illustrating thresholds of the sensing signal in accordance with some embodiments.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>8</b>A</figref> is a cross-sectional side view of an illustrative sensor module including a force sensing sensor mounted to a resilient member that includes an inner resilient layer and an outer resilient layer in accordance with some embodiments.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>8</b>B</figref> is a chart of an illustrative sensing signal produced by a sensor module of the type shown in <figref idref="DRAWINGS">FIG. <b>8</b>A</figref>, illustrating thresholds of the sensing signal in accordance with some embodiments.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>9</b>A</figref> is a cross-sectional side view of an illustrative sensor module including a proximity sensor and having a resilient layer with an inner resilient layer and an outer resilient layer in accordance with some embodiments.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>9</b>B</figref> is a chart of an illustrative sensing signal produced by a sensor module of the type shown in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>, illustrating thresholds of the sensing signal in accordance with some embodiments.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>10</b>A</figref> is a cross-sectional side view of an illustrative sensor module including a proximity sensor and an external coverage member in accordance with some embodiments.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>10</b>B</figref> is a chart of an illustrative sensing signal produced by a sensor module of the type shown in <figref idref="DRAWINGS">FIG. <b>10</b>A</figref>, illustrating thresholds of the sensing signal in accordance with some embodiments.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>11</b>A</figref> is a cross-sectional side view of an illustrative sensor module including a proximity sensor and a contact detecting sensor in accordance with some embodiments.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>11</b>B</figref> is a chart of an illustrative sensing signal produced by a sensor module of the type shown in <figref idref="DRAWINGS">FIG. <b>11</b>A</figref>, illustrating thresholds of the sensing signal in accordance with some embodiments.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>12</b>A</figref> is a cross-sectional side view of an illustrative sensor module including a deformable air chamber and an air pressure sensor in accordance with some embodiments.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>12</b>B</figref> is a chart of an illustrative sensing signal produced by a sensor module of the type shown in <figref idref="DRAWINGS">FIG. <b>12</b>A</figref>, illustrating thresholds of the sensing signal in accordance with some embodiments.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a cross-sectional side view of an illustrative sensor module including a deformable air chamber constructed with two deformable materials having different rigidities and an air pressure sensor in accordance with some embodiments.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a cross-sectional side view of an illustrative resilient member having denser projections within the resilient member in accordance with some embodiments.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram of an illustrative sensor module mounted to a movable member of a robot and including a proximity sensor in accordance with some embodiments.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is diagram of an illustrative sensor module mounted to a movable member of a robot and including a medium propagating wave sensor in accordance with some embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0035" num="0034">The following description provides specific details for a thorough understanding of and enabling description for the disclosed embodiments. One of ordinary skill in the art will understand that one or more embodiments may be practiced without one or more of such specific details. In some instances, specific description of well-known structures or functions may have been omitted to avoid unnecessarily obscuring the description of the embodiments.</p><p id="p-0036" num="0035">Unless the context clearly requires otherwise, the words &#x201c;comprise,&#x201d; &#x201c;comprising,&#x201d; and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense. The words &#x201c;herein,&#x201d; &#x201c;above,&#x201d; &#x201c;below&#x201d;, when used in this description, refer to this description as a whole and not to any particular portions of this description. When the claims use the word &#x201c;or&#x201d; in reference to a list of two or more items, that word covers all of the following interpretations of the word: any of the items in the list, all of the items in the list, and any combination of the items in the list. When the word &#x201c;each&#x201d; is used to refer to an element that was previously introduced as being at least one in number, the word &#x201c;each&#x201d; does not necessarily imply a plurality of the elements but can also mean a singular element.</p><p id="p-0037" num="0036">Power and force limiting (PFL) is one key of user-robot collaboration in the case that a robot is allowed to move side-by-side with a human user. The robot can be a hand guided robot (e.g., a robot that is taught to perform movements or poses via hand-guidance by the user). In these scenarios, the user is physically located in the same working area as the robot and the robot moves. While the robot is under instruction from the user, and considering user-robot collaboration safety, there is a need to consider a situation where the robot loses control and bumps into the user or clamps a limb or hand of the user. Hence, in ISO 10218-1:2011 (Robots and robotic devices&#x2014;Safety requirements for industrial robots&#x2014;Part 1: Robots), hand guidance is required to be performed with an emergency stop button and an enabling switch mounted close to a tool end of the robot. In its extension, ISO/TS 15066:2016 (Robots and robotic devices&#x2014;Collaborative robots), PFL is considered as an important method for reducing the risk of hand guidance injuries. Having a safety rated PFL function may replace the requirement to mount emergency stop switches and enabling devices to the tool end, or the guiding device of a robot. In the perspective of user-robot collaborative safety, the safety rated PFL is more comprehensive than the combination of emergency stop switches and enabling switches, because the latter involves reaction time and judgement of the user during operation. For example, when the robot loses control during hand guidance, if the user does not immediately operate the emergency switch or the enabling switch properly, the user may still be hit or severely clamped down upon by the robot. A robot having a safety rated PFL function can stop before causing non-acceptable risk of injury, even when it hits or clamps onto the user.</p><p id="p-0038" num="0037">Joint current or joint torque sensors may perform PFL and hand guidance. However, the speed of the robot when performing PFL is significantly limited by the low sensitive and inaccuracy of the associated joint current modeling, which relates to the reduction gear of the joint. The speed of the robot can also be limited by the maximum allowable torque of a joint torque sensor. In addition, both types of sensors require precise modeling of the dynamics of the robot, which can be overly burdensome or expensive. In most cases, due to risk assessment, users still need to use an enabling switch and emergency stop button at the same time while they are hand guiding a collaborative robot, because most collaborative robots cannot reach an efficient speed in hand guide mode while keeping PFL at a proper level as indicated by safety regulations.</p><p id="p-0039" num="0038">Other than joint-based sensing solutions, mounting an enabling switch to the tool end of a robot to perform hand guidance is not intuitive because the direction of the pushing force applied to the enabling device is often different from the hand guidance direction. Other solutions like mounting a force and torque sensor in the tool end to perform hand guidance only solves the tool-end cartesian hand guidance, while there is also a need for hand guidance through manipulating the body of the robot (e.g., as a joint-based hand guidance). Solutions like mounting a safety skin or cover on a robot body and using it to manipulate the robot may still require an emergency stop button and enabling switch to reduce risk, because of the lack of integration of hand guidance and PFL.</p><p id="p-0040" num="0039">Integration of hand guidance and PFL has another remaining problem. When the user performs hand guidance, if the force exceeds a preset limit, the robot stops. The hand guidance force is never easily regulated at a certain level that does not trigger the stopping of the robot, especially when the user is focused on dragging the robot to a desired position or adjusting the pose of the robot. This results in frequent false-triggering the force/torque limit of the PFL, which lowers the efficiency of such hand guidance. While visual indications or vibrations may help to warn the user, the user still needs to handle the force applied carefully to prevent a false-triggering. Therefore, it may be desirable to be able to provide improved hand guidance systems for robots to integrate with PFL and to provide efficient hand guide functions.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an overview of a robot system <b>10</b>. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, robot system <b>10</b> may include robot <b>1</b>. Robot <b>1</b> may include a controller <b>4</b>, a user interface/switch <b>5</b>, and multiple movable members <b>2</b> (sometimes referred to herein as movable parts <b>2</b>, movable robot body members <b>2</b>, robot body members <b>2</b>, movable members <b>2</b>, or body linkages <b>2</b> of robot <b>1</b>) such as body links <b>101</b>, <b>102</b>, and <b>103</b>. Motion of body links <b>101</b>, <b>102</b>, and <b>103</b> may be actuated by actuators <b>11</b>. Some or all of movable members <b>2</b> may be covered by sensor modules <b>3</b> (sometimes referred to herein as sensor structures <b>3</b> or sensors <b>3</b>). In other words, sensor modules <b>3</b> may be mounted to one or more of body links <b>101</b>-<b>103</b>. Sensors <b>3</b> may sense the distance between the sensor(s) and a user <b>20</b>, the touch of user <b>20</b>, or a force applied to the sensor(s) by user <b>20</b> (e.g., the pressing of user <b>20</b> against the sensor(s)). Controller <b>4</b> may include a safety module <b>41</b> and a motion control module <b>42</b>. Sensor modules <b>3</b>, safety module <b>41</b>, and motion control module <b>42</b> may include one or more processors to process sensing signals, safety logics or motion control. The one or more processors may be one or more central processing units (CPUs), one or more digital signal processors (DSPs), one or more microcontroller units (MCUs), one or more application specific integrated circuits (ASICs), and/or one or more field programmable gate arrays (FPGAs).</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a schematic architecture diagram of robot system <b>10</b>. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, sensor module <b>3</b> may be coupled to controller <b>4</b>. Sensor module <b>3</b> may convey analog, digital, or communication signals with safety module <b>41</b> and motion control module <b>42</b>, which deliver control signals to robot <b>1</b>. Motion control module <b>42</b> may be configured to process signals received from sensor module <b>3</b>, may calculate the kinematics of the robot <b>1</b>, and/or may control actuators <b>11</b> to perform motions (e.g., cartesian space motions or joint space motions). Safety module <b>41</b> may process signals received from sensor module <b>3</b>, may make decisions for safety actions, and may be coupled to a safety execution structure <b>411</b> that executes a safety stop of robot <b>1</b>. The safety execution structure <b>411</b> may, for example, include circuitry (e.g., switches) that cuts power provided to actuators <b>11</b> (Cat. 0 stop in IEC60204-1 or STO defined in IEC61800-5-2), that cuts the power after instructing motion control module <b>42</b> to decrease the speed of movable members <b>2</b> of robot <b>1</b> (Cat. 1 stop in IEC60204-1 or SS1 in IEC61800-5-2), or that monitors a standstill state of movable member <b>2</b> of robot <b>1</b> after instructing motion control module <b>42</b> to decrease the speed of movable members <b>2</b> of robot <b>1</b>, and if the standstill state is violated, that cuts the power provided to actuators <b>11</b> (Cat. 2 stop in IEC60204-1 or SS2 in IEC61800-5-2).</p><p id="p-0043" num="0042">In this overview of the system, sensor module <b>3</b> may generate sensor signals (sometimes referred to herein as control signals, sensor output signals, sensor output, or sensor data). The sensor signals may be indicative of touch or force applied to sensor module <b>3</b> and/or of proximity between the sensor module and an external object such as the user. The sensor signals may include a trigger of a hand guidance motion associated with a hand guidance instruction performed by user <b>20</b> in a hand guidance mode of robot <b>1</b>. Additionally or alternatively, the sensor signals may identify a touch position of an instruction force applied to sensor module <b>3</b>, may include an identification (ID) number or other identifying information of sensor module <b>3</b> (e.g., identification information that identifies or is associated with a known mounting location of the sensor module <b>3</b> on robot <b>1</b>), and/or may include or identify a coordinate of where on sensor module <b>3</b> user <b>20</b> is touching (sometimes referred to herein as a touched position). Sensor module <b>3</b> may transmit the generated sensor signals to safety module <b>41</b> and motion control module <b>42</b> for use in subsequent processing.</p><p id="p-0044" num="0043">Motion control module <b>42</b> may use the received sensor signals to generate control the motion of the robot <b>1</b> (e.g., to follow an instruction of touching, pressing, or proximity performed by user <b>20</b> in performing hand guidance and as identified by the sensor signals). The hand guidance motion may be a position control of the cartesian space or joint space motion of the robot, or a &#x201c;Zero gravity&#x201d; compliance control that allows robot <b>1</b> to be easily moved by an external force when the sensor signal from sensor module <b>3</b> solely indicates an enabling signal. If desired, the sensor signal generated by sensor module <b>3</b> may also include a detected magnitude of the instruction force, a proximal distance, or a proximal speed that the motion control module <b>42</b> may utilize to adjust the speed or the compliance of the hand guidance motion (e.g. a larger instruction force, a shorter proximal distance, or a higher proximal speed may indicate a faster guided motion speed).</p><p id="p-0045" num="0044">Safety module <b>41</b> may use the sensor signals generated by sensor module <b>3</b> to perform PFL. For example, when a certain level of force or proximal distance is detected by sensor module <b>3</b>, safety module <b>41</b> may control safety execution structure <b>411</b> to safely stop the robot.</p><p id="p-0046" num="0045">In addition, safety module <b>41</b> may use the sensor signals to keep robot <b>1</b> in a safety stop status while the hand guidance instruction force, proximal distance, or contact is not detected. Combined with the PFL function, sensor module <b>3</b> and safety module <b>41</b> may perform a safety function like a 3-position enabling switch in the perspective of functional safety and machinery safety by forming an OFF-ON-OFF manipulation. This kind of design may ensure safety when the robot <b>1</b> loses control. User <b>20</b> may, for example, either fully release sensor module <b>3</b> or fully press sensor module <b>3</b> to stop the robot <b>1</b> safely. It may also ensure that in the hand guidance mode, without the user's triggering, robot <b>1</b> will be in a standstill state safely. An example of the actions of the motion control module <b>42</b> and the safety module <b>41</b> is shown in Table 1 below:</p><p id="p-0047" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="49pt" align="left"/><colspec colname="2" colwidth="91pt" align="left"/><colspec colname="3" colwidth="77pt" align="left"/><thead><row><entry namest="1" nameend="3" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry/><entry>Signal:</entry><entry>Signal:</entry></row><row><entry/><entry>PFL not reached</entry><entry>PFL reached</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>Signal:</entry><entry>Motion control module:</entry><entry>Motion control module:</entry></row><row><entry>No Contact</entry><entry>No hand guide motion</entry><entry>No hand guide motion</entry></row><row><entry/><entry>Safety module:</entry><entry>Safety module:</entry></row><row><entry/><entry>Safety Stop</entry><entry>Safety Stop</entry></row><row><entry/><entry/><entry>*This may only happen </entry></row><row><entry/><entry/><entry>when there is a </entry></row><row><entry/><entry/><entry>fault in the system</entry></row><row><entry>Signal:</entry><entry>Motion control module:</entry><entry>Motion control module:</entry></row><row><entry>Contacted</entry><entry>hand guide motion is </entry><entry>No hand guide motion</entry></row><row><entry/><entry>triggered, motion direction </entry><entry>Safety module:</entry></row><row><entry/><entry>is generated by considering </entry><entry>Safety Stop</entry></row><row><entry/><entry>the pressing position</entry><entry/></row><row><entry/><entry>on the robot, and the </entry><entry/></row><row><entry/><entry>motion velocity or the </entry><entry/></row><row><entry/><entry>compliance is proportional </entry><entry/></row><row><entry/><entry>to the contact force</entry><entry/></row><row><entry/><entry>Safety module:</entry><entry/></row><row><entry/><entry>Cancel the safety stop</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0048" num="0046">The sensor signals generated by sensor module <b>3</b> may be a trigger signal (High/Low) of a result of processing of one or more processors in sensor module <b>3</b>, or a signal with a magnitude, and then processed by safety module <b>41</b> and/or motion control module <b>42</b>.</p><p id="p-0049" num="0047">The systems and methods described herein may replace functions of the enabling switch and the emergency switch during hand guidance, which brings improved efficiency for the hand guidance of a robot as users do not need to hold additional buttons or switches in their hands, hence both hands can be used on hand guiding of the robot. The systems and methods described herein also exhibits improved safety performance by having a more direct risk reduction design than the enabling switch or emergency switch that relies more on the user's reaction to trigger a safety stop.</p><p id="p-0050" num="0048">An important factor in the safety performance of a machine is the time between a fault happening (e.g., the loss of control that violates a user's instructions) and the activation of the safety protection system (e.g., the safety stop function of a robot). This time includes reaction time of the user and the reaction time of the machine. The process can be broken down to the time for user to recognize that there is a fault, the time for the user to consider the action that he/she need to take, the time for user to act to trigger the safety system (like pressing the emergency stop or to fully press/fully release the enabling switch), and then the reaction time inside the machine to process the emergency signal in the safety system to order a safety stop.</p><p id="p-0051" num="0049">Before the user triggers the safety system, the machine may still be in a loss of control status, which brings additional safety risk. Even after triggering the safety stop, the robot needs a stopping time and distance to stop due to inertia. A longer user reaction time brings increased hazards and a worse safety performance because within this period the robot is not yet stopped and is still moving with the original speed in an errant manner.</p><p id="p-0052" num="0050"><figref idref="DRAWINGS">FIGS. <b>3</b>-<b>5</b></figref> show some solutions of safety reduction in manipulating a robot: jogging a robot (<figref idref="DRAWINGS">FIG. <b>3</b></figref>) with a teaching pendant/tablet having an enabling switch, hand guiding a robot with a teaching pendant/tablet having an enabling switch (<figref idref="DRAWINGS">FIG. <b>4</b></figref>) and hand guiding a robot with a tool end enabling switch (<figref idref="DRAWINGS">FIG. <b>5</b></figref>).</p><p id="p-0053" num="0051">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, during jogging of the robot, the user needs to observe the movement of the robot with their eyes, recognizing if the robot moves according to the jog command that user gives by continuously pressing (&#x201c;hold to run&#x201d;) the physical or software buttons or switches, which usually do not belong to a safety rated device of software, on the teaching pendant (in front of the user, not shown in the figure). At the same time, the user needs to hold a safety rated enabling device <b>5</b> at a middle position continuously. Once the robot performs an unexpected action, the user needs to realize that the unexpected action has occurred and then fully press or fully release the enabling switch <b>5</b> in hand to stop the robot safely.</p><p id="p-0054" num="0052"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a solution in which robot <b>1</b> includes a hand guide function that requires the user to hold the tool end of robot <b>1</b> to guide robot <b>1</b>. When performing such a hand guiding manipulation, a similar effort is required&#x2014;a hold-to-run button needs to be held, and a safety rated enabling device <b>5</b> needs to be pressed in its middle position continuously.</p><p id="p-0055" num="0053"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a solution in which the hold-to-run button and safety rated enabling device are mounted to the tool end of robot <b>1</b>. If desired, the function of the hold-to-run button and safety rated enabling device may be combined and performed by a safety rated 3-position enabling device <b>5</b>. <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a scenario wherein the user holds the tool end by hand and concurrently presses the enabling switch <b>5</b> with their thumb (e.g., in a pressing direction A) to hand guide the robot, while the robot may detect the guiding force with built-in sensors such as tool end force/torque sensor, or joint torque sensors. When a robot performs unexpected motions, the instinctive reaction of the user may be to hold the robot tool end to stop the robot. If the robot swings away along direction B, it is easiest for the user to react because the direction A that user pressing the enabling device <b>5</b> is just the same with the direction of blocking the running direction of the robot. But in the case where the robot swings errantly along direction B&#x2032;, it is more difficult to instinctively press or release the enabling switch, and the runaway direction C is the most difficult case for user to instinctively press the enabling device <b>5</b>.</p><p id="p-0056" num="0054"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an implementation that may allow a better reaction time and a more intuitive, no-need-for-training arrangement relative to the arrangements of <figref idref="DRAWINGS">FIGS. <b>3</b>-<b>5</b></figref>. As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, robot <b>1</b> may be covered with multiple sensor modules <b>3</b> on the surfaces of its body linkages <b>2</b>. The user may perform the hand guiding and safety functions shown and described in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref> and in table 1. User <b>20</b> may guide robot <b>1</b> by pressing one or more sensor module <b>3</b> in a corresponding direction A. If a fault occurs in robot <b>1</b> that causes the robot to swing errantly away along direction B or C, the user instinctively blocks the robot, and the blocking force may trigger PFL provided by sensor module <b>3</b> and safety module <b>41</b> which serve to stop the robot safely. This action may equate to the full pressing of an enabling switch that enables the robot's motion. In the case where after a fault occurs, the robot swings errantly in direction B&#x2032; and C&#x2032;, the robot leaves the user which also trigger a stop (e.g., according to the logics presented in table <b>1</b>), equating to releasing the enabling switch. In case of D and D&#x2032;, although the runaway direction does not directly cause pressing of release, the user still has a chance to react to stop the robot by simply leaving his/her hand in place, grasping the robot (and so grasping the sensor module <b>3</b>), or to press deeper on the sensor module <b>3</b> to stop the robot.</p><p id="p-0057" num="0055">If the user is not pushing the robot as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, and is grasping/pulling the robot, such as in the case of direction B&#x2032;/C&#x2032;/D/D&#x2032;, the safety design also works well because the instinctive reaction to grasp and hold the robot, if it is moving errantly, will also trigger the PFL.</p><p id="p-0058" num="0056">Even if the user does not leave their hand on the robot or press deeper to stop the robot and still holds the sensor module <b>3</b> at an average level of force continuously (although this is unlikely to happen) which still enables the robot, causing the robot to bump into objects in the environment or part of the user, the PFL will still be triggered in such contact as long as the robot is covered with the sensor modules <b>3</b>.</p><p id="p-0059" num="0057">The implementations of <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>2</b></figref> and table <b>1</b> integrate the enabling function into the entire body of the robot using sensor modules <b>3</b>, so that the user does not need to put one or more fingers or hands on an additional enabling device and can use all their fingers or hands as needed (e.g., to manually instruct or teach the robot).</p><p id="p-0060" num="0058">Sensor module <b>3</b> may include any desired sensor structures for sensing force, proximity, and/or touch of the user along some or all of robot <b>1</b>. Sensor module <b>3</b> may include a sensor <b>31</b> mounted to a sensor structure such as resilient member <b>32</b>. Resilient member <b>32</b> may, for example, be a rigid or deformable member, support, substrate, layer, or support structure for sensor <b>31</b>. Resilient member <b>32</b> may be formed from foam, polymer, plastic, rubber, or other materials, for example. Resilient member <b>32</b> may couple sensor <b>31</b> to the underlying movable part <b>2</b> of robot <b>1</b>. Sensor <b>31</b> may sometimes be referred to herein as sensor layer <b>31</b>, active layer <b>31</b>, sensing layer <b>31</b>, or the sensing/active portion <b>31</b> of sensor module <b>3</b>.</p><p id="p-0061" num="0059"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> show one example in which sensor <b>31</b> in sensor module <b>3</b> is a force sensor. The force sensor may sense and output a magnitude of contact force to its surface (e.g., as applied by user <b>20</b>). The force sensor may be, for example, a resistive force or contact sensor (e.g., a sensor that senses force or contact via minute or large depressions or forces applied to the sensor). Sensor module <b>3</b> may be disposed (layered) onto the outer surface of one of the movable parts <b>2</b> of robot <b>1</b>. Sensor <b>31</b> (e.g., a force sensor) may be located on/at the outer surface <b>36</b> of sensor module <b>3</b> (e.g., the side of sensor module <b>3</b> opposite movable part <b>2</b>). This kind of arrangement may maximize the sensitivity of the force sensing sensor that it contacts and detects the external object first so it will have a most clear contact signal for hand guidance. Sensor module <b>3</b> may further include one or more processors <b>34</b> (e.g., control circuitry), which can include an MCU and/or other circuitry coupled to sensor <b>31</b>. Sensor <b>31</b> may generate a sensor signal in response to a force applied to sensor module <b>3</b> (e.g., by user <b>20</b>). One or more processors <b>34</b> may process the sensor signal and/or may provide the sensor signal to motion control module <b>42</b> and safety module <b>41</b> in controller <b>4</b> of robot <b>1</b>.</p><p id="p-0062" num="0060"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> shown a sequence of user's hand approaching sensor module <b>3</b>. <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> illustrates the corresponding sensing signal <b>35</b> produced by sensor <b>31</b>. In the first (left-most) portion of <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, the user's hand is not yet touching the sensor <b>31</b>, so there is no force detected, and the sensor module <b>3</b> may not output a hand guidance instruction signal to controller <b>4</b>. Then, in the second portion of <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, user <b>20</b> contacts sensor <b>31</b>, the contact force may be sensed by sensor module <b>3</b>, and motion control module <b>42</b> may be configured not to initial (initialize) a hand guidance motion. Until the force reaches a set level of magnitude (e.g., threshold <b>51</b> in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>), as a first compression status in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, the motion control module <b>42</b> may start to perform the hand guidance motion. This may eliminate the false triggering of the hand guidance motion, such as in the case when external wirings of the robot are dropped on or leaned on the sensor module <b>3</b>. Then, following the increasing of the compression, the user's hand may finally reach a status shown in the third portion of <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>: the full compression of the resilient member <b>32</b>, where the force that sensor <b>31</b> senses reaches a threshold <b>53</b> in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>. This is a steady supported status for the hand of the user <b>20</b>, wherein motion control module <b>42</b> may maintain robot <b>1</b> in a hand guidance motion. Then, if there is a larger force than threshold <b>53</b>, for example, a set threshold <b>52</b> in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> (e.g., a force that falls outside the range between thresholds <b>53</b> and <b>52</b>), sensor module <b>3</b> may send out a safety signal to safety module <b>41</b>, and the robot <b>1</b> may be stopped safely by safety module <b>41</b>. The force sensed by sensor module <b>3</b> reaching threshold <b>52</b> may correspond to a status in which resilient member <b>32</b> is fully compressed, and with additional force applied on the sensor module <b>3</b>, such as when the user presses harder.</p><p id="p-0063" num="0061">When robot <b>1</b> is in a hand guidance mode and user <b>20</b> does not press sensor module <b>3</b> of robot <b>1</b>, the hand guidance may not be triggered. Then with a proper level of instruction force, robot <b>1</b> may initialize the hand guiding. During hand guidance, user <b>20</b> may press sensor module <b>3</b> with a range of instruction force, and finally can feel a physical limitation or a blocking, so user <b>20</b> can keep a relatively constant instruction force applied that is easy to maintain while not triggering a safety stop.</p><p id="p-0064" num="0062">When robot <b>1</b> loses control, there may be three main scenarios. In the first scenario, user <b>20</b> may recognize that robot <b>1</b> is not following their instruction, so the user either tries to hold robot <b>1</b> to stop it or is shocked and releases contact with robot <b>1</b>. In both cases robot <b>1</b> will stop safely. In the second scenario, robot <b>1</b> may errantly move toward user <b>20</b>, and then robot <b>1</b> will also be stopped safely because the set threshold <b>52</b> is finally reached and PFL triggers the stop of robot <b>1</b> safely. In the third scenario, although less likely, user <b>20</b> may still maintain a proper instruction/enabling force (e.g., according to threshold <b>53</b>) to sensor module <b>3</b> and robot <b>1</b> may not be safely stopped and may still be enabled, but when robot <b>1</b> finally bumps into an external object like the environment or user <b>20</b>, threshold <b>52</b> is reached and PFL triggers robot <b>1</b> to stop safely.</p><p id="p-0065" num="0063">The resilient member <b>32</b> in this case may also act as a buffer of PFL bumping processes that detect a collision and trigger the safety stop before the movable parts <b>2</b> of the robot <b>1</b> bump into the environment or user <b>20</b>. There is a reaction time of sensor module <b>3</b> that senses and processes the sensor signal produced by sensor <b>31</b>, deciding and triggering the stop, while the signal to trigger the stop may need further processing in safety module <b>41</b>. During this time period, robot <b>1</b> may not yet stop and move with the original speed, or, under a fault situation, an unexpected speed in a loss of control status. In a case wherein robot <b>1</b> has the PFL function but does not have resilient member <b>32</b>, the rigid body of the robot <b>1</b> (e.g., the movable parts <b>2</b>) may hit user <b>20</b> first then triggering PFL to stop, and the final impact force may be large because the impact force is generated once the rigid body of robot <b>1</b> hits user <b>20</b>. Within the sensor's reaction time, robot <b>1</b> may still move at the original speed, so the impact force is much higher. Putting soft covers on robot <b>1</b> may absorb some of the shock and decrease the harm to the user, but a prior triggering of stop before the rigid body of the robot <b>1</b> hits the user will significantly lower the maximum impact force.</p><p id="p-0066" num="0064"><figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> show another example in which resilient member <b>32</b> includes multiple sub-layers such as a first resilient layer <b>62</b> and a second resilient layer <b>61</b> (e.g., resilient member <b>32</b> may sometimes be referred to herein as resilient layer <b>32</b> whereas layers <b>61</b> and <b>62</b> form sub-layers of resilient layer <b>32</b>). Second resilient layer <b>61</b> may be layered on movable part <b>2</b> of robot <b>1</b>, first resilient layer <b>62</b> may be layered on second resilient layer <b>61</b>, and sensor <b>31</b> may be layered on first resilient layer <b>62</b> (e.g., resilient layer <b>62</b> may be interposed between sensor <b>31</b> and resilient layer <b>61</b>). First resilient layer <b>62</b> (sometimes referred to herein as layer <b>62</b> or sub-layer <b>62</b>) and second resilient layer <b>61</b> (sometimes referred to herein as layer <b>61</b> or sub-layer <b>61</b>) may have different rigidities. This may serve to create a clear physical support for the user to recognize and to consciously apply a proper instruction force on the sensor <b>31</b>. In the case shown in <figref idref="DRAWINGS">FIG. <b>8</b>A</figref>, the rigidity of resilient layer <b>61</b> may be higher than the rigidity of resilient layer <b>62</b> (e.g., resilient layer <b>61</b> is more rigid than resilient layer <b>62</b>). Alternatively, resilient layer <b>61</b> may be less rigid than resilient layer <b>62</b>. If a harder (more rigid) resilient layer is arranged on top of a softer (less rigid) resilient layer, the function may be similar, because when the layers are pressed by an external force, the layer with the lower rigidity will be compressed first.</p><p id="p-0067" num="0065"><figref idref="DRAWINGS">FIG. <b>8</b>B</figref> shows the corresponding sensor signal <b>35</b> that may be generated (sensed) by sensor <b>31</b>. As shown in <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>, first, when user <b>20</b> is not yet touching the sensor module <b>3</b>, no force is detected. Then, user <b>20</b> touches the sensor module <b>3</b> and starts to compress resilient layer <b>62</b>, but only until the resilient layer <b>62</b> is fully compressed (e.g., as shown in the third portion of <figref idref="DRAWINGS">FIG. <b>8</b>A</figref>), causing the sensing signal to reach a set (predetermined) threshold <b>53</b>, which causes motion control module <b>42</b> to start to put the robot <b>1</b> in a hand guidance motion. If user <b>20</b> continuously presses deeper, the user may start to compress the underlying resilient layer <b>61</b> and may feel a harder physical resistance, allowing the user to know they can keep the instruction force at a proper level. The trigger of the safety stop (e.g., threshold <b>52</b> in <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>) is preferably set in a distance that under a certain depth that the resilient layer <b>61</b> is compressed, to have a buffer for avoiding false triggering to the safety stop.</p><p id="p-0068" num="0066"><figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> show an example in which sensor <b>31</b> is a proximity sensor. The proximity sensor may be, for example, a capacitive proximity sensor that detects when any approaching conductor, like a human hand or the metal parts in the environment, changes a capacitance detected by the sensor. In this example, sensor <b>31</b> (e.g., a proximity sensor) may be arranged under the resilient layer <b>32</b> (e.g., between resilient layer <b>32</b> and movable member <b>2</b>). The resilient layer's material may be selected so as not to impede the sensing of capacitance through the resilient layer by the underlying sensor <b>31</b>. For example, resilient member <b>32</b> may include an insulated material that allows the capacitive proximity sensing to pass through the resilient member <b>32</b> and to still allow sensor <b>31</b> to detect external conductive objects approaching sensor module <b>3</b>. If desired, resilient member <b>32</b> of <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> may include a resilient layer <b>62</b> and a resilient layer <b>61</b> having different rigidities.</p><p id="p-0069" num="0067">Referring to <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, the sensing signal <b>35</b> is indicative of the distance sensed by sensor <b>31</b> between sensor <b>31</b> and an external object (e.g., user <b>20</b>). In the beginning the sensed distance to user <b>20</b> is larger than the thickness of the resilient member <b>32</b>. Then, if desired, only after the user's hand presses the resilient member <b>32</b> and compresses a certain set depth of the resilient layer <b>62</b> (second portion of <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>), motion control module <b>42</b> starts to put the robot <b>1</b> into hand guided motion. The steady supported status is shown in the third portion of <figref idref="DRAWINGS">FIG. <b>9</b>A</figref> and the corresponding set threshold <b>53</b> to let motion control module <b>42</b> to initialize hand guide motion of robot <b>1</b> is shown in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>. The safety stop threshold <b>52</b> in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref> corresponds to the fourth portion of <figref idref="DRAWINGS">FIG. <b>9</b>A</figref> and may function similar to as shown in <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>.</p><p id="p-0070" num="0068">In the example shown in <figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref>, if desired, the distance threshold <b>51</b> to let motion control module <b>42</b> initial a hand guide motion may be set at a distance corresponding to user <b>20</b> being kept at a certain distance from the outer surface of resilient member <b>32</b>, whereas the distance threshold <b>53</b> may be set at a distance corresponding to user <b>20</b> touching the surface resilient member <b>32</b>, which works as a physical steady status of continuously enabling the hand guide. Furthermore, if desired, the distance threshold <b>53</b> may also be set at a distance corresponding to user <b>20</b> being kept a certain distance to the outer surface of resilient member <b>32</b> but is shorter than the case of threshold <b>51</b>. In such a case, the resilient member may still absorb the impact force to the user when an error is occurred, and robot loses control.</p><p id="p-0071" num="0069"><figref idref="DRAWINGS">FIGS. <b>10</b>A and <b>10</b>B</figref> show an alternative example in which sensor <b>31</b> is a proximity sensor and in which a cover layer such as covering layer <b>33</b> is layered over sensor module <b>3</b> (e.g., at/on the outer surface <b>36</b> of sensor module <b>3</b>). In this example, sensor <b>31</b> may detect the distance between sensor <b>31</b> and covering layer <b>33</b> instead of detecting the distance between sensor <b>31</b> and the external object. As user <b>20</b> presses on covering layer <b>33</b> and covering layer <b>33</b> is deformed towards sensor <b>31</b>, sensor <b>31</b> may thereby detect the presence of user <b>20</b> and the force applied by user <b>20</b> via the corresponding deformation of resilient layer <b>32</b> as sensed via the distance between covering layer <b>33</b> and sensor <b>31</b>. Adding the covering layer <b>33</b> may bring advantages for some applications such as when sensor <b>31</b> is a capacitive proximity sensor and the external object to be detected is not conductive. At the same time in some industrial applications, robot <b>1</b> may be required to be anti-static, which means the surface of sensor module <b>3</b> cannot be an insulator which will gather static electricity. Another advantage is that the covering layer <b>33</b> can be an enclosure that protects the sensor module <b>3</b>, particularly when installed in a severe industrial environment, which may not be friendly to the resilient member <b>32</b> (e.g., when filled with oil or oil gas). The example of <figref idref="DRAWINGS">FIGS. <b>8</b>-<b>10</b></figref> in which resilient layer <b>61</b> is layered on resilient layer <b>62</b> is merely illustrative. If desired, sensor layer <b>31</b> may be interposed between resilient layer <b>61</b> and resilient layer <b>62</b> in any of these examples (e.g., resilient layer <b>62</b> or an additional cover layer may form the exterior surface of sensor module <b>3</b> and/or resilient layer <b>61</b> may be layered onto or in contact with movable part <b>2</b>).</p><p id="p-0072" num="0070"><figref idref="DRAWINGS">FIGS. <b>11</b>A and <b>11</b>B</figref> shows an example in which sensor module <b>3</b> includes a contact sensor <b>37</b> in its outermost layer, a single-layer resilient member <b>32</b>, and an where the underlying sensor <b>31</b> is a proximity sensor. The material or design of the resilient member <b>32</b> may be configured to allow proximity sensing to pass through the resilient layer. The contact sensor <b>37</b> may detect whether or not it is being touched by a user or external object. Contact sensor <b>37</b> may, for example, include resistive or capacitive touch screens or a medium propagating wave sensor. A medium propagating wave sensor may generate and propagate ultrasonic waves through the surface of contact sensor <b>37</b> and may measure changes of the wave form when an external body touches or deforms the surface of contact sensor <b>37</b>. Contact sensor <b>37</b> may detect if it is touched or not and may generate a corresponding sensor signal for one or more processors <b>34</b> that is used to trigger the hand guidance motion. When contact sensor <b>37</b> is touched, the resilient member <b>32</b> may only have a very small compression (amount of depression) or no compression (amount of depression), and this may be set as the threshold <b>51</b> for motion control module <b>42</b> to initialize a hand guide motion. The sensor signal indicating whether or not contact sensor <b>37</b> is being touched or not may also be sent to the safety module <b>41</b> with a safety transmission method like a safety <b>10</b> or a safety rated communication, to put the robot <b>1</b> in a safety stop when it is not being touched. <figref idref="DRAWINGS">FIG. <b>11</b>B</figref> shows the signal that sensor <b>31</b> may sense during the hand guiding process shown in <figref idref="DRAWINGS">FIG. <b>11</b>A</figref>. Sensor <b>31</b> may detect a deeper compression (depression) if user <b>20</b> continues to apply a compressive force after touching contact sensor <b>37</b>. Then, within a range of compression (depression) to the resilient member <b>32</b>, the user can still manipulate the hand guidance of the robot <b>1</b>, as shown in <figref idref="DRAWINGS">FIG. <b>11</b>B</figref> (e.g., between threshold <b>51</b> and <b>52</b>). When a set compression threshold <b>52</b> is reached, the safety module <b>41</b> may stop the robot <b>1</b> safely. The advantage of this arrangement is that it allows for a lighter contact force to trigger and manipulate the hand guidance, but still provides a steady physical contact for user to properly perform a continuously enabling, for example, continuously touching the surface of sensor <b>37</b>.</p><p id="p-0073" num="0071">For the embodiments disclosed in <figref idref="DRAWINGS">FIG. <b>10</b>A-<b>11</b>B</figref>, sensor <b>31</b> may include an optical sensor, where resilient member <b>32</b> is non-opaque (transparent or translucent). The optical sensor can be an infrared sensor that emits infrared light and receives reflection infrared light from the covering layer <b>33</b> (e.g., in <figref idref="DRAWINGS">FIG. <b>10</b>A</figref>) or contact sensor <b>37</b> (e.g., in <figref idref="DRAWINGS">FIG. <b>11</b>A</figref>), and then outputs a sensor signal identifying proximity distance. Another kind of optical sensor <b>68</b> is a micro camera that monitors a pattern (not shown) marked in the inner side of the layer <b>33</b><i>d </i>or <b>33</b><i>e </i>and calculates the compressed distance or the amount of deformation of the resilient member <b>32</b>.</p><p id="p-0074" num="0072"><figref idref="DRAWINGS">FIGS. <b>12</b>A and <b>12</b>B</figref> show an example in which sensor module <b>3</b> includes a pressure sensor <b>71</b> that detects a change in air pressure inside of resilient member <b>32</b>, which may include a deformable air chamber <b>70</b>. A relationship between the air pressure and the compression (depression) of the deformable air chamber <b>70</b> may be predetermined. The resilient member <b>32</b> may include a deformable plate <b>72</b> arranged inside the air chamber <b>70</b> with holes so the air between the two spaces separated by the deformable plate is connected. The deformable plate <b>72</b>, as shown in the second portion of <figref idref="DRAWINGS">FIG. <b>12</b>A</figref>, provides a physical interface for the steady supported status for indicating the maximum hand guidance instruction force. The sensing signal <b>35</b> in such an example is shown in <figref idref="DRAWINGS">FIG. <b>12</b>B</figref>, and thresholds <b>51</b>, <b>52</b>, and <b>53</b> may function similar to the former embodiments for the hand guide and PFL of a robot.</p><p id="p-0075" num="0073">As shown in the example of <figref idref="DRAWINGS">FIG. <b>13</b></figref>, instead of including deformable plate <b>72</b> in <figref idref="DRAWINGS">FIG. <b>11</b>A</figref>, deformable air chamber <b>70</b> may be formed from resilient layers <b>61</b> and <b>62</b> having different rigidities. For example, resilient layer <b>62</b> may form an upper portion or wall of deformable air chamber <b>70</b>, resilient layer <b>61</b> may form a lower portion or wall of deformable air chamber <b>70</b>, and resilient layers <b>62</b> and <b>61</b> may collectively surround and enclose the air chamber. The differing rigidities may provide physical support for user to continue enabling during a hand guide process.</p><p id="p-0076" num="0074">If desired, the example shown in <figref idref="DRAWINGS">FIG. <b>11</b>A</figref> may include two layers of deformable air chambers one on top of another, and each having a pressure sensor to detect the deformation of them when user compress them. The rigidity of one air chamber may be higher than another one, so as to provide a physical support to let user apply a proper enabling force continuously during a hand guide motion.</p><p id="p-0077" num="0075"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows examples in which resilient member <b>32</b> includes deformable pillars or projections <b>69</b> mounted on a top or a bottom of the internal space (air chamber) of resilient member <b>32</b>. Projections <b>69</b> may form a steady compression recognition for the physical support for the user to apply proper enabling force during a hand guide process (e.g., the user may feel the presence of projections <b>69</b> when the user has pressed a certain amount, allowing the user to know how much force to continue to apply during the hand guide process without ending the hand guide process or triggering a safety stop). This example may be used wherein the sensor module <b>3</b> detects the deformation of resilient member <b>32</b> through different kind of sensing technology, for example proximity sensing, force sensing, pressure sensing, as described above.</p><p id="p-0078" num="0076"><figref idref="DRAWINGS">FIG. <b>15</b></figref> shows an example of robot <b>1</b> having multiple sensor modules <b>3</b>. Sensor modules <b>3</b> may be disposed on robot <b>1</b> in a manner that covers multiple movable members <b>2</b> of robot <b>1</b>, such as the movable members indicated by letters A, B, C, D, E, and F in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. Sensor module <b>3</b> may provide PFL safety function and enabling hand-guiding at the same time. The cross-sectional side view in <figref idref="DRAWINGS">FIG. <b>15</b></figref> shows an example structure of sensor module <b>3</b>. In this example, sensor module <b>3</b> includes an array of sensors <b>31</b> such as proximity sensors, which may allow sensor module <b>3</b> to detect the location on sensor module <b>3</b> and thus the corresponding movable member where the hand guide instruction is being applied by the user. The sensing signals generated by sensor module <b>3</b> may include information identifying this location (e.g., the location of the particular sensor <b>31</b> that detected contact/pressing by the user). The information identifying the pressed position then can be used in motion control module <b>42</b> to generate the hand guidance motion of the robot corresponding to a contact point of the resilient member <b>32</b>.</p><p id="p-0079" num="0077"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows an example in which sensor <b>31</b> is a medium propagating wave contact sensor, which also plays the role of the covering layer <b>33</b> of sensor module <b>3</b>. The covering layer <b>33</b> may be a rigid cover and sensor <b>31</b> may generate an ultrasonic wave that propagates along the cover. Sensor module <b>3</b> may include a resilient layer <b>32</b>, for example a layer of foam, and deformable pillars or projections <b>69</b> on an underlying support structure <b>331</b> that couples the sensor module to movable member <b>2</b> of the robot <b>1</b>. When the user <b>20</b> presses the covering layer <b>33</b>, resilient layer <b>32</b> is compressed and sensor <b>31</b> detects the changing of the waveform of ultrasonic waves propagating on the covering layer <b>33</b> and outputs the position of the touch and the magnitude of the touched force. When the user compresses further, the rigid cover <b>33</b> will contact the deformable pillars <b>69</b> to form a physical recognition of the boundary of a proper hand guide instruction force. This example brings an advantage of having a metal cover in the outermost layer which is more endurable in an industrial environment. In this way, sensor module <b>3</b> may form a removable or installable cover or safety cover for movable parts <b>2</b> of robot <b>1</b>. Sensor module <b>3</b> may therefore sometimes be referred to herein as safety cover <b>3</b>, cover <b>3</b>, or robot safety cover <b>3</b>.</p><p id="p-0080" num="0078">The position of the touch may be an important information for a robot <b>1</b> using a position control to perform hand guide motion. For a robot <b>1</b> using a compliance function or a &#x201c;Zero gravity&#x201d; mode hand guide function, the contact position may not be required. In this case, sensor module <b>3</b> may only work as an enabling switch for hand guide and a PFL safety sensor.</p><p id="p-0081" num="0079">While a particular form of the invention has been illustrated and described, it will be apparent that various modifications can be made without departing from the spirit and scope of the proposed disclosure. For example, various other types of sensors <b>31</b> and resilient member <b>32</b> may be included. The foregoing embodiments may be implemented individually or in any combination.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A robot system comprising:<claim-text>a robot having a movable part;</claim-text><claim-text>a sensor disposed on the movable part, wherein the sensor has a layer and is configured to generate a sensor signal indicative of depression of the layer relative to the movable part; and</claim-text><claim-text>one or more processors configured to:<claim-text>move the robot according to a manual instruction of guiding the robot when there is a first amount of depression of the layer relative to the movable part, and</claim-text><claim-text>stop the robot when there is a second amount of depression of the sensor relative to the movable part, the second amount of depression being greater than the first amount of depression.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The robot system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor comprises a sensor layer interposed between the layer and the moveable part, the sensor layer being configured to generate the sensor signal.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The robot system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor comprises a first additional layer and a second additional layer, the layer comprises a sensor layer configured to generate the sensor signal, the sensor layer is interposed between the first additional layer and the second additional layer, the first additional layer has a first rigidity, and the second additional layer has a second rigidity that is different from the first rigidity.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The robot system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor comprises a first additional layer and a second additional layer on the first additional layer, wherein the second additional layer is interposed between the first additional layer and the layer, the first additional layer has a first rigidity, and the second additional layer has a second rigidity that is different from the first rigidity.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The robot system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor comprises a resilient member and a proximity sensor interposed between the resilient member and the movable part.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The robot system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the layer comprises a cover layer on the resilient member and forming an outermost surface of the sensor.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The robot system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor comprises a capacitive proximity sensor.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The robot system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor comprises a resilient member and an optical sensor interposed between the resilient member and the movable part, the resilient being configured to transmit light generated by the optical sensor.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The robot system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sensor comprises an air pressure detection sensor having a deformable air chamber defined at least in part by the layer.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The robot system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein sensor comprises a sensor layer configured to generate the sensor signal and the one or more processors is configured to stop the robot when the sensor signal indicates that an external object has moved to more than a threshold distance from the sensor layer.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A safety cover for a robot, comprising:<claim-text>a sensor layer configured to detect a distance to an external object that applies a manual instruction of guiding the robot; and</claim-text><claim-text>a resilient member coupled to the sensor layer, wherein the sensor layer is configured to generate a sensor signal having a first value when the sensor layer detects that the external object is at a first distance and having a second value when the sensor layer detects that the external object is at a second distance.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The safety cover of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the resilient member is at least partially compressed by a force applied to the safety cover by the external object when the external object is at the second distance.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The safety cover of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the sensor layer comprises a contact sensor configured to detect a contact or a force applied to the safety cover by the external object, the sensor layer forming an outermost layer of the safety cover and the resilient member being interposed between the sensing member and a movable member of the robot.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The safety cover of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the resilient member comprises a first layer having a first rigidity and a second layer having a second rigidity that is different from the first rigidity.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The safety cover of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the sensor layer comprises a proximity sensor disposed between the resilient member and a movable part of the robot.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The safety cover of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising a cover layer that forms an outermost layer of the safety cover, wherein the sensor layer comprises a proximity sensor disposed between the resilient member and a movable part of the robot and the sensor layer is configured to detect the distance by detecting a proximity of the cover layer.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The safety cover of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the sensor layer comprises a capacitive proximity sensor.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The safety cover of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the sensor layer comprises an optical sensor configured to transmit light through the resilient member.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The safety cover of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the sensor layer comprises an air pressure detection sensor and the resilient member comprises a deformable air chamber.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A method of controlling a robot, the method comprising:<claim-text>with a sensor layer covering at least some of a movable member of the robot, generating sensor signals indicative of an external object that applies a force to the sensor that teaches a motion of the movable member to the robot;</claim-text><claim-text>with an actuator, moving the movable member according to the motion when the sensor signal is within a range of values between a first threshold value and a second threshold value; and</claim-text><claim-text>performing a safety stop of the movable member when the sensor signal is outside the range of values</claim-text></claim-text></claim></claims></us-patent-application>
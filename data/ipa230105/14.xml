<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000015A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221220" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000015</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17757074</doc-number><date>20201120</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>01</class><subclass>D</subclass><main-group>41</main-group><subgroup>127</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>01</class><subclass>D</subclass><main-group>45</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>01</class><subclass>D</subclass><main-group>41</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>01</class><subclass>D</subclass><main-group>41</main-group><subgroup>127</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>01</class><subclass>D</subclass><main-group>45</main-group><subgroup>021</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>01</class><subclass>D</subclass><main-group>41</main-group><subgroup>141</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHODS AND IMAGING SYSTEMS FOR HARVESTING</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>62945289</doc-number><date>20191209</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Precision Planting LLC</orgname><address><city>Tremont</city><state>IL</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Herrmann</last-name><first-name>Aaron</first-name><address><city>Tremont</city><state>IL</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Swanson</last-name><first-name>Todd</first-name><address><city>Morton</city><state>IL</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Stoller</last-name><first-name>Jason J.</first-name><address><city>Eureka</city><state>IL</state><country>US</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/IB2020/060962</doc-number><date>20201120</date></document-id><us-371c12-date><date>20220608</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Described herein are methods and harvesters for adjusting settings of a harvester. In one embodiment, a computer Implemented method includes capturing, with at least one image capture device that is located on the harvester, images of a field view of an unharvested region to be harvested, analyzing the captured images to determine crop information for a crop of a harvested region that is adjacent to the unharvested region, and adjusting settings or operating parameters of the harvester for the unharvested region based on the crop information for the crop of the harvested region.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="187.45mm" wi="148.34mm" file="US20230000015A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="214.63mm" wi="149.78mm" file="US20230000015A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="159.34mm" wi="149.10mm" file="US20230000015A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="173.82mm" wi="113.28mm" orientation="landscape" file="US20230000015A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="198.80mm" wi="150.37mm" file="US20230000015A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="205.23mm" wi="153.25mm" file="US20230000015A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="201.93mm" wi="149.18mm" orientation="landscape" file="US20230000015A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="207.77mm" wi="147.66mm" file="US20230000015A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="187.71mm" wi="147.24mm" file="US20230000015A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="121.07mm" wi="133.01mm" file="US20230000015A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="187.96mm" wi="151.21mm" orientation="landscape" file="US20230000015A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="208.28mm" wi="161.46mm" orientation="landscape" file="US20230000015A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority to U.S. Application No. 62/945,289, filed 9 Dec. 2020, which is incorporated herein by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">Embodiments of the present disclosure relate to methods and imaging systems for harvesting operations with a harvester.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Planters are used for planting seeds of crops (e.g., corn, soybeans) in a field. Some planters include a display monitor within a cab for displaying a coverage map that shows regions of the field that have been planted. The coverage map of the planter is generated based on planting data collected by the planter.</p><p id="p-0005" num="0004">A combine harvester or combine is a machine that harvests crops. A coverage map of a combine displays regions of the field that have been harvested by that combine. A coverage map allows the operator of the combine to know that a region of the field has already been harvested by the same combine. Yield data for a field can then be generated after harvesting the field. The yield data can be analyzed in order to potentially improve agricultural operations for a subsequent growing season.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0006" num="0005">The present disclosure is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which:</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an example of a system for collecting data of agricultural fields and performing analysis of the data of agricultural fields in accordance with one embodiment;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a flow diagram of one embodiment for a method <b>200</b> of adjusting settings of a harvester based on capturing images of field regions;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIGS. <b>3</b>-<b>6</b></figref> illustrate harvesters with an imaging system (e.g., image sensors, image capturing devices) positioned in different locations on each harvester in accordance with certain embodiments;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an example of a system <b>700</b> that includes a machine <b>702</b> (e.g., tractor, combine harvester, etc.) in accordance with one embodiment;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>8</b>A</figref> illustrates an example of a header having an image capturing system in accordance with certain embodiments;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>8</b>B</figref> illustrates an example of a header having an image capturing system in accordance with other embodiments;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates mounting an image capturing device under a snout <b>900</b> in accordance with one embodiment;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an image <b>1000</b> of unharvesting crop in a first region to be harvested that is adjacent to a second region that has been harvested; and</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates an image that has been captured by the imaging system of the harvester after settings of the harvester are adjusted based on analyzing the captured image <b>1000</b>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0016" num="0015">Described herein are methods and imaging systems for harvesting. In one example, a harvester includes at least one image capturing device (e.g., camera) for capturing images of a field view of first region to be harvested that is adjacent to a second region that has been harvested. The captured images are analyzed to determine residue crop from the second region that was discarded by the harvester while harvesting the second region. Parameters of the harvester for the first region can be adjusted based on analyzing the captured images.</p><p id="p-0017" num="0016">In the following description, numerous details are set forth. It will be apparent, however, to one skilled in the art, that embodiments of the present disclosure may be practiced without these specific details. In some instances, well-known structures and devices are shown in block diagram form, rather than in detail, in order to avoid obscuring the present disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an example of a system for collecting and analyzing agricultural data from agricultural fields in order to display customized agricultural data in accordance with one embodiment. For example, in one embodiment, the system <b>100</b> may be implemented as a cloud based system with servers, data processing devices, computers, etc. Aspects, features, and functionality of the system <b>100</b> can be implemented in servers, harvesters (e.g., combine harvester), planters, planter monitors, drones, laptops, tablets, computer terminals, client devices, user devices, handheld computers, personal digital assistants, cellular telephones, cameras, smart phones, mobile phones, computing devices, or a combination of any of these or other data processing devices.</p><p id="p-0019" num="0018">In other embodiments, the system includes a network computer or an embedded processing device within another device (e.g., display device) or within a machine (e.g., planter, combine), or other types of data processing systems having fewer components or perhaps more components than that shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. While illustrated with a monitor as the display device, the display device can by any display device, such as a monitor, a smartphone, a tablet, a personal computer, or any touch activated screen.</p><p id="p-0020" num="0019">The system <b>100</b> (e.g., cloud based system) for collecting and analyzing agricultural data includes machines <b>140</b>, <b>106</b>, and <b>108</b> (e.g., harvesters, planters) for performing field operations (e.g., tillage, planting, fertilization, harvesting, etc). The machines can include devices (e.g., devices <b>142</b>, <b>108</b>, <b>11</b>I) in addition to other devices <b>104</b> and <b>190</b> (e.g., user devices, mobile device, tablet devices, drones, etc) for displaying customized agricultural data based on agricultural operations. The machines may also include sensors (e.g., image capturing devices, speed sensors, moisture sensors, auger sensors, mass flow sensors, head pressure sensors, seed sensors for detecting passage of seed, downforce sensors, actuator valves. OEM sensors, etc.) for capturing data of crops and soil conditions within associated fields (e.g., fields <b>102</b>, <b>105</b>, <b>107</b>, <b>109</b>). The system <b>100</b> includes an agricultural analysis system <b>102</b> and a storage medium <b>136</b> to store instructions, software, software programs, etc. for execution by the processing system <b>102</b> and for performing operations of the agricultural analysis system <b>102</b>. A data analytics module <b>130</b> may perform analytics on agricultural data (e.g., images, field, yield, etc.) to generate crop predictions <b>162</b> relating to agricultural operations. For example, the crop predictions may predict yield (e.g., crop yield) based on development of crops (e.g., yield potential or ear potential for corn) at different growth stages.</p><p id="p-0021" num="0020">A field information database <b>134</b> stores agricultural data (e.g., crop growth stage, soil types, soil characteristics, moisture holding capacity, etc.) for the fields that are being monitored by the system <b>100</b>. An agricultural practices information database <b>135</b> stores farm practices information (e.g., harvesting information, as-applied planting information, fertilization information, planting population, applied nutrients (e.g., nitrogen), yield levels, proprietary indices (e.g., ratio of seed population to a soil parameter), etc.) for the fields that are being monitored by the system <b>100</b>. A cost/price database <b>138</b> stores input cost information (e.g., cost of seed, cost of nutrients (e.g., nitrogen)) and commodity price information (e.g., revenue from crop).</p><p id="p-0022" num="0021">The system <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may include a network interface <b>118</b> for communicating with other systems or devices such as drone devices, user devices, and machines (e.g., planters, combines) via a network <b>180</b> (e.g., Internet, wide area network, WiMax, satellite, cellular, IP network, etc.). The network interface includes one or more types of transceivers for communicating via the network <b>180</b>.</p><p id="p-0023" num="0022">The processing system <b>132</b> may include one or more microprocessors, processors, a system on a chip (integrated circuit), or one or more microcontrollers. The processing system includes processing logic for executing software instructions of one or more programs. The system <b>100</b> includes the storage medium <b>136</b> for storing data and programs for execution by the processing system. The storage medium <b>136</b> can store, for example, software components such as a software application for capturing images and performing analysis of the capturing images or any other software application. The storage medium <b>136</b> can be any known form of a machine readable non-transitory storage medium, such as semiconductor memory (e.g., flash; SRAM; DRAM; etc.) or non-volatile memory, such as hard disks or solid-state drive.</p><p id="p-0024" num="0023">While the storage medium (e.g., machine-accessible non-transitory medium) is shown in an exemplary embodiment to be a single medium, the term &#x201c;machine-accessible non-transitory medium&#x201d; should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of instructions. The term &#x201c;machine-accessible non-transitory medium&#x201d; shall also be taken to include any medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure. The term &#x201c;machine-accessible non-transitory medium&#x201d; shall accordingly be taken to include, but not be limited to, solid-state memories, optical and magnetic media, and carrier wave signals.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a flow diagram of one embodiment for a method <b>200</b> of adjusting settings of a harvester based on capturing images of field regions. The method <b>200</b> is performed by processing logic that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine or a device), or a combination of both. In one embodiment, the method <b>200</b> is performed by processing logic of at least one data processing system (e.g., system <b>102</b>, machine, apparatus, monitor, display device, user device, self-guided device, self-propelled device, etc). The data processing system executes instructions of a software application or program with processing logic. The software application or program can be initiated by the data processing system. In one example, a monitor or display device receives user input and provides a customized display for operations of the method <b>200</b>.</p><p id="p-0026" num="0025">At operation <b>202</b>, a software application is initiated on a data processing system (e.g., system <b>102</b>, machine, apparatus, user device, self-guided device, self-propelled device, etc) and displayed on a monitor or display device as an interface. The data processing system may be integrated with or coupled to a machine (e.g., harvester) that performs an application pass (e.g., harvesting). Alternatively, the data processing system may be integrated with an apparatus (e.g., drone, image capture device) associated with the machine that captures images during the application pass.</p><p id="p-0027" num="0026">At least one image capturing device is mounted on a harvester to view the ground in front of the harvester, adjacent to the harvester, or just behind a header of the harvester. The at least one image capturing device can be positioned on the harvester to be in a row adjacent to a row that was previously harvested. At operation <b>204</b>, the at least one image capture device captures images (e.g., sequence of images, video) of a field view of a first region to be harvested that is adjacent to a second region that has been harvested. The at least one image capturing device can be looking forward devices with respect to a direction of travel of the harvester that are positioned to view crops of the first region or downwards towards the ground.</p><p id="p-0028" num="0027">At operation <b>206</b>, the method includes analyzing the captured images to determine crop information (e.g., a level or amount of residue crop, residue crop effectiveness, crop header loss, bent over crop that was not cut in second region, soybean percentage of stalk uncut or length stalk uncut, percent area of bent stalks, a level or percentage of soybean cut quality, percent area of intact pods, percentage of surface area viewed that has kernels, percentage of yield loss of crop based on bushel acre estimate or cost per acre estimate, bushels of crop lost per acre based on cost per acre estimate, economic loss window, etc.) for crop from the second region that was dispersed or discarded by the harvester while harvesting the second region. An Economic Loss Window preferably displays the economic loss value in dollars lost per acre ($Loss/acre) attributable to the various yield robbing events. The calculated economic loss value may be continually displayed or the value may only be displayed only upon an alarm condition, such as when the value exceeds a predefined value, such as, for example, $3.00/acre. If an alarm condition is not present, the Economic Loss Window may simply display the word &#x201c;Good&#x201d; or some other desired designation. The Economic Loss Window may provide some sort of visual or audible alarm to alert the operator if the economic loss exceeds a predefined limit. Additionally, the Economic Loss Window may be associated or tied to other Windows (e.g., other Windows for harvesting settings such as angle of header, header height, reel speed, or reel tine angle of harvester) if an alarm condition is met in any of these other Windows, and such alarm condition is found to be the contributing factor to the alarm condition in the Economic Loss Window, then both Windows produce a visual or audible indication of the alarm condition. An ear loss, kernel loss, or header loss per row as determined by captured images can be used in determine the Economic Loss Window.</p><p id="p-0029" num="0028">At operation <b>207</b>, the method includes displaying images or video captured by the at least one image capture device to a display device (e.g., display device of a machine, display device of a harvester, smart phone, tablet, computer, etc.). At operation <b>208</b>, the method includes displaying the crop information to the display device (e.g., display device of a machine, display device of a harvester, smart phone, tablet, computer, etc.). At operation <b>210</b>, the method includes manually with user input or automatically without user input adjusting settings or parameters (e.g., adjust angle of header, header height, header speed, reel speed, reel tine angle, deck plate spacing, adjusting fan speed, cylinder speed, concave clearance, vehicle speed, precleaner, chaffer, extension, sieve, draper belt speed) of the harvester for the first region based on the crop information.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIGS. <b>3</b>-<b>6</b></figref> illustrate harvesters with imaging systems (e.g., image sensors, image capturing devices) positioned in different locations on each harvester in accordance with certain embodiments.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a harvester or combine 10 having an imaging system <b>50</b> (e.g., image capturing devices <b>50</b><i>a</i>, <b>50</b><i>b</i>, <b>50</b><i>c</i>) in accordance with one embodiment. In one example, device <b>50</b><i>a </i>is integrated with a front of a snout, device <b>50</b><i>b </i>is positioned on an upper region of the header <b>15</b>, and device <b>50</b><i>c </i>is positioned or mounted on a chassis <b>12</b> of the harvester <b>10</b>. As the operator in cab <b>12</b> drives the combine 10 through the field, the imaging system <b>50</b> captures images of unharvested crop in a first region to be harvested that is adjacent to a second region that has been harvested. The captured images are analyzed to determine crop information from the second region that was dispersed by the harvester while harvesting the second region. Settings of the harvester for the first region can be adjusted based on analyzing the captured images as discussed in the operations of method <b>200</b>.</p><p id="p-0032" num="0031">The crop being harvested is drawn through the header <b>15</b> which gathers the plant material and feeds it into the feederhouse <b>16</b>. The feederhouse <b>16</b> carries the plant material into the combine where the grain is separated from the other plant material. The separated grain is then carried upward by the grain elevator <b>120</b> to the auger <b>150</b> which carries the grain into the grain tank <b>20</b>. The other plant material is discharged out the back of the combine.</p><p id="p-0033" num="0032">When the grain tank <b>20</b> becomes full, a transport vehicle such as grain cart, wagon or truck is driven up next to the combine or the combine drives to the awaiting transport vehicle. The unloading auger <b>30</b> is swung outwardly until the end is positioned over the awaiting transport vehicle. A cross-auger <b>35</b> positioned in the bottom of the grain tank <b>20</b> feeds the grain to the extended unloading auger <b>30</b> which in turn deposits the grain into the awaiting transport vehicle below.</p><p id="p-0034" num="0033">Live or real-time yield monitoring during crop harvesting is known in the art. One type of commercially available yield monitor uses a mass flow sensor as disclosed in U.S. Pat. No. 5,343,761, which is hereby incorporated herein in its entirety by reference. Using the speed and the width of the pass being harvested (usually the width of the header), it is possible to obtain a yield rate in bushels per acre by dividing the mass of grain harvested over a particular time period by the area harvested. In addition to reporting the current yield rate, such systems often incorporate GPS or other positioning systems in order to associate each reported yield rate with a discrete location in the field. Thus a yield map may be generated for reference in subsequent seasons.</p><p id="p-0035" num="0034">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the harvester <b>400</b> (e.g., bean harvester) includes looking forward sensors <b>410</b>-<b>414</b> (e.g., image capturing devices, cameras) having a field of view that is forward in a direction of travel <b>440</b> of the harvester, looking rearward sensor <b>425</b> having a field of view that is backward in an opposite direction of travel <b>440</b>, and looking down sensors <b>430</b>-<b>433</b> that view the ground surface of a field. The looking down sensors will see where beans are bent over or see intact pods not harvested. To correct, a harvester can adjust an angle of a header that is harvesting the crop. Also, angle of header, header height, header speed, reel speed, reel tine angle, deck plate spacing, adjusting fan speed, cylinder speed, concave clearance, vehicle speed, precleaner, chaffer, extension, sieve, or draper belt speed can be changed based on captured images.</p><p id="p-0036" num="0035">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the harvester <b>500</b> (e.g., corn harvester) includes looking forward sensors <b>510</b>-<b>512</b> having a field of view that is forward in a direction of travel <b>540</b> of the harvester and looking down sensors <b>520</b>-<b>521</b> that view the ground surface of a field.</p><p id="p-0037" num="0036">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the harvester <b>600</b> (e.g., bean harvester) includes looking forward sensors <b>610</b>-<b>611</b> having a field of view that is forward in a direction of travel of the harvester.</p><p id="p-0038" num="0037">As the operator drives the harvester (e.g., <b>400</b>, <b>500</b>, <b>600</b>) through the field, the imaging system captures images of unharvesting crop in a first region (e.g., <b>420</b>, <b>580</b>, <b>680</b>) to be harvested that is adjacent to a second region (e.g., <b>482</b>, <b>582</b>, <b>682</b>) that has been harvested. The captured images are analyzed to determine crop information from the first region that was dispersed by the harvester while harvesting the second region. Settings of the harvester for the first region can be adjusted based on analyzing the captured images as discussed in the operations of method <b>200</b>.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an example of a machine <b>700</b> (e.g., tractor, combine harvester, etc.) in accordance with one embodiment. The machine <b>700</b> includes a processing system <b>720</b>, memory <b>705</b>, machine network <b>710</b> (e.g., a controller area network (CAN) serial bus protocol network, an ISOBUS network, etc.), and a network interface <b>715</b> for communicating with other systems or devices. The machine network <b>710</b> includes sensors <b>712</b> (e.g., speed sensors, moisture sensor, auger sensor, mass flow sensor, head pressure sensor, etc.), controllers <b>711</b> (e.g., GPS receiver, radar unit) for controlling and monitoring operations of the machine, and image capture devices <b>714</b> (e.g., looking forward image capturing devices, rear looking image capturing devices, downward looking image capturing devices) for capturing images of crops and soil conditions of a field in accordance with embodiments of the present disclosure. The network interface <b>715</b> can include at least one of a GPS transceiver, a WLAN transceiver (e.g., WiFi), an infrared transceiver, a Bluetooth transceiver, Ethernet, cellular transceiver, or other interfaces from communications with other devices and systems including the implement <b>740</b>. The network interface <b>715</b> may be integrated with the machine network <b>710</b> or separate from the machine network <b>710</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The I/O ports <b>729</b> (e.g., diagnostic/on board diagnostic (OBD) port) enable communication with another data processing system or device (e.g., display devices, sensors, etc.).</p><p id="p-0040" num="0039">In one example, the machine performs operations of a combine (combine harvester) for harvesting grain crops. The machine combines reaping, threshing, and winnowing operations in a single harvesting operation. A header <b>780</b> (e.g., grain platform, flex platform) includes a cutting mechanism to cause cutting of crops to be positioned into an auger or draper (belt feed). The header <b>780</b> includes an orientation device <b>782</b> or mechanism for orienting a crop (e.g., corn, soybeans) for improving image capture with at least one image capture device <b>784</b>.</p><p id="p-0041" num="0040">The processing system <b>720</b> may include one or more microprocessors, processors, a system on a chip (integrated circuit), or one or more microcontrollers. The processing system includes processing logic <b>726</b> for executing software instructions of one or more programs and a communication unit <b>728</b> (e.g., transmitter, transceiver) for transmitting and receiving communications from the machine via machine network <b>710</b> or network interface <b>715</b> or implement via implement network <b>750</b> or network interface <b>760</b>. The communication unit <b>728</b> may be integrated with the processing system or separate from the processing system. In one embodiment, the communication unit <b>728</b> is in data communication with the machine network <b>710</b> and implement network <b>750</b> via a diagnostic/OBD port of the I/O ports <b>729</b>.</p><p id="p-0042" num="0041">Processing logic <b>726</b> including one or more processors may process the communications received from the communication unit <b>728</b> including agricultural data. The system <b>700</b> includes memory <b>705</b> for storing data and programs for execution (software <b>706</b>) by the processing system. The memory <b>705</b> can store, for example, software components such as image capture software, field view software for performing operations or methods of the present disclosure, or any other software application or module, images (e.g., captured images of crops), alerts, maps, etc. The memory <b>705</b> can be any known form of a machine readable non-transitory storage medium, such as semiconductor memory (e.g., flash; SRAM; DRAM; etc.) or non-volatile memory, such as hard disks or solid-state drive. The system can also include an audio input/output subsystem (not shown) which may include a microphone and a speaker for, for example, receiving and sending voice commands or for user authentication or authorization (e.g., biometrics).</p><p id="p-0043" num="0042">The processing system <b>720</b> communicates bi-directionally with memory <b>705</b>, machine network <b>710</b>, network interface <b>715</b>, header <b>780</b>, display device <b>730</b>, display device <b>725</b>, and <b>1</b>/O ports <b>729</b> via communication links <b>730</b>-<b>736</b>, respectively.</p><p id="p-0044" num="0043">Display devices <b>725</b> and <b>730</b> can provide visual user interfaces for a user or operator. The display devices may include display controllers. In one embodiment, the display device <b>725</b> is a portable tablet device or computing device with a touchscreen that displays images (e.g., captured images and data (localized view map layer, high definition field maps of as-planted or as-harvested data or other agricultural variables or parameters, yield maps, alerts, economic loss data, seeds per area, cobs and cob size to determine performance, percent of cracked kernels, stand count data (number of stalks) to determine number of plants that germinated and grew, stalk diameter data measured from images, etc.)) generated by an agricultural data analysis software application or field view software application and receives input from the user or operator for a customized scale region and corresponding view of a region of a field, monitoring and controlling field operations, or any operations or methods of the present disclosure. The operations may include configuration of the machine or implement, reporting of data, control of the machine or implement including sensors and controllers (e.g., adjust angle of header, header height, header speed, reel speed, reel tine angle, deck plate spacing, adjusting fan speed, cylinder speed, concave clearance, vehicle speed, precleaner, chaffer, extension, sieve, draper belt speed) based on captured images from image capturing devices, and storage of the data generated. The display device <b>730</b> may be a display (e.g., display provided by an original equipment manufacturer (OEM)) that displays images and data for a localized view map layer, as-planted or as-harvested data, yield data, controlling a machine (e.g., planter, tractor, combine, sprayer, etc.), steering the machine, and monitoring the machine or an implement (e.g., planter, combine, sprayer, etc.) that is connected to the machine with sensors and controllers located on the machine or implement.</p><p id="p-0045" num="0044">A cab control module <b>770</b> may include an additional control module for enabling or disabling certain components or devices of the machine or implement. For example, if the user or operator is not able to control the machine or implement using one or more of the display devices, then the cab control module may include switches to shut down or turn off components or devices of the machine or implement.</p><p id="p-0046" num="0045">In one embodiment, a machine-accessible non-transitory medium (e.g., memory <b>705</b>) contains executable computer program instructions which when executed by a data processing system cause the system to perform operations or methods of the present disclosure including customizing scale and corresponding field views of agricultural fields with expand and panning operations. While the machine-accessible non-transitory medium (e.g., memory <b>705</b>) is shown in an exemplary embodiment to be a single medium, the term &#x201c;machine-accessible non-transitory medium&#x201d; should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of instructions. The term &#x201c;machine-accessible non-transitory medium&#x201d; shall also be taken to include any medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure. The term &#x201c;machine-accessible non-transitory medium&#x201d; shall accordingly be taken to include, but not be limited to, solid-state memories, optical and magnetic media, and carrier wave signals.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>8</b>A</figref> illustrates an example of a header having an image capturing system in accordance with certain embodiments. The header <b>800</b> includes a plurality of snouts <b>820</b> and image capturing devices <b>810</b>-<b>813</b> that can be mounted in various locations (e.g., on snout, within snout, integrated with a reflector).</p><p id="p-0048" num="0047">In one example, the image capturing devices can only be located so far in (usually no more than 3 snouts) so that the devices can see seeds dispersed onto the ground from the prior row. The tip of the snout <b>805</b> could be replaced with a camera (e.g., image capturing device <b>810</b>, <b>811</b>) in a protective cover that matches the contour of the snout. An example is a camera in a dome.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>8</b>B</figref> illustrates an example of a header having an image capturing system in accordance with other embodiments. The header <b>850</b> includes a plurality of snouts and image capturing devices that can be mounted in various locations (e.g., on snout, within snout, integrated with a reflector). The image capturing devices <b>805</b>, <b>860</b>-<b>863</b> face forward to capture the number of seeds that were thrown from the prior pass of an adjacent region of the field. This header <b>850</b> may be a corn header to capture header loss at each row.</p><p id="p-0050" num="0049">In this example, a plurality of image capturing devices <b>870</b>-<b>880</b> are positioned at each row after the header to capture the amount of seeds, which includes the number of seeds from the prior pass that were thrown. These devices <b>870</b>-<b>880</b> can be downward or rearward looking. By subtracting the prior seeds from images of devices <b>860</b>-<b>863</b> from the row amount from images captured by devices <b>870</b>-<b>880</b>, this gives header loss at each row.</p><p id="p-0051" num="0050">Also, there are places to mount an image capturing device under a snout <b>900</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. The image capturing devices <b>910</b> and <b>920</b> can be mounted on any surface (e.g., <b>902</b>, <b>904</b>) under a snout. Preferably, the image capturing devices would also need a light source.</p><p id="p-0052" num="0051">As the operator drives the harvester through the field, the imaging system captures images (e.g., an image <b>1000</b>) as illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> of unharvesting crop in a first region to be harvested that is adjacent to a second region that has been harvested. The captured images are analyzed to determine crop information (e.g., cob data <b>99</b>, kernel data <b>98</b>) from the first region that was dispersed by the harvester while harvesting the second region. <figref idref="DRAWINGS">FIG. <b>1</b>I</figref> illustrates an image <b>1100</b> that has been captured by the imaging system of the harvester after settings of the harvester are adjusted based on analyzing the captured images as discussed in the operations of method <b>200</b>. The image <b>1100</b> shows fewer cobs and kernels being dispersed from the second region, which reduces economic loss for the farmer.</p><p id="p-0053" num="0052">Any of the following examples can be combined into a single embodiment or these examples can be separate embodiments. In one example of a first embodiment, a computer implemented method for adjusting settings of a harvester comprises capturing, with at least one image capture device that is located on the harvester, images of a field view of an unharvested region to be harvested, analyzing the captured images to determine crop information for a crop of a harvested region that is adjacent to the unharvested region, and adjusting settings or operating parameters of the harvester for the unharvested region based on the crop information for the crop of the harvested region.</p><p id="p-0054" num="0053">In another example of the first embodiment, wherein adjusting settings or operating parameters comprises adjusting one or more of angle of header, header height, header speed, reel speed, reel tine angle, deck plate spacing, adjusting fan speed, cylinder speed, concave clearance, vehicle speed, precleaner, chaffer, extension, sieve, draper belt speed of the harvester for the unharvested region based on the crop information.</p><p id="p-0055" num="0054">In another example of the first embodiment, wherein the at least one image capturing device comprises a looking forward device that looks forward of the harvester.</p><p id="p-0056" num="0055">In another example of the first embodiment, wherein the at least one image capturing device comprises a downward viewing device to view crops and a ground surface of the unharvested region.</p><p id="p-0057" num="0056">In another example of the first embodiment, the computer implemented method, further comprises displaying images or video captured by the at least one image capture device to a display device.</p><p id="p-0058" num="0057">In another example of the first embodiment, the computer implemented method, further comprises displaying the crop information to a display device.</p><p id="p-0059" num="0058">In another example of the first embodiment, wherein adjusting settings or operating parameters comprises automatically without user input adjusting settings or operating parameters of the harvester for the unharvested region based on the crop information.</p><p id="p-0060" num="0059">In another example of the first embodiment, wherein the crop information comprises a level or amount of residue crop or a residue crop effectiveness.</p><p id="p-0061" num="0060">In another example of the first embodiment, wherein the crop information comprises one or more of bent over crop that was not cut, soybean percentage of stalk uncut or length stalk uncut, percent area of bent stalks, a level or percentage of soybean cut quality, or percent area of intact pods.</p><p id="p-0062" num="0061">In another example of the first embodiment, wherein the crop information comprises one or more of percentage of surface area viewed that has kernels, percentage of yield loss of crop based on bushel acre estimate or cost per acre estimate, bushels of crop lost per acre based on cost per acre estimate, or an economic loss window for crop from the harvested region that was dispersed or discarded by the harvester.</p><p id="p-0063" num="0062">In one example of a second embodiment, a combine harvester comprises a header to engage a crop, at least one image capturing device to capture images of an unharvested region in front of the combine harvester, and at least one processor communicatively coupled to the at least one image capturing device. The at least one processor is configured to execution instructions to analyze the captured images to determine crop information for a crop of a harvested region that is adjacent to the unharvested region and to adjust settings or operating parameters of the combine harvester for the unharvested region based on the crop information for the crop of the harvested region.</p><p id="p-0064" num="0063">In another example of the second embodiment, wherein the header includes a plurality of snouts and at least one snout includes the at least one image capturing device that is integrated with a tip of the snout.</p><p id="p-0065" num="0064">In another example of the second embodiment, wherein at least one of three outer most snouts of the header includes a looking forward image capturing device.</p><p id="p-0066" num="0065">In another example of the second embodiment, wherein at least one image capturing device is positioned underneath a header, e.g. underneath a snout, in a downward looking direction.</p><p id="p-0067" num="0066">In another example of the second embodiment, wherein the at least one image capturing device is mounted on the header in a looking forward or downward direction.</p><p id="p-0068" num="0067">In another example of the second embodiment, the combine harvester further comprises a chassis to support the harvester with at least image capturing device being mounted on the chassis.</p><p id="p-0069" num="0068">In another example of the second embodiment, wherein to adjust settings or operating parameters comprises adjusting one or more of angle of header, header height, header speed, reel speed, reel tine angle, deck plate spacing, adjusting fan speed, cylinder speed, concave clearance, vehicle speed, precleaner, chaffer, extension, sieve, draper belt speed of the harvester for the unharvested region based on the crop information.</p><p id="p-0070" num="0069">In another example of the second embodiment, the combine harvester further comprises a display device to display images or video captured by the at least one image capture device.</p><p id="p-0071" num="0070">In another example of the second embodiment, wherein the display device to display the crop information.</p><p id="p-0072" num="0071">In another example of the second embodiment, wherein the crop information comprises a level or amount of residue crop or a residue crop effectiveness.</p><p id="p-0073" num="0072">In another example of the second embodiment, wherein the at least one image capturing device comprises a looking forward image capturing device positioned on a first outer edge of the header, an image capturing device positioned to view behind the header, a looking forward image capturing device positioned on a second outer edge of the header, and an image capturing device positioned on a frontal region of a frame of the harvester.</p><p id="p-0074" num="0073">In another example of the second embodiment, wherein the looking forward image capturing devices face forward to capture a number of seeds that were thrown from a prior pass of an adjacent harvested region of the field.</p><p id="p-0075" num="0074">In another example of the second embodiment, wherein the image capturing device is positioned to view behind the header to capture an amount of seeds after harvest for a current pass, which includes a number of seeds from the prior pass that were thrown.</p><p id="p-0076" num="0075">In another example of the second embodiment, wherein the at least one processor is configured to execution instructions to determine a header loss at each row for a current pass based on the number of seeds from the prior pass and the amount of seeds for the current pass.</p><p id="p-0077" num="0076">It is to be understood that the above description is intended to be illustrative, and not restrictive. Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description. The scope of the disclosure should, therefore, be determined with reference to the appended claims, along with the full scope of equivalents to which such claims are entitled.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer implemented method for adjusting settings of a harvester comprising:<claim-text>capturing, with at least one image capture device that is located on the harvester, images of a field view of an unharvested region to be harvested;</claim-text><claim-text>analyzing the captured images to determine crop information for a crop of a harvested region that is adjacent to the unharvested region; and</claim-text><claim-text>adjusting settings or operating parameters of the harvester for the unharvested region based on the crop information for the crop of the harvested region.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein adjusting settings or operating parameters comprises adjusting one or more of angle of header, header height, header speed, reel speed, reel tine angle, deck plate spacing, adjusting fan speed, cylinder speed, concave clearance, vehicle speed, precleaner, chaffer, extension, sieve, draper belt speed of the harvester for the unharvested region based on the crop information.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one image capturing device comprises a looking forward device that looks forward of the harvester.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one image capturing device comprises a downward viewing device to view crops and a ground surface of the unharvested region.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>displaying images or video captured by the at least one image capture device to a display device.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>displaying the crop information to a display device</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein adjusting settings or operating parameters comprises automatically without user input adjusting settings or operating parameters of the harvester for the unharvested region based on the crop information.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the crop information comprises a level or amount of residue crop or a residue crop effectiveness.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the crop information comprises one or more of bent over crop that was not cut, soybean percentage of stalk uncut or length stalk uncut, percent area of bent stalks, a level or percentage of soybean cut quality, or percent area of intact pods.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the crop information comprises one or more of percentage of surface area viewed that has kernels, percentage of yield loss of crop based on bushel acre estimate or cost per acre estimate, bushels of crop lost per acre based on cost per acre estimate, or an economic loss window for crop from the harvested region that was dispersed or discarded by the harvester.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A combine harvester comprising:<claim-text>a header to engage a crop;</claim-text><claim-text>at least one image capturing device to capture images of an unharvested region in front of the combine harvester; and</claim-text><claim-text>at least one processor communicatively coupled to the at least one image capturing device, the at least one processor is configured to execution instructions to analyze the captured images to determine crop information for a crop of a harvested region that is adjacent to the unharvested region and to adjust settings or operating parameters of the combine harvester for the unharvested region based on the crop information for the crop of the harvested region.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The combine harvester of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the header includes a plurality of snouts and at least one snout includes the at least one image capturing device that is integrated with a tip of the snout.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The combine harvester of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein at least one of three outer most snouts of the header includes a looking forward image capturing device.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The combine harvester of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein at least one image capturing device is positioned underneath a snout in a downward looking direction.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The combine harvester of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one image capturing device is mounted on the header in a looking forward or downward direction.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The combine harvester of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>a chassis to support the harvester with at least image capturing device being mounted on the chassis.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The combine harvester of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein to adjust settings or operating parameters comprises adjusting one or more of angle of header, header height, header speed, reel speed, reel tine angle, deck plate spacing, adjusting fan speed, cylinder speed, concave clearance, vehicle speed, precleaner, chaffer, extension, sieve, draper belt speed of the harvester for the unharvested region based on the crop information.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The combine harvester of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>a display device to display images or video captured by the at least one image capture device.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The combine harvester of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the display device to display the crop information.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The combine harvester of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the crop information comprises a level or amount of residue crop or a residue crop effectiveness.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The combine harvester of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the at least one image capturing device comprises a looking forward image capturing device positioned on a first outer edge of the header, an image capturing device positioned to view behind the header, a looking forward image capturing device positioned on a second outer edge of the header, and an image capturing device positioned on a frontal region of a frame of the harvester.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The combine harvester of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the looking forward image capturing devices face forward to capture a number of seeds that were thrown from a prior pass of an adjacent harvested region of the field.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The combine harvester of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the image capturing device is positioned to view behind the header to capture an amount of seeds after harvest for a current pass, which includes a number of seeds from the prior pass that were thrown.</claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The combine harvester of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the at least one processor is configured to execution instructions to determine a header loss at each row for a current pass based on the number of seeds from the prior pass and the amount of seeds for the current pass.</claim-text></claim></claims></us-patent-application>
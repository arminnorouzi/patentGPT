<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007164A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007164</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17855426</doc-number><date>20220630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-110503</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>243</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23216</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180801</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232127</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>243</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23225</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">IMAGING APPARATUS, CONTROL METHOD FOR IMAGING APPARATUS, AND STORAGE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>CANON KABUSHIKI KAISHA</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Kamba</last-name><first-name>Masaki</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system control unit controls an action regarding imaging by an imaging unit according to an instruction from a user. The system control unit automatically controls the action regarding the imaging by the imaging unit based on a preset condition. The system control unit chronologically records details of the control of the action of the imaging unit according to the instruction from the user as operation information. The system control unit chronologically records details of the automatic control of the action of the imaging unit as change information. The system control unit plays back the chronological details of the control of the action of the imaging unit based on the recorded operation information and change information.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="108.71mm" wi="152.74mm" file="US20230007164A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="133.52mm" wi="154.77mm" file="US20230007164A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="152.91mm" wi="158.24mm" file="US20230007164A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="135.64mm" wi="105.49mm" file="US20230007164A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="218.36mm" wi="118.53mm" file="US20230007164A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="198.71mm" wi="119.21mm" file="US20230007164A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="121.58mm" wi="113.11mm" file="US20230007164A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="224.96mm" wi="120.65mm" file="US20230007164A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="198.71mm" wi="119.21mm" file="US20230007164A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="205.15mm" wi="153.16mm" file="US20230007164A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="214.04mm" wi="85.17mm" file="US20230007164A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="202.44mm" wi="119.30mm" file="US20230007164A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="210.06mm" wi="111.00mm" file="US20230007164A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="135.21mm" wi="152.74mm" file="US20230007164A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="228.18mm" wi="123.44mm" file="US20230007164A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="171.37mm" wi="150.79mm" file="US20230007164A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND OF THE DISCLOSURE</heading><heading id="h-0002" level="1">Field of the Disclosure</heading><p id="p-0002" num="0001">The present disclosure relates to an imaging apparatus, a control method for an imaging apparatus, and a storage medium.</p><heading id="h-0003" level="1">Description of the Related Art</heading><p id="p-0003" num="0002">The expansion of the video streaming market in recent years has led to various proposals of systems allowing an event such as a wedding ceremony and a lecture meeting to be imaged using an imaging apparatus capable of capturing a moving image under remote control via a network (e.g., a network camera). In particular, there have also been proposed imaging apparatuses configured in such a manner that the installation of an application into a mobile terminal such as a smart-phone, a personal computer (PC), or the like enables the imaging apparatus to be remotely operated from the mobile terminal, the PC, or the like. Examples of this remote operation include a pan/tilt/zoom (PTZ) operation for operating panning, tilting, and zooming of the imaging apparatus. Among imaging apparatuses configured in this manner, there have also been proposed imaging apparatuses equipped with a presetting function of controlling the imaging apparatus so as to satisfy a preset angle of view and a trace function of recording information about an operation received from a user in advance to thereby reproduce an action based on this operation later. Japanese Patent No. 5661345 discusses an example of a technique for realizing the trace function in a camera platform system that allows an operation regarding pan/tilt/zoom and focus control to be performed.</p><p id="p-0004" num="0003">In contrast, some imaging apparatuses have a function of automatically controlling an action regarding imaging according to a moment-to-moment situation based on preset conditions. In such an imaging apparatus, the conditions regarding imaging may be determined under the control according to the operation received from the user and the automatic control. Under such a situation, for example, even when the information about the operation received from the user is recorded, it may be difficult to reproduce the action regarding imaging performed when this operation has been carried out based on the information.</p><heading id="h-0004" level="1">SUMMARY OF THE DISCLOSURE</heading><p id="p-0005" num="0004">In order to enable the previously performed action to be reproduced later in a further suitable manner even under a situation that the action regarding imaging is automatically controlled, an imaging apparatus includes a processor executing instructions that, when executed, cause the processor to function as a first control unit configured to control an action regarding an imaging unit according to an instruction from a user, a second control unit configured to automatically control an action regarding the imaging unit based on a preset condition, a first recording unit configured to chronologically record, as first information, details of the control of the action of the imaging unit according to the instruction from the user, a second recording unit configured to chronologically record, as second information, details of the automatic control of the action of the imaging unit based on the condition, in association with the first information, and a playback unit configured to play back chronological details of the control of the action of the imaging unit based on the first information and the second information.</p><p id="p-0006" num="0005">Further features of the present disclosure will become apparent from the following description of exemplary embodiments with reference to the attached drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example of the system configuration of an imaging system.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example of the configuration of an imaging apparatus.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of the configuration of a client apparatus.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example of processing in the imaging system.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating an example of processing in the imaging system.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example of a use case of the imaging system.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIGS. <b>7</b>A to <b>7</b>C</figref> each illustrate an example of a change in the action of the imaging apparatus in trace playback.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating another example of the processing in the imaging system.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> each illustrate an example of a user interface (UI) of the imaging system.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. <b>10</b>A and <b>10</b>B</figref> illustrate an example of an automatic adjustment of trace data.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart of automatic white balance control at the time of the trace playback.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIGS. <b>12</b>A and <b>12</b>B</figref> illustrate the automatic white balance control at the time of the trace playback.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example of a UI of an application.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates a flowchart for control at the time of the trace playback.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates a flowchart for control according to a setting of control at the time of the trace playback.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF THE EMBODIMENTS</heading><p id="p-0022" num="0021">In the following description, a representative exemplary embodiment of the present disclosure will be described in detail with reference to the accompanying drawings.</p><p id="p-0023" num="0022">In the present specification and drawings, components having substantially the same functions and configurations will be identified by the same reference numerals, and redundant descriptions thereof will be omitted.</p><heading id="h-0007" level="2">&#x3c;System Configuration&#x3e;</heading><p id="p-0024" num="0023">An example of the system configuration of an imaging system according to the present exemplary embodiment will be described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The imaging system according to the present exemplary embodiment includes an imaging apparatus <b>101</b>, and a terminal apparatus <b>102</b> used to control the action of this imaging apparatus <b>101</b>. The imaging apparatus <b>101</b> and the terminal apparatus <b>102</b> are connected so as to be able to transmit and receive information to and from each other via a network <b>105</b>. A plurality of terminal apparatuses <b>102</b> may be connected to the imaging apparatus <b>101</b> via the network <b>105</b>. A controller <b>104</b> may be employed instead of at least some of the terminal apparatuses <b>102</b>. An input device <b>103</b> for receiving an operation regarding the control of the action of the imaging apparatus <b>101</b> from a user may be connected to at least some of the terminal apparatuses <b>102</b>.</p><p id="p-0025" num="0024">The imaging apparatus <b>101</b> may capture an image in an imaging range according to an instruction from another apparatus (e.g., the terminal apparatus <b>102</b>, the controller <b>104</b>, or the like) via the network <b>105</b>. The imaging apparatus <b>101</b> may control conditions regarding imaging (e.g., focus, an aperture, a shutter speed, a gain, and the like) according to an instruction from another apparatus via the network <b>105</b>. According to an instruction from another apparatus via the network <b>105</b>, the imaging apparatus <b>101</b> may transmit data of a still image or a moving image according to a result of imaging to this other apparatus. In the following description, when being not especially referred to distinctively from each other, the still image and the moving image will also be referred to as an &#x201c;image&#x201d; for convenience.</p><p id="p-0026" num="0025">In the following description, when being not especially referred to distinctively from each other, the data of each of the still image and the moving image will also be referred to as &#x201c;image data&#x201d; for convenience.</p><p id="p-0027" num="0026">The terminal apparatus <b>102</b> can be realized by an information processing apparatus having a communication function, such as a personal computer (PC), a tablet terminal, and a smart-phone. The terminal apparatus <b>102</b> includes an output device for presenting information to the user, such as a display, and an input device for receiving an instruction from the user, such as a touch panel. At least either one of the output device and the input device may be realized as a device to be externally attached to the terminal apparatus <b>102</b>.</p><p id="p-0028" num="0027">For example, the input device <b>103</b> corresponds to an example of the input device externally attached to the terminal apparatus <b>102</b>. The input device <b>103</b> may be connected to the terminal apparatus <b>102</b> via a transmission path based on a standard, such as Universal Serial Bus (USB) and Bluetooth&#xae;. An input device for realizing a smooth pan/tilt/zoom (PTZ) operation, which is difficult to realize using only a graphical user interface (GUI) presented by an application, such as a joystick, may be employed as the input device <b>103</b>.</p><p id="p-0029" num="0028">The controller <b>104</b> schematically indicates hardware including an input interface regarding an operation of the imaging apparatus <b>101</b>. The controller <b>104</b> is connected to the imaging apparatus <b>101</b> via the network <b>105</b> in the example illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, but this example does not necessarily limit the connection method between the controller <b>104</b> and the imaging apparatus <b>101</b>. As a specific example, the controller <b>104</b> may be connected to the imaging apparatus <b>101</b> by a connection method such as a serial connection.</p><p id="p-0030" num="0029">The type of the network <b>105</b> is not particularly limited as long as communication can be established between the imaging apparatus <b>101</b>, and the terminal apparatus <b>102</b> and the controller <b>104</b>. As a specific example, a network in compliance with a communication standard such as ETHERNET may be employed as the network <b>105</b>. In this case, the network <b>105</b> may be realized using a router, a switch, a cable, and the like in compliance with this communication standard. As another example, a network in compliance with a communication standard for wireless communication, such as Wireless Fidelity (Wi-Fi) (registered trademark), Bluetooth&#xae;, Long Term Evolution (LTE) registered trademark), and the Fifth Generation Mobile Communication System (5G), may be employed as the network <b>105</b>. The network <b>105</b> may be realized by a plurality of networks. In this case, different two or more types of networks may be included in this plurality of networks. The communication between the imaging apparatus <b>101</b>, and the terminal apparatus <b>102</b> and the controller <b>104</b> may be mediated by another communication apparatus.</p><p id="p-0031" num="0030">The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is merely an example, and does not necessarily limit the system configuration of the imaging system according to the present exemplary embodiment. As a specific example, the imaging apparatus <b>101</b> may be realized as a stand-alone apparatus. In this case, an input device for receiving an instruction from the user and an output device for presenting information to the user may be provided to this imaging apparatus <b>101</b>. In this case, at least either one of the input device and the output device may also be realized as a device externally attached to the imaging apparatus <b>101</b>.</p><heading id="h-0008" level="2">&#x3c;Configuration&#x3e;</heading><p id="p-0032" num="0031">An example of the configuration of the imaging system according to the present exemplary embodiment will be described focusing on each of the imaging apparatus <b>101</b> and the terminal apparatus <b>102</b>, in particular.</p><p id="p-0033" num="0032">Initially, an example of the configuration of the imaging apparatus <b>101</b> will be described with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The imaging apparatus <b>101</b> includes a system control unit <b>201</b>, an imaging unit <b>202</b>, an image processing unit <b>203</b>, a lens driving unit <b>204</b>, an imaging angle-of-view control unit <b>205</b>, a focus control unit <b>206</b>, a pan driving unit <b>207</b>, a tilt driving unit <b>208</b>, and a pan/tilt control unit <b>209</b>. The imaging apparatus <b>101</b> may include a storage unit <b>210</b> and a program memory <b>211</b>. The imaging apparatus <b>101</b> may include a communication unit <b>220</b>.</p><p id="p-0034" num="0033">The system control unit <b>201</b> instructs each component of the imaging apparatus <b>101</b>, thus controlling various actions of the imaging apparatus <b>101</b> (esp., an action regarding imaging). The system control unit <b>201</b> can be realized by a computing device, such as a central processing unit (CPU) and a micro processing unit (MPU).</p><p id="p-0035" num="0034">The system control unit <b>201</b> may communicate various types of information with other apparatuses (e.g., the terminal apparatus <b>102</b>) via the network <b>105</b> by controlling the action of the communication unit <b>220</b>, which will be described below. As a specific example, the system control unit <b>201</b> may receive a control command regarding imaging from the terminal apparatus <b>102</b> via the network <b>105</b> and analyze this control command, thus performing processing according to this control command. Hereinafter, the control command regarding imaging will also be referred to as a &#x201c;camera control command&#x201d; for convenience.</p><p id="p-0036" num="0035">The camera control command includes a request command for requesting the imaging apparatus <b>101</b> to transmit image data and various types of setting values, and a setting command regarding the specification of a setting value.</p><p id="p-0037" num="0036">For example, the system control unit <b>201</b> may receive the request command regarding the transmission of image data from the terminal apparatus <b>102</b>. In this case, the system control unit <b>201</b> instructs the communication unit <b>220</b> to transmit image data generated by the image processing unit <b>203</b> to this terminal apparatus <b>102</b> via the network <b>105</b>.</p><p id="p-0038" num="0037">As another example, the system control unit <b>201</b> may receive the request command regarding the transmission of a setting value regarding imaging, such as setting values regarding focusing, zooming, panning, tilting, and the like from the terminal apparatus <b>102</b>. In this case, the system control unit <b>201</b> may acquire the setting value specified in this request command from a component managing this setting value and instruct the communication unit <b>220</b> to transmit the acquired information to the terminal apparatus <b>102</b> via the network <b>105</b>. Examples of candidates of components managing various types of setting values include the image processing unit <b>203</b>, the imaging angle-of-view control unit <b>205</b>, the focus control unit <b>206</b>, and the pan/tilt control unit <b>209</b>. The system control unit <b>201</b> may transmit, to the terminal apparatus <b>102</b> via the network <b>105</b>, not only the currently set value but also, for example, information about a settable range of this value as the information about a setting value regarding imaging.</p><p id="p-0039" num="0038">The system control unit <b>201</b> may receive the setting command regarding the specification of a setting value regarding imaging from the terminal apparatus <b>102</b>. In this case, the system control unit <b>201</b> instructs the component corresponding to this setting value to perform control based on the setting value specified by this setting command. Examples of candidates of such a component include the image processing unit <b>203</b>, the imaging angle-of-view control unit <b>205</b>, the focus control unit <b>206</b>, and the pan/tilt control unit <b>209</b>. The actions of, for example, the imaging unit <b>202</b>, the lens driving unit <b>204</b>, the pan driving unit <b>207</b>, and the tilt driving unit <b>208</b> are controlled by these components, so that the action of the imaging apparatus <b>101</b> according to the setting value specified by the terminal apparatus <b>102</b> is realized.</p><p id="p-0040" num="0039">The imaging unit <b>202</b> includes an imaging optical system such as a lens, and an image sensor. An optical image (a subject image) formed by the imaging optical system is optically guided to the image sensor and forms an image thereon, and is photoelectrically converted into an electric signal by the image sensor. The electric signal (an image signal) into which the above-described optical image is photoelectrically converted is subjected to, for example, a gain adjustment and an analog-to-digital (A/D) conversion from an analog signal into a digital signal by an A/D converter, and is then output to the image processing unit <b>203</b> after that.</p><p id="p-0041" num="0040">The image processing unit <b>203</b> applies various types of image processing, resolution conversion processing, compression/encoding processing, and/or the like on the image signal output from the imaging unit <b>202</b>, thus generating the image data. The image data generated by the image processing unit <b>203</b> may be, for example, stored into the storage unit <b>210</b>, which will be described below. As another example, this image data may be transmitted to another apparatus (e.g., the terminal apparatus <b>102</b>) via the network <b>105</b> by the communication unit <b>220</b>, which will be described below.</p><p id="p-0042" num="0041">The lens driving unit <b>204</b> includes a driving system regarding control of the position of at least a part of optical members among a series of optical members forming the imaging optical system of the imaging unit <b>202</b>, a motor serving as a power source of this driving system, and the like. In the present exemplary embodiment, an optical member regarding focus control (hereinafter also referred to as a &#x201c;focus lens&#x201d;), and an optical member regarding control of the angle of view (hereinafter also referred to as a &#x201c;zoom lens&#x201d;) are included as the optical members targeted for the positional control to be performed by the lens driving unit <b>204</b>. The action of the lens driving unit <b>204</b> is controlled by the imaging angle-of-view control unit <b>205</b> and the focus control unit <b>206</b>.</p><p id="p-0043" num="0042">The imaging angle-of-view control unit <b>205</b> instructs the lens driving unit <b>204</b> to control the position of the zoom lens based on the setting value regarding zooming that is output from the system control unit <b>201</b>. Examples of the setting value regarding zooming include a setting value of a focal length.</p><p id="p-0044" num="0043">The focus control unit <b>206</b> instructs the lens driving unit <b>204</b> to control the position of the focus lens based on the setting value regarding focusing that is output from the system control unit <b>201</b>. The position in the imaging range in which the focus lens focuses (a focus position) is controlled by the position of the focus lens being controlled.</p><p id="p-0045" num="0044">At least a part of actions among a series of actions regarding imaging by the imaging apparatus <b>101</b> may be automatically controlled according to various types of conditions such as the imaging environment.</p><p id="p-0046" num="0045">As a specific example, in autofocus (AF), an evaluation value is calculated from contrast in the image according to a result of imaging performed by the imaging unit <b>202</b>, and the focus control unit <b>206</b> controls the position of the focus lens according to this evaluation value. As a result, the focus of the imaging unit <b>202</b> is controlled so as to bring the subject in the imaging range into focus.</p><p id="p-0047" num="0046">Automatic control may be applied to not only the focus control but also, for example, an exposure (an aperture, a shutter speed, a gain, a neutral density (ND) filter, and the like), white balance, a noise reduction, and gamma control. For such automatic control, the component that performs this control may be changed as appropriate according to details of this control. As a specific example, the noise reduction, the gamma control, and the like may be performed by the image processing unit <b>203</b>.</p><p id="p-0048" num="0047">The pan driving unit <b>207</b> includes a driving system for realizing a pan action that controls the imaging direction of the imaging unit <b>202</b> in the pan direction, a motor serving as a power source of this driving system, and the like. The action of the pan driving unit <b>207</b> is controlled by the pan/tilt control unit <b>209</b>.</p><p id="p-0049" num="0048">The tilt driving unit <b>208</b> includes a driving system for realizing a tilt action that controls the imaging direction of the imaging unit <b>202</b> in the tilt direction, a motor serving as a power source of this driving system, and the like. The action of the tilt driving unit <b>208</b> is controlled by the pan/tilt control unit <b>209</b>.</p><p id="p-0050" num="0049">The pan/tilt control unit <b>209</b> instructs at least either the pan driving unit <b>207</b> or the tilt driving unit <b>208</b> to control the imaging direction (control regarding the pan action and the tilt action) based on the setting values regarding panning and tilting that are output from the system control unit <b>201</b>.</p><p id="p-0051" num="0050">The storage unit <b>210</b> stores various types of data (e.g., the image data) into at least either an internal storage or an external storage. The storage unit <b>210</b> may read out various types of data stored in the internal storage and the external storage. The above-described external storage and the above-described internal storage can be realized by, for example, a nonvolatile memory represented by a hard disk drive (HDD) and a solid state drive (SSD).</p><p id="p-0052" num="0051">The program memory <b>211</b> is a storage area storing a program regarding the control of the action of the imaging apparatus <b>101</b> therein. The system control unit <b>201</b> realizes various types of actions of the imaging apparatus <b>101</b> by loading this program stored in the program memory <b>211</b> and executing it.</p><p id="p-0053" num="0052">The communication unit <b>220</b> is a communication interface that allows the components of the imaging apparatus <b>101</b> (e.g., the system control unit <b>201</b>) to communicate various types of information with other apparatuses (e.g., the terminal apparatus <b>102</b>) via the network <b>105</b>. For example, the communication unit <b>220</b> may receive the camera control command from the terminal apparatus <b>102</b> via the network <b>105</b> and output this camera control command to the system control unit <b>201</b>. In this case, the communication unit <b>220</b> may transmit a response to the above-described camera control command to the above-described terminal apparatus <b>102</b> via the network <b>105</b> according to an instruction from the system control unit <b>201</b>. The camera control command has been described above, and thus, a detailed description thereof will be omitted here.</p><p id="p-0054" num="0053">The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is merely an example, and does not limit the configuration of the imaging apparatus <b>101</b> according to the present exemplary embodiment. For example, the configuration illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may be realized by a plurality of apparatuses cooperating with one another.</p><p id="p-0055" num="0054">As a specific example, some of the components among the series of components of the imaging apparatus <b>101</b> may be provided in another apparatus. As a specific example, components equivalent to the system control unit <b>201</b>, the storage unit <b>210</b>, and the program memory <b>211</b> may be provided on another apparatus capable of transmitting and receiving information to and from the imaging apparatus <b>101</b> via a predetermined transmission route. In this case, the other apparatus corresponds to an example of an &#x201c;information processing apparatus&#x201d; that controls the action of the imaging apparatus <b>101</b>.</p><p id="p-0056" num="0055">As another example, a load regarding processing of at least some of the components among the series of components of the imaging apparatus <b>101</b> may be divided among a plurality of apparatuses.</p><p id="p-0057" num="0056">Subsequently, an example of the configuration of a client apparatus will be described with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The client apparatus corresponds to an apparatus used to control the action of the imaging apparatus <b>101</b>, such as the terminal apparatus <b>102</b> and the controller <b>104</b>. The client apparatus includes a system control unit <b>301</b>, a communication unit <b>302</b>, a storage unit <b>303</b>, and a program memory <b>305</b>. The client apparatus may include an input unit <b>304</b>.</p><p id="p-0058" num="0057">The system control unit <b>301</b> instructs each component of the client apparatus, thus controlling various types of actions of this client apparatus. The system control unit <b>301</b> can be realized by a central processing device such as a CPU.</p><p id="p-0059" num="0058">For example, the system control unit <b>301</b> may generate the camera control command according to an operation that the input unit <b>304</b> receives from the user and instruct the communication unit <b>302</b> to transmit this camera control command to the imaging apparatus <b>101</b> via the network <b>105</b>. The mechanism in which the camera control command is transmitted from the client apparatus to the imaging apparatus <b>101</b> in this manner enables the imaging apparatus <b>101</b> to be also remotely controlled via the client apparatus.</p><p id="p-0060" num="0059">The system control unit <b>301</b> may instruct the imaging apparatus <b>101</b> to, for example, record information about details of the control of the action and reproduce the above-described action (play back of details of the control) later based on this recorded information. Hereinafter, the term &#x201c;trace function&#x201d; will also be used to refer to the series of functions of recording information about the details of the control of the action of the imaging apparatus <b>101</b> and reproducing the action of the imaging apparatus <b>101</b> later based on this information in the above-described manner for convenience. The term &#x201c;trace recording&#x201d; will also be used to refer to the function regarding recording information about the details of the control of the action of the imaging apparatus <b>101</b> and the term &#x201c;trace playback&#x201d; will also be used to refer to the function regarding reproducing the action of the imaging apparatus <b>101</b> (playing back the details of the control) later based on the recorded information.</p><p id="p-0061" num="0060">When the communication unit <b>302</b> receives a response from the imaging apparatus <b>101</b>, the system control unit <b>301</b> may perform processing according to this response by analyzing this response.</p><p id="p-0062" num="0061">The communication unit <b>302</b> is a communication interface that allows the components of the client apparatus (e.g., the system control unit <b>301</b>) to communicate various types of information with other apparatuses (e.g., the imaging apparatus <b>101</b>) via the network <b>105</b>. For example, the communication unit <b>302</b> may transmit the camera control command to the imaging apparatus <b>101</b> via the network <b>105</b> and receive a response to this camera control command from this imaging apparatus <b>101</b>. The camera control command has been described above, and thus, a detailed description thereof will be omitted here.</p><p id="p-0063" num="0062">The storage unit <b>303</b> stores therein various types of data (e.g., the image data) into either an internal storage or an external storage. The storage unit <b>303</b> may read out the various types of data stored in the internal storage and the external storage. The above-described external storage and internal storage can be realized by, for example, a nonvolatile memory represented by an HDD and an SSD.</p><p id="p-0064" num="0063">The program memory <b>305</b> is a storage area storing a program regarding the control of the action of the client apparatus (e.g., programs of various types of applications) therein. The system control unit <b>301</b> realizes various types of actions of the client apparatus by loading this program stored in the program memory <b>305</b> and executing it.</p><p id="p-0065" num="0064">The input unit <b>304</b> is an input interface for receiving an instruction from the user.</p><p id="p-0066" num="0065">The input unit <b>304</b> can be realized by an input device, such as a button provided to the client apparatus, a keyboard, a pointing device, and a joystick. As another example, the input unit <b>304</b> may be realized by a touch panel provided on a display unit (not illustrated) such as a display.</p><p id="p-0067" num="0066">The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> is merely an example, and does not limit the configuration of the client apparatus according to the present exemplary embodiment.</p><p id="p-0068" num="0067">For example, no component corresponding to a display unit such as a display is illustrated in the example illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, but the client apparatus may include a component corresponding to this display unit. Providing a component corresponding to the display unit to the client apparatus in this manner enables the client apparatus to present, for example, an image according to a result of imaging by the imaging apparatus <b>101</b> and the setting value applied to the action regarding the imaging by this imaging apparatus <b>101</b> to the user.</p><p id="p-0069" num="0068">The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be realized by a plurality of apparatuses cooperating with one another.</p><p id="p-0070" num="0069">As a specific example, some of the components among the series of components of the client apparatus may be provided in another apparatus. As a specific example, components equivalent to the input unit <b>304</b> and the storage unit <b>303</b> may be provided on another apparatus capable of transmitting and receiving information to and from the client apparatus via a predetermined transmission route.</p><p id="p-0071" num="0070">As another example, a load regarding processing of at least some of the components among the series of components of the client apparatus may be divided among a plurality of apparatuses.</p><p id="p-0072" num="0071">Hereinafter, various descriptions will be given assuming that the terminal apparatus <b>102</b> is employed as the client apparatus for convenience.</p><heading id="h-0009" level="2">&#x3c;Processing&#x3e;</heading><p id="p-0073" num="0072">An example of processing in the imaging system according to the present exemplary embodiment will be described with reference to <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref>.</p><p id="p-0074" num="0073">An example of processing regarding the trace recording will now be described with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0075" num="0074">In step S<b>401</b>, the system control unit <b>201</b> of the imaging apparatus <b>101</b> starts a series of processing procedures regarding the trace recording according to an instruction from the terminal apparatus <b>102</b>.</p><p id="p-0076" num="0075">Initially, in step S<b>402</b>, the system control unit <b>201</b> records information about the current state of the imaging apparatus <b>101</b> (e.g., the imaging direction and the imaging conditions) into a predetermined storage area when starting the trace recording. Hereinafter, the information about the state of the imaging apparatus <b>101</b> will also be referred to as &#x201c;camera information&#x201d; for convenience. The storage unit <b>210</b> of the imaging apparatus <b>101</b> may be used or the storage unit <b>303</b> of the terminal apparatus <b>102</b> may be used as the storage area. In the case where the storage unit <b>303</b> of the terminal apparatus <b>102</b> is used as the storage area, the system control unit <b>201</b> can fulfill this operation by transmitting the camera information to the terminal apparatus <b>102</b> via the network <b>105</b>.</p><p id="p-0077" num="0076">Hereinafter, various descriptions will be provided assuming that the storage unit <b>210</b> of the imaging apparatus <b>101</b> is used as the above-described storage area for convenience.</p><p id="p-0078" num="0077">In step S<b>403</b>, the system control unit <b>201</b> determines whether the terminal apparatus <b>102</b> receives an operation from the user (i.e., whether the terminal apparatus <b>102</b> receives an instruction from the user).</p><p id="p-0079" num="0078">If the system control unit <b>201</b> determines that the terminal apparatus <b>102</b> receives an operation from the user in step S<b>403</b> (YES in step S<b>403</b>), the processing proceeds to step S<b>404</b>. In this case, in step S<b>404</b>, the system control unit <b>201</b> records, from the terminal apparatus <b>102</b> via the network <b>105</b>, information about the operation received by this terminal apparatus <b>102</b> from the user (hereinafter also referred to as &#x201c;operation information&#x201d;) into the storage unit <b>210</b>. At this time, the system control unit <b>201</b> may record time information in association with the operation information. The operation information corresponds to an example of &#x201c;first information&#x201d;. The operation in step S<b>404</b> corresponds to an example of &#x201c;first recording processing&#x201d;.</p><p id="p-0080" num="0079">If the system control unit <b>201</b> determines that the terminal apparatus <b>102</b> receives no operation from the user in step S<b>403</b> (NO in step S<b>403</b>), the processing proceeds to step S<b>405</b>. In this case, the operation in step S<b>404</b> is skipped.</p><p id="p-0081" num="0080">In step S<b>405</b>, the system control unit <b>201</b> checks whether a change, in the state of the imaging apparatus <b>101</b>, due to automatic control of the action of the imaging apparatus <b>101</b> is detected.</p><p id="p-0082" num="0081">If the system control unit <b>201</b> determines that a change, in the state of this imaging apparatus <b>101</b>, due to automatic control of the action of the imaging apparatus <b>101</b> is detected in step S<b>405</b> (YES in step S<b>405</b>), the processing proceeds to step S<b>406</b>. In this case, in step S<b>406</b>, the system control unit <b>201</b> records information about the change, in the state of this imaging apparatus <b>101</b>, due to automatic control of the action of the imaging apparatus <b>101</b> (hereinafter also referred to as &#x201c;change information&#x201d;) into the storage unit <b>210</b>. In the case where the operation information has been recorded in step S<b>404</b>, the change information is additionally recorded next to the operation information, which leads to the establishment of association between the operation information and the change information. The change information corresponds to an example of &#x201c;second information&#x201d;. The processing in step S<b>405</b> corresponds to an example of &#x201c;second recording processing&#x201d;.</p><p id="p-0083" num="0082">If the system control unit <b>201</b> determines that no change, in the state of this imaging apparatus <b>101</b>, due to automatic control of the action of the imaging apparatus <b>101</b> is detected in step S<b>405</b> (NO in step S<b>405</b>), the processing proceeds to step S<b>407</b>. In this case, the operation in step S<b>406</b> is skipped.</p><p id="p-0084" num="0083">Now, the change information recorded in step S<b>406</b> will be further described supplementarily. The change information can include the information about the focus, the exposure (the aperture, the shutter speed, the gain, the ND filter, and the like), the white balance, the noise reduction, the gamma control, and the like, described above in conjunction with <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0085" num="0084">As a specific example, for the focus control, the change information may include information about, for example a change in distance information between the imaging apparatus <b>101</b> and the subject and the evaluation value information when the subject is in focus. For the exposure control, the change information may include information about a change in the exposure chart. For the white balance, the change information may include information about a change in the color temperature. For the noise reduction, the change information may include information about a change in the filter strength. For the gamma control, the change information may include information about a change in a dark portion correction and a high luminance correction due to the automatic control. The above-described information is merely an example, and the change information can include not only the above-described examples but also any types of information that relates to details of automatic control of the action of the imaging apparatus <b>101</b>.</p><p id="p-0086" num="0085">In step S<b>407</b>, the system control unit <b>201</b> determines whether to end the trace recording. As a specific example, the system control unit <b>201</b> may determine whether to end the trace recording according to whether an instruction regarding the end of the trace recording is received from the user.</p><p id="p-0087" num="0086">If the system control unit <b>201</b> determines not to end the trace recording in step S<b>407</b> (NO in step S<b>407</b>), the processing proceeds to step S<b>403</b>. This case leads to a repetition of the operations in step S<b>403</b> and the subsequent steps. This results in chronological and sequential recording of the operation information and the change information. Hereinafter, the data of the operation information and the change information chronologically and sequentially recorded by the trace recording will also be referred to as &#x201c;trace data&#x201d;.</p><p id="p-0088" num="0087">If the system control unit <b>201</b> determines to end the trace recording in step S<b>407</b> (YES in step S<b>407</b>), the processing proceeds to step S<b>408</b>.</p><p id="p-0089" num="0088">In step S<b>408</b>, the system control unit <b>201</b> ends the control regarding the trace recording (e.g., the control regarding the recording of the operation information and the change information).</p><p id="p-0090" num="0089">In step S<b>409</b>, the system control unit <b>201</b> records the camera information about the state of the imaging apparatus <b>101</b> at the time of the end of the trace recording into the storage unit <b>210</b>. After that, the system control unit <b>201</b> ends the series of processing procedures illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0091" num="0090">Next, an example of processing regarding the trace playback will be described with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0092" num="0091">In step S<b>501</b>, the system control unit <b>201</b> of the imaging apparatus <b>101</b> starts a series of processing procedures regarding the trace playback according to an instruction from the terminal apparatus <b>102</b>.</p><p id="p-0093" num="0092">In step S<b>502</b>, the system control unit <b>201</b> controls the imaging apparatus <b>101</b> based on the camera information at the time of the start of the trace recording that is recorded in the storage unit <b>210</b> in such a manner that the state of the imaging apparatus <b>101</b> matches the state thereof at the time of the start of this trace recording. As a result, the state of the imaging apparatus <b>101</b> (e.g., the imaging direction and the imaging conditions) is set to a substantially similar state to the state thereof at the time of the start of the trace recording (when step S<b>402</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is performed).</p><p id="p-0094" num="0093">In step S<b>503</b>, the system control unit <b>201</b> acquires the trace data (i.e., the operation information and the change information) recorded in the trace recording from the storage unit <b>210</b>. At this time, the system control unit <b>201</b> acquires information recorded earliest among pieces of information not acquired yet at this moment from the storage unit <b>210</b>.</p><p id="p-0095" num="0094">In step S<b>504</b>, the system control unit <b>201</b> reflects the details of the control of the action of the imaging apparatus <b>101</b> that is indicated in the operation information in the trace data acquired in step S<b>503</b> into the state set as the target of the control of the imaging apparatus <b>101</b> (hereinafter also referred to as a &#x201c;target state).</p><p id="p-0096" num="0095">In step S<b>505</b>, the system control unit <b>201</b> reflects the details of the control of the action of the imaging apparatus <b>101</b> that is indicated in the change information in the trace data acquired in step S<b>503</b> into the automatic control of the action of the imaging apparatus <b>101</b>. This causes the action of the imaging apparatus <b>101</b> to be automatically controlled based on the change information recorded in the trace recording, which enables limitation of, for example, the range of a state change accompanying the control of the action of the imaging apparatus <b>101</b> to within the range of the maximum change amount at the time of the trace recording. Under a scene for which the imposition of such a limitation is not required, for example, control under which the change in the state of the imaging apparatus <b>101</b> at the time of the trace recording is traced without change may be applied.</p><p id="p-0097" num="0096">In step S<b>506</b>, the system control unit <b>201</b> applies the automatic control in which the details of control indicated in the change information has been reflected in step S<b>505</b> with the aim of achieving the target state in which the details of control indicated in the operation information has been reflected in step S<b>504</b>, and controls the action of the imaging apparatus <b>101</b>.</p><p id="p-0098" num="0097">In step S<b>507</b>, the system control unit <b>201</b> determines whether an instruction regarding the stop of the trace playback is received or whether the trace playback is carried out for the series of pieces of information recorded in the trace recording to the last.</p><p id="p-0099" num="0098">If the system control unit <b>201</b> determines that no instruction regarding the stop of the trace playback is received and that the trace playback is not carried out to the last in step S<b>507</b> (NO in step S<b>507</b>), the processing proceeds to step S<b>503</b>. This case leads to a repetition of the operations in step S<b>503</b> and the subsequent steps for information not acquired yet through the operation in step S<b>503</b> among the pieces of information recorded in the storage unit <b>210</b> in the trace recording.</p><p id="p-0100" num="0099">If the system control unit <b>201</b> determines that an instruction regarding the stop of the trace playback is received or that the trace playback is carried out to the last in step S<b>507</b> (YES in step S<b>507</b>), the processing proceeds to step S<b>508</b>.</p><p id="p-0101" num="0100">In step S<b>508</b>, the system control unit <b>201</b> ends the series of processing procedures regarding the trace playback. This means that the series of processing procedures illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is ended.</p><p id="p-0102" num="0101">A case where the imaging apparatus <b>101</b> itself performs the processing regarding the trace recording and the trace playback has been described as the example described in conjunction with <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref>, but does not necessarily limit the processing in the imaging system according to the present exemplary embodiment. As a specific example, another apparatus such as the terminal apparatus <b>102</b> may perform the processing regarding the trace recording and the trace playback based on communication with the imaging apparatus <b>101</b> via the network <b>105</b>. In this case, the trace data may be recorded in the internal storage or the external storage of this other apparatus.</p><heading id="h-0010" level="1">EMBODIMENTS</heading><p id="p-0103" num="0102">An embodiment of the processing in the imaging system according to the present exemplary embodiment will be described with reference to <figref idref="DRAWINGS">FIGS. <b>6</b> to <b>8</b></figref>, focusing on, in particular, the autofocus control at the time of the trace playback.</p><p id="p-0104" num="0103">An outline of an issue in the autofocus control at the time of the trace playback will now be described with reference to <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b>A to <b>7</b>C</figref> to facilitate a better understanding of the characteristics of the imaging system according to the present exemplary embodiment. For example, <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example of a use case of the imaging system according to the present exemplary embodiment, and schematically illustrates a state in which the inside of a wedding hall is imaged by the imaging apparatus <b>101</b> under a situation that a wedding ceremony is ongoing in the wedding hall. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the imaging system is assumed to be in use under a scene that a person <b>601</b>, who is set as a main subject, is walking in a direction indicated by an arrow. In this example, the imaging apparatus <b>101</b> is disposed to face the person <b>601</b>, and is subjected to the PTZ control and various types of control regarding imaging with a remote operation.</p><p id="p-0105" num="0104"><figref idref="DRAWINGS">FIGS. <b>7</b>A to <b>7</b>C</figref> each illustrate a chronological change in the action of the imaging apparatus <b>101</b> as a graph, in a case where the action of the imaging apparatus <b>101</b> is controlled by the trace playback using the information recorded by the trace recording under the scene illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. More specifically, the example illustrated in each of <figref idref="DRAWINGS">FIGS. <b>7</b>A to <b>7</b>C</figref> chronologically indicates a change in the focus position in a case where the subject is in focus with the aid of the autofocus control (the position in the imaging range in which the focus lens focuses). In each of the graphs illustrated in <figref idref="DRAWINGS">FIGS. <b>7</b>A to <b>7</b>C</figref>, the horizontal axis represents time and the vertical axis represents the focus position in the depth direction.</p><p id="p-0106" num="0105">A graph C<b>701</b> illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> indicates a chronological change in the focus position when the focus control is performed as expected. More specifically, the person <b>601</b> is moving to further approach the imaging apparatus <b>101</b> as time passes. Thus, in a case where the imaging apparatus <b>101</b> is kept in the state of focusing on the person <b>601</b>, the focus position also changes to further approach the imaging apparatus <b>101</b> as time passes, as indicated as the graph C<b>701</b>.</p><p id="p-0107" num="0106">In contrast to this, a graph C<b>702</b> illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> indicates a chronological change in the focus position in a case where the focus control is not performed as expected. More specifically, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, a person other than the person <b>601</b> (e.g., a guest) is temporarily brought into focus, by which the focus position rapidly changes as indicated as the graph C<b>702</b> at the time of the transition between the state of focusing on the person <b>601</b> and the state of focusing on the other person.</p><p id="p-0108" num="0107">In consideration of such a situation, the imaging system according to the present exemplary embodiment may limit the range of the control of the action of the imaging apparatus <b>101</b> at the time of the trace playback based on the information recorded by the trace recording. For example, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>, the range in which the focus position is searched for (e.g., the range in which the focus lens is driven to bring the subject into focus) is limited based on the information indicated as the graph C<b>701</b> in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>. A range indicated as C<b>703</b> schematically indicates the range in which the focus position is searched for at a moment-to-moment timing. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>, limiting the range of the control of the action of the imaging apparatus <b>101</b> enables the imaging apparatus <b>101</b> to prevent the occurrence of a rapid change in the action thereof due to a cause which is not expected initially as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>.</p><p id="p-0109" num="0108">Next, an example of the processing in the imaging system according to the present exemplary embodiment will be described with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, focusing on, in particular, the processing in a case where the focus control is performed by the trace playback. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the trace data (the operation information and the change information) to be used for the trace playback is recorded in advance through the trace recording processing described in conjunction with <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In the following description, the example illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> will be described focusing on portions different from the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and detailed descriptions of portions substantially similar to the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> are omitted. For example, the operations in steps S<b>801</b> and S<b>802</b> are substantially similar to the operations in steps S<b>501</b> and S<b>502</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0110" num="0109">In step S<b>803</b>, the system control unit <b>201</b> acquires the trace data (the operation information and the change information) recorded in the trace recording from the storage unit <b>210</b>. The acquired trace data can include, for example, information about the PTZ position at the time of the trace recording, information about a mode regarding the focus control, information about the focus position, and information about the distance between the imaging apparatus <b>101</b> and the subject.</p><p id="p-0111" num="0110">In step S<b>804</b>, the system control unit <b>201</b> outputs the information about the distance between the imaging apparatus <b>101</b> and the subject and the information about the focus position in the trace data acquired in step S<b>803</b> to the focus control unit <b>206</b>. This output allows the focus control unit <b>206</b> to recognize a chronological change in the distance between the imaging apparatus <b>101</b> and the main subject and the focus position at the time of the trace recording based on the information output from the system control unit <b>201</b>.</p><p id="p-0112" num="0111">In step S<b>805</b>, the focus control unit <b>206</b> updates the driving range at the time of the focus control based on the information output from the system control unit <b>201</b> in step S<b>804</b>. As a specific example, the focus control unit <b>206</b> may determine the range in which the focus position is searched for (i.e., the range in which the focus lens is driven so as to bring the subject into focus) with reference to the size of a face or a human body in a case where the main subject is a human. As another example, the focus control unit <b>206</b> may determine the range in which the focus position is searched for according to the distance between the imaging apparatus <b>101</b> and the subject (i.e., depth information) in light of such a characteristic that the blur state changes according to the settings regarding zooming and the aperture. As another example, the focus control unit <b>206</b> may determine the range in which the focus position is searched for according to the range in which each unit (e.g., the component relating to the focus control) has been driven at the time of the trace recording.</p><p id="p-0113" num="0112">In step S<b>806</b>, the focus control unit <b>206</b> transmits an instruction regarding the focus control to the lens driving unit <b>204</b> based on the driving range undated in step S<b>805</b>. This leads to the imposition of a limitation on the range in which the focus position is searched for at the time of the focus control, for example, as described in conjunction with <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>.</p><p id="p-0114" num="0113">In step S<b>807</b>, the system control unit <b>201</b> determines whether an instruction regarding the stop of the trace playback is received or whether the trace playback is carried out for the series of pieces of information (the operation information and the change information) recorded as the trace data in the trace recording to the last of them.</p><p id="p-0115" num="0114">If the system control unit <b>201</b> determines that no instruction regarding the stop of the trace playback is received and that the trace playback is not carried out to the last in step S<b>807</b> (NO in step S<b>807</b>), the processing proceeds to step S<b>803</b>. This leads to a repetition of the operations in step S<b>803</b> and the subsequent steps for information not acquired yet by the operation in step S<b>803</b> among the pieces of information recorded in the storage unit <b>210</b> in the trace recording.</p><p id="p-0116" num="0115">If the system control unit <b>201</b> determines that an instruction regarding the stop of the trace playback is received or that the trace playback is carried out to the last in step S<b>807</b> (YES in step S<b>807</b>), the processing proceeds to step S<b>808</b>.</p><p id="p-0117" num="0116">In step S<b>808</b>, the system control unit <b>201</b> ends the series of processing procedures regarding the trace playback. Thus, the series of processing procedures illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> is ended.</p><p id="p-0118" num="0117">An embodiment of the processing in the imaging system according to the present exemplary embodiment has been described in conjunction with <figref idref="DRAWINGS">FIGS. <b>6</b> to <b>8</b></figref>, focusing on, in particular, the autofocus control at the time of the trace playback. The employment of the control as in the above-described example improves the stability of the control of the action of the imaging apparatus <b>101</b> at the time of the trace playback even in a case where the automatic control is applied to the action of the imaging apparatus <b>101</b> at the time of the trace recording. In this manner, the imaging system according to the present exemplary embodiment enables the previously performed action to be reproduced later in a further suitable manner even under a situation that the action regarding imaging is automatically controlled.</p><heading id="h-0011" level="1">First Exemplary Modification</heading><p id="p-0119" num="0118">An exemplary modification of the imaging system according to the present exemplary embodiment will be described with reference to <figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B and <b>10</b>A and <b>10</b>B</figref>. As described above, in the imaging system according to the present exemplary embodiment, the trace data (the operation information and the change information) is recorded in the trace recording and the action of the imaging apparatus <b>101</b> is controlled based on this trace data in the trace playback. The imaging system according to the present exemplary modification is different from the imaging system according to the above-described exemplary embodiment in terms of the provision of a function of editing the trace data recorded in the trace recording. Thus, in the following description, the imaging system according to the present exemplary modification will be described focusing on different portions from the imaging system according to the above-described exemplary embodiment and detailed descriptions of substantially portions similar to the imaging system according to the above-described exemplary embodiment are omitted.</p><p id="p-0120" num="0119">Initially, <figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> will be described. <figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> each illustrate an example of a user interface (UI) of the imaging system according to the present exemplary modification. More specifically, an operation screen <b>900</b> illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref> indicates an example of a UI for receiving an instruction regarding the control of the action of the imaging apparatus <b>101</b> (esp., the action regarding imaging) from the user. For example, by a predetermined application being executed on the terminal apparatus <b>102</b>, the operation screen <b>900</b> is presented to the user via an output unit of this terminal apparatus <b>102</b>.</p><p id="p-0121" num="0120">The operation screen <b>900</b> includes an image display region <b>901</b>, a PTZ bar <b>902</b>, a focus mode operation portion <b>903</b>, and a manual focus (MF) operation portion <b>904</b>. The operation screen <b>900</b> includes a trace number (No.) setting portion <b>905</b>, a recording button <b>906</b>, a playback button <b>907</b>, and an editing button <b>908</b> as UIs regarding the trace function.</p><p id="p-0122" num="0121">The image display region <b>901</b> is a display region for displaying an image according to a result of imaging by the imaging apparatus <b>101</b>. The display of the above-described image in the image display region <b>901</b> enables the user to remotely operate the imaging apparatus <b>101</b> while checking this image.</p><p id="p-0123" num="0122">The PTZ bar <b>902</b> is an input interface for receiving an instruction regarding the pan, tilt, and zoom control from the user.</p><p id="p-0124" num="0123">The focus mode operation portion <b>903</b> is an input interface for receiving the specification of an action mode regarding the focus control from the user. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>, either AF (autofocus) or MF (manual focus) can be specified as the action mode regarding the focus control via the focus mode operation portion <b>903</b>.</p><p id="p-0125" num="0124">The MF operation portion <b>904</b> is an input interface for receiving an instruction regarding an adjustment of the focus position from the user in a case where the action mode regarding the focus control is set to MF. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>, an input interface for controlling the focus position in each of a FAR direction and a NEAR direction is provided as the MF operation portion <b>904</b>.</p><p id="p-0126" num="0125">The PTZ bar <b>902</b> and the focus mode operation portion <b>903</b> may be equipped with a function of presenting the value currently set to the imaging apparatus <b>101</b>.</p><p id="p-0127" num="0126">The trace No. setting portion <b>905</b> is an input interface for receiving the specification of identification information for identifying the trace data (the operation information and the change information) targeted for the trace recording, the trace playback, and the editing from the user. Hereinafter, this identification information will also be referred to as a &#x201c;trace No.&#x201d;</p><p id="p-0128" num="0127">The recording button <b>906</b> is an input interface for receiving an instruction regarding the trace recording from the user. When the recording button <b>906</b> is pressed, the processing regarding the trace recording described in conjunction with <figref idref="DRAWINGS">FIG. <b>4</b></figref> is started. When the recording button <b>906</b> is pressed again after that, the started processing regarding the trace recording is ended. The trace No. specified via the trace No. setting portion <b>905</b> is assigned to the trace data (the operation information and the change information) recorded by performing the processing regarding the trace recording.</p><p id="p-0129" num="0128">The playback button <b>907</b> is an input interface for receiving an instruction regarding the trace playback from the user. When the playback button <b>907</b> is pressed, the processing regarding the trace playback described in conjunction with <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>8</b></figref> is started based on the trace data (the operation information and the change information) to which the trace No. specified via the trace No. setting portion <b>905</b> is assigned. When the playback button <b>907</b> is pressed again, the above-described started processing regarding the trace playback is ended.</p><p id="p-0130" num="0129">The editing button <b>908</b> is an input interface for receiving an instruction regarding the editing of the trace data (the operation information and the change information) recorded by the trace recording from the user.</p><p id="p-0131" num="0130">When the editing button <b>908</b> is pressed, a trace data editing screen <b>909</b> illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref> is displayed with the editing target set to the trace data to which the trace No. specified via the trace No. setting portion <b>905</b> is assigned.</p><p id="p-0132" num="0131">Next, the trace data editing screen <b>909</b> illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref> will be described now. The trace data editing screen <b>909</b> is an operation screen for receiving an instruction regarding the editing of the trace data from the user. The trace data editing screen <b>909</b> includes a trace No. display portion <b>910</b>, an editing target specification portion <b>911</b>, a trace data editing portion <b>912</b>, an automatic adjustment button <b>913</b>, a save button <b>914</b>, and a close button <b>915</b>.</p><p id="p-0133" num="0132">The trace No. display portion <b>910</b> is a region where the trace No. assigned to the trace data specified as the editing target is displayed. For example, the trace No. specified via the trace No. setting portion <b>905</b> is displayed in the trace No. display portion <b>910</b>.</p><p id="p-0134" num="0133">The editing target specification portion <b>911</b> is an input interface for receiving the specification of data targeted for the editing among the pieces of data regarding the control of various types of actions of the imaging apparatus <b>101</b> included in the trace data specified as the editing target from the user. For example, data regarding the focus control is specified in the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>. The editing target is not limited only to data regarding the focus control as long as the data is recorded as the trace data, of course. As a specific example, data regarding the PTZ control, a parameter regarding the control of the action of the imaging apparatus <b>101</b>, and the like may be able to be specified as the editing target.</p><p id="p-0135" num="0134">The trace data editing portion <b>912</b> serves as both an output interface regarding a display of the data targeted for the editing and an input interface for receiving an instruction regarding the editing of this data from the user. As a specific example, the data specified via the editing target specification portion <b>911</b> in the trace data corresponding to the trace No. displayed in the trace No. display portion <b>910</b> is displayed in the trace data editing portion <b>912</b>.</p><p id="p-0136" num="0135">For example, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, the data regarding the focus control is displayed in the trace data editing portion <b>912</b> as a graph indicating a chronological change in the focus position. In this case, for example, when the graph displayed in the trace data editing portion <b>912</b> is corrected according to an instruction from the user, the data regarding the focus control is edited according to this correction.</p><p id="p-0137" num="0136">The method for displaying the data in the trace data editing portion <b>912</b> is not limited only to the method of displaying the data as a graph as in the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, and may be changed as appropriate according to the type of the data targeted for the editing. According to the method of displaying the data in the trace data editing portion <b>912</b>, the method of editing this data may also be changed as appropriate. As a specific example, a setting value regarding the control of the action of the imaging apparatus <b>101</b> that is recorded as the trace data may be displayed in the trace data editing portion <b>912</b> as character information such as a numerical value. In this case, for example, with a correction made to the setting value displayed as the character information, the data regarding the focus control may be edited according to this correction.</p><p id="p-0138" num="0137">The automatic adjustment button <b>913</b> is an input interface for receiving an instruction regarding an automatic adjustment of the trace data from the user. In a case where the automatic adjustment button <b>913</b> is pressed, automatic editing processing based on preset conditions is applied to the data displayed in the trace data editing portion <b>912</b>.</p><p id="p-0139" num="0138">For example, <figref idref="DRAWINGS">FIGS. <b>10</b>A and <b>10</b>B</figref> illustrate an example of the automatic adjustment of the trace data.</p><p id="p-0140" num="0139">More specifically, a graph <b>1001</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b>A</figref> schematically represents a graph indicating a chronological change in the focus position based on the data regarding the focus control before the automatic adjustment is applied. A subtle change in the focus position accompanying a fluctuation of the focus control or the like emerges in the graph <b>1001</b>.</p><p id="p-0141" num="0140">In contrast to this, a graph <b>1002</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b>B</figref> schematically represents a graph indicating a chronological change in the focus position based on the data regarding the focus control after the automatic adjustment is applied. The graph <b>1002</b> indicates an example of a result of an adjustment that is made to the graph <b>1001</b> in such a manner that the focus position changes chronologically and smoothly with application of processing such as smoothing, a spline correction, and a removal of extreme data to the graph <b>1001</b>.</p><p id="p-0142" num="0141">As a specific example, the trace data may be automatically adjusted by removing data corresponding a chronological change exceeding a threshold value (i.e., data indicating a rapid change) among the series of pieces of data before the editing, and conducting liner interpolation based on data before and after this removed data. As a result of such an automatic adjustment made to the data, for example, the details of the focus control indicated as the graph <b>1001</b> is adjusted in such a manner that the focus position chronologically and smoothly changes as indicated as the graph <b>1002</b>.</p><p id="p-0143" num="0142">Now, refer to <figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> again.</p><p id="p-0144" num="0143">The save button <b>914</b> is an input interface for receiving, from the user, an instruction regarding reflecting a result of the editing of the trace data and saving this trace data after the editing.</p><p id="p-0145" num="0144">When the save button <b>914</b> is pressed, the details of editing specified via the trace data editing portion <b>912</b> or the details of the automatic adjustment made based on the pressing of the automatic adjustment button <b>913</b> serving as a trigger therefor is reflected into the trace data, and this trace data is newly recorded. In recording the trace data after the editing, the trace data before the editing may be overwritten.</p><p id="p-0146" num="0145">The close button <b>915</b> is an input interface for receiving an instruction regarding the end of the editing of the trace data from the user. In a case where the close button <b>915</b> is pressed, the trace data editing screen <b>909</b> is closed with the editing details specified via the trace data editing portion <b>912</b> and the details of the automatic adjustment made based on the pressing of the automatic adjustment button <b>913</b> serving as a trigger therefor not being reflected into the trace data. In this case, the data indicating the editing details specified via the trace data editing portion <b>912</b> or the data indicating the details of the automatic adjustment made based on the pressing of the automatic adjustment button <b>913</b> serving as a trigger therefor is to be discarded.</p><heading id="h-0012" level="1">Second Exemplary Modification</heading><p id="p-0147" num="0146"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart according to a second exemplary modification, in which the above-described control is modified in such a manner that the automatic white balance (AWB) control based on trace recording information is performed as in the autofocus control at the time of the trace playback. The control at the time of the trace recording is similar to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, and detailed descriptions will be omitted with respect to portions overlapping the description of <figref idref="DRAWINGS">FIG. <b>5</b></figref> at the time of the trace playback. The configuration diagrams illustrated in <figref idref="DRAWINGS">FIGS. <b>2</b>, <b>3</b></figref>, and the like are also similar to the above-described example, and the descriptions of overlapping contents will be omitted.</p><p id="p-0148" num="0147">Further, <figref idref="DRAWINGS">FIGS. <b>12</b>A and <b>12</b>B</figref> each schematically illustrate an AWB region of the white balance control. The white balance control is control performed by the image processing unit <b>203</b>, and, color information is acquired for each region in the input image acquired from the imaging unit <b>202</b>, and a representative value of the color information is calculated. A white balance gain (a WB gain) with which the representative value of the color information in the output image matches a predetermined target value is calculated, and is applied to the output image. The WB gain includes, for example, a Red gain for adjusting redness in the output image and a Blue gain for adjusting blueness in the output image. <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> illustrates the AWB region at the time of the trace recording, and A<b>1</b> represents an effective range of the gain set as a target at the time of the AWB. The AWB control at the time of the trace recording is similar to the AWB control as that at the time of normal imaging. In a case where P represents a WB gain which is applied to the current image and Q represents a target WB gain which has been obtained through calculation in the next input image, the image processing unit <b>203</b> determines whether the WB gain Q falls within the predetermined region A<b>1</b>, and multiplies the input image by the WB gain Q if the WB gain Q falls within the range A<b>1</b>. If the WB gain Q set as the target falls outside the range A<b>1</b>, the WB gain is kept in a state of P. The range A<b>1</b>, which is the effective range, is designed to such a range in which white balance is suitably controlled and considerably uncomfortable feeling is not given to the user, by application of the WB gain in this effective range to the input image achieves. <figref idref="DRAWINGS">FIG. <b>12</b>B</figref> illustrates the AWB region at the time of the trace playback, and the effective range of the gain set as the target at the time of the AWB is adjusted to a range A<b>2</b> narrower than A<b>1</b> at the time of the trace recording. In a case where R represents the target WB gain which is obtained through calculation in the next input image, R falls within the effective range in the case of the region A<b>1</b> but falls outside the effective range in the case of the region A<b>2</b>, and therefore the WB gain is kept in the state of P. The trace function is a function used based on the premise that the installation location of the camera, the light source environment, and the like are the same, but a fine adjustment of the WB gain may be to be made due to, for example, an influence of external light from a window in some cases. However, performing the AWB control in a wide range as in A<b>1</b> may undesirably result in a considerable difference from the color at the time of the storage due to an influence of, for example, the clothes of the subject. The range of the region A<b>2</b> is determined based on the amount of a change in the WB gain at the time of the trace recording. Since the current value of the WB gain associated with time is recorded in the trace recording information, the WB gain may be controlled within the range of this change amount or may be controlled within a range with a predetermined correction amount added thereto. The state at the time of the trace recording can be reproduced and finely adjusted by narrowing the effective range as in the region A<b>2</b> at the time of the trace playback in this manner.</p><p id="p-0149" num="0148">Referring back now to the flowchart illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, details thereof will be described. Initially, in step S<b>1101</b>, the system control unit <b>201</b> of the imaging apparatus <b>101</b> starts the series of processing procedures regarding the trace playback according to an instruction from the terminal apparatus <b>102</b>, as in the operation in step S<b>501</b>. Next, in step S<b>1102</b>, the image processing unit <b>203</b> acquires the WB gain change amount from the trace recording information, and determines the AWB effective range as described in conjunction with <figref idref="DRAWINGS">FIGS. <b>12</b>A and <b>12</b>B</figref>. The operations in steps S<b>1103</b> and S<b>1104</b> are similar to those in steps S<b>502</b> and S<b>503</b>, and thus, the descriptions thereof will be omitted here. In step S<b>1105</b>, the system control unit <b>201</b> controls the imaging apparatus <b>101</b> so as to reproduce the user operation based on the recording information acquired in step S<b>1104</b>. The autofocus control described in the example 1 may be added thereto while being not illustrated. In step S<b>1106</b>, the image processing unit <b>203</b> performs the AWB control based on the AWB effective range determined in step S<b>1102</b>. The operations in steps S<b>1103</b> and S<b>1106</b> may be replaced with automatic control of the exposure (the aperture, the shutter speed, the gain, and the ND filter), the noise reduction, and the gamma. A change in the exposure diagram is included for the exposure control, a change in the filter strength is included for the noise reduction, and a change in the dark portion correction and the high luminance correction due to the automatic control is included for the gamma. The image can be finely adjusted while a difference from the image at the time of the trace recording is controlled by limiting the control range at the time of the trace playback based on the change range at the time of the trace recording. In a case where the imaging apparatus <b>101</b> is equipped with an automatic control function besides them, it may be included in the recording target. The operations in steps S<b>1107</b> and S<b>1108</b> are similar to those in steps S<b>507</b> and S<b>508</b>, and thus, the descriptions thereof will be omitted here.</p><p id="p-0150" num="0149">In the above-described manner, the imaging apparatus <b>101</b> performs the AWB control at the time of the trace playback. As a result, stable trace control can be easily provided by recording a change in the camera control due to the automatic settings at the time of the trace recording, together with the user operation, and controlling the imaging apparatus <b>101</b> based on the recorded change information at the time of the trace playback.</p><heading id="h-0013" level="1">Third Exemplary Modification</heading><p id="p-0151" num="0150"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example of an application screen according to a third exemplary modification, in which the application screen described in conjunction with <figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> is modified in such a manner that control is added thereto so as to allow the user to select the control method at the time of the trace playback. The descriptions of portions overlapping the above description will be omitted in the following description.</p><p id="p-0152" num="0151"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example of a GUI in which the operation portion of the trace control of the operation screen <b>900</b> in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref> is extracted and a part of control items is added thereto. A trace control portion <b>1301</b> is similar to the control items <b>905</b> to <b>908</b> in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>. A setting at a portion of &#x201c;control at the time of the trace playback&#x201d; <b>1302</b> is control for selecting details of the control when the trace playback button <b>907</b> is pressed. More specifically, when the trace playback is carried out with a toggle button <b>1303</b> selected, manual control at the time of the trace recording is performed. This setting leads to the playback of the trace information recorded at the time of the trace recording, and can be utilized in a case where the recording information based on the user operation at the time of the trace recording is desired to be faithfully reproduced. Subsequently, in a case where the trace playback is carried out with a toggle button <b>1304</b> selected, automatic control is performed based on the change information at the time of the trace recording as in, for example, the processing according to the flowchart illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Lastly, when the trace playback is carried out with a toggle button <b>1305</b> selected, the change information at the time of the trace recording is not used and the operation information is played back under automatic control in a manner similar to the control at the time of the trace recording. In a case where the trace playback is carried out with the toggle button <b>1305</b> selected, for example, the operation information about the imaging range at the time of the trace recording is played back. In contrast, the information about a change, in the recorded autofocus control, due to the automatic control of the action of the imaging apparatus <b>101</b> at the time of the trace recording is not played back, and the autofocus control is automatically performed again at the time of the trace playback. The settings of the toggle buttons <b>1303</b> to <b>1305</b> are applied to the imaging apparatus <b>101</b> from the terminal apparatus <b>102</b>. Thus, an optimum operation according to the imaging environment is enabled by the user being allowed to select the control method.</p><p id="p-0153" num="0152">Now, a flowchart at the time of the trace playback to which the setting of the control at the time of the trace playback according to the present exemplary modification is added will be described with reference to <figref idref="DRAWINGS">FIG. <b>14</b></figref>. Detailed descriptions of portions overlapping <figref idref="DRAWINGS">FIG. <b>11</b></figref> will be omitted here.</p><p id="p-0154" num="0153">Initially, the operation in step S<b>1401</b> is similar to that in step S<b>1101</b>, and the imaging apparatus <b>101</b> starts the trace playback according to an instruction from the client apparatus. Subsequently, in step S<b>1402</b>, the system control unit <b>201</b> acquires the information set via the setting of the control at the time of the trace playback <b>1302</b>. If the toggle button <b>1304</b> is set (YES in step S<b>1402</b>), the processing proceeds to step S<b>1403</b>. If another setting is selected (NO in step S<b>1402</b>), the processing proceeds to step S<b>1404</b>. In step S<b>1403</b>, the image processing unit <b>203</b> acquires, for example, the WB gain change amount as in the example described in the second exemplary modification from the trace recording information, and determines the control range at the time of the automatic control. The operations in steps S<b>1404</b> to S<b>1406</b> are similar to those in steps S<b>1103</b> to S<b>1105</b>, and the system control unit <b>201</b> controls the imaging apparatus <b>101</b> to the initial position of the trace playback and acquires the next trace recording information from the storage unit <b>210</b>. The imaging apparatus <b>101</b> is controlled to reproduce the user operation based on the recording information acquired in step S<b>1405</b>. Next, in step S<b>1407</b>, the system control unit <b>201</b> controls the camera according to the setting set via the setting at the portion of the &#x201c;control at the time of the trace playback&#x201d; <b>1302</b>.</p><p id="p-0155" num="0154">Now, the camera control according to the setting of the control at the time of the trace playback in step S<b>1407</b> will be described with reference to a flowchart illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. The system control unit <b>201</b> of the imaging apparatus <b>101</b> acquires the information set via the setting of the control at the time of the trace playback <b>1302</b> and switches the control according to the setting state. In step S<b>1501</b>, the system control unit <b>201</b> checks whether the setting of the control at the time of the trace playback <b>1302</b> is the state in which the toggle button <b>1303</b> is selected. If the toggle button <b>1303</b> is selected (YES in step S<b>1501</b>), the processing proceeds to step S<b>1502</b>. If the toggle button <b>1303</b> is not selected (NO in step S<b>1501</b>), the processing proceeds to step S<b>1503</b>. In step S<b>1502</b>, the system control unit <b>201</b> performs the processing for playing back the operation information recorded at the time of the trace recording. In step S<b>1503</b>, the system control unit <b>201</b> checks whether the setting of the control at the time of the trace playback <b>1302</b> is the state in which the toggle button <b>1304</b> is selected. If the toggle button <b>1304</b> is selected (YES in step S<b>1503</b>), the processing proceeds to step S<b>1504</b>. If the toggle button <b>1304</b> is not selected (NO in step S<b>1503</b>), the processing proceeds to step S<b>1505</b>. In step S<b>1504</b>, the system control unit <b>201</b> performs, for example, the automatic control described in conjunction with <figref idref="DRAWINGS">FIG. <b>11</b></figref> or the automatic control such as the focus control in the driving range based on the change information as in the control described in conjunction with <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Then, the flow is ended. Lastly in step S<b>1505</b>, while playing back the operation information at the time of the trace recording, the system control unit <b>201</b> does not play back the parameter recorded as the information about a change due to the automatic control at the time of the trace recording and adjusts this parameter under automatic control again. For example, the operation information about the imaging range at the time of the trace recording is played back. By contrast, the recorded information about a change, in the autofocus control, due to the automatic control of the action of the imaging apparatus <b>101</b> at the time of the trace recording is not played back, and the autofocus control is automatically performed again at the time of the trace playback. The operations in steps S<b>1408</b> and S<b>1409</b> are similar to those in steps S<b>1107</b> and S<b>1108</b>, and thus, the descriptions thereof will be omitted here.</p><p id="p-0156" num="0155">In the above-described manner, this processing enables the trace playback to be carried out according to the mode selected by the user among a plurality of modes regarding the trace playback, thus adaptively achieving the trace playback intended by the user.</p><heading id="h-0014" level="1">OTHER EXEMPLARY EMBODIMENTS</heading><p id="p-0157" num="0156">The present disclosure can also be realized by processing that supplies a program capable of fulfilling one or more functions of the above-described exemplary embodiment to a system or an apparatus via a network or a recording medium, and causes one or more processors in a computer of this system or apparatus to read out and execute the program. The present disclosure can also be realized by a circuit (e.g., an application specific integrated circuit (ASIC)) capable of fulfilling one or more functions.</p><p id="p-0158" num="0157">According to each of the above-described exemplary embodiments, it becomes possible to reproduce the previously performed action later in a further desirable manner even under a situation that the action regarding imaging is automatically controlled.</p><heading id="h-0015" level="1">OTHER EMBODIMENTS</heading><p id="p-0159" num="0158">Embodiment(s) of the present disclosure can also be realized by a computer of a system or apparatus that reads out and executes computer executable instructions (e.g., one or more programs) recorded on a storage medium (which may also be referred to more fully as a &#x2018;non-transitory computer-readable storage medium&#x2019;) to perform the functions of one or more of the above-described embodiment(s) and/or that includes one or more circuits (e.g., application specific integrated circuit (ASIC)) for performing the functions of one or more of the above-described embodiment(s), and by a method performed by the computer of the system or apparatus by, for example, reading out and executing the computer executable instructions from the storage medium to perform the functions of one or more of the above-described embodiment(s) and/or controlling the one or more circuits to perform the functions of one or more of the above-described embodiment(s). The computer may comprise one or more processors (e.g., central processing unit (CPU), micro processing unit (MPU)) and may include a network of separate computers or separate processors to read out and execute the computer executable instructions. The computer executable instructions may be provided to the computer, for example, from a network or the storage medium. The storage medium may include, for example, one or more of a hard disk, a random-access memory (RAM), a read only memory (ROM), a storage of distributed computing systems, an optical disk (such as a compact disc (CD), digital versatile disc (DVD), or Blu-ray Disc (BD)&#x2122;), a flash memory device, a memory card, and the like.</p><p id="p-0160" num="0159">While the present disclosure has been described with reference to exemplary embodiments, it is to be understood that the disclosure is not limited to the disclosed exemplary embodiments. The scope of the following claims is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures and functions.</p><p id="p-0161" num="0160">This application claims the benefit of Japanese Patent Application No. 2021-110503, filed Jul. 2, 2021, which is hereby incorporated by reference herein in its entirety.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An imaging apparatus comprising,<claim-text>a processor executing instructions that, when executed, cause the processor to function as;</claim-text><claim-text>a first control unit configured to control an action regarding an imaging unit according to an instruction from a user;</claim-text><claim-text>a second control unit configured to automatically control an action regarding the imaging unit based on a preset condition;</claim-text><claim-text>a first recording unit configured to chronologically record, as first information, details of the control of the action of the imaging unit according to the instruction from the user;</claim-text><claim-text>a second recording unit configured to chronologically record, as second information, details of the automatic control of the action of the imaging unit based on the condition, in association with the first information; and</claim-text><claim-text>a playback unit configured to play back chronological details of the control of the action of the imaging unit based on the first information and the second information.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The imaging apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second control unit automatically controls an action regarding at least any one of conditions for focus, an aperture value, a shutter speed, a gain, an neutral density (ND) filter, white balance, a noise reduction, and gamma control, as the action regarding the imaging by the imaging unit.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The imaging apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the second control unit performs at least autofocus control of automatically controlling a focus position, as the action regarding the imaging by the imaging unit,<claim-text>wherein the second recording unit includes, in the second information, information about a change in the focus position in a case where at least the autofocus control is performed, and</claim-text><claim-text>wherein the focus position is controlled based on the information about the change in the focus position included in the second information, at the time of the playback of the details of the control of the action of the imaging unit.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The imaging apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein a range in which the focus position is searched for is limited based on the information about the change in the focus position included in the second information at the time of the playback of the details of the control of the action of the imaging unit.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The imaging apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the range in which the focus position is searched for is determined based on at least any one of a size of a subject, a distance to the subject, and a driving range regarding the control of the focus position at the time of the recording of the second information.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The imaging apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instruction further causes the processor to function as an update unit configured to update the recorded second information,<claim-text>wherein the playback unit plays back the chronological details of the control of the action of the imaging unit based on the updated second information.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The imaging apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the instruction further causes the processor to function as an output unit configured to present, to the user, information about the details of the automatic control of the action of the imaging unit based on the condition based on the recorded second information; and<claim-text>an input unit configured to receive an instruction from the user,</claim-text><claim-text>wherein the update unit updates the second information according to the instruction from the user that is received by the input unit.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The imaging apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the update unit updates the second information by correcting, based on a preset condition, the details of the control of the action regarding the imaging by the imaging unit, the second information having been recorded as the second information.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The imaging apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the first information recorded by the first recording unit includes information about a white balance gain, and</claim-text><claim-text>wherein the playback unit performs white balance control based on the information about the white balance gain.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The imaging apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the playback unit limits an effective range of automatic white balance based on the information about the white balance gain.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The imaging apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the effective range is determined based on the information about the white balance gain recorded by the first recording unit.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A control method for an imaging apparatus, the control method comprising:<claim-text>controlling, as a first control, an action regarding an imaging unit according to an instruction from a user;</claim-text><claim-text>automatically controlling, as a second control, an action regarding the imaging unit based on a preset condition;</claim-text><claim-text>chronologically recording, as a first recording, details of the control of the action of the imaging unit according to the instruction from the user, as first information;</claim-text><claim-text>chronologically recording, as a second recording, details of the automatic control of the action of the imaging unit based on the condition, in association with the first information, as second information; and</claim-text><claim-text>playing back chronological details of the control of the action of the imaging unit based on the first information and the second information.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A non-transitory computer readable storage medium storing a program that causes a computer to execute a method, the method comprising:<claim-text>controlling, as a first control, an action regarding an imaging unit according to an instruction from a user;</claim-text><claim-text>automatically controlling, as a second control, an action regarding the imaging unit based on a preset condition;</claim-text><claim-text>chronologically recording, as first information, details of control of the action regarding the imaging unit according to the instruction from a user;</claim-text><claim-text>chronologically recording, as second information, details of automatic control of the action regarding the imaging unit based on the preset condition, in association with the first information; and</claim-text><claim-text>playing back chronological details of the control of the action of the imaging unit based on the first information and the second information.</claim-text></claim-text></claim></claims></us-patent-application>
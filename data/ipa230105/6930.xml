<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230006931A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230006931</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17868400</doc-number><date>20220719</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>49</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>24</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>49</main-group><subgroup>9078</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>29</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>24</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>49</main-group><subgroup>9089</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>47</main-group><subgroup>6215</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEM AND METHOD OF A HIGH BUFFERED HIGH BANDWIDTH NETWORK ELEMENT</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16925872</doc-number><date>20200710</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11425041</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17868400</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15187732</doc-number><date>20160620</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10715441</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16925872</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>62214627</doc-number><date>20150904</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Arista Networks, Inc.</orgname><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Sweeney</last-name><first-name>Adam James</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Holbrook</last-name><first-name>Hugh W.</first-name><address><city>Palo Alto</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method and apparatus of a network element that processes a packet in the network element is described. In an exemplary embodiment, the network element receives a data packet that includes a destination address. The network element receives a packet, with a packet switch unit, wherein the packet was received by the network element on an ingress interface. The network element further determines if the packet is to be stored in an external queue. In addition, the network element identifies the external queue for the packet based on one or more characteristics of the packet. The network element additionally forwards the packet to a packet storage unit, wherein the packet storage unit includes storage for the external queue. Furthermore, the network element receives the packet from the packet storage unit and forwards the packet to an egress interface corresponding to the external queue.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="230.12mm" wi="106.93mm" file="US20230006931A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="151.72mm" wi="124.71mm" file="US20230006931A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="168.66mm" wi="155.53mm" file="US20230006931A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="152.06mm" wi="152.15mm" file="US20230006931A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="152.06mm" wi="152.15mm" file="US20230006931A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="232.16mm" wi="151.72mm" file="US20230006931A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="228.43mm" wi="147.07mm" file="US20230006931A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="206.50mm" wi="143.09mm" file="US20230006931A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="228.43mm" wi="142.75mm" file="US20230006931A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="143.09mm" wi="156.29mm" file="US20230006931A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="74.76mm" wi="122.60mm" file="US20230006931A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="102.53mm" wi="121.92mm" file="US20230006931A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="128.44mm" wi="150.03mm" file="US20230006931A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="139.87mm" wi="117.35mm" file="US20230006931A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present disclosure is a continuation of and claims priority to U.S. application Ser. No. 16/925,872, filed Jul. 10, 2020, which is a continuation of U.S. application Ser. No. 15/187,732, filed Jun. 20, 2016, which is now U.S. Pat. No. 10,715,441, which in turn claims priority to U.S. Provisional App. No. 62/214,627 filed Sep. 4, 2015, all of which are incorporated herein by reference for all purposes.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF INVENTION</heading><p id="p-0003" num="0002">This invention relates generally to data networking, and more particularly, to processing data packets using a packet switch unit that determines forwarding decisions for the data packets and a packet storage unit that queues the data packets for transmission.</p><heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0004" num="0003">A network element, such as an Ethernet switch or router, typically operates in &#x201c;store and forward&#x201d; mode. In this mode of operations, the network element receives a packet on some &#x201c;input port&#x201d;, makes a forwarding decision to decide which output port to send the packet to, and then transmits the packet on the output port. For this network element, transmission is not instantaneous, as a packet that is N bits long sent on an interface that can transmit at K bits per second, will take N/K seconds to transmit. As the packet is being processed for transmission, other packets may be queued for transmission using the same output port. The condition where packets are arriving faster than can be transmitted to some output port is referred to as &#x201c;network congestion&#x201d;, or just &#x201c;congestion.&#x201d; Network elements typically store packets in a queue in memory. If more memory is available for packet queuing, then the network element can sustain longer bursts of congestion without dropping one or more packets.</p><p id="p-0005" num="0004">However, many Ethernet network elements are built with small buffers, for cost reasons. Furthermore, a high performance network element is commonly implemented using highly integrated silicon, such as a custom application-specific integrated circuit (ASIC) or field-programmable gate array (FPGA). In such a device, adding large memories can be prohibitively costly for many reasons, such as increasing the die-size of the integrated silicon, adding an increased number of off-chip memory interfaces to off-chip memory, and that the off-chip memory runs at slower speeds than the ASIC or FPGA.</p><heading id="h-0004" level="1">SUMMARY OF THE DESCRIPTION</heading><p id="p-0006" num="0005">A method and apparatus of a network element that processes a packet in the network element is described. In an exemplary embodiment, the network element receives a data packet that includes a destination address. The network element receives a packet, with a packet switch unit, wherein the packet was received by the network element on an ingress interface. The network element further determines if the packet is to be stored in an external queue. In addition, the network element identifies the external queue for the packet based on one or more characteristics of the packet. The network element additionally forwards the packet to a packet storage unit, wherein the packet storage unit includes storage for the external queue. Furthermore, the network element receives the packet from the packet storage unit and forwards the packet to an egress interface corresponding to the external queue.</p><p id="p-0007" num="0006">In another embodiment, the network element receives, with a packet storage unit, a packet from a packet switch unit via an interface coupling the packet storing unit and the packet switch unit, The network element further determines an external queue for the packet, wherein the external queue is associated with the packet storage unit. The network element additionally stores the packet in the external queue. Furthermore, in response to receiving a flow control message indicating packets may be sent from the external queue to the packet switch unit, the network element forwards the packet from the external queue to the packet switch unit.</p><p id="p-0008" num="0007">In a further embodiment, the device includes a plurality of network interfaces that communicate a plurality of packets. The device further includes a data plane coupled to the plurality of network interfaces that processes the plurality of packets. The data plane further includes a plurality of external queues, a packet storage unit, and a packet switch unit. The plurality of external queue stores at least one of the plurality of packets prior to this packet being transmitted by the network element. The packet storage unit is coupled to the plurality of external queues and controls the storing of the at least one of the plurality of packets in the plurality of queues. The packet switch unit is coupled to the packet storage unit and includes a plurality of internal queues, where for each of the plurality of packets, receives that packet from a first network interface of the plurality of network interfaces. In addition, the packet switch unit further determines if that packet is to be stored in one of a plurality of external queues. If the packet is to be stored in the one of the plurality of external queues, the data plane identifies which of the plurality of external queues for that packet based on one or more characteristics of that packet, forwards that packet to the packet storage unit, and receives that packet from the packet storage unit. If the packet is not to be stored in the one of the plurality of external queues, the data plane stores the packet in one of the plurality of internal queues.</p><p id="p-0009" num="0008">Other methods and apparatuses are also described.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings in which like references indicate similar elements.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of one embodiment of a network element that communicates data packets with devices and other network elements.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of one embodiment of a network element that includes a control plane and multiple data planes.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is a block diagram of one embodiment of a switch component that includes a packet switch unit, packet storage unit, and memory.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> is a block diagram of one embodiment of a switch component that includes a packet switch unit and packet storage unit.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is an illustration of one embodiment of a process to queue a packet using a packet storage unit.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flow diagram of one embodiment of a process to perform flow control between a packet switch unit and a packet storage unit.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a flow diagram of one embodiment of a process to store a packet in a packet storage unit.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is a flow diagram of one embodiment of a process to de-queue a packet from a packet storage unit.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram of one embodiment of a queue module that queues a packet using a packet storage unit.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram of one embodiment of a flow control module that performs flow control between a packet switch unit and a packet storage unit.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of one embodiment of a storage queue module that de-queues a packet from a packet storage unit.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates one example of a typical computer system, which may be used in conjunction with the embodiments described herein.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram of one embodiment of an exemplary network element that queues a packet using a packet storage unit.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0024" num="0023">A method and apparatus of a network element that processes a packet in the network element is described. In the following description, numerous specific details are set forth to provide thorough explanation of embodiments of the present invention. It will be apparent, however, to one skilled in the art, that embodiments of the present invention may be practiced without these specific details. In other instances, well-known components, structures, and techniques have not been shown in detail in order not to obscure the understanding of this description.</p><p id="p-0025" num="0024">Reference in the specification to &#x201c;one embodiment&#x201d; or &#x201c;an embodiment&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase &#x201c;in one embodiment&#x201d; in various places in the specification do not necessarily all refer to the same embodiment.</p><p id="p-0026" num="0025">In the following description and claims, the terms &#x201c;coupled&#x201d; and &#x201c;connected,&#x201d; along with their derivatives, may be used. It should be understood that these terms are not intended as synonyms for each other. &#x201c;Coupled&#x201d; is used to indicate that two or more elements, which may or may not be in direct physical or electrical contact with each other, co-operate or interact with each other. &#x201c;Connected&#x201d; is used to indicate the establishment of communication between two or more elements that are coupled with each other.</p><p id="p-0027" num="0026">The processes depicted in the figures that follow, are performed by processing logic that comprises hardware (e.g., circuitry, dedicated logic, etc.), software (such as is run on a general-purpose computer system or a dedicated machine), or a combination of both. Although the processes are described below in terms of some sequential operations, it should be appreciated that some of the operations described may be performed in different order. Moreover, some operations may be performed in parallel rather than sequentially.</p><p id="p-0028" num="0027">The terms &#x201c;server,&#x201d; &#x201c;client,&#x201d; and &#x201c;device&#x201d; are intended to refer generally to data processing systems rather than specifically to a particular form factor for the server, client, and/or device.</p><p id="p-0029" num="0028">A method and apparatus of a network element that processes a packet in the network element is described. In one embodiment, the buffering needs of a network element may not be symmetric on all ports. For example and in one embodiment, one or more of the ports may be coupled to device(s) that generate or receive high levels of packets, while other ports are coupled to device(s) that may generate low levels of packets. Thus, in some cases, most of the congestion in a network element occurs from packets destined for (or arriving on) a subset of the switch ports, and this observation allows for a better solution to the &#x201c;buffering problem&#x201d; than prior alternatives.</p><p id="p-0030" num="0029">In one embodiment, the network element includes a small buffered packet switch unit with n pin interfaces that is combined with a large-buffered packet storage unit to produce a &#x201c;partially large-buffered&#x201d; device with n&#x2212;m externally-visible pin interfaces, where in of the pin interfaces are designated as &#x201c;externally-queued&#x201d; (EQ) interfaces with associated large buffers. In this embodiment, any packet arriving on one of in EQ interfaces is directed to packet storage unit <b>304</b> for queuing in the larger buffers associated with the packet storage unit. While in one embodiment, the large buffers associated with the packet storage unit are in one or more memory chips that are coupled to the packet storage unit, in alternate embodiments, the buffers are on the packet storage unit.</p><p id="p-0031" num="0030">In this network element, a packet received on one of the EQ pin interfaces and destined for interface J, queue Q remains queued in the memory of packet storage unit until a flow control channel from the packet switch unit to the packet storage unit indicates to the packet storage unit that the packet switch unit has room for a packet to interface J and queue Q. If more than one queue on the packet storage unit is associated with one queue on the packet switch unit, then the packet storage unit uses a scheduling and prioritization mechanisms to decide which packet to send to the packet switch unit. In one embodiment, the packet switch unit uses a flow control channel to indicate to the packet storage unit when the packet storage unit should transmit a packet to the packet switch unit. The flow control channel is used such that the packet switch unit does not drop any packets. In one embodiment, the flow control information may be carried over a special dedicated connection from packet switch unit and packet storage unit &#x201c;out-of-band&#x201d;, or flow control information may be carried &#x201c;in-band&#x201d; using one or more of the m pin interfaces that connect packet switch unit and packet storage unit. In one embodiment, this type of flow control is called an internal flow control as the internal flow control is used to control packet transmission between the packet switch unit and the packet storage unit.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of one embodiment of a network element <b>102</b> that communicates data packets with devices <b>106</b>A-D and/or other network elements <b>104</b>A-E. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the system <b>100</b> includes the network element <b>102</b> that is coupled with network elements <b>104</b>A-E and/or devices <b>106</b>A-D. In one embodiment, each of the network element <b>102</b> and network elements <b>104</b>A-E can be a switch, router, hub, bridge, gateway, etc., or any type of device that can communicate data packets with a network. In one embodiment, any one of the network elements <b>102</b> or <b>104</b>A-E can be a virtual machine. In one embodiment, the device <b>106</b>A-D is any type of device that can communicate network data with another device (e.g., a personal computer, laptop, server, mobile device (e.g., phone, smartphone, personal gaming device, etc.), another network element, etc.). In one embodiment, the devices <b>106</b>A-D can be a virtual machine or can be a device that hosts one or more virtual machines. While in one embodiment, network element <b>102</b> is coupled to five network elements and four devices, in alternate embodiments, the network elements can be coupled to a different mix of other network elements and/or devices (e.g., more or less network elements, more or less devices, only network elements, only devices, and/or another types of combination of network elements and/or devices).</p><p id="p-0033" num="0032">A network element, such as an Ethernet switch, router, or network element <b>102</b>, typically operates in &#x201c;store and forward&#x201d; mode. In this mode of operations, the network element receives a packet on an input port, makes a forwarding decision to decide which output port to send it to, and then transmits it on the output port. Transmission is not instantaneous as a packet that is N bits long sent on an interface that can transmit at K bits per second, will take N/K seconds to transmit. While a packet P<b>1</b> is being transmitted to interface I, if a second packet P<b>2</b> is also forwarded to I, per the network element's <b>102</b> forwarding decision, the second packet is queued, or &#x201c;buffered&#x201d;, for later transmission (after P<b>1</b> is done being transmitted). The condition where packets are arriving faster than they can be transmitted to some output port is referred to as &#x201c;network congestion&#x201d;, or just &#x201c;congestion.&#x201d; Network elements typically store packets in some sort of queue in memory. If more memory is available for packet queuing, then the switch can sustain longer bursts of congestion without dropping traffic.</p><p id="p-0034" num="0033">In one embodiment, Ethernet network elements with larger packet buffers perform better in situations of network congestion than switches with smaller packet buffers. This increased buffering allows a switch to absorb rather than drop more packets, avoiding costly transmission control protocol (TCP) timeouts and retransmissions. Thus, larger buffers improve fairness when multiple TCP flows are contending for limited bandwidth on a single link.</p><p id="p-0035" num="0034">Many Ethernet network elements, however, are built with small buffers for cost reasons. A high performance network element can be implemented using highly integrated silicon, such as a custom ASIC or FPGA. In such a device, adding large memories can be prohibitively costly for many reasons. For example, adding sufficient on-chip memory to improve performance increases the die size of the integrated silicon, which can substantially increase cost. Second, adding off-chip memory requires external interfaces. In the most demanding case of N interfaces all sending packets to one interface, a network element stores (N&#x2212;1)/N of the incoming packets in memory for a period of time. This requirement effectively doubles the external interface speed of a device, which also increases the cost. Third, commonly-available external memory technology is based on a parallel bus in which each &#x201c;pin&#x201d; runs at a slower speed than the interfaces on which the packets arrive. Thus, even more pins need to be devoted to external memory, which further increases the device cost. Accordingly, it is desirable to advance the state of the art by creating a network element that can store packets in memory when needed, without requiring either a large internal memory, or high-bandwidth external memory interfaces.</p><p id="p-0036" num="0035">Furthermore, not all of the network element <b>102</b> ports would experience congestion or the same amount of congestion. For example and in one embodiment, if network element <b>104</b>E is transmitting packets for network element <b>104</b>B via network element <b>102</b> at a data rate of 8 gigabits/sec (Gbps), where the link between network elements <b>102</b> and <b>104</b>B is 10 Gbps, and, in addition, the devices <b>106</b>A-D are each bursting packets at a rate 1 Gbps to network <b>104</b>B, there is congestion for the link between network elements <b>102</b> and <b>104</b>B. In this example, a larger queue to store the packets from the devices <b>106</b>A-D and/or network element <b>104</b>E being transmitted reduces the likelihood that some of these packets being transmitted will be dropped.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of one embodiment of a network element <b>200</b> that includes a control plane <b>204</b> and a data plane <b>202</b>. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the network element <b>200</b> includes a data plane <b>102</b> and a control plane <b>104</b>. In one embodiment, the data plane <b>202</b> receives, processes, and forwards network data using various configuration data (e.g. packet forwarding (routing, switching, or another type of packet forwarding), security, quality of service (QoS), and other network traffic processing information). For example, for each received packet of the network traffic, the data plane determines a destination address of that packet, looks up the requisite information for that destination in one or more tables stored in the data plane, and forwards the packet out the proper outgoing interface. The data plane <b>202</b> includes multiple switches <b>206</b>A-C that can each receives, process, and/or forward network traffic. In one embodiment, each switch <b>206</b>A-C includes a packet switch unit <b>210</b>A-C, packet storage unit <b>212</b>A-C and ports <b>214</b>A-C, respectively. As will be described further below, the packet switch unit <b>210</b>A-C is a chip that is used to make processing decisions for each packet received by the corresponding switch <b>206</b>A-C and the packet storage unit <b>212</b>A-C is used to queue packets received on interfaces that are configured for external queuing.</p><p id="p-0038" num="0037">In one embodiment, the control plane <b>204</b> gathers the configuration data from different sources (e.g., locally stored configuration data, via a command line interface, or other management channel (e.g., SNMP, Simple Object Access Protocol (SOAP), Representational State Transfer type Application Programming Interface (RESTful API), Hypertext Transfer Protocol (HTTP), HTTP over Secure Sockets layer (HTTPs), Network Configuration Protocol (NetConf), Secure Shell (SSH), and/or another management protocol) and writes this configuration data to one or more tables.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> is a block diagram of one embodiment of a switch component <b>300</b> of a data plane that includes a packet switch unit <b>302</b>, packet storage unit <b>304</b>, and memory <b>306</b>. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the switch component <b>300</b> includes the packet switch unit <b>302</b> coupled to the packet storage unit <b>304</b> via the packet switch unit-packet storage unit interfaces (PSU-PStU) <b>312</b>. In one embodiment, the PSU-PStU interface can be an Ethernet interface or a type of non-Ethernet interface (e.g., cellular fabric, packetized link, Infiniband, or another type of interface whether proprietary or non-proprietary). The packet storage unit <b>304</b> is further coupled to memory <b>306</b> via packet storage unit-memory interfaces (PStU-Mem) <b>314</b>. In one embodiment, the packet switch unit <b>302</b> includes n pin interfaces that couple the packet switch unit <b>302</b> to ports <b>308</b> and the packet storage unit <b>304</b>. In one embodiment, a pin interface is an interface on either the packet switch unit <b>302</b> or packet storage unit <b>304</b> that couples that chip to another component of the network element and communicates a packet through that interface. For example and in one embodiment, a pin interface of the packet switch unit <b>302</b> can be an interface coupling the packet switch unit <b>302</b> with the packet storage unit <b>304</b>, in which this interface is used to transfer packets between the two chips. In another example, a pin interface of the packet switch unit <b>302</b> can be an interface coupling the packet switch unit <b>302</b> to a network interface or port of the network element. In this example, the packet switch unit <b>302</b> can communicate packets with a port via this pin interface. While in one embodiment, each of the packet switch unit <b>302</b>, packet storage unit <b>304</b>, and memory <b>306</b> are illustrated as one chip, in alternate embodiments, each of the packet switch unit <b>302</b>, packet storage unit <b>304</b>, and memory <b>306</b> can be more that one chip. For example and in one embodiment, the memory <b>306</b> can include multiple memory chips that are used for the external queues.</p><p id="p-0040" num="0039">The packet switch unit <b>302</b> further includes internal queues <b>318</b> that are used to queue packets prior to the packets being forwarded to a port that is part of the switching component or another port in the network element. The packet switch unit <b>302</b> also includes a queue module <b>320</b> that manages the decision to store the packet in an internal or external queue. In one embodiment, the packet storage unit <b>304</b> includes switch circuitry <b>322</b> to process the packet and storage queue module <b>324</b> to manage the de-queuing of externally stored packets stored in an external queue.</p><p id="p-0041" num="0040">In one embodiment, the buffering needs of a network element are not symmetric on all ports. For example and in one embodiment, one or more of the ports may be coupled to device(s) that generate or receives high levels of packets, while other ports are coupled to device(s) that may generate low levels of packets. Thus, in some cases, most of the congestion in a network element occurs from packets arriving on a subset of the switch ports, and this observation allows for a solution to handle congestion on the ports that exhibit the congestion.</p><p id="p-0042" num="0041">In one embodiment, the small buffered packet switch unit <b>302</b> with n pin interfaces is combined with the packet storage unit <b>304</b> to produce a &#x201c;partially large-buffered&#x201d; device with n-m externally-visible pin interfaces, where m of the pin interfaces are designated as &#x201c;externally-queued&#x201d; (EQ) interfaces with associated large buffers. In this embodiment, any packet arriving on one of m EQ interfaces is directed to packet storage unit <b>304</b> for queuing in the larger memory associated with the packet storage unit <b>304</b>. In another embodiment, the memory is not external and instead exists inside the packet storage unit, as described in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> below.</p><p id="p-0043" num="0042">As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, and in one embodiment, the packet switch unit <b>302</b> is coupled to the packet storage unit <b>304</b> via the m pin interfaces (PSU-PStU interface <b>312</b>). In addition, m of the externally-visible pin interfaces on packet switch unit <b>302</b> (EQ interfaces <b>310</b>A) are designated as &#x201c;externally-queued&#x201d; (EQ) interfaces. Furthermore, the packet switch unit <b>302</b> includes n&#x2212;2m externally visible pin interfaces that are designated non-EQ interfaces (<b>310</b>B). The packet switch unit <b>302</b> further includes a &#x201c;flow control&#x201d; connection <b>316</b> from the packet switch unit <b>302</b> to packet storage unit <b>304</b>. In one embodiment, the flow control connection <b>316</b> is employed to allow packet switch unit <b>302</b> to tell packet storage unit <b>304</b> when to send externally queued packets to the packet switch unit <b>302</b>.</p><p id="p-0044" num="0043">A packet arriving on an EQ interface is not subject to the normal forwarding rules of the network device. Instead, a packet arriving on an EQ interface I<sub>k </sub>whose forwarding decision is to send this packet to queue Q on network interface J, is NOT sent to interface J, but rather to the packet storage unit <b>304</b> by way of interface I<sub>(n-m+k)</sub>, with an indication of the forwarding result (interface J, queue Q). In one embodiment, each EQ pin interface on the packet switch unit <b>302</b> has an associated storage pin interface (e.g., one of the pin interfaces from PSU-PStU interfaces <b>312</b>) between packet switch unit <b>302</b> and packet storage unit <b>304</b> with equivalent bandwidth to that EQ pin interface. In this embodiment, having the same bandwidth on the EQ pin interface and the storage pin interface, the chance of congestion is reduced or eliminated on the link from packet switch unit <b>302</b> to packet storage unit <b>304</b>. Thus, in this embodiment, no queue ever accumulates too many packets in packet switch unit <b>302</b> on any of the interfaces that connect to packet storage unit <b>304</b>. In one embodiment, there are multiple ways to achieve this property. For example and in one embodiment, by having a smaller number of higher-speed storage pin interfaces between packet switch unit <b>302</b> and packet storage unit <b>304</b> and mapping each of EQ pin interfaces to one of these higher-speed storage pin interfaces, reduces or eliminates the change of congestion between packet switch unit <b>302</b> and packet storage unit <b>304</b>.</p><p id="p-0045" num="0044">In one embodiment, the communication of the forwarding decision from packet switch unit <b>302</b> to packet storage unit <b>304</b> may be done in multiple ways:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0045">A special-purpose packet header that carries the final interface and queue.</li>        <li id="ul0002-0002" num="0046">An 802.1q Virtual Local Area Network (VLAN) tag to identify the final interface and queue.</li>        <li id="ul0002-0003" num="0047">A Multiprotocol Label Switching (MPLS) header to identify the final interface and queue.</li>        <li id="ul0002-0004" num="0048">The final destination can be implied from the network header of the packet sent from packet switch unit <b>302</b> to packet storage unit <b>304</b>. The actual destination port and queue would be derived by a lookup in packet storage unit <b>304</b>. For instance, if the combined device is acting as an Internet Protocol (IP) router operating on Ethernet packets, the Ethernet destination address of the packet switch unit <b>302</b>-to-packet storage unit <b>304</b> packet could be rewritten by packet switch unit <b>302</b>, and then this address could be retrieved from the packet and looked up by packet storage unit <b>304</b> to determine the ultimate port and queue.</li>        <li id="ul0002-0005" num="0049">A combination of the above techniques may be used. For instance, the Ethernet destination address may be used to derive the ultimate interface, and an identifier for the queue on that interface may be explicitly carried in the packet header, such as the Priority Code Point field of the IEEE 802.1q Ethernet header.</li>    </ul>    </li></ul></p><p id="p-0046" num="0050">In an alternative embodiment, packets arriving on EQ pin interfaces I<sub>1 </sub>to I<sub>m </sub>(<b>310</b>A) have no forwarding decisions or lookups made in packet switch unit <b>302</b>. Instead, the packet is sent to the packet storage unit <b>304</b> by way of the associated interface, and the packet storage unit <b>304</b> makes the forwarding and queuing decisions for this packet.</p><heading id="h-0007" level="2">Queuing on the Packet Storage Unit</heading><p id="p-0047" num="0051">The packet storage unit <b>304</b>, in one embodiment, has the ability to receive and queue packets, and to schedule packets for transmission and de-queue them and send them over the packet storage unit <b>304</b>-to-packet switch unit <b>302</b> link. In this embodiment, packet storage unit <b>304</b> is a commercially available general purpose Ethernet switch module with queuing and scheduling capability that includes one or more chips. This embodiment leverages the favorable economics associated with commonly available off-the-shelf silicon. In another embodiment, the packet storage unit <b>304</b> is a dedicated queuing chip with limited or no forwarding or lookup tables but only the queuing functionality. This implementation leverages the favorable economics associated with the limited functionality. By eliminating the ternary content-addressable memories (TCAMs), memories, and/or tables needed to perform a full routing or switching lookup, significant cost savings may be achieved for the packet storage unit <b>304</b>. Moreover, further savings accrue in this embodiment because packet storage unit <b>304</b> can have significantly fewer external pin interfaces than packet switch unit <b>302</b>. For example and in one embodiment, the packet storage unit <b>304</b> has m pin interface whereas packet switch unit <b>302</b> has n=2m+k, where k is the number of non-EQ pin interfaces on packet switch unit <b>302</b>.</p><p id="p-0048" num="0052">In one embodiment, there maybe multiple external queues associated with the packet storage unit <b>304</b> and/or multiple internal queues on the packet switch unit <b>302</b> that are associated with one pin interface. For example and in one embodiment, a particular network interface J is coupled to a pin interface J&#x2032; on the packet switch unit and the network interface J is an EQ interface. Thus, packets received on network interface J interface are sent to the packet storage unit <b>304</b> to be queued in an external queue for the egress interface for this packet. In this example, there are 8 external queues for the egress interface, so the packet is queued in one of these queues. Which external queue to use is based on the queuing decision made for the packet. Furthermore, each of these external queues is associated with a corresponding internal queue on the packet switch unit <b>302</b>. In one embodiment, each of the external and internal queues is a virtual output queue, where a virtual output queue is a queue that is used for each possible output location.</p><p id="p-0049" num="0053">In another embodiment, the forwarding lookup and queuing decision is made by a combination of lookups in the packet switch unit <b>302</b> and the packet storage unit <b>304</b>. For example and in one embodiment, input filtering and a forwarding lookup may be done in the packet switch unit <b>302</b>, whereas determining the output queue on the egress network interface is decided by a lookup in the packet storage unit <b>304</b>. Other processing combinations for the packet switch unit <b>302</b> and the packet storage unit <b>304</b> are possible as well. By splitting the lookups and/or other processing of a packet across the packet switch unit <b>302</b> and the packet storage unit <b>304</b>, the packet processing can take advantage of the unique capabilities of each chip. For example and in one embodiment, the packet processing can be done in the packet switch unit <b>302</b>, if the packet switch unit <b>302</b> has larger lookup tables or is more capable than packet storage unit <b>304</b>.</p><p id="p-0050" num="0054">In one embodiment, each of the packet switch unit <b>302</b> and the packet storage unit <b>304</b> maintains a set of queues for each of the n-rn external pin interfaces on the packet switch unit <b>302</b>. In this embodiment, the packet storage unit <b>304</b> has at least one queue associated with each queue in the packet switch unit <b>302</b>. In another embodiment, each queue in packet storage unit <b>304</b> is associated with only one queue in packet switch unit <b>302</b>.</p><p id="p-0051" num="0055">In one embodiment, any packet arriving at packet storage unit <b>304</b> from packet switch unit <b>302</b> is queued into the appropriate queue on packet storage unit <b>304</b>, as determined by the forwarding result sent from packet switch unit <b>302</b> to packet storage unit <b>304</b>. In another embodiment, packet storage unit <b>304</b> can determine the appropriate queue to use for a packet based on the packet characteristics. In this embodiment, the packet storage unit <b>304</b> can make some or all of the queuing decisions for packets that are queued in the packet storage unit <b>304</b> instead or in conjunction with the packet switch unit <b>302</b>. This can be used if the packet switch unit <b>302</b> does not have the full information regarding the queuing structure of the queues for packet storage unit <b>304</b> or to save bandwidth between the packet switch unit <b>302</b> and the packet storage unit <b>304</b>.</p><p id="p-0052" num="0056">In one embodiment, the packet storage unit <b>304</b> can further perform queue shaping and queue scheduling on the packets stored in the external queues controlled by the packet storage unit <b>304</b>. Queue shaping is a mechanism for rate limiting the rate at which data can flow through a queue. It allows network element to configure limits on the maximum bit rate at which data is dequeued from the queue. Typically, this will be less than the speed at which the interface the queue serves can actually transmit data. Queue shaping can be used to put controls on the rate of high priority traffic or to limit the data rate to something agreed on with the &#x201c;customer&#x201d; at the other end. For example and in one embodiment, one customer might have a physical connection that can run at 100 Mbps, but the customer has only paid for 10 Mbps service, so the network element shape the queue for traffic going to the customer to a maximum of 10 Mbps.</p><p id="p-0053" num="0057">In another embodiment, queue scheduling is the means by which the network element decides which queue to draw the next packet from when there is more than one queue serving a given interface. In the simplest case, there are two queues serving an interface, and the network element decides which queue to pull a packet from next. One common scheme for queue scheduling is Strict Priority (SP), where each queue gets a priority, and the queue with the highest priority that actually has a packet is always served first. Another is Weighted Round Robin (WRR), where the queues are served in turn, but the amount served from each queue each turn is controlled by a weight value assigned to the queue. This allows the network element to assign 75% of the throughput to the highest priority queue and 25% to the lower priority queue. Furthermore, there are many variations of WRR, such as Deficit Round Robin, Deficit Weighted Round Robin, Weighted Fair Queuing, Min Bandwidth and/or any other variant of WRR. Alternatively, the network element can use another type of queue scheduling.</p><p id="p-0054" num="0058">In one embodiment, the packet store chip <b>304</b> uses one or more of the types of queue shaping and/or queue scheduling described above to determine which of the packets stored in the external queues. In this embodiment, when the flow control between the packet switch unit <b>302</b> and the packet store chip <b>304</b> indicates that packets can be sent to the packet switch unit <b>302</b> for a certain queue or interface associated to the packet switch unit <b>302</b>, the packet store chip <b>304</b> can perform the queue shaping and/or queue scheduling to determine which of the externally queued packets are transmitted to the packet switch unit <b>302</b>. For example and in one embodiment, consider the arrangement if there is one internal queue for an interface on the packet switch unit <b>302</b> and there are multiple external queues on the packet storage unit <b>304</b> for this interface. In this example, when the flow control indicates that packets can be sent to the internal queue (e.g., packet storage unit <b>304</b> receives an XON message indicating the internal queue for the interface is ready to receive packets from the packet storage unit <b>304</b>), the packet storage unit <b>304</b> uses the shaping and/or queue scheduling to determine which of the externally queued packets in these four external queues to transmit to the packet switch unit <b>302</b>. As another example, the four external queues could correspond to different QoS levels, with one or more of the external queues corresponding to higher priority queue(s) and one or more of the external queues corresponding to lower priority queue(s).</p><p id="p-0055" num="0059">In a further example, there are can be more than one internal queue for an interface and multiple external queues also for that interface. In this example, the packet storage unit <b>304</b> performs queue shaping and/or queue scheduling to determine which of the externally queued packets are transmitted to the packet switch unit <b>302</b> and the packets switch unit <b>302</b> can perform the same or different queue shaping and/or queue scheduling to determine which of the internally queued packets are transmitted out the interface.</p><heading id="h-0008" level="2">Flow Control Between the Packet Switch Unit and the Switch Storage Ship</heading><p id="p-0056" num="0060">A packet destined for network interface J, queue Q remains queued in the memory of packet storage unit <b>304</b> until the flow control channel from the packet switch unit <b>302</b> to the packet storage unit <b>304</b> indicates to the packet storage unit <b>304</b> that the packet switch unit <b>302</b> has room for a packet to network interface J and queue Q. In one embodiment, the flow control channel indicates when packets can be transmitted from the packet storage unit <b>304</b> to the packet switch unit <b>302</b>. In one embodiment, the flow control channel can be used to send flow control message between the packet switch unit <b>302</b> and the packet storage <b>304</b>. In another embodiment, the flow control channel can be another mechanism for communicating flow control information between the packet switch unit <b>302</b> and the packet storage <b>304</b>. In one embodiment, the flow control channel is Ethernet based. If more than one queue on the packet storage unit <b>304</b> is associated with one queue on the packet switch unit <b>302</b>, then the packet storage unit <b>304</b> can use scheduling and prioritization mechanisms to decide which packet to send to the packet switch unit <b>302</b>. In one embodiment, the packet switch unit <b>302</b> uses a flow control channel to indicate to the packet storage unit <b>304</b> when the packet storage unit <b>304</b> should transmit a packet to the packet switch unit <b>302</b>. The flow control channel ideally ensures that the packet switch unit <b>302</b> does not drop any packets. In one embodiment, the flow control information may be carried over a special dedicated connection from packet switch unit <b>302</b> and packet storage unit <b>304</b> (e.g., flow control <b>316</b>) &#x201c;out-of-band&#x201d;, or flow control information may be carried &#x201c;in-band&#x201d; using one or more of the m pin interfaces that connect packet switch unit <b>302</b> and packet storage unit <b>304</b>.</p><p id="p-0057" num="0061">In these embodiments, the packet switch unit <b>302</b> uses the flow control channel to indicate to the packet storage unit <b>304</b> that the packet storage unit <b>304</b> can send a packet that will not be dropped by the packet switch unit <b>302</b>. In one embodiment, the flow control channel uses a stateful XON/XOFF protocol between packet switch unit <b>302</b> and packet storage unit <b>304</b>. In this embodiment, the packet switch unit <b>302</b> sends an XON message for internal queue Q when packet switch unit <b>302</b>'s internal queue Q is below a &#x201c;low watermark&#x201d;, and packet switch unit <b>302</b> sends an XOFF for internal queue Q when packet switch unit <b>302</b>'s internal queue Q is above a &#x201c;high watermark.&#x201d; If the flow control channel is &#x201c;in-band&#x201d; for XON/XOFF messages supporting multiple queues, the XON/XOFF messages indicating the state of multiple queues can be sent in a single packet from packet storage unit <b>304</b> to packet switch unit <b>302</b> to improve efficiency and/or reduce latency of the flow control messages. In one embodiment, the flow control messages may be prioritized over regular traffic to ensure that they are delivered with minimal latency.</p><p id="p-0058" num="0062">The flow control technique, in one embodiment, has two properties: (1) the XOFF message for internal queue Q on the packet switch unit <b>302</b> is to be processed by packet storage unit <b>304</b> before Q on packet switch unit <b>302</b> overflows (including any packets in flight from packet storage unit <b>304</b> to packet switch unit <b>302</b>), and (II) the XON message for Q is to be processed by packet storage unit <b>304</b> before Q goes empty on packet switch unit <b>302</b>. The former property ensures that no packets are sent by packet switch unit <b>302</b> that are then dropped on packet switch unit <b>302</b> due to congestion in the outgoing queues. The latter property ensures that the path from packet storage unit <b>304</b> to packet switch unit <b>302</b> allows for the queue on the packet switch unit <b>302</b> does not go empty if there are packets for this queue in the packet storage unit <b>304</b>. In this embodiment, these properties determine when a XON or XOFF message is sent by the packet switch unit <b>302</b> to the packet storage unit <b>304</b> for a queue on the packet switch unit <b>302</b>.</p><p id="p-0059" num="0063">In one embodiment, the flow control information is &#x201c;piggybacked&#x201d; on regular packets sent from packet switch unit <b>302</b> to packet storage unit <b>304</b> by encoding the XON/XOFF state in additional headers appended by packet switch unit <b>302</b>. For example and in one embodiment, consider a device with 16 EQ network interfaces operating at 100 gigabits per second, and 96 non-EQ network interfaces, and 8 queues per network interface. With 4 pin interfaces connecting packet switch unit <b>302</b> and packet storage unit <b>304</b>, there are at least 33.333 million packets per second from packet switch unit <b>302</b> to packet storage unit <b>304</b>, assuming 1500 byte packets, a common packet size in the Internet. If 72 bits are added to each packet to communicate the XON/XOFF flow control state for EQ interfaces 8-15, then the XON/XOFF state of all 8 queues of EQ interfaces 8-15 could be communicated in one packet header, encoded as follows.</p><p id="p-0060" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="1" colwidth="28pt" align="center"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="49pt" align="center"/><colspec colname="4" colwidth="42pt" align="center"/><colspec colname="5" colwidth="21pt" align="center"/><colspec colname="6" colwidth="42pt" align="center"/><thead><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row><row><entry>(Byte) 0</entry><entry>1</entry><entry>2</entry><entry>3</entry><entry/><entry>8</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>IID</entry><entry>xoff-IID</entry><entry>xoff-IID + 1</entry><entry>xoff-IID + 2</entry><entry>. . .</entry><entry>xoff-IID + 7</entry></row><row><entry>8</entry><entry>00001000</entry><entry>00000001</entry><entry>00000000</entry><entry>. . .</entry><entry>11110001</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row></tbody></tgroup></table></tables><br/>where IID is the interface ID of the first XOFF information.</p><p id="p-0061" num="0064">In another embodiment, there is a separate link dedicated to flow control (e.g., flow control <b>316</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>). In one embodiment, this dedicated link carries the flow control in the body of continuously sent Ethernet packets. For example and in one embodiment and referring to the example described above with 100 externally visible ports and eight queues per port, each packet might contain 800 bits (100 bytes) of flow control status. With the dedicated link for flow control information that operates at the same speed as each of four packet switch unit <b>302</b>-to-packet storage unit <b>304</b> links, a queue that crosses its high watermark and immediately sends an XOFF message at the next opportunity could receive additional packets corresponding to data in-flight from the packet storage unit <b>304</b> before an XOFF message was received and processed by packet storage unit <b>304</b>. The potential number of additional packets determines the amount of buffering above the high watermark that packet switch unit <b>302</b> has in order to not drop traffic from packet storage unit <b>304</b>.</p><p id="p-0062" num="0065">In another embodiment, the flow control link need not operate at the same speed as the packet switch unit <b>302</b>-to-packet storage unit <b>304</b> links. Furthermore, the flow control link need not use the same encapsulation format or link-layer encoding. In an Ethernet switch, however, it may be useful to communicate the flow control information over Ethernet in order to leverage the existing communication technology used on the other links.</p><p id="p-0063" num="0066">In another embodiment, switch component <b>300</b> can operate without a dedicated flow control channel if the traffic from the packet storage unit <b>304</b> to the packet switch unit <b>302</b> for any interface I is shaped to an aggregate rate that is lower than the transmission rate of interface I on the packet switch unit <b>302</b>. This embodiment may work well in the absence of &#x201c;East-West&#x201d; traffic between the non-EQ ports. If the aggregate rate of traffic from packet switch unit <b>302</b> to packet storage unit <b>304</b> is not exceeded, then the primary queuing for the non-EQ interfaces happens in packet storage unit <b>304</b> and the non-EQ interfaces will behave as in a large buffered switch.</p><p id="p-0064" num="0067">In a further embodiment, a 802.3x flow control (commonly referred to as &#x201c;PAUSE&#x201d;) or Priority Flow Control &#x201c;PFC&#x201d; can be enabled on the non-EQ externally-visible links to prevent them from overrunning their output buffers on the packet switch unit <b>302</b>. This effectively pushes the buffering of packets received by those ports back to the neighboring devices, rather than consuming buffers on packet switch unit <b>302</b>. In situations where the neighboring devices are end stations, this technique is especially effective, because end stations tend to be able to buffer large amounts of data. In one embodiment, this type of flow control is called an external flow control as the external flow control is used to control packet transmission between the packet switch unit or network element and one or more devices coupled to an external facing interface. In this embodiment, external flow control is different than the internal flow control described above that is used between the packet switch unit and packet storage unit. The external flow control is between the network element and one or more devices coupled to the network element.</p><p id="p-0065" num="0068">Using flow control on the uplink ports (e.g., I<sub>1 </sub>to I<sub>m</sub>, EQ pin interfaces <b>310</b>A), however, is not desirable because it &#x201c;spreads&#x201d; the congestion on the edge switch to the neighboring switch, which can result in head-of-line blocking (HOLB), which is an undesirable condition for a network element in a network. However, end station connected ports do not suffer from the HOLB problem, and so 802.3x flow control can be an effective solution for buffering of packets from directly-connected end stations.</p><p id="p-0066" num="0069">In another embodiment, 802.3x link level, 802.1Qbb flow control mechanisms, 802.1Q-2011/802.1qau flow control or another type of flow control mechanism can be used manage a flow of packets between the packet switch unit <b>302</b> and packet storage unit <b>304</b>. For example and in one embodiment, a limited number of uplink network interfaces on a network element use external queuing, while the remainder of the network interfaces are internally queued. For the internally queued network interfaces, the network element uses external flow control mechanisms such as 802.3x flow control or 802.1Qbb Priority Flow Control on them. These internally queued network interfaces use flow control across the network interface to get the device coupled on these interfaces to stop sending us traffic when the internal queues or buffers are filling up. Using flow control to push the buffering back into this device (e.g., and end station) is generally fine. However, using flow control on uplinks into a network can have bad side effects relating to spreading congestion into the rest of the network. For the uplinks, the network element can use the external queues, which do not suffer from these side effects.</p><p id="p-0067" num="0070"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> is a block diagram of one embodiment of a switch component <b>350</b> that includes a packet switch unit and packet storage unit. In <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, the switch component <b>350</b> includes the packet switch unit <b>352</b> coupled to the packet storage unit <b>354</b> via the packet switch unit-packet storage unit interfaces <b>362</b>. In one embodiment, the switch component <b>350</b> is similar to switch component <b>300</b> of <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, except that the external queues <b>376</b> are on the packet storage unit <b>354</b> instead in the memory chip. In one embodiment, the packet switch unit <b>352</b> includes n pin interfaces that couple the packet switch unit <b>352</b> to ports <b>358</b> (EQ interfaces <b>360</b>A and non-EQ interfaces <b>360</b>B) and the packet storage unit <b>354</b> (PSU-PStU interface <b>362</b>). The packet switch unit <b>352</b> further includes internal queues <b>368</b> that are used to queue packets prior to the packets being forwarded to a network interface and a queue module <b>370</b> manages the decision to store the packet in an internal or external queue. In one embodiment, the packet storage unit <b>354</b> includes switch circuitry <b>372</b> to process the packet and storage queue module <b>374</b> to manage the de-queuing of externally stored packets stored in an external queue.</p><p id="p-0068" num="0071"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is an illustration of one embodiment of a process <b>400</b> to queue a packet using a packet storage unit. In one embodiment, process <b>400</b> is performed by a queue module to queue a packet using a packet storage unit, such as the queue module <b>320</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> or queue module <b>370</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, process <b>400</b> begins by receiving a packet on an ingress interface at block <b>402</b>. In one embodiment, the packet can be layer 2 packet, layer 3 packet, or another type of packet used to communicate data across a network. For example and in one embodiment, the packet includes a header and a payload, where the header includes source and destination addresses. In one embodiment, the ingress interface is the network interface used by the network element to receive the packet from the network. At block <b>404</b>, process <b>400</b> determines if the ingress interface is associated with an EQ pin interface. In one embodiment, an EQ pin interface is an interface that has been configured to have packets received from this interface to be queued in an external queue before these packets are transmitted via an egress interface. In one embodiment, process <b>400</b> determines if the ingress interface is an EQ pin interface by determining whether the ingress interface has been configured to be an EQ pin interface. In this embodiment, a network element may have some interfaces configured as EQ interface(s) (e.g., EQ interfaces <b>310</b>A) and other interfaces as internal queuing interface(s) (e.g., non-EQ interfaces <b>310</b>B). For example and in one embodiment, interfaces that couple to high-bandwidth sources or sources that are network services that are sensitive to dropped packets (e.g., a video server, data storage traffic (e.g., Internet Small Computer System Interface (iSCSI) or Fibre Channel over Ethernet (FCoE) packets) may be configured as EQ pin interfaces. Alternatively, an EQ pin interface can be configured for high speed uplinks. For example and in one embodiment, high speed uplinks into the rest of the network, that have to rate convert to lower speed links connected to end stations, are especially appropriate for EQ pin interfaces. For example, if the data comes in on the uplink at 100 Gbps but goes to the server at 10 Gbps, the network element have to buffer the traffic to allow for the rate conversion. If the ingress interface is not an external queuing interface, at block <b>406</b>, process <b>400</b> processes the packet normally.</p><p id="p-0069" num="0072">In one embodiment, process <b>400</b> uses the external queuing designation for the ingress interface so as to determine which of the packets process <b>400</b> is processing are to be externally queued. In another embodiment, process <b>400</b> may use a different determination as to whether to externally queue the packets. For example and in one embodiment, process <b>400</b> may determine a packet is to be externally queued based on the packet characteristics of that packet. In this example, packets with certain source and/or destination addresses and ports may be externally queued. Thus a flow of packets with similar characteristics may be externally queued, whereas a different flow of packets may be internally queued. In another embodiment, quality of service (QoS) indications in the packet, such as the class of service (COS) field of an 802.1q header or the differentiated services code point (DSCP) field of an IPv4 packet or the traffic class of an IPv6 packet, could be used to determine whether to externally buffer or not. In this embodiment, certain classes could be externally queued while others are not, allowing low latency traffic to avoid the extra queuing while traffic that is less latency sensitive but more drop sensitive can benefit from the external queuing. In a further embodiment, the depth of the internal queue for the egress interface could be used to decide to externally queue a packet. When the internal queue gets beyond a given depth the network element could choose to start externally queuing packets destined there.</p><p id="p-0070" num="0073">If the packet was received on an ingress interface that is not an externally queuing interface, at block <b>406</b>, process <b>400</b> processes the packet normally. In one embodiment, process <b>400</b> processes the packet by queuing this packet in a queue that is internal to the packet switch unit that is processing the packet. If the ingress interface is an externally queuing interface, process <b>400</b> determines the forwarding decisions for that packet at block <b>408</b>. In one embodiment, the forwarding decisions for that packet are which egress interface is used to transmit that packet. For example in one embodiment, if the packet has an associated route or the packet is to be transmitted towards a specific attached network element, then the forwarding decision is to forward that packet to the egress interface for that specific network element.</p><p id="p-0071" num="0074">At block <b>410</b>, process <b>400</b> encodes a forwarding decision in the packet. In one embodiment, process <b>400</b> encodes the forwarding decision in the packet header. For example and in one embodiment, process <b>400</b> can encode the forwarding decision in a special-purpose packet header, an 802.1Q VLAN tag, an MPLS header, and/or a combination thereof. Alternatively, process <b>400</b> can leave the forwarding decision to the packet storage unit, which determines the actual destination port and queue for that packet. For example and in one embodiment, process <b>400</b> can encode the forwarding decision as described in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> above. Process <b>400</b> sends the packet to the external queue corresponding to the to the forwarding decision at block <b>412</b>. In one embodiment, process <b>400</b> sends the packet to the packet storage unit, which then stores the packet in an external queue corresponding to the forwarding decision for that packet.</p><p id="p-0072" num="0075">At block <b>414</b>, process <b>400</b> performs flow control for the queue that corresponds to this packet. In one embodiment, the flow control is used to ensure that there is space in the internal queue for this packet. In this embodiment, a packet, destined for an egress interface and queue Q, remains queued in the internal queue until a flow control channel from the packet switch unit to the packet storage unit indicates to the packet storage unit that the switch chip has room for a packet to egress interface and internal queue Q. In other words, the flow control channel is used by the packet switch unit to indicate to the packet storage unit when the packet storage unit should transmit a packet for that queue. In one embodiment, the flow control channel is used to ensure that no externally queued packets are dropped by the packet switch unit. In one embodiment, process <b>400</b> performs the flow control as described in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> above. The flow control performed by process <b>400</b> is further described in <figref idref="DRAWINGS">FIG. <b>5</b></figref> below.</p><p id="p-0073" num="0076">Process <b>400</b> receives a packet from the external queue at block <b>416</b>. In one embodiment, process <b>400</b> stores this packet in an internal queue prior to this packet being forwarded to the egress interface for transmission. At block <b>418</b>, process <b>400</b> forwards this packet to the egress interface for transmission. In one embodiment, process <b>400</b> forwards this packet when a packet scheduler indicates that this packet should be transmitted.</p><p id="p-0074" num="0077">As described above, the flow control channel is used by the packet switch unit to indicate to packet storage unit when the packet storage unit should transmit a packet for a particular internal queue on the packet switch unit. <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flow diagram of one embodiment of a process <b>500</b> to perform flow control between a packet switch unit and a packet storage unit. In one embodiment, process <b>500</b> is performed by a queue module to perform flow control between a packet switch unit and a packet storage unit, such as the queue module <b>320</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> or queue module <b>370</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>. In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, process <b>500</b> begins by performing a processing loop for each internal queue, Q<sub>i</sub>, (blocks <b>502</b>-<b>514</b> to perform the flow control for each queue in the switch component of a network element. At block <b>504</b>, process <b>500</b> determines the queue occupancy for the internal queue, Q<sub>i</sub>. In one embodiment, the queue occupancy for this queue should be between a low watermark and a high watermark, such that packets stored in the external queue can be stored in the internal queue without being dropped (for lack of space in the queue) and that there are packets in the internal queue, Q<sub>i</sub>, that are available to be forwarded for transmission. In one embodiment, process <b>500</b> determines the queue occupancy for Q<sub>i </sub>by reading the queue depth value that is stored on the network element.</p><p id="p-0075" num="0078">At block <b>506</b>, process <b>500</b> determines if the internal queue occupancy for internal queue Q<sub>i </sub>is below a low watermark. In one embodiment, the low watermark is set to a value such that the packet storage unit processes the flow control XON message before Q<sub>i </sub>goes empty. If the queue occupancy of Q<sub>i </sub>is below the low watermark, process <b>500</b> sends a flow control XON message to the packet storage unit for Q<sub>i </sub>at block <b>508</b>. In one embodiment, the XON flow control message indicates that the packet storage unit should start sending packets for Q<sub>i</sub>. Execution proceeds to block <b>514</b> below.</p><p id="p-0076" num="0079">At block <b>510</b>, process <b>500</b> determines if the external queue occupancy for external queue Q<sub>i </sub>is above a high watermark. In one embodiment, the high watermark for the queue is set low enough so that the internal queue Q<sub>i </sub>has space for additional packets. For example and in one embodiment, the high watermark is set to a value such that the packet storage unit processes the flow control XON message before Q<sub>i </sub>overfills. If the queue occupancy of Q<sub>i </sub>is up the high watermark, process <b>500</b> sends a flow control XOFF message to the packet storage unit for Q<sub>i </sub>at block <b>512</b>. In one embodiment, the XOFF flow control message indicates that the packet storage unit should stop sending packets for Q<sub>i</sub>. Execution proceeds to block <b>514</b> below. The processing loop ends at block <b>514</b>.</p><p id="p-0077" num="0080"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a flow diagram of one embodiment of a process <b>600</b> to process a packet with a packet storage unit. In one embodiment, process <b>600</b> is performed by a storage queue module to process a packet within a packet storage unit, such as the storage queue module <b>324</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> or storage queue module <b>374</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>. In <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, process <b>600</b> begins by receiving a packet at block <b>602</b>. In one embodiment, process <b>600</b> receives the packet from the packet switch unit over an interface that corresponds to the external queue for this packet. At block <b>604</b>, process <b>600</b> determines an external queue for this packet. In one embodiment, process <b>600</b> determines the external queue for the packet based on an encoded forwarding decision included in the packet. For example and in one embodiment, which external queue to use can be encoded in a special purpose packet header, an 802.1q VLAN tag, MPLS header, or a combination thereof. In another embodiment, process <b>600</b> determines the external queue by examining the packet characteristics and assigning the external queue. In this embodiment, process <b>600</b> makes the queuing decision for the packet instead of the packet switch unit.</p><p id="p-0078" num="0081">At block <b>606</b>, process <b>600</b> performs further packet processing. In one embodiment, the packet processing responsibilities for each packet can be either performed by the packet switch unit, the packet storage unit, or both of these chips. For example and in one embodiment, the different types of packet processing can be input filtering, forwarding decisions, queuing decision, egress filtering, rate limiting, classifying, QOS marking, tunnel encapsulating, tunnel decapsulating, and network address translation (NAT) rewriting. In this example, the input filtering is applying access control lists to the packet, forwarding decision is determining the egress interface used to transmit the packet, and the queuing decision is determining which queue the packet will use. In another example, the packet switch unit can perform the input filtering and the forwarding decision and the packet storage unit can perform the queuing decision. In one embodiment, by splitting the responsibilities between the two different chips, neither chip needs additional expensive processing capabilities. At block <b>608</b>, process <b>600</b> stores the packet in the external queue. In one embodiment, process <b>600</b> sends the packet to a memory chip to be stored in the corresponding external queue on the memory chip. In another embodiment, process <b>600</b> stores the packet in an external queue on the packet storage unit.</p><p id="p-0079" num="0082"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is a flow diagram of one embodiment of a process <b>650</b> to de-queue a packet from a packet storage unit. In one embodiment, process <b>650</b> is performed by a storage queue module to de-queue a packet from a packet storage unit, such as the storage queue module <b>324</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> or storage queue module <b>374</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>. In <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, process <b>650</b> begins by performing a processing loop (blocks <b>652</b>-<b>666</b>) to de-queue a packet. At block <b>654</b>, process <b>650</b> determines if the flow control for external queue Q<sub>i </sub>allows for a packet transfer to a corresponding internal queue. In one embodiment, process <b>650</b> determines an allowable packet transfer if the last flow control message for external Q<sub>i </sub>was an XON message indicating the packets from the external queue Q should be sent to the corresponding internal queue. If the flow control allows for packet transfer, at block <b>656</b>, process <b>650</b> transmits the packet to the corresponding internal queue. In one embodiment, process <b>650</b> transmits this packet using the interface for this queue coupling the packet switch unit and the packet storage unit. In another embodiment, process <b>650</b> performs queue shaping and/or queue scheduling to determine which packet is transmitted to the packet switch unit. In this embodiment, there may be multiple external queues that are associated with the internal queue and process <b>650</b> can use queue shaping and/or queue scheduling to determine which packet from which of the external queues should be transmitted. Execution proceeds to block <b>658</b> below. If the flow control does not allow for packet transfer for Q<sub>i </sub>execution proceeds to block <b>658</b> below.</p><p id="p-0080" num="0083">At block <b>658</b>, process <b>650</b> determines if this process has received a flow control XON message for external queue Q<sub>i</sub>. If process <b>650</b> has received the XON flow control message, process <b>650</b> sets an indicator to allow packet transfers for Q<sub>i</sub>. Execution proceeds to block <b>662</b> below. If the XON flow control message has not been received, execution proceeds to block <b>662</b> below. Process <b>650</b> determines if this process has received a flow control XOFF message for external queue Q<sub>i </sub>at block <b>662</b>. If process <b>650</b> has received the XOFF flow control message, process <b>650</b> sets an indicator to disallow packet transfers for Q<sub>i</sub>. Execution proceeds to block <b>666</b> below. If the XOFF flow control message has not been received, execution proceeds to block <b>666</b> below. The processing loop ends at block <b>666</b>.</p><p id="p-0081" num="0084"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram of one embodiment of a queue module <b>700</b> that queues a packet using a switching storage chip. In one embodiment, the queue module <b>700</b> is the queue module <b>320</b> as described in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> or queue module <b>370</b> as described in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>. In one embodiment, the queue module <b>700</b> includes a receive packet module <b>702</b>, determine ingress interface <b>704</b>, process packet module <b>706</b>, determine forwarding module <b>708</b>, encode forwarding module <b>710</b>, send packet module <b>712</b>, flow control module <b>714</b>, receive packet module <b>716</b>, and forward packet module <b>718</b>. In one embodiment, the receive packet module <b>702</b> receives a packet as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>402</b> above. The determine ingress interface <b>704</b> determines if the ingress interface for the received packet is an external queuing interface as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>404</b> above. The process packet module <b>706</b> processes the packet normally as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>406</b> above. The determine forwarding module <b>708</b> determines the forwarding decision for the packet as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>408</b> above. The encode forwarding module <b>710</b> encodes the forwarding decision as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>410</b> above. The send packet module <b>712</b> sends the packet to the packet storage unit as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>412</b> above. The flow control module <b>714</b> performs flow control as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>414</b> above. The receive packet module <b>716</b> receives the packet from the packet storage unit as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>416</b> above. The forward packet module <b>718</b> forwards the packet to the egress interface as described in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, block <b>418</b> above.</p><p id="p-0082" num="0085"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram of one embodiment of a flow control module <b>714</b> that performs flow control between a packet switch unit and a packet storage unit. In one embodiment, the flow control module <b>714</b> includes a determine queue occupancy module <b>802</b>, XON module <b>804</b>, and XOFF module <b>806</b>. In one embodiment, the determine queue occupancy module <b>802</b> determines the queue occupancy for a queue as described in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, block <b>504</b> above. The XON module <b>804</b> determines if the queue occupancy is below a low watermark and sends an XON message as described in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, blocks <b>506</b> and <b>508</b> above. The XOFF module <b>806</b> determines if the queue occupancy is above a high watermark and sends an XOFF message as described in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, blocks <b>510</b> and <b>512</b> above.</p><p id="p-0083" num="0086"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of one embodiment of a storage queue module <b>900</b> that process a packet in a packet storage unit. In one embodiment, the storage queue module <b>900</b> is the storage queue module <b>324</b> as described in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> or storage queue module <b>374</b> as described in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>. In one embodiment, the storage queue module <b>900</b> includes process packet module <b>902</b>, transmit packet module <b>904</b>, set flow control indicator module <b>906</b>, determine external queue module <b>908</b>, and packet store module <b>910</b>. In one embodiment, the process packet module <b>902</b> process the packet as described in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, block <b>606</b> above. The transmit packet module <b>904</b> transmits the packet to the packet switch unit as described in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, block <b>656</b> above. The set flow control indicator module <b>906</b> sets the flow control indicator as described in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, blocks <b>660</b> and <b>664</b> above. The determine external queue module <b>908</b> determines the external queue for a packet as described in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, block <b>604</b> above. The packet store module <b>910</b> stores the packet in the external queue as described in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, block <b>610</b> above.</p><p id="p-0084" num="0087"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows one example of a data processing system <b>1000</b>, which may be used with one embodiment of the present invention. For example, the system <b>1000</b> may be implemented including a network element <b>102</b> as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Note that while <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates various components of a computer system, it is not intended to represent any particular architecture or manner of interconnecting the components as such details are not germane to the present invention. It will also be appreciated that network computers and other data processing systems or other consumer electronic devices, which have fewer components or perhaps more components, may also be used with the present invention.</p><p id="p-0085" num="0088">As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the computer system <b>1000</b>, which is a form of a data processing system, includes a bus <b>1003</b> which is coupled to a microprocessor(s) <b>1005</b> and a ROM (Read Only Memory) <b>1007</b> and volatile RAM <b>1009</b> and a non-volatile memory <b>1011</b>. The microprocessor <b>1005</b> may retrieve the instructions from the memories <b>1007</b>, <b>1009</b>, <b>1011</b> and execute the instructions to perform operations described above. The bus <b>1003</b> interconnects these various components together and also interconnects these components <b>1005</b>, <b>1007</b>, <b>1009</b>, and <b>1011</b> to a display controller and display device <b>1017</b> and to peripheral devices such as input/output (I/O) devices which may be mice, keyboards, modems, network interfaces, printers and other devices which are well known in the art. In one embodiment, the system <b>1000</b> includes a plurality of network interfaces of the same or different type (e.g., Ethernet copper interface, Ethernet fiber interfaces, wireless, and/or other types of network interfaces). In this embodiment, the system <b>1000</b> can include a forwarding engine to forward network date received on one interface out another interface.</p><p id="p-0086" num="0089">Typically, the input/output devices <b>1015</b> are coupled to the system through input/output controllers <b>1013</b>. The volatile RAM (Random Access Memory) <b>1009</b> is typically implemented as dynamic RAM (DRAM), which requires power continually in order to refresh or maintain the data in the memory.</p><p id="p-0087" num="0090">The mass storage <b>1011</b> is typically a magnetic hard drive or a magnetic optical drive or an optical drive or a DVD ROM/RAM or a flash memory or other types of memory systems, which maintains data (e.g. large amounts of data) even after power is removed from the system. Typically, the mass storage <b>1011</b> will also be a random access memory although this is not required. While <figref idref="DRAWINGS">FIG. <b>10</b></figref> shows that the mass storage <b>1011</b> is a local device coupled directly to the rest of the components in the data processing system, it will be appreciated that the present invention may utilize a non-volatile memory which is remote from the system, such as a network storage device which is coupled to the data processing system through a network interface such as a modem, an Ethernet interface or a wireless network. The bus <b>1003</b> may include one or more buses connected to each other through various bridges, controllers and/or adapters as is well known in the art.</p><p id="p-0088" num="0091">Portions of what was described above may be implemented with logic circuitry such as a dedicated logic circuit or with a microcontroller or other form of processing core that executes program code instructions. Thus processes taught by the discussion above may be performed with program code such as machine-executable instructions that cause a machine that executes these instructions to perform certain functions. In this context, a &#x201c;machine&#x201d; may be a machine that converts intermediate form (or &#x201c;abstract&#x201d;) instructions into processor specific instructions (e.g., an abstract execution environment such as a &#x201c;process virtual machine&#x201d; (e.g., a Java Virtual Machine), an interpreter, a Common Language Runtime, a high-level language virtual machine, etc.), and/or, electronic circuitry disposed on a semiconductor chip (e.g., &#x201c;logic circuitry&#x201d; implemented with transistors) designed to execute instructions such as a general-purpose processor and/or a special-purpose processor. Processes taught by the discussion above may also be performed by (in the alternative to a machine or in combination with a machine) electronic circuitry designed to perform the processes (or a portion thereof) without the execution of program code.</p><p id="p-0089" num="0092">The present invention also relates to an apparatus for performing the operations described herein. This apparatus may be specially constructed for the required purpose, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, and magnetic-optical disks, read-only memories (ROMs), RAMs, EPROMs, EEPROMs, magnetic or optical cards, or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus.</p><p id="p-0090" num="0093">A machine readable medium includes any mechanism for storing or transmitting information in a form readable by a machine (e.g., a computer). For example, a machine readable medium includes read only memory (&#x201c;ROM&#x201d;); random access memory (&#x201c;RAM&#x201d;); magnetic disk storage media; optical storage media; flash memory devices; etc.</p><p id="p-0091" num="0094">An article of manufacture may be used to store program code. An article of manufacture that stores program code may be embodied as, but is not limited to, one or more memories (e.g., one or more flash memories, random access memories (static, dynamic or other)), optical disks, CD-ROMs, DVD ROMs, EPROMs, EEPROMs, magnetic or optical cards or other type of machine-readable media suitable for storing electronic instructions. Program code may also be downloaded from a remote computer (e.g., a server) to a requesting computer (e.g., a client) by way of data signals embodied in a propagation medium (e.g., via a communication link (e.g., a network connection)).</p><p id="p-0092" num="0095"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram of one embodiment of an exemplary network element <b>1100</b> that queues a packet using a packet storage unit. In <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the backplane <b>1106</b> couples to the line cards <b>1102</b>A-N and controller cards <b>1104</b>A-B. While in one embodiment, the controller cards <b>1104</b>A-B control the processing of the traffic by the line cards <b>1102</b>A-N, in alternate embodiments, the controller cards <b>1104</b>A-B, perform the same and/or different functions. In one embodiment, the line cards <b>1102</b>A-N process and forward traffic according to the network policies received from controller cards the <b>1104</b>A-B. In one embodiment, one of the line cards <b>1102</b>A-N queues a packet using a packet storage unit as described in <figref idref="DRAWINGS">FIGS. <b>2</b>-<b>6</b>B</figref>. In this embodiment, one, some, or all of the line cards <b>1102</b>A-N includes the switch component to queue a packet using a packet storage unit, such as the switch component <b>300</b> in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> or switch component <b>350</b> as described in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> above. It should be understood that the architecture of the network element <b>1100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref> is exemplary, and different combinations of cards may be used in other embodiments of the invention.</p><p id="p-0093" num="0096">The preceding detailed descriptions are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the tools used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, conceived to be a self-consistent sequence of operations leading to a desired result. The operations are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.</p><p id="p-0094" num="0097">It should be kept in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion, it is appreciated that throughout the description, discussions utilizing terms such as &#x201c;receiving,&#x201d; &#x201c;identifying,&#x201d; &#x201c;determining,&#x201d; &#x201c;performing,&#x201d; &#x201c;forwarding,&#x201d; &#x201c;storing,&#x201d; &#x201c;identifying,&#x201d; &#x201c;updating,&#x201d; &#x201c;processing,&#x201d; &#x201c;sending,&#x201d; or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.</p><p id="p-0095" num="0098">The processes and displays presented herein are not inherently related to any particular computer or other apparatus. Various general-purpose systems may be used with programs in accordance with the teachings herein, or it may prove convenient to construct a more specialized apparatus to perform the operations described. The required structure for a variety of these systems will be evident from the description below. In addition, the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.</p><p id="p-0096" num="0099">The foregoing discussion merely describes some exemplary embodiments of the present invention. One skilled in the art will readily recognize from such discussion, the accompanying drawings and the claims that various modifications can be made without departing from the spirit and scope of the invention.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A non-transitory machine-readable medium having executable instructions to cause one or more processing units to perform a method to process a packet in a network element, the method comprising:<claim-text>receiving the packet, with a packet switch unit, wherein the packet was received by the network element on an ingress interface;</claim-text><claim-text>determining if the packet is to be stored in an external queue;</claim-text><claim-text>identifying the external queue for the packet based on one or more characteristics of the packet;</claim-text><claim-text>forwarding the packet to a packet storage unit, wherein the packet storage unit includes storage for the external queue;</claim-text><claim-text>receiving, with the packet switch unit, the packet from the packet storage unit; and</claim-text><claim-text>forwarding the packet to an egress interface corresponding to the external queue.</claim-text></claim-text></claim></claims></us-patent-application>
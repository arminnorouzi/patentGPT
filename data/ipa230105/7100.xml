<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007101A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007101</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17943241</doc-number><date>20220913</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>60</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>567</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>612</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20110101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>462</subgroup><symbol-position>L</symbol-position><classification-value>N</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>60</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>567</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>65</main-group><subgroup>612</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>63</main-group><subgroup>029</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>4622</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">System and Method for Improving Internet Communication by Using Intermediate Nodes</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17518595</doc-number><date>20211104</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17943241</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17146625</doc-number><date>20210112</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11178250</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17518595</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16292364</doc-number><date>20190305</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10924580</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17146625</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15663762</doc-number><date>20170730</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10277711</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16292364</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>14930894</doc-number><date>20151103</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>9742866</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>15663762</doc-number></document-id></child-doc></relation></continuation><division><relation><parent-doc><document-id><country>US</country><doc-number>14468836</doc-number><date>20140826</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>9241044</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>14930894</doc-number></document-id></child-doc></relation></division><us-provisional-application><document-id><country>US</country><doc-number>61870815</doc-number><date>20130828</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>BRIGHT DATA LTD.</orgname><address><city>Netanya</city><country>IL</country></address></addressbook><residence><country>IL</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Shribman</last-name><first-name>Derry</first-name><address><city>Tel Aviv</city><country>IL</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Vilenski</last-name><first-name>Ofer</first-name><address><city>Moshav Hadar Am</city><country>IL</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for fetching a content from a web server to a client device is disclosed, using tunnel devices serving as intermediate devices. The client device accesses an acceleration server to receive a list of available tunnel devices. The requested content is partitioned into slices, and the client device sends a request for the slices to the available tunnel devices. The tunnel devices in turn fetch the slices from the data server, and send the slices to the client device, where the content is reconstructed from the received slices. A client device may also serve as a tunnel device, serving as an intermediate device to other client devices. Similarly, a tunnel device may also serve as a client device for fetching content from a data server. The selection of tunnel devices to be used by a client device may be in the acceleration server, in the client device, or in both. The partition into slices may be overlapping or non-overlapping, and the same slice (or the whole content) may be fetched via multiple tunnel devices.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="114.47mm" wi="158.75mm" file="US20230007101A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="243.25mm" wi="167.30mm" orientation="landscape" file="US20230007101A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="199.90mm" wi="171.45mm" orientation="landscape" file="US20230007101A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="197.10mm" wi="146.73mm" orientation="landscape" file="US20230007101A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="152.99mm" wi="156.55mm" orientation="landscape" file="US20230007101A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="221.83mm" wi="185.00mm" orientation="landscape" file="US20230007101A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="221.66mm" wi="184.57mm" orientation="landscape" file="US20230007101A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="217.93mm" wi="162.05mm" orientation="landscape" file="US20230007101A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="212.43mm" wi="168.06mm" orientation="landscape" file="US20230007101A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="199.90mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="219.12mm" wi="171.20mm" orientation="landscape" file="US20230007101A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="236.22mm" wi="179.15mm" orientation="landscape" file="US20230007101A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="227.41mm" wi="171.20mm" orientation="landscape" file="US20230007101A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="229.28mm" wi="168.23mm" orientation="landscape" file="US20230007101A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="189.31mm" wi="159.85mm" orientation="landscape" file="US20230007101A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="133.60mm" wi="180.09mm" orientation="landscape" file="US20230007101A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="204.13mm" wi="173.65mm" orientation="landscape" file="US20230007101A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="198.97mm" wi="178.90mm" orientation="landscape" file="US20230007101A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="218.10mm" wi="173.91mm" orientation="landscape" file="US20230007101A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="230.55mm" wi="174.50mm" orientation="landscape" file="US20230007101A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="212.09mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="212.09mm" wi="163.66mm" orientation="landscape" file="US20230007101A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="212.09mm" wi="163.66mm" orientation="landscape" file="US20230007101A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="212.09mm" wi="163.66mm" orientation="landscape" file="US20230007101A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="199.64mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="204.64mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="209.97mm" wi="166.29mm" orientation="landscape" file="US20230007101A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="160.70mm" wi="180.68mm" orientation="landscape" file="US20230007101A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="216.83mm" wi="171.20mm" orientation="landscape" file="US20230007101A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00029" num="00029"><img id="EMI-D00029" he="216.83mm" wi="170.26mm" orientation="landscape" file="US20230007101A1-20230105-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00030" num="00030"><img id="EMI-D00030" he="164.00mm" wi="171.53mm" orientation="landscape" file="US20230007101A1-20230105-D00030.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00031" num="00031"><img id="EMI-D00031" he="146.90mm" wi="167.13mm" orientation="landscape" file="US20230007101A1-20230105-D00031.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00032" num="00032"><img id="EMI-D00032" he="200.74mm" wi="172.38mm" orientation="landscape" file="US20230007101A1-20230105-D00032.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00033" num="00033"><img id="EMI-D00033" he="185.42mm" wi="163.58mm" orientation="landscape" file="US20230007101A1-20230105-D00033.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00034" num="00034"><img id="EMI-D00034" he="132.33mm" wi="168.66mm" orientation="landscape" file="US20230007101A1-20230105-D00034.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00035" num="00035"><img id="EMI-D00035" he="211.16mm" wi="168.99mm" orientation="landscape" file="US20230007101A1-20230105-D00035.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00036" num="00036"><img id="EMI-D00036" he="199.90mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00036.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00037" num="00037"><img id="EMI-D00037" he="229.53mm" wi="175.18mm" orientation="landscape" file="US20230007101A1-20230105-D00037.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00038" num="00038"><img id="EMI-D00038" he="175.26mm" wi="167.89mm" orientation="landscape" file="US20230007101A1-20230105-D00038.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00039" num="00039"><img id="EMI-D00039" he="229.53mm" wi="175.18mm" orientation="landscape" file="US20230007101A1-20230105-D00039.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00040" num="00040"><img id="EMI-D00040" he="175.26mm" wi="167.89mm" orientation="landscape" file="US20230007101A1-20230105-D00040.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00041" num="00041"><img id="EMI-D00041" he="231.90mm" wi="179.15mm" orientation="landscape" file="US20230007101A1-20230105-D00041.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00042" num="00042"><img id="EMI-D00042" he="182.03mm" wi="166.71mm" orientation="landscape" file="US20230007101A1-20230105-D00042.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00043" num="00043"><img id="EMI-D00043" he="233.26mm" wi="174.92mm" orientation="landscape" file="US20230007101A1-20230105-D00043.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00044" num="00044"><img id="EMI-D00044" he="213.53mm" wi="177.46mm" orientation="landscape" file="US20230007101A1-20230105-D00044.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00045" num="00045"><img id="EMI-D00045" he="203.37mm" wi="168.40mm" orientation="landscape" file="US20230007101A1-20230105-D00045.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00046" num="00046"><img id="EMI-D00046" he="192.70mm" wi="171.03mm" orientation="landscape" file="US20230007101A1-20230105-D00046.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00047" num="00047"><img id="EMI-D00047" he="218.19mm" wi="171.20mm" orientation="landscape" file="US20230007101A1-20230105-D00047.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00048" num="00048"><img id="EMI-D00048" he="199.90mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00048.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00049" num="00049"><img id="EMI-D00049" he="199.90mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00049.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00050" num="00050"><img id="EMI-D00050" he="199.90mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00050.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00051" num="00051"><img id="EMI-D00051" he="199.90mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00051.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00052" num="00052"><img id="EMI-D00052" he="199.90mm" wi="169.93mm" orientation="landscape" file="US20230007101A1-20230105-D00052.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00053" num="00053"><img id="EMI-D00053" he="217.42mm" wi="177.46mm" orientation="landscape" file="US20230007101A1-20230105-D00053.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00054" num="00054"><img id="EMI-D00054" he="217.09mm" wi="171.20mm" orientation="landscape" file="US20230007101A1-20230105-D00054.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00055" num="00055"><img id="EMI-D00055" he="217.09mm" wi="170.26mm" orientation="landscape" file="US20230007101A1-20230105-D00055.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00056" num="00056"><img id="EMI-D00056" he="190.33mm" wi="162.05mm" orientation="landscape" file="US20230007101A1-20230105-D00056.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00057" num="00057"><img id="EMI-D00057" he="166.79mm" wi="153.75mm" orientation="landscape" file="US20230007101A1-20230105-D00057.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00058" num="00058"><img id="EMI-D00058" he="193.21mm" wi="175.43mm" orientation="landscape" file="US20230007101A1-20230105-D00058.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00059" num="00059"><img id="EMI-D00059" he="168.57mm" wi="176.95mm" orientation="landscape" file="US20230007101A1-20230105-D00059.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00060" num="00060"><img id="EMI-D00060" he="221.32mm" wi="176.45mm" orientation="landscape" file="US20230007101A1-20230105-D00060.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00061" num="00061"><img id="EMI-D00061" he="230.97mm" wi="162.05mm" orientation="landscape" file="US20230007101A1-20230105-D00061.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00062" num="00062"><img id="EMI-D00062" he="230.97mm" wi="162.14mm" orientation="landscape" file="US20230007101A1-20230105-D00062.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00063" num="00063"><img id="EMI-D00063" he="116.59mm" wi="144.19mm" orientation="landscape" file="US20230007101A1-20230105-D00063.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00064" num="00064"><img id="EMI-D00064" he="229.36mm" wi="168.49mm" orientation="landscape" file="US20230007101A1-20230105-D00064.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00065" num="00065"><img id="EMI-D00065" he="194.82mm" wi="176.19mm" orientation="landscape" file="US20230007101A1-20230105-D00065.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00066" num="00066"><img id="EMI-D00066" he="208.45mm" wi="171.20mm" orientation="landscape" file="US20230007101A1-20230105-D00066.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00067" num="00067"><img id="EMI-D00067" he="213.70mm" wi="178.22mm" orientation="landscape" file="US20230007101A1-20230105-D00067.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00068" num="00068"><img id="EMI-D00068" he="148.08mm" wi="83.82mm" file="US20230007101A1-20230105-D00068.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00069" num="00069"><img id="EMI-D00069" he="181.27mm" wi="170.18mm" orientation="landscape" file="US20230007101A1-20230105-D00069.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00070" num="00070"><img id="EMI-D00070" he="192.19mm" wi="165.52mm" orientation="landscape" file="US20230007101A1-20230105-D00070.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00071" num="00071"><img id="EMI-D00071" he="192.19mm" wi="163.66mm" orientation="landscape" file="US20230007101A1-20230105-D00071.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00072" num="00072"><img id="EMI-D00072" he="220.73mm" wi="172.38mm" orientation="landscape" file="US20230007101A1-20230105-D00072.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00073" num="00073"><img id="EMI-D00073" he="220.73mm" wi="167.13mm" orientation="landscape" file="US20230007101A1-20230105-D00073.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00074" num="00074"><img id="EMI-D00074" he="167.81mm" wi="164.85mm" orientation="landscape" file="US20230007101A1-20230105-D00074.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00075" num="00075"><img id="EMI-D00075" he="152.99mm" wi="153.75mm" orientation="landscape" file="US20230007101A1-20230105-D00075.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00076" num="00076"><img id="EMI-D00076" he="198.88mm" wi="169.42mm" orientation="landscape" file="US20230007101A1-20230105-D00076.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00077" num="00077"><img id="EMI-D00077" he="205.40mm" wi="168.23mm" orientation="landscape" file="US20230007101A1-20230105-D00077.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00078" num="00078"><img id="EMI-D00078" he="232.83mm" wi="177.63mm" orientation="landscape" file="US20230007101A1-20230105-D00078.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00079" num="00079"><img id="EMI-D00079" he="149.69mm" wi="168.06mm" orientation="landscape" file="US20230007101A1-20230105-D00079.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00080" num="00080"><img id="EMI-D00080" he="241.47mm" wi="178.90mm" orientation="landscape" file="US20230007101A1-20230105-D00080.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00081" num="00081"><img id="EMI-D00081" he="241.55mm" wi="184.32mm" orientation="landscape" file="US20230007101A1-20230105-D00081.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00082" num="00082"><img id="EMI-D00082" he="178.22mm" wi="169.50mm" orientation="landscape" file="US20230007101A1-20230105-D00082.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00083" num="00083"><img id="EMI-D00083" he="217.42mm" wi="169.59mm" orientation="landscape" file="US20230007101A1-20230105-D00083.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00084" num="00084"><img id="EMI-D00084" he="229.36mm" wi="168.32mm" orientation="landscape" file="US20230007101A1-20230105-D00084.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00085" num="00085"><img id="EMI-D00085" he="170.01mm" wi="165.52mm" orientation="landscape" file="US20230007101A1-20230105-D00085.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00086" num="00086"><img id="EMI-D00086" he="202.35mm" wi="164.34mm" orientation="landscape" file="US20230007101A1-20230105-D00086.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00087" num="00087"><img id="EMI-D00087" he="214.55mm" wi="172.30mm" orientation="landscape" file="US20230007101A1-20230105-D00087.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00088" num="00088"><img id="EMI-D00088" he="147.24mm" wi="172.72mm" orientation="landscape" file="US20230007101A1-20230105-D00088.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00089" num="00089"><img id="EMI-D00089" he="192.11mm" wi="165.27mm" orientation="landscape" file="US20230007101A1-20230105-D00089.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00090" num="00090"><img id="EMI-D00090" he="192.11mm" wi="163.24mm" orientation="landscape" file="US20230007101A1-20230105-D00090.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00091" num="00091"><img id="EMI-D00091" he="178.39mm" wi="176.45mm" orientation="landscape" file="US20230007101A1-20230105-D00091.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00092" num="00092"><img id="EMI-D00092" he="127.59mm" wi="123.95mm" orientation="landscape" file="US20230007101A1-20230105-D00092.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00093" num="00093"><img id="EMI-D00093" he="158.67mm" wi="117.43mm" orientation="landscape" file="US20230007101A1-20230105-D00093.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00094" num="00094"><img id="EMI-D00094" he="143.93mm" wi="172.04mm" orientation="landscape" file="US20230007101A1-20230105-D00094.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00095" num="00095"><img id="EMI-D00095" he="140.63mm" wi="140.63mm" orientation="landscape" file="US20230007101A1-20230105-D00095.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00096" num="00096"><img id="EMI-D00096" he="181.10mm" wi="108.03mm" file="US20230007101A1-20230105-D00096.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00097" num="00097"><img id="EMI-D00097" he="152.99mm" wi="138.60mm" orientation="landscape" file="US20230007101A1-20230105-D00097.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00098" num="00098"><img id="EMI-D00098" he="138.26mm" wi="155.19mm" orientation="landscape" file="US20230007101A1-20230105-D00098.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00099" num="00099"><img id="EMI-D00099" he="138.01mm" wi="136.48mm" orientation="landscape" file="US20230007101A1-20230105-D00099.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00100" num="00100"><img id="EMI-D00100" he="141.31mm" wi="162.22mm" orientation="landscape" file="US20230007101A1-20230105-D00100.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00101" num="00101"><img id="EMI-D00101" he="173.23mm" wi="120.90mm" file="US20230007101A1-20230105-D00101.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00102" num="00102"><img id="EMI-D00102" he="134.45mm" wi="168.66mm" orientation="landscape" file="US20230007101A1-20230105-D00102.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00103" num="00103"><img id="EMI-D00103" he="167.89mm" wi="118.70mm" file="US20230007101A1-20230105-D00103.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00104" num="00104"><img id="EMI-D00104" he="178.14mm" wi="132.25mm" orientation="landscape" file="US20230007101A1-20230105-D00104.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00105" num="00105"><img id="EMI-D00105" he="181.44mm" wi="127.00mm" orientation="landscape" file="US20230007101A1-20230105-D00105.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00106" num="00106"><img id="EMI-D00106" he="175.68mm" wi="113.96mm" file="US20230007101A1-20230105-D00106.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00107" num="00107"><img id="EMI-D00107" he="164.76mm" wi="171.20mm" orientation="landscape" file="US20230007101A1-20230105-D00107.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00108" num="00108"><img id="EMI-D00108" he="185.25mm" wi="167.56mm" orientation="landscape" file="US20230007101A1-20230105-D00108.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00109" num="00109"><img id="EMI-D00109" he="164.34mm" wi="117.86mm" orientation="landscape" file="US20230007101A1-20230105-D00109.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00110" num="00110"><img id="EMI-D00110" he="159.00mm" wi="163.07mm" orientation="landscape" file="US20230007101A1-20230105-D00110.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00111" num="00111"><img id="EMI-D00111" he="141.99mm" wi="162.48mm" orientation="landscape" file="US20230007101A1-20230105-D00111.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00112" num="00112"><img id="EMI-D00112" he="167.56mm" wi="153.16mm" orientation="landscape" file="US20230007101A1-20230105-D00112.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00113" num="00113"><img id="EMI-D00113" he="167.56mm" wi="125.81mm" orientation="landscape" file="US20230007101A1-20230105-D00113.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00114" num="00114"><img id="EMI-D00114" he="187.20mm" wi="150.45mm" orientation="landscape" file="US20230007101A1-20230105-D00114.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00115" num="00115"><img id="EMI-D00115" he="122.34mm" wi="167.72mm" orientation="landscape" file="US20230007101A1-20230105-D00115.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00116" num="00116"><img id="EMI-D00116" he="135.64mm" wi="164.93mm" orientation="landscape" file="US20230007101A1-20230105-D00116.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00117" num="00117"><img id="EMI-D00117" he="172.21mm" wi="102.70mm" file="US20230007101A1-20230105-D00117.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00118" num="00118"><img id="EMI-D00118" he="133.43mm" wi="138.43mm" orientation="landscape" file="US20230007101A1-20230105-D00118.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00119" num="00119"><img id="EMI-D00119" he="123.61mm" wi="167.98mm" orientation="landscape" file="US20230007101A1-20230105-D00119.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00120" num="00120"><img id="EMI-D00120" he="174.84mm" wi="116.59mm" file="US20230007101A1-20230105-D00120.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00121" num="00121"><img id="EMI-D00121" he="128.27mm" wi="165.27mm" orientation="landscape" file="US20230007101A1-20230105-D00121.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00122" num="00122"><img id="EMI-D00122" he="137.84mm" wi="152.06mm" orientation="landscape" file="US20230007101A1-20230105-D00122.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00123" num="00123"><img id="EMI-D00123" he="136.31mm" wi="166.37mm" orientation="landscape" file="US20230007101A1-20230105-D00123.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00124" num="00124"><img id="EMI-D00124" he="149.27mm" wi="124.54mm" orientation="landscape" file="US20230007101A1-20230105-D00124.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00125" num="00125"><img id="EMI-D00125" he="142.58mm" wi="113.11mm" orientation="landscape" file="US20230007101A1-20230105-D00125.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00126" num="00126"><img id="EMI-D00126" he="163.24mm" wi="132.42mm" orientation="landscape" file="US20230007101A1-20230105-D00126.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00127" num="00127"><img id="EMI-D00127" he="183.47mm" wi="135.64mm" orientation="landscape" file="US20230007101A1-20230105-D00127.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00128" num="00128"><img id="EMI-D00128" he="122.00mm" wi="164.59mm" orientation="landscape" file="US20230007101A1-20230105-D00128.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00129" num="00129"><img id="EMI-D00129" he="150.11mm" wi="147.49mm" orientation="landscape" file="US20230007101A1-20230105-D00129.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00130" num="00130"><img id="EMI-D00130" he="170.35mm" wi="107.78mm" file="US20230007101A1-20230105-D00130.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00131" num="00131"><img id="EMI-D00131" he="163.66mm" wi="114.30mm" file="US20230007101A1-20230105-D00131.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00132" num="00132"><img id="EMI-D00132" he="139.95mm" wi="159.09mm" orientation="landscape" file="US20230007101A1-20230105-D00132.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00133" num="00133"><img id="EMI-D00133" he="167.56mm" wi="113.71mm" file="US20230007101A1-20230105-D00133.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00134" num="00134"><img id="EMI-D00134" he="162.22mm" wi="108.54mm" file="US20230007101A1-20230105-D00134.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is a continuation application of U.S. application Ser. No. 15/663,762, filed on Jul. 30, <b>2017</b>, which is a continuation application of U.S. application Ser. No. 14/930,894, filed on Nov. 3, 2015 (now U.S. Pat. No. 9,742,866), which is a divisional of U.S. application Ser. No. 14/468,836, filed on Aug. 26, 2014 (now U.S. Pat. No. 9,241,044), which claims priority from U.S. Provisional Application Ser. No. 61/870,815, filed on Aug. 28, 2013, all of which are hereby incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">This disclosure relates generally to an apparatus and method for improving communication over the Internet by using intermediate nodes, and in particular, to using devices that may doubly function as an end-user and as an intermediate node.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Unless otherwise indicated herein, the materials described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.</p><p id="p-0005" num="0004">The Internet is a global system of interconnected computer networks that use the standardized Internet Protocol Suite (TCP/IP), including Transmission Control Protocol (TCP) and the Internet Protocol (IP), to serve billions of users worldwide. It is a network of networks that consists of millions of private, public, academic, business, and government networks, of local to global scope, that are linked by a broad array of electronic and optical networking technologies. The Internet carries a vast range of information resources and services, such as the interlinked hypertext documents on the World Wide Web (WWW) and the infrastructure to support electronic mail. The Internet backbone refers to the principal data routes between large, strategically interconnected networks and core routers in the Internet. These data routes are hosted by commercial, government, academic, and other high-capacity network centers, the Internet exchange points and network access points that interchange Internet traffic between the countries, continents and across the oceans of the world. Traffic interchange between Internet service providers (often Tier 1 networks) participating in the Internet backbone exchange traffic by privately negotiated interconnection agreements, primarily governed by the principle of settlement-free peering.</p><p id="p-0006" num="0005">The Transmission Control Protocol (TCP) is one of the core protocols of the Internet protocol suite (IP) described in RFC 675 and RFC 793, and the entire suite is often referred to as TCP/IP. TCP provides reliable, ordered and error-checked delivery of a stream of octets between programs running on computers connected to a local area network, intranet or the public Internet. It resides at the transport layer. Web browsers typically use TCP when they connect to servers on the World Wide Web, and used to deliver email and transfer files from one location to another. HTTP, HTTPS, SMTP, POP3, IMAP, SSH, FTP, Telnet and a variety of other protocols that are typically encapsulated in TCP. As the transport layer of TCP/IP suite, the TCP provides a communication service at an intermediate level between an application program and the Internet Protocol (IP). Due to network congestion, traffic load balancing, or other unpredictable network behavior, IP packets can be lost, duplicated, or delivered out of order. TCP detects these problems, requests retransmission of lost data, rearranges out-of-order data, and even helps minimize network congestion to reduce the occurrence of the other problems. Once the TCP receiver has reassembled the sequence of octets originally transmitted, it passes them to the receiving application. Thus, TCP abstracts the application's communication from the underlying networking details. The TCP is utilized extensively by many of the Internet's most popular applications, including the World Wide Web (WWW), E-mail, File Transfer Protocol, Secure Shell, peer-to-peer file sharing, and some streaming media applications.</p><p id="p-0007" num="0006">While IP layer handles actual delivery of the data, TCP keeps track of the individual units of data transmission, called segments, which a message is divided into for efficient routing through the network. For example, when an HTML file is sent from a web server, the TCP software layer of that server divides the sequence of octets of the file into segments and forwards them individually to the IP software layer (Internet Layer). The Internet Layer encapsulates each TCP segment into an IP packet by adding a header that includes (among other data) the destination IP address. When the client program on the destination computer receives them, the TCP layer (Transport Layer) reassembles the individual segments and ensures they are correctly ordered and error free as it streams them to an application.</p><p id="p-0008" num="0007">The TCP protocol operations may be divided into three phases. Connections must be properly established in a multi-step handshake process (connection establishment) before entering the data transfer phase. After data transmission is completed, the connection termination closes established virtual circuits and releases all allocated resources. A TCP connection is typically managed by an operating system through a programming interface that represents the local end-point for communications, the Internet socket. During the duration of a TCP connection, the local end-point undergoes a series of state changes.</p><p id="p-0009" num="0008">Since TCP/IP is based on the client/server model of operation, the TCP connection setup involves the client and server preparing for the connection by performing an OPEN operation. A client process initiates a TCP connection by performing an active OPEN, sending a SYN message to a server. A server process using TCP prepares for an incoming connection request by performing a passive OPEN. Both devices create for each TCP session a data structure used to hold important data related to the connection, called a Transmission Control Block (TCB).</p><p id="p-0010" num="0009">There are two different kinds of OPEN, named &#x2018;Active OPEN&#x2019; and &#x2018;Passive OPEN&#x2019;. In Active OPEN the client process using TCP takes the &#x201c;active role&#x201d; and initiates the connection by actually sending a TCP message to start the connection (a SYN message). In Passive OPEN the server process designed to use TCP is contacting TCP and saying: &#x201c;I am here, and I am waiting for clients that may wish to talk to me to send me a message on the following port number&#x201d;. The OPEN is called passive because aside from indicating that the process is listening, the server process does nothing. A passive OPEN can in fact specify that the server is waiting for an active OPEN from a specific client, though not all TCP/IP APIs support this capability. More commonly, a server process is willing to accept connections from all comers. Such a passive OPEN is said to be unspecified.</p><p id="p-0011" num="0010">In passive OPEN, the TCP uses a three-way handshake, and before a client attempts to connect with a server, the server must first bind to and listen at a port to open it up for connections. Once the Passive OPEN is established, a client may initiate an Active OPEN. To establish a connection, the three-way (or 3-step) handshake occurs:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0011">1. SYN: The active open is performed by the client sending a SYN to the server. The client sets the segment's sequence number to a random value A.</li>        <li id="ul0002-0002" num="0012">2. SYN-ACK: In response, the server replies with a SYN-ACK. The acknowledgment number is set to one more than the received sequence number, i.e. A+1, and the sequence number that the server chooses for the packet is another random number, B.</li>        <li id="ul0002-0003" num="0013">3. ACK: Finally, the client sends an ACK back to the server. The sequence number is set to the received acknowledgement value, i.e. A+1, and the acknowledgement number is set to one more than the received sequence number i.e. B+1.</li>    </ul>    </li></ul></p><p id="p-0012" num="0014">At this point, both the client and server have received an acknowledgment of the connection. The steps 1, 2 establish the connection parameter (sequence number) for one direction and it is acknowledged. The steps 2, 3 establish the connection parameter (sequence number) for the other direction and it is acknowledged, and then a full-duplex communication is established.</p><p id="p-0013" num="0015">The Internet Protocol (IP) is the principal communications protocol used for relaying datagrams (packets) across a network using the Internet Protocol Suite. Responsible for routing packets across network boundaries, it is the primary protocol that establishes the Internet. IP is the primary protocol in the Internet Layer of the Internet Protocol Suite and has the task of delivering datagrams from the source host to the destination host based on their addresses. For this purpose, IP defines addressing methods and structures for datagram encapsulation. Internet Protocol Version 4 (IPv4) is the dominant protocol of the Internet. IPv4 is described in Internet Engineering Task Force (IETF) Request for Comments (RFC) 791 and RFC 1349, and the successor, Internet Protocol Version 6 (IPv6), is currently active and in growing deployment worldwide. IPv4 uses 32-bit addresses (providing 4 billion: 4.3&#xd7;10<sup>9 </sup>addresses), while IPv6 uses 128-bit addresses (providing 340 undecillion or 3.4&#xd7;10<sup>38 </sup>addresses), as described in RFC 2460.</p><p id="p-0014" num="0016">An overview of an IP-based packet <b>15</b> is shown in <figref idref="DRAWINGS">FIG. <b>2</b><i>a</i></figref>. The packet may be generally segmented into the IP data <b>16</b><i>b </i>to be carried as payload, and the IP header <b>16</b><i>f</i>. The IP header <b>16</b><i>f </i>contains the IP address of the source as Source IP Address field <b>16</b><i>d </i>and the Destination IP Address field <b>16</b><i>c. </i>In most cases, the IP header <b>16</b><i>f </i>and the payload <b>16</b><i>b </i>are further encapsulated by adding a Frame Header <b>16</b><i>e </i>and Frame Footer <b>16</b><i>a </i>used by higher layer protocols.</p><p id="p-0015" num="0017">The Internet Protocol is responsible for addressing hosts and routing datagrams (packets) from a source host to the destination host across one or more IP networks. For this purpose the Internet Protocol defines an addressing system that has two functions. Addresses identify hosts and provide a logical location service. Each packet is tagged with a header that contains the meta-data for the purpose of delivery. This process of tagging is also called encapsulation. IP is a connectionless protocol for use in a packet-switched Link Layer network, and does not need circuit setup prior to transmission. The aspects of guaranteeing delivery, proper sequencing, avoidance of duplicate delivery, and data integrity are addressed by an upper transport layer protocol (e.g., TCP&#x2014;Transmission Control Protocol and UDP&#x2014;User Datagram Protocol).</p><p id="p-0016" num="0018">The main aspects of the IP technology are IP addressing and routing. Addressing refers to how IP addresses are assigned to end hosts and how sub-networks of IP host addresses are divided and grouped together. IP routing is performed by all hosts, but most importantly by internetwork routers, which typically use either Interior Gateway Protocols (IGPs) or External Gateway Protocols (EGPs) to help make IP datagram forwarding decisions across IP connected networks. Core routers serving in the Internet backbone commonly use the Border Gateway Protocol (BGP) as per RFC 4098 or Multi-Protocol Label Switching (MPLS). Other prior art publications relating to Internet related protocols and routing include the following chapters of the publication number 1-587005-001-3 by Cisco Systems, Inc. (7/99) entitled: &#x201c;<i>Internetworking Technologies Handbook</i>&#x201d;, which are all incorporated in their entirety for all purposes as if fully set forth herein: Chapter 5: &#x201c;<i>Routing Basics</i>&#x201d; (pages 5-1 to 5-10), Chapter 30: &#x201c;<i>Internet Protocols</i>&#x201d; (pages 30-1 to 30-16), Chapter 32: &#x201c;<i>IPv</i>6&#x201d; (pages 32-1 to 32-6), Chapter 45: &#x201c;<i>OSI Routing</i>&#x201d; (pages 45-1 to 45-8) and Chapter 51: &#x201c;<i>Security</i>&#x201d; (pages 51-1 to 51-12), as well as in a IBM Corporation, International Technical Support Organization Redbook Documents No. GG24-4756-00, entitled: &#x201c;<i>Local area Network Concepts and Products: LAN Operation Systems and management&#x201d;, </i>1st Edition May 1996, Redbook Document No. GG24-4338-00, entitled: &#x201c;<i>Introduction to Networking Technologies&#x201d;, </i>1<sup>st </sup>Edition April 1994, Redbook Document No. GG24-2580-01 &#x201c;<i>IP Network Design Guide&#x201d;, </i>2<sup>nd </sup>Edition June 1999, and Redbook Document No. GG24-3376-07 &#x201c;<i>TCP/IP Tutorial and Technical Overview</i>&#x201d;, ISBN 0738494682 8<sup>th </sup>Edition December 2006, which are incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0017" num="0019">An Internet packet typically includes a value of Time-to-live (TTL) for avoiding the case of packet looping endlessly. The initial TTL value is set in the header of the packet, and each router in the packet path subtracts one from the TTL field, and the packet is discarded upon the value exhaustion. Since the packets may be routed via different and disparately located routers and servers, the TTL of the packets reaching the ultimate destination computer are expected to vary.</p><p id="p-0018" num="0020">The Internet architecture employs a client-server model, among other arrangements. The terms &#x2018;server&#x2019; or &#x2018;server computer&#x2019; relates herein to a device or computer (or a plurality of computers) connected to the Internet and is used for providing facilities or services to other computers or other devices (referred to in this context as &#x2018;clients&#x2019;) connected to the Internet. A server is commonly a host that has an IP address and executes a &#x2018;server program&#x2019;, and typically operates as a socket listener. Many servers have dedicated functionality such as web server, Domain Name System (DNS) server (described in RFC 1034 and RFC 1035), Dynamic Host Configuration Protocol (DHCP) server (described in RFC 2131 and RFC 3315), mail server, File Transfer Protocol (FTP) server and database server. Similarly, the term &#x2018;client&#x2019; is used herein to include, but not limited to, a program or to a device or a computer (or a series of computers) executing this program, which accesses a server over the Internet for a service or a resource. Clients commonly initiate connections that a server may accept. For non-limiting example, web browsers are clients that connect to web servers for retrieving web pages, and email clients connect to mail storage servers for retrieving mails.</p><p id="p-0019" num="0021">The Hypertext Transfer Protocol (HTTP) is an application protocol for distributed, collaborative, hypermedia information systems, commonly used for communication over the Internet. Hypertext is. HTTP is the protocol to exchange or transfer hypertext, which is a structured text that uses logical links (hyperlinks) between nodes containing text. HTTP version 1.1 was standardized as RFC 2616 (June 1999), which was replaced by a set of standards (obsoleting RFC 2616), including RFC 7230-HTTP/1.1: Message Syntax and Routing, RFC 7231-HTTP/1.1: Semantics and Content, RFC 7232-HTTP/1.1: Conditional Requests, RFC 7233-HTTP/1.1: Range Requests, RFC 7234-HTTP/1.1: Caching, and RFC 7235-HTTP/1.1: Authentication. HTTP functions as a request-response protocol in the client-server computing model. A web browser, for example, may be the client and an application running on a computer hosting a website may be the server. The client submits an HTTP request message to the server. The server, which provides resources such as HTML files and other content, or performs other functions on behalf of the client, returns a response message to the client. The response contains completion status information about the request and may also contain requested content in its message body. A web browser is an example of a user agent (UA). Other types of user agent include the indexing software used by search providers (web crawlers), voice browsers, mobile apps and other software that accesses, consumes or displays web content.</p><p id="p-0020" num="0022">HTTP is designed to permit intermediate network elements to improve or enable communications between clients and servers. High-traffic websites often benefit from web cache servers that deliver content on behalf of upstream servers to improve response time. Web browsers cache previously accessed web resources and reuse them when possible, to reduce network traffic. HTTP proxy servers at private network boundaries can facilitate communication for clients without a globally routable address, by relaying messages with external servers. HTTP is an application layer protocol designed within the framework of the Internet Protocol Suite. Its definition presumes an underlying and reliable transport layer protocol, and Transmission Control Protocol (TCP) is commonly used. However, HTTP can use unreliable protocols such as the User Datagram Protocol (UDP), for example, in the Simple Service Discovery Protocol (SSDP). HTTP resources are identified and located on the network by Uniform Resource Identifiers (URIs) or, more specifically, Uniform Resource Locators (URLs), using the http or https URI schemes. URIs and hyperlinks in Hypertext Markup Language (HTML) documents form webs of inter-linked hypertext documents. An HTTP session is a sequence of network request-response transactions. An HTTP client initiates a request by establishing a Transmission Control Protocol (TCP) connection to a particular port on a server. An HTTP server listening on that port waits for a client's request message. Upon receiving the request, the server sends back a status line, such as &#x201c;HTTP/1.1 200 OK&#x201d;, and a message of its own. The body of this message is typically the requested resource, although an error message or other information may also be returned. HTTP is a stateless protocol. A stateless protocol does not require the HTTP server to retain information or status</p><p id="p-0021" num="0023">HTTP persistent connection, also called HTTP keep-alive, or HTTP connection reuse, refers to using a single TCP connection to send and receive multiple HTTP requests/responses, as opposed to opening a new connection for every single request/response pair. Persistent connections provide a mechanism by which a client and a server can signal the close of a TCP connection. This signaling takes place using the Connection header field. The HTTP persistent connection is described in IETF RFC 2616, entitled: &#x201c;<i>Hypertext Transfer Protocol&#x2014;HTTP/</i>1.1&#x201d;. In HTTP 1.1, all connections are considered persistent unless declared otherwise. The HTTP persistent connections do not use separate keepalive messages, but they allow multiple requests to use a single connection. The advantages of using persistent connections involve lower CPU and memory usage (because fewer connections are open simultaneously), enabling HTTP pipelining of requests and responses, reduced network congestion (due to fewer TCP connections), and reduced latency in subsequent requests (due to minimal handshaking). Any connection herein may use, or be based on, an HTTP persistent connection.</p><p id="p-0022" num="0024">An Operating System (OS) is software that manages computer hardware resources and provides common services for computer programs. The operating system is an essential component of any system software in a computer system, and most application programs usually require an operating system to function. For hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and will frequently make a system call to an OS function or be interrupted by it. Common features typically supported by operating systems include process management, interrupts handling, memory management, file system, device drivers, networking (such as TCP/IP and UDP), and Input/Output (I/O) handling. Examples of popular modern operating systems include Android, BSD, iOS, Linux, OS X, QNX, Microsoft Windows, Windows Phone, and IBM z/OS.</p><p id="p-0023" num="0025">A server device (in server/client architecture) typically offers information resources, services, and applications to clients, and is using a server dedicated or oriented operating system. Current popular server operating systems are based on Microsoft Windows (by Microsoft Corporation, headquartered in Redmond, Wash., U.S.A.), Unix, and Linux-based solutions, such as the &#x2018;Windows Server 2012&#x2019; server operating system is part of the Microsoft &#x2018;Windows Server&#x2019; OS family, that was released by Microsoft on 2012, providing enterprise-class datacenter and hybrid cloud solutions that are simple to deploy, cost-effective, application-focused, and user-centric, and is described in Microsoft publication entitled: &#x201c;<i>Inside</i>-<i>Out Windows Server </i>2012&#x201d;, by William R. Stanek, published 2013 by Microsoft Press, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0024" num="0026">Unix operating systems are widely used in servers. Unix is a multitasking, multiuser computer operating system that exists in many variants, and is characterized by a modular design that is sometimes called the &#x201c;Unix philosophy,&#x201d; meaning the OS provides a set of simple tools that each perform a limited, well-defined function, with a unified filesystem as the main means of communication, and a shell scripting and command language to combine the tools to perform complex workflows. Unix was designed to be portable, multi-tasking and multi-user in a time-sharing configuration, and Unix systems are characterized by various concepts: the use of plain text for storing data; a hierarchical file system; treating devices and certain types of Inter-Process Communication (IPC) as files; and the use of a large number of software tools, small programs that can be strung together through a command line interpreter using pipes, as opposed to using a single monolithic program that includes all of the same functionality. Under Unix, the operating system consists of many utilities along with the master control program, the kernel. The kernel provides services to start and stop programs, handles the file system and other common &#x201c;low level&#x201d; tasks that most programs share, and schedules access to avoid conflicts when programs try to access the same resource or device simultaneously. To mediate such access, the kernel has special rights, reflected in the division between user-space and kernel-space. Unix is described in a publication entitled: &#x201c;UNIX Tutorial&#x201d; by tutorialspoint.com, downloaded on July 2014, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0025" num="0027">A client device (in server/client architecture) typically receives information resources, services, and applications from servers, and is using a client dedicated or oriented operating system. Current popular server operating systems are based on Microsoft Windows (by Microsoft Corporation, headquartered in Redmond, Wash., U.S.A.), which is a series of graphical interface operating systems developed, marketed, and sold by Microsoft. Microsoft Windows is described in Microsoft publications entitled: &#x201c;Windows Internals&#x2014;Part 1&#x201d; and &#x201c;Windows Internals&#x2014;Part 2&#x201d;, by Mark Russinovich, David A. Solomon, and Alex Ioescu, published by Microsoft Press in 2012, which are both incorporated in their entirety for all purposes as if fully set forth herein. Windows 8 is a personal computer operating system developed by Microsoft as part of Windows NT family of operating systems, that was released for general availability on October 2012, and is described in Microsoft Press 2012 publication entitled: &#x201c;<i>Introducing Windows </i>8&#x2014;<i>An Overview for IT Professionals</i>&#x201d; by Jerry Honeycutt, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0026" num="0028">Chrome OS is a Linux kernel-based operating system designed by Google Inc. out of Mountain View, Calif., U.S.A., to work primarily with web applications. The user interface takes a minimalist approach and consists almost entirely of just the Google Chrome web browser; since the operating system is aimed at users who spend most of their computer time on the Web, the only &#x201c;native&#x201d; applications on Chrome OS are a browser, media player and file manager, and hence the Chrome OS is almost a pure web thin client OS.</p><p id="p-0027" num="0029">The Chrome OS is described as including a three-tier architecture: firmware, browser and window manager, and system-level software and userland services. The firmware contributes to fast boot time by not probing for hardware, such as floppy disk drives, that are no longer common on computers, especially netbooks. The firmware also contributes to security by verifying each step in the boot process and incorporating system recovery. The system-level software includes the Linux kernel that has been patched to improve boot performance. The userland software has been trimmed to essentials, with management by Upstart, which can launch services in parallel, re-spawn crashed jobs, and defer services in the interest of faster booting. The Chrome OS user guide is described in the Samsung Electronics Co., Ltd. presentation entitled: &#x201c;<i>Google&#x2122; Chrome OS USER GUIDE&#x201d; published </i>2011, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0028" num="0030">A mobile operating system (also referred to as mobile OS), is an operating system that operates a smartphone, tablet, PDA, or other mobile device. Modern mobile operating systems combine the features of a personal computer operating system with other features, including a touchscreen, cellular, Bluetooth, Wi-Fi, GPS mobile navigation, camera, video camera, speech recognition, voice recorder, music player, near field communication and infrared blaster. Currently popular mobile OS are Android, Symbian, Apple iOS, BlackBerry, MeeGo, Windows Phone, and Bada. Mobile devices with mobile communications capabilities (e.g. smartphones) typically contain two mobile operating systems&#x2014;the main user-facing software platform is supplemented by a second low-level proprietary real-time operating system which operates the radio and other hardware.</p><p id="p-0029" num="0031">Android is an open source and Linux-based mobile operating system (OS) based on the Linux kernel that is currently offered by Google. With a user interface based on direct manipulation, Android is designed primarily for touchscreen mobile devices such as smartphones and tablet computers, with specialized user interfaces for televisions (Android TV), cars (Android Auto), and wrist watches (Android Wear). The OS uses touch inputs that loosely correspond to real-world actions, such as swiping, tapping, pinching, and reverse pinching to manipulate on-screen objects, and a virtual keyboard. Despite being primarily designed for touchscreen input, it also has been used in game consoles, digital cameras, and other electronics. The response to user input is designed to be immediate and provides a fluid touch interface, often using the vibration capabilities of the device to provide haptic feedback to the user. Internal hardware such as accelerometers, gyroscopes and proximity sensors are used by some applications to respond to additional user actions, for example adjusting the screen from portrait to landscape depending on how the device is oriented, or allowing the user to steer a vehicle in a racing game by rotating the device, simulating control of a steering wheel.</p><p id="p-0030" num="0032">Android devices boot to the homescreen, the primary navigation and information point on the device, which is similar to the desktop found on PCs. Android homescreens are typically made up of app icons and widgets; app icons launch the associated app, whereas widgets display live, auto-updating content such as the weather forecast, the user's email inbox, or a news ticker directly on the homescreen. A homescreen may be made up of several pages that the user can swipe back and forth between, though Android's homescreen interface is heavily customizable, allowing the user to adjust the look and feel of the device to their tastes. Third-party apps available on Google Play and other app stores can extensively re-theme the homescreen, and even mimic the look of other operating systems, such as Windows Phone. The Android OS is described in a publication entitled: &#x201c;<i>Android Tutorial</i>&#x201d;, downloaded from tutorialspoint.com on July 2014, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0031" num="0033">iOS (previously iPhone OS) from Apple Inc. (headquartered in Cupertino, Calif., U.S.A.) is a mobile operating system distributed exclusively for Apple hardware. The user interface of the iOS is based on the concept of direct manipulation, using multi-touch gestures. Interface control elements consist of sliders, switches, and buttons. Interaction with the OS includes gestures such as swipe, tap, pinch, and reverse pinch, all of which have specific definitions within the context of the iOS operating system and its multi-touch interface. Internal accelerometers are used by some applications to respond to shaking the device (one common result is the undo command) or rotating it in three dimensions (one common result is switching from portrait to landscape mode). The iOS is described in the publication entitled: &#x201c;<i>IOS Tutorial</i>&#x201d;, downloaded from tutorialspoint.com on July 2014, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0032" num="0034">Operating systems: An Operating System (OS) is software that manages computer hardware resources and provides common services for computer programs. The operating system is an essential component of any system software in a computer system, and most application programs usually require an operating system to function. For hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and will frequently make a system call to an OS function or be interrupted by it. Common features typically supported by operating systems include process management, interrupts handling, memory management, file system, device drivers, networking (such as TCP/IP and UDP), and Input/Output (I/O) handling. Examples of popular modern operating systems include Android, BSD, iOS, Linux, OS X, QNX, Microsoft Windows, Windows Phone, and IBM z/OS.</p><p id="p-0033" num="0035">Process management: The operating system provides an interface between an application program and the computer hardware, so that an application program can interact with the hardware only by obeying rules and procedures programmed into the operating system. The operating system is also a set of services which simplify development and execution of application programs. Executing an application program involves the creation of a process by the operating system kernel which assigns memory space and other resources, establishes a priority for the process in multi-tasking systems, loads program binary code into memory, and initiates execution of the application program which then interacts with the user and with hardware devices. The OS must allocate resources to processes, enable processes to share and exchange information, protect the resources of each process from other processes, and enable synchronization among processes. The OS maintains a data structure for each process, which describes the state and resource ownership of that process, and which enables the OS to exert control over each process.</p><p id="p-0034" num="0036">In many modern operating systems, there can be more than one instance of a program loaded in memory at the same time; for example, more than one user could be executing the same program, each user having separate copies of the program loaded into memory. With some programs, known as re-entrant type, it is possible to have one copy loaded into memory, while several users have shared access to it so that they each can execute the same program-code. The processor at any instant can only be executing one instruction from one program but several processes can be sustained over a period of time by assigning each process to the processor at intervals while the remainder become temporarily inactive. A number of processes being executed over a period of time instead of at the same time is called concurrent execution. A multiprogramming or multitasking OS is a system executing many processes concurrently. A multiprogramming requires that the processor be allocated to each process for a period of time, and de-allocated at an appropriate moment. If the processor is de-allocated during the execution of a process, it must be done in such a way that it can be restarted later as easily as possible.</p><p id="p-0035" num="0037">There are two typical ways for an OS to regain control of the processor during a program's execution in order for the OS to perform de-allocation or allocation: The process issues a system call (sometimes called a software interrupt); for example, an I/O request occurs requesting to access a file on hard disk. Alternatively, a hardware interrupt occurs; for example, a key was pressed on the keyboard, or a timer runs out (used in pre-emptive multitasking). The stopping of one process and starting (or restarting) of another process is called a context switch or context change. In many modern operating systems, processes can consist of many sub-processes. This introduces the concept of a thread. A thread may be viewed as a sub-process; that is, a separate, independent sequence of execution within the code of one process. Threads are becoming increasingly important in the design of distributed and client-server systems and in software run on multi-processor systems.</p><p id="p-0036" num="0038">Modes: Many contemporary processors incorporate a mode bit to define the execution capability of a program in the processor. This bit can be set to a kernel mode or a user mode. A kernel mode is also commonly referred to as supervisor mode, monitor mode or ring 0. In kernel mode, the processor can execute every instruction in its hardware repertoire, whereas in user mode, it can only execute a subset of the instructions. Instructions that can be executed only in kernel mode are called kernel, privileged or protected instructions to distinguish them from the user mode instructions. For example, I/O instructions are privileged. So, if an application program executes in user mode, it cannot perform its own I/O, and must request the OS to perform I/O on its behalf. The system may logically extend the mode bit to define areas of memory to be used when the processor is in kernel mode versus user mode. If the mode bit is set to kernel mode, the process executing in the processor can access either the kernel or user partition of the memory. However, if user mode is set, the process can reference only the user memory space, hence two classes of memory are defined, the user space and the system space (or kernel, supervisor or protected space). In general, the mode bit extends the operating system's protection rights, and is set by the user mode trap instruction, also called a supervisor call instruction. This instruction sets the mode bit, and branches to a fixed location in the system space. Since only the system code is loaded in the system space, only the system code can be invoked via a trap. When the OS has completed the supervisor call, it resets the mode bit to user mode prior to the return.</p><p id="p-0037" num="0039">Computer operating systems provide different levels of access to resources, and these hierarchical protection domains are often referred to as &#x2018;protection rings&#x2019;, and are used to protect data and functionality from faults (by improving fault tolerance) and malicious behaviour (by providing computer security). A protection ring is one of two or more hierarchical levels or layers of privilege within the architecture of a computer system. These levels may be hardware-enforced by some CPU architectures that provide different CPU modes at the hardware or microcode level. Rings are arranged in a hierarchy from most privileged (most trusted, usually numbered zero) to least privileged (least trusted, usually with the highest ring number). On most operating systems, kernel mode or &#x2018;Ring 0&#x2019; is the level with the most privileges and interacts most directly with the physical hardware such as the CPU and memory. Special gates between rings are provided to allow an outer ring to access an inner ring's resources in a predefined manner, as opposed to allowing arbitrary usage. Correctly gating access between rings can improve security by preventing programs from one ring or privilege level from misusing resources intended for programs in another. For example, spyware running as a user program in Ring 3 should be prevented from turning on a web camera without informing the user, since hardware access should be a Ring 1 function reserved for device drivers. Programs such as web browsers running in higher numbered rings must request access to the network, a resource restricted to a lower numbered ring.</p><p id="p-0038" num="0040">Kernel: With the aid of the firmware and device drivers, the kernel provides the most basic level of control over all of the computer's hardware devices. It manages memory access for programs in the RAM, it determines which programs get access to which hardware resources, it sets up or resets the CPU's operating states for optimal operation at all times, and it organizes the data for long-term non-volatile storage with file systems on such media as disks, tapes, flash memory, etc. The part of the system executing in kernel supervisor state is called the kernel, or nucleus, of the operating system. The kernel operates as trusted software, meaning that when it was designed and implemented, it was intended to implement protection mechanisms that could not be covertly changed through the actions of untrusted software executing in user space. Extensions to the OS execute in user mode, so the OS does not rely on the correctness of those parts of the system software for correct operation of the OS. Hence, a fundamental design decision for any function to be incorporated into the OS is whether it needs to be implemented in the kernel. If it is implemented in the kernel, it will execute in kernel (supervisor) space, and have access to other parts of the kernel. It will also be trusted software by the other parts of the kernel. If the function is implemented to execute in user mode, it will have no access to kernel data structures.</p><p id="p-0039" num="0041">There are two techniques by which a program executing in user mode can request the kernel's services, namely &#x2018;System call&#x2019; and &#x2018;Message passing&#x2019;. Operating systems are typically with one or the other of these two facilities, but commonly not both. Assuming that a user process wishes to invoke a particular target system function, in the system call approach, the user process uses the trap instruction, so the system call should appear to be an ordinary procedure call to the application program; the OS provides a library of user functions with names corresponding to each actual system call. Each of these stub functions contains a trap to the OS function, and when the application program calls the stub, it executes the trap instruction, which switches the CPU to kernel mode, and then branches (indirectly through an OS table), to the entry point of the function which is to be invoked. When the function completes, it switches the processor to user mode and then returns control to the user process; thus simulating a normal procedure return. In the message passing approach, the user process constructs a message, that describes the desired service, and then it uses a trusted send function to pass the message to a trusted OS process. The send function serves the same purpose as the trap; that is, it carefully checks the message, switches the processor to kernel mode, and then delivers the message to a process that implements the target functions. Meanwhile, the user process waits for the result of the service request with a message receive operation. When the OS process completes the operation, it sends a message back to the user process.</p><p id="p-0040" num="0042">Interrupts handling: Interrupts are central to operating systems, as they provide an efficient way for the operating system to interact with and react to its environment. Interrupts are typically handled by the operating system's kernel, and provide a computer with a way of automatically saving local register contexts, and running specific code in response to events. When an interrupt is received, the computer's hardware automatically suspends whatever program is currently running, saves its status, and runs computer code previously associated with the interrupt. When a hardware device triggers an interrupt, the operating system's kernel decides how to deal with this event, generally by running some processing code. The amount of code being run depends on the priority of the interrupt, and the processing of hardware interrupts is executed by a device driver, which may be either part of the operating system's kernel, part of another program, or both. Device drivers may then relay information to a running program by various means. A program may also trigger an interrupt to the operating system. For example, if a program wishes to access an hardware (such as a peripheral), it may interrupt the operating system's kernel, which causes control to be passed back to the kernel. The kernel will then process the request. If a program wishes additional resources (or wishes to shed resources) such as memory, it will trigger an interrupt to get the kernel's attention. Each interrupt has its own interrupt handler. The number of hardware interrupts is limited by the number of interrupt request (IRQ) lines to the processor, but there may be hundreds of different software interrupts. Interrupts are a commonly used technique for computer multitasking, especially in real-time computing systems, which are commonly referred to as interrupt-driven systems.</p><p id="p-0041" num="0043">Memory management: A multiprogramming operating system kernel is responsible for managing all system memory which is currently in use by programs, ensuring that a program does not interfere with memory already in use by another program. Since programs time share, each program must have independent access to memory. Memory protection enables the kernel to limit a process' access to the computer's memory. Various methods of memory protection exist, including memory segmentation and paging. In both segmentation and paging, certain protected mode registers specify to the CPU what memory address it should allow a running program to access. Attempts to access other addresses will trigger an interrupt which will cause the CPU to re-enter supervisor mode, placing the kernel in charge. This is called a segmentation violation (or Seg-V), and the kernel will generally resort to terminating the offending program, and will report the error.</p><p id="p-0042" num="0044">Memory management further provides ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed. This is critical for any advanced computer system where more than a single process might be underway at any time. Several methods have been devised that increase the effectiveness of memory management. Virtual memory systems separate the memory addresses used by a process from actual physical addresses, allowing separation of processes and increasing the effectively available amount of RAM using paging or swapping to secondary storage. The quality of the virtual memory manager can have an extensive effect on overall system performance.</p><p id="p-0043" num="0045">File system: Commonly a file system (or filesystem) is used to control how data is stored and retrieved. By separating the data into individual pieces, and giving each piece a name, the information is easily separated and identified, where each piece of data is called a &#x201c;file&#x201d;. The structure and logic rules used to manage the groups of information and their names is called a &#x201c;file system&#x201d;. There are many different kinds of file systems. Each one has a different structure and logic, properties of speed, flexibility, security, size and more. Some file systems have been designed to be used for specific applications. For example, the ISO 9660 file system is designed specifically for optical discs. File systems can be used on many different kinds of storage devices. Some file systems are used on local data storage devices; others provide file access via a network protocol (for example, NFS, SMB, or 9P clients). Some file systems are &#x201c;virtual&#x201d;, in that the &#x201c;files&#x201d; supplied are computed on request (e.g. procfs) or are merely a mapping into a different file system used as a backing store. The file system manages access to both the content of files and the metadata about those files. It is responsible for arranging storage space; reliability, efficiency, and tuning with regard to the physical storage medium are important design considerations.</p><p id="p-0044" num="0046">A disk file system takes advantages of the ability of disk storage media to randomly address data in a short amount of time. Additional considerations include the speed of accessing data following that initially requested and the anticipation that the following data may also be requested. This permits multiple users (or processes) access to various data on the disk without regard to the sequential location of the data. Examples include FAT (FAT12, FAT16, FAT32), exFAT, NTFS, HFS and HFS+, HPFS, UFS, ext2, ext3, ext4, XFS, btrfs, ISO 9660, Files-11, Veritas File System, VMFS, ZFS, ReiserFS and UDF. Some disk file systems are journaling file systems or versioning file systems.</p><p id="p-0045" num="0047">TMPFS. TMPFS (or tmpfs) is a common name for a temporary file storage facility on many Unix-like operating systems. While intended to appear as a mounted file system, it is stored in volatile memory instead of a non-volatile storage device. A similar construction is a RAM disk, which appears as a virtual disk drive and hosts a disk file system. The tmpfs is typically a file system based on SunOS virtual memory resources, which does not use traditional non-volatile media to store file data; instead, tmpfs files exist solely in virtual memory maintained by the UNIX kernel. Because tmpfs file systems do not use dedicated physical memory for file data, but instead use VM system resources and facilities, they can take advantage of kernel resource management policies. Tmpfs is designed primarily as a performance enhancement to allow short-lived files to be written and accessed without generating disk or network I/O. Tmpfs maximizes file manipulation speed while preserving UNIX file semantics. It does not require dedicated disk space for files and has no negative performance impact. The tmpfs is described in a Sun Microsystem Inc. paper entitled: &#x201c;<i>tmpfs: A Virtual Memory File System</i>&#x201d; by Peter Snyder, downloaded on July 2014, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0046" num="0048">Device drivers: A device driver is a specific type of computer software developed to allow interaction with hardware devices. Typically, this constitutes an interface for communicating with the device, through the specific computer bus or communications subsystem that the hardware is connected to, providing commands to and/or receiving data from the device, and on the other end, the requisite interfaces to the operating system and software applications. It is a specialized hardware-dependent computer program which is also operating system specific that enables another program, typically an operating system or applications software package or computer program running under the operating system kernel, to interact transparently with a hardware device, and usually provides the requisite interrupt handling necessary for any necessary asynchronous time-dependent hardware interfacing needs.</p><p id="p-0047" num="0049">Networking: Most operating systems support a variety of networking protocols, hardware, and applications for using them, allowing computers running dissimilar operating systems to participate in a common network, for sharing resources such as computing, files, printers, and scanners, using either wired or wireless connections. Networking can essentially allow a computer's operating system to access the resources of a remote computer, to support the same functions as it could if those resources were connected directly to the local computer. This includes everything from simple communication, to using networked file systems, or sharing another computer's graphics or sound hardware. Some network services allow the resources of a computer to be accessed transparently, such as SSH, which allows networked users direct access to a computer's command line interface. A client/server networking allows a program on a computer, called a client, to connect via a network to another computer, called a server. Servers offer (or host) various services to other network computers and users. These services are usually provided through ports or numbered access points beyond the server's network address. Each port number is usually associated with a maximum of one running program, which is responsible for handling requests to that port. A daemon, being a user program, can in turn access the local hardware resources of that computer by passing requests to the operating system kernel.</p><p id="p-0048" num="0050">Input/Output (I/O) handling: An input/output (or I/O) is the communication between an information processing system (such as a computer) and the outside world, possibly a human or other information processing system. The inputs are typically the signals or data received by the system, and the outputs are the signals or data sent from it. I/O devices may be used by a person (or other system) to communicate with a computer. For instance, a keyboard or a mouse may be an input device for a computer, while monitors and printers are considered output devices for a computer. Devices for communication between computers, such as modems and network cards, typically serve for both input and output.</p><p id="p-0049" num="0051">User interface: Every computer that is to be operated by a human being requires a user interface, usually referred to as a &#x2018;shell&#x2019;, and is essential if human interaction is to be supported. The user interface views the directory structure and requests services from the operating system that will acquire data from input hardware devices, such as a keyboard, mouse or credit card reader, and requests operating system services to display prompts, status messages and such on output hardware devices, such as a video monitor or printer. The two most common forms of a user interface have historically been the command-line interface, where computer commands are typed out line-by-line, and the Graphical User Interface (GUI), where a visual environment (most commonly a WIMP) is present. Typically the GUI is integrated into the kernel, allowing the GUI to be more responsive by reducing the number of context switches required for the GUI to perform its output functions.</p><p id="p-0050" num="0052">WDM. The Windows Driver Model (WDM), also known as the Win32 Driver Model, is a standard model defining a framework for device drivers specified by Microsoft, providing unified driver models. The WDM model is based on WDM drivers that are layered in a complex hierarchy and communicate with each other via I/O Request Packets (IRPs). The WDM was introduced with Windows 98 and Windows 2000 to replace VxD which was used on older versions of Windows such as Windows 95 and Windows 3.1, as well as the Windows NT Driver Model, and WDM drivers are usable on all of Microsoft's operating systems of Windows 95 and later. The WDM is described in the publication entitled: &#x201c;<i>Microsoft Windows Driver Model </i>(<i>WDM</i>)&#x201d;, by Mohamad (Hani) Atassy, submitted to Dr. Dennis R. Hafermann dated Jan. 28, 2002, and in publication entitled: &#x201c;<i>A Comparison of the Linux and Windows Device Driver Architecture</i>&#x201d;, by Melekam Tsegaye and Ricahrd Foss, both from Rhodes University, South-Africa, downloaded from the Internet on July 2014, both are incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0051" num="0053">A general schematic view of the WDM architecture <b>430</b> is shown on <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In the example shown, three applications designated as application #<b>1</b> <b>431</b><i>a, </i>application #<b>2</b> <b>431</b><i>b, </i>and application #<b>3</b> <b>431</b><i>c, </i>are accessing three peripheral hardware devices, designated as peripheral #<b>1</b> <b>439</b><i>a, </i>peripheral #<b>2</b> <b>439</b><i>b, </i>and peripheral #<b>3</b> <b>439</b><i>c. </i>The model involves three layers. The lower layer is the hardware layer <b>50</b><i>c, </i>which includes the hardware devices and peripherals, accessed by the processor (such as processor <b>27</b>) via the hardware bus <b>430</b><i>d, </i>which may correspond to internal bus <b>13</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The highest layer is a &#x2018;user space&#x2019; layer <b>430</b><i>a, </i>corresponding to the user mode nd to the higher &#x2018;ring&#x2019; layers such as Ring 3, and is relating to the space is the memory area where application software and some drivers execute. The kernel of the operating system provides the services as part of a &#x2018;kernel space&#x2019; layer <b>430</b><i>b, </i>serving as an intermediate layer between the user space layer <b>430</b><i>a </i>and the hardware layer <b>430</b><i>c. </i>The kernel space <b>430</b><i>b </i>operates in a highly privileged hierarchical protection domain, and is strictly reserved for running privileged kernel, kernel extensions, and most device drivers, and is typically corresponding to the kernel mode and to the &#x2018;ring-0&#x2019; layer (in x86 processors). The kernel mode may be supported by the processor hardware, or may be supported by a code segment level.</p><p id="p-0052" num="0054">The user mode applications (such as application #<b>1</b> <b>431</b><i>a, </i>application #<b>2</b> <b>431</b><i>b, </i>and application #<b>3</b> <b>431</b><i>c</i>) access the kernel space <b>430</b><i>b </i>by the invoking of system calls respectively denoted as connections <b>432</b><i>a, </i><b>432</b><i>b </i>and <b>432</b><i>c. </i>Typically, such system calls are processed via intermediating entity known as Windows API, such as a Win32 API <b>433</b>, which access the kernel space <b>430</b><i>b </i>via a standard messaging <b>434</b>. The Win32 API <b>433</b> is an example of a Windows API (informally WinAPI), which is Microsoft's core set of Application Programming Interfaces (APIs) available in the Microsoft Windows operating systems. Almost all Windows programs interact with the Windows API; on the Windows NT line of operating systems, a small number (such as programs started early in the Windows startup process) uses the Native API. Supporting for developers is in the form of the Windows Software Development Kit (SDK), providing documentation and tools necessary to build software based upon the Windows API and associated Windows interfaces. The Win32 API <b>433</b> is the 32-bit API for modern versions of Windows, and consists of functions implemented, as with Win16, in system DLLs. The core DLLs of the Win32 include the kernel32.dll, user32.dll, and gdi32.dll. The Win32 API is described in the tutorial entitled: &#x201c;<i>Welcome to Version </i>2.0 <i>of the Win</i>32 <i>API Tutorial</i>&#x201d; by Prof. M. Saeed, published by Brook Miles, downloaded from the Internet on July 2014, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0053" num="0055">System calls provide an essential interface between a process and the operating system. A system call is how a program requests a service from an operating system's kernel. This may include hardware related services (e.g., accessing the hard disk), creating and executing new processes, and communicating with integral kernel services (such as scheduling). A system call is typically processed in the kernel mode, which is accomplished by changing the processor execution mode to a more privileged one. The hardware sees the world in terms of the execution mode according to the processor status register, and processes are an abstraction provided by the operating system. A system call does not require a context switch to another process, it is processed in the context of whichever process invoked it. The system calls are often executed via traps or interrupts; that automatically puts the CPU into some required privilege level, and then passes control to the kernel, which determines whether the calling program should be granted the requested service. If the service is granted, the kernel executes a specific set of instructions over which the calling program has no direct control, returns the privilege level to that of the calling program, and then returns control to the calling program. Implementing system calls requires a control transfer, which involves some sort of architecture-specific feature.</p><p id="p-0054" num="0056">System calls can be roughly grouped into five major categories: Process control, such as load, execute, create/terminate process, get/set process attributes, wait for time, wait event, and signal event; file management, such as request/release device, create/delete file, open/close file, read/write/reposition file, and get/set file attributes; device management, such as read/write/reposition device, get/set device attributes, and logically attach/detach devices; information maintenance, such as get/set time or date, get/set system data, and get/set process, file, or device attributes; and communication such as create, delete communication connection, transfer status information, and attach or detach remote devices.</p><p id="p-0055" num="0057">The system calls are commonly handled by the I/O manager <b>435</b><i>b, </i>which allows devices to communicate with user-mode subsystems. It translates user-mode read and write commands into read or write IRPs which it passes to device drivers. It accepts file system I/O requests and translates them into device specific calls, and can incorporate low-level device drivers that directly manipulate hardware to either read input or write output. It also includes a cache manager to improve disk performance by caching read requests and write to the disk in the background. The I/O manager <b>435</b><i>b </i>may interface the power manager <b>435</b><i>c, </i>which deals with power events (power-off, stand-by, hibernate, etc.) and notifies affected drivers with special IRPs (Power IRPs).</p><p id="p-0056" num="0058">The PnP manager <b>435</b><i>a </i>handles &#x2018;Plug and Play&#x2019; and supports device detection and installation at boot time. It also has the responsibility to stop and start devices on demand, that can happen when a bus (such as USB or FireWire) gains a new device and needs to have a device driver loaded to support it. The PnP manager <b>435</b><i>a </i>may be partly implemented in user mode, in the Plug and Play Service, which handles the often complex tasks of installing the appropriate drivers, notifying services and applications of the arrival of new devices, and displaying GUI to the user.</p><p id="p-0057" num="0059">I/O Request Packets (IRPs) are kernel mode structures that are used to communicate with each other and with the operating system. They are data structures that describe I/O requests, to a driver, all of these parameters (such as buffer address, buffer size, I/O function type, etc.) are passed via a single pointer to this persistent data structure. The IRP with all of its parameters can be put on a queue if the I/O request cannot be performed immediately. I/O completion is reported back to the I/O manager by passing its address to a routine for that purpose, IoCompleteRequest. The IRP may be repurposed as a special kernel APC object if such is required to report completion of the I/O to the requesting thread. IRPs are typically created by the I/O Manager in response to I/O requests from user mode. However, IRPs are sometimes created by the plug-and-play manager, power manager, and other system components, and can also be created by drivers and then passed to other drivers.</p><p id="p-0058" num="0060">The WDM uses kernel-mode device drivers to enable it to interact with hardware devices, where each of the drivers has well defined system routines and internal routines that it exports to the rest of the operating system. DriverEntry is the first routine called after a driver is loaded, and is responsible for initializing the driver. All devices are seen by user mode code as a file object in the I/O manager, though to the I/O manager itself the devices are seen as device objects, which it defines as either file, device or driver objects. The drivers may be aggregated as a driver stack <b>436</b>, including kernel mode drivers in three levels: highest level drivers <b>436</b><i>a, </i>intermediate drivers <b>436</b><i>b, </i>and low level drivers <b>436</b><i>c. </i>The highest level drivers <b>436</b><i>a, </i>such as file system drivers for FAT and NTFS, rely on the intermediate drivers <b>436</b><i>b, </i>which consist of function drivers or main driver for a device, that are optionally sandwiched between lower and higher level filter drivers. The highest level drivers typically know how files are represented on disk, but not the details of how to actually fetch the data, the intermediate level drivers process the requests from the highest level driver by breaking down a large request into a series of small chunks. The function driver commonly posseses the details relating to how the hardware of the peripheral works, typically relies on a bus driver, or a driver that services a bus controller, adapter, or bridge, which can have an optional bus filter driver that sits between itself and the function driver. For example, a PCI bus driver detects the PCI-slot plugged card or hardware, and determines the I/O-mapped or the memory-mapped connection with the host. Intermediate drivers <b>436</b><i>b </i>rely on the low level drivers <b>436</b><i>c </i>to function. The lowest level drivers <b>436</b><i>c </i>are either legacy device drivers that control a device directly, or can be a PnP hardware bus. These lower level drivers <b>436</b><i>c </i>directly control hardware and do not rely on any other drivers. The I/O manager <b>435</b><i>c </i>communicate with the high-level driver <b>436</b><i>a </i>using IRP <b>437</b><i>a, </i>the high-level driver <b>436</b><i>a </i>communicate with the intermediate level driver <b>436</b><i>b </i>using IRP <b>437</b><i>b, </i>the intermediate level driver <b>436</b><i>b </i>communicate with the low-level driver <b>436</b><i>c </i>using IRP <b>437</b><i>c, </i>and the low-level driver <b>436</b><i>b </i>communicate with the HAL <b>438</b> using IRP <b>437</b><i>d. </i></p><p id="p-0059" num="0061">WDM drivers can be classified into the following types and sub-types: Device function drivers, bus drivers, and filter drivers. A function driver is the main driver for a device. A function driver is typically written by the device vendor and is required (unless the device is being used in raw mode). A function driver can service one or more devices. Miniport drivers are a type of function drivers for interfaces such as USB, audio, SCSI and network adapters. They are hardware specific, but the control access to the hardware is through a specific bus class driver. Class drivers are a type of function drivers and can be thought of as built-in framework drivers that miniport and other class drivers can be built on top of The class drivers provide interfaces between different levels of the WDM architecture. Common functionality between different classes of drivers can be written into the class driver and used by other class and miniport drivers. The lower edge of the class driver will have its interface exposed to the miniport driver, while the upper edge of top level class drivers is operating system specific. Class drivers can be dynamically loaded and unloaded at will. They can do class specific functions that are not hardware or bus-specific (with the exception of bus-type class drivers) and in fact sometimes only do class specific functions such as enumeration.</p><p id="p-0060" num="0062">A bus driver services a bus controller, adapter, or bridge. Microsoft provides bus drivers for most common buses, such as Advanced configuration and Power Interface (ACPI), Peripheral Component Interconnect (PCI), PnPISA, SCSI, Universal Serial Bus (USB), and FireWire. A bus driver can service more than one bus if there is more than one bus of the same type on the machine. The ACPI bus driver interacts with the ACPI BIOS to enumerate the devices in the system and control their power use, the PCI bus driver (such as pci.sys) enumerates and configures devices connected via the PCI bus, the FireWire and the USB bus driver respectively enumerates and controls devices connected via the IEEE 1394 high speed bus and the USB. The stream class driver provides a basic processing supporting high bandwidth, time critical, and video and audio data related hardware, and uses minidrivers for interfacing the actual hardware, and hard-disk, floppies, CDs, and DVDs are interfaces using SCSI and CDROM/DVD class driver. The Human Input Device (HID) provides an abstract view of input devices, and the Still Image Architecture (SIA) class driver is used to obtain content from a scanner and a still camera, using minidrivers. For example, accessing an hard disk (such as HDD <b>30</b>) involves a file system driver as high-level driver, a volume manager driver as interemediate level driver, and a disk driver as a low-level driver.</p><p id="p-0061" num="0063">Filter drivers are optional drivers that add value to or modify the behavior of a device and may be non-device drivers. A filter driver can also service one or more devices. Upper level filter drivers sit above the primary driver for the device (the function driver), while lower level filter drivers sit below the function driver and above the bus driver. A driver service is a type of kernel-level filter driver implemented as a Windows service that enables applications to work with devices.</p><p id="p-0062" num="0064">The Hardware Abstraction Layer <b>438</b>, or HAL, is a layer between the physical hardware layer <b>430</b><i>c </i>of the computer and the rest of the operating system. It was designed to hide differences in hardware and therefore provide a consistent platform on which the kernel is run. The HAL <b>438</b> includes hardware-specific code that controls I/O interfaces, interrupt controllers and multiple processors. Typically the particular hardware abstraction does not involve abstracting the instruction set, which generally falls under the wider concept of portability. Abstracting the instruction set, when necessary (such as for handling the several revisions to the x86 instruction set, or emulating a missing math coprocessor), is performed by the kernel, or via platform virtualization.</p><p id="p-0063" num="0065">Linux is a Unix-like and mostly POSIX-compliant computer operating system assembled under the model of free and open source software development and distribution. The defining component of Linux is the Linux kernel, an operating system kernel first released on 5 Oct. 1991 by Linus Torvalds. Linux was originally developed as a free operating system for Intel x86-based personal computers, but has since been ported to more computer hardware platforms than any other operating system. Linux also runs on embedded systems such as mobile phones, tablet computers, network routers, facility automation controls, televisions, and video game consoles. Android, which is a widely used operating system for mobile devices, is built on top of the Linux kernel. Typically, Linux is packaged in a format known as a Linux distribution for desktop and server use.</p><p id="p-0064" num="0066">Linux distributions include the Linux kernel, supporting utilities and libraries and usually a large amount of application software to fulfill the distribution's intended use. A Linux-based system is a modular Unix-like operating system. Such a system uses a monolithic kernel, the Linux kernel, which handles process control, networking, and peripheral and file system access. Device drivers are either integrated directly with the kernel or added as modules loaded while the system is running. Some components of an installed Linux system are a bootloader, for example GNU GRUB or LILO, which is executed by the computer when it is first turned on, and loads the Linux kernel into memory; an init program, which is the first process launched by the Linux kernel, and is at the root of the process tree, and starts processes such as system services and login prompts (whether graphical or in terminal mode); Software libraries which contain code which can be used by running processes; and user interface programs such as command shells or windowing environments. A version of Linux is described, for example, in IBM Corporation (headquartered in Armonk, N.Y., U.S.A.) publication No. SC34-2597-03 entitled: &#x201c;Device Drivers, Features, and Commands on Red Hat Exterprise Linux 6.3&#x201d;, downloaded from the Internet on July 2014, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0065" num="0067">The general schematic Linux driver architecture <b>450</b> is shown in <figref idref="DRAWINGS">FIG. <b>3</b><i>a</i></figref>, and the Linux kernel is further described in Wiley Publishing, Inc. publication entitled: &#x201c;Professional Linux Kernel Architecture&#x201d;, by Wofgang Mauerer published 2008, and Linux programming is described in the book entitled: &#x201c;The Linux Kernel Module Programming Guide&#x201d; ver. 2.6.4 by Peter Jay Salzman, Michael Burian, and Ori Pomerantz, dated May 18, 2007, and in the publication entitled: &#x201c;<i>A Comparison of the Linux and Windows Device Driver Architecture</i>&#x201d;, by Melekam Tsegaye and Richard Foss, both from Rhodes University, South-Africa, downloaded from the Internet on July 2014, which are all incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0066" num="0068">Similar to the WDM <b>430</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the Linux kernel involves a &#x2018;System Call Interface&#x2019; <b>453</b>, receiving system calls <b>452</b><i>a, </i><b>452</b><i>b, </i>and <b>452</b><i>c </i>from the respective applications such as an application #<b>1</b> <b>431</b><i>a, </i>an application #<b>2</b> <b>431</b><i>b, </i>and an application #<b>3</b> <b>431</b><i>c, </i>and serves as the denomination for the entirety of all implemented and available system calls in a kernel. The Linux kernel is based on a layered modules stack <b>454</b>, which may include three levels of modules, such as module #<b>1</b> <b>454</b><i>a, </i>module #<b>2</b> <b>454</b><i>b, </i>and module #<b>3</b> <b>454</b><i>c, </i>where the module #<b>1</b> <b>454</b><i>a </i>communicate over connection <b>455</b><i>a </i>with the system call interface <b>453</b>, the module #<b>2</b> <b>454</b><i>b </i>communicates with the module #<b>1</b> <b>454</b><i>a </i>over connection <b>455</b><i>b, </i>the module #<b>3</b> <b>454</b><i>c </i>communicates over the connection <b>455</b><i>c </i>with the module #<b>2</b> <b>454</b><i>b </i>and over a connection <b>455</b><i>d </i>with the HAL <b>438</b>.</p><p id="p-0067" num="0069">Similar to the WDM <b>430</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the Linux kernel shown as the arrangement <b>450</b> in <figref idref="DRAWINGS">FIG. <b>3</b><i>a</i></figref>, is using the concept of layered architecture of a modules stack <b>454</b>, which may comprise module #<b>1</b> <b>454</b><i>a, </i>module #<b>2</b> <b>454</b><i>b, </i>and module #<b>3</b> <b>454</b><i>c, </i>communicating using messaging mechanism, such as a connection <b>455</b><i>a </i>between the system call interface <b>453</b> and the module #<b>1</b> <b>454</b><i>a, </i>a connection <b>455</b><i>b </i>between the module #<b>1</b> <b>454</b><i>a </i>and the module #<b>2</b> <b>454</b><i>b, </i>a connection <b>455</b><i>c </i>between the module #<b>2</b> <b>454</b><i>b </i>and the module #<b>3</b> <b>454</b><i>c, </i>and a connection <b>455</b><i>d </i>between the module #<b>3</b> <b>454</b><i>c </i>and the HAL <b>438</b>.</p><p id="p-0068" num="0070">The modules in the modules stack <b>454</b>, typically referred to as Loadable Kernel Modules (or LKM), are object files that contain code to extend the running Linux kernel, or so-called base kernel. LKMs are typically used to add support for new hardware and/or filesystems, or for adding system calls. When the functionality provided by a LKM is no longer required, it can be unloaded in order to free memory and other resources. Loadable kernel modules in Linux are located in /lib/modules and have had the extension &#x2018;.ko&#x2019; (&#x201c;kernel object&#x201d;) since version 2.6 (previous versions used the .o extension), and are loaded (and unloaded) by the modprobe command. The lsmod command lists the loaded kernel modules. In emergency cases, when the system fails to boot (due to e.g. broken modules), specific modules can be enabled or disabled by modifying the kernel boot parameters list (for example, if using GRUB, by pressing &#x2018;e&#x2019; in the GRUB start menu, then editing the kernel parameter line). Linux allows disabling module loading via sysctl option/proc/sys/kernel/modules_disabled. An initramfs system may load specific modules needed for a machine at boot and then disable module loading.</p><p id="p-0069" num="0071">A web browser (commonly referred to as a browser) is a software application for retrieving, presenting, and traversing information resources on the World Wide Web. An information resource is identified by a Uniform Resource Identifier (URI/URL) and may be part of a web page, a web-page, an image, a video, or any other piece of content. Hyperlinks present in resources enable users easily to navigate their browsers to related resources. Although browsers are primarily intended to use the World Wide Web, they can also be used to access information provided by web servers in private networks or files in file systems. The primary purpose of a web browser is to bring information resources to the user (&#x201c;retrieval&#x201d; or &#x201c;fetching&#x201d;), allowing them to view the information (&#x201c;display&#x201d;, &#x201c;rendering&#x201d;), and then access other information (&#x201c;navigation&#x201d;, &#x201c;following links&#x201d;). Currently the major web browsers are known as Firefox, Internet Explorer, Google Chrome, Opera, and Safari.</p><p id="p-0070" num="0072">The process begins when the user inputs a Uniform Resource Locator (URL), for example &#x2018;http://en.wikipedia.org&#x2019;, into the browser. The prefix of the URL, the Uniform Resource Identifier or URI, determines how the URL will be interpreted. The most commonly used kind of URI starts with http: and identifies a resource to be retrieved over the Hypertext Transfer Protocol (HTTP). Many browsers also support a variety of other prefixes, such as https: for HTTPS, ftp: for the File Transfer Protocol, and file: for local files. Prefixes that the web browser cannot directly handle are often handed off to another application entirely. For example, mailto: URIs are usually passed to the user's default e-mail application, and news: URIs are passed to the user's default newsgroup reader. In the case of http, https, file, and others, once the resource has been retrieved the web browser will display it. HTML and associated content (image files, formatting information such as CSS, etc.) is passed to the browser's layout engine to be transformed from markup to an interactive document, a process known as &#x201c;rendering&#x201d;. Aside from HTML, web browsers can generally display any kind of content that can be part of a web page. Most browsers can display images, audio, video, and XML files, and often have plug-ins to support Flash applications and Java applets. Upon encountering a file of an unsupported type or a file that is set up to be downloaded rather than displayed, the browser prompts the user to save the file to disk. Information resources may contain hyperlinks to other information resources. Each link contains the URI of a resource to go to. When a link is clicked, the browser navigates to the resource indicated by the link's target URI, and the process of bringing content to the user begins again. The architecture of a web browser is described in the publication entitled: &#x201c;<i>Architecture and evolution of the modern web browser</i>&#x201d; by Alan Grosskurth and Michael W. Godfrey of the University of Waterloo in Canada, dated Jun. 20, 2006, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0071" num="0073">A currently popular web browser is the Internet Explorer (formerly Microsoft Internet Explorer and Windows Internet Explorer, commonly abbreviated IE or MSIE) from Microsoft Corporation, headquartered in Redmond, Wash., U.S.A., which is a series of graphical web browsers developed by Microsoft and included as part of the Microsoft Windows line of operating systems. The Internet Explorer 8 is described, for example, in Microsoft 2009 publication entitled: &#x201c;<i>Step by Step Tutorials for Microsoft Internet Explorer </i>8 <i>Accessibility Options</i>&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein. Another popular web browser is the Google Chrome which is a freeware web browser developed by Google, heagquartered in Googleplex, Mountain View, Calif., U.S.A. Google Chrome aims to be secure, fast, simple, and stable, providing strong application performance and JavaScript processing speed.</p><p id="p-0072" num="0074">A mobile browser, also called a microbrowser, minibrowser, or Wireless Internet Browser (WIB), is a web browser designed for use on a mobile device such as a mobile phone or PDA. Mobile browsers are optimized so as to display Web content most effectively for small screens on portable devices. Mobile browser software must be small and efficient to accommodate the low memory capacity and low-bandwidth of wireless handheld devices. Some mobile browsers can handle more recent technologies like CSS 2.1, JavaScript, and Ajax. Websites designed for access from these browsers are referred to as wireless portals or collectively as the Mobile Web. They may automatically create &#x201c;mobile&#x201d; versions of each page, for example this one</p><p id="p-0073" num="0075">The mobile browser typically connects via cellular network, via Wireless LAN, or via other wireless networks, and are using standard HTTP over TCP/IP, and displays web pages written in HTML, XHTML Mobile Profile (WAP 2.0), or WML (which evolved from HDML). WML and HDML are stripped-down formats suitable for transmission across limited bandwidth, and wireless data connection called WAP. WAP 2.0 specifies XHTML Mobile Profile plus WAP CSS, subsets of the W3C's standard XHTML and CSS with minor mobile extensions. Some mobile browsers are full-featured Web browsers capable of HTML, CSS, ECMAScript, as well as mobile technologies such as WML, i-mode HTML, or cHTML. To accommodate small screens, some mobile browsers use Post-WIMP interfaces. An example of a mobile browser is Safari, which is a mobile web browser developed by Apple Inc. (headquartered in Apple Campus, Cupertino, Calif., U.S.A), included with the OS X and iOS operating systems, and described in Apple publication entitled: &#x201c;Safari Web Content Guide&#x201d;, dated March 2014, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0074" num="0076"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a block diagram that illustrates a system <b>10</b> including a computer system <b>11</b> and the associated Internet <b>113</b> connection. Such configuration is typically used for computers (hosts) connected to the Internet <b>113</b> and executing a server or a client (or a combination) software. The system <b>11</b> may be used as a portable electronic device such as a notebook/laptop computer, a media player (e.g., MP3 based or video player), a desktop computer, a laptop computer, a cellular phone, a Personal Digital Assistant (PDA), an image processing device (e.g., a digital camera or video recorder), and/or any other handheld or fixed location computing devices, or a combination of any of these devices. Note that while <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates various components of a computer system, it is not intended to represent any particular architecture or manner of interconnecting the components; as such details are not germane. It will also be appreciated that network computers, handheld computers, cell phones and other data processing systems which have fewer components or perhaps more components may also be used. The computer system of <figref idref="DRAWINGS">FIG. <b>1</b></figref> may, for example, be an Apple Macintosh computer or Power Book, or an IBM compatible PC. The computer system <b>11</b> includes a bus <b>13</b>, an interconnect, or other communication mechanism for communicating information, and a processor <b>27</b>, commonly in the form of an integrated circuit, coupled to the bus <b>13</b> for processing information and for executing the computer executable instructions. Computer system <b>11</b> also includes a main memory <b>122</b>, such as a Random Access Memory (RAM) or other dynamic storage device, coupled to bus <b>13</b> for storing information and instructions to be executed by processor <b>27</b>. Main memory <b>122</b> also may be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor <b>27</b>. The computer system <b>11</b> further includes a Read Only Memory (ROM) <b>25</b><i>b </i>(or other non-volatile memory) or other static storage device coupled to the bus <b>13</b> for storing static information and instructions for the processor <b>27</b>. A storage device <b>25</b><i>c, </i>such as a magnetic disk or optical disk, a hard disk drive (HDD) for reading from and writing to a hard disk, a magnetic disk drive for reading from and writing to a magnetic disk, and/or an optical disk drive (such as DVD) for reading from and writing to a removable optical disk, is coupled to bus <b>13</b> for storing information and instructions. The hard disk drive, magnetic disk drive, and optical disk drive may be connected to the system bus by a hard disk drive interface, a magnetic disk drive interface, and an optical disk drive interface, respectively. The drives and their associated computer-readable media provide non-volatile storage of computer readable instructions, data structures, program modules and other data for the general purpose computing devices. Typically, the computer system <b>11</b> includes an Operating System (OS) stored in a non-volatile storage for managing the computer resources and provides the applications and programs with an access to the computer resources and interfaces. An operating system commonly processes system data and user input, and responds by allocating and managing tasks and internal system resources, such as controlling and allocating memory, prioritizing system requests, controlling input and output devices, facilitating networking and managing files. Non-limiting examples of operating systems are Microsoft Windows, Mac OS X, and Linux.</p><p id="p-0075" num="0077">The term &#x201c;processor&#x201d; is used herein to include, but not limited to, any integrated circuit or other electronic device (or collection of devices) capable of performing an operation on at least one instruction, including, without limitation, Reduced Instruction Set Core (RISC) processors, CISC microprocessors, Microcontroller Units (MCUs), CISC-based Central Processing Units (CPUs), and Digital Signal Processors (DSPs). The hardware of such devices may be integrated onto a single substrate (e.g., silicon &#x201c;die&#x201d;), or distributed among two or more substrates. Furthermore, various functional aspects of the processor may be implemented solely as software or firmware associated with the processor.</p><p id="p-0076" num="0078">The computer system <b>11</b> may be coupled via a bus <b>13</b> to a display <b>17</b>, such as a Cathode Ray Tube (CRT), a Liquid Crystal Display (LCD), a flat screen monitor, a touch screen monitor or similar means for displaying text and graphical data to a user. The display may be connected via a video adapter for supporting the display. The display allows a user to view, enter, and/or edit information that is relevant to the operation of the system. An input device <b>18</b>, including alphanumeric and other keys, is coupled to the bus <b>13</b> for communicating information and command selections to the processor <b>27</b>. Another type of user input device is a cursor control <b>19</b>, such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to the processor <b>27</b> and for controlling cursor movement on the display <b>17</b>. This input device typically has two degrees of freedom in two axes, a first axis (e.g., x) and a second axis (e.g., y), that allows the device to specify positions in a plane.</p><p id="p-0077" num="0079">The computer system <b>11</b> may be used for implementing the methods and techniques described herein. According to one embodiment, those methods and techniques are performed by the computer system <b>11</b> in response to the processor <b>27</b> executing one or more sequences of one or more instructions contained in a main memory <b>25</b><i>a. </i>Such instructions may be read into the main memory <b>25</b><i>a </i>from another computer-readable medium, such as a storage device <b>123</b>. Execution of the sequences of instructions contained in the main memory <b>25</b><i>a </i>causes the processor <b>27</b> to perform the process steps described herein. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions to implement the arrangement. Thus, embodiments of the invention are not limited to any specific combination of hardware circuitry and software.</p><p id="p-0078" num="0080">The term &#x201c;computer-readable medium&#x201d; (or &#x201c;machine-readable medium&#x201d;) is used herein to include, but not limited to, any medium or any memory, that participates in providing instructions to a processor, (such as the processor <b>27</b>) for execution, or any mechanism for storing or transmitting information in a form readable by a machine (e.g., a computer). Such a medium may store computer-executable instructions to be executed by a processing element and/or control logic, and data which is manipulated by a processing element and/or control logic, and may take many forms, including but not limited to, non-volatile medium, volatile medium, and transmission medium. Transmission media includes coaxial cables, copper wire and fiber optics, including the wires that comprise the bus <b>13</b>. Transmission media can also take the form of acoustic or light waves, such as those generated during radio-wave and infrared data communications, or other form of propagating signals (e.g., carrier waves, infrared signals, digital signals, etc.). Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, or any other magnetic medium, a CD-ROM, any other optical medium, punch-cards, paper-tape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computer can read.</p><p id="p-0079" num="0081">Various forms of computer-readable media may be involved in carrying one or more sequences of one or more instructions to to processor <b>27</b> for execution. For example, the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to the computer system <b>11</b> can receive the data on the telephone line and use an infrared transmitter to convert the data to an infrared signal. An infrared detector can receive the data carried in the infrared signal and appropriate circuitry can place the data on the bus <b>13</b>. The bus <b>13</b> carries the data to the main memory <b>25</b><i>a, </i>from which the processor <b>27</b> retrieves and executes the instructions. The instructions received by the main memory <b>25</b><i>a </i>may optionally be stored on the storage device <b>25</b><i>c </i>either before or after execution by the processor <b>27</b>.</p><p id="p-0080" num="0082">The computer system <b>11</b> commonly includes a communication interface <b>29</b> coupled to the bus <b>13</b>. The communication interface <b>29</b> provides a two-way data communication coupling to a network link <b>28</b> that is connected to a local network <b>14</b>. For example, the communication interface <b>29</b> may be an Integrated Services Digital Network (ISDN) card or a modem to provide a data communication connection to a corresponding type of telephone line. As another non-limiting example, the communication interface <b>29</b> may be a local area network (LAN) card to provide a data communication connection to a compatible LAN. For example, Ethernet based connection based on IEEE802.3 standard may be used, such as 10/100BaseT, 1000BaseT (gigabit Ethernet), 10 gigabit Ethernet (10 GE or 10 GbE or 10 GigE per IEEE Std. 802.3ae-2002as standard), 40 Gigabit Ethernet (40 GbE), or 100 Gigabit Ethernet (100 GbE as per Ethernet standard IEEE P802.3ba). These technologies are described in Cisco Systems, Inc. Publication number 1-587005-001-3 (6/99), &#x201c;Internetworking Technologies Handbook&#x201d;, Chapter 7: &#x201c;Ethernet Technologies&#x201d;, pages 7-1 to 7-38, which is incorporated in its entirety for all purposes as if fully set forth herein. In such a case, the communication interface <b>29</b> typically includes a LAN transceiver or a modem, such as Standard Microsystems Corporation (SMSC) LAN91C111 10/100 Ethernet transceiver, described in a Standard Microsystems Corporation (SMSC) data-sheet &#x201c;<i>LAN</i>91<i>C</i>111 10/100 <i>Non</i>-<i>PCI Ethernet Single Chip MAC+PHU</i>&#x201d; Data-Sheet, Rev. 15 (Feb. 20, 2004), which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0081" num="0083">The Internet <b>113</b> is a global system of interconnected computer networks that use the standardized Internet Protocol Suite (TCP/IP), including Transmission Control Protocol (TCP) and the Internet Protocol (IP), to serve billions of users worldwide. It is a network of networks that consists of millions of private, public, academic, business, and government networks, of local to global scope, that are linked by a broad array of electronic and optical networking technologies. The Internet carries a vast range of information resources and services, such as the interlinked hypertext documents on the World Wide Web (WWW) and the infrastructure to support electronic mail. The Internet backbone refers to the principal data routes between large, strategically interconnected networks and core routers in the Internet. These data routes are hosted by commercial, government, academic and other high-capacity network centers, the Internet exchange points and network access points that interchange Internet traffic between the countries, continents and across the oceans of the world. Traffic interchange between Internet service providers (often Tier 1 networks) participating in the Internet backbone exchange traffic by privately negotiated interconnection agreements, primarily governed by the principle of settlement-free peering.</p><p id="p-0082" num="0084">An Internet Service Provider (ISP) <b>12</b> is an organization that provides services for accessing, using, or participating in the Internet <b>113</b>. Internet Service Providers may be organized in various forms, such as commercial, community-owned, non-profit, or otherwise privately owned. Internet services typically provided by ISPs include Internet access, Internet transit, domain name registration, web hosting, and colocation. Various ISP Structures are described in Chapter 2: &#x201c;<i>Structural Overview of ISP Networks</i>&#x201d; of the book entitled: &#x201c;<i>Guide to Reliable Internet Services and Applications</i>&#x201d;, by Robert D. Doverspike, K. K. Ramakrishnan, and Chris Chase, published 2010 (ISBN: 978-1-84882-827-8), which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0083" num="0085">A mailbox provider is an organization that provides services for hosting electronic mail domains with access to storage for mailboxes. It provides email servers to send, receive, accept, and store email for end users or other organizations. Internet hosting services provide email, web-hosting, or online storage services. Other services include virtual server, cloud services, or physical server operation. A virtual ISP (VISP) is an operation that purchases services from another ISP, sometimes called a wholesale ISP in this context, which allow the VISP's customers to access the Internet using services and infrastructure owned and operated by the wholesale ISP. It is akin to mobile virtual network operators and competitive local exchange carriers for voice communications. A Wireless Internet Service Provider (WISP) is an Internet service provider with a network based on wireless networking. Technology may include commonplace Wi-Fi wireless mesh networking, or proprietary equipment designed to operate over open 900 MHz, 2.4 GHz, 4.9, 5.2, 5.4, 5.7, and 5.8 GHz bands or licensed frequencies in the UHF band (including the MMDS frequency band) and LMDS.</p><p id="p-0084" num="0086">ISPs may engage in peering, where multiple ISPs interconnect at peering points or Internet exchange points (IXs), allowing routing of data between each network, without charging one another for the data transmitted&#x2014;data that would otherwise have passed through a third upstream ISP, incurring charges from the upstream ISP. ISPs requiring no upstream and having only customers (end customers and/or peer ISPs), are referred to as Tier 1 ISPs.</p><p id="p-0085" num="0087">A multitasking is a method where multiple tasks (also known as processes or programs) are performed during the same period of time&#x2014;they are executed concurrently (in overlapping time periods, new tasks starting before others have ended) instead of sequentially (one completing before the next starts). The tasks share common processing resources, such as a CPU and main memory. Multitasking does not necessarily mean that multiple tasks are executing at exactly the same instant. In other words, multitasking does not imply parallelism, but it does mean that more than one task can be part-way through execution at the same time, and more than one task is advancing over a given period of time.</p><p id="p-0086" num="0088">In the case of a computer with a single CPU, only one task is said to be running at any point in time, meaning that the CPU is actively executing instructions for that task. Multitasking solves the problem by scheduling which task may be the one running at any given time, and when another waiting task gets a turn. The act of reassigning a CPU from one task to another one is called a context switch. When context switches occur frequently enough, the illusion of parallelism is achieved. Even on computers with more than one CPU (called multiprocessor machines) or more than one core in a given CPU (called multicore machines), where more than one task can be executed at a given instant (one per CPU or core), multitasking allows many more tasks to be run than there are CPUs.</p><p id="p-0087" num="0089">Operating systems may adopt one of many different scheduling strategies. In multiprogramming systems, the running task keeps running until it performs an operation that requires waiting for an external event (e.g. reading from a tape) or until the computer's scheduler forcibly swaps the running task out of the CPU. Multiprogramming systems are designed to maximize CPU usage. In time-sharing systems, the running task is required to relinquish the CPU, either voluntarily or by an external event such as a hardware interrupt. Time sharing systems are designed to allow several programs to execute apparently simultaneously. In real-time systems, some waiting tasks are guaranteed to be given the CPU when an external event occurs. Real time systems are designed to control mechanical devices such as industrial robots, which require timely processing.</p><p id="p-0088" num="0090">Encryption based mechanisms are commonly end-to-end processes involving only the sender and the receiver, where the sender encrypts the plain text message by transforming it using an algorithm, making it unreadable to anyone, except the receiver which possesses special knowledge. The data is then sent to the receiver over a network such as the Internet, and when received the special knowledge enables the receiver to reverse the process (decrypt) to make the information readable as in the original message. The encryption process commonly involves computing resources such as processing power, storage space and requires time for executing the encryption/decryption algorithm, which may delay the delivery of the message.</p><p id="p-0089" num="0091">Transport Layer Security (TLS) and its predecessor Secure Sockets Layer (SSL) are non-limiting examples of end-to-end cryptographic protocols, providing secured communication above the OSI Transport Layer, using keyed message authentication code and symmetric cryptography. In client/server applications, the TLS client and server negotiate a stateful connection by using a handshake procedure, during which various parameters are agreed upon, allowing a communication in a way designed to prevent eavesdropping and tampering. The TLS 1.2 is defined in RFC 5246, and several versions of the protocol are in widespread use in applications such as web browsing, electronic mail, Internet faxing, instant messaging and Voice-over-IP (VoIP). In application design, TLS is usually implemented on top of any of the Transport Layer protocols, encapsulating the application-specific protocols such as HTTP, FTP, SMTP, NNTP, and XMPP. Historically, it has been used primarily with reliable transport protocols such as the Transmission Control Protocol (TCP). However, it has also been implemented with datagram-oriented transport protocols, such as the User Datagram Protocol (UDP) and the Datagram Congestion Control Protocol (DCCP), a usage which has been standardized independently using the term Datagram Transport Layer Security (DTLS). A prominent use of TLS is for securing World Wide Web traffic carried by HTTP to form HTTPS. Notable applications are electronic commerce and asset management. Increasingly, the Simple Mail Transfer Protocol (SMTP) is also protected by TLS (RFC 3207). These applications use public key certificates to verify the identity of endpoints. Another Layer 4 (Transport Layer) and upper layers encryption-based communication protocols include SSH (Secure Shell) and SSL (Secure Socket Layer).</p><p id="p-0090" num="0092">Layer 3 (Network Layer) and lower layer encryption based protocols include IPsec, L2TP (Layer 2 Tunneling Protocol) over IPsec, and Ethernet over IPsec. The IPsec is a protocol suite for securing IP communication by encrypting and authenticating each IP packet of a communication session. The IPsec standard is currently based on RFC 4301 and RFC 4309, and was originally described in RFCs 1825-1829, which are now obsolete, and uses the Security Parameter Index (SPI, as per RFC 2401) as an identification tag added to the header while using IPsec for tunneling the IP traffic. An IPsec overview is provided in Cisco Systems, Inc. document entitled: &#x201c;<i>An Introduction to IP Security </i>(<i>IPSec</i>) <i>Encryption</i>&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0091" num="0093">Two common approaches to cryptography are found in U.S. Pat. No. 3,962,539 to Ehrsam et al., entitled &#x201c;Product Block Cipher System for Data Security&#x201d;, and in U.S. Pat. No. 4,405,829 to Rivest et al., entitled &#x201c;Cryptographic Communications System and Method&#x201d;, which are both incorporated in their entirety for all purposes as if fully set forth herein. The Ehrsam patent discloses what is commonly known as the Data Encryption Standard (DES), while the Rivest patent discloses what is commonly known as the RSA algorithm (which stands for Rivest, Shamir and Adleman who first publicly described it), which is widely used in electronic commerce protocols. The RSA involves using a public key and a private key. DES is based upon secret-key cryptography, also referred to as symmetric cryptography, and relies upon a 56-bit key for encryption. In this form of cryptography, the sender and receiver of cipher text both possess identical secret keys, which are, in an ideal world, completely unique and unknown to the world outside of the sender and receiver. By encoding plain text into cipher text using the secret key, the sender may send the cipher text to the receiver using any available public or otherwise insecure communication system. The receiver, having received the cipher text, decrypts it using the secret key to arrive at the plain text.</p><p id="p-0092" num="0094">A proxy server is a server (a computer system or an application) that acts as an intermediary for requests from clients seeking resources from other servers. A client connects to the proxy server, requesting some service, such as a file, connection, web page, or other resource, available from a different server and the proxy server evaluates the request as a way to simplify and control its complexity. Proxies may be used to add structure and encapsulation to distributed systems. Today, most proxies are web proxies, facilitating access to content on the World Wide Web and providing anonymity. A proxy server may reside on the user's local computer, or at various points between the user's computer and destination servers on the Internet. A proxy server that passes requests and responses unmodified is usually called a gateway or sometimes a tunneling proxy. A forward proxy is an Internet-facing proxy used to retrieve from a wide range of sources (in most cases anywhere on the Internet). Forward proxies are proxies in which the client server names the target server to connect to, and are able to retrieve from a wide range of sources (in most cases anywhere on the Internet). An open proxy is a forwarding proxy server that is accessible by any Internet user, while browsing the Web or using other Internet services. There are varying degrees of anonymity, however, as well as a number of methods of &#x2018;tricking&#x2019; the client into revealing itself regardless of the proxy being used. A reverse proxy is usually an Internet-facing proxy used as a front-end to control and protect access to a server on a private network. A reverse proxy commonly also performs tasks such as load-balancing, authentication, decryption or caching.</p><p id="p-0093" num="0095">Randomness is commonly implemented by using random numbers, defined as a sequence of numbers or symbols that lack any pattern and thus appear random, are often generated by a random number generator. Randomness for security is also described in IETF RFC 1750 &#x201c;<i>Randomness Recommendations for Security</i>&#x201d; (December 1994), which is incorporated in its entirety for all purposes as if fully set forth herein. A random number generator (having either analog or digital output) can be hardware based, using a physical process such as thermal noise, shot noise, nuclear decaying radiation, photoelectric effect or other quantum phenomena. Alternatively, or in addition, the generation of the random numbers can be software based, using a processor executing an algorithm for generating pseudo-random numbers which approximates the properties of random numbers.</p><p id="p-0094" num="0096">Onion routing (OR) is a technique for anonymous communication over the Internet or any other computer network. Messages are repeatedly encrypted and then sent through several network nodes called onion routers. Each onion router removes a layer of encryption to uncover routing instructions, and sends the message to the next router where this is repeated. This prevents these intermediary nodes from knowing the origin, destination, and contents of the message. To prevent an adversary from eavesdropping on message content, messages are encrypted between routers. The advantage of onion routing (and mix cascades in general) is that it is not necessary to trust each cooperating router; if one or more routers are compromised, anonymous communication can still be achieved. This is because each router in an OR network accepts messages, re-encrypts them, and transmits to another onion router. The idea of onion routing (OR) is to protect the privacy of the sender and the recipient of a message, while also providing protection for message content as it traverses a network. Onion routing accomplishes this according to the principle of Chaum mix cascades: messages travel from source to destination via a sequence of proxies (&#x201c;onion routers&#x201d;), which re-route messages in an unpredictable path.</p><p id="p-0095" num="0097">Routing onions are data structures used to create paths through which many messages can be transmitted. To create an onion, the router at the head of a transmission selects a number of onion routers at random and generates a message for each one, providing it with symmetric keys for decrypting messages, and instructing it which router will be next in the path. Each of these messages, and the messages intended for subsequent routers, is encrypted with the corresponding router's public key. This provides a layered structure, in which it is necessary to decrypt all outer layers of the onion in order to reach an inner layer. Onion routing is described in U.S. Pat. No. 6,266,704 to Reed et al., entitled: &#x201c;Onion Routing Network for Securely Moving data through Communication Networks&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein. Other prior art publications relating to onion routing are the publications &#x201c;<i>Probabilistic Analysis of Onion Routing in a Black</i>-<i>box Model [Extended Abstract]</i>&#x201d; presented in WPES'07: Proceedings of the 2007 ACM Workshop on Privacy in Electronic Society, &#x201c;<i>A Model of Onion Routing with Provable Anonymity</i>&#x201d; presented in Proceedings of Financial Cryptography and Data Security '07, and &#x201c;<i>A Model of Onion Routing with Provable Anonymity</i>&#x201d;, presented in the Financial Cryptography and Data Security, 11th International Conference, all by Feigenbaum J., Johnson J. and Syverson P., publications &#x201c;<i>Improving Efficiency and Simplicity of Tor circuit establishment and hidden services</i>&#x201d;, Proceedings of the 2007 Privacy Enhancing Technologies Symposium, Springer-Verlag, LNCS 4776, publication &#x201c;<i>Untraceable electronic mail, return addresses, and digital pseudonyms</i>&#x201d; by Chaum D., in Communications of the ACM 24(2), February 1981, and &#x201c;<i>Valet Services: Improving Hidden Servers with a Personal Touch</i>&#x201d;, Proceedings of the 2006 Privacy Enhancing Technologies Workshop, Springer-Verlag, LNCS 4285, both by Overlier L., Syverson P., publications &#x201c;<i>Making Anonymous Communication</i>&#x201d;, Generation 2 Onion Routing briefing slides, Center for High Assurance Computer Systems, naval Research Laboratory, Presented at the National Science Foundation, Jun. 8, 2004 by Syverson P., publications &#x201c;<i>Onion Routing Access Configurations, DISCEX </i>2000: <i>Proceedings of the DARPA Information Survivability Conference and Exposition</i>&#x201d;, Volume I Hilton Head, SC, IEEE CS Press, January 2000, &#x201c;<i>Onion Routing for Anonymous and Private Internet Connections</i>&#x201d; Communications of the ACM, vol. 42, num. 2, February 1999, and &#x201c;<i>Anonymous Connections and Onion Routing</i>&#x201d; IEEE Journal on Selected Areas in Communication Special Issue on Copyright and Privacy Protection, 1998, all by Syverson P., Reed M. G., Goldschlag M., publication &#x201c;<i>Towards an Analysis of Onion Routing Security</i>&#x201d;, and &#x201c;<i>Workshop on Design Issues in Anonymity and Unobservability</i>&#x201d;, Berkeley, Calif., July 2000 by Syverson P., Tsudik G., Reed M. G., and Landwehr C, which are incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0096" num="0098">&#x2018;Tor&#x2019; is an anonymizing network based on the principles of &#x2018;onion routing&#x2019;, and involves a system which selects a randomly chosen route for each connection, via the routers present in the Tor network. The last server appears herein as an &#x2018;exit node&#x2019; and sends the data to the final recipient after leaving the Tor cloud. At this point, it is no longer possible for an observer constantly watching the &#x2018;exit node&#x2019; to determine who the sender of the message was. This concept and its components are known from the Tor project in http://www.torproject.org. The Tor network concept is described in U.S. Patent Application Publication 2010/0002882 to Rieger et al., in the publication &#x201c;<i>Tor: The Second</i>-<i>Generation Onion Router</i>&#x201d;, in Proceedings of the 13th USENIX Security Symposium August 2004, by Dingledine R., Mathewson N., Syverson P., in the publication &#x201c;<i>Tor Protocol specification</i>&#x201d; by Dingledine R. and Mathewson N., in the publication &#x201c;<i>Tor Directory Protocol, Version </i>3&#x201d;, and the publication &#x201c;<i>TC: A Tor Control Protocol</i>&#x201d; downloaded from the Tor web-site, which are incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0097" num="0099">Computer networks may use a tunneling protocol where one network protocol (the delivery protocol) encapsulates a different payload protocol. Tunneling enables the encapsulation of a packet from one type of protocol within the datagram of a different protocol. For example, VPN uses PPTP to encapsulate IP packets over a public network, such as the Internet. A VPN solution based on Point-to-Point Tunneling Protocol (PPTP), Layer Two Tunneling Protocol (L2TP), or Secure Socket Tunneling Protocol (SSTP) can be configured. By using tunneling a payload may be carried over an incompatible delivery-network, or provide a secure path through an untrusted network. Typically, the delivery protocol operates at an equal or higher OSI layer than does the payload protocol. In one example of a network layer over a network layer, Generic Routing Encapsulation (GRE), a protocol running over IP (IP Protocol Number 47), often serves to carry IP packets, with RFC 1918 private addresses, over the Internet using delivery packets with public IP addresses. In this case, the delivery and payload protocols are compatible, but the payload addresses are incompatible with those of the delivery network. In contrast, an IP payload might believe it sees a data link layer delivery when it is carried inside the Layer 2 Tunneling Protocol (L2TP), which appears to the payload mechanism as a protocol of the data link layer. L2TP, however, actually runs over the transport layer using User Datagram Protocol (UDP) over IP. The IP in the delivery protocol could run over any data-link protocol from IEEE 802.2 over IEEE 802.3 (i.e., standards-based Ethernet) to the Point-to-Point Protocol (PPP) over a dialup modem link.</p><p id="p-0098" num="0100">Tunneling protocols may use data encryption to transport insecure payload protocols over a public network (such as the Internet), thereby providing VPN functionality. IPsec has an end-to-end Transport Mode, but can also operate in a tunneling mode through a trusted security gateway. HTTP tunneling is a technique by which communications performed using various network protocols are encapsulated using the HTTP protocol, the network protocols in question usually belonging to the TCP/IP family of protocols. The HTTP protocol therefore acts as a wrapper for a channel that the network protocol being tunneled uses to communicate. The HTTP stream with its covert channel is termed an HTTP tunnel. HTTP tunnel software consists of client-server HTTP tunneling applications that integrate with existing application software, permitting them to be used in conditions of restricted network connectivity including firewalled networks, networks behind proxy servers, and network address translation.</p><p id="p-0099" num="0101">Virtual Private Networks (VPNs) are point-to-point connections across a private or public network, such as the Internet. A VPN client typically uses special TCP/IP-based protocols, called tunneling protocols, to make a virtual call to a virtual port on a VPN server. In a typical VPN deployment, a client initiates a virtual point-to-point connection to a remote access server over the Internet, then the remote access server answers the call, authenticates the caller, and transfers data between the VPN client and the organization's private network. To emulate a point-to-point link, data is encapsulated, or wrapped, with a header. The header provides routing information that enables the data to traverse the shared or public network to reach its endpoint. To emulate a private link, the data being sent is encrypted for confidentiality. Packets that are intercepted on the shared or public network are indecipherable without the encryption keys. The link in which the private data is encapsulated and encrypted is known as a VPN connection. Commonly there are two types of VPN connections, referred to as Remote Access VPN and Site-to-Site VPN. Popular VPN connections use PPTP, L2TP/IPsec, or SSTP protocols. The RFC 4026 provides &#x2018;Provider Provisioned Virtual Private Network (VPN) Terminology&#x2019;, and RFC 2547 provides a VPN method based on MPLS (Multiprotocol Label Switching) and BGP (Border Gateway Protocol).</p><p id="p-0100" num="0102">Remote access VPN connections enable users working at home or on the road to access a server on a private network using the infrastructure provided by a public network, such as the Internet. From the user's perspective, the VPN is a point-to-point connection between the computer (the VPN client) and an organization's server. The exact infrastructure of the shared or public network is irrelevant because it appears logically as if the data is sent over a dedicated private link.</p><p id="p-0101" num="0103">Site-to-site VPN connections (also known as router-to-router VPN connections) enable organizations to have routed connections between separate offices or with other organizations over a public network while helping to maintain secure communications. A routed VPN connection across the Internet logically operates as a dedicated wide area network (WAN) link. When networks are connected over the Internet, a router forwards packets to another router across a VPN connection. To the routers, the VPN connection operates as a data-link layer link. A site-to-site VPN connection connects two portions of a private network. The VPN server provides a routed connection to the network to which the VPN server is attached. The calling router (the VPN client) authenticates itself to the answering router (the VPN server), and, for mutual authentication, the answering router authenticates itself to the calling router. In the site-to site VPN connection, the packets sent from either router across the VPN connection typically do not originate at the routers.</p><p id="p-0102" num="0104">There is a growing widespread use of the Internet for carrying multimedia, such as a video and audio. Various audio services include Internet-radio stations and VoIP (Voice-over-IP). Video services over the Internet include video conferencing and IPTV (IP Television). In most cases, the multimedia service is a real-time (or near real-time) application, and thus sensitive to delays over the Internet. In particular, two-way services such a VoIP or other telephony services and video-conferencing are delay sensitive. In some cases, the delays induced by the encryption process, as well as the hardware/software costs associated with the encryption, render encryption as non-practical. Therefore, it is not easy to secure enough capacity of the Internet accessible by users to endure real-time communication applications such as Internet games, chatting, VoIP, and MoIP (Multimedia-over-IP), so there may be a data loss, delay or severe jitter in the course of communication due to the property of an Internet protocol, thereby causing inappropriate real-time video communication. The following chapters of the publication number 1-587005-001-3 by Cisco Systems, Inc. (July 1999), entitled: &#x201c;<i>Internetworking Technologies Handbook</i>&#x201d;, relate to multimedia carried over the Internet, and are all incorporated in their entirety for all purposes as if fully set forth herein: Chapter 18: &#x201c;<i>Multiservice Access Technologies</i>&#x201d; (pages 18-1 to 18-10), and Chapter 19: &#x201c;<i>Voice/Data Integration Technologies</i>&#x201d; (pages 19-1 to 19-30).</p><p id="p-0103" num="0105">VoIP systems in widespread use today fall into three groups: systems using the ITU-T H.323 protocol, systems using the SIP protocol, and systems that use proprietary protocols. H.323 is a standard for teleconferencing that was developed by the International Telecommunications Union (ITU). It supports full multimedia, audio, video and data transmission between groups of two or more participants, and it is designed to support large networks. H.323 is network-independent: it can be used over networks using transport protocols other than TCP/IP. H.323 is still a very important protocol, but it has fallen out of use for consumer VoIP products due to the fact that it is difficult to make it work through firewalls that are designed to protect computers running many different applications. It is a system best suited to large organizations that possess the technical skills to overcome these problems.</p><p id="p-0104" num="0106">Session Initiation Protocol (SIP) is an Internet Engineering Task Force (IETF) standard signaling protocol for teleconferencing, telephony, presence and event notification and instant messaging. It provides a mechanism for setting up and managing connections, but not for transporting the audio or video data. It is probably now the most widely used protocol for managing Internet telephony. Similar to the IETF protocols, SIP is defined in a number of RFCs, principally RFC 3261. A SIP-based VoIP implementation may send the encoded voice data over the network in a number of ways. Most implementations use a Real-time Transport Protocol (RTP), which is defined in RFC 3550. Both SIP and RTP are implemented on UDP, which, as a connectionless protocol, can cause difficulties with certain types of routers and firewalls. Usable SIP phones therefore also need to use Simple Traversal of UDP over NAT (STUN), a protocol defined in RFC 3489 that allows a client behind a NAT router to find out its external IP address and the type of NAT device.</p><p id="p-0105" num="0107"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows arrangement <b>20</b> of devices communicating over the Internet. Various devices such as client #<b>1</b> <b>24</b><i>a, </i>client #<b>2</b> <b>24</b><i>b, </i>client #<b>3</b> <b>24</b><i>c, </i>client #<b>4</b> <b>24</b><i>d, </i>and client #<b>5</b> <b>24</b><i>e, </i>may communicate over the Internet <b>113</b> for obtaining data from a data server #<b>1</b> <b>22</b><i>a </i>and a data server #<b>2</b> <b>22</b><i>b. </i>In one example, the servers are HTTP servers, sometimes known as web servers. A method describing a more efficient communication over the Internet is described in U.S. Pat. No. 8,560,604 to Shribman et al., entitled: &#x201c;System and Method for Providing Faster and More Efficient Data Communication&#x201d; (hereinafter the &#x201c;&#x2018;604 Patent&#x2019;&#x201d;), which is incorporated in its entirety for all purposes as if fully set forth herein. The method described in the '604 Patent uses an acceleration server <b>32</b> for managing the traffic in the network, as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. A splitting of a message or a content into slices, and transferring each of the slices over a distinct data path is described in U.S. Patent Application No. 2012/0166582 to Binder entitled: &#x201c;System and Method for Routing-Based Internet Security&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0106" num="0108">A Cyclic Redundancy Check (CRC) is an error-detecting code commonly used in digital networks and storage devices to detect accidental changes to raw data. Blocks of data entering these systems get a short check value attached, based on the remainder of a polynomial division of their contents; on retrieval the calculation is repeated, and corrective action can be taken against presumed data corruption if the check values do not match. Ethernet commonly uses 32-bit CRC function. Specification of a CRC code requires definition of a so-called generator polynomial. The polynomial becomes a divisor in a polynomial long division, which takes the message as the dividend, and in which the quotient is discarded and the remainder becomes the result. The important caveat that the polynomial coefficients are calculated according to the arithmetic of a finite field, so the addition operation can always be performed bitwise-parallel (there is no carry between digits). The length of the remainder is always less than the length of the generator polynomial, which therefore determines how long the result can be. In practice, all commonly used CRCs employ the finite field GF(2). This is the field of two elements, usually called 0 and 1, comfortably matching computer architecture.</p><p id="p-0107" num="0109">A CRC is referred to as an n-bit CRC when its check value is n bits. For a given n, multiple CRCs are possible, each with a different polynomial. Such a polynomial has highest degree n, which means it has n+1 terms. In other words, the polynomial has a length of n+1; its encoding requires n+1 bits. Note that most integer encodings either drop the Most Significant Bit (MSB) or Least Significant Bit (LSB), since they are always 1. The CRC and associated polynomial typically have a name of the form CRC-n-XXX. The simplest error-detection system, the parity bit, is in fact a trivial 1-bit CRC: it uses the generator polynomial x+1 (two terms), and has the name CRC-1. Computation of a cyclic redundancy check is derived from the mathematics of polynomial division, modulo two. In practice, it resembles long division of the binary message string, with a fixed number of zeroes appended, by the &#x201c;generator polynomial&#x201d; string except that exclusive OR operations replace subtractions. Division of this type is efficiently realised in hardware by a modified shift register and in software by a series of equivalent algorithms, starting with simple code close to the mathematics and becoming faster through byte-wise parallelism and space-time tradeoffs.</p><p id="p-0108" num="0110">Various CRC standards extend the polynomial division algorithm by specifying an initial shift register value, a final exclusive OR step and, most critically, a bit ordering (endianness). As a result, the code seen in practice deviates confusingly from &#x201c;pure&#x201d; division, and the register may shift left or right. The most important attribute of the polynomial is its length (largest degree&#x2014;exponent&#x2014;+1 of any one term in the polynomial), because of its direct influence on the length of the computed check value. The most commonly used polynomial lengths are 9 bits (CRC-8), 17 bits (CRC-16), 33 bits (CRC-32), and 65 bits (CRC-64). A calculation of CRC-32 is described in the publication entitled: &#x201c;32-<i>Bit Cyclic Redundancy Codes for Internet Applications</i>&#x201d; by Philip Koopman of Carnegie Mellon University, presented at The International Conference on Dependable Systems and Networks (DSN) 2002.</p><p id="p-0109" num="0111">A CRC is an example of a hash function, which refers to any function that can be used to map data of arbitrary size to data of fixed size, with slight differences in input data producing very big differences in an output data. Values returned by the hash function are called hash values, hash codes, hash sums, or simply hashes. Hash values are commonly used to differentiate between data. For example, in implementing a set in software, one has to avoid including an element more than once. Recent developments in internet payment networks also uses a form of &#x2018;hashing&#x2019; for producing checksums, bringing additional attention to the term. Hash functions are primarily used to generate fixed-length output data that act as a shortened reference to the original data. This is useful when the original data is too cumbersome to use in its entirety. Hash functions commonly include checksums, check digits, fingerprints, randomization functions, error-correcting codes, and ciphers.</p><p id="p-0110" num="0112">One practical use is a data structure called a hash table where the data is stored associatively. Searching linearly for a person's name in a list becomes cumbersome as the length of the list increases, but the hashed value can be used to store a reference to the original data and retrieve constant time (barring collisions). Another use is in cryptography, the science of encoding and safeguarding data. It is easy to generate hash values from input data and easy to verify that the data matches the hash, but for certain hash functions hard to &#x2018;fake&#x2019; a hash value to hide malicious data. Hash functions are also frequently used to accelerate table lookup or data comparison tasks such as finding items in a database, detecting duplicated or similar records in a large file and finding similar stretches in DNA sequences. A hash function should be deterministic: when it is invoked twice on identical data (e.g. two strings containing exactly the same characters), the function should produce the same value. This is crucial to the correctness of virtually all algorithms based on hashing. In the case of a hash table, the lookup operation should look at the slot where the insertion algorithm actually stored the data that is being sought for, so it needs the same hash value.</p><p id="p-0111" num="0113">Hash functions used to accelerate data searches typically produce smaller hash values, such as a 32 bit integer. On the other hand, cryptographic hash functions produce much larger hash value, in order to ensure the computational complexity of brute-force inversion. For example SHA-1, one of the most widely used cryptographic hash functions, produces a 160-bit value. In both cases, the hash function breaks the input data into chunks of specific size. Hash functions used for data searches use an arithmetic expression which iteratively processes those chunks (such as the characters in a string) to produce the hash value. In cryptographic hash functions, these chunks are processed by a one-way compression function, with the last chunk being padded if necessary. In this case, their size, which is called block size, is much bigger than the size of the hash value. For example, in SHA-1, the hash value is 160 bits and the block size 512 bits.</p><p id="p-0112" num="0114">A hash table (a.k.a. Hash map) is a data structure that associates keys with values, and is commonly used to support a lookup: given a key (e.g., a person's name), find the corresponding value (e.g., that person's telephone number), thus allowing to use a number to locate a desired value in a table. Hash tables are typically used to implement an associative array, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the correct value can be found. The hash function may assign each key to a unique bucket, but typically hash table designs assume that hash collisions&#x2014;different keys that are assigned by the hash function to the same bucket&#x2014;will occur and must be accommodated in some way. In a well-dimensioned hash table, the average cost (number of instructions) for each lookup is independent of the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key-value pairs, at a constant average cost per operation. In many situations, hash tables turn out to be more efficient than search trees or any other table lookup structure, and thus are widely used in many kinds of computer software, particularly for associative arrays, database indexing, caches, and sets.</p><p id="p-0113" num="0115">Filter driver. A filter driver is a Microsoft Windows compatible driver that extends or modifies the function of peripheral devices or supports a specialized device in a personal computer. It is a driver or program or module that is inserted into the existing driver stack to perform some specific function, while not affecting the normal working of the existing driver stack in any major way. Any number of filter drivers can be added to Windows, where upper level filter drivers sit above the primary driver for the device (the function driver), while lower level filter drivers sit below the function driver and above a bus driver. Filter drivers may work on a certain brand of device such as a mouse or keyboard, or they may perform some operation on a class of devices, such as any mouse or any keyboard. A filter driver may be developed using the guide entitled: &#x201c;<i>Filter Driver Development Guide</i>&#x201d; Version <b>1</b>.<b>0</b><i>a </i>by Microsoft Corporation, dated 2004, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0114" num="0116">Hook. A hook (also known as a hook procedure or hook function) is a mechanism by which an application can intercept events, such as messages, mouse actions, and keystrokes, and generally refers to a function provided by a software application that receives certain data before the normal or intended recipient of the data. The hook function can thus examine or modify certain data before passing on the data. Therefore, a hook function allows a software application to examine data before the data is passed to the intended recipient. A function that intercepts a particular type of event is known as a hook procedure. The hook procedure can act on each event it receives, and then modify or discard the event. The term &#x2018;hooking&#x2019; is used herein to include, but not limited to, a range of techniques used to alter or augment the behavior of an operating system, of applications, or of other software components by intercepting function calls, messages, or events passed between software components. A code that handles such intercepted function calls, events or messages is called a &#x201c;hook&#x201d;. Hooking is used for many purposes, including debugging and extending functionality. Examples might include intercepting keyboard or mouse event messages before they reach an application, or intercepting operating system calls in order to monitor behavior or modify the function of an application or other component. It is also widely used in benchmarking programs, for example frame rate measuring in 3D games, where the output and input is done through hooking. Hooking is described, for example, in the presentations by High-Tech Bridge SA and titled: &#x201c;<i>Userland Hooking in Windows</i>&#x201d; dated August 2011, and &#x201c;<i>Inline Hooking in Windows</i>&#x201d; dated September 2011, both by Brian Mariani, and both incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0115" num="0117">Physical modification. An hooking may be achieved by physically modifying an executable or library before an application is running through techniques of reverse engineering. This is typically used to intercept function calls to either monitor or replace them entirely. For example, by using a disassembler, the entry point of a function within a module can be found. It can then be altered to instead dynamically load some other library module and then have it execute desired methods within that loaded library. If applicable, another related approach by which hooking can be achieved is by altering an import table of an executable. This table can be modified to load any additional library modules as well as changing what external code is invoked when a function is called by an application. An alternate method for achieving the function of hooking is by intercepting function calls through a wrapper library. When creating a wrapper, you make your own version of a library that an application loads, with all the same functionality of the original library that it will replace, so all the functions that are accessible are essentially the same between the original and the replacement. This wrapper library can be designed to call any of the functionality from the original library, or replace it with an entirely new set of logic.</p><p id="p-0116" num="0118">Runtime modification. Operating systems and software may provide the means to easily insert event hooks at runtime, as long as the process inserting the hook is granted enough permission to do so. Microsoft Windows allows to insert hooks that can be used to process or modify system events and application events for dialogs, scrollbars, and menus, as well as other items. It also allows a hook to insert, remove, process, or modify keyboard and mouse events. Linux provides another example where hooks can be used in a similar manner to process network events within the kernel through NetFilter. When such functionality is not provided, a special form of hooking employs intercepting library function calls that are made by a process. Function hooking is implemented by changing the very first few code instructions of the target function to jump to an injected code. Alternatively on systems using the shared library concept, the interrupt vector table or the import descriptor table can be modified in memory.</p><p id="p-0117" num="0119">A hook chain is a list of pointers to special, application-defined callback functions called hook procedures. When a message occurs that is associated with a particular type of hook, the operating system passes the message to each hook procedure referenced in the hook chain, one after the other. The action of a hook procedure can depend on the type of hook involved. For example, the hook procedures for some types of hooks can only monitor messages, others can modify the messages or stop their progress through the chain, restricting them from reaching the next hook procedure or a destination window.</p><p id="p-0118" num="0120">Plug-in. A plug-in (or &#x2018;plugin&#x2019;, &#x2018;extension&#x2019;, or &#x2018;add-on&#x2019;/&#x2018;addon&#x2019;) is a software component that adds a specific feature to an existing software application, for example for enabling customization. The common examples are the plug-ins used in web browsers to add new features such as search-engines, virus scanners, or the ability to utilize a new file type such as a new video format. An &#x2018;Add-on&#x2019; (or &#x2018;addon&#x2019;) is the general term for what enhances an application, and comprises snap-in, plug-in, theme, and skin. An extension add-on tailors the core features of an application by adding an optional module, whereas a plug-in add-on would tailor the outer layers of an application to personalize functionality. A theme or a skin add-on is a preset package containing additional or changed graphical appearance details, achieved by the use of a Graphical User Interface (GUI) that can be applied to a specific software and websites to suit the purpose, topic, or tastes of different users to customize the look and feel of a piece of computer software or an operating system front-end GUI (and window managers).</p><p id="p-0119" num="0121">Typically, the host application provides services which the plug-in can use, including a way for plug-ins to register themselves with the host application and a protocol for the exchange of data with plug-ins. Plug-ins depend on the services provided by the host application and do not usually work by themselves. Conversely, the host application operates independently of the plug-ins, making it possible for end-users to add and update plug-ins dynamically without needing to make changes to the host application. The term &#x2018;plug-in&#x2019; is used herein to include, but not limited to, a software extension, which is software that serves to extend the capabilities of, or data available to an existing software application; it becomes included in the program. Therefore, after integration, extensions can be seen as part of the browser itself, tailored from a set of optional modules.</p><p id="p-0120" num="0122">IPC. An Inter-Process Communication (IPC) (also be referred to as inter-thread communication and inter-application communication) is a set of methods for the exchange of data between multiple threads, in one or more processes. IPC methods may use message passing, synchronization, shared memory, and Remote Procedure Calls (RPC). IPC provides an environment that allows process cooperation, and may be used for providing Information sharing, computational speedup, modularity, convenience, and privilege separation. In the Windows operating system environment, the IPC provides mechanisms for facilitating communications and data sharing between processes or applications.</p><p id="p-0121" num="0123">Common IPC methods include file sharing, where a record (or any other information) stored on disk (or any other memory) can be accessed by name by any process; a signal which is an asynchronous notification sent to a process or to a specific thread within the same process in order to notify it of an event that occurred; a socket which is a data stream sent over a network interface, either to a different process on the same computer or to another computer, such as Internet sockets; a pipe (or pipeline) which is a two-way data stream interfaced through standard input and output and is read character by character, commonly used in Unix-like computer operating systems; message queues which are anonymous data stream similar to the pipe that stores and retrieves information in packets, providing an asynchronous communications protocol; a semaphore which is a variable or abstract data type that is used for controlling access to a common resource; a shared memory which is a memory that may be simultaneously accessed by multiple programs with an intent to provide communication among them or avoid redundant copies, such as where one process creates an area in RAM which other processes can access; and memory mapped file, where a file that is physically present on-disk, but can also be a device, shared memory object, or other resource that the operating system can reference through a file descriptor. Few IPC mechanisms are described in the Marko Vuskovic publication &#x2018;Operating Systems&#x2019; in Chapter 9 entitled: &#x201c;<i>INTERPROCESS COMMUNICATION</i>&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0122" num="0124">The Windows operating system supports IPC mechanisms such as a clipboard, where the clipboard acts as a central depository for data sharing among applications, so when a user performs a cut or copy operation in an application, the application puts the selected data on the clipboard in one or more standard or application-defined formats, and any other application can then retrieve the data from the clipboard, choosing from the available formats that it understands; using Component Object Model (COM), where applications that use Object Linking and Embedding (OLE) manage compound documents can be used to call on other applications for data editing; Using Data Copy enabling an application to send information to another application using the WM_COPYDATA message; DDE protocol that enables applications to exchange data in a variety of formats; and mailslots providing one-way communication where processes write messages to their mailslot.</p><p id="p-0123" num="0125">Browser extension. A browser extension is a computer program that extends the functionality of a web browser in some way. Extensions can be created through use of web technologies such as HTML, JavaScript, and CSS. Browser extensions can also improve the user interface of the web browser without directly affecting viewable content of a web page, which can be achieved through a variety of add ons such as toolbars and plug-ins. Microsoft Internet Explorer started supporting extensions from version 5 released in 1999. Mozilla Firefox has supported extensions since its launch in 2004. The Opera desktop web browser supported extensions from version 10 released in 2009. Google Chrome started supporting extensions from version <b>4</b> released in 2010. The Apple Safari web browser started supporting native extensions from version <b>5</b> released in 2010. The syntax for extensions may differ from browser to browser, or at least enough different that an extension working on a browser does not work on another one.</p><p id="p-0124" num="0126">Plug-ins add specific abilities into browsers using Application Programming Interfaces (APIs) allowing third parties to create plug-ins that interact with the browser. The original API was NPAPI, but subsequently Google introduced the PPAPI interface in Chrome. In addition, plug-ins allow browser extensions to perform tasks such as blocking ads, creating a secure online connection, and adding applications within a browser. Well-known browser plug-ins include the Adobe Flash Player, the QuickTime Player, and the Java plug-in, which can launch a user-activated Java applet on a web page to its execution a local Java virtual machine.</p><p id="p-0125" num="0127">Sockets. A socket (a.k.a. &#x2018;network socket&#x2019;) is an endpoint of an IPC flow across a computer network. In the case the communications is based on IP (Internet Protocol), the network sockets are referred to as Internet sockets. A socket API is an application programming interface (API), usually provided by the operating system, that allows application programs to control and use network sockets. Internet socket APIs are usually based on the Berkeley sockets standard. A socket address is the combination of an IP address and a port number, similar to one end of a telephone connection in the combination of a phone number and a particular extension. Based on this address, internet sockets deliver incoming data packets to the appropriate application process or thread. Sockets are further described in a Universoty of Toronto, Department of Computer Science presentation entitled: &#x201c;<i>Tutorial on Socket Programming</i>&#x201d; by Amin Tootoonchian, downloaded on August, 2014, and in the SAS Institute Inc. SHARE Session 5958 tutorial &#x2018;C Socket Programming Tutorial&#x2019; entitled: &#x201c;<i>Writing Client/Server Programs in C Using Sockets </i>(<i>A Tutorial</i>) <i>Part I</i>&#x201d;, by Greg Granger, dated February of 1998, which are both incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0126" num="0128">An Internet socket is characterized by a unique combination of a Local socket address (Local IP address and port number), remote socket address (used for established TCP sockets), and the used Protocol, typically a transport protocol (e.g., TCP, UDP, raw IP, or others). Within the operating system and the application that created a socket, a socket is referred to by a unique integer value called a socket descriptor. The operating system forwards the payload of incoming IP packets to the corresponding application by extracting the socket address information from the IP and transport protocol headers and stripping the headers from the application data.</p><p id="p-0127" num="0129">Several Internet socket types are available, such as Datagram sockets, also known as connectionless sockets, which use User Datagram Protocol (UDP), Stream sockets, also known as connection-oriented sockets, which use Transmission Control Protocol (TCP) or Stream Control Transmission Protocol (SCTP), and Raw sockets (or Raw IP sockets), typically available in routers and other network equipment. Here the transport layer is bypassed, and the packet headers are made accessible to the application. Other socket types are implemented over other transport protocols, such as Systems Network Architecture (SNA). Communicating local and remote sockets are called socket pairs. Each socket pair is described by a unique <b>4</b>-tuple consisting of source and destination IP addresses and port numbers, i.e. of local and remote socket addresses. In the TCP case, each unique socket pair 4-tuple is assigned a socket number, while in the UDP case, each unique local socket address is assigned a socket number.</p><p id="p-0128" num="0130">The socket is primarily a concept used in the Transport Layer of the Internet model. Networking equipment such as routers and switches do not require implementations of the Transport Layer, as they operate on the Link Layer level (switches) or at the Internet Layer (routers). However, stateful network firewalls, network address translators, and proxy servers keep track of active socket pairs. Also in fair queuing, layer 3 switching and quality of service (QoS) support in routers, packet flows may be identified by extracting information about the socket pairs. Raw sockets are typically available in network equipment and are used for routing protocols such as IGRP and OSPF, and in Internet Control Message Protocol (ICMP).</p><p id="p-0129" num="0131">The amount of data transferred in a given period in commonly referred to as &#x2018;bandwidth&#x2019; (BW) or &#x2018;bit-rate&#x2019;, which is the number of bits that are conveyed or processed per unit of time. The bit rate is quantified using the bits per second unit (symbol bit/s or b/s), often in conjunction with an SI prefix such as kilo&#x2014;(1 kbit/s=1000 bit/s), mega&#x2014;(1 Mbit/s=1000 kbit/s), giga&#x2014;(1 Gbit/s=1000 Mbit/s) or tera&#x2014;(1 Tbit/s=1000 Gbit/s). The non-standard abbreviation bps is often used to replace the standard symbol bit/s, so that, for example, &#x201c;1 Mbps&#x201d; (or 1 Mb/s) is used to mean one million bits per second. One byte per second (1 B/s) corresponds to 8 bit/s.</p><p id="p-0130" num="0132">Latency is typically defined as a time interval between the stimulation and the response, or, from a more general point of view, as a time delay between the cause and the effect of some physical change in the system being observed. Network-related latency, such as in a packet-switched network, is measured either one-way (the time from the source sending a packet to the destination receiving it), or Round-Trip delay Time (RTT), referring to the one-way latency from source to destination plus the one-way latency from the destination back to the source, plus any delays at the destination, such as processing or other delays. Round-trip latency can be measured from a single point. Latency limits total bandwidth in reliable two-way communication systems as described by the bandwidth-delay product, which refers to the product of a data link's capacity (in bits per second) and its end-to-end delay (in seconds). The result, an amount of data measured in bits (or bytes), is equivalent to the maximum amount of data on the network circuit at any given time, i.e., data that has been transmitted but not yet acknowledged. Sometimes it is calculated as the data link's capacity multiplied by its round trip time. A network with a large bandwidth-delay product is commonly known as a Long Fat Network (LFN). As defined in IETF RFC 1072, a network is considered an LFN if its bandwidth-delay product is significantly larger than 105 bits (12500 bytes).</p><p id="p-0131" num="0133">The Round-trip Delay Time (RTD) or Round-Trip Time (RTT) is the length of time it takes for a signal to be sent and to be received and processed at the destination node, plus the length of time it takes for an acknowledgment of that signal to be received. This time delay therefore includes the propagation times between the two points of a signal. The signal is generally a data packet, and the RTT is also known as the ping time, and an internet user can determine the RTT by using the ping command. Network links with both a high bandwidth and a high RTT can have a very large amount of data (the bandwidth-delay product) &#x201c;in flight&#x201d; at any given time. Such &#x201c;long fat pipes&#x201d; require a special protocol design. One example is the TCP window scale option. The RTT was originally estimated in TCP by: RTT=(a Old RTT)+((1&#x2212;&#x3b1;)&#xb7;New_Round_Trip Sample), where a is a constant weighting factor (0&#x2264;&#x3b1;&#x3c;1). Choosing a value a close to 1 makes the weighted average immune to changes that last a short time (e.g., a single segment that encounters long delay). Choosing a value for &#x3b1; close to 0 makes the weighted average response to changes in delay very quickly. Once a new RTT is calculated, it is entered into the above equation to obtain an average RTT for that connection, and the procedure continues for every new calculation. The RTT may be measured as described in IETF 1323, and may be estimated by using a method described in IETF RFC 6323, which are both incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0132" num="0134">An estimation of RTT for messages using TCP may use Karn's Algorithm, described by Karn, Phil and Craig Partridge in ACM SIGCOMM '87&#x2014;Computer Communication Review publication, entitled: &#x201c;<i>Improving Round</i>-<i>Trip Time Estimates in Reliable Transport Protocols</i>&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein. The round trip time is estimated as the difference between the time that a segment was sent and the time that its acknowledgment was returned to the sender, but when packets are re-transmitted there is an ambiguity: the acknowledgment may be a response to the first transmission of the segment or to a subsequent re-transmission. Karn's Algorithm ignores re-transmitted segments when updating the round trip time estimate. Round trip time estimation is based only on unambiguous acknowledgments, which are acknowledgments for segments that were sent only once.</p><p id="p-0133" num="0135">Many software platforms provide a service called &#x2018;ping&#x2019; that can be used to measure round-trip latency. Ping performs no packet processing; it merely sends a response back when it receives a packet (i.e., performs a no-op), thus it is a first rough way of measuring latency. Ping operates by sending Internet Control Message Protocol (ICMP) echo requesting packets to the target host, and waiting for an ICMP response. During this process it measures the time from transmission to reception (round-trip time) and records any packet loss. The results of the test are printed in a form of a statistical summary of the response packets received, including the minimum, maximum, and the mean round-trip times, and sometimes the standard deviation of the mean.</p><p id="p-0134" num="0136">The Transmission Control Protocol/Internet Protocol (TCP/IP) suite normally used on the Internet has included an Internet Message Control Protocol (ICMP) that is commonly used in echo testing or ping and trace route applications. In general, the Internet standard &#x2018;ping&#x2019; or &#x2018;ICMP echo&#x2019; has a request/response format, wherein one device sends an ICMP echo request and another device responds to a received ICMP echo request with a transmitted ICMP echo response. Normally, IP devices are expected to implement the ICMP as part of the support for IP, to be able to use ICMP for testing. Internet RFC 792, entitled &#x201c;<i>Internet Control Message Protocol: DARPA Internet Program Protocol Specification</i>&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein, at least partially describes the behavior of ICMP. The ICMP echo message has a type field, a code field, a checksum field, an identifier field, a sequence number field, and a data field. According to RFC 79: &#x201c;<i>The data received in the echo message must be returned in the echo reply message</i>&#x201d;. Thus, an RFC compliant ping responders or an ICMP echo reply message responders are supposed to copy the received data field in an echo request message directly into the data field of the transmitted echo response message.</p><p id="p-0135" num="0137">A newer version of ICMP known as ICMP version 6 or ICMPv6 as described at least partially in RFCs 1885 and 2463, which are both entitled &#x201c;<i>Internet Control Message Protocol </i>(<i>ICMPv</i>6) <i>for the Internet Protocol Version </i>6 (<i>IPv</i>6) <i>Specification</i>&#x201d;, which are both incorporated in their entirety for all purposes as if fully set forth herein. According to RFC 2463, &#x201c;<i>Every [IPv</i>6] <i>node MUST implement an ICMPv</i>6 <i>Echo responder function that receives Echo Requests and sends corresponding Echo Replies. An IPv</i>6 <i>node SHOULD also implement an application</i>-<i>layer interface for sending Echo Requests and receiving Echo Replies, for diagnostic purposes.</i>&#x201d;. Thus, responding to ICMP echo requests normally is a necessary function in supporting IPv4 and/or IPv6 standards. The ICMPv6 RFCs 1885 and 2464 goes on to specify that the data field of an ICMP echo response contains the &#x201c;data from the invoking Echo Request message.&#x201d; Therefore, both ICMP and ICMP v6 associated with IPv4 and IPv6, respectively, specify that the data field in an ICMP echo reply message is to essentially contain a copy of the data received in the corresponding ICMP echo request message.</p><p id="p-0136" num="0138">Moreover, the ICMP echo protocol is basically a two-way echo in which one initiating device and/or process starts the communication by transmitting an echo request message, which may be then received by an echo responder process. The echo responder process, generally located on another device, receives the echo request message and responds with an echo reply back to the initiating process. Once the initiating device and/or process receives the response or times out waiting on the response, the two-way echo exchange of messages is complete. Although the echo request and echo response normally are performed between processes on two different devices, one skilled in the art will be aware that a device can ping its own IP address implying that the echo request and echo responder reply processes are on the same device. In addition, the loopback address of network 127.0.0.0 in IPv4 can be used to allow a device to the loopback outbound echo request messages back into the device's own incoming echo request responder processes. IPv6 has a loopback functionality as well.</p><p id="p-0137" num="0139">This copying of data exactly in the ICMP echo response is somewhat wasteful because the responder generally does not convey that much (if any) information back to the ICMP echo request initiating device. Arguably the initiating device could compute bit error rate (BER) statistics on the transmitted versus the received data field in ICMP echo packets. However, such physical layer issues as BER statistics normally are not as relevant for network layer IP datagranis that already include various error control code mechanisms. Arguably the device running the responding process can communicate information to the device running the initiating process by having the device running the original responding process initiate its own echo request and wait for an echo response from the original initiating device. Such a solution results in four packets, with a first echo request from a local device responded to by a first echo response from a remote device, and with a second echo request from the remote device responded to by a second echo response from the local device.</p><p id="p-0138" num="0140">An identifier and/or sequence number in ping packets generally has allowed the ping to be used by a device to determine the round-trip delay from the time an ICMP echo request packet is sent to the time corresponding to when an associated received ICMP echo request is received back at an initiating device. Furthermore, ping packets generally convey little or no information about the type of the device that initiated the ping. Moreover, although IPv4 has Type of Service (ToS) fields in the IP datagram, these fields have become more important as the services used over the Internet and networks using Internet technology have grown from basic computer data communication to also include real-time applications such as voice and/or video. Various Type of Service (ToS) in IPv4 and IPv6 have been used in implementing various (Quality of Service) QoS characteristics that are defined for different classes of service and/or Service Level Agreements (SLAs).</p><p id="p-0139" num="0141">Timestamp. A timestamp is a sequence of characters or encoded information identifying when a certain event occurred, usually giving date and time of day, sometimes accurate to a small fraction of a second, and also refers to digital date and time information attached to the digital data. For example, computer files contain timestamps that tell when the file was last modified, and digital cameras add timestamps to the pictures they take, recording the date and time the picture was taken. A timestamp is typically the time at which an event is recorded by a computer, not the time of the event itself In many cases, the difference may be inconsequential: the time at which an event is recorded by a timestamp (e.g., entered into a log file) should be close to the time of the event. Timestamps are typically used for logging events or in a Sequence of Events (SOE), in which case each event in the log or SOE is marked with a timestamp. In a file system such as a database, timestamp commonly mean the stored date/time of creation or modification of a file or a record. The ISO 8601 standard standardizes the representation of dates and times which are often used to construct timestamp values, and IETF RFC 3339 defines a date and time format for use in Internet protocols using the ISO 8601 standard representation.</p><p id="p-0140" num="0142">Caching. A system and method for increasing cache size by performing the steps of: categorizing storage blocks within a storage device as within a first category of storage blocks if the storage blocks that are available to the system for storing data when needed; categorizing storage blocks within the storage device as within a second category of storage blocks if the storage blocks contain application data therein; and categorizing storage blocks within the storage device as within a third category of storage blocks if the storage blocks are storing cached data and are available for storing application data if no first category of storage blocks are available to the system, is described in U.S. Pat. No. 8,135,912 to Shribman et al. entitled: &#x201c;System and Method of Increasing Cache Size&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein. A system for resolving Domain Name System (DNS) queries that contains a communication device for resolving DNS queries, wherein the communication device further contains a memory and a processor that is configured by the memory, a cache storage for use by the communication device, and a network of authoritative domain name servers, where in a process of the communication device looking up a DNS request within the cache storage, if the communication device views an expired DNS entry within the cache storage, the communication device continues the process of looking up the DNS request in the cache storage while, in parallel, sending out a concurrent DNS request to an authoritative domain name server that the expired DNS entry belongs to, is described in U.S. Pat. No. 8,671,221 to the same inventors as this application, entitled: &#x201c;Method and System for Increasing Speed of Domain Name System Resolution within a Computing Device&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0141" num="0143">Systems and methods of storing previously transmitted data and using it to reduce bandwidth usage and accelerate future communications, and using algorithms to identify long compression history matches. A network device that may improve compression efficiency and speed is described in U.S. Pat. No. 7,865,585 to Samuels et al., entitled: &#x201c;Systems and Methods for Providing Dynamic Ad Hok Proxy-Cache Hierarchies&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein. Further, a method and system for accelerating the receipt of data in a client-to-client network described in U.S. Pat. No. 7,203,741 to Marco et al., entitled: &#x201c;Method and System for Accelerating Receipt of Data in a Client-to-Client Networld&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0142" num="0144">Hearbeat. A heartbeat is a periodic signal generated by hardware or software to indicate normal operation or to synchronize other parts of a system. Usually a heartbeat is sent between machines at a regular interval of an order of seconds. If a heartbeat is not received for a time&#x2014;usually a few heartbeat intervals&#x2014;the machine that should have sent the heartbeat is assumed to have failed. As used herein, a heartbeat is a periodic message, such as a &#x2018;ping&#x2019;, generated by devices connected to the Internet to indicate being &#x2018;online&#x2019; (connected to the Internet) and normal operation, and if a heartbeat is not received for a time, the device is assumed to be &#x2018;offline&#x2019; (not connected to the Internet). A heartbeat protocol is generally used to negotiate and monitor the availability of a resource, such as a floating IP address. Typically, when a heartbeat starts on a machine, it will perform an election process with other machines on the network to determine which machine, if any, owns the resource. The IETF RFC 6520 describes Heartbeat operation for the Transport Layer Security (TLS), and is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0143" num="0145">Users in the Internet may desire anonymity in order not to be identified as a publisher (sender), or reader (receiver), of information. Common reasons include censorship at the local, organizational, or national level, personal privacy preferences such as preventing tracking or data mining activities, the material or its distribution is considered illegal or incriminating by possible eavesdroppers, the material may be legal but socially deplored, embarrassing, or problematic in the individual's social world, and fear of retribution (against whistleblowers, unofficial leaks, and activists who do not believe in restrictions on information nor knowledge). Full anonymity on the Internet, however, is not guaranteed since IP addresses can be tracked, allowing to identify the computer from which a certain post was made, albeit not the actual user. Anonymizing services, such as I2P&#x2014;&#x2018;The Anonymous Network&#x2019; or Tor, address the issue of IP tracking, as their distributed technology approach may grant a higher degree of security than centralized anonymizing services where a central point exists that could disclose one's identity. An anonymous web browsing refers to browsing the World Wide Web while hiding the user's IP address and any other personally identifiable information from the websites that one is visiting. There are many ways of accomplishing anonymous web browsing. Anonymous web browsing is generally useful to internet users who want to ensure that their sessions cannot be monitored. For instance, it is used to circumvent traffic monitoring by organizations that want to find out or control which web sites employees visit. Further, since some web-sites response differently when approached from mobile devices, anonymity may allow for accessing such a web-site from a non-mobile device, posing as a mobile device.</p><p id="p-0144" num="0146">WiFi. A device herein (such as device <b>11</b>) may consist of, be part of, or include, a Personal Computer (PC), a desktop computer, a mobile computer, a laptop computer, a notebook computer, a tablet computer, a server computer, a handheld computer, a handheld device, a Personal Digital Assistant (PDA) device, or a cellular handset. Alternatively or in addition, a device may consist of, be part of, or include, a handheld PDA device, an on-board device, an off-board device, a hybrid device, a vehicular device, a non-vehicular device, a mobile device, or a portable device. A network herein (such as LAN <b>14</b>), may consist of, be part of, or include, a wired or wireless network, a Local Area Network (LAN), a Wireless LAN (WLAN), a Metropolitan Area Network (MAN), a Wireless MAN (WMAN), a Wide Area Network (WAN), a Wireless WAN (WWAN), a Personal Area Network (PAN), or a Wireless PAN (WPAN). Alternatively or in addition, a network herein may be operating substantially in accordance with existing IEEE 802.11, 802.11a, 802.11b, 802.11g, 802.11k, 802.11n, 802.11r, 802.16, 802.16d, 802.16e, 802.20, 802.21 standards and/or future versions and/or derivatives of the above standards. Further, a network element (or a device) herein may consist of, be part of, or include, a cellular radio-telephone communication system, a cellular telephone, a wireless telephone, a Personal Communication Systems (PCS) device, a PDA device which incorporates a wireless communication device, or a mobile/portable Global Positioning System (GPS) device. The communication interface <b>29</b> may consist of, be part of, or include, a transceiver or modem for communication with the network, such as LAN <b>14</b>. In the case of wired networks, the communication interface <b>29</b> connects to the network via a port <b>28</b> that may include a connector, and in the case of wireless network, the communication interface <b>29</b> connects to the network via a port <b>28</b> that may include an antenna.</p><p id="p-0145" num="0147">The LAN <b>14</b> may be a Wireless LAN (WLAN) such as according to, or base on, IEEE 802.11-2012, and the WLAN port may be a WLAN antenna and the WLAN transceiver may be a WLAN modem. The WLAN may be according to, or base on, IEEE 802.11a, IEEE 802.11b, IEEE 802.11g, IEEE 802.11n, or IEEE 802.11ac. Commonly referred to as Wireless Local Area Network (WLAN), such communication makes use of the Industrial, Scientific and Medical (ISM) frequency spectrum. In the US, three of the bands within the ISM spectrum are the A-Band, 902-928 MHz; the B-Band, 2.4-2.484 GHz (a.k.a. 2.4 GHz); and the C-Band, 5.725-5.875 GHz (a.k.a. 5 GHz). Overlapping and/or similar bands are used in different regions such as Europe and Japan. In order to allow interoperability between equipment manufactured by different vendors, few WLAN standards have evolved, as part of the IEEE 802.11 standard group, branded as WiFi (www.wi-fi.org). The IEEE 802.11b standard describes a communication using the 2.4 GHz frequency band and supporting a communication rate of 11 Mb/s, IEEE 802.11a uses the 5 GHz frequency band to carry 54 MB/s, and IEEE 802.11g uses the 2.4 GHz band to support 54 Mb/s. The WiFi technology is further described in a publication entitled: &#x201c;WiFi Technology&#x201d; by Telecom Regulatory Authority, published on July 2003, which is incorporated in its entirety for all purposes as if fully set forth herein. The IEEE 802 defines an ad-hoc connection between two or more devices without using a wireless access point: the devices communicate directly when in range. An ad hoc network offers peer-to-peer layout and is commonly used in situations such as a quick data exchange or a multiplayer LAN game, because the setup is easy and an access point is not required.</p><p id="p-0146" num="0148">In order to support multiple devices and using a permanent solution, a Wireless Access Point (WAP) is typically used. A Wireless Access Point (WAP, or Access Point&#x2014;AP) is a device that allows wireless devices to connect to a wired network using Wi-Fi, or related standards. The WAP usually connects to a router (via a wired network) as a standalone device, but it can also be an integral component of the router itself. Using Wireless Access Point (AP) allows users to add devices that access the network with little or no cables. A WAP normally connects directly to a wired Ethernet connection and the AP then provides wireless connections using radio frequency links for other devices to utilize that wired connection. Most APs support the connection of multiple wireless devices to one wired connection. An example of using WAPs is shown in a system <b>20</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>2</b><i>b</i></figref>, where a device lla (corresponding to the device <b>11</b> above) may communicate, and for example, any access the Internet, via any one of a WAPs <b>26</b><i>a, </i><b>26</b><i>b, </i>or <b>26</b><i>c. </i>Wireless access typically involves special security considerations, since any device within a range of the WAP can attach to the network. The most common solution is wireless traffic encryption. Modern access points come with built-in encryption such as Wired Equivalent Privacy (WEP) and Wi-Fi Protected Access (WPA), typically used with a password or a passphrase. A WAP may not be password protected, allowing free access (for example to the Internet via the WAP) to any device communicating with it, such as WAP <b>26</b><i>a </i>shown in system <b>20</b><i>a. </i>However, most WAPs, such as WAPs <b>26</b><i>b </i>and <b>26</b><i>c </i>shown in system <b>20</b><i>a </i>(denoted with the lock symbol), are password protected, allowing access only to specific users which can use the password.</p><p id="p-0147" num="0149">Authentication in general, and a WAP authentication in particular, is used as the basis for authorization, which is the determination whether a privilege may be granted to a particular user or process, privacy, which keeps information from becoming known to non-participants, and non-repudiation, which is the inability to deny having done something that was authorized to be done based on the authentication. An authentication in general, and a WAP authentication in particular, may use an authentication server, that provides a network service that applications may use to authenticate the credentials, usually account names and passwords, of their users. When a client submits a valid set of credentials, it receives a cryptographic ticket that it can subsequently use to access various services. Authentication algorithms include passwords, Kerberos, and public key encryption.</p><p id="p-0148" num="0150">Compression. Data compression, also known as source coding and bit-rate reduction, involves encoding information using fewer bits than the original representation. Compression can be either lossy or lossless. Lossless compression reduces bits by identifying and eliminating statistical redundancy, so that no information is lost in lossless compression. Lossy compression reduces bits by identifying unnecessary information and removing it. The process of reducing the size of a data file is commonly referred to as a data compression. A compression is used to reduce resource usage, such as data storage space or transmission capacity. Data compression is further described in a Carnegie Mellon University chapter entitled: &#x201c;<i>Introduction to Data Compression</i>&#x201d; by Guy E. Blelloch, dated Jan. 31, 2013, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0149" num="0151">In a scheme involving lossy data compression, some loss of information is acceptable. For example, dropping of a nonessential detail from a data can save storage space. Lossy data compression schemes may be informed by research on how people perceive the data involved. For example, the human eye is more sensitive to subtle variations in luminance than it is to variations in color. JPEG image compression works in part by rounding off nonessential bits of information. There is a corresponding trade-off between preserving information and reducing size. A number of popular compression formats exploit these perceptual differences, including those used in music files, images, and video.</p><p id="p-0150" num="0152">Lossy image compression is commonly used in digital cameras, to increase storage capacities with minimal degradation of picture quality. Similarly, DVDs use the lossy MPEG-2 Video codec for video compression. In lossy audio compression, methods of psychoacoustics are used to remove non-audible (or less audible) components of the audio signal. Compression of human speech is often performed with even more specialized techniques; speech coding, or voice coding, is sometimes distinguished as a separate discipline from audio compression. Different audio and speech compression standards are listed under audio codecs. Voice compression is used in Internet telephony, for example, and audio compression is used for CD ripping and is decoded by audio player.</p><p id="p-0151" num="0153">Lossless data compression algorithms usually exploit statistical redundancy to represent data more concisely without losing information, so that the process is reversible. Lossless compression is possible because most real-world data has statistical redundancy. The Lempel-Ziv (LZ) compression methods are among the most popular algorithms for lossless storage. DEFLATE is a variation on LZ optimized for decompression speed and compression ratio, and is used in PKZIP, Gzip and PNG. The LZW (Lempel-Ziv-Welch) method is commonly used in GIF images, and is described in IETF RFC 1951. The LZ methods use a table-based compression model where table entries are substituted for repeated strings of data. For most LZ methods, this table is generated dynamically from earlier data in the input. The table itself is often Huffman encoded (e.g., SHRI, LZX). Typical modern lossless compressors use probabilistic models, such as prediction by partial matching.</p><p id="p-0152" num="0154">Lempel-Ziv-Welch (LZW) is an example of lossless data compression algorithm created by Abraham Lempel, Jacob Ziv, and Terry Welch. The algorithm is simple to implement, and has the potential for very high throughput in hardware implementations. It was the algorithm of the widely used Unix file compression utility compress, and is used in the GIF image format. The LZW and similar algorithms are described in U.S. Pat. No. 4,464,650 to Eastman et al. entitled: &#x201c;Apparatus and Method for Compressing Data Signals and Restoring the Compressed Data Signals&#x201d;, in U.S. Pat. No. 4,814,746 to Miller et al. entitled: &#x201c;Data Compression Method&#x201d;, and in U.S. Pat. No. 4,558,302 to Welch entitled: &#x201c;High Speed Data Compression and Decompression Apparatus and Method&#x201d;, which are all incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0153" num="0155">A class of lossless data compression algorithms is based on using dictionaries, and operates by searching for matches between the text to be compressed and a set of strings contained in a data structure (called the &#x2018;dictionary&#x2019;) maintained by the encoder. When the encoder finds such a match, it substitutes a reference to the string's position in the data structure.</p><p id="p-0154" num="0156">Some dictionary coders use a &#x2018;static dictionary&#x2019;, one whose full set of strings is determined before coding begins and does not change during the coding process. This approach is most often used when the message or set of messages to be encoded is fixed and large. A dictionary is often built from redundancy extracted from a data environment (various input streams) which dictionary is then used statically to compress a further input stream. For example, a dictionary may be built from old English texts then is used to compress a book. More common are methods where the dictionary starts in some predetermined state, but the contents change during the encoding process, based on the data that has already been encoded.</p><p id="p-0155" num="0157">Both the LZ77 and LZ78 algorithms work on this principle, where in LZ77, a circular buffer called the &#x201c;sliding window&#x201d; holds the last N bytes of data processed, which serves as the dictionary, effectively storing every substring that has appeared in the past N bytes as dictionary entries. Instead of a single index identifying a dictionary entry, two values are needed: the length, indicating the length of the matched text, and the offset (also called the distance), indicating that the match is found in the sliding window starting offset bytes before the current text. LZ78 uses a more explicit dictionary structure; at the beginning of the encoding process, the dictionary only needs to contain entries for the symbols of the alphabet used in the text to be compressed, but the indexes are numbered in order to leave spaces for many more entries. At each step of the encoding process, the longest entry in the dictionary that matches the text is found, and its index is written to the output; the combination of that entry and the character that followed it in the text is then added to the dictionary as a new entry. An example of a dictionary-based compression is described in an University of Michigan paper entitled: &#x201c;<i>Dictionary</i>-<i>Based Compression for Long Time</i>-<i>Series Similarity</i>&#x201d; by Willis Lang, Michael Morse, and Jignesh M. Patel, downloaded from http://pages.cs.wisc.edu/ on August 2014, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0156" num="0158">A one-way dictionary-based compression system is shown as a system <b>470</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. An encoding device <b>471</b> is shown to transmit data, such as DATA_<b>1</b> to a decoding device <b>472</b> via a network <b>480</b>, which may be the Internet <b>113</b>. The encoding device <b>471</b> comprises an encoder <b>474</b> (also referred to as a coder, data coder, or data compressor), serving to compress DATA_<b>1</b> received at an input port <b>475</b><i>a </i>into a DATA_<b>2</b> (which is a lossless compression of DATA_<b>1</b>, preferably having a lower number of bits or lower data-rate that DATA_<b>1</b>) at an output port <b>475</b><i>b, </i>using the content in a shared dictionary <b>473</b><i>a. </i>The output DATA _<b>2</b> is transmitted via the network <b>480</b>, and is received at an input port <b>476</b><i>a </i>of a decoder <b>477</b> (also referred to as a data decoder or data decompressor) in the decoding device <b>472</b>. Using a shared dictionary <b>473</b><i>b </i>in the decoding device <b>472</b>, which preferably includes the same content as in the shared dictionary <b>473</b><i>a </i>of the encoding device <b>471</b>, the decoder <b>477</b> reconstructs the original data DATA_<b>1</b> at an output port <b>476</b><i>b. </i></p><p id="p-0157" num="0159">A two-way dictionary-based compression system is shown as a system <b>470</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>4</b><i>a</i></figref>. An encoding/decoding device <b>471</b><i>c </i>includes the functionalities of an encoding device <b>471</b><i>a </i>for transmitting, and of a decoding device <b>472</b><i>a </i>for receiving data. Similarly, an encoding/decoding device <b>472</b><i>c </i>includes the functionalities of the encoding device <b>471</b><i>a </i>for transmitting, and of the decoding device <b>472</b><i>a </i>for receiving data. In addition to the functionality of the decoding device <b>472</b><i>a, </i>the encoding/decoding device <b>472</b><i>c </i>is shown to also transmit data, such as DATA_<b>3</b> to the encoding/decoding device <b>471</b><i>c </i>via the network <b>480</b>, which may be the Internet <b>113</b>. The encoding/decoding device <b>472</b><i>c </i>comprises an encoder <b>474</b><i>b </i>(also referred to as a coder, data coder, or data compressor), serving to compress DATA_<b>3</b> received at an input port <b>475</b><i>c </i>into a DATA_<b>4</b> (which is a lossless compression of DATA_<b>3</b>, preferably having a lower number of bits or lower data-rate that DATA_<b>3</b>) at an output port <b>475</b><i>d, </i>using the content in a shared dictionary <b>473</b><i>d. </i>The output DATA_<b>4</b> is transmitted via the network <b>480</b>, and is received at an input port <b>476</b><i>d </i>of a decoder <b>477</b><i>b </i>(also referred to as a data decoder or data decompressor) in the encoding/decoding device <b>471</b><i>c. </i>Using the shared dictionary <b>473</b><i>c </i>in the encoding/decoding device <b>471</b><i>c, </i>which preferably includes the same content as in the shared dictionary <b>473</b><i>d </i>of the encoding/decoding device <b>472</b><i>c, </i>the decoder <b>477</b><i>b </i>reconstructs the original data DATA_<b>3</b> at an output port <b>476</b><i>c. </i></p><p id="p-0158" num="0160">Image/video. Any content herein may consist of, be part of, or include, an image or a video content. A video content may be in a digital video format that may be based on one out of: TIFF (Tagged Image File Format), RAW format, AVI, DV, MOV, WMV, MP4, DCF (Design Rule for Camera Format), ITU-T H.261, ITU-T H.263, ITU-T H.264, ITU-T CCIR 601, ASF, Exif (Exchangeable Image File Format), and DPOF (Digital Print Order Format) standards. A intraframe or interframe compression may be used, and the compression may a lossy or a non-lossy (lossless) compression, that may be based on a standard compression algorithm, which may be one or more out of JPEG (Joint Photographic Experts Group) and MPEG (Moving Picture Experts Group), ITU-T H.261, ITU-T H.263, ITU-T H.264 and ITU-T CCIR 601.</p><p id="p-0159" num="0161">Web Analytics. Web analytics typically refers to the measurement, collection, analysis, and reporting of web data for purposes of understanding and optimizing web usage. Web analytics is commonly used for measuring web traffic, and may be used as a tool for business and market research, as well as to assess and improve the effectiveness of a web site. Web analytics applications can also help companies measure the results of traditional print or broadcast advertising campaigns. For example, it helps one to estimate how traffic to a website changes after the launch of a new advertising campaign. The web analytics provide information about the number of visitors to a website and the number of page views, and helps gauge traffic and popularity trends, which may be useful for market research. Web analytics related description and methods are described in a whitepaper by E-Nor, Inc. entitled: &#x201c;<i>A </i>7-<i>Step Analytics Reporting Framework&#x2014;Marketing Optimization Whitepaper</i>&#x201d; by Feras Alhlou, downloaded on August 2014, and in U.S. Pat. No. 8,234,370 to Hammer et al., entitled: &#x201c;Determining Web Analytics Information&#x201d;, in U.A. Patent Application Publication No. 2008/0046562 to Butler entitled: &#x201c;Visual Web Page Analytics&#x201d;, and in U.S. Pat. No. 7,941,525 to Yavilevich entitled: &#x201c;Method and System for Monitoring an Activity of a User&#x201d;, which are all incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0160" num="0162">There are two categories of web analytics: off-site and on-site web analytics. Off-site web analytics refers to web measurement and analysis, and includes the measurement of a website's potential audience (opportunity), share of voice (visibility), and buzz (comments) that is happening on the Internet. On-site web analytics measure a visitor's behavior once on the website, and includes its drivers and conversions; for example, the degree to which different landing pages are associated with online purchases. On-site web analytics typically measures the performance of the website in a commercial context, and this data is typically compared against key performance indicators for performance, and used to improve a web site or marketing campaign's audience response. Google Analytics is a widely used on-site web analytics service; although new tools are emerging that provide additional layers of information, including heat maps and session replay.</p><p id="p-0161" num="0163">Google Analytics is a service offered by Google that generates detailed statistics about a website's traffic and traffic sources and measures conversions and sales. The product is aimed at marketers as opposed to webmasters and technologists from which the industry of web analytics originally grew. Google Analytics can track visitors from all referrers, including search engines and social networks, direct visits and referring sites, and also tracks display advertising, pay-per-click networks, email marketing and digital collateral such as links within PDF documents. Integrated with AdWords, users can now review online campaigns by tracking landing page quality and conversions (goals). Goals might include sales, lead generation, viewing a specific page, or downloading a particular file.</p><p id="p-0162" num="0164">Google Analytics is implemented with &#x201c;page tags&#x201d;. A page tag, in this case called the Google Analytics Tracking Code is a snippet of JavaScript code that the website owner user adds to every page of the web site. The tracking code runs in the client browser when the client browses the page (if JavaScript is enabled in the browser), and collects visitor data and sends it to a Google data collection server, as part of a request for a web beacon. The tracking code loads a larger JavaScript file from the Google webserver and then sets variables with the user's account number. The larger file (currently known as ga.js) is typically 18 KB. The file does not usually have to be loaded, though, because of browser caching. Assuming caching is enabled in the browser, it downloads ga.js only once at the start of the visit. Furthermore, as all websites that implement Google Analytics with the ga.js code use the same master file from Google, a browser that has previously visited any other website running Google Analytics will already have the file cached on their machine. In addition to transmitting information to a Google server, the tracking code sets first party cookies (If cookies are enabled in the browser) on each visitor's computer. These cookies store anonymous information, such as whether the visitor has been to the site before (new or returning visitor), the timestamp of the current visit, and the referrer site or campaign that directed the visitor to the page (e.g., search engine, keywords, banner, or email). Google Analytics is further described in an Koozai Ltd. guide entitled: &#x201c;<i>The Practical Guide To Google Analytics For Business&#x201d;, </i>2<sup>nd </sup>Edition, published 2013, by Anna Lewis, Graeme Benge, and Gemma Hollooway, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0163" num="0165">DHCP. The Dynamic Host Configuration Protocol (DHCP) is a standardized networking protocol used on Internet Protocol (IP) networks for dynamically distributing network configuration parameters, such as IP addresses for interfaces and services. With DHCP, network elements request IP addresses and networking parameters automatically from a DHCP server, reducing the need for a network administrator or a user to configure these settings manually.</p><p id="p-0164" num="0166">DHCP is typically used by network elements for requesting Internet Protocol parameters, such as an IP address from a network server, and is based on the client-server model. When a network element connects to a network, its DHCP client software in the operating system sends a broadcast query requesting necessary information. Any DHCP server on the network may service the request. The DHCP server manages a pool of IP addresses and information about client configuration parameters such as default gateway, domain name, the name servers, and time servers. On receiving a request, the server may respond with specific information for each client, as previously configured by an administrator, or with a specific address and any other information valid for the entire network, and the time period for which the allocation (lease) is valid. A host typically queries for this information immediately after booting, and periodically thereafter before the expiration of the information. When an assignment is refreshed by the client computer, it initially requests the same parameter values, and may be assigned a new address from the server, based on the assignment policies set by administrators.</p><p id="p-0165" num="0167">Depending on implementation, the DHCP server may have three methods of allocating IP-addresses: (a) Dynamic allocation, where a network administrator reserves a range of IP addresses for DHCP, and each client computer on the LAN is configured to request an IP address from the DHCP server during network initialization. The request-and-grant process uses a lease concept with a controllable time period, allowing the DHCP server to reclaim (and then reallocate) IP addresses that are not renewed. (b) Automatic allocation, where the DHCP server permanently assigns an IP address to a requesting client from the range defined by the administrator. This is similar to dynamic allocation, but the DHCP server keeps a table of past IP address assignments, so that it can preferentially assign to a client the same IP address that the client previously had. (c) Static allocation, where the DHCP server allocates an IP address based on a preconfigured mapping to each client's MAC address.</p><p id="p-0166" num="0168">DHCP used for Internet Protocol version 4 (IPv4) is described in IETF RFC 2131, entitled &#x201c;<i>Dynamic Host Configuration Protocol</i>&#x201d;, and DHCP for IPv6 is described IETF RFC 3315, entitled: &#x201c;<i>Dynamic Host Configuration Protocol for IPv</i>6 (<i>DHCPv</i>6)&#x201d;, both incorporated in their entirety for all purposes as if fully set forth herein. While both versions serve the same purpose, the details of the protocol for IPv4 and IPv6 are sufficiently different that they may be considered separate protocols. For IPv6 operation, devices may alternatively use stateless address auto-configuration. IPv4 hosts may also use link-local addressing to achieve operation restricted to the local network link.</p><p id="p-0167" num="0169">The DHCP protocol employs a connectionless service model, using the User Datagram Protocol (UDP). It is implemented with two UDP port numbers for its operations, which are the same as for the BOOTP protocol. The UDP port number 67 is the destination port of a server, and the UDP port number 68 is used by the client. DHCP operations fall into four phases: Server discovery, IP lease offer, IP request, and IP lease acknowledgment. These stages are often abbreviated as DORA for discovery, offer, request, and acknowledgment. The DHCP protocol operation begins with clients broadcasting a request. If the client and server are on different subnets, a DHCP Helper or DHCP Relay Agent may be used. Clients requesting renewal of an existing lease may communicate directly via an UDP unicast, since the client already has an established IP address at that point.</p><p id="p-0168" num="0170">Redundancy. A redundancy may be used in order to improve an accuracy, reliability, or availability. The redundancy may be implemented where two or more components may be used for the same functionality. The components may be similar, substantially or fully the same, identical, different, substantially different, or distinct from each other, or any combination thereof. The redundant components may be concurrently operated, allowing for improved robustness and allowing for overcoming a Single Point Of Failure (SPOF), or alternatively one or more of the components serves as a backup. The redundancy may be a standby redundancy, which may be &#x2018;Cold Standby&#x2019; and &#x2018;Hot Standby&#x2019;. In the case three redundant components are used, Triple Modular Redundancy (TMR) may be used, and Quadruple Modular Redundancy (QMR) may be used in the case of four components. A 1:N Redundancy logic may be used for three or more components. A communication system employing redundancy is described in U.S. Patent Application No. 2013/0201316 to Binder et al., entitled: &#x201c;System and Method for Server Based Control&#x201d;, and redundancy for carrying audio over the Internet is described in IETF RFC 2198 entitled: &#x201c;RTP Payload for Redundant Audio Data&#x201d;, both are incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0169" num="0171">Parallel Redundancy Protocol (PRP) is a data communication network standardized by the International Electrotechnical Commission (IEC) as IEC 62439-3 Clause 4, which allows systems to overcome any single network failure without affecting the data transmission by using redundancy. Under PRP, each network node has two Ethernet ports attached to two different local area networks of arbitrary, but similar topology, and the two LANs are completely separated and are assumed to be fail-independent. A source node sends simultaneously two copies of a frame, one over each port. The two frames travel through their respective LANs until they reach a destination node, in the fault-free case, with a certain time skew. The destination node accepts the first frame of a pair and discards the second, taking advantage of a sequence number in each frame that is incremented for each frame sent. Therefore, as long as one LAN is operational, the destination always receives one frame. This protocol provides a zero-time recovery and allows checking the redundancy continuously to detect lurking failures. The PRP is described in an ABB Switzerland Ltd. 2012 presentation entitled &#x201c;<i>Highly Available Automation Networks Standard Redundancy Methods&#x2014;Rationale behind the IEC </i>63429 <i>standard suite</i>&#x201d;, and in a Zurich University tutorial entitled: &#x201c;<i>Tutorial on Parallel redundancy Protocol </i>(<i>PRP</i>)&#x201d;, by Prof. Hans Weibel, downloaded July 2014, both are incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0170" num="0172">Gateway. The term &#x2018;gateway&#x2019; is used herein to include, but not limited to, a network element (or node) that is equipped for interfacing between networks that uses different protocols. A gateway typically contains components such as protocol translators, impedance matching devices, rate converters, fault isolators, or signal translators, as necessary to provide networking interoperability. A gateway may be a router or a proxy server that routes between networks, and may operate at any network layer. In a network for an enterprise, a computer server acting as a gateway node is often also acting as a proxy server and a firewall server. A gateway is often associated with both a router, which knows where to direct a given packet of data that arrives at the gateway, and a switch, which furnishes the actual path in and out of the gateway for a given packet.</p><p id="p-0171" num="0173">A subnet mask is a mask used to determine what subnet belongs to an IP address. An IP address has two components, the network address and the host address. For example, consider the IP address 150.215.017.009. Assuming this is part of a Class B network, the first two numbers (150.215) represent the Class B network address, and the second two numbers (017.009) identify a particular host on this network. A subnetting enables the network administrator to further divide the host part of the address into two or more subnets. In this case, a part of the host address is reserved to identify the particular subnet. On an IP network, clients should automatically send IP packets with a destination outside a given subnet mask to a network gateway. A subnet mask defines the IP range of a private network. For example, if a private network has a base IP address of 192.168.0.0 and has a subnet mask of 255.255.255.0, then any data going to an IP address outside of 192.168.0.X will be sent to that network gateway. While forwarding an IP packet to another network, the gateway might or might not perform Network Address Translation (NAT).</p><p id="p-0172" num="0174">Domain Name System (DNS) is a hierarchical distributed naming system for computers, services, or any resource connected to the Internet or a private network. It associates various information with domain names assigned to each of the participating entities, and translates easily memorized domain names to the numerical IP addresses needed for the purpose of locating computer services and devices worldwide. The DNS is described, for example, in the IETF RFC 3467 entitled: &#x201c;<i>Role of the Domain Name System </i>(<i>DNS</i>)&#x201d;, in the IETF RFC 6195 entitled: &#x201c;<i>Domain Name System </i>(<i>DNS</i>) <i>IANA Considerations</i>&#x201d;, and in the IETF RFC 1591 entitled: &#x201c;<i>Domain Name System Structure and Delegation</i>&#x201d;, which are incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0173" num="0175">The &#x2018;404&#x2019; or &#x2018;Not Found&#x2019; error message is a HTTP standard response code indicating that the client was able to communicate with a given gateway or server, but the server could not find what was requested. The web site hosting server will typically generate a &#x201c;404 Not Found&#x201d; web page when a user attempts to follow a broken or dead link; hence, the 404 error is one of the most recognizable errors users can find on the web. When communicating via HTTP, a server is required to respond to a request, such as a web browser request for a web page, with a numeric response code and an optional, mandatory, or disallowed (based upon the status code) message. In the code 404, the first digit indicates a client error, such as a mistyped Uniform Resource Locator (URL). The following two digits indicate the specific error encountered. At the HTTP level, a 404 response code is followed by a human-readable &#x201c;reason phrase&#x201d;. The HTTP specification suggests the phrase &#x201c;Not Found&#x201d; and many web servers by default issue an HTML page that includes both the 404 code and the &#x201c;Not Found&#x201d; phrase.</p><p id="p-0174" num="0176">Referring to <figref idref="DRAWINGS">FIG. <b>50</b></figref> showing a system <b>500</b> using a gateway #<b>1</b> <b>505</b><i>a </i>as an intermediate device between a LAN <b>503</b> (which may be the LAN <b>14</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) and a WAN <b>502</b> (which may be the Internet <b>113</b>). The gateway #<b>1</b> <b>505</b><i>a </i>allows an application <b>506</b> in the network element <b>504</b> to communicate with another network element such as a server <b>501</b> via the networks. The network element <b>504</b> typically includes a memory, such as the main memory <b>25</b><i>a, </i>the storage device <b>25</b><i>c, </i>or the ROM <b>25</b><i>b, </i>storing a software <b>508</b>, which typically includes the application <b>506</b>, which uses the Operating System (OS) <b>507</b>, which may be associated with the WDM architecture <b>430</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, or with the Linux architecture <b>450</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b><i>a</i></figref>. As part of initializing of a communication session with the network element <b>501</b>, the OS <b>507</b> typically identifies the gateway <b>505</b><i>a </i>in the LAN <b>503</b>, and obtains therefrom the required information such as an IP address, a DNS server IP, a subnet mask, and other information to be used before and during the communication session. The gateway #<b>1</b> <b>505</b><i>a </i>may consist of, include, be part of, or integrated with, a network router or a WiFi router.</p><p id="p-0175" num="0177">In consideration of the foregoing, it would be an advancement in the art to provide an improved functionality method and system that is simple, secure, anonymous, cost-effective, load balanced, redundant, reliable, provide lower CPU and/or memory usage, enable pipelining of requests and responses, reduce network congestion, easy to use, reduce latency, faster, has a minimum part count, minimum hardware, and/or uses existing and available components, protocols, programs and applications for providing better quality of service, overload avoidance, better or optimal resources allocation, better communication and additional functionalities, and provides a better user experience.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0176" num="0178">A system may comprise multiple data servers and multiple client and tunnel devices, each data server may be storing a respective content that may be fetched by the client devices via the Internet. The tunnel devices may be used as intermediate devices (or nodes). Upon initializing of the client and tunnel devices (such as upon powering up or upon launching the applicable software application), they sign-in with an acceleration server, which stores an identification (such as IP address) of each of the client and tunnel devices. A client device, which may be requesting a content from a data server, first communicates with the acceleration server to receive a list of the available tunnel devices. The client device may then select one (or more) tunnel device, and then executes a pre-connection process with the selected tunnel device. Upon determining the need for a content to be fetched from the data server, the client device sends a request to the tunnel device, which in turn fetches the required content from the data server, and sends the fetched content to the client device. Each of the devices (client or tunnel) and each of the servers (acceleration or data) may be identified in the Internet using an IP address that may be in an IPv<b>4</b> or IPv<b>6</b> form. Alternatively or in addition to using an intermediary device such as the tunnel device (or multiple tunnel devices), the client device may directly access and fetch content from the data server, without using any intermediate device such as a tunnel device. A device may be both a client device and a tunnel device, and the roles may be assumed one at a time, or may be employed in parallel using multitasking or multiprocessing.</p><p id="p-0177" num="0179">The required communication of requests and content between the client device and the selected tunnel device may be preceded by a pre-connection phase used for establishing a connection between the devices, which may be later used for the required request or content transfer. The devices may communicate using VPN or TCP, and a connection may be established by performing &#x2018;Active OPEN&#x2019; or &#x2018;Passive OPEN&#x2019;. The content may include files, text, numbers, audio, voice, multimedia, video, images, music, computer programs or any other sequence of instructions, as well as any other form of information represented as a string of bits or bytes. In one example, the content may include, be a part of, or a whole of, a web site page.</p><p id="p-0178" num="0180">One or a plurality of tunnel devices may be used. Further, a device may directly access the data server, hence acting as its own tunnel device. The selection of a tunnel or of multiple tunnels to be used by the client device may be based on pre-set criteria. The selection may use various attributes or characteristics of the tunnel devices, its operation environment, history, and any other characteristics. The attributes associated with each tunnel device may be stored in the acceleration server, and sent to the client device as part of the available tunnel devices list, so that the client device may use these attributes for the selection process. The criteria herein may be used independently or in combination. In yet another alternative, the selection may be based on a timing, such as Time-Of-Day (TOD) or a day of the week.</p><p id="p-0179" num="0181">The tunnel device (or devices) to be used may be randomly selected; using a random number generator may be based on a physical process, or may be software based using pseudo-random numbers. Alternatively or in addition, the tunnel device (or devices) to be used may be selected based on physical geographical location, such as based on the physical proximity to another device in the system, such as the data server. Alternatively or in addition, the tunnel device (or devices) to be used may be selected based on their IP address or addresses. Alternatively or in addition, the tunnel device (or devices) to be used may be selected based on their sign-in time, or the time of its last activity as a tunnel.</p><p id="p-0180" num="0182">The content requested by the client device may be partitioned into multiple parts or &#x2018;slices&#x2019;. Any number of slices may be used. The slicing may be in a bit, nibble (4-bits), byte (8-bits), word (multiple bytes), character, string, or a file level. The partition may be into equal length parts, or may use different length slicing. The content may be composed of inherent or identifiable parts or segments, and the partition may make use of these parts. The content may be a website content composed of multiple webpages, and each slice may include one (or few) webpages. Further, the partition may be sequential or non-sequential in the content. The partitioning may be non-overlapping or overlapping.</p><p id="p-0181" num="0183">A method is disclosed for fetching over the Internet a first content, identified by a first content identification, by a first device, identified in the Internet by a first identifier, from a second server identified in the Internet by a third identifier via a second device identified in the Internet by a second identifier, by using a first server. The method may be comprising the steps of the second device sending the second identifier to the first server; in response to receiving the second identifier, the first server storing the second identifier; the first device sending a first request to the first server; in response to receiving the first request, the first server sending the second identifier to the first device; the first device sending a second request to the second device using the second identifier, the second request includes the first content identification and the third identifier; in response to receiving the second request, the second device sending the first content identification to the second server using the third identifier; in response to receiving the first content identification, the second server sending the first content to the second device; and in response to receiving the first content, the second device sending the first content to the first device.</p><p id="p-0182" num="0184">The method may further comprise the following steps of the first device sending the first content identification to the second server using the third identifier; and in response to receiving the first content identification, the second server sending the first content to the first device. These steps may be performed before, after, or concurrently (using multitasking or multiprocessing) with any of the former steps.</p><p id="p-0183" num="0185">The method may further be used with a third device identified in the Internet by a fourth identifier, and may further comprise the steps of the third device sending the fourth identifier to the first server; in response to receiving the fourth identifier, the first server storing the fourth identifier; in response to receiving the first request, the first server sending the fourth identifier to the first device; the first device sending a third request to the third device using the fourth identifier, the third request includes the first content identification and the third identifier; in response to receiving the third request, the third device sending the first content identification to the second server using the third identifier; in response to receiving the first content identification, the second server sending the first content to the third device; and in response to receiving the first content, the third device sending the first content to the first device. These steps may be performed before, after, or concurrently (using multitasking or multiprocessing) with any of the former steps.</p><p id="p-0184" num="0186">The method may further be used with a group consisting of a plurality of devices, each associated with a respective identifier for being identified in the Internet, for each of the devices in the group the method further comprising the steps of the group device sending the associated identifier to the first server; and in response to receiving the associated identifier, the first server storing the associated identifier. Further, in response to receiving the first request, the first server may be sending the identifiers of all the devices in the group to the first device. The method may further comprise the steps of the first device sending a third request to the group device using the device associated identifier, the third request includes the first content identification and the third identifier; in response to receiving the third request, the group device sending the first content identification to the second server using the third identifier; in response to receiving the first content identification, the second server sending the first content to the group device; and in response to receiving the first content, the group device sending the first content to the first device.</p><p id="p-0185" num="0187">The second device may be included as part of the group, and the method may further comprise a step of selecting the second device out of the devices in the group. The first server may select the second device out of the devices in the group, and in the first server may send the second identifier to the first device in response to the selection. Further, the first server may send the identifiers of all the devices in the group to the first device, followed by a step of the first device selecting the second device. Further, the method may include a step of selecting one or more devices, distinct from the second device, out of the devices in the group.</p><p id="p-0186" num="0188">The second device may be randomly selected out of the devices in the group using one or more random numbers generated by a random number generator. The random number generator may be hardware based using thermal noise, shot noise, nuclear decaying radiation, photoelectric effect, or quantum phenomena. Alternatively or in addition, the random number generator may be software based, based on executing an algorithm for generating pseudo-random numbers. The second device may be selected based on attributes or characteristics of the device.</p><p id="p-0187" num="0189">The second device may be selected based on the physical geographical location, and the method may comprise for each of the devices in the group the step of sending the device physical geographical location to the first server, followed by the step of the first server storing the received group device physical geographical location. The physical geographical location may include at least one out of a continent, a country, a state or province, a city, a street, a ZIP code, or a longitude and a latitude. The second device may be selected based on the physical geographical proximity to the second server.</p><p id="p-0188" num="0190">The second device may be selected based on the second identifier, the second identifier may be an IP address, and the second device may be selected based on its IP address. Alternatively or in addition, the second device may be selected based on comparing the second identifier to the third identifier. Alternatively or in addition, the second device may be selected based on past activities, such as based on the timing of an event. The event may be a last or previous communication between the second device and the first device, the last communication between the second device and the first server, or the last communication between the second device and the second server. These steps may be performed before, after, or concurrently (using multitasking or multiprocessing) with any of the former steps.</p><p id="p-0189" num="0191">Each of the identifiers herein may be a URL or an IP address in IPv4 or IPv6 form. Any one of the servers herein may be a web server using Hyper Text Transfer Protocol (HTTP) that responds to HTTP requests via the Internet, and any request herein may be an HTTP request. Any communication herein may be based on, or according to, TCP/IP protocol or connection, and may be preceded by the step of establishing a connection, such as an &#x2018;Active OPEN&#x2019; or a &#x2018;Passive OPEN&#x2019;. Alternatively or in addition, any communication herein may be based on, or use a VPN or a tunneling protocol. Any content herein may include, consist of, or comprise, part or whole of files, text, numbers, audio, voice, multimedia, video, images, music, or computer program, or may include, consists of, or comprise, a part of, or a whole of, a website page.</p><p id="p-0190" num="0192">The method may be used for fetching over the Internet a second content, identified by a second content identification, by a third device identified in the Internet by a fourth identifier, from a third server identified in the Internet by a fifth identifier, via the first device, and may further comprising the steps of the third device sending a third request to the first server; in response to receiving the third request, the first server sending the first identifier to the third device; the third device sending a fourth request to the first device using the first identifier, the fourth request includes the second content identification and the fifth identifier; in response to receiving the fourth request, the first device sending the second content identification to the third server using the fifth identifier; in response to receiving the second content identification, the third server sending the second content to the first device; and in response to receiving the second content, the first device sending the second content to the third device. The third server may be distinct from, or the same device as, the second server. The third device may be distinct from, or the same device as, the second device. The second content may be distinct from, or the same content as, the first content.</p><p id="p-0191" num="0193">A client device may be a first device identified in the Internet by a first identifier, executing a method for fetching over the Internet a first content, identified by a first content, from a second server identified in the Internet by a third identifier, via a second device identified in the Internet by a second identifier, using a first server. The method may include the steps of sending the first identifier to the first server; sending a first request to the first server; receiving the second identifier from the first server; sending a second request to the second device using the second identifier, the second request includes the first content identification and the third identifier; and receiving the first content from the second device. The method may further comprising of the step of sending the first content identification to the second server using the third identifier. These steps may be performed before, after, or concurrently (using multitasking or multiprocessing) with any of the former steps.</p><p id="p-0192" num="0194">The method may further be used with a third device identified in the Internet by a fourth identifier, and may further comprise the steps of receiving the fourth identifier from the first server; sending a third request to the third device using the fourth identifier, the third request includes the first content identification and the third identifier; and receiving the first content from the third device. These steps may be performed before, after, or concurrently (using multitasking or multiprocessing) with any of the former steps.</p><p id="p-0193" num="0195">The method may further be used with a group consisting of a plurality of devices, each device in the group may be associated with a respective identifier for being identified in the Internet, and may further comprise the steps of receiving the identifiers of the group devices from the first server; sending a third request to the group devices using their associated identifiers, the third request includes the first content identification and the third identifier; and receiving the first content from the group devices. The second device may be included in the group, and the method may further comprise a step of selecting the second device out of the devices in the group, or the step of selecting one or more devices, distinct from the second device, out of the devices in the group.</p><p id="p-0194" num="0196">The method may further be used for fetching over the Internet a second content, identified by a second content identification, by a third device, identified in the Internet by a fourth identifier, from a third server identified in the Internet by a fifth identifier, via the first device. The method may further comprise steps of receiving a third request from the third device, the third request includes the second content identification and the fifth identifier; in response to receiving the third request, sending the second content identification to the third server using the fifth identifier; receiving the second content from the third server; and in response to receiving the second content, sending the second content to the third device using the fourth identifier. The third server may be distinct from the second server, or the third server and the second server are the same server. The second content may be distinct from the first content, or the second content and the first content may be the same content.</p><p id="p-0195" num="0197">A tunnel device may be identified in the Internet by a second identifier execute a method for fetching over the Internet a first content, identified by a first content identification, by a first device, identified in the Internet by a first identifier, from a second server identified in the Internet by a third identifier using a first server. The method may comprise the steps of sending the second identifier to the first server; receiving a second request from the first device, the second request includes the first content identification and the third identifier; in response to receiving the second request, sending the first content identification to the second server using the third identifier; receiving the first content from the second server; and in response to receiving the first content, sending the first content to the first device using the first identification.</p><p id="p-0196" num="0198">An acceleration server may execute a method for fetching over the Internet a first content, identified by a first content identification, by a first device identified in the Internet by a first identifier, from a second server identified in the Internet by a third identifier via a second device identified in the Internet by a second identifier. The method may comprise steps of receiving the second identifier from the second device; in response to receiving the second identifier, storing the second identifier; receiving a first request from the first device; and in response to receiving a first request, sending the second identifier to the first device. The method may further be used with a third device identified in the Internet by a fourth identifier, and may comprise the steps of receiving the fourth identifier from the third device; in response to receiving the fourth identifier, storing the fourth identifier; and in response to receiving the first request, sending the fourth identifier to the first device.</p><p id="p-0197" num="0199">The method may further be used with a group consisting of a plurality of devices; each device in the group may be associated with a respective identifier for being identified in the Internet, for each of the group devices in the group. The method may comprise steps of receiving the associated identifier from the group device; in response to receiving the associated identifier, storing the associated identifier; and in response to receiving the first request, sending the identifier of all group devices to the first device. The second device may be included as part of the group, and the method may further comprise the step of selecting the second device out of the devices in the group, and the sending the second identifier to the first device may be in response to the selection.</p><p id="p-0198" num="0200">A method is disclosed for fetching a content over the Internet by a first device identified in the Internet by a first identifier, from a first server identified in the Internet by a second identifier via a group of multiple devices each identified in the Internet by an associated group device identifier. The method may comprise a step of partitioning the content into a plurality of content slices, each content slice containing at least part of the content, and identified using a content slice identifier. For each of the content slices, the method may comprise steps of selecting a device from the group; the first device sending a first request to the selected device using the selected device identifier, the first request including the content slice identifier and a second identifier; in response to receiving the first request, the selected device sending a second request to the first server using the second identifier, the second request including the content slice identifier; in response to receiving the second request, the first server sending the content slice to the selected device; and in response to receiving the content slice, the selected device sending the content slice to the first device.</p><p id="p-0199" num="0201">The content may be composed of bits, nibbles, bytes, characters, words, or strings, and the partitioning may be based on bit, nibble, byte, multi-byte, number, character, word, or string level, or may be composed of files, or programs, and the partitioning may be based on file or program level. Alternatively or in addition, the content may be a website content comprising multiple webpages, and the partitioning may be based webpages level. All the parts of the content may be included in all of the content slices. All of the content slices may be having a same size. A part of the content may be included in two or more content slices. The partitioning may be sequential or non-sequential in the content. The number of content slices may be equal to, higher than, or lower than, the number of devices in the group. A distinct device may be selected for each content slice</p><p id="p-0200" num="0202">A method to be executed by a device is disclosed for fetching a content over the Internet from a first server identified in the Internet by a second identifier via a group of multiple devices each identified in the Internet by an associated group device identifier, the method comprising a step of partitioning the content into a plurality of content slices, each content slice containing at least part of the content, and identified using a content slice identifier. For each of the content slices, the method may comprise steps of selecting a device from the group; sending a first request to the selected device using the selected device identifier, the first request including the content slice identifier and the second identifier; receiving the content slice from the selected device; and constructing the content from the received content slices.</p><p id="p-0201" num="0203">A method is disclosed for fetching over the Internet a first content, identified by a first content identifier, by a first device, identified in the Internet by a first identifier, from a second server identified in the Internet by a third identifier via a second device identified in the Internet by a second identifier, using a first server. The method may comprise the steps of the second device sending the second identifier to the first server; in response to receiving the second identifier, the first server storing the second identifier; the first device sending a first request to the first server; in response to receiving the first request, the first server sending the second identifier to the first device; the first device sending a second request to the second device using the second identifier, the second request includes the first content identifier and the third identifier; in response to receiving the second request, the second device sending the first content identifier to the second server using the third identifier; in response to receiving the first content identifier, the second server sending the first content to the second device; and in response to receiving the first content, the second device sending the first content to the first device. Alternatively or in addition, the method may comprise the additional steps of the first device sending the first content identifier to the second server using the third identifier; and in response to receiving the first content identifier, the second server sending the first content to the first device. These additional steps may precede any of the other steps, follow any of the other steps, or may be executed simultaneously with any one of the other steps using multitasking or multiprocessing.</p><p id="p-0202" num="0204">Alternatively or in addition, the method may be for use with a third device identified in the Internet by a fourth identifier, and may further comprising the steps of the third device sending the fourth identifier to the first server; in response to receiving the fourth identifier, the first server storing the fourth identifier; in response to receiving the first request, the first server sending the fourth identifier to the first device; the first device sending a third request to the third device using the fourth identifier, the third request includes the first content identifier and the third identifier; in response to receiving the third request, the third device sending the first content identifier to the second server using the third identifier; in response to receiving the first content identifier, the second server sending the first content to the third device; and in response to receiving the first content, the third device sending the first content to the first device.</p><p id="p-0203" num="0205">Alternatively or in addition, the method may be for use with a group consisting of a plurality of devices, each associated with a respective identifier for being identified in the Internet, for each of the devices in the group, and the method may further comprise the steps of the group device sending the associated identifier to the first server; and in response to receiving the associated identifier, the first server storing the associated identifier. Alternatively or in addition, the method may comprise the step of in response to receiving the first request, the first server sending the identifiers of all the devices in the group to the first device. Alternatively or in addition, for each of the group devices in the group, the method may further comprise the steps of the first device sending a third request to the group device using the device associated identifier, the third request includes the first content identifier and the third identifier; in response to receiving the third request, the group device sending the first content identifier to the second server using the third identifier; in response to receiving the first content identifier, the second server sending the first content to the group device; and in response to receiving the first content, the group device sending the first content to the first device.</p><p id="p-0204" num="0206">The second device may be included in the group, the method may further comprise the step of selecting the second device out of the devices in the group by the first server, and the first server may be sending the second identifier to the first device in response to the selection. Alternatively or in addition, the method may comprise the step of the first server may be sending the identifiers of all devices and the group to the first device, followed by a step of the first device selecting the second device. Alternatively or in addition, the method may comprise the step of selecting 2, 3, 4, 5, 6, 7, 8, 9, 10, or more than 10 devices, distinct from the second device, out of the devices in the group. The second device may be randomly selected out of the devices in the group, such as being randomly selected using one or more random numbers generated by a random number generator. The random number generator may be software based, such as based on executing an algorithm for generating pseudo-random numbers. Alternatively or in addition, the second device may be selected based on attributes or characteristics of the device, or based on the device physical geographical location. Further, for each of the devices in the group, the method may comprise the steps of sending the device physical geographical location to the first server, followed by the step of the first server storing the received group device physical geographical location. The physical geographical location may include a continent, a country, a state or province, a city, a street, a ZIP code, or longitude and latitude, and the second device may be selected based on the physical geographical proximity to the second server. The second device may be selected based on the second identifier that may be an IP address, and the second device may be selected based on its IP address, or the second device may be selected based on comparing the second identifier to the third identifier. Alternatively or in addition, the second device may be selected based on past activities, or based on the timing of an event, wherein the event may be the last communication between the second device and the first device, may be the last communication between the second device and the first server, or may be the last communication between the second device and the second server.</p><p id="p-0205" num="0207">The method may be used for fetching over the Internet a second content, identified by a second content identifier, by a third device, identified in the Internet by a fourth identifier, from a third server identified in the Internet by a fifth identifier, via the first device, the method further comprising the steps of the third device sending a third request to the first server; in response to receiving the third request, the first server sending the first identifier to the third device; the third device sending a fourth request to the first device using the first identifier, the fourth request includes the second content identifier and the fifth identifier; in response to receiving the fourth request, the first device sending the second content identifier to the third server using the fifth identifier; in response to receiving the second content identifier, the third server sending the second content to the first device; and in response to receiving the second content, the first device sending the second content to the third device. The third server may be distinct from, or the same as, the second server, the third device may be distinct from, or the same as, the second device, and the second content may be distinct from, or the same as, the first content. The method may further comprise the steps of the first device receiving the first content from the second device; and the first device storing the first content in a memory.</p><p id="p-0206" num="0208">Further, a method is disclosed for fetching over the Internet a first content, identified by a first content identifier, by a first device, identified in the Internet by a first identifier, from a second server identified in the Internet by a third identifier via a second device identified in the Internet by a second identifier, using a first server. The method may comprise the steps of sending the first identifier to the first server; sending a first request to the first server; receiving the second identifier from the first server; sending a second request to the second device using the second identifier, the second request includes the first content identifier and the third identifier; and receiving the first content from the second device. The method may be further for use with a third device identified in the Internet by a fourth identifier, and may further comprise the steps of receiving the fourth identifier from the first server; sending a third request to the third device using the fourth identifier, the third request includes the first content identifier and the third identifier; and receiving the first content from the third device.</p><p id="p-0207" num="0209">The method may further for use with a group consisting of a plurality of devices, each device in the group may be associated with a respective identifier for being identified in the Internet, and may further comprise the steps of receiving the identifiers of the group devices from the first server; sending a third request to the group device using their associated identifiers, the third request includes the first content identifier and the third identifier; and receiving the first content from the group devices. The second device may be included in the group, and the method may further comprise the step of selecting the second device out of the devices in the group. Further, one or more devices, distinct from the second device, may be selected out of the devices in the group. The second device may be randomly selected out of the devices in the group, may be selected based on attributes or characteristics of the device. Alternatively or in addition, the selection may be based on a physical geographical location, such as on the physical geographical proximity to the second server. Further, the second device may be selected based on the second identifier, based on past activities, or based on the timing of an event.</p><p id="p-0208" num="0210">Further, the method may be for fetching over the Internet a second content, identified by a second content identifier, by a third device, identified in the Internet by a fourth identifier, from a third server identified in the Internet by a fifth identifier, via the first device, the method may further comprise the steps of receiving a third request from the third device, where the third request includes the second content identifier and the fifth identifier; in response to receiving the third request, sending the second content identifier to the third server using the fifth identifier; receiving the second content from the third server; and in response to receiving the second content, sending the second content to the third device using the fourth identifier. The third server may be distinct from, or same as, the second server. The second content may be distinct from, or same as, the first content.</p><p id="p-0209" num="0211">A method is disclosed for fetching over the Internet a first content, identified by a first content identifier, by a first device, identified in the Internet by a first identifier, from a second server identified in the Internet by a third identifier via a second device identified in the Internet by a second identifier, using a first server. The method may comprise the steps of sending the second identifier to the first server; receiving a second request from the first device, the second request includes the first content identifier and the third identifier; in response to receiving the second request, sending the first content identifier to the second server using the third identifier; receiving the first content from the second server; and in response to receiving the first content, sending the first content to the first device using the first identifier.</p><p id="p-0210" num="0212">A method is disclosed for fetching over the Internet a first content, identified by a first content identifier, by a first device, identified in the Internet by a first identifier, from a second server identified in the Internet by a third identifier via a second device identified in the Internet by a second identifier, using a first server, the method may comprise the steps of receiving the second identifier from the second device; in response to receiving the second identifier, storing the second identifier; receiving a first request from the first device; and in response to receiving a first request, sending the second identifier to the first device. The method may for use with a third device identified in the Internet by a fourth identifier, and may further comprise the steps of receiving the fourth identifier from the third device; in response to receiving the fourth identifier, storing the fourth identifier; and in response to receiving the first request, sending the fourth identifier to the first device. The method may be used with a group consisting of a plurality of devices; each device in the group may be associated with a respective identifier for being identified in the Internet. For each of the group devices in the group, the method further comprising the steps of receiving the associated identifier from the group device; in response to receiving the associated identifier, storing the associated identifier; and in response to receiving the first request, sending the identifier of all group devices to the first device.</p><p id="p-0211" num="0213">A method is disclosed for fetching a content over the Internet by a first device identified in the Internet by a first identifier, from a first server identified in the Internet by a second identifier is a group of multiple devices, each identified in the Internet by an associated group device identifier, the method comprising the step of partitioning the content into a plurality of content slices, each content slice containing at least part of the content, and identified using a content slice identifier, and for each of the content slices. The method may comprise the steps of selecting a device from the group; the first device sending a first request to the selected device using the selected device identifier, the first request including the content slice identifier and the second identifier; in response to receiving the first request, the selected device sending a second request to the first server using the second identifier, the second request including the content slice identifier; in response to receiving the second request, the first server sending the content slice to the selected device; and in response to receiving the content slice, the selected device sending the content slice to the first device.</p><p id="p-0212" num="0214">A method is disclosed for fetching a content over the Internet from a first server identified in the Internet by a second identifier via a group of multiple devices, each identified in the Internet by an associated group device identifier, the method may comprise the step of partitioning the content into a plurality of content slices, each content slice containing at least part of the content, and identified using a content slice identifier. For each of the content slices, the method may comprise the steps of selecting a device from the group; sending a first request to the selected device using the selected device identifier, the first request including the content slice identifier and the second identifier; receiving the content slice from the selected device; and constructing the content from the received content slices.</p><p id="p-0213" num="0215">A content herein may be composed of bits, nibbles, bytes, characters, words, or strings, and the partitioning may be based on bit, nibble, byte, multi-byte, number, character, word, or string level. Alternatively or in addition, a content herein may be composed of files or programs, and the partitioning may be based on file or program level. Further, the content may be a website content comprising multiple webpages, and the partitioning may be based on webpages level. All parts of the content may be included in all of the content slices, and two or more, or all of the content slices, may be having the same size. Two or more of the content slices may include the same information. Further, the same part of the content may be included in two or more content slices. The partitioning may be sequential or non-sequential in the content, and the number of the content slices may be equal to, higher than, or lower than, the number of devices in the group. A distinct device may be selected for each content slice.</p><p id="p-0214" num="0216">The first device may consist of, comprise, or be part of, any network element. In one example, the first device may consist of, comprise, or be part of, a client device, such as the client device #<b>1</b>. The first server may consist of, comprise, or be part of, any network element. In one example, the first server may consist of, comprise, or be part of, the acceleration server. The second server may consist of, comprise, or be part of, any network element. In one example, the second server may consist of, comprise, or be part of, a data server, such as the data server #<b>1</b>. The third server may consist of, comprise, or be part of, any network element. In one example, the third server may consist of, comprise, or be part of, a data server, such as the data server #<b>2</b>. The second device may consist of, comprise, or be part of, any network element. In one example, the second device may consist of, comprise, or be part of, a tunnel device, such as the tunnel device #<b>1</b>. The third device may consist of, comprise, or be part of, any network element. Alternatively or in addition, the third device may consist of, comprise, or be part of, a client device, such as the client device #<b>2</b>.</p><p id="p-0215" num="0217">A method is disclosed for a first device fetching over the Internet a first content, identified by a first content identifier, stored in a first server that may be identified in the Internet by a first identifier, where the first content may be composed of multiple content parts, and each content part may be identified by a respective content part identifier. The method may be for use with a group of devices, each storing a copy of at least one content part and each group device may be identified in the internet by a respective group device identifier, and may be further for use with a second device identified in the Internet by a second identifier and storing the group device identifiers, and furthermore for use with a second server. The method may comprise the steps of the first device sending the first content identifier to the second server; in response to receiving the first content identifier, the second server sending the second identifier to the first device; the first device sending the first content identifier to the second device using the second identifier; and in response to receiving the first content identifier, the second device sending the group devices identifiers to the first device. Further, for each one out of the group devices identifiers, the method may comprise the steps of the first device sending a content part identifier to the group device using the group device identifier; and in response to receiving the content part identifier, the group device sending the content part identified by the content part identifier to the first device.</p><p id="p-0216" num="0218">The first device may consist of, comprise, or be part of, any network element. In one example, the first device may consist of, comprise, or be part of, a client device, such as the client device #<b>1</b>. The first server may consist of, comprise, or be part of, any network element. In one example, the first server may consist of, comprise, or be part of, the acceleration server. The second server may consist of, comprise, or be part of, any network element. In one example, the second server may consist of, comprise, or be part of, a data server, such as the data server #<b>1</b>. The third server may consist of, comprise, or be part of, any network element. In one example, the third server may consist of, comprise, or be part of, a data server, such as the data server #<b>2</b>. The second device may consist of, comprise, or be part of, any network element. In one example, the second device may consist of, comprise, or be part of, a tunnel device, such as the agent device #<b>1</b>. Any device included in the group of devices may consist of, comprise, or be part of, any network element. Alternatively or in addition, a group device may consist of, comprise, or be part of, a peer device, such as the peer device #<b>2</b>.</p><p id="p-0217" num="0219">The first server may be a web server, and the first content may be a web-site, a web-page, or a URL, and the first content identifier may be an IP address, URL, or an HTTP header. The first identifier may be the first server IP address, the second identifier may be the second IP address, and each of the group devices identifier may be an IP address or the respective group device. The first content may be composed of bits, nibbles, bytes, characters, words, or strings, and the content parts may be based on bit, nibble, byte, multi-byte, number, character, word, or string level partitioning of the first content, and the first content may include, consist of, or comprise, part or whole of files, text, numbers, audio, voice, multimedia, video, images, music, or computer program. Alternatively or in addition, the first content may include, be composed of, consist of, or comprise, a part of, or a whole of, files or programs, and the content parts may be based on file level or program level partitioning of the first content. Further, the first content may be a website content comprising multiple webpages, and the content parts may be based on webpages level partitioning of the first content. All the components of the first content may be included in all of the content parts. The method may further comprise the step of the first device reconstructing the first content from the received multiple content parts. Part of, or all of, the content parts may be having the same size, that may be 8 KB, 16 KB, 32 KB, or 64 KB. Two or more content parts may be identical and may contain the same data. A same portion of the first content may be included in two or more content parts. The content parts may be a result of a sequential, or a non-sequential, partitioning of the first content. The number of content parts may be equal to the number of group devices in the group. Each of the content part identifiers may be a hash value that may be the result of a hash function of the respective data in the content part, such as a checksum or CRC of the respective data in the content part. The CRC may be CRC-8, CRC-16. CRC-32, or CRC-64.</p><p id="p-0218" num="0220">The method may further comprise the steps of the first device sending the first content identifier to the first server using the first identifier; and in response to receiving the first content identifier, the first server may be sending the part of, or the whole of, the first content to the first device. These steps may precede, follow, or be executed concurrently, with any one of the previously mentioned steps, using multitasking or multiprocessing</p><p id="p-0219" num="0221">The method may be for use with a second group consisting of a plurality of devices, each associated with a respective identifier for being identified in the Internet, the second group including the second device, wherein in response to receiving the first content identifier, the second server sending the identifiers of all devices in the second group to the first device, and may further comprise the step of selecting the second device from the second group. The second device may be randomly selected out of the devices in the group, using one or more random numbers generated by a random number generator. The random number generator may be hardware based, and may be using thermal noise, shot noise, nuclear decaying radiation, photoelectric effect, or quantum phenomena. Alternatively or in addition, the random number generator may be software based, and may be based on executing an algorithm for generating pseudo-random numbers. Alternatively or in addition, the second device may be selected based on attributes or characteristics of the device. Further, the second device may be selected based on the physical geographical location, and the method may further comprise for each of the devices in the second group, the steps of sending the device physical geographical location to the first device, followed by the step of the first device storing the received second group devices physical geographical location. The physical geographical location may include a continent, a country, a state or province, a city, a street, or a ZIP code, as well as longitude and latitude. Furthermore, the second device may be selected based on the physical geographical proximity to the first device.</p><p id="p-0220" num="0222">Alternatively or in addition, the second device may be selected based on the second identifier, which may be an IP address, where the second device may be selected based on its IP address, or based on comparing the second identifier to a first device identifier. Further, the second device may be selected based on past activities, or based on the timing of an event, such as the last communication between the second device and the first device. Furthermore, the second device may be selected based on the ISP used to connect the second device to the Internet.</p><p id="p-0221" num="0223">One or more of the group devices may be storing the first content. Alternatively or in addition, all of the group devices may be storing the first content. Alternatively or in addition, at least one of, or all of, the group devices may be storing only one content part. Each of the identifiers may be an IP address (such as in IPv4 or IPv6 form) or a URL. At least one of the servers may be a web server using HyperText Transfer Protocol (HTTP) that responds to HTTP requests (such as the first and second requests) the via the Internet. Further, the communication with the second server may be based on, or using, HTTP persistent connection. Furthermore, the communication with the first device, the second device, one of the group devices, the first server, or the second server, may be based on, or may be according to, TCP/IP protocol or connection.</p><p id="p-0222" num="0224">The method may further comprise the step of of establishing a connection between the first device and the second device in response to receiving the second identifier, and the first device may be communicating with the second device over the established connection. Further, the first device may be communicating with the second device using TCP, wherein the connection may be established by performing &#x2018;Active OPEN&#x2019; or &#x2018;Passive OPEN&#x2019;. Alternatively or in addition, the first device may be communicating with the second device using a VPN or a tunneling protocol, and the connection may be established using authentication. Further, the method may comprise the step of of establishing a connection between the first device and at least one of the group devices in response to receiving the group devices identifiers. The first device may be communicating with at least one of, or all of, the group devices over established connections. The first device may be communicating with at least one of the group devices using TCP, and the connection may be established by performing &#x2018;Active OPEN&#x2019; or &#x2018;Passive OPEN&#x2019;. Alternatively or in addition, the first device may be communicating with at least one of the group devices using a VPN or using a tunneling protocol. Any of the connections may be using authentication.</p><p id="p-0223" num="0225">The method according may further used with a fourth device fetching over the Internet a second content, identified by a second content identifier, stored in a second server that may be identified in the Internet by a fifth identifier, the second content may be composed of multiple second content parts, each second content part may be identified by a respective second content part identifier, and may be for use with a second group of devices each storing a copy of at least one second content part and each second group device may be identified in the internet by a respective second group device identifier, where the first device may be identified in the Internet by a third identifier. The method may further comprise the steps of the fourth device sending the second content identifier to the second server; in response to receiving the second content identifier, the second server sending the third identifier to the fourth device; the fourth device sending the second content identifier to the first device using the third identifier; and in response to receiving the second content identifier, the first device sending the second group devices identifiers to the fourth device.</p><p id="p-0224" num="0226">The method may further be used with a fourth device fetching over the Internet a second content, identified by a second content identifier, stored in a second server that may be identified in the Internet by a fifth identifier, the second content may be composed of multiple second content parts, each second content part may be identified by a respective second content part identifier, and may be further for use with a second group of devices each storing a copy of at least one second content part and each second group device is identified in the internet by a respective second group device identifier where the first device may be identified in the Internet by a third identifier and may be storing at least one of the second content parts, and may be for use with a fifth device fetching identified in the Internet by a fifth identifier and storing the third identifier. The method may further comprise the steps of the fourth device sending the second content identifier to the second server; in response to receiving the second content identifier, the second server sending the fifth identifier to the fourth device; the fourth device sending the second content identifier to the fifth device using the fifth identifier; in response to receiving the second content identifier, the fourth device sending the third identifier to the fourth device; the fourth device sending the identifier of the at least one second content part stored in the first device to the first device using the third identifier; and in response to receiving the identifier of the at least one second content part, the first device sending the at least one second content part to the fourth device.</p><p id="p-0225" num="0227">The fourth device may consist of, comprise, or be part of, any network element. In one example, the first device may consist of, comprise, or be part of, a client device, such as the client device #<b>1</b>. In one example, the second server may consist of, comprise, or be part of, a data server, such as the data server #<b>2</b>. The fourth device and the second device may be the same device or distinct devices, and the fourth device may be the same as one of the group devices. The fifth device may consist of, comprise, or be part of, any network element. In one example, the fifth device may consist of, comprise, or be part of, an agent device, such as the agent device #<b>2</b>.</p><p id="p-0226" num="0228">The fourth device and the second device may be the same device or distinct devices. The fourth device may be the same as one of the group devices. Further, the fifth device and the second device may be the same device. Alternatively or in addition, the fifth device and the one of the group devices may be the same device.</p><p id="p-0227" num="0229">A method is disclosed for fetching over the Internet a first content, identified by a first content identifier, stored in a first server that may be identified in the Internet by a first identifier, the first content may be composed of multiple content parts, each content part may be identified by a respective content part identifier. The method may be used with a group of devices each storing a copy of at least one content part and each group device may be identified in the internet by a respective group device identifier, may be for use with a second device identified in the Internet by a second identifier and storing the group device identifiers, and may be used with a second server. The method may comprise the steps of sending the first content identifier to the second server; receiving the second identifier from the second server; sending the first content identifier to the second device using the second identifier; and receiving the group devices identifiers from the second device. For each one out of the group devices identifiers, the method may further comprise the steps of sending a content part identifier to the group device using the group device identifier; and receiving from the group device the content part identified by the content part identifier. The method may further comprise the steps of sending the first content identifier to the first server using the first identifier; and receiving the part of, or the whole of, the first content, from the first server.</p><p id="p-0228" num="0230">A method is disclosed for a first device fetching over the Internet a first content, identified by a first content identifier, stored in a first server that may be identified in the Internet by a first identifier, the first content may be composed of multiple content parts, each content part may be identified by a respective content part identifier, for use with a group of devices each storing a copy of at least one content part and each group device may be identified in the internet by a respective group device identifier. The method may be used with a second device identified in the Internet by a second identifier and storing the group device identifiers, and may further be for use with a second server. The method may comprise the steps of receiving the first content identifier from the first device; and sending the group devices identifiers to the first device.</p><p id="p-0229" num="0231">A method for a first device fetching over the Internet a first content, identified by a first content identifier, stored in a first server that may be identified in the Internet by a first identifier, the first content may be composed of multiple content parts, where each content part may be identified by a respective content part identifier, is disclosed. The method may comprise the steps of storing a content part identified by a content part identifier; receiving from the first device sending the content part identifier; and in response to receiving the content part identifier sending the content part identified by the content part identifier to the first device.</p><p id="p-0230" num="0232">A method and system using an internet-connected device designated as a tunnel device is disclosed. A tunnel device may receive from a client device a request for content from a data server. Upon receiving such a request, the tunnel device fetches the requested content from the data server and sends the retrieved content to the client device. The request may specify a range of, or any portion of, the content, and then only the specified portion or range is retrieved from the data server and sent to the requesting client device. A tunnel device may open multiple connections when fetching the requested content from the data server. In a case where more connections may be opened for higher loading bandwidth, the client device may send a request to the tunnel device to open more connection with the data server.</p><p id="p-0231" num="0233">The client device may use multiple tunnel devices, and may specify different or the same ranges or portions for each one of the tunnel devices. In a case where the requested content is locally stored in the tunnel device, such as in a local memory, such as a cache, the content is fetched from the local (internal) memory. Multiple tunnel devices, such as 5 tunnel devices, may be selected to be used by the client device, and the client device may request each of the tunnel devices to open more connections to the data server, up to the maximum allowable number of connections. The selection may be based on their proximity to the data server, such as selecting those tunnel devices that are the closest to the data server, based on their geolocation, IP distance, physical location, or the data communication characteristics.</p><p id="p-0232" num="0234">A first network element may request content stored in a second network element over a communication link being part of a network. A time period for fetching the content may be estimated by the first network element by estimating the Bandwidth (BW) and the Round Trip Time (RTT) associated with the content fetching transaction. The estimation of the BW and RTT may use a database that contains information relating to previous interactions with the second network elements. Alternatively or in addition, the estimation of the BW and RTT may use a database that contains information relating to previous interactions with a first group of network elements that are associated with an IP distance lower than, and with a second group of network elements that is associated with an IP distance higher than, the second network element, such as by calculating the average IP distance between the two groups.</p><p id="p-0233" num="0235">A system may comprise a central server and network elements, each of the network elements may be in an &#x2018;online&#x2019; or an &#x2018;offline&#x2019; state. When in the online' state, each of the network elements periodically transmits a message (such as a &#x2018;ping&#x2019;) to the central server. In response to receiving the message, the central server determines that the network element from which a message was received in a defined past period is in an &#x2018;online&#x2019; state, and further determines that network elements, from which a message was not received in the defined past period, are in an &#x2018;offline&#x2019; state.</p><p id="p-0234" num="0236">An operating system may send data from an application to network elements using sockets. A method may queue the data to be sent, and transfer the data to a socket that is available for immediate data transfer. The queue may be dynamic and may be part of an added layer to the OS. The added layer may further continuously check the sockets and queues, and upon detecting a queued data and a ready-to-send data socket, the data is un-queued from its dynamic queue and sent through the socket ready for sending. In a case where the application cancels the data sending, data is removed from the respective socket and the respective queue.</p><p id="p-0235" num="0237">In a network element that is connected to a network and includes an operating system and applications, a method by which a program on the network element may provide the communication configuration to the operating system, instead of the operating system getting it from a gateway on the network. The program may communicate with the external gateway to get the configuration information so that it can communicate with other network elements, and provides separate configuration information to the operating system, thereby having the operating system communicate with the program, and the program communicating with the external network elements.</p><p id="p-0236" num="0238">In a scenario where a communication of content between two network elements may use two or more data paths (routes), the content may be concurrently transmitted and received over multiple data paths. In one scenario, one or both of the network elements may connect only via a single data path. A reliability proxy server that is capable of concurrently communicating with one (or both) of the network elements over multiple data paths, may be used. The reliability proxy server serves as a proxy server, and communicate the content with one (or both) of the network elements over multiple data paths,</p><p id="p-0237" num="0239">A timeout period (such as 5 ms, or any period substantially shorter than the defined typical) may be defined for completing a DHCP request. A DHCP request is repeatedly retransmitted to a DHCP server upon each timeout expiration, until a response is received, or until the typical timeout period expires.</p><p id="p-0238" num="0240">A data may be transferred from a first network element to a second network element may involve transporting of a low priority, such as less time critical, meta data. Such meta data may be delayed by the first network element and be sent to the second network element only after higher priority, or more time sensitive, data was sent.</p><p id="p-0239" num="0241">For use with devices such as WiFi access points that requires authentication such as being password protected, a user may try to connect a network element to a device that its password is unknown. The connection may automatically guess passwords for the connection, such as passwords that were used to connect to other devices, passwords that are common in the geographical location, or passwords that are common to similar devices from this same manufacturer. A central server (or servers) may store a list of known devices, such as WiFi access points, and their associated authentication methods, and may further store social connections between users. A user connecting to the devices may be prompted to update the central server the authentication information regarding the device and the device associated sharing level with others. A sharing-approved user may fetch the authentication information from the central server for connecting to a device.</p><p id="p-0240" num="0242">A network element may use a hierarchical structure, whereby some of the graphical elements are sons or parents of other elements, for a user interface. If a user drags an object beyond the borders of a parent object, the dragging may be performed by carrying over (inheriting) the dragging to the parent object, and so recursively until reaching a parent that allows the dragging.</p><p id="p-0241" num="0243">A method is disclosed for dictionary-based compression scheme, that may be used with a first device storing a first content in a first memory, and a second device storing a second content in a second memory, and for use with communicating a third content stored in the first device over a network. The method comprising the steps of the first device partitioning at least part of the first content into a plurality of first content slices according to a partitioning scheme; the first device associating a distinct slice identifier to each of the first content slices according to a rule; the second device partitioning at least part of the second content into a plurality of second content slices according to a partitioning scheme; the second device associating a distinct slice identifier to each of the second content slices according to the rule; the first device partitioning at least part of the third content into a plurality of third content slices according to a partitioning scheme. For each one of the third content slices, the method may further comprise the steps of the first device comparing the data in the third content slice to the data in the plurality of the first content slices; the first device sending to the second device over the network the slice identifier of the first content slice that includes the same data as the third content slice; the second device receiving the slice identifiers sent from the first device over the network; and the second device associating second content slices associated with the received slice identifiers. Two of, or all of, the slices may have the same the same size. Two of, or all of, the slices may be the same. The partitioning may be sequential in the respective content.</p><p id="p-0242" num="0244">A method for attribute-based selecting devices by a first device located in a first geographical location, from a group of multiple Internet-connected devices is disclosed, where each of the group devices may be addressable in the Internet by a respective IP address. The method comprising the steps of obtaining a list of the IP addresses of the devices of the group; determining the geographical location of each of the group devices based on the IP address; associating a value of the attribute for each of the geographical location of each of the group devices; associating a first value of the attribute for the first geographical location; and selecting one or more devices from the group based on comparing the values of the group devices to the first value. A single device or multiple devices may be selected, associated with the first value or having a value close to the first value. The geographical location may consist of, or comprise, a continent, a country, a region, a city, a street, a ZIP code, or a timezone. The determining of the geographical location of each of the group devices may be based on a geolocation, such as based on W3C Geolocation API.</p><p id="p-0243" num="0245">The method may be used with a database associating IP addresses to geographical locations, wherein the determining of the geographical location of each of the group devices based on the IP address may be using the database. The database may be stored in the first device or may be stored in a server accessible via the Internet, where the geographical location may be determined by the first device sending the IP addresses of the group devices to the server over the Internet; in response to receiving the IP addresses, the server sending the database associated physical locations to the first device; and the first device receiving the physical locations from the server. The attribute may relate to people or society, such as language, sport, demographics, or religion, or may be demographic based, such as culture, race, ethnicity, population, age structure, population growth rate, death rate, birth rate, migration rate, sex ratio, life expectancy, or health expenditures. The attribute may be economy related, such as Gross Domestic Product (GDP), GDP per capita (PPP), gross national saving, agriculture products, industry types, labor force, unemployment rate, household income or consumption by percentage share, Government budget, taxes and other revenues, inflation rate (consumer prices), export/import of goods and services, household consumption, government consumption, or investment in fixed capital. The attribute may relate to geography, such as climate, coastline, terrain, natural resources, and environment.</p><p id="p-0244" num="0246">A method is disclosed for a first device fetching over the Internet a first content having a size X and identified by a first content identification, the first content may be stored in a second device that is identified in the Internet by a second identifier. The first device may be identified in the Internet by a first identifier, and the method may comprise the steps of the first device sending the first identifier and the first content identification to the second device; in response to receiving the first identifier and the first content identification, the second device sending the first content to the first device using the first identifier; the first device starting to receive the first content from the second device; the first device ending to receive the first content from the second device; the first device measuring an Round Trip Time (RTT) as a first time interval between the sending of the first identifier and the starting to receive the first content from the second device; the first device measuring a second time interval (T) between the starting and the ending of receiving the first content from the second device; and the first device calculating the bandwidth (BW) as X/T.</p><p id="p-0245" num="0247">The method may further comprise the step of the first device storing in a memory the RTT and the BW, or the step of the first device sending the RTT and the BW to the second device. The method may be used with a second content having a size Y identified by a second content identification stored in the second device, and the method may further comprise the step of estimating a third time interval between a sending of the first identifier to the second device and an ending to receive the second content from the second device, where the third time interval may be estimated to be RTT+Y/BW.</p><p id="p-0246" num="0248">A method is disclosed for a first device fetching over the Internet a first content having a size X identified by a first content identification, for use with a group of group devices, each of the group devices storing the first content and each identified in the Internet by a respective group device identifier. Each of the group devices may be associated with a respective Round Trip Time (RTT) and a respective bandwidth (BW), and the method may comprise the steps of for each one of the group devices, estimating the time interval for fetching the first content from the group device using the RTT and BW; selecting the group device having the lowest estimated time interval; the first device sending the first identifier and the first content identification to the selected group device; and in response to receiving the first identifier and the first content identification, the selected group device sending the first content to the first device using the first identifier. The method may further comprise the steps of the first device starting to receive the first content from the selected group device; the first device ending to receive the first content from the selected group device; the first device measuring an Round Trip Time (RTT) as a first time interval between the sending of the first identifier and the starting to receive the first content from the selected group device; the first device measuring a second time interval (T) between the starting and the ending of receiving the first content from the selected group device; and the first device calculating the bandwidth (BW) as X/T. Further, the method may further comprise the step of associating the measured RTT and the calculated BW with the selected group device, and the step of the first device storing in a memory the measured RTT and the calculated BW. Alternatively or in addition, the method may further comprising the step of the first device sending the measured RTT and the calculated BW to the selected group device, wherein the time interval for each group device is estimated using the RTT and the BW associated with the group device, and is calculated as RTT+X/BW.</p><p id="p-0247" num="0249">A method is disclosed for fetching to a first device a content having a size X from N multiple locations each storing a copy of a part of, or the entire of, the content. The method may comprise for each location designated as i (1&#x2264;i&#x2264;N) the steps of obtaining the Round Trip Time (RTTi), wherein the RTTi is the time interval between a sending of a request to the i location and a starting to receive part of the first content from the i location; obtaining the Bandwidth (BWi), wherein the BWi is the rate of receiving data after the starting to receive from the i location; and designating Ti as Ti=RTTi+Xi/BWi, wherein Xi is the size of part of the content fetched from the i location. The method may further comprise the steps of non-overlapping partitioning of the content into N partitions, wherein the size of each partition is designated as Xi, so that for i=1 to N, &#x3a3;Xi=X; the first device fetching the partitions from the N locations; and the first device assembling the content from the received partitions. The content may be stored in a device in each location, and the first device and the location devices may be interconnected via a digital network, such as the Internet.</p><p id="p-0248" num="0250">The partitioning may be based on the RTTi values, may be based on BWi, or may be based on both BWi and RTTi of all of the locations. The partitioning may be based on calculating the maximum or minimum value of Ti for all locations. Alternatively or in addition, the partitioning may be based on minimizing the maximum value of Ti for all locations, and may be calculated at the first device according to: Xi=BWi*[(X+&#x3a3;RTTi*BWi)/(&#x3a3;BWi)&#x2212;RTTi]. The RTTi and the BWi values may be stored in the first device, and may be based on previous communication with the locations. A non-transitory computer readable medium containing computer instructions that, when executed by a computer processor, cause the processor to perform at least part of, or all of, the above steps.</p><p id="p-0249" num="0251">The first device may consist of, comprise, or be part of, any network element. In one example, the first device may consist of, comprise, or be part of, a client device, such as the client device #<b>1</b>. The second device, or each of the group devices, may consist of, comprise, or be part of, any network element. In one example, the second device, or each of the group devices, may consist of, comprise, or be part of, a tunnel device, such as the tunnel device #<b>1</b> or the tunnel device #<b>2</b>.</p><p id="p-0250" num="0252">A method for improving the fetching of a content from a first server over the Internet, for use with a second server distinct from the first server identified in the Internet by an identifier, is described. The method may comprise the steps of the application sending a first message to the second server; intercepting the first message to the second server; obtaining a second message based on the first message and on the identifier; returning the second message to the application; and in response to receiving the second message, the application sending a request for the content to the first server. The interception may be by hooking to the application, may be in a filter driver form, or may use an Inter-Process Communication (IPC). The IPC may use, or be based on, a file sharing, a signal, a socket, a pipe, a message queue, a shared memory, a semaphore, memory mapped file, a clipboard, a Component Object Model (COM), a data copy, a DDE protocol, or mailslots.</p><p id="p-0251" num="0253">The application may be a web browser that consists of, comprises, or may be based on, Microsoft Internet Explorer, Google Chrome, Opera&#x2122;, or Mozilla Firefox&#xae;. The web browser may be a mobile web browser, which consists of, comprises of, or may be based on, Safari, Opera Mini&#x2122;, or Android web browser. The identifiers may be an IP address (in IPv4 or IPv6 form), or a URL.</p><p id="p-0252" num="0254">The first message may be a web analytic related message, and the second server may be a web analytic server, such as Google Analytics server. The second message may be the same as, or based on, a response to the first message from the web analytic server. The method may use a database storing a list of typical responses from a web analytic server, and the second message may be obtained from the database. The method may comprise the step of blocking the sending of the first message to the second server, and the step of receiving a response from the second server. The method may use a database storing a list of typical responses from a web analytic server, and may further comprise the step of storing the response from the second server in the database.</p><p id="p-0253" num="0255">A system is disclosed comprising multiple Internet-connected network elements, designated as peer devices, where each of the peer devices may store only a portion of a file (or other content) (&#x2018;chunks&#x2019;) in its cache memory. Network elements, designated as client devices, may use the peer devices for fetching the portions of the file therefrom, and reconstructing the entire file. The system may consist, may include, may be based on, or may be part of, the system described in the '604 Patent. A same portion or the file may be stored in two or more peer devices, each may be associated with a BW and RTT (where BW is the bandwidth of a peer device to the client device connection and RTT is the round trip time from a peer device to the client and back), and the peer device associated with the highest BW/RTT may be selected to provide the portion of the file. Alternatively or in addition, the number of portions allocated to be fetched from a peer device is based on, or pro-rata to, the respective peer device BW/RTT.</p><p id="p-0254" num="0256">The system may further comprise multiple Internet-connected network elements, designated as agent devices, which store in their memory information regarding which peer devices are storing which portions of the file, and further store which client devices requested which files, so that client devices may serve as peer devices for providing the portions of file that they have fetched. After a client device completes the fetching of a file, it may update network elements, such as the agent devices used, regarding the files availability in each of the used peer devices.</p><p id="p-0255" num="0257">An agent device may provide a client device a list of peer devices that may be used for sourcing a part of, or an entire of, the file, and the client device may select five (5) or any other number of peer devices from the list, to fetch data therefrom. The agent device may store a first list of peer devices that may be available for use and storing a part of, or an entire of, the file, and may select from the first list a second list of peer devices to be sent to the client device. The second list may be selected based on the BW/RTT ratio associated with the communication of the respective peer device with the client device, such as selecting the peer devices having the highest ration of BW/RTT. Alternatively or in addition, the second list may be selected based on recent transaction between these peer devices and other client devices, such as selecting only peer devices that completed a successful data transfer. Alternatively or in addition, the second list may be selected based on the geographical distance to the client device.</p><p id="p-0256" num="0258">The number of chunks allocated to the peer devices, to be fetched by a client device from the peer devices, may be set to a same number for all the peer devices. Alternatively or in addition, the number of chunks allocated to the peer devices may be determined by the latency in transporting the chunks to the client device, such as based on estimating the BW/RTT between the peer devices to the client device.</p><p id="p-0257" num="0259">A client device may send out the request for a list of agent devices also to other network elements that the client device has communicated with in the past, so that if these elements have knowledge of any agent devices that may provide the information about the applicable peer devices, such an agent devices list will be sent to the client device. If these network elements themselves have knowledge of peer devices (including themselves) that might provide portions of the data required by the client device, they might provide themselves as an agent devices to the client device. Further, the client device may fetch information from a peer device regarding available agent devices, such as agent devices that were previously used with the data server. Alternatively or in addition, the client device may request a list of agent devices from an acceleration server.</p><p id="p-0258" num="0260">A client device may request a list of peer devices from an agent device. If the requested data or file, in part or in whole, is stored in the agent device, the agent device may provide that data or file directly to the client device, instead of providing the meta data about the file to the client device. Alternatively or in addition, the agent device may provide that data or file directly to the client device only when the file is below a certain size, such as 16 KB. In a case where a client device fetches the required file from any other source, and that file is below that certain size, the client device may update and send the file to be stored in the agent devices, so that the data may be later provided to a client device.</p><p id="p-0259" num="0261">A client device may receive and use a list of agent devices for a specific transaction, and when the network is idle, the client device may update the acceleration server regarding the used agent devices, allowing the acceleration server to later recommend or use these agent devices. The updating of the acceleration server may include the IP address of each of the agent devices, the communication session information such as RTT, BW and speed, the ports used in the communication sessions, the latency and speed for each of the connection phases, and whether the required file or data was stored in each of the agent devices. The acceleration server may use this information to decide which agent devices to recommend and include in a future agent devices list requested by client devices. A client device may receive and use a list of peer devices for a specific transaction (such as from an agent device), and when the network is idle, the client device may update the acceleration server, agent devices, or both, regarding the used peer devices, allowing the acceleration server or the agent devices to later recommend or use these peer devices. The updating of the acceleration server or the agent devices may include the IP address of each of the peer devices, the communication session information such as RTT, BW and speed, the ports used in the communication sessions, the latency and speed for each of the connection phases, and whether the required file or data was stored in each of the peer devices. The acceleration server or the agent devices may use this information to decide which peer devices to recommend and include in future peer devices list requested, such as by client devices. In a case where an agent device does not store a required information, such as a peer devices list, the client device or the acceleration server may update the agent device with that information after it was obtained. Further, the client device or the acceleration server may update all of the agent devices that were used in a transaction. Such an update may be performed only when the communication is idling.</p><p id="p-0260" num="0262">The acceleration server may periodically review the load of each of the network elements (such as agent devices), and if two network elements are used below a certain threshold of load, it merges the range responsibilities of these network elements. The responsibilities may be the peer devices that the agent device is responsible for serving, or may be the data servers that the agent device is responsible for serving. A network element may log network elements that are accessing it, or may only log a portion of the requests according to a certain algorithm, by which the list of accessing network elements may be representative of all of the requests. The algorithm may be based on logging only the past several requests (such as a last 1000 requests or the requests in the past 5 minutes), or may be based on logging a logarithmically reducing list of random requests.</p><p id="p-0261" num="0263">Upon fetching requested chunks from various sources (such as peer devices) by a client device, some chunks may be larger than a pre-set minimum size. The client device may estimate that one of the sources will complete providing its last chunk much later than all other chunks from the other sources. In such a case, this chunk may be split into smaller sized chunks, such as into half of the original size, and re-distributed between the various sources. The splitting may be only performed if the last chunk is expected to delay the entire file loading by 10% or 50%. A back end module may be used that is based on applying criteria to a request received by a client device. Only requests that meet the criteria may be handled using a handling method associated with the criteria. The criteria may be based on the URL requested, the domain requested, the IP address of the request defined data server, the type of the requested file, the request timing, or the client device geographical location.</p><p id="p-0262" num="0264">Two or more data path may be available for fetching a content. The selection of which data path to use may be based on estimating the time for completing the content fetching for each data path, and may be based on historical data regarding the performance and timing of each stage of part connections of each of the data paths. The times used for each stage may be the top percentile under which most samples fall (e.g., using a sample that is larger than 95% of the other samples). A watermark system may be used to determine a threshold used to prefer and select one scheme over the other. If both data paths estimated performance are below a threshold, both data paths may be simultaneously used.</p><p id="p-0263" num="0265">In a case where either a peers-using scheme (system or method) or a tunnels-using scheme may be used, the scheme to be used may be selected based on an evaluating the time to completely receive the information using the scheme. The evaluation may be based on data from previous interactions with peer devices and tunnel devices associated with, or in the vicinity of, the available peer devices and tunnel devices. Once the desired scheme is chosen, a timer is set for the expected time to complete the transaction, and if that time plus a margin has passed, both schemes may be selected to operate concurrently. In such a case of simultaneous activation of both schemes, upon receiving the first piece of data by one of the schemes, and if the other scheme is still active, that other scheme is terminated. Alternatively or in addition, upon receiving the last piece by one of the schemes, if the other scheme is still active, it is terminated. Further, upon fetching all requested data, information about all of the participating network elements, including response times for one or more of their functions, is stored for future use, and may further be sent to other network elements in the network for future use.</p><p id="p-0264" num="0266">A method for managing congestion within a group of network elements is disclosed; where a central load-balancing server may identify that an element is congested. If over a certain amount of the network elements within the group are congested, a new network element is added to the group, and if over a certain amount of the network elements has not signaled being congested (such as by sending a message from the congested network elements), the server removes one or more of the network elements from the group. Alternatively or in addition, the signaling to the central load-balancing server may be performed by communication devices that are trying to connect or to use these network elements. The signaling to the central load-balancing server may be performed by the network elements whenever their own resources (such as storage capacity, I/O activity, CPU utilization, or available communication bandwidth) are used over a certain threshold. The central load-balancing server may send a request to the network elements and may mark them as congested, if they do not respond within a determined timeframe to a status request.</p><p id="p-0265" num="0267">Each of the identifiers herein may be an IP address (in IPv<b>4</b> or IPv<b>6</b> form) or a URL. Each of the servers may be a web server using HyperText Transfer Protocol (HTTP) that responds to HTTP requests via the Internet, and the first and second requests may be HTTP requests. Each communication with a server may be based on, or using, HTTP persistent connection.</p><p id="p-0266" num="0268">Any communication with a network element, such as with the first device, the second device, the first server, or the second server, may be based on, or be according to, TCP/IP protocol or connection, and may be preceded by the step of establishing a connection. Further, communication between any two network elements, such as between the first device and the second device, may be over the established connection. Any communication between any two network elements may use TCP, and wherein the connection may be established by performing &#x2018;Active OPEN&#x2019; or &#x2018;Passive OPEN&#x2019;, may use a VPN, or may use a tunneling protocol. Any content herein, such as the first content, may include, consist of, or comprise, a part or whole of files, text, numbers, audio, voice, multimedia, video, images, music, web-site page, or computer program.</p><p id="p-0267" num="0269">Each of the network elements herein, such as the first, second, and third servers, may store, operate, or use, a server operating system, that may be based on, comprise, or use, Microsoft Windows Server&#xae;, Linux, or UNIX, such as Microsoft Windows Server&#xae; 2003 R2, 2008, 2008 R2, 2012, or 2012 R2 variant, Linux&#x2122; or GNU/Linux based Debian GNU/Linux, Debian GNU/kFreeBSD, Debian GNU/Hurd, Fedora&#x2122;, Gentoo&#x2122;, Linspire&#x2122;, Mandriva, Red Hat&#xae; Linux, SuSE, and Ubuntu&#xae;, UNIX&#xae; variant Solaris&#x2122;, AIX&#xae;, Mac&#x2122; OS X, FreeBSD&#xae;, OpenBSD, and NetBSD&#xae;. Each of the network elements herein, such as the first, second, and third devices, may store, operate, or use, a client operating system, that may consist or, comprise of, or may be based on, Microsoft Windows 7, Microsoft Windows XP, Microsoft Windows 8, Microsoft Windows 8.1, Linux, or Google Chrome OS. The client operating system may be a mobile operating system, such as Android version 2.2 (Froyo), Android version 2.3 (Gingerbread), Android version 4.0 (Ice Cream Sandwich), Android Version 4.2 (Jelly Bean), Android version 4.4 (KitKat)), Apple iOS version 3, Apple iOS version 4, Apple iOS version 5, Apple iOS version 6, Apple iOS version 7, Microsoft Windows&#xae; Phone version 7, Microsoft Windows&#xae; Phone version 8, Microsoft Windows&#xae; Phone version 9, or Blackberry&#xae; operating system.</p><p id="p-0268" num="0270">Any method herein may further comprise the step of intercepting a request for a content by a network element, such as the intercepting of the request for the first content by the first device. The request may be initiated in an application (that may be a communications application such as a TCP/IP or HTTP handling application) in a network element such as the first device. The interception may be in the form of a plug-in or an extension of the application, may be by hooking to the application, may be in a filter driver form, or may be using Inter-Process Communication (IPC). The IPC may be using a file sharing, a signal, a socket, a pipe, a message queue, a shared memory, a semaphore, memory mapped file, a clipboard, a Component Object Model (COM), a data copy, a DDE protocol, or mailslots. The application may be a web browser that may be consisting of, comprising of, or may be based on, Microsoft Internet Explorer, Google Chrome, Opera&#x2122;, or Mozilla Firefox&#xae;. Alternatively or in addition, the web browser may be a mobile web browser, that consist of, comprise of, or may be based on, Safari, Opera Mini&#x2122;, or Android web browser.</p><p id="p-0269" num="0271">Any system or method herein may implement redundancy, where the system or method may include one or more additional identical, similar, or different element, such as using two or more identical or similar slices or any other content parts, using two or more identical or similar network elements performing identical or similar functionalities, using two or more identical or similar hardware pieces performing identical or similar functionalities, or using two or more data-paths transporting identical or similar information. The redundancy may be based on Dual Modular Redundancy (DMR), Triple Modular Redundancy (TMR), Quadruple Modular Redundancy (QMR), 1:N Redundancy, &#x2018;Cold Standby&#x2019;, or &#x2018;Hot Standby&#x2019;.</p><p id="p-0270" num="0272">The steps described herein may be sequential, and performed in the described order. For example, in a case where a step is performed in response to another step, or upon completion of another step, the steps are executed one after the other. However, in case where two or more steps are not explicitly described as being sequentially executed, these steps may be executed in any order, or may be simultaneously performed. Two or more steps may be executed by two different network elements, or in the same network element, and may be executed in parallel using multiprocessing or multitasking.</p><p id="p-0271" num="0273">A tangible machine-readable medium (such as a storage) may have a set of instructions detailing part (or all) of the methods and steps described herein stored thereon, so that when executed by one or more processors, may cause the one or more processors to perform part of, or all of, the methods and steps described herein. Any of the network elements may be a computing device that comprises a processor and a computer-readable memory (or any other tangible machine-readable medium), and the computer-readable memory may comprise computer-readable instructions such that, when read by the processor, the instructions causes the processor to perform the one or more of the methods or steps described herein.</p><p id="p-0272" num="0274">Any communication or connection herein, such as the connection of peripherals in general, and memories in particular to a processor, and between any two network elements, may use a bus. A communication link (such as Ethernet, or any other LAN, PAN or WAN communication links may also be regarded as buses herein. A bus may be an internal bus, an external bus or both. A bus may be a parallel or a bit-serial bus. A bus may be based on a single or on multiple serial links or lanes. A bus medium may be electrical conductors based such as wires or cables, or may be based on a fiber-optic cable. A bus topology may use point-to-point, multi-drop (electrical parallel) and daisy-chain, and may be based on hubs or switches. A point-to-point bus may be full-duplex, or half-duplex. Further, a bus may use proprietary specifications, or may be based on, similar to, substantially or fully compliant to an industry standard (or any variant thereof), and may be hot-pluggable. A bus may be defined to carry only digital data signals, or may also defined to carry a power signal (commonly DC voltages), either in separated and dedicated cables and connectors, or may carry the power and digital data together over the same cable. A bus may support master/slave configuration. A bus may carry a separated and dedicated timing signal or may use self-clocking line-code.</p><p id="p-0273" num="0275">The networks or the data paths may be similar, identical or different geographical scale or coverage types and data rates, such as NFCs, PANs, LANs, MANs, or WANs, or any combination thereof. The networks or the data paths may be similar, identical or different types of modulation, such as Amplitude Modulation (AM), a Frequency Modulation (FM), or a Phase Modulation (PM), or any combination thereof. The networks or the data paths may be similar, identical or different types of duplexing such half- or full-duplex, or any combination thereof. The networks or the data paths may be based on similar, identical or different types of switching such as circuit-switched or packet-switched, or any combination thereof. The networks or the data paths may have similar, identical or different ownership or operation, such as private or public networks, or any combination thereof.</p><p id="p-0274" num="0276">Any selection of devices herein, such as the selection of tunnel devices to be used either by a client device or by an acceleration sever, or the selection of agent devices either by a client device or by an acceleration sever, or the selection of peer devices, either by a client device or by an agent device, may be based on one or more of the following: Content URL, such as specific files on the Internet (e.g., &#x201c;Wikipedia.org/contact.html&#x201d;), domain name such as specific web sites (e.g., &#x201c;Wikipedia.org&#x201d;), data server IP such as specific servers (e.g., server having IP address of &#x201c;208.80.152.201&#x201d;), type of file such as specific file types (e.g., &#x201c;.flv files&#x201d;), time of day such as specific handling of all files or a group of files during certain hours of the day (e.g., &#x201c;all files between 11 pm to 4 am&#x201d;), or geography of the client such as specific handling according to a location of the client device (e.g., &#x201c;for all Clients in Germany&#x201d;).</p><p id="p-0275" num="0277">The above summary is not an exhaustive list of all aspects of the present invention. Indeed, it is contemplated that the invention includes all systems and methods that can be practiced from all suitable combinations and derivatives of the various aspects summarized above, as well as those disclosed in the detailed description below and particularly pointed out in the claims filed with the application. Such combinations have particular advantages not specifically recited in the above summary.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0276" num="0278">The invention is herein described, by way of non-limiting examples only, with reference to the accompanying drawings, wherein like designations denote like elements. Understanding that these drawings only provide information concerning typical embodiments of the invention and are not therefore to be considered limiting in scope:</p><p id="p-0277" num="0279"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates schematically a block diagram of a computer connected to the Internet;</p><p id="p-0278" num="0280"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts schematically the Internet and computers connected to the Internet;</p><p id="p-0279" num="0281"><figref idref="DRAWINGS">FIG. <b>2</b><i>a </i></figref>illustrates schematically a structure of an IP-based packet;</p><p id="p-0280" num="0282"><figref idref="DRAWINGS">FIG. <b>2</b><i>b </i></figref>depicts schematically a computerized device communicating with WAPs;</p><p id="p-0281" num="0283"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates schematically a simplified flowchart in a WDM architecture;</p><p id="p-0282" num="0284"><figref idref="DRAWINGS">FIG. <b>3</b><i>a </i></figref>illustrates schematically a simplified flowchart in a Linux architecture;</p><p id="p-0283" num="0285"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates schematically a block diagram of a one-way compression-based communication;</p><p id="p-0284" num="0286"><figref idref="DRAWINGS">FIG. <b>4</b><i>a </i></figref>illustrates schematically a block diagram of a two-way compression-based communication;</p><p id="p-0285" num="0287"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts schematically client devices, tunnel devices, and servers connected to the Internet;</p><p id="p-0286" num="0288"><figref idref="DRAWINGS">FIG. <b>5</b><i>a </i></figref>illustrates schematically a table of data stored in a server;</p><p id="p-0287" num="0289"><figref idref="DRAWINGS">FIG. <b>5</b><i>b </i></figref>illustrates schematically a timing chart of messages and states associated with messages exchanged over the Internet in a system using tunnel devices;</p><p id="p-0288" num="0290"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates schematically a simplified flowchart of a method relating to a client device using a single tunnel device;</p><p id="p-0289" num="0291"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates schematically a simplified flowchart of a method relating to a tunnel device;</p><p id="p-0290" num="0292"><figref idref="DRAWINGS">FIG. <b>7</b><i>a </i></figref>illustrates schematically a simplified flowchart for increasing a number of connections to a server;</p><p id="p-0291" num="0293"><figref idref="DRAWINGS">FIG. <b>7</b><i>b </i></figref>illustrates schematically a simplified flowchart involving locally fetching of a content;</p><p id="p-0292" num="0294"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates schematically a simplified flowchart relating to an acceleration server in a tunnel-device based system;</p><p id="p-0293" num="0295"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates schematically a simplified flowchart relating to an acceleration server that also selects the tunnels to be used;</p><p id="p-0294" num="0296"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates schematically a simplified flowchart of a method relating to a client device using multiple tunnel devices;</p><p id="p-0295" num="0297"><figref idref="DRAWINGS">FIG. <b>10</b><i>a </i></figref>illustrates schematically a simplified flowchart of a method relating to a client device using multiple tunnel devices and direct access;</p><p id="p-0296" num="0298"><figref idref="DRAWINGS">FIGS. <b>11</b>, <b>11</b></figref><i>a</i>, and <b>11</b><i>b </i>depict schematically messages exchanged over the Internet between a client device and a data server, using different tunnel devices;</p><p id="p-0297" num="0299"><figref idref="DRAWINGS">FIG. <b>11</b><i>c </i></figref>depicts schematically messages exchanged over the Internet between a client device and a data server using a direct access;</p><p id="p-0298" num="0300"><figref idref="DRAWINGS">FIG. <b>12</b></figref> depicts schematically client devices, tunnel devices, servers, and client/tunnel device connected to the Internet;</p><p id="p-0299" num="0301"><figref idref="DRAWINGS">FIG. <b>12</b><i>a </i></figref>depicts schematically messages exchanged over the Internet between a client device and a data server using a client/tunnel device;</p><p id="p-0300" num="0302"><figref idref="DRAWINGS">FIG. <b>13</b></figref> depicts schematically client devices, tunnel devices, and servers connected to the Internet, where the client device is implemented using a proxy server;</p><p id="p-0301" num="0303"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates schematically a simplified flowchart of a method relating to a client device measuring and logging a communication with a tunnel device;</p><p id="p-0302" num="0304"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates schematically a table of a log of transactions of a client;</p><p id="p-0303" num="0305"><figref idref="DRAWINGS">FIG. <b>15</b><i>a </i></figref>illustrates schematically a table of a log of transactions of a client relating to content fetching from a single data server;</p><p id="p-0304" num="0306"><figref idref="DRAWINGS">FIG. <b>16</b></figref> illustrates schematically a simplified flowchart of managing a number of connections to a server by a client device;</p><p id="p-0305" num="0307"><figref idref="DRAWINGS">FIG. <b>17</b></figref> illustrates schematically a simplified flowchart of an accessing of an analytics server;</p><p id="p-0306" num="0308"><figref idref="DRAWINGS">FIG. <b>17</b><i>a </i></figref>illustrates schematically a simplified flowchart of an intercepting and simulating access to an analytics server;</p><p id="p-0307" num="0309"><figref idref="DRAWINGS">FIG. <b>18</b></figref> depicts schematically a computerized device accessing DHCP servers;</p><p id="p-0308" num="0310"><figref idref="DRAWINGS">FIG. <b>18</b><i>a </i></figref>illustrates schematically a simplified flowchart of accessing of a DHCP server;</p><p id="p-0309" num="0311"><figref idref="DRAWINGS">FIG. <b>19</b></figref> illustrates schematically a simplified flowchart of improving an accessing of a DHCP server;</p><p id="p-0310" num="0312"><figref idref="DRAWINGS">FIG. <b>20</b></figref> depicts schematically client devices, agent devices, peer devices, and server devices connected to the Internet;</p><p id="p-0311" num="0313"><figref idref="DRAWINGS">FIG. <b>21</b></figref> depicts schematically the relations of chunks relating to URLs and peer devices;</p><p id="p-0312" num="0314"><figref idref="DRAWINGS">FIG. <b>21</b><i>a </i></figref>depicts schematically the relations of content in peer devices to content in agent devices;</p><p id="p-0313" num="0315"><figref idref="DRAWINGS">FIG. <b>21</b><i>b </i></figref>depicts schematically the relations of content in peer devices to content of URLs;</p><p id="p-0314" num="0316"><figref idref="DRAWINGS">FIG. <b>21</b><i>c </i></figref>depicts schematically the relations of content in peer devices to content in agent devices;</p><p id="p-0315" num="0317"><figref idref="DRAWINGS">FIG. <b>22</b></figref> illustrates schematically a timing chart of messages and states associated with messages exchanged over the Internet in a system using peer and agent devices;</p><p id="p-0316" num="0318"><figref idref="DRAWINGS">FIGS. <b>23</b>, <b>23</b></figref><i>a</i>, and <b>23</b><i>b </i>illustrate schematically a simplified flowchart relating to a client device using agent and peer devices;</p><p id="p-0317" num="0319"><figref idref="DRAWINGS">FIG. <b>24</b></figref> illustrates schematically a simplified flowchart relating to an agent device;</p><p id="p-0318" num="0320"><figref idref="DRAWINGS">FIG. <b>24</b><i>a </i></figref>illustrates schematically a simplified flowchart relating to a peer device;</p><p id="p-0319" num="0321"><figref idref="DRAWINGS">FIG. <b>25</b></figref> illustrates schematically a simplified flowchart relating to an acceleration server in a peer and agent devices system;</p><p id="p-0320" num="0322"><figref idref="DRAWINGS">FIG. <b>25</b><i>a </i></figref>illustrates schematically a table of data stored in an acceleration server;</p><p id="p-0321" num="0323"><figref idref="DRAWINGS">FIG. <b>26</b></figref> depicts schematically messages exchanged over the Internet between a client device and an acceleration server;</p><p id="p-0322" num="0324"><figref idref="DRAWINGS">FIG. <b>26</b><i>a </i></figref>depicts schematically messages exchanged over the Internet between a client device and an agent device;</p><p id="p-0323" num="0325"><figref idref="DRAWINGS">FIGS. <b>26</b><i>b</i>, <b>26</b><i>c</i>, and <b>26</b><i>d </i></figref>depict schematically messages exchanged over the Internet between a client device and a peer device;</p><p id="p-0324" num="0326"><figref idref="DRAWINGS">FIG. <b>27</b></figref> illustrates schematically a simplified flowchart relating to a client device measuring and logging a communication with a peer device;</p><p id="p-0325" num="0327"><figref idref="DRAWINGS">FIG. <b>28</b></figref> illustrates schematically a table representing a log of transactions of a client device;</p><p id="p-0326" num="0328"><figref idref="DRAWINGS">FIG. <b>28</b><i>a </i></figref>illustrates schematically a table representing a log of transactions of a client device relating to content fetching from a single data server,</p><p id="p-0327" num="0329"><figref idref="DRAWINGS">FIG. <b>29</b></figref> depicts schematically timing considerations involving a client device and peer devices;</p><p id="p-0328" num="0330"><figref idref="DRAWINGS">FIG. <b>29</b><i>a </i></figref>depicts schematically the calculations involving optimal timing considerations of a system involving a client device and peer devices;</p><p id="p-0329" num="0331"><figref idref="DRAWINGS">FIG. <b>29</b><i>b </i></figref>depicts schematically a chunks flow in a system involving a client device and peer devices;</p><p id="p-0330" num="0332"><figref idref="DRAWINGS">FIG. <b>29</b><i>c </i></figref>depicts schematically an improved chunks flow in a system involving a client device and peer devices;</p><p id="p-0331" num="0333"><figref idref="DRAWINGS">FIG. <b>29</b><i>d </i></figref>illustrates schematically a simplified flowchart for an improved flow of chunks in a system involving a client device and peer devices;</p><p id="p-0332" num="0334"><figref idref="DRAWINGS">FIG. <b>29</b><i>e </i></figref>depicts schematically a flow of chunks in a system involving a client device and peer devices;</p><p id="p-0333" num="0335"><figref idref="DRAWINGS">FIG. <b>29</b><i>f </i></figref>depicts schematically an improved chunks flow in a system involving a client device and peer devices;</p><p id="p-0334" num="0336"><figref idref="DRAWINGS">FIG. <b>30</b></figref> illustrates schematically a state diagram of a network element;</p><p id="p-0335" num="0337"><figref idref="DRAWINGS">FIG. <b>31</b></figref> illustrates schematically a simplified flowchart for determining a network element status;</p><p id="p-0336" num="0338"><figref idref="DRAWINGS">FIG. <b>32</b></figref> illustrates schematically a simplified flowchart for determining a network element status of a connected device;</p><p id="p-0337" num="0339"><figref idref="DRAWINGS">FIG. <b>33</b></figref> illustrates schematically a simplified flowchart for determining by a client the content fetching method;</p><p id="p-0338" num="0340"><figref idref="DRAWINGS">FIG. <b>34</b></figref> depicts schematically client devices, tunnel devices, agent devices, peer devices, and servers connected to the Internet;</p><p id="p-0339" num="0341"><figref idref="DRAWINGS">FIG. <b>35</b></figref> illustrates schematically a simplified flowchart relating to selecting devices based on an attribute relating to their geographical location;</p><p id="p-0340" num="0342"><figref idref="DRAWINGS">FIG. <b>36</b></figref> illustrates schematically a simplified flowchart relating to scaling an image;</p><p id="p-0341" num="0343"><figref idref="DRAWINGS">FIG. <b>36</b><i>a </i></figref>depicts schematically a part of a prior art image upscaling;</p><p id="p-0342" num="0344"><figref idref="DRAWINGS">FIG. <b>36</b><i>b </i></figref>depicts schematically a part of a prior art image downscaling;</p><p id="p-0343" num="0345"><figref idref="DRAWINGS">FIG. <b>37</b></figref> depicts schematically a prior art limited object movement on a screen;</p><p id="p-0344" num="0346"><figref idref="DRAWINGS">FIG. <b>37</b><i>a </i></figref>depicts schematically an unlimited movement of an object on a screen;</p><p id="p-0345" num="0347"><figref idref="DRAWINGS">FIG. <b>38</b></figref> illustrates schematically a simplified flowchart relating to unlimited moving object on a screen;</p><p id="p-0346" num="0348"><figref idref="DRAWINGS">FIG. <b>39</b></figref> depicts schematically a computerized device communicating with locked WAPs;</p><p id="p-0347" num="0349"><figref idref="DRAWINGS">FIG. <b>40</b></figref> illustrates schematically a simplified flowchart relating to guessing passwords in a WiFi environment;</p><p id="p-0348" num="0350"><figref idref="DRAWINGS">FIG. <b>41</b></figref> depicts schematically computerized devices communicating with locked WAPs;</p><p id="p-0349" num="0351"><figref idref="DRAWINGS">FIG. <b>42</b></figref> illustrates schematically a simplified flowchart relating to sharing passwords in a WiFi environment;</p><p id="p-0350" num="0352"><figref idref="DRAWINGS">FIG. <b>43</b></figref> illustrates schematically a simplified flowchart relating to the normalizing reference of a video content;</p><p id="p-0351" num="0353"><figref idref="DRAWINGS">FIG. <b>44</b></figref> illustrates schematically a block diagram relating to queueing schemes in a WDM architecture;</p><p id="p-0352" num="0354"><figref idref="DRAWINGS">FIG. <b>45</b></figref> illustrates schematically a block diagram relating to an improved dynamic queueing scheme in a WDM architecture;</p><p id="p-0353" num="0355"><figref idref="DRAWINGS">FIG. <b>46</b></figref> illustrates schematically a simplified flowchart relating to implementing an improved dynamic queueing scheme;</p><p id="p-0354" num="0356"><figref idref="DRAWINGS">FIG. <b>47</b></figref> illustrates schematically a block diagram relating to a one-way compression using a local dictionary;</p><p id="p-0355" num="0357"><figref idref="DRAWINGS">FIG. <b>48</b></figref> illustrates schematically a simplified flowchart relating to implementing a one-way compression using a local dictionary;</p><p id="p-0356" num="0358"><figref idref="DRAWINGS">FIG. <b>48</b><i>a </i></figref>illustrates schematically a simplified flowchart relating to implementing a compression using both dictionaries;</p><p id="p-0357" num="0359"><figref idref="DRAWINGS">FIG. <b>49</b></figref> illustrates schematically a block diagram relating to multiple copies of the same content;</p><p id="p-0358" num="0360"><figref idref="DRAWINGS">FIG. <b>49</b><i>a </i></figref>illustrates schematically a simplified flowchart relating to comparing multiple copies of the same content;</p><p id="p-0359" num="0361"><figref idref="DRAWINGS">FIG. <b>49</b><i>b </i></figref>illustrates schematically a simplified flowchart relating to validating a copy of a content;</p><p id="p-0360" num="0362"><figref idref="DRAWINGS">FIG. <b>50</b></figref> illustrates schematically a gateway connecting network elements over a WAN and a LAN;</p><p id="p-0361" num="0363"><figref idref="DRAWINGS">FIG. <b>51</b></figref> illustrates schematically using a VGS for communicating with a gateway connecting network elements over a WAN and a LAN;</p><p id="p-0362" num="0364"><figref idref="DRAWINGS">FIG. <b>51</b><i>a </i></figref>illustrates schematically a simplified flowchart of a VGS;</p><p id="p-0363" num="0365"><figref idref="DRAWINGS">FIG. <b>52</b></figref> depicts schematically a prior art of a cache arrangement in a memory;</p><p id="p-0364" num="0366"><figref idref="DRAWINGS">FIG. <b>53</b></figref> depicts schematically a cache arrangement in a memory using overwrite reduction;</p><p id="p-0365" num="0367"><figref idref="DRAWINGS">FIG. <b>54</b></figref> illustrates schematically a simplified flowchart for cache overwrite reduction and cleanup;</p><p id="p-0366" num="0368"><figref idref="DRAWINGS">FIG. <b>55</b></figref> depicts schematically a cache arrangement in a memory using redundancy with overwrite reduction;</p><p id="p-0367" num="0369"><figref idref="DRAWINGS">FIG. <b>56</b></figref> illustrates schematically a simplified flowchart for cache overwrite reduction;</p><p id="p-0368" num="0370"><figref idref="DRAWINGS">FIG. <b>57</b></figref> depicts schematically a cache arrangement in a memory using overwrite reduction and having multiple chunk copies;</p><p id="p-0369" num="0371"><figref idref="DRAWINGS">FIG. <b>58</b></figref> depicts schematically a prior-art association of physical addresses to virtual addresses;</p><p id="p-0370" num="0372"><figref idref="DRAWINGS">FIG. <b>59</b></figref> illustrates schematically a simplified block diagram of a memory management unit for translating between physical addresses and virtual addresses;</p><p id="p-0371" num="0373"><figref idref="DRAWINGS">FIG. <b>60</b></figref> illustrates schematically a simplified block diagram of a prior-art memory management unit operation;</p><p id="p-0372" num="0374"><figref idref="DRAWINGS">FIG. <b>61</b></figref> illustrates schematically a simplified flowchart of a prior-art method of an exception handler;</p><p id="p-0373" num="0375"><figref idref="DRAWINGS">FIG. <b>62</b></figref> illustrates schematically a simplified flowchart of an NDCACHE operation;</p><p id="p-0374" num="0376"><figref idref="DRAWINGS">FIG. <b>63</b></figref> illustrates schematically a simplified block diagram of an NDCACHE API;</p><p id="p-0375" num="0377"><figref idref="DRAWINGS">FIG. <b>64</b></figref> illustrates schematically a simplified block diagram of mounting a filesystem;</p><p id="p-0376" num="0378"><figref idref="DRAWINGS">FIG. <b>65</b></figref> illustrates schematically a simplified block diagram of mounting a TMPFS filesystem;</p><p id="p-0377" num="0379"><figref idref="DRAWINGS">FIG. <b>66</b></figref> illustrates schematically a simplified flowchart of an NDCACHE operation using FS mounting;</p><p id="p-0378" num="0380"><figref idref="DRAWINGS">FIG. <b>67</b></figref> illustrates schematically a simplified flowchart of an NDCACHE operation using user and kernel mode;</p><p id="p-0379" num="0381"><figref idref="DRAWINGS">FIG. <b>68</b></figref> illustrates schematically a first part of a simplified block diagram of a high-level implementation of NDCACHE;</p><p id="p-0380" num="0382"><figref idref="DRAWINGS">FIG. <b>69</b></figref> depicts schematically an arrangement in a memory of NDCACHE pages and using a lock flag;</p><p id="p-0381" num="0383"><figref idref="DRAWINGS">FIG. <b>70</b></figref> illustrates schematically a second part of a simplified block diagram of a high-level implementation of NDCACHE;</p><p id="p-0382" num="0384"><figref idref="DRAWINGS">FIG. <b>71</b></figref> illustrates schematically a third part of a simplified block diagram of a high-level implementation of NDCACHE;</p><p id="p-0383" num="0385"><figref idref="DRAWINGS">FIG. <b>72</b></figref> depicts schematically an arrangement in a memory of NDCACHE pages using multiple segments in the cache;</p><p id="p-0384" num="0386"><figref idref="DRAWINGS">FIG. <b>73</b></figref> illustrates schematically a simplified flowchart of an improved NDCACHE operation;</p><p id="p-0385" num="0387"><figref idref="DRAWINGS">FIG. <b>74</b></figref> depicts schematically an arrangement in a memory of NDCACHE pages;</p><p id="p-0386" num="0388"><figref idref="DRAWINGS">FIG. <b>75</b></figref> illustrates schematically a first part of a simplified block diagram of a high-level implementation of an improved NDCACHE;</p><p id="p-0387" num="0389"><figref idref="DRAWINGS">FIG. <b>76</b></figref> illustrates schematically a second part of a simplified block diagram of a high-level implementation of an improved NDCACHE;</p><p id="p-0388" num="0390"><figref idref="DRAWINGS">FIG. <b>77</b></figref> illustrates schematically a simplified flowchart of an idle monitor;</p><p id="p-0389" num="0391"><figref idref="DRAWINGS">FIG. <b>78</b></figref> illustrates schematically a simplified block diagram of an idle monitor for reducing a storage read time;</p><p id="p-0390" num="0392"><figref idref="DRAWINGS">FIG. <b>79</b></figref> illustrates schematically a simplified flowchart of selecting WAP.</p><p id="p-0391" num="0393"><figref idref="DRAWINGS">FIG. <b>80</b></figref> illustrates schematically a simplified flowchart of an improved selection of a WAP;</p><p id="p-0392" num="0394"><figref idref="DRAWINGS">FIG. <b>81</b></figref> depicts schematically a network element selecting a WAP from two groups of WAPs;</p><p id="p-0393" num="0395"><figref idref="DRAWINGS">FIG. <b>82</b></figref> depicts schematically a network element selecting a WAP based on the WAP performance;</p><p id="p-0394" num="0396"><figref idref="DRAWINGS">FIG. <b>83</b></figref> illustrates schematically a simplified flowchart for selecting a WAP based on the WAP prior performance;</p><p id="p-0395" num="0397"><figref idref="DRAWINGS">FIG. <b>84</b></figref> illustrates schematically two network elements connected over an unreliable connection;</p><p id="p-0396" num="0398"><figref idref="DRAWINGS">FIG. <b>85</b></figref> illustrates schematically two network elements connected over multiple unreliable connections;</p><p id="p-0397" num="0399"><figref idref="DRAWINGS">FIG. <b>86</b></figref> illustrates schematically two network elements connected over multiple unreliable connections using a reliability proxy server;</p><p id="p-0398" num="0400"><figref idref="DRAWINGS">FIG. <b>87</b></figref> illustrates schematically two network elements connected over multiple unreliable connections using two reliability proxy servers;</p><p id="p-0399" num="0401"><figref idref="DRAWINGS">FIG. <b>88</b></figref> illustrates schematically a simplified flowchart for using a reliability proxy network server;</p><p id="p-0400" num="0402"><figref idref="DRAWINGS">FIG. <b>89</b></figref> illustrates schematically a simplified flowchart for carrying packets over multiple routes;</p><p id="p-0401" num="0403"><figref idref="DRAWINGS">FIG. <b>90</b></figref> illustrates schematically a simplified flowchart for minimizing disconnect times when using multiple routes;</p><p id="p-0402" num="0404"><figref idref="DRAWINGS">FIG. <b>91</b></figref> illustrates schematically a table containing IP related BW and RTT values;</p><p id="p-0403" num="0405"><figref idref="DRAWINGS">FIG. <b>92</b></figref> illustrates schematically a simplified flowchart for estimating BW and RTT values relating to network elements;</p><p id="p-0404" num="0406"><figref idref="DRAWINGS">FIG. <b>93</b></figref> illustrates schematically a simplified flowchart for reading or storing BW and RTT values relating to network elements; and</p><p id="p-0405" num="0407"><figref idref="DRAWINGS">FIG. <b>94</b></figref> illustrates schematically a simplified flowchart for estimating BW and RTT values relating to network elements.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0406" num="0408">The principles and operation of an apparatus or a method according to the present invention may be understood with reference to the figures and the accompanying description wherein identical or similar components (either hardware or software) appearing in different figures are denoted by identical reference numerals. The drawings and descriptions are conceptual only. In actual practice, a single component can implement one or more functions; alternatively or in addition, each function can be implemented by a plurality of components and devices. In the figures and descriptions, identical reference numerals indicate those components that are common to different embodiments or configurations. Identical numerical references (in some cases, even in the case of using different suffix, such as <b>5</b>, <b>5</b><i>a, </i><b>5</b><i>b </i>and <b>5</b><i>c</i>) refer to functions or actual devices that are either identical, substantially similar, similar, or having similar functionality. It will be readily understood that the components of the present invention, as generally described and illustrated in the figures herein, could be arranged and designed in a wide variety of different configurations. Thus, the following more detailed description of the embodiments of the apparatus, system, and method of the present invention, as represented in the figures herein, is not intended to limit the scope of the invention, as claimed, but is merely representative of embodiments of the invention. It is to be understood that the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; herein include plural referents unless the context clearly dictates otherwise. Thus, for example, reference to &#x201c;a component surface&#x201d; includes reference to one or more of such surfaces. By the term &#x201c;substantially&#x201d; it is meant that the recited characteristic, parameter, or value need not be achieved exactly, but that deviations or variations, including, for example, tolerances, measurement error, measurement accuracy limitations and other factors known to those of skill in the art, may occur in amounts that do not preclude the effect the characteristic was intended to provide.</p><p id="p-0407" num="0409">Each of devices herein may consist of, include, be part of, or be based on, a part of, or the whole of, the computer <b>11</b> or the system <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Each of the servers herein may consist of, may include, or may be based on, a part or a whole of the functionalities or structure (such as software) of any server described in the '604 Patent, such as the web server, the proxy server, or the acceleration server. Each of the clients or devices herein may consist of, may include, or may be based on, a part or a whole of the functionalities or structure (such as software) of any client or device described in the '604 Patent, such as the peer, client, or agent devices.</p><p id="p-0408" num="0410">In one example, an accessing to a data server is improved by using an intermediate device referred to as &#x2018;tunnel&#x2019; device, that is executing a &#x2018;tunnel&#x2019; flowchart. <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a system <b>30</b> including two client devices, a client device #<b>1</b> <b>31</b><i>a </i>and a client device #<b>2</b> <b>31</b><i>b, </i>that may access the data servers <b>22</b><i>a </i>and <b>22</b><i>b </i>using one or more of a tunnel device #<b>1</b> <b>33</b><i>a, </i>a tunnel device #<b>2</b> <b>33</b><i>b, </i>and a tunnel device #<b>3</b> <b>33</b><i>c, </i>under the management and control of an acceleration server <b>32</b>. These network elements communicates with each other using the Internet <b>113</b>.</p><p id="p-0409" num="0411">The method of using a tunnel device is described below, based on a database <b>40</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b><i>a </i></figref>describing a list stored in the acceleration server <b>32</b>, a flowchart <b>60</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> describing a client device (such as the client device #<b>1</b> <b>31</b><i>a</i>) operation, a flow chart <b>70</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> describing a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>) operation, and a messaging and states timing chart <b>50</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b><i>b</i></figref>. The chart <b>50</b> shows the messaging and related timing associated with the operation of the acceleration server <b>32</b> (corresponding to a dashed line <b>51</b><i>a</i>), a client device such as the client device #<b>1</b> <b>31</b><i>a </i>(corresponding to a dashed line <b>51</b><i>b</i>), a tunnel device such as the tunnel device #<b>1</b> <b>33</b><i>a </i>(corresponding to a dashed line <b>51</b><i>c</i>), and a data server such as the data server #<b>1</b> <b>22</b><i>a </i>(corresponding to a dashed line <b>51</b><i>d</i>). The flowchart <b>60</b> comprises a flowchart <b>64</b> relating to a pre-connection phase, and a flowchart <b>65</b> describing a content fetch phase, of the client device. Similarly, a flowchart <b>70</b> comprises a flowchart <b>72</b> relating to the pre-connection phase, and a flowchart <b>73</b> describing the content fetch phase, of the tunnel device. The database <b>40</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b><i>a </i></figref>is illustrated as a table, wherein a first column <b>41</b><i>a </i>(designated as &#x2018;TYPE&#x2019;) relates to a device functionality, such as tunnel or client, a second column <b>41</b><i>b </i>(designated as &#x2018;IP ADDRESS&#x2019;) relates to the respective device IP address, a third column <b>41</b><i>c </i>(designated as &#x2018;SIGN-IN DATE/TIME&#x2019;) relates to a timestamping including a date (in DD/MM format) and a time when a respective device signed in with the acceleration server, and a fourth column <b>41</b><i>d, </i>relating to the device physical geographical location. A top row <b>42</b> in the table refers to the field designations. First <b>42</b><i>a, </i>second <b>42</b><i>b, </i>third <b>42</b><i>c, </i>fourth <b>42</b><i>d, </i>and fifth <b>42</b><i>e </i>rows in the table, respectively relate to first, second, third, fourth, and fifth devices that signed in with the acceleration server <b>32</b>. For example, the second device shown in the row <b>42</b><i>b </i>has signed in as a tunnel device as shown in the column <b>41</b><i>a, </i>timestamped as January 23<sup>rd </sup>at 8:55 as shown in the third column <b>41</b><i>c, </i>and can be addressed over the Internet using the IP address 109.23.78.5 as shown in the second column <b>41</b><i>b. </i></p><p id="p-0410" num="0412">The process starts upon initializing a tunnel application in a tunnel device, schematically shown as a step &#x2018;START&#x2019; <b>71</b><i>a </i>in the flowchart <b>70</b>, corresponding to a state <b>54</b><i>a </i>&#x2018;Start&#x2019; in the chart <b>50</b>. Such initialization may be executed upon the device powering up process, or upon a user request. Then the tunnel device #<b>1</b> <b>33</b><i>a </i>sign in with the acceleration server <b>32</b> in a step &#x2018;Sign-in as Tunnel&#x2019; <b>71</b><i>b, </i>which corresponds to a message &#x2018;Sign In&#x2019; <b>56</b><i>a </i>in the chart <b>50</b>. The message comprises the device functionality as &#x2018;tunnel&#x2019;, and the device <b>33</b><i>a </i>identification on the Internet <b>113</b>, such as its IP address (for example 125.12.67.0). The message &#x2018;Sign In&#x2019; is received as the acceleration server <b>32</b>, which updates the database of the signed-in devices in a state &#x2018;Update List&#x2019; <b>52</b><i>a, </i>as shown in a first row <b>42</b><i>a </i>in the table <b>40</b>. The acceleration server <b>32</b> further log to the database the date and time of the signing in, such as January 23 as the date and 7:32 as the time, as shown in the third column <b>41</b><i>c </i>of the table <b>40</b>. The acceleration server <b>32</b> further adds rows to the table per each added tunnel device in a case of multiple tunnel devices, such as the addition of the tunnel device #<b>2</b> <b>33</b><i>b, </i>that its signing-in details are shown in the second row <b>42</b><i>b, </i>as addressed by the IP address 109.23.78.5 and having signed in at January 23 at 8:55.</p><p id="p-0411" num="0413">Similarly, the client device #<b>1</b> <b>31</b><i>a </i>starts and sign in with the acceleration server <b>32</b>. The process starts upon initializing a client application in a client device, schematically shown as a step &#x2018;START&#x2019; <b>61</b><i>a </i>in the flowchart <b>60</b>, corresponding to a state <b>53</b><i>a </i>&#x2018;Start&#x2019; in the chart <b>50</b>. Such initialization may be executed upon the device powering up process, or upon a user request. Then the client device #<b>1</b> <b>31</b><i>a </i>sign in with the acceleration server <b>32</b> in a step &#x2018;Sign-in as Client&#x2019; <b>61</b><i>b, </i>which corresponds to a message &#x2018;Sign In&#x2019; <b>56</b><i>b </i>in the chart <b>50</b>. The message comprises the device functionality as &#x2018;client&#x2019;, and the device <b>31</b><i>a </i>identification on the Internet <b>113</b>, such as its IP address (for example 36.83.92.12). The message &#x2018;Sign In&#x2019; is received as the acceleration server <b>32</b>, which updates the database of the signed-in devices in a state &#x2018;Update List&#x2019; <b>52</b><i>b, </i>as shown in the third row <b>42</b><i>c </i>in the table <b>40</b>. The acceleration server <b>32</b> further logs to the database the date and time of the signing in, such as January 23 as the date and 10:44 as the time, as shown in the third column <b>41</b><i>c </i>of the table <b>40</b>. The acceleration server <b>32</b> further adds to the table an additional row per each newly signed client device in a case of multiple client devices, such as the addition of the client device #<b>2</b> <b>31</b><i>b, </i>that its signing-in details are shown in the second row <b>42</b><i>d, </i>as addressed by the IP address 125.66.69.73 and having signed in at January 24 on 15:34.</p><p id="p-0412" num="0414">In order to make the communication between a client device and a tunnel device faster and more efficient, a pre-connection phase is defined, where a preparation for communication such as a TCP connection is established, allowing for quick data transfer afterwards. The pre-connection phase starts at a &#x2018;Start Pre-Connection&#x2019; state <b>53</b><i>b </i>in the chart <b>50</b>, followed by the &#x2018;Request List&#x2019; message <b>56</b><i>c </i>(corresponding to the &#x2018;Request Tunnels List&#x2019; step <b>62</b> in the flowchart <b>60</b>), being part of the Pre-connection client flowchart <b>64</b>, where the client <b>31</b><i>a </i>requests the list of the available tunnels that may be used, from the acceleration server <b>32</b>. The tunnel device #<b>1</b> <b>33</b><i>a </i>at this point is idling in an &#x2018;IDLE&#x2019; step <b>72</b><i>c </i>shown in the flowchart <b>70</b>, being part of the Pre-connection tunnel flowchart <b>72</b>. In response to the client device <b>31</b><i>a </i>request, the acceleration server <b>32</b> prepares in a step &#x2018;Prepare List&#x2019; <b>52</b><i>b </i>the list of current available tunnels, and sends the list as a &#x2018;Send List&#x2019; message <b>56</b><i>d </i>to the client device <b>31</b><i>a, </i>which in turn receives the list as part of a &#x2018;Receive Tunnels List&#x2019; step <b>62</b><i>b. </i></p><p id="p-0413" num="0415">Based on pre-set criteria, a tunnel device (or multiple tunnel devices) is selected by the client device #<b>1</b> <b>31</b><i>a </i>in a &#x2018;Tunnel Select&#x2019; step <b>53</b><i>c </i>(corresponding to a &#x2018;Select Tunnel&#x2019; step <b>62</b><i>c </i>in the flowchart <b>60</b>). For example, the tunnel device #<b>1</b> <b>33</b><i>a </i>may be selected. Then, pre-connection is initiated in an &#x2018;Initiate Pre-Connection&#x2019; step <b>62</b><i>d, </i>where an &#x2018;Initiate Pre-Connection&#x2019; message <b>56</b><i>e </i>is sent to the tunnel device #<b>1</b> <b>33</b><i>a, </i>which starts the pre-connection in a &#x2018;Pre-Connection Start&#x2019; state <b>54</b><i>b, </i>and replies the &#x2018;Pre-Connection&#x2019; message <b>56</b><i>f </i>to the client device <b>31</b><i>a, </i>thus completing the pre-connection phase.</p><p id="p-0414" num="0416">The pre-connection process involves establishing a connection (directly or via a server) between the client device #<b>1</b> <b>31</b><i>a </i>(executing the flowchart <b>64</b>) and the tunnel device #<b>1</b> <b>33</b><i>a </i>(executing the flowchart <b>72</b>). The handshaking between the two devices at this stage involves forming the connection by exchanging communication-related information. The formed connection may be used later for efficiently exchange data between the devices. In one example, the communication between the devices uses TCP, and the pre-connection is used for establishing a connection by forming &#x2018;passive open&#x2019;, involving exchanging SYN, SYN-ACK, and ACK messages. In one example, the message &#x2018;Initiate Pre-Connection&#x2019; message <b>56</b><i>e </i>includes a SYN message, and the &#x2018;Pre-Connection&#x2019; message <b>56</b><i>f </i>includes an ACK message.</p><p id="p-0415" num="0417">In another example, a VPN is formed between the devices, and the tunneling or the VPN establishment is performed as part of the pre-connection phase. The tunnel endpoints are authenticated before secure VPN tunnels can be established. User-created remote-access VPNs may use passwords, biometrics, two-factor authentication, or any other cryptographic methods. Network-to-network tunnels often use passwords or digital certificates, and permanently stores the key in order to allow a tunnel to establish automatically, without intervention from a user.</p><p id="p-0416" num="0418">As long as the client device #<b>1</b> <b>31</b><i>a </i>is not requiring any content from a data server as described in a &#x2018;Content Required?&#x2019; step <b>63</b><i>a, </i>the device is idling in an &#x2018;IDLE&#x2019; step <b>62</b><i>e. </i>Once the client device #<b>1</b> <b>31</b><i>a </i>determines that external content from a data server is required, as shown in a &#x2018;Content Required&#x2019; state <b>53</b><i>d, </i>a &#x2018;Content Request&#x2019; message <b>56</b><i>g </i>(shown in the messaging chart <b>50</b>) is sent (corresponding to a &#x2018;Send Content Request&#x2019; step <b>63</b><i>b </i>in the flowchart <b>60</b>) to the selected tunnel device #<b>1</b> <b>33</b><i>a. </i>The request is received at the tunnel device #<b>1</b> <b>33</b><i>a </i>at a &#x2018;Request Received&#x2019; state <b>54</b><i>c, </i>corresponding to a &#x2018;Receive Content Request&#x2019; <b>73</b><i>b </i>in the flowchart <b>70</b>). In response, the tunnel device <b>33</b><i>a </i>sends a &#x2018;Content Request&#x2019; message <b>56</b><i>h </i>to the data server #<b>1</b> <b>22</b><i>a </i>(corresponding to a &#x2018;Send Request To Server&#x2019; step <b>73</b><i>c</i>), requesting the content that was requested by the client device #<b>1</b> <b>31</b><i>a. </i>The data server #<b>1</b> <b>22</b><i>a </i>receives the request and prepares the requested content in a &#x2018;Content Prepared&#x2019; state <b>55</b><i>a, </i>and sends the requested content back to the tunnel device #<b>1</b> <b>33</b><i>a </i>in a &#x2018;Send Content&#x2019; message <b>56</b><i>i, </i>received by the tunnel device #<b>1</b> <b>33</b><i>a </i>in a &#x2018;Receive Content from Server&#x2019; step <b>73</b><i>d. </i>The received content is prepared in a &#x2018;Content Prepared&#x2019; state <b>54</b><i>d, </i>and then sent, in a &#x2018;Send Content&#x2019; message <b>56</b><i>j </i>(corresponding to a &#x2018;Send Content To Client&#x2019; step <b>73</b><i>e</i>), to the client device #<b>1</b> <b>31</b><i>a. </i>The tunnel device <b>33</b><i>a </i>may then revert to idling in the &#x2018;IDLE&#x2019; step <b>73</b><i>a, </i>until a new request is received. The requested content is received in a &#x2018;Content Received&#x2019; state <b>53</b><i>e </i>in the timing chart <b>50</b>, corresponding to a &#x2018;Receive Content&#x2019; step <b>63</b><i>c </i>shown in the flowchart <b>60</b>. The client device <b>31</b><i>a </i>may then revert to idling in the &#x2018;IDLE&#x2019; step <b>62</b><i>e, </i>until a new content is required. When such new content is required as determined as part of the &#x2018;Content Required?&#x2019; step <b>63</b><i>a, </i>the process repeats by sending a &#x2018;Content Request&#x2019; message <b>56</b><i>k, </i>corresponding to the &#x2018;Send Content Request&#x2019; step <b>63</b><i>b. </i>In one example, the &#x2018;Content Fetch&#x2019; flowchart <b>73</b> executed by the tunnel device #<b>1</b> <b>33</b><i>a </i>may be a typical HTTP session for accessing a content from a web-server.</p><p id="p-0417" num="0419">The content herein may consist of, or comprise, data such as files, text, numbers, audio, voice, multimedia, video, images, music, computer programs or any other sequence of instructions, as well as any other form of information represented as a string of bits, bytes, or characters. In one example, the content may include, be a part of, or a whole of, a URL or a website page.</p><p id="p-0418" num="0420">The acceleration server <b>32</b> generally executes a flowchart <b>80</b> shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. The server <b>32</b> is idling in an &#x2018;IDLE&#x2019; step <b>81</b><i>a </i>until a request is received from one of the devices in the network. The request may be a sign-in request, as checked in a &#x2018;Sign-In Request?&#x2019; step <b>81</b><i>b, </i>which may be the result of a signing in of the client device #<b>1</b> <b>31</b><i>a </i>as part of the &#x2018;Sign-in as Client&#x2019; step <b>61</b><i>b </i>in the client flowchart <b>60</b>, or may be the result of a signing in of the tunnel device #<b>1</b> <b>33</b><i>a </i>as part of the &#x2018;Sign-in as Tunnel&#x2019; step <b>71</b><i>b </i>in the tunnel flowchart <b>70</b>. In the case of signing in, the server <b>32</b> update the database such as the table <b>40</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b><i>a </i></figref>in an &#x2018;Update Table&#x2019; step <b>81</b><i>c, </i>corresponding to an &#x2018;Update List&#x2019; state <b>52</b><i>a </i>for tunnel signing-in and an &#x2018;Update List&#x2019; state <b>52</b><i>b </i>for the client signing-in in the timing chart <b>50</b>. In a &#x2018;List Request?&#x2019; step <b>81</b><i>d </i>the acceleration server <b>32</b> checks for receiving a request from the client device #<b>1</b> <b>31</b><i>a </i>as part of a &#x2018;Request Tunnels List&#x2019; step <b>62</b><i>a, </i>corresponding to the message &#x2018;Request List&#x2019; <b>56</b><i>c </i>in the timing chart <b>50</b>. In response to such request, the server <b>32</b> compiles a list of tunnels that can be used by the client device #<b>1</b> <b>31</b><i>a </i>to serve the received request, as part of a &#x2018;Prepare List&#x2019; step <b>81</b><i>e </i>(corresponding to a &#x2018;Prepare List&#x2019; state <b>52</b><i>c </i>in the timing chart <b>50</b>). The compiled list is sent to the client device <b>31</b><i>a </i>as part of a &#x2018;Send List&#x2019; step <b>81</b><i>f, </i>corresponding to a &#x2018;Send List&#x2019; message <b>56</b><i>d </i>in the timing chart <b>50</b>. After completing the signing-in or sending list processes, the server <b>32</b> reverts to idling in the &#x2018;IDLE&#x2019; step <b>81</b><i>a. </i></p><p id="p-0419" num="0421">Data servers (such as the data server #<b>1</b> <b>22</b><i>a</i>) typically limit the number of concurrent active connections with connected devices (hosts). In many cases, a web page content may include multiple URLs, and it is beneficial to open many concurrent connections, each for one or more of the URLs, to accelerate the fetching of the web site content. In one example, the maximum number of connections permitted by the data server from which the content is to be fetched is sent to a tunnel device, such as the tunnel device #<b>1</b> <b>33</b><i>a, </i>as part of the &#x2018;Pre-connection Tunnel #<b>1</b>&#x2019; step <b>64</b><i>a </i>or the &#x2018;Content Fetch Tunnel #<b>1</b>&#x2019; step <b>65</b><i>a, </i>shown as part of the flowchart <b>100</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. In response, the tunnel device #<b>1</b> <b>33</b><i>a </i>as part of the &#x2018;Send Request To Server&#x2019; step <b>73</b><i>c, </i>opens the requested number of connections with the respective data server. For example, the client may request, based on stored information in the client device (such as based on former interaction with the respective data server received from a tunnel device as part of a &#x2018;Notify Client&#x2019; step <b>74</b><i>c</i>), sends the tunnel device a request to open 8 connections, which is known to be the maximum available (or allowable) number of connections relating to the specific data server. The client device may request all the tunnel devices used to use the maximum number of connections. For example, assuming 3 tunnel devices are used, and the maximum connections per host (device) is limited (by the data server) to 10 connections per host, each tunnel device may open the maximum 10 connections available. Hence, such scenario results in total open connections (for fetching the requested content) to be 10*3=30, which is 3 times better than using a single tunnel device, or when compared to a direct content fetching by the single client device from the data server. In another example, assuming the limitation of the data server is 8 connections, and wherein the client device sets the optimal number of total of 15 connections, the client device may request one tunnel device to use 8 connection and another tunnel device to use 7 connections, thus obtaining the optimal 8+7=15 connections.</p><p id="p-0420" num="0422">Alternatively or in addition, a tunnel device may try to open as many connections as available, as described in a flowchart <b>74</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b><i>a</i></figref>. The flowchart <b>74</b> corresponds to the flowchart <b>73</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. In parallel to starting the content fetching from the data server in the &#x2018;Send Request To Server&#x2019; step <b>73</b><i>c </i>and starting the reception of content from the data server in the &#x2018;Receive Content From Server&#x2019; step <b>73</b><i>d, </i>the tunnel device tries to open an additional connection (or multiple additional connections) to those already in use in a &#x2018;Open Connection(s)&#x2019; step <b>74</b><i>a. </i>In the case the additional connection was properly established, as is checked in a &#x2018;Successful?&#x2019; step <b>74</b><i>b, </i>the tunnel device reverts to try to open an additional connection in the &#x2018;Open Connection(s)&#x2019; step <b>74</b><i>a. </i>In the case no additional connection can be established, typically because the limit set by the data server was reached, the tunnel device notifies the client device in the &#x2018;Notify Client&#x2019; step <b>74</b><i>c </i>of the maximum number of connections available for this data server. This notification allows the client device to use such information for use with other tunnel devices communicating with this data server or for future use with the data server.</p><p id="p-0421" num="0423">Alternatively or in addition, a tunnel device may be used to store a content to be provided to a client device, as described in a flowchart <b>75</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b><i>b</i></figref>, which corresponds to the flowchart <b>73</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. Upon receiving a request for content from a client device, a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>) first checks if the requested content is stored locally (in the tunnel device itself), such as in its cache memory, in a &#x2018;Locally Available?&#x2019; step <b>75</b><i>a. </i>The requested content may be stored in the tunnel device as a result of a former accessing the respective data server, for example by a web browser (or any other application) that is part of the tunnel device. Alternatively or in addition, the content may be stored as part of a &#x2018;Store Content From Server&#x2019; step <b>75</b><i>b </i>in a past fetching of content, for this client device or for another client device. If the content is available locally in the tunnel device, the overhead, time, and resources, of accessing the respective data server are obviated, and the locally stored requested content is sent to the client device in the &#x2018;Send Content To Client&#x2019; step <b>73</b><i>e. </i>In the case the requested content is not locally available, the tunnel device continues as described in the flowchart <b>73</b> to fetch the content from the data server. Alternatively or in addition, upon receiving the requested content from the data server in the &#x2018;Receive Content From Server&#x2019; step <b>73</b><i>d, </i>the receive content may be stored locally in the tunnel device for future use, in the &#x2018;Store Content From Server&#x2019; step <b>75</b><i>b. </i>Storing of the received content may be executed before, after, or in parallel to sending the content to the requesting client device in the &#x2018;Send Content To Client&#x2019; step <b>73</b><i>e. </i></p><p id="p-0422" num="0424">Since the data server #<b>1</b> <b>22</b><i>a </i>is accessed by, and sends information only to, tunnel devices (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>), and is not aware of the final content destination being the client device #<b>1</b> <b>31</b><i>a, </i>the identity (such as the IP address) of the client device #<b>1</b> <b>31</b><i>a </i>is concealed from the data server #<b>1</b> <b>22</b><i>a, </i>thus providing anonymity and untraceability. Further, in a case where the data server #<b>1</b> <b>22</b><i>a </i>is a web server, the method and system described may provide for an anonymous web browsing. Further, the system and method provide an Internet traffic route for the content delivery that is distinct from the typical approach where the client device #<b>1</b> <b>31</b><i>a </i>access the data server #<b>1</b> <b>22</b><i>a </i>directly over the Internet, hence may alleviates bottlenecks and conserve bandwidth. Furthermore, since multiple parts of the content stored in a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>) are loaded in parallel to a client device (such as the client device #<b>1</b> <b>31</b><i>a</i>) using multiple distinct paths, the content is fetched faster and using more effectively the network resources.</p><p id="p-0423" num="0425">A schematic messaging flow diagram <b>110</b> describing the client device #<b>1</b> <b>31</b><i>a </i>related &#x2018;content fetch&#x2019; flowchart <b>65</b> and the tunnel device #<b>1</b> <b>33</b><i>a </i>related flowchart <b>73</b> is shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. A &#x2018;Content Request&#x2019; message <b>111</b><i>a </i>(corresponding to the &#x2018;Content Request&#x2019; message <b>56</b><i>g </i>in the timing chart <b>50</b>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the selected tunnel device #<b>1</b> <b>33</b><i>a, </i>which responds by forwarding the request to the data server #<b>1</b> <b>22</b><i>a </i>using a &#x2018;Content Request&#x2019; message <b>111</b><i>b </i>(corresponding to the &#x2018;Content Request&#x2019; message <b>56</b><i>h </i>in the timing chart <b>50</b>). In turn the data server #<b>1</b> replies and sends the content in a &#x2018;Send Content&#x2019; message <b>111</b><i>c </i>(corresponding to the &#x2018;Send Content&#x2019; message <b>56</b><i>i </i>in the timing chart <b>50</b>) to the requesting tunnel device #<b>1</b> <b>33</b><i>a, </i>which in turn forward the fetched content to the asking client device #<b>1</b> <b>31</b><i>a </i>using a &#x2018;Send Content&#x2019; message <b>111</b><i>d </i>(corresponding to the Send Content' message <b>56</b><i>j </i>in the timing chart <b>50</b>).</p><p id="p-0424" num="0426">While accessing the data server #<b>1</b> <b>22</b><i>a </i>was exampled above using the tunnel device #<b>1</b> <b>33</b><i>a </i>as an intermediary device, the system and the client #<b>1</b> <b>31</b><i>a </i>may use multiple tunnel devices in order to fetch the content from the same data server #<b>1</b> <b>22</b><i>a. </i>Two, three, four, or any other number of tunnel devices, serving as intermediary devices having the same or similar role as the tunnel device #<b>1</b> <b>33</b><i>a, </i>may be equally used. In one example, three tunnel devices may be used, such as adding the tunnel device #<b>2</b> <b>33</b><i>b </i>and the tunnel device #<b>3</b> <b>33</b><i>c, </i>shown in system <b>30</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. Each of the tunnel devices may execute the flow chart <b>70</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0425" num="0427">A flowchart <b>100</b> relating to the client device #<b>1</b> <b>31</b><i>a </i>when employing three tunnel devices is shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, based on the flowchart <b>60</b> described above. Upon receiving a list of available tunnel in a &#x2018;Receive Tunnels List&#x2019; step <b>62</b><i>b </i>from the Acceleration server <b>32</b>, the client device #<b>1</b> <b>31</b><i>a </i>selects multiple tunnels from the received list, rather than selecting a single tunnel as described in the &#x2018;Select Tunnel&#x2019; step <b>62</b><i>c </i>described above. In the described example, three distinct tunnel devices are selected from the list, such as the tunnel device #<b>1</b> <b>33</b><i>a </i>(as before), the tunnel device #<b>2</b> <b>33</b><i>b, </i>and the tunnel device #<b>3</b> <b>33</b><i>c. </i>The client device <b>31</b><i>a </i>executes three pre-connection processes in a &#x2018;Pre-Connection Tunnel #<b>1</b>&#x2019; step <b>64</b><i>a, </i>a &#x2018;Pre-Connection Tunnel #<b>2</b>&#x2019; step <b>64</b><i>b, </i>and a &#x2018;Pre-Connection Tunnel #<b>3</b>&#x2019; step <b>64</b><i>c </i>(each corresponding to the &#x2018;Pre-connection&#x2019; flow chart <b>64</b> above), followed by a &#x2018;Content Fetch Tunnel #<b>1</b>&#x2019; step <b>65</b><i>a, </i>a &#x2018;Content Fetch Tunnel #<b>2</b>&#x2019; step <b>65</b><i>b, </i>and a &#x2018;Content Fetch Tunnel #<b>3</b>&#x2019; step <b>65</b><i>c, </i>respectively (each corresponding to the &#x2018;Content Fetch&#x2019; flow chart <b>65</b> above).</p><p id="p-0426" num="0428">In such a configuration, three distinct data paths are involved in the content fetching. In addition to the messaging data path <b>110</b>, a messaging flow <b>110</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>11</b><i>a </i></figref>describes the usage of the tunnel device #<b>2</b> <b>33</b><i>b </i>as an intermediary device, relating to the client device #<b>1</b> <b>31</b><i>a </i>&#x2018;content fetch&#x2019; related flowchart <b>65</b><i>b </i>and the tunnel device #<b>2</b> <b>33</b><i>b </i>related flowchart <b>73</b>. A &#x2018;Content Request&#x2019; message <b>112</b><i>a </i>(corresponding to the &#x2018;Content Request&#x2019; message <b>56</b><i>g </i>in the timing chart <b>50</b>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the selected tunnel device #<b>2</b> <b>33</b><i>b, </i>which responds by forwarding the request to the data server #<b>1</b> <b>22</b><i>a </i>using a &#x2018;Content Request&#x2019; message <b>112</b><i>b </i>(corresponding to the &#x2018;Content Request&#x2019; message <b>56</b><i>h </i>in the timing chart <b>50</b>). In turn the data server #<b>1</b> replies and sends the content in a &#x2018;Send Content&#x2019; message <b>112</b><i>c </i>(corresponding to the &#x2018;Send Content&#x2019; <b>56</b><i>i </i>in the timing chart <b>50</b>) to the requesting tunnel device #<b>2</b> <b>33</b><i>b, </i>which in turn forward the fetched content to the asking client device #<b>1</b> <b>31</b><i>a </i>using a &#x2018;Send Content&#x2019; message <b>112</b><i>d </i>(corresponding to the &#x2018;Send Content&#x2019; message <b>56</b><i>j </i>in the timing chart <b>50</b>). Similarly, a messaging flow <b>110</b><i>b </i>shown in <figref idref="DRAWINGS">FIG. <b>11</b><i>b </i></figref>describes the usage of the tunnel device #<b>3</b> <b>33</b><i>c </i>as an intermediary device, relating to the client device #<b>1</b> <b>31</b><i>a </i>associated with &#x2018;content fetch&#x2019; in the flowchart <b>65</b><i>c </i>and with the tunnel device #<b>2</b> <b>33</b><i>b </i>in the flowchart <b>73</b>. The &#x2018;Content Request&#x2019; message <b>115</b><i>a </i>(corresponding to the &#x2018;Content Request&#x2019; message <b>56</b><i>g </i>in the timing chart <b>50</b>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the selected tunnel device #<b>3</b> <b>33</b><i>c, </i>which responds by forwarding the request to the data server #<b>1</b> <b>22</b><i>a </i>using the &#x2018;Content Request&#x2019; message <b>115</b><i>b </i>(corresponding to &#x2018;Content Request&#x2019; message <b>56</b><i>h </i>in the timing chart <b>50</b>). In turn the data server #<b>1</b> <b>22</b><i>a </i>replies and sends the content in the &#x2018;Send Content&#x2019; message <b>115</b><i>c </i>(corresponding to the &#x2018;Send Content&#x2019; message <b>56</b><i>i </i>in the timing chart <b>50</b>) to the requesting tunnel device #<b>3</b> <b>33</b><i>c, </i>which in turn forward the fetched content to the asking client device #<b>1</b> <b>31</b><i>a </i>using the &#x2018;Send Content&#x2019; message <b>115</b><i>d </i>(corresponding to the &#x2018;Send Content&#x2019; message <b>56</b><i>j </i>in the timing chart <b>50</b>).</p><p id="p-0427" num="0429">Alternatively or in addition to accessing the data server #<b>1</b> <b>22</b><i>a </i>via intermediary devices such as one or more tunnel devices as described herein, the client device #<b>1</b> <b>31</b><i>a </i>may also directly access the data server #<b>1</b> <b>22</b><i>a </i>for fetching the content therefrom. Such a flowchart <b>100</b><i>a </i>is shown in <figref idref="DRAWINGS">FIG. <b>10</b><i>a</i></figref>, where a &#x2018;Content Fetch Direct&#x2019; step <b>65</b><i>d </i>is added. In this step <b>65</b><i>d, </i>the client device #<b>1</b> <b>31</b><i>a </i>directly accesses the data server #<b>1</b> <b>22</b><i>a, </i>as typically known, and in the same way, or in a similar way, the tunnel devices are accessing the data server #<b>1</b> <b>22</b><i>a </i>for fetching content therefrom. Such direct access is shown in messaging flow <b>110</b><i>c </i>shown in <figref idref="DRAWINGS">FIG. <b>11</b><i>c</i></figref>, where no intermediary device is used. The &#x2018;Content Request&#x2019; message <b>114</b><i>a </i>(which may be corresponding to the &#x2018;Content Request&#x2019; message <b>56</b><i>g </i>in the timing chart <b>50</b>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the data server #<b>1</b> <b>22</b><i>a. </i>In turn the data server #<b>1</b> <b>22</b><i>a </i>replies and sends the content in the &#x2018;Send Content&#x2019; message <b>114</b><i>b </i>(which may be corresponding to the &#x2018;Send Content&#x2019; message <b>56</b><i>i </i>in the timing chart <b>50</b>) to the client device #<b>1</b> <b>31</b><i>a. </i>As used herein, a direct access by a client device, such as the client device #<b>1</b> <b>31</b><i>a, </i>is considered as if the client device itself serves as a tunnel device for itself.</p><p id="p-0428" num="0430">In one example, the same content (from the same data server #<b>1</b> <b>22</b><i>a</i>) is requested by the client device #<b>1</b> <b>31</b><i>a, </i>from all the selected tunnel devices. In such a case, the same content is requested and fetched in the &#x2018;Content Fetch&#x2019; flowcharts. In the example of three tunnel devices shown in a flowchart <b>100</b>, the same content may be defined to be requested (and later fetched) in the &#x2018;Content Fetch Tunnel #<b>1</b>&#x2019; step <b>65</b><i>a, </i>the &#x2018;Content Fetch Tunnel #<b>2</b>&#x2019; step <b>65</b><i>b, </i>and the &#x2018;Content Fetch Tunnel #<b>3</b>&#x2019; step <b>65</b><i>c. </i>Such configuration may be advantageous, for example, in the case where one or multiple data paths are unstable or unreliable, or provide intermittent connection. In the case wherein multiple redundant tunnels and data paths are used, there is a higher probability to fetch the required content, even if one or more of the data paths are problematic or non-functioning. For example, in the case where the tunnel device #<b>1</b> <b>33</b><i>a </i>and the tunnel device #<b>3</b> <b>33</b><i>c </i>are not fully functioning or having a momentary (or continuous) problem fetching the requested content, still the tunnel device #<b>2</b> <b>33</b><i>b </i>may provide the content. Further, such redundant operation may allow for quicker and faster content fetching, since the client device #<b>1</b> <b>31</b><i>a </i>may use the content first to be received, hence using the faster content fetching route. For example, in case of the tunnel device #<b>1</b> <b>33</b><i>a </i>replying and providing the content after 12 milliseconds, the tunnel device #<b>2</b> <b>33</b><i>b </i>replying and providing the content after 23 milliseconds, and the tunnel device #<b>3</b> <b>33</b><i>c </i>replying and providing the content after 5 milliseconds, the content is available at the client device #<b>1</b> <b>31</b><i>a </i>after 5 milliseconds, and there is no need to wait for the other tunnels to reply. Similarly, in case of a direct access, the client device #<b>1</b> <b>31</b><i>a </i>direct access is added as a redundant content fetching path to the tunnels-associated data paths.</p><p id="p-0429" num="0431">The tasks relating to the different data paths, such as shown in a flowchart <b>100</b><i>a, </i>relating to communicating with the multiple tunnel devices and/or direct access, may be executed sequentially or in parallel. Further, each of the messages transferred shown in the messaging charts and data paths, such as in the diagrams <b>110</b>, <b>110</b><i>a, </i><b>110</b><i>b, </i>and <b>110</b><i>c, </i>may be executed, or may occur, sequentially or in parallel. For example, in case of multiple pre-connection processes, the client device #<b>1</b> <b>31</b><i>a </i>may execute the processes sequentially, meaning initiating a new pre-connection only after a former pre-connection is completed (or only upon being successfully completed). For example, relating to the flowchart <b>100</b><i>a, </i>the client device first executes the &#x2018;Pre-connection Tunnel #<b>1</b>&#x2019; step <b>64</b><i>a, </i>and only upon completion of this step initiates the &#x2018;Pre-connection Tunnel #<b>2</b>&#x2019; step <b>64</b><i>b, </i>and only upon completion of the latter step initiates the &#x2018;Pre-connection Tunnel #<b>3</b>&#x2019; step <b>64</b><i>c. </i>Alternatively or in addition, the processes may be executed in parallel, using a multitasking.</p><p id="p-0430" num="0432">Similarly, in case of multiple connect fetching processes, the client device #<b>1</b> <b>31</b><i>a </i>may execute the processes sequentially, meaning initiating a new content fetching only after a former content fetching is completed (or only upon being successfully completed). For example, relating to the flowchart <b>100</b><i>a, </i>the client device first executes the &#x2018;Content Fetch Direct&#x2019; step <b>65</b><i>d, </i>and only upon completion of this step initiates the &#x2018;Content Fetch Tunnel #<b>1</b>&#x2019; step <b>65</b><i>a, </i>and only upon completion of the latter step initiates the &#x2018;Content Fetch Tunnel #<b>2</b>&#x2019; step <b>65</b><i>b. </i>Alternatively or in addition, the processes may be executed in parallel, using a multitasking.</p><p id="p-0431" num="0433">The client device <b>31</b><i>a </i>may select a single tunnel device to be used as an intermediary device as described above relating to the &#x2018;Select Tunnel&#x2019; step <b>62</b><i>c. </i>Alternatively or addition, the client device <b>31</b><i>a </i>may select a plurality of tunnel devices (including itself as described in the &#x2018;Content Fetch Direct&#x2019; step <b>65</b><i>d</i>) to be used as an intermediary device as described above relating to the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a. </i>The selection of a tunnel or of multiple tunnels may be based on pre-set criteria. The selection may use various attributes or characteristics of the tunnel devices, its operation environment, history, and any other characteristics. The attributes associated with each tunnel device may be stored in the acceleration server <b>23</b>, and sent to the client device #<b>1</b> <b>31</b><i>a </i>as part of the available tunnel devices list, so that the client device #<b>1</b> <b>31</b><i>a </i>may use these attributes for the selection process. The criteria herein may be used independently or in combination. In yet another alternative, the selection is based on timing measurement, such as Time-of-Day (TOD). For example, one selection scheme may be used on a daily basis from 2.00 AM to 3.00 AM, a different selection from 3.00 AM to 4.00 AM and so on, cycling in a 24-hour day. Similarly, each day of the week may use different selection. Any combination of the schemes described herein may be equally used. Any number of tunnel devices may be selected. The number of tunnel devices that are selected in the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a </i>may be 1 (one) (corresponding to the &#x2018;Select Tunnel&#x2019; step <b>62</b><i>c</i>). Alternatively, a small number of tunnel devices may be selected, such as 2 or 3. Alternatively, 4, 5, 6, 7, 8, 9, or 10 tunnel devices may be selected. Further, more than <b>10</b> tunnel devices may be selected, such as 10, 20, 30, 40, or 50.</p><p id="p-0432" num="0434">The client device <b>31</b><i>a </i>may select a single tunnel device to be used as an intermediary device as described above relating to the &#x2018;Select Tunnel&#x2019; step <b>62</b><i>c. </i>Alternatively or addition, the client device #<b>1</b> <b>31</b><i>a </i>may select a plurality of tunnel devices (including itself as described in the &#x2018;Content Fetch Direct&#x2019; step <b>65</b><i>d</i>) to be used as an intermediary device as described above relating to the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a. </i>Alternatively or in addition, the tunnel devices to be used may be selected by the acceleration server <b>32</b>, and the tunnel list sent to the client device #<b>1</b> <b>31</b><i>a </i>(in the &#x2018;Send List&#x2019; step <b>81</b><i>f </i>and received by the client device #<b>1</b> <b>31</b><i>a </i>in the &#x2018;Receive Tunnels List&#x2019; step <b>62</b><i>b</i>) may include only the identification (e.g., IP address) of the tunnel devices to be used as intermediary devices to the client device #<b>1</b> <b>31</b><i>a. </i>Such a flowchart <b>90</b> to be executed by the acceleration server <b>32</b> is shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. After preparing a list of available or potential tunnel devices that may be used in the &#x2018;Prepare List&#x2019; step <b>81</b><i>e, </i>the acceleration server <b>32</b> itself selects in a &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a </i>the tunnel devices that are to be used by the client device #<b>1</b> <b>31</b><i>a, </i>and sends only these tunnel devices list to the client device #<b>1</b> <b>31</b><i>a </i>in a &#x2018;Send Selected List&#x2019; step <b>91</b><i>a. </i></p><p id="p-0433" num="0435">Alternatively or in addition, the tunnel devices to be used may be selected by both the client device #<b>1</b> <b>31</b><i>a </i>and the acceleration server <b>32</b> working in cooperation. In one example, the acceleration server <b>32</b> (for example, as part of the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a </i>in the flow chart <b>90</b>) may select a subgroup of suggested, offered, or recommended tunnel devices that can be used, while the client device #<b>1</b> <b>31</b><i>a </i>(for example, as part of the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a </i>in the flow chart <b>100</b>) further selects and uses a subset of the tunnel devices from the list of offered suggested tunnel devices. Alternatively or in addition, the tunnel devices to be used may be selected by the acceleration server <b>32</b>, based on rules or criteria set by, or requested from, the client device #<b>1</b> <b>31</b><i>a. </i>For example, as part of the requesting of tunnel devices list in the &#x2018;Request Tunnels List&#x2019; step <b>62</b><i>a, </i>the client device #<b>1</b> <b>31</b><i>a </i>may send to the acceleration server <b>32</b> a set or rules or criteria, relating to the tunnel devices that are to be used by this client, which may relate to various attributes or characteristics of the available tunnel devices. In one example, the criteria may be the geographical location of the tunnel devices. The client device #<b>1</b> <b>31</b><i>a </i>may ask for tunnel devices only in a specific location, such as a specific country, and in response the acceleration server <b>32</b> may select tunnel devices only in the specified country (for example, in the &#x2018;Select Tunnel&#x2019; step <b>101</b><i>a </i>in the flowchart <b>90</b>) and send only this list (for example in the &#x2018;Send Selected List&#x2019; step <b>91</b><i>a</i>) to the client device #<b>1</b> <b>31</b><i>a. </i>For example, relating to the example of the table <b>40</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b><i>a</i></figref>, in the case the client device #<b>1</b> <b>31</b><i>a </i>asks for tunnels only in Germany (or Europe), only the second listed tunnel device in the row <b>42</b><i>b </i>may be included in the list, being the only one located in Germany.</p><p id="p-0434" num="0436">The selection of the tunnel device (or devices) to be used, or the priorities assigned to them, may be based on the available communication attributes or their history. For example, based on the costs associated with the usage of a network, the higher cost network may have lower priority and less used than lower cost or free network. In another example, a high quality network, such as having a higher available bandwidth or throughput, lower communication errors or packet loss, lower hops to destination, or lower transfer delay time, is having higher priority that a lower quality network. The system may use Bit Error Rate (BER), Received Signal Strength Indicator (RSSI), Packet Loss Ratio (PLR), Cyclic Redundancy Check (CRC) and other indicators or measures associated with the communication channel associated with a network interface, and may be based on, use, or include the methodology and schemes described in RFC 2544 entitled: &#x201c;<i>Benchmarking Methodology for Network Interconnect Devices</i>&#x201d;, and ITU-T Y.1564 entitled: &#x201c;<i>Ethernet Service Activation Test Methodology</i>&#x201d;, which are both incorporated in their entirety for all purposes as if fully set forth herein. The network quality grade may be affected by the history of using such a network, for example during a pre-set period before the process of selection of a network interface. In one example, the network interface where the last proper packet was received from may be selected as the interface to be used for the next packet to be transmitted. The system may further use, or be based on, the schemes and technologies described in U.S. Pat. No. 7,027,418 to Gan et al. entitled: &#x201c;Approach for Selecting Communications Channels Based on Performance&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0435" num="0437">Random: In one example, the tunnel device (or devices) to be used are randomly selected. Randomness is commonly implemented by using random numbers, defined as a sequence of numbers or symbols that lack any pattern and thus appear random, are often generated by a random number generator. Randomness is described, for example, in IETF RFC 1750 &#x201c;<i>Randomness Recommendations for Security</i>&#x201d; (December 1994), which is incorporated in its entirety for all purposes as if fully set forth herein. A random number generator (having either analog or digital output) can be hardware based, using a physical process such as thermal noise, shot noise, nuclear decaying radiation, photoelectric effect or other quantum phenomena. Alternatively, or in addition, the generation of the random numbers can be software based, using a processor executing an algorithm for generating pseudo-random numbers which approximates the properties of random numbers.</p><p id="p-0436" num="0438">Physical location: In one example, the selection criterion is based on physical geographical location of a tunnel device. For example, a tunnel device, which is geographically the closest to the data server #<b>1</b> <b>22</b><i>a </i>from which a content is to be requested, will be the first to be selected. The second nearest tunnel device will be the second to be selected, and so on. In this scheme, tunnel devices which are in the same city as the data server #<b>1</b> <b>22</b><i>a, </i>will have highest priority than other tunnel devices in the same country, then in the same continent and so forth. Alternatively or in addition, the criterion may be based on the physical distance between a tunnel device and the acceleration server <b>32</b> location, or on the physical distance between a tunnel device and the client device #<b>1</b> <b>31</b><i>a. </i>In one example, the tunnel devices may be selected based on being in a location, which is the most distant from the data server #<b>1</b> <b>22</b><i>a, </i>the acceleration server <b>32</b>, or the client device #<b>1</b> <b>31</b><i>a. </i>The information about the tunnel device locations may be obtained, for example, from the tunnel devices themselves during the signing-up process. In such a scheme, the tunnel device sends its physical geographical location (which may include country, state or province, city, street address, or ZIP code) as part of the sign-in process, and the location is stored in the acceleration server as part of the tunnels related database. The table <b>40</b> in <figref idref="DRAWINGS">FIG. <b>5</b><i>a </i></figref>shows various devices in the system listed with associated cities and countries in the fourth column <b>41</b><i>d. </i>In the example shown, the first row <b>42</b><i>a </i>relates to a tunnel device located in Boston, Massachusetts, in the United States, the second row <b>42</b><i>b </i>relates to a tunnel device located in Munich in Germany, the third row <b>42</b><i>c </i>relates to a client device located in Sidney in Australia, the fourth row <b>42</b><i>d </i>relates to a client device located at Tel-Aviv in Israel, and the fifth row <b>42</b><i>e </i>relates to a device located at Cairo in Egypt. In the case wherein the criterion involved relates to the node closest to the data server #<b>1</b> <b>22</b><i>a, </i>which for example is located in London in the United-Kingdom, the first (or only) tunnel device to be selected may be the second tunnel device associated with the second row <b>42</b><i>b, </i>being in Europe and thus the geographically closest device. In one example, the device location may be obtained using its built-in Global Positioning System (GPS), and may include the latitude, longitude, and timezone of the device location.</p><p id="p-0437" num="0439">IP Address: In one example, the IP address is used as a measure to determine &#x2018;closeness&#x2019;. For example, an IP address that is numerically close to another IP, may be considered as &#x2018;geographically&#x2019; close. In this context, 192.166.3.103 is closer to 192.166.3.212 than to 192.167.3.104. Alternatively or in addition, devices that share the same ISP are considered as &#x2018;close&#x2019;, since it is likely that better and faster communication is provided, since the need to communicate via the Internet is obviated.</p><p id="p-0438" num="0440">Timing: In one example, the timing of an event or activity of a tunnel device affects its selection. The timing of a tunnel device signing up with the acceleration server <b>32</b> may be used for the selection criterion. The first available tunnel device that signed in may be first selected, then the second in line. In the example of the table <b>40</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b><i>a</i></figref>, the tunnel device associated with the first row <b>42</b><i>a </i>will be first to be selected, having the earliest sign-in time (January 23, 7:32), while the following tunnel device to sign in (shown in the row <b>42</b><i>b</i>) will be selected next. Alternatively or in addition, the latest signed-in tunnel device will be the first to be selected.</p><p id="p-0439" num="0441">Alternatively or in addition, the time of the last usage as the tunnel device may be used as a criterion. For example, a tunnel device that was most recently used will have the highest priority to be reselected. Alternatively, a &#x2018;fairness&#x2019; rule will be applied in order to uniformly use all available channels, where a tunnel device will be selected if it was not used the most time.</p><p id="p-0440" num="0442">The content requested by the client device #<b>1</b> <b>31</b><i>a </i>may be partitioned into multiple parts or &#x2018;slices&#x2019;. Any number of slices may be used. The slicing may be in a bit, nibble (4-bits), byte (8-bits), word (multiple bytes), character, string, or file level. For example, in a case wherein the content includes 240 bytes designated byte #<b>1</b> to byte #<b>240</b>, using a byte level partitioning into two slices results in a first slice (slice #<b>1</b>) including byte #<b>1</b> to byte #<b>120</b>, and a second slice (slice #<b>2</b>) including byte #<b>121</b> to byte #<b>240</b>. In the case of byte-level partitioning into three slices (referred as slice #<b>1</b>, slice #<b>2</b>, and slice #<b>3</b>), a first slice (slice #<b>1</b>) may be including byte #<b>1</b> to byte #<b>80</b>, a second slice (slice #<b>2</b>) may be including byte #<b>81</b> to byte #<b>160</b>, and a third slice (slice #<b>3</b>) may be including byte #<b>161</b> to byte #<b>240</b>. Similarly, in a case wherein the content include 3 bytes designated byte #<b>1</b> to byte #<b>3</b> representing 24 bits, using a bit-level partitioning into four slices results in a slice #<b>1</b> including the first 6 bits, slice #<b>2</b> including the next 6 bits, slice #<b>3</b> including the next 6 bits, and slice #<b>4</b> including the last 6 bits. The partition may be into equal length parts. Alternatively or in addition, a different length slicing may be applied. For example, in the case of a 240 bytes content and using byte-level partitioning into three slices (referred as slice #<b>1</b>, slice #<b>2</b>, and slice #<b>3</b>), a first slice (slice #<b>1</b>) may be including byte #<b>1</b> to byte #<b>20</b> (20-byte length), a second slice (slice #<b>2</b>) may be including byte #<b>21</b> to byte #<b>100</b> (80-byte length), and a third slice (slice #<b>3</b>) may be including byte #<b>101</b> to byte #<b>240</b> (<b>140</b>-byte length). In one example, the content itself is made of inherent or identifiable parts or segments, and the partition may make use of these parts. In one example, the content may be a website content composed of multiple webpages, and thus the partition may be such that each slice includes one (or few) webpages. Further, the partitioning may be sequential or non-sequential in the content.</p><p id="p-0441" num="0443">The partitioning may be non-overlapping, wherein each slice includes a distinct part of the content, as is exampled above in a case wherein the content includes 240 bytes designated byte #<b>1</b> to byte #<b>240</b>, where using a byte level partitioning into three slices (referred as slice #<b>1</b>, slice #<b>2</b>, and slice #<b>3</b>), results in a first slice (slice #<b>1</b>) including byte #<b>1</b> to byte #<b>80</b>, a second slice (slice #<b>2</b>) including byte #<b>81</b> to byte #<b>160</b>, and a third slice (slice #<b>3</b>) including byte #<b>161</b> to byte #<b>240</b>. Alternatively or in addition, an overlapping partitioning may be applied, where the same part of the content is included in multiple slices. For example, in a case above where the content includes <b>240</b> bytes designated byte #<b>1</b> to byte #<b>240</b>, and using a byte level partitioning into three slices (referred as slice #<b>1</b>, slice #<b>2</b>, and slice #<b>3</b>), a first slice (slice #<b>1</b>) may include byte #<b>1</b> to byte #<b>160</b>, a second slice (slice #<b>2</b>) may include byte #<b>81</b> to byte #<b>240</b>, and a third slice (slice #<b>3</b>) may include byte #<b>1</b> to byte #<b>80</b> in addition to byte #<b>161</b> to byte #<b>240</b>. In such a case, byte #<b>1</b> to byte #<b>80</b> are part of both slice #<b>1</b> and slice #<b>3</b>, byte #<b>81</b> to byte #<b>160</b> are part of both slice #<b>1</b> and slice #<b>2</b>, and byte #<b>161</b> to byte #<b>240</b> are part of both slice #<b>2</b> and slice #<b>3</b>. It is noted that in such a partition, the content may be fully reconstructed from any two of the slices, hence providing a degree of redundancy. For example, in case of carrying the three slices over the Internet and a failure to receive one of the slices, the remaining two slices may be used to fully reconstruct the whole content.</p><p id="p-0442" num="0444">The same content may be requested and fetched using multiple tunnel devices as exampled above. Alternatively or in addition, the content may be partitioned into multiple slices (overlapping or non-overlapping), where each slice is requested and fetched using a distinct tunnel device (or via the client device serving as its own tunnel). The content is partitioned into slices in a &#x2018;Content Partition&#x2019; step <b>101</b><i>b </i>shown in the flowchart <b>100</b>. In one example, each of the slices is allocated to a different tunnel device, and fetched via that tunnel device as explained herein. For example, in the case of partitioning into <b>3</b> slices, where slice #<b>1</b> may be fetched via the tunnel device #<b>1</b> <b>33</b><i>a </i>in a &#x2018;Content Fetch Tunnel #<b>1</b>&#x2019; step <b>65</b><i>a, </i>slice #<b>2</b> may be fetched via the tunnel device #<b>2</b> <b>33</b><i>b </i>in a &#x2018;Content Fetch Tunnel #<b>2</b>&#x2019; step <b>65</b><i>b, </i>and slice #<b>2</b> may be fetched via the tunnel device #<b>3</b> <b>33</b><i>c </i>in a &#x2018;Content Fetch Tunnel #<b>3</b>&#x2019; step <b>65</b><i>c. </i>Alternatively or in addition, a slice (or multiple slices) may be requested and fetched via two or more tunnel devices. Such scheme provides redundancy and may further accelerate the content fetch. For example, in the case of partitioning into <b>2</b> slices, where slice #<b>1</b> may be fetched via the tunnel device #<b>1</b> <b>33</b><i>a </i>in the &#x2018;Content Fetch Tunnel #<b>1</b>&#x2019; step <b>65</b><i>a </i>and in parallel slice #<b>1</b> may also be fetched via the tunnel device #<b>2</b> <b>33</b><i>b </i>in the &#x2018;Content Fetch Tunnel #<b>2</b>&#x2019; step <b>65</b><i>b, </i>while slice #<b>2</b> may be fetched via the tunnel device #<b>3</b> <b>33</b><i>c </i>in the &#x2018;Content Fetch Tunnel #<b>3</b>&#x2019; step <b>65</b><i>c. </i></p><p id="p-0443" num="0445">The system was exampled above where a device may be a client device (such as the client device #<b>1</b> <b>31</b><i>a</i>) executing, for example, the flowchart <b>60</b>, the flowchart <b>100</b>, or the flowchart <b>100</b><i>a. </i>Similarly, a device may be a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>) executing, for example, the flowchart <b>70</b>. It is appreciated that a device may serve as both a client device and as a tunnel device, executing both a client device flowchart (such as the flowchart <b>100</b><i>a</i>) and a tunnel device flowchart (such as the flowchart <b>70</b>). The two roles may be performed sequentially, where one role is assumed at a time, or may be used in parallel using multitasking or multiprocessing. For example, the client device #<b>1</b> <b>31</b><i>a </i>may also serve as a tunnel device, referred to as Client/Tunnel device #<b>1</b> a<b>1</b><i>a </i>as shown in system <b>120</b> in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. For example, the table <b>40</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b><i>a </i></figref>shows in the fifth row <b>42</b><i>e </i>such a client/tunnel device after signing in. A system may include client&#x2014;only devices using tunnel-only devices. Alternatively or in addition, a part of, or all the devices in a system may be client/tunnel devices, capable of assuming both roles of client and tunnel devices.</p><p id="p-0444" num="0446">In one example shown as a messaging flow <b>120</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>12</b><i>a</i></figref>, the client/tunnel #<b>1</b> device <b>121</b><i>a </i>is serving as a tunnel device (in addition to being the client device #<b>1</b> <b>31</b><i>a </i>as described above) serving as an intermediary device for the client device #<b>2</b> <b>31</b><i>b </i>for fetching content from the data server #<b>2</b> <b>22</b><i>b. </i>The &#x2018;Content Request&#x2019; message <b>122</b><i>a </i>(corresponding to the &#x2018;Content Request&#x2019; message <b>56</b><i>g </i>in the timing chart <b>50</b>) is first sent from the client device #<b>2</b> <b>31</b><i>b </i>to the client/tunnel device #<b>1</b> <b>121</b><i>a, </i>which responds by forwarding the request to the data server #<b>2</b> <b>22</b><i>b </i>using the &#x2018;Content Request&#x2019; message <b>122</b><i>b </i>(corresponding to the &#x2018;Content Request&#x2019; message <b>56</b><i>h </i>in the timing chart <b>50</b>). In turn the data server #<b>2</b> <b>22</b><i>b </i>replies and sends the content in &#x2018;Send Content&#x2019; message <b>122</b><i>c </i>(corresponding to the &#x2018;Send Content&#x2019; message <b>56</b><i>i </i>in the timing chart <b>50</b>) to the requesting client/tunnel device #<b>1</b> <b>121</b><i>a </i>now serving as a tunnel device, which in turn forward the fetched content to the asking client device #<b>2</b> <b>31</b><i>b </i>using the &#x2018;Send Content&#x2019; message <b>122</b><i>d </i>(corresponding to the &#x2018;Send Content&#x2019; message <b>56</b><i>j </i>in the timing chart <b>50</b>).</p><p id="p-0445" num="0447">Any device referred to herein as a &#x2018;tunnel device&#x2019;, such as the tunnel device #<b>1</b> <b>33</b><i>a, </i>the tunnel device #<b>2</b> <b>33</b><i>b, </i>or the tunnel device #<b>3</b> <b>33</b><i>c, </i>may be implemented as a computer serving as a client device in the server/client sense, and may execute client applications or software. In particular, such a tunnel device may execute a web browser application. Similarly, any tunnel device may be implemented as a computer serving as a server device in the server/client sense. Similarly, any device referred to herein as a &#x2018;client device&#x2019;, such as client device #<b>1</b> <b>31</b><i>a, </i>client device #<b>2</b> <b>31</b><i>b, </i>and client device #<b>3</b> <b>31</b><i>c, </i>may be implemented as a computer serving as a client device in the server/client sense, and may be executing client applications or software. In particular, such a client device may execute a web browser application. Similarly, any client device may be implemented as a computer serving as a server device in the server/client sense.</p><p id="p-0446" num="0448">Further, the functionality of any device herein may be implemented using multiple physical devices. In one example shown as a system <b>130</b> in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the client device #<b>1</b> <b>31</b><i>a </i>functionality is implemented in as client device #<b>1</b> system <b>133</b>, comprising a computer <b>132</b> (may be used for GUI or as a client), is communicating with a proxy server <b>131</b>. The client device #<b>1</b> <b>31</b><i>a </i>functionality may be split between the computer <b>132</b> and the proxy server <b>131</b>.</p><p id="p-0447" num="0449">In one example, the acceleration server <b>32</b> (together with the tunnel devices) forms a system that may be used to provide a service to a client device. The service allows the client device (such as client device #<b>1</b> <b>31</b><i>a</i>) to quickly and anonymously fetch content from the data server #<b>1</b> <b>22</b><i>a. </i>The service level may be measured, or the service may be billed for, if applicable, for example, using the following parameters (individually or combined):</p><p id="p-0448" num="0450">Content amount. In this example, the amount of data relating to the content fetched from a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>) is measured and logged. In such a scheme, the tunnel devices may send to the acceleration server the amount of data flowing through from the data server to the client device. Alternatively or in addition, the client device may log or send the amount of content fetched to the acceleration server <b>32</b>.</p><p id="p-0449" num="0451">Number of tunnels. The number of tunnels that were available to a client device, or the number of tunnel devices that were actually used, may be used as an indication to the service level.</p><p id="p-0450" num="0452">Location. The service level may be measured or billed based the country the data server, from which the content is fetched, is located. Similarly, the service level may be measured or billed based the country the client device, to which the content is fetched, is located.</p><p id="p-0451" num="0453">While the pre-connection process was described above regarding the communication between a client device (such as the client device #<b>1</b> <b>31</b><i>a</i>) and a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>), described as the client device pre-connection flowchart <b>64</b> and the tunnel device pre-connection flowchart <b>72</b>, a pre-connection may be established between any two devices in the system <b>30</b>, such as between a client device and the acceleration server <b>32</b>, between two client devices, or between a client device and a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>). Similarly, a pre-connection may be established between a tunnel device and the acceleration server <b>32</b>, between two tunnel devices, or between a tunnel device and a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>).</p><p id="p-0452" num="0454">The performance of the method and system described herein may be based on the latency involved in fetching a required content. The flowchart <b>65</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref> describes the steps involved in fetching content from a tunnel device, and a flowchart <b>140</b> in <figref idref="DRAWINGS">FIG. <b>14</b></figref> provides further detailed operation of a client device, such as the client device #<b>1</b> <b>31</b><i>a. </i>The &#x2018;receive Content&#x2019; step <b>63</b><i>c </i>may be partitioned into two or more steps, as shown in the flowchart <b>270</b> in <figref idref="DRAWINGS">FIG. <b>27</b></figref>, such as a &#x2018;Receive Start&#x2019; step <b>141</b><i>a, </i>relating to the starting of receiving data from a tunnel device, upon starting or completing the reception of the first byte of the data, for example, and a &#x2018;Receive End&#x2019; step <b>141</b><i>b, </i>relating to the ending of receiving data from a tunnel device, for example upon starting or completing the reception of the end byte of the data.</p><p id="p-0453" num="0455">As part of the &#x2018;Send Content Request&#x2019; step <b>63</b><i>b, </i>a timer #<b>1</b> is started in &#x2018;Timer #<b>1</b> Start&#x2019; step <b>142</b><i>a, </i>and the timer #<b>1</b> is stopped in a &#x2018;Timer #<b>1</b> Stop&#x2019; step <b>142</b><i>b </i>at the beginning of the receiving the data from the tunnel device in the &#x2018;Receive Start&#x2019; step <b>141</b><i>a. </i>Hence, the timer #<b>1</b> is used to measure the Round Trip Time (RTT), relating to the time interval measured from sending the request to a tunnel device until the requested data is starting to be received. Similarly, as part of the &#x2018;Receive Start&#x2019; step <b>143</b><i>a </i>a timer #<b>2</b> is started, and the timer #<b>2</b> is stopped in a &#x2018;Timer #<b>2</b> Stop&#x2019; step <b>143</b><i>b </i>at the end of the receiving the data from the tunnel device in a &#x2018;Receive End&#x2019; step <b>141</b><i>b. </i>Hence, the timer #<b>2</b> is used to measure the time interval required to receive the content itself from the tunnel. For example, in case the time interval is 50 milliseconds (ms), this is the time interval measured from starting to ending of the data reception from the tunnel device. In the case the content size is X bits, the BW can be calculated as the X bits divided by the timer #<b>2</b> measured time interval. For example, in the case the received content from the tunnel device is about the size of 50,000 bits (50 Kbits) received during 100 milliseconds (ms), the effective (or average) BW is BW=50,000/0.1=500,000 bits/second=500 Kb/s=62.5 Kbytes/s=62.5 KB/s. The total latency affecting the performance is the combination of both the time interval measured by timer #<b>1</b> and the time interval measured by timer #<b>2</b>. Using the above examples where the timer #<b>1</b> measured an RTT of 50 ms and the timer #<b>2</b> measured 100 ms, the total latency, measured from sending the request to the tunnel in the &#x2018;Send Content Request&#x2019; step <b>63</b><i>b </i>to the end of the content reception in the &#x2018;Receive End&#x2019; step <b>141</b><i>b, </i>is 150 ms (50+100=150).</p><p id="p-0454" num="0456">After a transaction involving fetching a content from a tunnel is completed, it is beneficial to store the fetched content for future use, as shown in a &#x2018;Store Content&#x2019; step <b>145</b> in the flowchart <b>140</b>. The fetched content may be stored in the client device in any volatile or non-volatile memory, or may be stored in a local cache as described in U.S. Pat. No. 8,135,912 to the same inventors as this application, entitled: &#x201c;System and Method of Increasing Cache Size&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein. The content is stored with its related metadata or any other identifiers, so it can be easily detected and fetched when later required. For example, the stored content may be used when the same content is required at any later stage by the same client, or may be used when the client device also serves as a peer device, such as the peer device #<b>1</b> <b>102</b><i>a </i>as shown in system <b>260</b>. In the latter case, the fetched content (such as a URL content) may be arranged and stored as chunks, as described herein.</p><p id="p-0455" num="0457">After a transaction involving fetching a content from a tunnel is completed, it is beneficial to store the transaction related information for future use, such as for future analysis. An example of a table relating to transactions log, that may be part of a database, is shown as table <b>150</b> in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. The table is updated in the &#x2018;Update Transactions Log&#x2019; step <b>144</b> as part of the flowchart <b>140</b> shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. A top row <b>152</b> provides the titles of the various columns, where each of the rows provides information regarding a specific transaction, where a first transaction information is shown in a first row <b>152</b><i>a, </i>the second transaction information is shown in a second row <b>152</b><i>b, </i>the third transaction information is shown in a third row <b>152</b><i>c, </i>and so forth. The first column <b>151</b><i>a </i>shows the date and time (in DD/MM HH/MM format) when the transaction occurred, such as the start or end of the transaction. For example, the first transaction related information is in the first row <b>152</b><i>a </i>shows that the transaction was completed (or started) at March 13<sup>th</sup>, on 9:23. Similarly, the second transaction information is in the second row <b>152</b><i>b </i>shows that the transaction was completed (or started) on March 13<sup>th</sup>, at 9:46, and the third transaction information is in the third row <b>152</b><i>b </i>shows that the transaction was completed (or started) at April 16<sup>th</sup>, on 11:22. The second column <b>151</b><i>b </i>includes an identifier such as the IP address of the tunnel device that was used in the transaction to fetch the content from the data server, which identifier (such as its IP address) is included in the third column <b>151</b><i>c. </i>In the example of the first transaction shown in the first row <b>152</b><i>a, </i>the IP address of the tunnel device used is 229.155.81.168, and it was used to fetch content stored in a data server having an IP address of 128.164.35.35.142. Similarly, in the example of the second transaction shown in the second row <b>152</b><i>b, </i>the IP address of the tunnel device used is 248.107.109.10, and it was used to fetch content stored in a data server having an IP address of 49.154.2.5, and in the example of the third transaction shown in the third row <b>152</b><i>c, </i>the IP address of the tunnel device used is 158.217.19.195, and it was used to fetch content stored in a data server having an IP address of 72.251.238.51. The fourth column <b>151</b><i>d </i>describes the identifier of the content that was fetched during this transaction, such as IP address, URL, web-site or web-page, where the first transaction content (in the first row <b>152</b><i>a</i>) relates to the URL www.111.com/22.mpg, the second transaction content (in the second row <b>152</b><i>b</i>) relates to the URL www.xxx.com/hy.avi, the third transaction content (in the third row <b>152</b><i>c</i>) relates to the URL www.yyy.com/t6.php, and so forth.</p><p id="p-0456" num="0458">A fifth column <b>151</b><i>e </i>logs the BW calculated in a respective transaction, based on timer #<b>2</b> time interval measurement as described above. In the first transaction (in the first row <b>152</b><i>a</i>) the calculated BW is logged as 1000 Kb/s (=1 Mb/s=125 KB/s), in the second transaction (in the second row <b>152</b><i>b</i>) the calculated BW is logged as 350 Kb/s (=0.35 Mb/s), and in the third transaction (in the third row <b>152</b><i>c</i>) the calculated BW is logged as 2500 Kb/s (=2.5 Mb/s). A sixth column <b>151</b><i>f </i>logs the RTT measured in the transaction, based on timer #<b>1</b> time interval measurement as described above. In the first transaction (in the first row <b>152</b><i>a</i>) the measured RTT is logged as 30 ms (=0.03 seconds=0.03 s), in the second transaction (in the second row <b>152</b><i>b</i>) the measured RTT is logged as 70 ms, and in the third transaction (in the third row <b>152</b><i>c</i>) the measured RTT is logged as 540 ms (=0.54 second).</p><p id="p-0457" num="0459">The transaction log, such as table <b>150</b>, may be prepared by a client device, such as client device #<b>1</b> <b>31</b><i>a, </i>and stored in the client device for future use. Alternatively or in addition, the transaction log may be sent, after each transaction or after multiple transactions, such as per a time period (e.g., hourly, daily, weekly, monthly), to other entities in the system, to be stored in the entities for future use by them or by other entities in the network. In one example, the transaction log is sent to the acceleration server <b>32</b>. Alternatively or in addition, the transactions log may be sent to the tunnel devices, such as the tunnel device #<b>1</b> <b>33</b><i>a, </i>the tunnel device #<b>2</b> <b>33</b><i>b, </i>or the tunnel device #<b>3</b> <b>33</b><i>c, </i>that were involved in the content fetching transaction.</p><p id="p-0458" num="0460">Similar to table <b>150</b> shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, a table <b>150</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>15</b><i>a </i></figref>shows a table relating to four tunnel devices used for fetching different content from the same data server (such as the data server #<b>1</b> <b>22</b><i>a</i>), thus the same server IP address is shown in the third column <b>153</b><i>c. </i>The IP addresses the tunnel devices are shown in the second column <b>153</b><i>b, </i>the URL fetched is shown in the fourth column <b>153</b><i>d, </i>the date and time of the transaction are logged in the first column <b>153</b><i>a, </i>the BW is shown in the fifth column <b>153</b><i>e, </i>and the measured RTT is shown in the sixth column <b>153</b><i>f. </i>The first transaction (logged in a first row <b>154</b><i>a</i>) is using a first tunnel device having IP address of 139.230.154.213, the second transaction (logged in a second row <b>154</b><i>b</i>) is using a second tunnel device having IP address of 132.171.60.197, the third transaction (logged in a third row <b>154</b><i>c</i>) is using a third tunnel device having IP address of 248.46.80.36, and the fourth transaction (logged in a fourth row <b>154</b><i>d</i>) is using a fourth tunnel device having IP address of 31.16.208.171.</p><p id="p-0459" num="0461">The tunnel devices to be used when content is to be fetched from a data server (such as the data server <b>22</b><i>a</i>) may be selected by a client device (such as the client device #<b>1</b> <b>31</b><i>a</i>) in the &#x2018;Select Tunnel&#x2019; step <b>62</b><i>c </i>in the flowchart <b>60</b>, or in the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>b </i>in the flowchart <b>100</b>. Alternatively or in addition, the tunnel devices may be selected by the acceleration server <b>32</b>, as part of the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a </i>in the flowchart <b>90</b>. The selection may be based on a past performance of the tunnel devices, such as information relating to former transactions involving these tunnel devices. In one example, the transactions log may be used to evaluate and select which tunnel devices to use in a specific transaction to be executed, or in multiple transactions.</p><p id="p-0460" num="0462">In the example of the transaction log table <b>150</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>15</b><i>a </i></figref>and relating to a client device, the client device may need to fetch content from the same data server shown in the table <b>150</b><i>a </i>(having an IP address of 49.154.2.5), and thus may use the table content as an indication of the performance of the various tunnel devices. In one example, the criterion to select a single tunnel device to be used for fetching content from the data server may be based on having higher BW, assuming that the higher BW has not changed and thus will result in faster content fetching, and hence the tunnel device used in the third logged transaction (having an IP address of 248.46.80.36) will be selected for this transaction, having the highest recorded BW of 2500 Kb/s. In the case two tunnel devices are to be selected, the second tunnel device to be selected is the tunnel device used in the fourth logged transaction (having an IP address of 31.16.208.171) will be selected for this transaction, being associated with the second highest BW in the table. Similarly, the tunnel device associated with the first logged transaction will be the next to be selected.</p><p id="p-0461" num="0463">Alternatively or in addition, the criterion to select a single tunnel to be used for fetching content from the data server may be based on having lower RTT, assuming that the lower RTT has not changed and thus will result in faster content fetching, and hence the tunnel device used in the first logged transaction (having an IP address of 139.230.154.213) will be selected for this transaction, having the lowest recorded RTT of 30 ms. In the case two tunnel devices are to be selected, the second tunnel device to be selected is the tunnel device used in the second logged transaction (having an IP address of 132.171.60.197) will be selected for this transaction, being associated with the second lowest RTT in the table (70 ms). Similarly, the tunnel device associated with the fourth logged transaction will be the next to be selected.</p><p id="p-0462" num="0464">Alternatively or in addition, both the RTT and the BW are used as criteria for selecting tunnel devices. In one example, the expected total latency is calculated, based on both the former BW and the former RTT, and the tunnel device offering the lowest estimated total latency will be selected. In one example, assuming the content to be fetched is estimated (or known to be) having the size of 100 Kb (100 kilobits). The tunnel device used in the first logged transaction (in the first row <b>154</b><i>a</i>) is associated with past performance (with the same data server) of BW=1000 Kb/s and RTT=30 ms. In such a case, the total latency is calculated and estimated as 30+100/1000=130 ms. The tunnel device used in the second logged transaction (in the second row <b>154</b><i>b</i>) is associated with past performance (with the same data server) of BW=<b>350</b> Kb/s and RTT=<b>70</b> ms, and thus the total latency is calculated and estimated as 70+100/350=355.7 ms. Similarly, the estimated total latency of using the tunnel device used in the third logged transaction (in the third row <b>154</b><i>c</i>) is 580 ms, and the estimated total latency of using the tunnel device used in the fourth logged transaction (in the fourth row <b>154</b><i>d</i>) is 241.4 ms. Having the lowest estimated total latency, the tunnel device used in the first logged transaction (in the first row <b>154</b><i>a</i>) will be selected first as having the lowest expected total latency, the tunnel device used in the fourth logged transaction (in the fourth row <b>154</b><i>d</i>) will be selected second, the tunnel device used in the second logged transaction (in the second row <b>154</b><i>b</i>) will be selected third, and the tunnel device used in the third logged transaction (in the third row <b>154</b><i>c</i>) will be selected last.</p><p id="p-0463" num="0465">However, assuming the content to be fetched is estimated (or known to be) having the size of 1000 Kb (1000 kilobits=1 Mb). The tunnel device used in the first logged transaction (in the first row <b>154</b><i>a</i>) is associated with past performance (with the same data server) of BW=1000 Kb/s and RTT=30 ms. In such a case, the total latency is calculated and estimated as 30+1000/1000=1030 ms (1.03 s). The tunnel device used in the second logged transaction (in the second row <b>154</b><i>b</i>) is associated with past performance (with the same data server) of BW=350 Kb/s and RTT=70 ms, and thus the total latency is calculated and estimated as 70+1000/350=2927.1 ms. Similarly, the estimated total latency of using the tunnel device used in the third logged transaction (in the third row <b>154</b><i>c</i>) is 940 ms, and the estimated total latency of using the tunnel device used in the fourth logged transaction (in the fourth row <b>154</b><i>d</i>) is 884.2 ms. Having the lowest estimated total latency, the tunnel device used in the fourth logged transaction (in the fourth row <b>154</b><i>d</i>) will be selected first as having the lowest expected total latency, the tunnel device used in the third logged transaction (in the third row <b>154</b><i>c</i>) will be selected second, the tunnel device used in the first logged transaction (in the first row <b>154</b><i>a</i>) will be selected third, and the tunnel device used in the second logged transaction (in the second row <b>154</b><i>b</i>) will be selected last.</p><p id="p-0464" num="0466">The flowchart <b>74</b> in <figref idref="DRAWINGS">FIG. <b>7</b><i>a </i></figref>describes a method to be executed by a tunnel device, such as the tunnel device #<b>1</b> <b>33</b><i>a </i>(or any other network element), for independently increasing the number of connections to a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>), in order to allow faster fetching of content from the data server. Alternatively or in addition, the client device may manage the number of connections used per tunnel device, as described in a flowchart <b>160</b> shown in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, which describes a method that may be executed by a client device, such as the client device #<b>1</b> <b>31</b><i>a </i>(or any other network), in element order to set more connection to the data server. The maximum number of connections available to the data server is determined in a &#x2018;Determine Maximum Connections Number&#x2019; step <b>161</b><i>a. </i>This maximum value may be obtained from previous interactions with this data server, received from a tunnel device in a &#x2018;Notify Client&#x2019; step <b>74</b><i>c </i>in the flowchart <b>74</b>, or using a known default number. The actual number of connections that are in use at a specific time is determined in a &#x2018;Determine Number of Connections Used&#x2019; step <b>161</b><i>b. </i>The actual connections used for each tunnel device may be obtained, for example, from the tunnel devices. In one example, more connection may be used, as checked in a &#x2018;More Connections Available?&#x2019; step <b>161</b><i>c. </i>For example, the data server may provide up to 8 connections per tunnel device, while one of tunnel devices only uses 5 connections. In such a case, the client device may send a request to this tunnel device to increase the number of connections, for example by adding a single connection, as part of a &#x2018;Request More Connections&#x2019; step <b>161</b><i>d. </i>In the case where the request for adding one or more connections is successful, as checked in a &#x2018;Rejected?&#x2019; step <b>161</b><i>e, </i>the device may repeat the request for additional connections. However, in one example, no additional connections may be opened, since the tunnel device has reached the maximum number of allowable connections with the data server. If no additional connections are to be opened, the client device may increase the effective bandwidth of content fetching from the data server by requesting the usage of more tunnel devices from an acceleration server (such as the acceleration server <b>32</b>) as part of a &#x2018;Request More Tunnels&#x2019; step <b>161</b><i>f, </i>corresponding to the &#x2018;Request Tunnels List&#x2019; step <b>62</b><i>a </i>in the flowchart <b>60</b>, followed by activating selected tunnel devices from the received tunnel devices list received from the acceleration server <b>32</b>, as part of an &#x2018;Activate More Tunnels&#x2019; step <b>161</b><i>g, </i>corresponding to the &#x2018;Content Fetch&#x2019; flowchart <b>65</b>. The client device may further repeat the process for maximizing the number of connections for the newly activated tunnel devices.</p><p id="p-0465" num="0467">Web analysis is used by many web sites in order to measure the usage statistics, such as counting of web pages views, checking an average time between various web pages, and other usage statistics (&#x2018;usage stats&#x2019;). In many cases, the web analysis is based on embedding a code in the web-browser, which sends an update or request to an analytics server, such as Google Analytics Server, which is used to measure and log the required web analysis. A flowchart <b>170</b> shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref> describes the scheme of interacting with the analytics server. An application, such as a web browser, may identify a content (such as by a URL) to be fetched via the Internet in a &#x2018;URL Identified&#x2019; step <b>171</b><i>a. </i>Alternatively or in addition, the content may be identified by the IP of the data server, or using any other identification. Before accessing the URL-associated data server for fetching the required content, the application first sends information to the analytics server for logging and gathering statistics, in an &#x2018;Update Analytics Server&#x2019; step <b>171</b><i>b. </i>The applications then waits until the update is completed, as acknowledged by receiving the analytics server response in an &#x2018;Analytics Server Response&#x2019; step <b>171</b><i>c. </i>Only upon receiving the analytics server response, the application requests the content from the respective data server in a &#x2018;Request to Data Server&#x2019; step <b>171</b><i>d. </i>The access to the analytics server, as described in the &#x2018;Update Analytics Server&#x2019; step <b>171</b><i>b </i>and waiting for the server to respond in the &#x2018;Analytics Server Response&#x2019; step <b>171</b><i>c, </i>consumes time and resources, and makes the process of fetching the required content slower.</p><p id="p-0466" num="0468">Each of the analytic servers that are commonly used typically uses a unified response to an update request in the &#x2018;Analytics Server Response&#x2019; step <b>171</b><i>c. </i>In one example, a database is built, including typical responses of analytic servers. Such information regarding typical responses may be obtained from previous interactions with analytic servers, either by the device executing the requesting application, or from other network elements.</p><p id="p-0467" num="0469">The database containing the typical responses may be used to accelerate the flow of the requesting application, as described in a flowchart <b>170</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>17</b><i>a</i></figref>, which corresponds to a flowchart <b>170</b> shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref>. The Upon detecting a communication request targeting the analytics server as part of the &#x2018;Update Analytics Server&#x2019; step <b>171</b><i>b, </i>the request is intercepted in an &#x2018;Intercept Update&#x2019; step <b>172</b><i>b. </i>Such interception may be in the form of a filter driver (or any other intermediate driver), enabling the interception as part of the OS kernel. Alternatively or in addition, the interception may be in the form of an extension or a plug-in of the requesting application, such as a browser plug-in or a browser extension in the case where the application is a web browser. Alternatively or in addition, the interception of the request may use hooking of the requesting application or of the communication-related application. Alternatively or in addition, the application and the steps described herein may communicate using an Inter-Process Communication (IPC), such as a file sharing, a signal, a socket, a pipe, a message queue, a shared memory, a semaphore, or memory mapped file. In Windows environment, the IPC may be based on a clipboard, a Component Object Model (COM), a data copy, a DDE protocol, or mail slots.</p><p id="p-0468" num="0470">The typical response database is used as a look-up table, associating to the update request intercepted a simulated artificial typical response, that is expected to be the same or similar to the response expected from the analytics server, as part of an &#x2018;Obtain Typical Response&#x2019; step <b>172</b><i>b. </i>The artificial response is then returned to the requesting application, in a &#x2018;Return Typical Response&#x2019; step <b>172</b><i>c, </i>so the requesting application may continue its operation in the &#x2018;Request to Data Server&#x2019; step <b>171</b><i>d, </i>without the need to wait first for the actual response from the analytics server as part of the &#x2018;Analytics Server Response&#x2019; step <b>171</b><i>c. </i>In such a scheme, the latency involved with waiting to the analytics server response is obviated.</p><p id="p-0469" num="0471">The actual response received from the analytics server as part of the &#x2018;Analytics Server Response&#x2019; step <b>171</b><i>c </i>may be ignored in general, and in particular by the requesting application, as it was substituted by the simulated response in the &#x2018;Return Typical Response&#x2019; step <b>172</b><i>c. </i>Alternatively or in addition, the response is stored as part of the typical response database, to be used for forming simulated responses in future interactions with the same analytics server. Further, in order to save resources such as bandwidth and processing power, the update request to the analytics server may not be actually transmitted, and replaced only with the simulated response. Alternatively or in addition, such update request may be stored and transmitted at a later stage, for example, when the network element is idle.</p><p id="p-0470" num="0472">The elements involved in a DHCP process are illustrated in a system <b>180</b> shown in <figref idref="DRAWINGS">FIG. <b>18</b></figref>. A device <b>181</b> (which may be any network element) may connect to a DHCP server #<b>1</b> <b>182</b><i>a </i>via a LAN <b>183</b>, or may use a DHCP server #<b>2</b> <b>182</b><i>b </i>connected via a WAN <b>184</b>. Typically, a DHCP process is completed in less than 5 milliseconds (ms) when communicating over the LAN <b>183</b>, such as LAN <b>183</b>, and is completed in less than 20 ms when communicating with the DHCP server #<b>2</b> <b>182</b><i>b </i>over the WAN <b>184</b>. The DHCP process performed by the device <b>181</b> is described as a flowchart <b>180</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>18</b><i>a</i></figref>. Upon sending to the DHCP server (such as DHCP server #<b>1</b> <b>182</b><i>a </i>or DHCP server #<b>2</b> <b>182</b><i>b</i>) a DHCP request in a &#x2018;Send DHCP Request&#x2019; step <b>185</b><i>a, </i>the device <b>181</b> starts a timer #<b>1</b> in a &#x2018;Start Timer #<b>1</b>) step <b>185</b><i>b. </i>Commonly, such a countdown timer is set to 5 seconds, notifying a timeout period after the 5 seconds expire. In a &#x2018;Response Received?&#x2019; step <b>185</b><i>c, </i>it is checked if a response was received, and the DHCP has been completed, so that the device may continue other activities, as part of a &#x2018;Return Response&#x2019; step <b>185</b><i>d. </i>The device <b>181</b> checks continuously and waits for a response from a DHCP server for completing the DHCP process as long as the timer #<b>1</b> has not expired in a &#x2018;Timer #<b>1</b> Expired?&#x2019; step <b>185</b><i>e. </i>In the case where the timer #<b>1</b> has expired, and no connection was made with the DHCP server or the DHCP has not been completed, then a failure of the DHCP process is declared in a &#x201c;Return &#x2018;No Response&#x2019;&#x201d; step <b>185</b><i>f. </i></p><p id="p-0471" num="0473">While the common DHCP resolving period is under 5 ms in a LAN environment, and under 20 ms in a WAN environment, the timer #<b>1</b> typical setting is of 5 seconds (or any other number of seconds), which is many orders of magnitude longer than required. Further, in some case a short or an intermittent communication problem, may cause a transiently drop of a packet, causing the DHCP process to fail and not be completed. Such failure will be detected only after the full 5 seconds has been expired, leading to a long delay in responding to, and fixing the problem (e.g, by repeating the DHCP process).</p><p id="p-0472" num="0474">An improved DHCP timing scheme is shown as a flowchart <b>190</b> in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, which may be executed by the device <b>181</b>, and is based on the flowchart <b>180</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>18</b><i>a</i></figref>. In addition to the prior-art timer #<b>1</b> that is commonly set for a few seconds, an additional timer #<b>2</b> is added, which is set to a much lower period, such as 100 or 200 ms, which allows for faster reconnection in case of a failure. The timer #<b>2</b> starts with a &#x2018;Start Timer #<b>2</b>&#x2019; step <b>191</b><i>a. </i>In the case the timer #<b>2</b> expires before a successful DHCP process is completed, as checked in a &#x2018;Timer #<b>2</b> Expired?&#x2019; step <b>191</b><i>b, </i>and as long as the timer #<b>1</b> has not expired, the timer #<b>2</b> is restarted in the &#x2018;Start Timer #<b>2</b>&#x2019; step <b>191</b><i>a, </i>and the DHCP process is re-initialized in the &#x2018;Send DHCP Request&#x2019; step <b>185</b><i>a. </i>Hence, in the case of a brief communication problem, the DHCP process initialization will be repeated, and as such will be recovered and completed in one of the cycles. In the case of a dysfunctional DHCP server, the problem will still be determined after timer #<b>1</b> expiration, as in the prior-art scheme.</p><p id="p-0473" num="0475">In one example, accessing a data server is improved by using an intermediate device referred to as &#x2018;peer&#x2019; and &#x2018;agent&#x2019; devices, respectfully executing a &#x2018;peer&#x2019; and &#x2018;agent&#x2019; flowchart. <figref idref="DRAWINGS">FIG. <b>20</b></figref> shows a system <b>200</b> including a client device <b>201</b><i>a, </i>which may be the same device as the client device #<b>1</b> <b>31</b><i>a </i>described above or a distinct device, that may access the data servers <b>22</b><i>a </i>and <b>22</b><i>b </i>using one or more of the peer device #<b>1</b> <b>102</b><i>a, </i>the peer device #<b>2</b> <b>102</b><i>b, </i>and the peer device #<b>3</b> <b>102</b><i>c, </i>under the management and control of the acceleration server <b>202</b>, and using agent devices such as the agent device #<b>1</b> <b>103</b><i>a </i>and the agent device #<b>2</b> <b>103</b><i>b. </i>The acceleration server <b>202</b> may be the same server as the acceleration server <b>32</b> in the system <b>30</b> described above, or may be a distinct or a dedicated server. Similarly, a data server, such as the data server #<b>1</b> <b>22</b><i>a </i>or data server #<b>2</b> <b>22</b><i>b, </i>may be the same as the same servers described above in system <b>30</b>, or may be distinct or dedicated servers. While two agent devices are shown, any number of agent devices may be used. Similarly, while three peer devices are shown, any number of peer devices may be used.</p><p id="p-0474" num="0476">The content stored in a data server, such as the data server #<b>1</b> <b>22</b><i>a, </i>which may be requested by a client device such as the client device #<b>1</b> <b>201</b><i>a, </i>may be partitioned into multiple parts or &#x2018;slices&#x2019;. Any number of slices may be used. The slicing may be in a bit, nibble (4-bits), byte (8-bits), word (multiple bytes), character, string, or file level. For example, in a case wherein the content includes 240 bytes designated byte #<b>1</b> to byte #<b>240</b>, using a byte level partitioning into two slices results in a first slice (slice #<b>1</b>) including byte #<b>1</b> to byte #<b>120</b>, and a second slice (slice #<b>2</b>) including byte #<b>121</b> to byte #<b>240</b>. In the case of byte-level partitioning into three slices (referred as slice #<b>1</b>, slice #<b>2</b>, and slice #<b>3</b>), a first slice (slice #<b>1</b>) may be including byte #<b>1</b> to byte #<b>80</b>, a second slice (slice #<b>2</b>) may be including byte #<b>81</b> to byte #<b>160</b>, and a third slice (slice #<b>3</b>) may be including byte #<b>161</b> to byte #<b>240</b>. Similarly, in a case wherein the content include 3 bytes designated byte #<b>1</b> to byte #<b>3</b> representing 24 bits, using a bit-level partitioning into four slices results in a slice #<b>1</b> including the first 6 bits, slice #<b>2</b> including the next 6 bits, slice #<b>3</b> including the next 6 bits, and slice #<b>4</b> including the last 6 bits. The partition may be into equal length parts. Alternatively or in addition, a different length slicing may be applied. For example, in the case of a 240 bytes content and using byte-level partitioning into three slices (referred as slice #<b>1</b>, slice #<b>2</b>, and slice #<b>3</b>), a first slice (slice #<b>1</b>) may be including byte #<b>1</b> to byte #<b>20</b> (20-byte length), a second slice (slice #<b>2</b>) may be including byte #<b>21</b> to byte #<b>100</b> (80-byte length), and a third slice (slice #<b>3</b>) may be including byte #<b>101</b> to byte #<b>240</b> (140-byte length). In one example, the content itself is made of inherent or identifiable parts or segments, and the partition may make use of these parts. In one example, the content may be a website content composed of multiple webpages, and thus the partition may be such that each slice includes one (or few) webpages. Further, the partitioning may be sequential or non-sequential in the content.</p><p id="p-0475" num="0477">The partitioning may be non-overlapping, wherein each slice includes a distinct part of the content, as exampled above in the case wherein the content includes 240 bytes designated byte #<b>1</b> to byte #<b>240</b>, where using a byte level partitioning into three slices (referred as slice #<b>1</b>, slice #<b>2</b>, and slice #<b>3</b>), results in a first slice (slice #<b>1</b>) including byte #<b>1</b> to byte #<b>80</b>, a second slice (slice #<b>2</b>) including byte #<b>81</b> to byte #<b>160</b>, and a third slice (slice #<b>3</b>) including byte #<b>161</b> to byte #<b>240</b>. Alternatively or in addition, an overlapping partitioning may be applied, where the same part of the content is included in multiple slices. For example, in a case above where the content includes 240 bytes designated byte #<b>1</b> to byte #<b>240</b>, and using a byte level partitioning into three slices (referred as slice #<b>1</b>, slice #<b>2</b>, and slice #<b>3</b>), a first slice (slice #<b>1</b>) may include byte #<b>1</b> to byte #<b>160</b>, a second slice (slice #<b>2</b>) may include byte #<b>81</b> to byte #<b>240</b>, and a third slice (slice #<b>3</b>) may include byte #<b>1</b> to byte #<b>80</b> in addition to byte #<b>161</b> to byte #<b>240</b>. In such a case, byte #<b>1</b> to byte #<b>80</b> are part of both slice #<b>1</b> and slice #<b>3</b>, byte #<b>81</b> to byte #<b>160</b> are part of both slice #<b>1</b> and slice #<b>2</b>, and byte #<b>161</b> to byte #<b>240</b> are part of both slice #<b>2</b> and slice #<b>3</b>. It is noted that in such a partition, the content may be fully reconstructed from any two of the slices, hence providing a degree of redundancy. For example, in case of carrying the three slices over the Internet and a failure to receive one of the slices, the remaining two slices may be used to fully reconstruct the whole content.</p><p id="p-0476" num="0478">In one example, the content is a website or a webpage, or may be identified as a URL, and consists of, or comprises, non-overlapping and equally-sized parts, referred to as chunks. For example, multiple chunks may be combined to reconstruct the original content, such as website or content. A chunk size may be 16 KB (Kilo-Bytes), and in the case the content to be partitioned is not an exact multiple of 16 KB, the &#x2018;last&#x2019; chunk will padded and filled with &#x2018;space&#x2019; characters (or any other no content data).</p><p id="p-0477" num="0479">For example, multiple chunks may be combined to reconstruct the original content, such as website or content, as schematically shown in an arrangement <b>210</b> shown in <figref idref="DRAWINGS">FIG. <b>21</b></figref>. The data servers may include content addressed by various IP addresses or URLs, such as URL #<b>1</b> <b>211</b><i>a, </i>URL #<b>2</b> <b>211</b><i>b, </i>URL #<b>3</b> <b>211</b><i>c, </i>and URL #N <b>211</b><i>d. </i>While exampled using URLs, any other type of content may equally apply. Each URL may be associated with the URL associated HTTP headers. A content of the URL #<b>1</b> <b>211</b><i>a </i>consists of multiple chunks stack <b>214</b><i>a </i>consisting of m chunks, designated chunk #<b>1</b><i>a </i><b>212</b><i>a, </i>chunk #<b>1</b><i>b </i><b>212</b><i>b, </i>chunk #<b>1</b><i>c </i><b>212</b><i>c, </i>up to chunk #<b>1</b><i>m </i><b>212</b><i>d. </i>Similarly, a content of the URL #<b>2</b> <b>211</b><i>b </i>consists of multiple chunks stack <b>214</b><i>b </i>consisting of n chunks (n=m or n&#x2260;m), designated chunk #<b>2</b><i>a </i><b>212</b><i>e, </i>chunk #<b>2</b><i>b </i><b>212</b><i>f, </i>chunk #<b>2</b><i>c </i><b>212</b><i>g, </i>up to chunk #<b>2</b><i>n </i><b>212</b><i>h, </i>and a content of the URL #N <b>211</b><i>d </i>consists of multiple chunks stack <b>214</b><i>c </i>consisting of n chunks (p=m, p=n, p&#x2260;n or p&#x2260;m), designated chunk #<b>3</b><i>a </i><b>212</b><i>i, </i>chunk #<b>3</b><i>b </i><b>212</b><i>j, </i>chunk #<b>3</b><i>c </i><b>212</b><i>k, </i>up to chunk #<b>3</b><i>p </i><b>212</b><i>l. </i>Similarly, the URL #<b>3</b> <b>211</b><i>c </i>may be partitioned into chunks (not shown).</p><p id="p-0478" num="0480">Each of the content in the chunks is identified by a chunk identifier, where each chunk identifier is associated with one, and only one, chunk. In one example, preferably used in sequential partitioning scheme, a chunk is identified by the identifier of the content and the location of the chunk in the sequence of the partitioning. For example, a chunk may be identified by the content (e.g., URL, web-site, or web-page), and a number such as the number &#x2018;23&#x2019;, meaning that this chunk is the 23<sup>rd </sup>slice in sequential partitioning of the content. Alternatively or in addition, the CRC of the content of the chunk is calculated, and used as the chunk identifier. For example, CRC-32 may be used, allowing each chunk (such as 16 KB size) to be identified by 33-bit identifier. Alternatively or in addition, a chunk identifier is based on a hash function of the chunk content.</p><p id="p-0479" num="0481">A peer device may include a part of, or the entire stack of a single URL. Alternatively or in addition, a peer device may include a part of, or the entire stack of multiple URLs. In one example, a peer device may store all of the chunks included in a URL (or any other content). As shown in the arrangement <b>210</b>, the peer device #<b>1</b> <b>213</b><i>a </i>stores the stack <b>214</b><i>a </i>of the entire chunks relating to the single URL #<b>1</b> <b>211</b><i>a, </i>the peer device #<b>2</b> <b>213</b><i>b </i>stores the stacks of <b>2</b> URLs: The stack <b>214</b><i>a </i>of the URL #<b>1</b> <b>211</b><i>a </i>and the stack <b>214</b><i>b </i>of the URL #<b>2</b> <b>211</b><i>b. </i>Similarly, the peer device #<b>3</b> <b>213</b><i>c </i>stores the stacks of 3 URLs: The stack <b>214</b><i>a </i>of the URL #<b>1</b> <b>211</b><i>a, </i>the stack <b>214</b><i>b </i>of the URL #<b>2</b> <b>211</b><i>b, </i>and the stack <b>214</b><i>c </i>of the URL #N <b>211</b><i>d. </i>Similar to peer device #<b>1</b> <b>213</b><i>a, </i>the peer device #d <b>213</b><i>q </i>stores the stack <b>214</b><i>c </i>of the entire chunks relating to the single URL #N <b>211</b><i>d. </i>The agent devices serve as pointers to the peer devices, based on the requested content. As shown in an arrangement <b>210</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>21</b><i>a</i></figref>, an agent device #<b>1</b> <b>215</b><i>a </i>stores information regarding the location of content relating to URL #<b>1</b> <b>211</b><i>a, </i>and thus stores the identifiers of the peer device #<b>1</b> <b>213</b><i>a, </i>the peer device #<b>2</b> <b>213</b><i>b, </i>and the peer device #<b>3</b> <b>213</b><i>c, </i>since all these peer devices store the content of URL #<b>1</b> <b>211</b><i>a. </i>An agent device #<b>2</b> <b>215</b><i>b </i>stores information regarding the location of content relating to URL #<b>2</b> <b>211</b><i>b, </i>and thus stores the identifiers of the peer device #<b>2</b> <b>213</b><i>b </i>and the peer device #<b>3</b> <b>213</b><i>c, </i>since these peer devices store the content of URL #<b>2</b> <b>211</b><i>b. </i>Similarly, an agent device #N <b>215</b><i>d </i>stores information regarding the location of content relating to URL #N <b>211</b><i>d, </i>and thus stores the identifiers of the peer device #q <b>213</b><i>d </i>and the peer device #<b>3</b> <b>213</b><i>c, </i>since these peer devices store the content of URL #N <b>211</b><i>d. </i>While exampled where each agent device stores information about a single URL, an agent device may equally store information regarding the location of multiple URLs.</p><p id="p-0480" num="0482">A peer device, such as the peer device #<b>1</b> <b>102</b><i>a, </i>the peer device #<b>2</b> <b>102</b><i>b, </i>and the peer device #<b>3</b> <b>102</b><i>c, </i>may store one or more chunks (or any part of the entire content), as a copy of the chunk content as part of the whole content, stored as in a data server. The availability of such content or chunks may be the result of a past loading of the content in the chunk from the appropriate data server. Each of the chunk content is stored in a memory of the associated peer device, and the memory may be referred to herein as a cache memory. As shown in scheme <b>210</b><i>b </i>in <figref idref="DRAWINGS">FIG. <b>21</b><i>b</i></figref>, the peer device #<b>1</b> <b>213</b><i>a </i>(corresponding for example to the peer device #<b>1</b> <b>102</b><i>a</i>) stores in its cache memory the chunk #<b>1</b><i>a </i><b>212</b><i>a, </i>the chunk #<b>1</b><i>b </i><b>212</b><i>b, </i>the chunk #<b>2</b><i>a </i><b>212</b><i>e, </i>and the chunk #<b>2</b><i>c </i><b>212</b><i>g. </i>Similarly, the peer device #<b>2</b> <b>213</b><i>b </i>(corresponding for example to the peer device #<b>2</b> <b>102</b><i>b</i>) stores in its cache memory the chunk #<b>1</b><i>b </i><b>212</b><i>b, </i>the chunk #<b>1</b><i>m </i><b>212</b><i>d, </i>the chunk #<b>2</b><i>b </i><b>212</b><i>f, </i>and the chunk #<b>3</b><i>a </i><b>212</b><i>i; </i>the peer device #<b>3</b> <b>213</b><i>c </i>(corresponding for example to the peer device #<b>3</b> <b>102</b><i>c</i>) stores in its cache memory the chunk #<b>2</b><i>b </i><b>212</b><i>f, </i>the chunk #<b>2</b><i>c </i><b>212</b><i>g, </i>and the chunk #<b>2</b><i>n </i><b>212</b><i>h; </i>and the peer device #q <b>213</b><i>d </i>stores in its cache memory the chunk #<b>1</b><i>m </i><b>212</b><i>d, </i>the chunk #<b>2</b><i>n </i><b>212</b><i>h, </i>the chunk #<b>3</b><i>b </i><b>212</b><i>j, </i>and the chunk #<b>3</b><i>p </i><b>212</b><i>l. </i>A chunk may not be associated with any peer device, such as the chunk #<b>3</b><i>c </i><b>212</b><i>k, </i>which is shown in scheme <b>210</b> as not being stored in any of the peer devices. Alternatively or in addition, a chunk may be stored in multiple peer devices, such as the chunk #<b>1</b><i>b </i><b>212</b><i>b </i>which is shown to be stored in both the peer device #<b>1</b> <b>213</b><i>a </i>and the peer device #<b>2</b> <b>213</b><i>b. </i>Further, a peer device may store chunks which are part of multiple URLs, such as peer #q <b>213</b><i>d </i>shown to store the chunk #<b>1</b><i>m </i><b>212</b><i>d </i>which is part of URL #<b>1</b> <b>211</b><i>a, </i>the chunk #<b>2</b><i>n </i><b>212</b><i>h </i>which is part of URL #<b>2</b> <b>211</b><i>b, </i>and the chunk #<b>3</b><i>b </i><b>212</b><i>j </i>which is part of URL #N <b>211</b><i>d. </i></p><p id="p-0481" num="0483">An agent device, such as the agent device #<b>1</b> <b>103</b><i>a </i>or the agent device #<b>2</b> <b>103</b><i>b, </i>may include a list of peers, for example peers that store chunks relating to, or retrieve from, the same data server or URL. In the example shown as a scheme <b>210</b><i>c </i>in <figref idref="DRAWINGS">FIG. <b>21</b><i>c</i></figref>, the agent device #<b>1</b> <b>215</b><i>a </i>(corresponding for example to the agent device #<b>1</b> <b>103</b><i>a</i>) stores a list of chunks location of URL #<b>1</b> <b>211</b><i>a, </i>including the peer device #<b>1</b> <b>213</b><i>a </i>(storing Chunk #<b>1</b><i>a </i><b>212</b><i>a </i>and Chunk #<b>1</b><i>b </i><b>212</b><i>b</i>), the peer #<b>2</b> <b>213</b><i>b </i>(storing Chunk #<b>1</b><i>b </i><b>212</b><i>b </i>and Chunk #<b>1</b><i>m </i><b>212</b><i>d</i>), and the peer #<b>3</b> <b>213</b><i>c </i>(storing Chunk #<b>1</b><i>m </i><b>212</b><i>d</i>). Similarly, the agent device #<b>2</b> <b>215</b><i>b </i>(corresponding for example to the agent device #<b>2</b> <b>103</b><i>b</i>) stores a list of chunks location of URL #<b>2</b> <b>211</b><i>b, </i>including the peer device #<b>1</b> <b>213</b><i>a </i>(storing Chunk #<b>2</b><i>b </i><b>212</b><i>f </i>and Chunk #<b>2</b><i>c </i><b>212</b><i>g</i>), the peer device #<b>2</b> <b>213</b><i>b </i>(storing Chunk #<b>2</b><i>b </i><b>212</b><i>f</i>), the peer device #<b>3</b> <b>213</b><i>c </i>(storing Chunk #<b>2</b><i>b </i><b>212</b><i>f, </i>Chunk #<b>2</b><i>c </i><b>212</b><i>g, </i>and Chunk #<b>2</b><i>n </i><b>212</b><i>h</i>), and the peer device #q <b>213</b><i>d </i>(storing Chunk #<b>2</b><i>n </i><b>212</b><i>h</i>); and the agent devices #r <b>215</b><i>c </i>and Agent #N <b>215</b><i>d, </i>both storing a list of chunks location of URL #N <b>211</b><i>d, </i>both stores a list including the peer #<b>2</b> <b>213</b><i>b </i>(storing Chunk #<b>3</b><i>a </i><b>212</b><i>i</i>) and the peer device #q <b>213</b><i>d </i>(storing Chunk #<b>3</b><i>b </i><b>212</b><i>j </i>and Chunk #<b>3</b><i>p </i><b>212</b><i>l</i>). An agent may store an empty list having no peers. Further, a peer may not be stored in any agent. The peer and agent devices may be identified by their respective IP address, or by any other mechanism allowing addressing over the Internet.</p><p id="p-0482" num="0484">In one example, accessing a data server may be obviated by accessing copies of the data server content stored as chunks in &#x2018;peer&#x2019; devices, each executing a &#x2018;peer&#x2019; flowchart. The peer devices for a content (such as a URL, web-page, web-site, or IP address) are identified by &#x2018;agent&#x2019; devices, each executing an &#x2018;agent&#x2019; flowchart.</p><p id="p-0483" num="0485">The method of retrieving chunks from peer devices is described below, based on the database <b>250</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>25</b></figref> describing the list stored in the acceleration server <b>202</b>, a flowcharts <b>230</b>, <b>230</b><i>a, </i>and <b>230</b><i>b </i>respectively shown in <figref idref="DRAWINGS">FIGS. <b>23</b>, <b>23</b></figref><i>a</i>, and <b>23</b><i>b </i>describing a client device (such as the client device #<b>1</b> <b>201</b><i>a</i>) operation, a flow chart <b>240</b> shown in <figref idref="DRAWINGS">FIG. <b>24</b></figref> describing an agent device (such as the agent device #<b>1</b> <b>103</b><i>a</i>) operation, a flow chart <b>240</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>24</b><i>a </i></figref>describing a peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>) operation, and a messaging and states timing chart <b>220</b> shown in <figref idref="DRAWINGS">FIG. <b>20</b></figref>. The chart <b>220</b> shows the messaging and related timing associated with the operation of the acceleration server <b>202</b> (corresponding to a dashed line <b>221</b><i>a</i>), a client device such as the client device #<b>1</b> <b>201</b><i>a </i>(corresponding to a dashed line <b>221</b><i>b</i>), an agent device such as the agent device #<b>1</b> <b>103</b><i>a </i>(corresponding to a dashed line <b>221</b><i>c</i>), and a peer device such as the peer device #<b>1</b> <b>102</b><i>a </i>(corresponding to a dashed line <b>221</b><i>d</i>). The flowchart <b>230</b><i>a </i>comprises a flowchart <b>239</b> relating to the chunks retrieving from peer devices. The database <b>250</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>25</b><i>a </i></figref>is illustrated as a table, wherein a first column <b>252</b><i>a </i>(designated as &#x2018;TYPE&#x2019;) relates to a device functionality, such as a agent, peer, or client, a second column <b>252</b><i>b </i>(designated as &#x2018;IP ADDRESS&#x2019;) relates to the device IP address, a third column <b>252</b><i>c </i>(designated as &#x2018;SIGN-IN DATE/TIME&#x2019;) relates to the date (in DD/MM format) and the time (in HH:MM&#x2014;Hour:Minute format) when the device signed in with the acceleration server, and a fourth column <b>252</b><i>d, </i>relating to the physical geographical location of the device. The top row <b>253</b> in the table refers to the field designations. The first <b>253</b><i>a, </i>second <b>253</b><i>b, </i>third <b>253</b><i>c, </i>fourth <b>253</b><i>d, </i>and fifth <b>253</b><i>e </i>rows in the table <b>250</b><i>a </i>respectively relate to first, second, third, fourth, and fifth devices that signed in with the acceleration server <b>202</b>. For example, the device shown in the first row <b>253</b><i>a </i>has signed in as an agent device as shown in the first column <b>252</b><i>a, </i>on March 24<sup>th </sup>at 8:35 as shown in the third column <b>252</b><i>c, </i>and can be addressed over the Internet using the IP address 73.0.82.8 as shown in the second column <b>252</b><i>b. </i>Similarly, the device shown in the third row <b>253</b><i>c </i>has signed in as a peer device as shown in the column <b>252</b><i>a, </i>on March 28<sup>th </sup>at 11:49 as shown in the third column <b>252</b><i>c, </i>and can be addressed over the Internet using the IP address 111.13.69.78 as shown in the second column <b>252</b><i>b. </i></p><p id="p-0484" num="0486">As shown in the messaging and timing chart <b>220</b>, the process starts upon initializing an agent application in an agent device, schematically shown as a &#x2018;START&#x2019; step <b>224</b><i>a </i>in the chart <b>220</b>, corresponding to the state <b>241</b><i>a </i>&#x2018;START&#x2019; in chart <b>240</b>. Such initialization may be executed upon the device powering up process, or upon a user request. Then the agent device #<b>1</b> <b>103</b><i>a </i>(as an example of an agent device) signs in with the acceleration server <b>202</b> in the &#x2018;Sign-in as Agent&#x2019; step <b>241</b><i>b, </i>which corresponds to a message &#x2018;Sign In&#x2019; <b>226</b><i>a </i>in the chart <b>220</b>. The message comprises the device functionality as &#x2018;agent&#x2019;, and the agent device <b>103</b><i>a </i>identification on the Internet <b>113</b>, such as its IP address (for example <b>73</b>.<b>0</b>.<b>82</b>.<b>8</b>). The acceleration server <b>202</b> is in an &#x2018;IDLE&#x2019; step <b>251</b><i>a, </i>until the message &#x2018;Sign In&#x2019; <b>226</b><i>a </i>is received at the acceleration server <b>202</b> at a &#x2018;Sign-In Request&#x2019; step <b>251</b><i>b, </i>which initiate an update of the database of the signed-in devices in a state &#x2018;Update Table&#x2019; <b>251</b><i>c </i>(corresponding to an &#x2018;Update List&#x2019; state <b>222</b><i>a </i>in the chart <b>220</b>), as shown, for example, in the first row <b>253</b><i>a </i>in table <b>250</b><i>a. </i>The acceleration server <b>202</b> further logs into the database the date and time of the signing in, such as March 24 as a date and 8:35 as the time, as shown in the first column <b>252</b><i>a </i>of the table <b>250</b><i>a. </i>The acceleration server <b>202</b> further adds rows to the table per each agent device, in the case of multiple agent devices, such as the addition of the agent device #<b>2</b> <b>103</b><i>b, </i>that its signing-in details are shown in the second row <b>253</b><i>b, </i>as addressed by IP address 68.78.78.3 and having signed in at March 25 at 10:59.</p><p id="p-0485" num="0487">Similarly, the peer device #<b>1</b> <b>102</b><i>a </i>starts and sign in with the acceleration server <b>202</b>. The process starts upon initializing a peer application in a peer device, schematically shown as a &#x2018;START&#x2019; step <b>225</b><i>a </i>in the chart <b>220</b>, corresponding to the state &#x2018;Start&#x2019; <b>242</b><i>a </i>in chart <b>240</b><i>a, </i>followed by the &#x2018;Sign In&#x2019; message (shown as dashed-line) <b>226</b><i>b </i>in the chart <b>220</b>, corresponding to the &#x2018;Sign-in As Peer&#x2019; step <b>242</b><i>b </i>in the flowchart <b>240</b><i>a. </i>The acceleration server <b>202</b> adds the agent device #<b>2</b> <b>103</b><i>b </i>and the signing-in details to the table <b>250</b><i>a </i>in the &#x2018;Update Table&#x2019; step <b>251</b>, as shown in the third row <b>253</b><i>c, </i>as addressed by IP address 111.13.69.78 and having signed in at March 28 on 11:49. Such initialization may be executed upon the device powering up process, or upon a user request. Alternatively or in addition, the peer device #<b>1</b> <b>102</b><i>a </i>may sign-in with the associated agent device, such as the agent device #<b>1</b> <b>103</b><i>a, </i>shown as a &#x2018;Sign In&#x2019; message (shown as dashed-line) <b>226</b><i>c </i>in the chart <b>220</b>. In the latter case, the agent device #<b>1</b> <b>103</b><i>a </i>updates its list of peer devices by adding the newly signed-in peer device #<b>1</b> <b>102</b><i>a, </i>as shown in an &#x2018;Update List&#x2019; state <b>224</b><i>b </i>in the chart <b>220</b>.</p><p id="p-0486" num="0488">Similarly, the client device #<b>1</b> <b>201</b><i>a </i>starts and sign in with the acceleration server <b>202</b>. The process starts upon initializing a client application in a client device, schematically shown as a &#x2018;START&#x2019; step <b>231</b><i>a </i>in the flowchart <b>230</b>, corresponding to a state <b>223</b><i>a </i>&#x2018;Start&#x2019; in the chart <b>220</b>. Such initialization may be executed upon the device powering up process, or upon a user request. Then the client device #<b>1</b> <b>201</b><i>a </i>sign in with the acceleration server <b>202</b> in the &#x2018;Sign-in as Client&#x2019; step <b>231</b><i>b, </i>which corresponds to the message &#x2018;Sign In&#x2019; <b>226</b><i>d </i>in the chart <b>220</b>. The message comprises the device functionality as &#x2018;client&#x2019;, and the client device #<b>1</b> <b>201</b><i>a </i>identification on the Internet <b>113</b>, such as its IP address (for example 125.90.25.92). The message &#x2018;Sign In&#x2019; is received as the acceleration server <b>202</b>, which update the database of the signed-in devices in state &#x2018;Update Table&#x2019; <b>251</b><i>c </i>(corresponding to a state &#x2018;Update List&#x2019; <b>222</b><i>b </i>in the chart <b>220</b>), as shown in the fourth row <b>253</b><i>d </i>in table <b>250</b><i>a. </i>The acceleration server <b>202</b> further logs to the database the date and time of the signing in, such as March 29 as a date and 14:23 as the sign-in time, as shown in the fourth column <b>253</b><i>d </i>of the table <b>250</b><i>a. </i>The acceleration server <b>202</b> further add to the table rows per each client device, in the case of multiple client devices. In one example, a device may be assigned to have multiple roles, such as functioning as both a client and an agent, as both an agent and a peer, as both a client and a peer, or as an agent, a client, and a peer. Multiple roles may be implemented at different times, or simultaneously using multiprocessing or multitasking. For example, a device may sign-in as both an agent and a peer, as shown in the fifth row <b>253</b><i>e </i>of the table <b>250</b><i>a, </i>addressed by its IP address 95.33.37.80 and signing in at March 16 on 21:53.</p><p id="p-0487" num="0489">While the pre-connection process was described above regarding the communication between a client device (such as the client device #<b>1</b> <b>31</b><i>a</i>) and a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>), described as the client device pre-connection flowchart <b>64</b> and the tunnel device pre-connection flowchart <b>72</b>, a pre-connection may be equally established between any two devices in the system <b>200</b>, such as between a client device (such as the client device #<b>1</b> <b>201</b><i>a</i>) and the acceleration server <b>202</b>, between two client devices, between a client device (such as the client device #<b>1</b> <b>201</b><i>a</i>) and an agent device (such as the agent device #<b>1</b> <b>103</b><i>a</i>), between a client device (such as the client device #<b>1</b> <b>201</b><i>a</i>) and a peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>), or between a client device and a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>). Similarly, a pre-connection may be established between an agent device (such as the agent device #<b>1</b> <b>103</b><i>a</i>) and the acceleration server <b>202</b>, between two agent devices, between an agent device (such as the agent device #<b>1</b> <b>103</b><i>a</i>) and a peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>), or between an agent device and a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>). Further, a pre-connection may be established between a peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>) and the acceleration server <b>202</b>, between two peer devices, or between a peer device and a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>).</p><p id="p-0488" num="0490">A content, such as an URL (or a web-page, or a web-site) which is typically stored in a data server, such as the data server #<b>1</b> <b>22</b><i>a, </i>may be requested by the client device, such as the client device <b>201</b><i>a, </i>as shown in a state &#x2018;Content Needed&#x2019; <b>223</b><i>b </i>in the chart <b>220</b>. The client device sends a &#x2018;Request List&#x2019; message <b>226</b><i>e </i>to the acceleration server <b>202</b>, corresponding to a &#x2018;Request Agents List&#x2019; step <b>231</b><i>c </i>in the flowchart <b>230</b>. This request includes the URL or any other identifier of the requested content. The request is received at the acceleration server <b>202</b> in the &#x2018;Agent List Request?&#x2019; step <b>251</b><i>d </i>in the flowchart <b>250</b>, which corresponds to the request by preparing a list of the agent devices which are associated with the required content, in the &#x2018;Prepare List&#x2019; state <b>222</b><i>c </i>in the chart <b>220</b>, corresponding to the &#x2018;Prepare List&#x2019; step <b>251</b><i>e </i>in the flowchart <b>250</b>. For example, the list may include identifiers of all agent devices that are related to the data server #<b>1</b> <b>22</b><i>a, </i>or the identifiers of all the agent devices, which may have information about the location of the chunks relating to the requested content. The list of agents (including the identifiers of the agent devices) is then sent, in a &#x2018;Send List&#x2019; step <b>251</b><i>f </i>in the flowchart <b>250</b> (corresponding to a message &#x2018;Send List&#x2019; <b>226</b> in the chart <b>220</b>), to the requesting client device #<b>1</b> <b>201</b><i>a, </i>that receives the list in a &#x2018;Receive Agents List&#x2019; step <b>231</b><i>d </i>in the flowchart <b>230</b>. In the case no appropriate agent devices were found, the client device #<b>1</b> may choose other schemes for fetching the required content, such as using tunnels as described above, or direct access to the data server #<b>1</b> <b>22</b><i>a </i>in a &#x2018;Content Fetch Direct&#x2019; step <b>233</b> shown as part of the flowchart <b>230</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>23</b><i>a</i></figref>. In the case the list received at the client device #<b>1</b> <b>201</b><i>a </i>include multiple agents, the client device #<b>1</b> <b>201</b><i>a </i>may select one, two, three, or any other number of agent devices from the list, in a &#x2018;Select Agents&#x2019; step <b>231</b><i>f </i>in the flowcharts <b>230</b> and <b>230</b><i>a, </i>corresponding to a &#x2018;Select Agent&#x2019; state <b>223</b><i>c </i>in the chart <b>220</b> illustrating selection of a single agent. Alternatively, all of the agent devices in the list may be selected.</p><p id="p-0489" num="0491">After receiving the agent devices list in the &#x2018;Receive Agents List&#x2019; step <b>231</b><i>d, </i>the client device #<b>1</b> <b>201</b><i>a </i>may store the list in its storage, such as a cache memory. In a &#x2018;Store Agents List&#x2019; step <b>231</b><i>g. </i>Further, a list of agent devices may be obtained from other elements in the system. Preferably, the list may include information about each agent device and transaction history relating to each agent device, such as the connection parameters (e.g., RTT and BW), the results quality, the resolved Domain Name System (DNS), and any other relevant information that may be used in the future. Alternatively or in addition to accessing the acceleration server <b>202</b> for obtaining a list of the available agent devices in the &#x2018;Request Agents List&#x2019; step <b>231</b><i>c, </i>the client device #<b>1</b> <b>201</b><i>a </i>may obtain a list of relevant agent devices locally from a storage or cache memory. For example, the client device #<b>1</b> <b>201</b><i>a </i>may use a list of agent devices that were previously stored as part of the &#x2018;Store Agents List&#x2019; step <b>231</b><i>g. </i></p><p id="p-0490" num="0492">Any number of agent devices may be selected. The number of agent devices that are selected in the &#x2018;Select Agents&#x2019; step <b>231</b><i>f </i>may be 1 (one). Alternatively, a small number of agent devices may be selected, such as two (2) or three (3). Further, 4, 5, 6, 7, 8, 9, or 10 agent devices may be selected. Further, more than <b>10</b> agent devices may be selected, such as 10, 20, 30, 40, or 50.</p><p id="p-0491" num="0493">A schematic messaging flow diagram <b>260</b> describing the client device #<b>1</b> <b>31</b><i>a </i>related steps of fetching the agent devices list from the acceleration server <b>202</b> is shown in <figref idref="DRAWINGS">FIG. <b>26</b></figref>. The &#x2018;Request Agent&#x2019; message <b>261</b><i>a </i>(corresponding to the &#x2018;Request Agents List&#x2019; step <b>231</b><i>c </i>in the flowchart <b>230</b>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the acceleration server <b>202</b>, which responds by sending the agents list using the &#x2018;Send Agent&#x2019; message <b>261</b><i>b </i>(corresponding to the &#x2018;Receive Agents List&#x2019; step <b>231</b><i>d </i>in the flowchart <b>230</b>).</p><p id="p-0492" num="0494">A flowchart <b>230</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>23</b><i>a </i></figref>shows an example where three agents are selected by the client device, designated as an agent device #<b>1</b> (such as the agent device #<b>1</b> <b>103</b><i>a</i>), an agent device #<b>2</b> (such as the agent device #<b>2</b> <b>103</b><i>b</i>), and an agent device #<b>3</b>, while the timing and messaging chart <b>220</b> illustrates the usage of a single agent device. In a &#x2018;Request List Agent #<b>1</b>&#x2019; step <b>234</b><i>a </i>in the flowchart <b>230</b><i>a, </i>the client device #<b>1</b> <b>201</b><i>a </i>send to the agent device #<b>1</b> <b>103</b><i>a </i>(using its identifier from the list received from the acceleration server <b>202</b>) a request for a list of peers associated the requested content identifier (such as a URL), such as these peer devices that are known or expected to store chunks of the requested content (or any part of it), corresponding to the &#x2018;Request List&#x2019; message <b>226</b><i>g </i>in the chart <b>220</b>. The agent device #<b>1</b> <b>103</b><i>a, </i>which may be idling in an &#x2018;IDLE&#x2019; step <b>241</b><i>c, </i>receives the request from the client device #<b>1</b> <b>201</b><i>a </i>in a &#x2018;Receive List Request&#x2019; step <b>241</b><i>d. </i>In response to the request, in a &#x2018;Prepare Peers List&#x2019; step <b>241</b><i>e </i>(corresponding to a state &#x2018;Prepare List&#x2019; <b>224</b><i>c </i>in the chart <b>220</b>), the agent device #<b>1</b> <b>103</b><i>a </i>prepares a list of the peer devices that it believes store chunks of the requested content, and in a &#x2018;Send List To Client&#x2019; step <b>241</b><i>f, </i>corresponding to a &#x2018;Send List&#x2019; message <b>226</b><i>h </i>in the chart <b>220</b>, sends the list of identifiers of the relevant peer devices back to the requesting client device #<b>1</b> <b>201</b><i>a. </i>For each of the selected agent devices, the client device #<b>1</b> <b>201</b><i>a </i>selects one, two, or all of the peers in the list, and then retrieves the relevant chunks from the each of the selected peer devices as shown in a &#x2018;Chunks Fetch&#x2019; flowchart <b>239</b>, shown in <figref idref="DRAWINGS">FIG. <b>23</b><i>b</i></figref>. The peers list is requested from agent device #<b>1</b> in a &#x2018;Request List Agent #<b>1</b>&#x2019; step <b>234</b><i>a, </i>and the chunks are fetched from the peer devices in the list in a &#x2018;Chunks Fetch Agent #<b>1</b>&#x2019; step <b>239</b><i>a. </i>Similarly, the peers list is requested from agent device #<b>2</b> in a &#x2018;Request List Agent #<b>2</b>&#x2019; step <b>234</b><i>b, </i>and the chunks are fetched from the peer devices in the list in a &#x2018;Chunks Fetch Agent #<b>2</b>&#x2019; step <b>239</b><i>b, </i>which follows the same &#x2018;Chunks Fetch&#x2019; flow in the flowchart <b>239</b>, and the peers list is requested from agent #<b>3</b> in a &#x2018;Request List Agent #<b>3</b>&#x2019; step <b>234</b><i>c, </i>and the chunks are fetched from the peer devices in the list in a &#x2018;Chunks Fetch Agent #<b>3</b>&#x2019; step <b>239</b><i>c, </i>which also follows the same &#x2018;Chunks Fetch&#x2019; flowchart <b>239</b>.</p><p id="p-0493" num="0495">A schematic visual messaging flow diagram <b>260</b><i>a </i>describing the client device #<b>1</b> <b>31</b><i>a </i>related steps of fetching the peer devices list from the agent device #<b>1</b> <b>103</b><i>a </i>is shown in <figref idref="DRAWINGS">FIG. <b>26</b><i>a</i></figref>. The &#x2018;Request Peer List&#x2019; message <b>262</b><i>a </i>(corresponding to the &#x2018;Request List Agent #<b>1</b>&#x2019; step <b>234</b><i>a </i>in the flowchart <b>230</b><i>b</i>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the agent device #<b>1</b> <b>103</b><i>a, </i>which responds by sending the peer list using a &#x2018;Send Peer List&#x2019; message <b>262</b><i>b </i>(corresponding to a &#x2018;Receive Peers List&#x2019; step <b>238</b> in the flowchart <b>230</b><i>b</i>).</p><p id="p-0494" num="0496">The flowchart <b>239</b> in <figref idref="DRAWINGS">FIG. <b>23</b><i>b </i></figref>is an example of a handling of the list received from the agent device #<b>1</b> <b>103</b><i>a. </i>The list of the peer devices identifiers is received at the client device in a &#x2018;Receive Peers List&#x2019; step <b>238</b>, followed by a &#x2018;Select Peers&#x2019; step <b>238</b><i>a </i>(corresponding to a &#x2018;Select Peers&#x2019; state <b>223</b><i>d </i>shown in the chart <b>220</b>), where the client device #<b>1</b> <b>201</b><i>a </i>selects which peer devices out of the list are to be used. The client device may select one, two, three, or any other number out of the listed peer identifiers, or may use all the peer devices in the list. In the example shown in the flowchart <b>239</b>, three peer devices are used, designated as peer #<b>1</b>, peer #<b>2</b>, and peer #<b>3</b>. For each selected peer device, such as the peer device #<b>1</b> <b>102</b><i>a, </i>the client device #<b>1</b> <b>201</b><i>a </i>in the &#x2018;Request Chunk Peer #<b>1</b>&#x2019; step <b>237</b><i>a </i>which corresponds to a &#x2018;Chunk Request&#x2019; message <b>226</b><i>i </i>in the chart <b>220</b>, send a request to the selected peer device asking for a chunk (or multiple chunks) that is stored (or expected to be stored) thereof. The peer device, such as the peer device #<b>1</b> <b>102</b><i>a </i>is in general idling in an &#x2018;IDLE&#x2019; step <b>242</b><i>c </i>in the flowchart <b>240</b><i>a. </i>Upon receiving the request from the client device #<b>1</b> <b>201</b><i>a </i>in a &#x2018;Receive Chunk Request&#x2019; step <b>242</b><i>d </i>in the flowchart <b>240</b><i>a, </i>the peer device #<b>1</b> <b>102</b><i>a </i>fetches the requested chunk (or chunks) as denoted in &#x2018;Fetch Chunk&#x2019; state <b>225</b><i>b </i>in the chart <b>220</b>, and send it to the requesting client device #<b>1</b> <b>201</b><i>a, </i>in a &#x2018;Send Chunk To Client&#x2019; step <b>242</b><i>e </i>in the flowchart <b>240</b><i>a, </i>which corresponds to a &#x2018;Send Chunk&#x2019; message <b>226</b><i>j </i>shown in the chart <b>220</b>. The sent chunk is received at the client device #<b>1</b> <b>201</b><i>a </i>in the &#x2018;Receive Chunk Peer #<b>1</b>&#x2019; step <b>236</b><i>a. </i>A schematic visual messaging flow diagram <b>260</b><i>b </i>describing the client device #<b>1</b> <b>31</b><i>a </i>related steps of fetching chunks from the peer device #<b>1</b> <b>102</b><i>a </i>is shown in <figref idref="DRAWINGS">FIG. <b>26</b><i>b</i></figref>. The &#x2018;Request Chunk&#x2019; message <b>263</b><i>a </i>(corresponding to the &#x2018;Request Chunk Peer #<b>1</b>&#x2019; step <b>237</b><i>a </i>in the flowchart <b>230</b><i>b</i>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the peer device #<b>1</b> <b>102</b><i>a, </i>which responds by sending the requested chunks in the &#x2018;Send Chunk&#x2019; message <b>263</b><i>b </i>(corresponding to the &#x2018;Receive Chunk Peer #<b>1</b>&#x2019; step <b>236</b><i>a </i>in the flowchart <b>230</b><i>b</i>).</p><p id="p-0495" num="0497">Similarly, the chunks from peer #<b>2</b> are requested (in parallel or sequentially to peer#<b>1</b> chunks fetching <b>239</b><i>a </i>operation) in a &#x2018;Request Chunk Peer #<b>2</b>&#x2019; step <b>237</b><i>b, </i>and are received in a &#x2018;Receive Chunk Peer #<b>2</b>&#x2019; step <b>236</b><i>b, </i>and the chunks from the peer device #<b>3</b> <b>102</b><i>c </i>are requested (in parallel or sequentially to peer device #<b>1</b> chunks fetching <b>239</b><i>a </i>operation) in a &#x2018;Request Chunk Peer #<b>3</b>&#x2019; step <b>237</b><i>b, </i>and are received in a &#x2018;Receive Chunk Peer #<b>3</b>&#x2019; step <b>236</b><i>c. </i>A schematic visual messaging flow diagram <b>260</b><i>c </i>describing the client device #<b>1</b> <b>31</b><i>a </i>related steps of fetching chunks from the peer device #<b>2</b> <b>102</b><i>b </i>is shown in <figref idref="DRAWINGS">FIG. <b>26</b><i>c</i></figref>. A &#x2018;Request Chunk&#x2019; message <b>263</b><i>c </i>(corresponding to the &#x2018;Request Chunk Peer #<b>2</b>&#x2019; step <b>237</b><i>b </i>in the flowchart <b>230</b><i>b</i>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the peer device #<b>2</b> <b>102</b><i>b, </i>which responds by sending the requested chunks in the &#x2018;Send Chunk&#x2019; message <b>263</b><i>d </i>(corresponding to the &#x2018;Receive Chunk Peer #<b>2</b>&#x2019; step <b>236</b><i>b </i>in the flowchart <b>230</b><i>b</i>). Similarly, a schematic visual messaging flow diagram <b>260</b><i>d </i>describing the client device #<b>1</b> <b>31</b><i>a </i>related steps of fetching chunks from the peer device #<b>3</b> <b>102</b><i>c </i>is shown in <figref idref="DRAWINGS">FIG. <b>26</b><i>d</i></figref>. The &#x2018;Request Chunk&#x2019; message <b>263</b><i>e </i>(corresponding to the &#x2018;Request Chunk Peer #<b>3</b>&#x2019; step <b>237</b><i>c </i>in the flowchart <b>230</b><i>b</i>) is first sent from the client device #<b>1</b> <b>31</b><i>a </i>to the peer device #<b>3</b> <b>102</b><i>c, </i>which responds by sending the requested chunks in the &#x2018;Send Chunk&#x2019; message <b>263</b><i>f </i>(corresponding to the &#x2018;Receive Chunk Peer #<b>3</b>&#x2019; step <b>236</b><i>c </i>in the flowchart <b>230</b><i>b</i>).</p><p id="p-0496" num="0498">Upon receiving part of, or all of, the requested chunks, the client device #<b>1</b> <b>201</b><i>a </i>assembles the chunks to render a reconstructed content (in part or in full), such as the requested URL, in an &#x2018;Assemble URL&#x2019; step <b>235</b>, corresponding to a &#x2018;Whole Content Received&#x2019; state <b>223</b><i>e </i>in the chart <b>220</b>. In the case part of the content is still missing, the client device #<b>1</b> <b>201</b><i>a </i>may directly approach the data server #<b>1</b> <b>22</b><i>a </i>in a &#x2018;Content Fetch Direct&#x2019; step <b>233</b>, or use other schemes, such as using tunnel devices as described above to fetch the remaining part of the content.</p><p id="p-0497" num="0499">Any number of peer devices may be selected. The number of peer devices that are selected in the &#x2018;Select Peers&#x2019; step <b>238</b><i>a </i>may be 1. Alternatively, a small number of peer devices may be selected, such as 2 or 3. Further, 4, 5, 6, 7, 8, 9, or 10 peer devices may be selected. Further, more than 10 peer devices may be selected, such as 10, 20, 30, 40, or 50.</p><p id="p-0498" num="0500">After a transaction involving fetching a content from all peer devices is completed, it is beneficial to store the fetched content for future use, as shown in a &#x2018;Store Content&#x2019; step <b>235</b><i>a </i>in the flowchart <b>230</b><i>a. </i>The fetched content may be stored in the client device in any volatile or non-volatile memory, or may be stored in a local cache as described in U.S. Pat. No. 8,135,912 to the Shribman et al., entitled: &#x201c;System and Method of Increasing Cache Size&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein. The content is stored with its related metadata or any other identifiers, so it can be easily detected and fetched when later required. For example, the stored content may be used when the same content is required at any later stage by the same client, or may be used when the client device also serves as a peer device, such as the peer device #<b>1</b> <b>102</b><i>a </i>as shown in system <b>260</b>. In the latter case, the fetched content (such as a URL content) may be arranged and stored as chunks, as described herein.</p><p id="p-0499" num="0501">The selection of the agent devices to be used in the &#x2018;Select Agents&#x2019; step <b>231</b><i>f </i>may use any of the selection rules or criteria described above regarding to selecting tunnel devices in the &#x2018;Select Tunnel&#x2019; step <b>62</b><i>c </i>or the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a </i>described above. Further, the selection of peer devices to be used in the &#x2018;Select Peers&#x2019; step <b>238</b><i>a </i>may use any of the selection rules or criteria described above regarding to selecting tunnel devices in the &#x2018;Select Tunnel&#x2019; step <b>62</b><i>c </i>or the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a </i>described above.</p><p id="p-0500" num="0502">The performance of the method and system described herein may be based on the latency involved in fetching a required content. The flowchart <b>230</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>23</b><i>a </i></figref>describes the steps involved in fetching content from a peer device, and a flowchart <b>239</b> in <figref idref="DRAWINGS">FIG. <b>23</b><i>b </i></figref>provides further detailed operation of a client device, such as the client device #<b>1</b> <b>201</b><i>a. </i>The &#x2018;Receive Chunk Peer #<b>1</b>&#x2019; step <b>236</b><i>a </i>(as an example for all equivalent steps such as the &#x2018;Receive Chunk #<b>2</b>&#x2019; step <b>236</b><i>b </i>and the &#x2018;Receive Chunk #<b>3</b>&#x2019; step <b>236</b><i>c</i>) may be partitioned into two or more steps, as shown in a flowchart <b>270</b> in <figref idref="DRAWINGS">FIG. <b>27</b></figref>, such as a &#x2018;Receive Start&#x2019; step <b>271</b><i>a, </i>relating to the starting of receiving data from a peer device, upon starting or completing the reception of the first byte of the data, for example, and a &#x2018;Receive End&#x2019; step <b>271</b><i>b, </i>relating to the ending of receiving data from a tunnel, for example upon starting or completing the reception of the end byte of the data.</p><p id="p-0501" num="0503">As part of the &#x2018;Request Chunk Peer #<b>1</b>&#x2019; step <b>237</b><i>a, </i>a timer #<b>1</b> is started in a &#x2018;Timer #<b>1</b> Start&#x2019; step <b>272</b><i>a, </i>and the timer #<b>1</b> is stopped in a &#x2018;Timer #<b>1</b> Stop&#x2019; step <b>272</b><i>b </i>at the beginning of the receiving the data from the peer device in a &#x2018;Receive Start&#x2019; step <b>271</b><i>a. </i>Hence, timer #<b>1</b> is used to measure the Round Trip Time (RTT), relating to the time interval measured from sending the request to a peer device until the requested data is starting to be received. Similarly, as part of a &#x2018;Receive Start&#x2019; step <b>273</b><i>a </i>a timer #<b>2</b> is started, and the timer #<b>2</b> is stopped in a &#x2018;Timer #<b>2</b> Stop&#x2019; step <b>273</b><i>b </i>at the end of the receiving the data from the peer device in a &#x2018;Receive End&#x2019; step <b>271</b><i>b. </i>Hence, timer #<b>2</b> is used to measure the time interval required to receive the content itself from the peer device. For example, in case the time interval is 50 milliseconds (ms), this is the time interval measured from starting to end of the data reception from the peer device. In the case the content size is X bits, the BW can be calculated as the X bits divided by the timer #<b>2</b> measured time interval. For example, in the case the received content from the peer device is about the size of 50,000 bits (50 Kbits) received during 100 milliseconds (ms), the effective (or average) BW is BW=50,000/0.1=500,000 bits/second=500 Kb/s=62.5 Kbytes/s=62.5 KB/s. The total latency affecting the performance is the combination of both the time interval measured by timer #<b>1</b> and the time interval measured by timer #<b>2</b>. Using the above examples where the timer #<b>1</b> measured an RTT of 50 ms and the timer #<b>2</b> measured 100 ms, the total latency, measured from sending the request to the peer device in the &#x2018;Request Chunk Peer #<b>1</b>&#x2019; step <b>237</b><i>a </i>to the end of the content reception in the &#x2018;Receive End&#x2019; step <b>271</b><i>b, </i>is 150 ms (50+100=150).</p><p id="p-0502" num="0504">After a transaction involving fetching a content from a peer is completed, it is beneficial to store the transaction related information for future use, such as for future analysis. An example of a table relating to transactions log, that may be part of a database, is shown as a table <b>280</b> in <figref idref="DRAWINGS">FIG. <b>28</b></figref>. The table is updated in the &#x2018;Update Transactions Log&#x2019; step <b>274</b> as part of the flowchart <b>270</b> shown in <figref idref="DRAWINGS">FIG. <b>27</b></figref>. A top row <b>282</b> provides the titles of the various columns, where each of the rows provides information regarding a specific transaction, where a first transaction information is shown in a first row <b>282</b><i>a, </i>the second transaction information is shown in a second row <b>282</b><i>b, </i>the third transaction information is shown in a third row <b>282</b><i>c, </i>and so forth. A first column <b>281</b><i>a </i>shows the date and time (in DD/MM HH/MM format) when the transaction occurred, such as the start or end of the transaction. For example, the first transaction related information is in the first row <b>282</b><i>a </i>shows that the transaction was completed (or started) at March 13, at 9:23. Similarly, the second transaction information is in the second row <b>282</b><i>b </i>shows that the transaction was completed (or started) at March 13<sup>th</sup>, at 9:46, and the third transaction information is in the third row <b>282</b><i>b </i>shows that the transaction was completed (or started) at April 16<sup>th</sup>, on 11:22. A second column <b>281</b><i>b </i>includes an identifier such as the IP address of the peer device that was used in the transaction to fetch the content from the data server, which identifier (such as its IP address) is included in a third column <b>281</b><i>c. </i>In the example of the first transaction shown in first row <b>282</b><i>a, </i>the IP address of the peer device used is 229.155.81.168, and it was used to fetch content stored in a data server having an IP address of 128.164.35.35.142. Similarly, in the example of the second transaction shown in second row <b>282</b><i>b, </i>the IP address of the peer device used is 248.107.109.10, and it was used to fetch content stored in a data server having an IP address of 49.154.2.5, and in the example of the third transaction shown in third row <b>282</b><i>c, </i>the IP address of the peer device used is 158.217.19.195, and it was used to fetch content stored in a data server having an IP address of 72.251.238.51. A fourth column <b>281</b><i>d </i>describes the identifier of the content that was fetched during this transaction, such as IP address, URL, web-site or web-page, where the first transaction content (in the first row <b>282</b><i>a</i>) relates to the URL www.111.com/22.mpg, the second transaction content (in the second row <b>282</b><i>b</i>) relates to the URL www.xxx.com/hy.avi, the third transaction content (in the third row <b>282</b><i>c</i>) relates to the URL www.yyy.com/t6.php, and so forth.</p><p id="p-0503" num="0505">A fifth column <b>281</b><i>e </i>logs the BW calculated in a respective transaction, based on timer #<b>2</b> time interval measurement as described above. In the first transaction (in the first row <b>282</b><i>a</i>) the calculated BW is logged as 1000 Kb/s (=1 Mb/s=125 KB/s), in the second transaction (in the second row <b>282</b><i>b</i>) the calculated BW is logged as 350 Kb/s (=0.35 Mb/s), and in the third transaction (in the third row <b>282</b><i>c</i>) the calculated BW is logged as 2500 Kb/s (=2.5 Mb/s). A sixth column <b>281</b><i>f </i>logs the RTT measured in the transaction, based on timer #<b>1</b> time interval measurement as described above. In the first transaction (in the first row <b>282</b><i>a</i>) the measured RTT is logged as 30 ms (=0.03 seconds=0.03 s), in the second transaction (in the second row <b>282</b><i>b</i>) the measured RTT is logged as 70 ms, and in the third transaction (in the third row <b>282</b><i>c</i>) the measured RTT is logged as 540 ms (=0.54 second).</p><p id="p-0504" num="0506">The transaction log, such as table <b>150</b>, may be prepared by a client device, such as client device #<b>1</b> <b>201</b><i>a, </i>and stored in the client device for future use. Alternatively or in addition, the transaction log may be sent, after each transaction or after multiple transactions, such as per a time period (e.g, hourly, daily, weekly, monthly), to other entities in the system, to be stored in the entities for future use by them or by other entities in the network. In one example, the transaction log is sent to the acceleration server <b>202</b>. Alternatively or in addition, the transactions log may be sent to the relevant agent devices, such as the agent device #<b>1</b> <b>103</b><i>a </i>or the agent device #<b>2</b> <b>103</b><i>b, </i>or any other agent device associated with the relevant peer device or devices involved in the transaction.</p><p id="p-0505" num="0507">Similar to table <b>280</b> shown in <figref idref="DRAWINGS">FIG. <b>28</b></figref>, a table <b>280</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>28</b><i>a </i></figref>shows a table relating to four peer devices used for fetching different content from the same data server (such as the data server #<b>1</b> <b>22</b><i>a</i>), thus the same server IP address is shown in the third column <b>283</b><i>c. </i>The IP addresses of the peer devices are shown in the second column <b>283</b><i>b, </i>the URL fetched is shown in the fourth column <b>283</b><i>d, </i>the date and time of the transaction are logged in the first column <b>283</b><i>a, </i>the BW is shown in the fifth column <b>283</b><i>e, </i>and the measured RTT is shown in the sixth column <b>283</b><i>f. </i>The first transaction (logged in a first row <b>284</b><i>a</i>) is using a first peer device having IP address of 139.230.154.213, the second transaction (logged in a second row <b>284</b><i>b</i>) is using a second peer device having IP address of 132.171.60.197, the third transaction (logged in a third row <b>282</b><i>c</i>) is using a third peer device having IP address of 248.46.80.36, and the fourth transaction (logged in a fourth row <b>154</b><i>d</i>) is using a fourth peer device having IP address of 31.16.208.171.</p><p id="p-0506" num="0508">The peer devices to be used when content is to be fetched from a data server (such as the data server <b>22</b><i>a</i>) may be selected by a client device (such as the client device #<b>1</b> <b>201</b><i>a</i>) in the &#x2018;Select Peers&#x2019; step <b>238</b><i>a </i>in the flowchart <b>230</b><i>b </i>or by the agent devices in the &#x2018;Prepare Peers List&#x2019; step <b>241</b><i>e </i>in the flowchart <b>240</b>. Alternatively or in addition, the peer devices may be selected by the acceleration server <b>202</b>. Similarly, the agent devices to be used may be selected by a client device (such as the client device #<b>1</b> <b>201</b><i>a</i>) in the &#x2018;Select Agents&#x2019; step <b>231</b><i>f </i>in the flowchart <b>230</b>, or may be selected by the acceleration server <b>202</b> in the &#x2018;Prepare List&#x2019; <b>251</b><i>e </i>in the flowchart <b>250</b>. The selection may be based on a past performance of the peer devices, such as on any information relating to former transactions involving these peers. In one example, the transactions log may be used to evaluate and select which peer devices to use in a specific transaction to be executed, or in multiple transactions.</p><p id="p-0507" num="0509">In the example of the transaction log table <b>280</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>28</b><i>a </i></figref>and relating to a client device, the client device may need to fetch content from the same data server shown in the table <b>280</b><i>a </i>(having an IP address of 49.154.2.5), and thus may use the table content as an indication of the performance of the various peer devices. In one example, the criterion to select a single peer (or agent) device to be used for fetching content from the data server may be based on having higher BW, assuming that the higher BW has not changed and thus will result in faster content fetching, and hence the peer device used in the third logged transaction (having an IP address of 248.46.80.36) will be selected for this transaction, having the highest recorded BW of 2500 Kb/s. In the case two peer devices are to be selected, the second peer device to be selected is the peer device used in the fourth logged transaction (having an IP address of 31.16.208.171) will be selected for this transaction, being associated with the second highest BW in the table. Similarly, the peer device associated with the first logged transaction will be the next to be selected.</p><p id="p-0508" num="0510">Alternatively or in addition, the criterion to select a single peer (or an agent) device to be used for fetching content from the data server may be based on having lower RTT, assuming that the lower RTT has not changed and thus will result in faster content fetching. Hence the peer device used in the first logged transaction (having an IP address of 139.230.154.213) will be selected for this transaction, having the lowest recorded RTT of 30 ms. In the case two peer devices are to be selected, the second peer device to be selected is the peer device used in the second logged transaction (having an IP address of 132.171.60.197) will be selected for this transaction, being associated with the second lowest RTT in the table (70 ms). Similarly, the peer device associated with the fourth logged transaction will be the next to be selected.</p><p id="p-0509" num="0511">Alternatively or in addition, both the RTT and the BW are used as criteria for selecting peer (or agent) devices. In one example, the expected total latency is calculated, based on both the former BW and the former RTT, and the peer device offering the lowest estimated total latency will be selected. In one example, assuming the content to be fetched is estimated (or known to be) having the size of 100 Kb (100 kilobits). The peer device used in the first logged transaction (in the first row <b>284</b><i>a</i>) is associated with past performance (with the same data server) of BW=1000 Kb/s and RTT=30 ms. In such a case, the total latency is calculated and estimated as 30+100/1000=130 ms. The peer device used in the second logged transaction (in the second row <b>284</b><i>b</i>) is associated with past performance (with the same data server) of BW=350 Kb/s and RTT=70 ms, and thus the total latency is calculated and estimated as 70+100/350=355.7 ms. Similarly, the estimated total latency of using the peer device used in the third logged transaction (in the third row <b>284</b><i>c</i>) is 580 ms, and the estimated total latency of using the peer device used in the fourth logged transaction (in the fourth row <b>284</b><i>d</i>) is 241.4 ms. Having the lowest estimated total latency, the peer device used in the first logged transaction (in the first row <b>284</b><i>a</i>) will be selected first as having the lowest expected total latency, the peer device used in the fourth logged transaction (in the fourth row <b>284</b><i>d</i>) will be selected second, the peer device used in the second logged transaction (in the second row <b>284</b><i>b</i>) will be selected third, and the peer device used in the third logged transaction (in the third row <b>284</b><i>c</i>) will be selected last.</p><p id="p-0510" num="0512">However, assuming the content to be fetched is estimated (or known to be) having the size of 1000 Kb (1000 kilobits=1 Mb). The peer device used in the first logged transaction (the first row <b>284</b><i>a</i>) is associated with past performance (with the same data server) of BW=1000 Kb/s and RTT=30 ms. In such a case, the total latency is calculated and estimated as 30+1000/1000=1030 ms (1.03 s). The peer device used in the second logged transaction (in the second row <b>284</b><i>b</i>) is associated with past performance (with the same data server) of BW=350 Kb/s and RTT=70 ms, and thus the total latency is calculated and estimated as 70+1000/350=2927.1 ms. Similarly, the estimated total latency of using the peer device used in the third logged transaction (in the third row <b>284</b><i>c</i>) is 940 ms, and the estimated total latency of using the peer device used in the fourth logged transaction (in the fourth row <b>284</b><i>d</i>) is 884.2 ms. Having the lowest estimated total latency, the peer device used in the fourth logged transaction (in the fourth row <b>284</b><i>d</i>) will be selected first as having the lowest expected total latency, the peer device used in the third logged transaction (in the third row <b>284</b><i>c</i>) will be selected second, the peer device used in the first logged transaction (in the first row <b>284</b><i>a</i>) will be selected third, and the peer device used in the second logged transaction (in the second row <b>284</b><i>b</i>) will be selected last.</p><p id="p-0511" num="0513">In the general case, there may be N peer devices that may be used, designated i=1, 2, . . . N, and that the total content size is X. Assuming non-overlapping partition, each of the peer devices (i) will be assigned part of the total content Xi, where X=&#x3a3;Xi. The latency (Ti) in each path (i) relating to a peer device (i) is calculated as Ti=RTTi+Xi/BWi, where RTTi is the RTT associated with peer device (i) and BWi is the BW associated with the peer device (i). Since typically the latency relating to complete the fetching of the whole of the content (T) is determined by the longest latency of the individual latency Ti, then T=max(Ti), hence it is beneficial to minimize the maximum Ti, designated as min(max(Ti))=min(max(RTTi+Xi/BWi)). Such a minimum is obtained when all Ti's are equal to each other, so that T=Ti=T<sub>1</sub>=T<sub>2</sub>=T<sub>3</sub>= . . . =T<sub>N</sub>, which is resulted when the partition Xi is: Xi=BWi*[(X+&#x3a3;RTTi*BWi)/&#x3a3;BWi)&#x2212;RTTi], and the latency in such a case is T=(X+&#x3a3;(RTTi*BWi))/(&#x3a3;BWi). In the example of using two peer devices (N=2), then X<sub>1</sub>=BW<sub>1</sub>*[X+BW<sub>2</sub>*(RTT<sub>2</sub>&#x2212;RTT<sub>1</sub>)]/(BW<sub>1</sub>+BW<sub>2</sub>) and X<sub>2</sub>=BW2*[X+BW<sub>1</sub>*(RTT<sub>1</sub>&#x2212;RTT<sub>2</sub>)]/(BW<sub>1</sub>+BW<sub>2</sub>), while the resulting latency is T=T<sub>1</sub>=T<sub>2</sub>=(RTT<sub>1</sub>*BW<sub>1</sub>+RTT<sub>2</sub>*BW<sub>2</sub>+X)/(BW<sub>1</sub>+BW<sub>2</sub>).</p><p id="p-0512" num="0514">Referring now to a system <b>290</b> shown in <figref idref="DRAWINGS">FIG. <b>29</b></figref>, schematically showing a general peer device #i <b>102</b><i>i, </i>which stores in a database <b>291</b><i>i </i>the entire content required (or a part of it), or at least part X, (which may be chunks-based) of the content that is required by the client device #<b>1</b> <b>201</b><i>a. </i>The peer device #i <b>102</b><i>i </i>communicates with the client device #<b>1</b> <b>201</b><i>a </i>over a data path <b>297</b><i>i, </i>characterized by an RTT<sub>1 </sub>and BW<sub>i</sub>, so that the latency can be estimated to be T<sub>i</sub>=RTT<sub>i</sub>+X<sub>i</sub>/BW<sub>i</sub>. Similarly, a peer device #<b>1</b> <b>102</b><i>a, </i>which stores in a database <b>291</b><i>a </i>the entire content required, or at least part X<sub>1 </sub>(which may be chunks-based) of the content that is required by the client device #<b>1</b> <b>201</b><i>a. </i>The peer device #<b>1</b> <b>102</b><i>a </i>communicates with the client device #<b>1</b> <b>201</b><i>a </i>over a data path <b>297</b><i>a, </i>characterized by an RTT<sub>1 </sub>and BW<sub>1</sub>, so that the latency can be estimated to be T<sub>1</sub>=RTT<sub>1</sub>+X<sub>i</sub>/BW<sub>1</sub>. Assuming that there are N peer devices, a peer device #N <b>102</b><sub>N </sub>is shown, which stores in a database <b>291</b><sub>N </sub>the entire content required, or at least part X<sub>N </sub>(which may be chunks-based) of the content that is required by the client device #<b>1</b> <b>201</b><i>a. </i>The peer device #<sub>N </sub><b>102</b><sub>N </sub>communicates with the client device #<b>1</b> <b>201</b><i>a </i>over a data path <b>297</b><sub>N</sub>, characterized by an RTT<sub>N </sub>and BW<sub>N</sub>, so that the latency over this data path can be estimated to be T<sub>N</sub>=RTT<sub>N</sub>+X<sub>N</sub>/BW<sub>N</sub>.</p><p id="p-0513" num="0515">An analysis of the system <b>290</b> is shown as a view <b>290</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>29</b><i>a</i></figref>. The total latency expression is based on the arrival of the last piece (or last chunk) of a requested content to the client device #<b>1</b> <b>201</b><i>a, </i>and hence T=Max (T<sub>i</sub>) as shown in an expression (1) <b>292</b><i>a, </i>and in order to obtain fastest load time, the target is to minimize the total latency T, based on a partition X<sub>i </sub>of the total content X, as shown in an expression (2) <b>292</b><i>b. </i>Such minimum is obtained where the latency is the same (T) in all the data paths, as shown in an expression (3) <b>292</b><i>c. </i>An expression (4) <b>292</b><i>d </i>provides the optimal partition X<sub>i </sub>for minimum latency, and an expression (5) <b>292</b><i>e </i>provides the obtained latency. It is apparent that in the case wherein a fixed-fixed chunks are used in the system, the calculation of Xi may result in a non-integer number of chunks. In such a case, a chunk may be further partitioned into smaller chunks. Alternatively or in addition, the resulting sizes may be round to the nearest integer value, allowing for keeping the scheme of only using fixed-size chunks.</p><p id="p-0514" num="0516">The allocation of the parts of the requested content to the available peer devices to be fetched therefrom, may be part of the &#x2018;Select Peers&#x2019; step <b>238</b><i>a. </i>While exampled above regarding the allocation of content and the partitioning in a peer/agent based system, the method and the analysis are equally applicable for any system or arrangement where multiple data paths are used, each relating to the allocated parts of the content. For example, such a method may be used when the content is fetched using agents, such as in the &#x2018;Content Partition&#x2019; step <b>101</b><i>b </i>in the flowchart <b>100</b> (or the flowchart <b>100</b><i>a</i>) above, where the partition may be based on the expression (4) <b>292</b><i>d </i>shown in the view <b>290</b><i>a. </i></p><p id="p-0515" num="0517"><figref idref="DRAWINGS">FIG. <b>29</b></figref> further shows an example of a content <b>293</b>, composed of 6 (six) non-overlapping fixed-sized chunks designated as &#x2018;A&#x2019; <b>293</b><i>a, </i>&#x2018;B&#x2019; <b>293</b><i>b, </i>&#x2018;C&#x2019; <b>293</b><i>c, </i>&#x2018;D&#x2019; <b>293</b><i>d, </i>&#x2018;E&#x2019; <b>293</b><i>e, </i>and &#x2018;F&#x2019; <b>293</b><i>f. </i>In one example, assuming three (3) peer devices are used (N=3 in the system <b>290</b>), the allocation determined is shown in view <b>295</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>29</b><i>b</i></figref>, where three chunks including the chunks &#x2018;A&#x2019; <b>293</b><i>a, </i>&#x2018;B&#x2019; <b>293</b><i>b, </i>and &#x2018;C&#x2019; <b>293</b><i>c, </i>are allocated to be fetched from a first peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>), a single chunk &#x2018;D&#x2019; <b>293</b><i>d </i>is allocated to be fetched from a second peer device (such as the peer device #i <b>102</b><i>i</i>), and the two chunks &#x2018;E&#x2019; <b>293</b><i>e </i>and &#x2018;F&#x2019; <b>293</b><i>f, </i>are allocated to be fetched from a third peer device (such as the peer device #N <b>102</b>N). At time t=0, the content fetching from the three peer devices is started. A client device (such as the client device #<b>1</b> <b>201</b><i>a</i>) prepares a memory <b>294</b> for storing the requested content <b>293</b> upon obtaining it.</p><p id="p-0516" num="0518">The allocations of the content chunks into the available peer devices may be based on estimation RTT, BW, as well as other parameters relating to each of the peer devices, as well as on the communication characteristics associated with each peer device, and known to the client device. Such an estimation may be found to be inaccurate or not updated. The client device may measure and update the BW, RTT, and other relevant information as part of the actual content fetching. For example, an actual RTT and BW may be measured per each of the peer devices as described in the flowchart <b>140</b> in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, added to other updated information gathered throughout the content fetching process. Further, the allocation of chunks to peer devices may be re-evaluated according to the updated parameters, and changed during the content fetching process. The re-evaluating of the allocation may be executed continuously and simultaneously with the content fetching, or preferably at specified time intervals.</p><p id="p-0517" num="0519">In one example shown as view <b>295</b><i>b </i>in <figref idref="DRAWINGS">FIG. <b>29</b><i>b</i></figref>, at a time t=t<b>1</b> after the content fetching activity has initiated, the client device checks the status of the fetching, to find that the chunks &#x2018;A&#x2019; <b>193</b><i>a, </i>&#x2018;B&#x2019; <b>293</b><i>b, </i>and &#x2018;D&#x2019; <b>293</b><i>d </i>have been completely fetched and loaded into the client device memory <b>294</b>. Further, the chunk &#x2018;C&#x2019; <b>293</b><i>c </i>is about to start to be fetched from the first peer device, and a chunk &#x2018;E&#x2019; <b>293</b><i>e </i>is in the process of being fetched. It is noted that the chunk &#x2018;F&#x2019; <b>293</b><i>f </i>has not yet been fetched, and is expected to be the last chunk to be fully fetched, and hence determines and affects the total time required for the fetching of the entire requested content <b>293</b>. In one example, shown as a view <b>295</b><i>d </i>in <figref idref="DRAWINGS">FIG. <b>29</b><i>c</i></figref>, the client device may decide, in order to reduce the total fetching time, to recalculate the allocation, and for example to reallocate the fetching of the chunk &#x2018;F&#x2019; <b>293</b><i>f </i>(being the &#x2018;bottleneck&#x2019; chunk) to another peer device, such as the second peer device. Alternatively or in addition, in order to improve efficiency and reduce the content fetching latency, the last to receive the chunk &#x2018;F&#x2019; <b>293</b><i>f </i>is split into two equal-sized chunks &#x2018;F<b>1</b>&#x2019; <b>293</b><i>f</i><b>1</b> and &#x2018;F<b>2</b>&#x2019; <b>293</b><i>f</i><b>2</b>. It is apparent that splitting into non-equally sized chunks, or splitting into more than two chunks, may be equally applicable. Each of the newly formed chunks may now be allocated to a peer device, using any allocation scheme or criteria. In one example shown in view <b>295</b><i>e </i>in <figref idref="DRAWINGS">FIG. <b>29</b><i>c</i></figref>, one of the new chunks &#x2018;F<b>1</b>&#x2019; <b>293</b><i>f</i><b>1</b> is allocated to the third peer device, while the other chunk &#x2018;F<b>2</b>&#x2019; <b>293</b><i>f</i><b>2</b> is allocated now to the second peer device.</p><p id="p-0518" num="0520">The flowchart <b>296</b> shown in <figref idref="DRAWINGS">FIG. <b>29</b><i>d</i></figref>, corresponds to the flowchart <b>239</b> shown in <figref idref="DRAWINGS">FIG. <b>23</b><i>b</i></figref>, describes an example of a method involving real-time re-allocation of chunks to peer devices. The initial allocation of chunks to peer devices, based on criteria and scheme known before the content fetch initiation, is part of the &#x2018;Select Peers&#x2019; step <b>238</b><i>a. </i>The fetching of the peer device #<b>1</b> allocated chunks starts in a &#x2018;Start Receive Chunk Peer #<b>1</b>&#x2019; step <b>298</b><i>a, </i>being part of the &#x2018;Receive Chunk Peer #<b>1</b>&#x2019; step <b>236</b><i>a </i>shown in the flowchart <b>239</b> in <figref idref="DRAWINGS">FIG. <b>23</b><i>b</i></figref>. Similarly, the fetching of the peer device #<b>2</b> allocated chunks starts in a Start Receive Chunk Peer #<b>2</b>&#x2032; step <b>298</b><i>b, </i>being part of the &#x2018;Receive Chunk Peer #<b>2</b>&#x2019; step <b>236</b><i>b </i>in the flowchart <b>239</b> in <figref idref="DRAWINGS">FIG. <b>23</b><i>b</i></figref>, and the fetching of the peer device #<b>3</b> allocated chunks starts in a &#x2018;Start Receive Chunk Peer #<b>3</b>&#x2019; step <b>298</b><i>c, </i>being part of the &#x2018;Receive Chunk Peer #<b>3</b>&#x2019; step <b>236</b><i>c </i>in the flowchart <b>239</b> in <figref idref="DRAWINGS">FIG. <b>23</b><i>b</i></figref>. In parallel to the process of fetching the various chunks from the allocated peer devices, the client device, continuously or periodically, measures the various communication related characteristics for each communication with a peer device, such as BW and RTT, as part of a &#x2018;Measure BW, RTT&#x2019; step <b>299</b><i>a. </i>The new measured parameters are used for recalculation of the allocation, for example according to the expression (4) <b>292</b><i>d </i>in <figref idref="DRAWINGS">FIG. <b>29</b><i>a</i></figref>. In a &#x2018;Re-Allocate?&#x2019; step <b>299</b><i>b, </i>the need for changing the former allocation is determined. In some cases, there may be no need to change the initial or former allocation. If there a need for re-allocation, the &#x2018;Select Peers&#x2019; step <b>238</b><i>a </i>is resumed, and new allocation is affected.</p><p id="p-0519" num="0521">In one example shown as arrangement <b>290</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>29</b><i>e</i></figref>, each of the peer devices stored all of the chunks composing the entire content <b>293</b>. The peer device #<b>1</b> <b>102</b><i>a </i>is shown to store the entire content in its memory as content <b>291</b><i>a. </i>Similarly, the peer device #i <b>102</b><i>i </i>stores the entire content in its memory as content <b>291</b><i>i, </i>and the peer device #N <b>102</b>N stores the entire content in its memory as content <b>291</b>N. In such a case, the client device <b>201</b><i>a </i>may choose any peer device for any chunk of the content <b>293</b>, or may even choose a single peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>) to fetch the entire content therefrom. Alternatively or in addition, each of the peer devices may store only part of the chunks composing the content <b>293</b>, as shown in an arrangement <b>290</b><i>b </i>in <figref idref="DRAWINGS">FIG. <b>29</b><i>f </i></figref>The peer device #<b>1</b> <b>102</b><i>a </i>is shown to store only chunks &#x2018;A&#x2019; <b>293</b><i>a, </i>&#x2018;B&#x2019; <b>293</b><i>b, </i>&#x2018;C&#x2019; <b>293</b><i>c, </i>and &#x2018;E&#x2019; <b>293</b><i>e, </i>in its memory as content <b>291</b><i>a, </i>while the peer device #i <b>102</b><i>i </i>stores only chunks &#x2018;A&#x2019; <b>293</b><i>a, </i>&#x2018;C&#x2019; <b>293</b><i>c, </i>&#x2018;D&#x2019; <b>293</b><i>d, </i>and &#x2018;F&#x2019; <b>293</b><i>f, </i>in its memory as content <b>291</b><i>i, </i>and the peer device #N <b>102</b>N stores only chunks &#x2018;A&#x2019; <b>293</b><i>a, </i>&#x2018;D&#x2019; <b>293</b><i>d, </i>&#x2018;E&#x2019; <b>293</b><i>e, </i>and &#x2018;F&#x2019; <b>293</b><i>f, </i>in its memory as content <b>291</b>N. It is noted that such storing of portions of the content <b>293</b> may not affect the system operation described in views <b>295</b><i>a, </i><b>295</b><i>b, </i><b>295</b><i>c, </i>and <b>295</b><i>d, </i>since the chunks required from each of the peer devices are indeed stored in these peer devices. In such a configuration, the agent devices and the client device should consider the actual content portion in each of the peer device, in addition to the size of the content portion that is optimal to be fetched from them.</p><p id="p-0520" num="0522">Each of the devices denoted herein as servers, such as the acceleration server <b>32</b>, the data server #<b>1</b> <b>22</b><i>a, </i>the data server #<b>2</b> <b>22</b><i>b, </i>and the acceleration server <b>202</b>, may typically function as a server in the meaning of client/server architecture, providing services, functionalities, and resources, to other devices (clients), commonly in response to the clients' request. Each of the server devices may further employ, store, integrate, or operate a server-oriented operating system, such as the Microsoft Windows Server&#xae; (2003 R2, 2008, 2008 R2, 2012, or 2012 R2 variant), Linux&#x2122; (or GNU/Linux) variants (such as Debian based: Debian GNU/Linux, Debian GNU/kFreeBSD, or Debian GNU/Hurd, Fedora&#x2122;, Gentoo&#x2122;, Linspire&#x2122;, Mandriva, Red Hat&#xae; Linux available from Red Hat, Inc. headquartered in Raleigh, N.C., U.S.A., Slackware&#xae;, SuSE, or Ubuntu&#xae;), or UNIX&#xae;, including commercial UNIX&#xae; variants such as Solaris&#x2122; (available from Oracle Corporation headquartered in Redwood City, Calif., U.S.A.), AIX&#xae; (available from IBM Corporation headquartered in Armonk, N.Y., U.S.A.), or Mac&#x2122; OS X (available from Apple Inc. headquartered in Cupertino, Calif., U.S.A.), or free variants such as FreeB SD&#xae;, OpenBSD, and NetB SD&#xae;. Alternatively or in addition, each of the devices denoted herein as servers, may equally function as a client in the meaning of client/server architecture.</p><p id="p-0521" num="0523">Devices that are not denoted herein as servers, such as client devices (such as the client device #<b>1</b> <b>31</b><i>a, </i>the client device #<b>2</b> <b>31</b><i>b, </i>or the client device #<b>1</b> <b>201</b><i>a</i>), tunnel devices (such as the tunnel device #<b>1</b> <b>33</b><i>a </i>or the tunnel device #<b>2</b> <b>33</b><i>b</i>), agent devices (such as the agent device #<b>1</b> <b>103</b><i>a </i>or the agent device #<b>2</b> <b>103</b><i>b</i>), or peer devices (such as the peer device #<b>1</b> <b>102</b><i>a </i>or the peer device #<b>2</b> <b>102</b><i>b</i>), may typically function as a client in the meaning of client/server architecture, commonly initiating requests for receiving services, functionalities, and resources, from other devices (servers or clients). Each of the these devices may further employ, store, integrate, or operate a client-oriented (or end-point dedicated) operating system, such as Microsoft Windows&#xae; (including the variants: Windows 7, Windows XP, Windows 8, and Windows 8.1, available from Microsoft Corporation, headquartered in Redmond, Wash., U.S.A.), Linux, and Google Chrome OS available from Google Inc. headquartered in Mountain View, Calif., U.S.A.. Further, each of the these devices may further employ, store, integrate, or operate a mobile operating system such as Android (available from Google Inc. and includes variants such as version 2.2 (Froyo), version 2.3 (Gingerbread), version 4.0 (Ice Cream Sandwich), Version 4.2 (Jelly Bean), and version 4.4 (KitKat)), iOS (available from Apple Inc., and includes variants such as versions 3-7), Windows&#xae; Phone (available from Microsoft Corporation and includes variants such as version 7, version 8, or version 9), or Blackberry&#xae; operating system (available from BlackBerry Ltd., headquartered in Waterloo, Ontario, Canada). Alternatively or in addition, each of the devices that are not denoted herein as servers, may equally function as a server in the meaning of client/server architecture.</p><p id="p-0522" num="0524">The method and system described herein allows for a client device (such as Client device #<b>1</b> <b>31</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>5</b></figref> or the client device #<b>1</b> <b>201</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>20</b></figref>) to effectively fetch content from a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>). The method and system may be used by the client device for supporting an application, such as a web browser application, when the application is requesting a content from the Internet in general, and from a data server in particular. The request for Internet-related content may be intercepted by the &#x2018;client&#x2019; application and process, initiating the client flowchart <b>60</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the flowchart <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, or the flowchart <b>230</b> shown in <figref idref="DRAWINGS">FIG. <b>23</b></figref>. In one example, the client device uses a communication-related application to be used by the application when no &#x2018;client&#x2019; application is present, such as HTTP stack handling application. The request from the requesting application to the communication-related application is intercepted and routed to be handled as part of the &#x2018;client&#x2019; application or process. Such interception may be in the form of a filter driver (or any other intermediate driver), enabling the interception as part of the OS kernel. Alternatively or in addition, the interception may be in the form of extension or a plug-in of the requesting application, such as a browser plug-in or a browser extension in the case where the application is a web browser. Alternatively or in addition, the interception of the request may use hooking of the requesting application or of the communication-related application. Alternatively or in addition, the application and the steps described herein may communicate using an Inter-Process Communication (IPC), such as a file sharing, a signal, a socket, a pipe, a message queue, a shared memory, a semaphore, or memory mapped file. In Windows environment, the IPC may be based on a clipboard, a Component Object Model (COM), a data copy, a DDE protocol, or mailslots.</p><p id="p-0523" num="0525">Examples of web browsers include Microsoft Internet Explorer (available from Microsoft Corporation, headquartered in Redmond, Wash., U.S.A.), Google Chrome which is a freeware web browser (developed by Google, headquartered in Googleplex, Mountain View, Calif., U.S.A.), Opera&#x2122; (developed by Opera Software ASA, headquartered in Oslo, Norway), and Mozilla Firefox&#xae; (developed by Mozilla Corporation headquartered in Mountain View, Calif., U.S.A.). The web-browser may be a mobile browser, such as Safari (developed by Apple Inc. headquartered in Apple Campus, Cupertino, Calif., U.S.A), Opera Mini&#x2122; (developed by Opera Software ASA, headquartered in Oslo, Norway), and Android web browser.</p><p id="p-0524" num="0526">Any network element, or any device that is herein that is connectable to the Internet, may be in one of the states in a state diagram <b>300</b> shown in <figref idref="DRAWINGS">FIG. <b>30</b></figref>. A device may be in an &#x2018;OFFLINE&#x2019; state <b>301</b>, where the device cannot access, and cannot be accessed via, the Internet. For example, the device may be not powered, or may not be connected to the Internet due to a faulty or non-operative communication interface, or due to the lack of Internet connectivity in the vicinity of the device. In normal operation, the device is in an &#x2018;ONLINE&#x2019; state <b>302</b>, where the device is connected to the Internet, and may receive messages from, and send messages to, the Internet. Further, a resource (or few resources) in the device may in time become congested in a &#x2018;CONGESTED&#x2019; state <b>303</b>. The device monitors its resources and performance, and upon detecting a resource utilization that is above a set threshold, declares itself as congested. The congestion detection scheme serves as a mechanism to measure the device performance and quality of service, and may be used to alert other devices in the system that the device may not be capable to handle additional tasks or services. The detection of congestion may be further used for load balancing, such as for distributing workloads across multiple computing resources, such as computers, a computer cluster, network links, central processing units, or disk drives, for optimizing resource use, maximizing throughput, minimizing response time, and avoiding overload of any one of the resources. Further, using multiple components in a device with load balancing instead of a single component may increase reliability through redundancy. Similarly, using multiple devices in a system or network with load balancing instead of a single (or few) device may increase reliability through redundancy.</p><p id="p-0525" num="0527">Upon power up and being operative, the device shifts from the &#x2018;OFFLINE&#x2019; state <b>301</b> to the &#x2018;ONLINE&#x2019; state <b>302</b> as depicted by an arrow <b>304</b><i>b </i>in the states chart <b>300</b>. If for any reason the device is not capable to access the Internet or to be operative as required, such as upon powering the device power off or a faulty Internet connection, the device is considered to shift to the &#x2018;OFFLINE&#x2019; state <b>301</b> as depicted by an arrow <b>304</b><i>a. </i>In the case a congestion is detected, the device shifts to the &#x2018;CONGESTED&#x2019; state <b>303</b>, as depicted by an arrow <b>304</b><i>e. </i>Upon detecting that the detected congestion has elapsed, the device may resume to normal operation in the &#x2018;ONLINE&#x2019; state <b>302</b>, as depicted by an arrow <b>304</b><i>d. </i>The device may also shift from the &#x2018;CONGESTED&#x2019; state <b>303</b> to the &#x2018;OFFLINE&#x2019; state <b>301</b>, as depicted by an arrow <b>304</b><i>c. </i></p><p id="p-0526" num="0528">In one example, the congestion decision may be based on a CPU utilization, where CPU time or CPU usage is reported either for each thread, for each process, or for the entire system. The CPU utilization relates to the relative time that the CPU is not idling (for example, the amount of time it not executing a system idle process). In the case the CPU utilization is above a predetermined threshold, such as 80%, the device declares itself as congested. Alternatively or in addition, a congestion state may be based on memory utilization. In the case wherein the memory locations that are in use are above a predetermined threshold, for example, when additional memory requirements may not be satisfied, the device may declare itself as congested. Alternatively or in addition, a congestion state may be the result of detecting of low availability of communication bandwidth (for example, for accessing the Internet), or input/output resources limitations. The congestion in Internet related communication is described in IETF RFC 2914 entitled: &#x201c;Congestion Control Principles&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0527" num="0529">A heartbeat mechanism may be used in order to allow devices to sense the status of other devices in the system. A &#x2018;ONLINE HEARTBEAT&#x2019; flow chart <b>305</b> is shown in <figref idref="DRAWINGS">FIG. <b>31</b></figref> as part of the flowchart <b>310</b>, may be executed by any device herein. The device may be in an &#x2018;OFFLINE&#x2019; step <b>301</b>, corresponding to the &#x2018;OFFLINE&#x2019; state in the state diagram <b>300</b>. When in the &#x2018;ONLINE&#x2019; state <b>302</b> and the &#x2018;CONGESTED&#x2019; state <b>303</b>, the device executes the flow chart &#x2018;ONLINE HEARTBEAT&#x2019; <b>305</b>, which starts at a &#x2018;Send Heartbeat&#x2019; step <b>305</b><i>a, </i>where the device sends a &#x2018;ping&#x2019; or any other message, thus notifying its availability over the Internet, and being in normal operation, and capable of providing services to other devices if required. The message sent in this step may be a dedicated heartbeat related message. Alternatively or in addition, any message which is sent as part of the device functionality, may as well be used as a &#x2018;heartbeat&#x2019; message, corresponding to the &#x2018;Send Heartbeat&#x2019; step <b>305</b><i>a. </i>For example, the &#x2018;Sign-in as Client&#x2019; step <b>61</b><i>b </i>in the client device flowchart <b>60</b>, the &#x2018;Request Tunnel List&#x2019; step <b>62</b><i>a, </i>the &#x2018;Request Agents List&#x2019; step <b>231</b><i>c </i>in the client flowchart <b>230</b>, and the &#x2018;Send Chunk to Client&#x2019; step <b>242</b><i>d </i>in the peer flowchart <b>240</b><i>a, </i>may serve also as a heartbeat message, corresponding to the &#x2018;Send Hearbeat&#x2019; step <b>305</b><i>a. </i>A timer set to a predetermined time interval is started in a &#x2018;Start Timer&#x2019; step <b>305</b><i>b. </i>The time period set by the timer is used to determine the frequency of the heartbeat &#x2018;pulse&#x2019;, where high frequency resulting short time periods allows for frequent updating of the device status. The time period between &#x2018;heartbeat pulses&#x2019; may be in the order of milliseconds, such as every 10, 20, 30, 50, or 100 milliseconds, may be in the order of seconds, such as every 1, 2, 3, 5, or 10 seconds, may be in the order of tens of seconds, such as every 10, 20, 30, 50, or 100 seconds, or may be in the order of minutes, such as every 1, 2, 3, 5, or 10 minutes. The device remains as long as the timer has not lapsed in a &#x2018;Timer Elapsed?&#x2019; step <b>305</b><i>c. </i>Upon an expiration of the timer, the device reverts to the &#x2018;Send Heartbeat&#x2019; step <b>305</b><i>a, </i>and the process is resumed.</p><p id="p-0528" num="0530">The congestion related activities of a device is shown in a flowchart <b>310</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>31</b></figref>, showing the flowchart <b>308</b>, including the &#x2018;ONLINE&#x2019; flowchart <b>308</b>, describing to the device activity while in the &#x2018;ONLINE&#x2019; state <b>302</b>, and the &#x2018;CONGESTED&#x2019; flowchart <b>307</b> describing the device activity while in the &#x2018;CONGESTED&#x2019; state <b>303</b>. The congestion related mechanism may also use heartbeat scheme, where the congestion state is periodically checked and reported. Upon entering the &#x2018;ONLINE&#x2019; step <b>302</b> (corresponding to the &#x2018;ONLINE&#x2019; state <b>302</b> in the state diagram <b>300</b>), the device sends a message regarding its availability in a &#x2018;Send Non-Congested&#x2019; step <b>308</b><i>a. </i>The device remains in a &#x2018;Congested?&#x2019; step <b>308</b><i>b, </i>as long as no congestion is detected. Upon detecting a congestion state, the device shifts to &#x2018;CONGESTED&#x2019; state <b>303</b> and executes a &#x2018;CONGESTED&#x2019; flowchart <b>307</b>, starting with notifying its status as congested, in a &#x2018;Send Congested&#x2019; step <b>307</b><i>a. </i>As long as the congestion condition is detected, the device stays in a &#x2018;Congested?&#x2019; step <b>307</b><i>b. </i>When the congestion criterion is not met anymore, the device reverts to normal operation in the &#x201c;ONLINE&#x201d; state <b>302</b> and executes the &#x2018;Send Non-Congested&#x2019; step <b>308</b><i>a. </i></p><p id="p-0529" num="0531">A device that monitors or tracks the status a tracked device (that executes the flowchart <b>310</b> and the flowchart <b>310</b><i>a</i>) may execute the flowchart <b>320</b> shown in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. In a &#x2018;Message Received?&#x2019; step <b>321</b><i>f </i>the tracking device checks for receiving any message from the tracked device, which may be following the flowchart <b>310</b> and the flowchart <b>310</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>31</b></figref>. In a &#x2018;Congested Message?&#x2019; step <b>321</b><i>a, </i>the received message type is checked. The received message may indicate that the tracked device is congested, for example, send the &#x2018;congested&#x2019; message in the &#x2018;Send Congested&#x2019; step <b>307</b><i>a </i>in the flowchart <b>307</b>. In such a case, the tracked device status is marked as &#x2018;congested&#x2019; in a &#x2018;Mark as Congested&#x2019; step <b>321</b><i>c, </i>and the system or the tracking device may hold any further workload, or request for any service, relating to the tracked device. The received message may indicate that the tracked device is online, for example initiated as part of a &#x2018;Send Heartbeat&#x2019; step <b>305</b><i>a, </i>as part of the &#x2018;Send Non-Congested&#x2019; step <b>308</b><i>a, </i>or any other message indicating proper operation of the tracked device. In such a case, the tracked device status is marked as &#x2018;online&#x2019; in a &#x2018;Mark as Online&#x2019; step <b>321</b><i>b, </i>and the tracked device is assumed available to provide services, receive messages, or response to requests. In a &#x2018;Start Timer&#x2019; step <b>321</b><i>e, </i>a timer configured to respond after a time interval has elapsed is triggered, similar to the timer described in the flowchart <b>305</b> in <figref idref="DRAWINGS">FIG. <b>31</b></figref>. In one example, the time interval measured by the timer starting at the &#x2018;Start Timer&#x2019; step <b>321</b><i>e </i>may be the same as the time interval measured by the timer operated in the flowchart <b>305</b>. Alternatively, the tracking device timer may be used to measure longer time interval, such as 5%, 10%, or 120% longer than the tracked device timer, allowing for an error margin. In the case a message is received in the &#x2018;Message Received?&#x2019; step <b>321</b><i>f, </i>the message is checked and the tracked device status is validated as described above. In the case no message is received from the tracked device, as noted in the &#x2018;Timer Elapsed?&#x2019; step <b>321</b><i>g, </i>it is assumed that the heartbeat mechanism of the tracked device shows as the flowchart <b>305</b> is inoperative, hence in a &#x2018;Mark as Offline&#x2019; step <b>321</b><i>h </i>the tracked device is assumed to be inoperative, and thus not available for any services or requests.</p><p id="p-0530" num="0532">In one example, all the devices herein (including server devices) in the system are tracked and are executing the tracked device flowchart <b>310</b> and the flowchart <b>310</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>31</b></figref>. Alternatively or in addition, all the devices in a system (including server devices) are tracking other devices and execute the tracking device flowcharts <b>320</b> in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. In one example, the client devices, such as client device #<b>1</b> <b>31</b><i>a </i>and the client device #<b>2</b> <b>31</b><i>b </i>are the tracked devices, and thus execute the tracked device flowchart <b>310</b> and the flowchart <b>310</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>31</b></figref>, and the tracking devices are the tunnel devices (such as the tunnel device #<b>1</b> <b>33</b><i>a, </i>the tunnel device #<b>2</b> <b>33</b><i>b, </i>and the tunnel device #<b>3</b> <b>33</b><i>c</i>) and the acceleration server <b>32</b>, each executing the tracking device flowcharts <b>320</b> in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. Alternatively or in addition, the tunnel devices (such as the tunnel device #<b>1</b> <b>33</b><i>a, </i>the tunnel device #<b>2</b> <b>33</b><i>b, </i>and the tunnel device #<b>3</b> <b>33</b><i>c</i>) are the tracked devices, and thus execute the tracked device flowchart <b>310</b> and the flowchart <b>310</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>31</b></figref>, and the tracking devices are the client devices (such as client device #<b>1</b> <b>31</b><i>a </i>and the client device #<b>2</b> <b>31</b><i>b</i>) and the acceleration server <b>32</b>, each executing the tracking device flowcharts <b>320</b> in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. An example of the acceleration server <b>32</b> keeping a status of client devices and tunnel devices is shown as a column &#x2018;status&#x2019; <b>41</b><i>e </i>in the table <b>40</b> in <figref idref="DRAWINGS">FIG. <b>5</b><i>a</i></figref>, where the first row <b>42</b><i>a </i>entry shows that the associated tunnel is in an &#x2018;online&#x2019; state, the second row <b>42</b><i>b </i>entry shows that the associated tunnel is in a &#x2018;congested&#x2019; state, the third row <b>42</b><i>c </i>entry shows that the associated client is in an &#x2018;online&#x2019; state, the fourth row <b>42</b><i>d </i>entry shows that the associated client is in an &#x2018;offline&#x2019; state, and the fifth row <b>42</b><i>e </i>entry shows that the associated client/tunnel is in a &#x2018;congested&#x2019; state. When the acceleration server <b>32</b> prepares a list of tunnel devices to be used as part of the &#x2018;Prepare List&#x2019; step <b>81</b><i>e </i>in the flowchart <b>80</b>, tunnel devices that are &#x2018;offline&#x2019; and tunnel devices that are congested (such as the tunnel device associated with the entry of the second row <b>42</b><i>b </i>in the table <b>40</b>) are not used, and are not included is the tunnel devices list sent to the requesting client device as part of the &#x2018;Send List&#x2019; step <b>81</b><i>f </i>in the flowchart <b>80</b>.</p><p id="p-0531" num="0533">In one example, the client devices, such as client device #<b>1</b> <b>201</b><i>a </i>is the tracked devices, and thus execute the tracked device flowchart <b>310</b> and the flowchart <b>310</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>31</b></figref>, and the tracking devices are the agent devices (such as the agent device #<b>1</b> <b>103</b><i>a, </i>the agent device #<b>2</b> <b>103</b><i>b, </i>and the agent device #<b>3</b> <b>103</b><i>c</i>), the peer devices (such as the peer device #<b>1</b> <b>102</b><i>a, </i>the peer device #<b>2</b> <b>102</b><i>b, </i>and the peer device #<b>3</b> <b>102</b><i>c</i>), and the acceleration server <b>202</b>, each executing the tracking device flowcharts <b>320</b> in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. Alternatively or in addition, the agent devices (such as the agent device #<b>1</b> <b>103</b><i>a, </i>the agent device #<b>2</b> <b>103</b><i>b, </i>and the agent device #<b>3</b> <b>103</b><i>c</i>) are the tracked devices, and thus execute the tracked device flowchart <b>310</b> and the flowchart <b>310</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>31</b></figref>, and the tracking devices are the client devices (such as client device #<b>1</b> <b>201</b><i>a</i>), the peer devices (such as the peer device #<b>1</b> <b>102</b><i>a, </i>the peer device #<b>2</b> <b>102</b><i>b, </i>and the peer device #<b>3</b> <b>102</b><i>c</i>), and the acceleration server <b>202</b>, each executing the tracking device flowchart <b>320</b> in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. Alternatively or in addition, the peer devices (such as the peer device #<b>1</b> <b>102</b><i>a, </i>the peer device #<b>2</b> <b>102</b><i>b, </i>and the peer device #<b>3</b> <b>102</b><i>c</i>) are the tracked devices, and thus execute the tracked device flowchart <b>310</b> and the flowchart <b>310</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>31</b></figref>, and the tracking devices are the client devices (such as client device #<b>1</b> <b>201</b><i>a</i>), the agent devices (such as the agent device #<b>1</b> <b>103</b><i>a, </i>the agent device #<b>2</b> <b>103</b><i>b, </i>and the agent device #<b>3</b> <b>103</b><i>c</i>), and the acceleration server <b>202</b>, each executing the tracking device flowchart <b>320</b> in <figref idref="DRAWINGS">FIG. <b>32</b></figref>. In such a system, an agent device or a peer device, that is either congested or offline, is not selected to provide a service to a client device. For example non-online agent devices are not selected as part of the &#x2018;Select Agents&#x2019; step <b>231</b><i>f </i>in the flowchart <b>230</b>, and non-online peer devices are not selected as part of the &#x2018;Select Peers&#x2019; step <b>238</b><i>a </i>in the flowchart <b>230</b>.</p><p id="p-0532" num="0534">A device may be selected to provide a service, such as a tunnel device that may be selected (alone or as part of a group) by a client device as part of the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a </i>in the flowchart <b>100</b>. The selected tunnel device may shift to the &#x2018;offline&#x2019; state <b>301</b> or to the &#x2018;congested&#x2019; state <b>303</b>, and thus respectively becomes unavailable or less effective to use. In such a case, a new tunnel device, that was not formerly selected, may be now selected as a substitute for the &#x2018;offline&#x2019; or &#x2018;congested&#x2019; tunnel device as part of a &#x2018;Replace Device&#x2019; step <b>321</b><i>d. </i>Similarly, an agent device may be selected (alone or as part of a group) by a client device as part of the &#x2018;Select Agents&#x2019; step <b>231</b><i>f </i>in the flowchart <b>230</b>. The selected agent device may shift to the &#x2018;offline&#x2019; state <b>301</b> or to the &#x2018;congested&#x2019; state <b>303</b>, and thus respectively becomes unavailable or less effective to use. In such a case, a new agent device, that was not formerly selected, may be now selected as a substitute for the &#x2018;offline&#x2019; or &#x2018;congested&#x2019; agent device as part of a &#x2018;Replace Device&#x2019; step <b>321</b><i>d. </i>Alternatively or in addition, a peer device may be selected (alone or as part of a group) by a client device as part of the &#x2018;Select Peers&#x2019; step <b>238</b><i>a </i>in the flowchart <b>230</b><i>b. </i>The selected peer device may shift to the &#x2018;offline&#x2019; state <b>301</b> or to the &#x2018;congested&#x2019; state <b>303</b>, and thus respectively becomes unavailable or less effective to use. In such a case, a new peer device, that was not formerly selected, may be now selected as a substitute for the &#x2018;offline&#x2019; or &#x2018;congested&#x2019; peer device as part of a &#x2018;Replace Device&#x2019; step <b>321</b><i>d. </i></p><p id="p-0533" num="0535">Alternatively or in addition, in the case where multiple devices are selected to provide a service, such as a group of multiple tunnel devices, a group of multiple agent devices, or a group of multiple peer devices, the unavailability of a single device or multiple devices in the group (due to shifting to &#x2018;offline&#x2019; state <b>301</b> or to &#x2018;congested&#x2019; state <b>303</b>), may not be handled or corrected, as long as a performance criterion or a threshold is not crossed. For example, assume 5 tunnel devices are assigned to a client device in the &#x2018;Select Tunnels&#x2019; step <b>101</b><i>a, </i>where the system set a criterion of a minimum of 3 operative tunnel devices. Hence, as long as at least 3 tunnel devices are available and operational, no corrective action will be taken, and no devices will be replaced as part of the &#x2018;Replace Device&#x2019; step <b>321</b><i>d. </i>Hence, even in the case of two tunnel devices becoming unavailable or congested, no new tunnel devices will be provided to fetch content for the applicable client device. However, in such a case, if 3 tunnel devices become unavailable rendering only 2 in operational (online) state, at least one new tunnel device will be selected (according to any criterion described herein) and will be used as a replacement as part of the &#x2018;Replace Device&#x2019; step <b>321</b><i>d. </i></p><p id="p-0534" num="0536">The system <b>30</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> above describes the components involved in fetching content using tunnel devices. The system <b>30</b> comprises the acceleration server <b>32</b>, which may execute a part of, or the whole of, the acceleration server tunnel-related flowcharts, such as the flowchart <b>80</b> shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref> or the flowchart <b>90</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. Further, the system <b>30</b> comprises client devices such as the client device #<b>1</b> <b>31</b><i>a </i>and the client device #<b>2</b> <b>31</b><i>b, </i>each of which may execute a part of, or the whole of, the client device related flowcharts, such as the flowchart <b>60</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the flowchart <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, or the flowchart <b>100</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>10</b><i>a</i></figref>. In addition, the system <b>30</b> comprises tunnel devices such as the tunnel device #<b>1</b> <b>33</b><i>a, </i>the tunnel device #<b>2</b> <b>33</b><i>b, </i>and the tunnel device #<b>3</b> <b>33</b><i>c, </i>each of which may execute a part of, or the whole of, the tunnel device related flowcharts, such as the flowchart <b>70</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0535" num="0537">Similarly, the system <b>200</b> shown in <figref idref="DRAWINGS">FIG. <b>20</b></figref> above describes the components involved in fetching content using agent and peer devices. The system <b>200</b> comprises the acceleration server <b>202</b>, which may execute a part of, or the whole of, the acceleration server agent/peer related flowcharts, such as the flowchart <b>250</b> shown in <figref idref="DRAWINGS">FIG. <b>25</b></figref>. Further, the system <b>200</b> comprises client devices such as the client device #<b>1</b> <b>201</b><i>a, </i>which may execute a part of, or the whole of, the client device related flowcharts, such as the flowchart <b>230</b> shown in <figref idref="DRAWINGS">FIG. <b>23</b></figref>, the flowchart <b>230</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>23</b><i>a</i></figref>, or the flowchart <b>230</b><i>b </i>shown in <figref idref="DRAWINGS">FIG. <b>23</b><i>b</i></figref>. In addition, the system <b>200</b> comprises agent devices such as the agent device #<b>1</b> <b>103</b><i>a </i>and the agent device #<b>2</b> <b>103</b><i>b, </i>each of which may execute a part of, or the whole of, the agent device related flowcharts, such as the flowchart <b>240</b> shown in <figref idref="DRAWINGS">FIG. <b>24</b></figref>. Furthermore, the system <b>200</b> comprises peer devices such as the peer device #<b>1</b> <b>102</b><i>a, </i>the peer device #<b>2</b> <b>103</b><i>b, </i>and the peer device #<b>3</b> <b>103</b><i>c, </i>each of which may execute a part of, or the whole of, the agent device related flowcharts, such as the flowchart <b>240</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>24</b></figref><i>a. </i></p><p id="p-0536" num="0538">Any network element in the system may be a dedicated device that assumes only a single role, and thus being only a client (using tunnels), a tunnel, a client (using agents/peers), an agent, or a peer device. Alternatively or in addition, a network element may be capable of assuming two or more roles, either at different times or simultaneously, from the list of roles including a client (using tunnels), a tunnel, a client (using agents/peers), an agent, or a peer device. Alternatively or in addition, a device may be capable of assuming all of the above roles. Further, the same server may be both the tunnels-related acceleration server <b>32</b> and the peer/agent related acceleration server <b>202</b>, either simultaneously or at different times. Alternately, two (or more) distinct servers may be used.</p><p id="p-0537" num="0539">Referring to a system <b>340</b> shown in <figref idref="DRAWINGS">FIG. <b>34</b></figref>, integrating both the system <b>30</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and the system <b>200</b> shown in <figref idref="DRAWINGS">FIG. <b>20</b></figref>. Using such a system, content may be fetched using either tunnel devices, as described, for example, in the timing and messaging chart <b>50</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b><i>b</i></figref>, or using agent and peer devices as described, for example, in the timing and messaging chart <b>220</b> shown in <figref idref="DRAWINGS">FIG. <b>22</b></figref>, or both methods together. A client device such as a client device #<b>1</b> <b>341</b> may assume the role of the tunnel-using client device #<b>1</b> <b>31</b><i>a, </i>the role of the agent/peers-using client device #<b>1</b> <b>201</b><i>a, </i>or both. Such a dual-function client device may execute the flowchart <b>330</b> shown in <figref idref="DRAWINGS">FIG. <b>33</b></figref>, which is based on using one of the methods described herein, or both.</p><p id="p-0538" num="0540">The client device <b>341</b> in the system <b>340</b> may use tunnel devices and assume the role of the client device #<b>1</b> <b>31</b><i>a, </i>may use peer/agent devices and assume the role of the client device #<b>1</b> <b>201</b><i>a, </i>or may use both methods, as shown in a flow chart <b>330</b> shown in <figref idref="DRAWINGS">FIG. <b>33</b></figref>. Upon a content request, the method starts in a &#x2018;START&#x2019; step <b>331</b><i>a. </i>First, it is checked in a &#x2018;Locally Cached?&#x2019; step <b>331</b><i>c </i>if the requested content is available in the client device #<b>1</b> <b>341</b> itself, for example in its cache or any available storage. In one example, the content may be available in the cache memory, since the content was fetched in a past transaction and stored in the device, such as in &#x2018;Store Content&#x2019; step <b>145</b> as a part of the flowchart <b>140</b> in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, or in a &#x2018;Store Content&#x2019; step <b>235</b><i>a </i>as a part of the flowchart <b>230</b><i>a. </i>In the case of locally available content, the content is fetched from the cache (or any other storage) as part of a &#x2018;Fetch from Local cache&#x2019; step <b>331</b><i>b. </i>In the case the requested content is not locally available at the device, the client device #<b>1</b> <b>341</b> may check in a &#x2018;Direct Fetch?&#x2019; step <b>331</b><i>d </i>the possibility of directly accessing a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>) storing the content. In one example, such directly approaching the data server without using any intermediate devices such as using tunnel devices, or fetching the content from peer devices, may result in less overhead and handling, and sometimes may be faster. In the case of direct fetching, the client device #<b>1</b> <b>341</b> accesses and fetch the requested content directly from the data server in a &#x2018;Fetch from Server&#x2019; step <b>331</b><i>e. </i></p><p id="p-0539" num="0541">If the direct fetching is not selected, then in a &#x2018;Method Select&#x2019; step <b>331</b><i>f, </i>the device selects which content fetching method to use. The selection of which method to use may be based on estimation of the latency associated with each method until the content is fully fetched. In one example, a method may be selected when the estimated latency using the other method is substantially longer. The client device #<b>1</b> <b>341</b> may select to only use tunnel devices (&#x2018;Tunnels Only&#x2019;), and in this scenario, it will execute the tunnels-using client device flowchart (such as the flowchart <b>60</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>) as part of a &#x2018;Tunnel Flowchart&#x2019; step <b>331</b><i>i. </i>In one example, the estimated latency using the tunnel-based method may not apply in reality, and may be much longer than estimated. In such a case, it may be beneficial to revert to the other method, which may be faster. Hence, a timer may be used in order to assess in real-time the latency associated with a method, in order to reconsider which method to use. Such a Timer #<b>3</b> is set to the estimated latency expected in the tunnels-using method, preferably with an additional margin to allow for estimation errors or inaccuracies. The Timer #<b>3</b> starts in a &#x2018;Timer #<b>3</b> Start&#x2019; step <b>331</b><i>g, </i>before or in parallel the starting of the tunnel-using method in the &#x2018;Tunnel Flowchart&#x2019; step <b>3311</b>. In the case the content fetching in the &#x2018;Tunnel Flowchart&#x2019; step <b>331</b><i>i </i>is completed before the timer #<b>3</b> expiration, the selected method has succeeded to fetch the content in full and the process is completed. In the case where the Timer #<b>3</b> expires in a &#x2018;Timer #<b>3</b> Expired&#x2019; step <b>331</b><i>i </i>before content fetching completion, the tunnel-based method in the &#x2018;Tunnel Flowchart&#x2019; step <b>3311</b> may be stopped in &#x2018;Stop Tunnel&#x2019; step <b>331</b><i>j </i>in order to save resources (such as processing power), and the &#x2018;Peer Flowchart&#x2019; step <b>331</b><i>h </i>is initiated, executing the alternate method for fetching the content.</p><p id="p-0540" num="0542">Alternatively, the client device #<b>1</b> <b>341</b> may select to only use peer/agent devices (&#x2018;Peers Only&#x2019;), and in this scenario, it will execute the peers/agents-using client device flowchart (such as the flowchart <b>230</b> in <figref idref="DRAWINGS">FIG. <b>23</b></figref> and the flowchart <b>230</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>23</b><i>a</i></figref>) as part of a &#x2018;Peer Flowchart&#x2019; step <b>331</b><i>h. </i>In one example, the estimated latency using the tunnel-based method may not apply in reality, and may be much longer than estimated. In such a case, it may be beneficial to revert to the other method, which may be faster. Hence, a timer may be used in order to assess in real-time the latency associated with a method, in order to reconsider which method to use. Such a Timer#<b>4</b> is set to the estimated latency expected in the peers/agents-using method, preferably with an additional margin to allow for estimation errors or inaccuracies. The Timer #<b>4</b> starts in a &#x2018;Timer #<b>4</b> Start&#x2019; step <b>331</b><i>n, </i>before or in parallel to the starting of the peers/agents-using the method in the &#x2018;Peers Flowchart&#x2019; step <b>331</b><i>h. </i>In the case the content fetching in the &#x2018;Peer Flowchart&#x2019; step <b>331</b><i>h </i>is completed before the timer #<b>4</b> expiration, the selected method has succeeded to fetch the content in full and the process is completed. In the case where the Timer #<b>4</b> expires in a &#x2018;Timer #<b>4</b> Expired&#x2019; step <b>331</b><i>m </i>before content fetching completion, the peers/agents-based method in the &#x2018;Peer Flowchart&#x2019; step <b>331</b><i>h </i>may be stopped in a &#x2018;Stop Peer&#x2019; step <b>331</b><i>k </i>in order to save resources (such as processing power), and the &#x2018;Tunnel Flowchart&#x2019; step <b>331</b><i>i </i>is initiated, executing the alternate method for fetching the content.</p><p id="p-0541" num="0543">Alternatively or in addition, the client device #<b>1</b> <b>341</b> may select to use both methods (&#x2018;Both&#x2019;), and such to simultaneously execute both the tunnels-using client device flowchart (such as the flowchart <b>60</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>) as part of the &#x2018;Tunnel Flowchart&#x2019; step <b>331</b><i>i, </i>and the peers/agents-using client device flowchart (such as the flowchart <b>230</b> in <figref idref="DRAWINGS">FIG. <b>23</b></figref> and the flowchart <b>230</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>23</b><i>a</i></figref>) as part of the &#x2018;Peer Flowchart&#x2019; step <b>331</b><i>h. </i>The two methods are executed in parallel, and one of them is completed before the other. In the case using of tunnels is faster than using peer/agent devices, the content will be fetched in full using this method, and the &#x2018;Tunnel Flowchart&#x2019; step <b>331</b><i>i </i>will be completed first. In such a case, in a &#x2018;Stop Peer&#x2019; step <b>331</b><i>k </i>the peer/agent using method executed as part of the &#x2018;Peer Flowchart&#x2019; step <b>331</b><i>h </i>is not needed anymore (since the content was fetched in full) and is stopped, in order to save processing power and bandwidth. Similarly, In the case the using peers/agents is faster than using tunnel devices, the content will be fetched in full using this method, and the &#x2018;Peer Flowchart&#x2019; step <b>331</b><i>h </i>will be completed first. In such a case, in a &#x2018;Stop Tunnel&#x2019; step <b>331</b><i>j </i>the tunnels-using method executed as part of the &#x2018;Tunnel Flowchart&#x2019; step <b>331</b><i>i </i>is not needed anymore (since the content was fetched in full) and is stopped, in order to save processing power and bandwidth.</p><p id="p-0542" num="0544">A content fetched or sent by a network element may consist of, or include, video data. Video data fetched via the Internet are typically identified by a set of characters, including three fields, relating to a URL domain name, a specific video identifier, and offset, relating to the viewing point in the video data itself. For example, in a video identifier such as https://www.youtube.com/watch?v=9mSb3P7cZIE?ST=1:48, the field &#x2018;https://www.youtube.com&#x2019; is the URL domain, which identify the server from which the video can be fetched, the part &#x2018;9mSb3P7cZIE&#x2019; identifies the video data (such as a movie) as a whole, and the offset &#x2018;1:48&#x2019; part in the video starting point, in this example after 1 minute and 48 seconds after the video start point. The offset may be presented (as part of the video identifier) in time using another format such as #T=3M54S (denoting starting point after 3 minutes and 54 seconds) is bytes (such as B=10344, denoting a starting point after 10344 bytes), relative offset (such as in %, such as R=54.3, denoting that the starting point is after 54.3% of the total video length, such as byte 543 out of 100 bytes sized video content)), and various other methods. In the case the content to be fetched is a video data, while the video content may be located in other network elements, it may be identified differently than the requested URL or content identifier, and as such may not be easily fetched. In one example, in order to form a common method for identification of a video-related URL, the offset is detected (e.g., by the &#x2018;/&#x2019; symbol, or by the identifying the offset format, or both), and the URL is stored (such as in a cache) identified as the domain name and the video data identifier only, where the offset is stored as additional separate attribute. In one example, the offset presentation is normalized to a common format, which is understood by all of the network elements.</p><p id="p-0543" num="0545">A flowchart <b>410</b> shown in <figref idref="DRAWINGS">FIG. <b>43</b></figref> describes a method for forming a unified identifying scheme for video content. The video-related content is received (or requested) by a network element in a &#x2018;URL Received&#x2019; step <b>411</b><i>a. </i>In a &#x2018;Remove Offset&#x2019; step <b>411</b><i>b, </i>the offset part of the URL is detected and removed, such as by detecting the &#x2018;/&#x2019; symbol, or by the identifying the offset format, or both. A direct request for the video content is sent to a respective data server (such as the data server #<b>1</b> <b>22</b><i>a</i>) in a &#x2018;Send Request To Server&#x2019; step <b>411</b><i>c. </i>Typically, the initial part of the data server response includes meta-data information, including the content length, in a form of time (such as hours, minutes, and seconds) or size (such as in bytes). Once the content size or length information is received, there is no need for any communication with the data server, and the communication session is terminated in a &#x2018;Terminate Server&#x2019; step <b>411</b><i>e. </i>The content size or length information is used for unifying the form of the video identifier in a &#x2018;Normalize Offset&#x2019; step <b>411</b><i>f. </i>For example, a unified scheme may include relating offset, so a video file that start at byte 345 out of 1000 total bytes will be identified as 34.5% (345/1000), and a video file that starts after 1 minute 30 second (1:30) out of a total of 10 minutes will be identified as 15%. Similarly, files that do not end at the video end may also be accordingly identified. For example, a video file that starts after 2 minutes and ends after 7 minutes, will be identified as 20-70%. In such a unified scheme, a network element may store (such as in a cache), or request, parts of a video file by using the common identification scheme. For example, a network element that stores the range from 1 minute to 22 minutes out of a video file, may respond to a request asking for the range of minute 15 to minute 17.</p><p id="p-0544" num="0546">IP-based geolocation (commonly known as geolocation) is a mapping of an IP address (or MAC address) to the real-world geographic location of a computing device or a mobile device connected to the Internet. The IP address based location data may include information such as country, region, city, postal/zip code, latitude, longitude, or Timezone. Deeper data sets can determine other parameters such as domain name, connection speed, ISP, language, proxies, company name, US DMA/MSA, NAICS codes, and home/business classification. The geolocation is further described in the publication entitled: &#x201c;<i>Towards Street</i>-<i>Level Client</i>-<i>Independent IP Geolocation</i>&#x201d; by Yong Wang et al., downloaded from the Internet on July 2014, and in an Information Systems Audit and Control Association (ISACA) 2011 white-paper entitled: &#x201c;<i>Geolocation: Risk, Issues and Strategies</i>&#x201d;, which are both incorporated in their entirety for all purposes as if fully set forth herein. There are a number of commercially available geolocation databases, such as a web-site http://www.ip2location.com operated by Ip2location.com headquartered in Penang, Malaysia, offering IP geolocation software applications, and geolocation databases may be obtained from IpInfoDB operating web-site http://ipinfodb.com, and by Max Mind, Inc., based in Waltham, Mass., U.S.A, operating the web-site https://www.maxmind.com/en/home.</p><p id="p-0545" num="0547">Further, the W3C Geolocation API is an effort by the World Wide Web Consortium (W3C) to standardize an interface to retrieve the geographical location information for a client-side device. It defines a set of objects, ECMA Script standard compliant, that executing in the client application give the client's device location through the consulting of Location Information Servers, which are transparent for the Application Programming Interface (API). The most common sources of location information are IP address, Wi-Fi and Bluetooth MAC address, radio-frequency identification (RFID), Wi-Fi connection location, or device Global Positioning System (GPS) and GSM/CDMA cell IDs. The location is returned with a given accuracy depending on the best location information source available. The W3C Recommendation for the geolocation API specifications draft dated Oct. 24, 2013, is available from the web-site http://www.w3.org/TR/2013/REC-geolocation-API-20131024. Geolocation-based addressing is described in U.S. Pat. No. 7,929,535 to Chen et al., entitled: &#x201c;Geolocation-based Addressing Method for IPv6 Addresses&#x201d;, and in U.S. Pat. No. 6,236,652 to Preston et al., entitled: &#x201c;Geo-spacial Internet Protocol Addressing&#x201d;, and in U.S. Patent Application Publication No. 2005/0018645 to Mustonen et al., entitled: &#x201c;Utilization of Geographic Location Information in IP Addressing&#x201d;, which are all incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0546" num="0548">Geolocation may be used by any network element. The peer devices described above as storing a content (chunks) that is required by a client device, and thus the client device fetches the content from the peer devices rather than directly from the web server (or in addition to it). In some cases, multiple devices are available storing unknown content which may be the content required by a client device. The geolocation may be used to determine which available devices may be, or are expected to be, storing the content that is requested. In this context, two Internet-connected devices, each identified by a respective IP address, for example, are considered as being &#x2018;close&#x2019; if there is a likelihood that the same content is stored in both, or that both devices fetched the same content from a data server. Similarly, two devices are considered closer than the other two devices if there is a higher likelihood that they store the same content (from the same data server).</p><p id="p-0547" num="0549">Referring now to <figref idref="DRAWINGS">FIG. <b>35</b></figref> showing a flowchart <b>350</b>, which may be executed by any network element, describing a method for selecting devices based on a geolocation and on location-specific attributes, for use by a requesting device, interested in obtaining a content from a data server. In a &#x2018;Receive IP List&#x2019; step <b>351</b> a list of devices available to select from is obtained. In one example, the devices may be identified by their respective IP addresses. In an &#x2018;Associate Location&#x2019; step <b>352</b>, the IP address of each of the devices is used to obtain the physical geographical location of the device using any geolocation schemes, such as looking up a local database stored in the requesting device, or using a remote database via the Internet. The physical geographical location may include a country, region (such as state or county), city, postal/zip code, latitude, longitude, or timezone. In a &#x2018;Select Devices&#x2019; step <b>354</b>, one or more devices are selected from the list.</p><p id="p-0548" num="0550">In one example, the selection is based only on the obtained the geographical location. In one example, such selection may be based on the physical geographical location of the requesting device (obtained locally at the requesting device or by using a geolocation), a physical geographical location of the data server storing a content that is requested (obtained locally or by using geolocation), or relating to physical geographical location of IP addressable, Internet connected device. In one example, the devices may be selected based on being in the same location, such as in the same continent, country, region, city, street, or timezone. The devices may be selected from the list based on the physical geographical distance, where &#x2018;closeness&#x2019; is defined as based on actual geographical distance between devices, where shorter distance indicates closer devices. For example, is the case where the latitude and the longitude are obtained, the physical distance between each device in the list and the requesting device (or the data server or another device) may be calculated, and the nearest device will be first selected, then the second nearest device, and so on. Alternatively or in addition, devices in the same city (or street) as the requesting device are considered as the closest and may be first selected, then the devices that are in the same region or country may be considered as close and may be selected next.</p><p id="p-0549" num="0551">In one example, an attribute is used as a basis for defining &#x2018;closeness&#x2019; in the &#x2018;Select Devices&#x2019; step <b>354</b>, and each device is associated with an attribute value based on its geographical physical location, in an &#x2018;Associate Attribute&#x2019; step <b>353</b>. The information relating to the various attributes can be obtained from a database that is local to the requesting device, or may be publicly available via the Internet, using city, region, or country based databases. In one example, country based information may be obtained via the Internet, such as &#x2018;The World Factbook&#x2019; website by the U.S. Central Intelligence Agency (CIA) having a URL: &#x201c;https://www.cia.gov/library/publications/the-world-factbook/docs/notesanddefs.html?fieldkey=2113&#x26;alphaletter=G&#x26;term=Geography-note&#x201d;, and the United Nations Statistics Division website: https://data.un.org.</p><p id="p-0550" num="0552">One example of such an attribute is the language that is widely spoken (or is the formal language) in a geographical location, such as in a country. In this aspect, while Portugal is geographically closer to Germany than to Brazil, using the language as the selection attribute suggest that Portugal is &#x2018;closer&#x2019; to Brazil, since the Portuguese language is popular in both these countries, and Portuguese-&#x2014;speaking Portugal is language-wise distant from German-speaking Germany. Similarly, Arabic-spoken countries are close to each other, regardless of the actual geographical distance. Such &#x2018;closeness&#x2019; definition is supported, since a web-site or URL having a content (such as text, audio or video) in Portuguese language, is likely to be accessed by users from Brazil and Portugal, and less likely to be accessed by users located in Germany.</p><p id="p-0551" num="0553">Another example of an attribute is the popular sport type in the geographical location. For example, soccer is most popular in Brazil and in Germany, while American football is popular in the U.S. Regarding this aspect, Brazil is considered to be closer to Germany than to the U.S., as it is expected that web-sites associated with soccer will be more popular with users in Germany and Brazil rather than with user in North-America. Another example of an attribute is the religion popular in a region or a country. In this aspect, Turkey and Egypt, both being Islamic countries, are religion-wise closer than Turkey and Greece, having different dominant religion, in spite of their geographical proximity. For example, web-site offering Islamic-related content are likely to be more popular in Turkey and Egypt, rather than in Greece.</p><p id="p-0552" num="0554">Other attributes relating to people and society may include race and ethnic groups, and demographic or social characteristics, such as population, age structure, population growth rate, death rate, birth rate, migration rate, sex ratio, life expectancy, and health expenditures. Other attributes may include economical-related characteristics (of a location or a country), such as Gross Domestic Product (GDP), GDP per capita (PPP), gross national saving, agriculture products, industry types, labor force, unemployment rate, household income or consumption by percentage share, Government budget, taxes and other revenues, inflation rate (consumer prices), export/import of goods and services, household consumption, government consumption, and investment in fixed capital.</p><p id="p-0553" num="0555">Another example of an attribute is the weather in a location or a country. Countries or locations associated with cold weather are being considered weather-wise closer than locations having distinct and different weather. For example, web-sites relating to ski resorts or snow related equipment are likely to be more popular in cold weather countries than countries having a desert climate. Similarly, web-sites relating to cooling equipment (such as air conditioners) are likely to be more popular in warm weather locations and countries. In addition to climate, other geographical related characteristics include having a coastline, terrain, natural resources, and environment.</p><p id="p-0554" num="0556">In one example, the following demographic attributes or categories can be used: Gender, such as male or female; age, such as the age groups 0-11, 12-17, 18-20, 21-24, 25-34, 35-49, 50-54, 55-64, and 65-99; income (in US $, for example) such as 0-24,999, 25,000-49,999, 50,000-74,999, 75,000-99,999, 100,000-149,000, and 150,000 and up; education such as some High School, High School Graduate, Home College, Associates Degree, Bachelor's Degree, and Post Graduate; occupation such as administrative or Clerical, Craftsman, Educators, Executive, Laborer, Homemaker, Military, Professional, Sales, Service, Student, Technical, Self-employed, and Retired; race such as Hispanic, Non-Hispanic, African American, Caucasian, Asian, and Native American. Alternatively or in addition, the following psychographic categories may be used: Travel, such as Air, Car Rental, Lodging; Reservations; and Maps; Finance/Investments such as Banking Brokers, Quotes, Insurance, and Mortgage; sports, such as Auto Racing, Baseball, Basketball, Fantasy Sports, Football, Hockey, Soccer, Golf, and Tennis; recreation &#x26; hobbies such as Cycling, Golf, Hiking, Sailing, Snow, Sports, Surfing, Tennis, Home &#x26; Garden, Pets, Genealogy, Photography, Games, and Toys; entertainment such as Movies/Film, Music, Theater, TV/Video, Sci-Fi, Humor, Games, and Toys; auto such as Trucks, SUV, and Sports car; news and information such as Magazines and Weather; politics such as Democrat and Republican; E-shopping such as Groceries, Furniture, Auctions, Cards/Gifts, Apparel, Books, Music, TV/Video; Software such as E-purchasing and Computers; Science; Employment; health &#x26; fitness; Medical; Pharmacy; Dating/Single; Advice; Beauty; Weddings; Maternity; or Spirituality/Religion such as Astrology. An example of profiling web users is described in U.S. Pat. No. 8,108,245 to Hosea et al., entitled: &#x201c;Method and System for Web User Profiling and Selectivve Content Delivery&#x201d;, which is incorporated in its entirety for all purposes as if fully set forth herein.</p><p id="p-0555" num="0557">A bitmap (a.k.a. bit array or bitmap index) is a mapping from some domain (for example, a range of integers) to bits (values that are zero or one). In computer graphics, when the domain is a rectangle (indexed by two coordinates) a bitmap gives a way to store a binary image, that is, an image in which each pixel is either black or white (or any two colors). More generally, the term &#x2018;bitmap&#x2019; is used herein to include, but not limited to, a pixmap, which refers to a map of pixels, where each one may store more than two colors, thus using more than one bit per pixel. A bitmap is a type of memory organization or image file format used to store digital images.</p><p id="p-0556" num="0558">In typical uncompressed bitmaps, image pixels are generally stored with a color depth of 1, 4, 8, 16, 24, 32, 48, or 64 bits per pixel. Pixels of 8 bits and fewer can represent either grayscale or indexed color. An alpha channel (for transparency) may be stored in a separate bitmap, where it is similar to a grayscale bitmap, or in a fourth channel that, for example, converts 24-bit images to 32 bits per pixel. The bits representing the bitmap pixels may be packed or unpacked (spaced out to byte or word boundaries), depending on the format or device requirements. Depending on the color depth, a pixel in the picture will occupy at least n/8 bytes, where n is the bit depth. For an uncompressed, packed within rows, bitmap, such as is stored in Microsoft DIB or BMP file format, or in uncompressed TIFF format, a lower bound on storage size for a n-bit-per-pixel (2n colors) bitmap, in bytes, can be calculated as: size=width&#xb7;height&#xb7;n/8, where height and width are given in pixels. In the formula above, header size and color palette size, if any, are not included.</p><p id="p-0557" num="0559">The BMP file format, also known as bitmap image file or Device Independent Bitmap (DIB) file format or simply a bitmap, is a raster graphics image file format used to store bitmap digital images, independently of the display device (such as a graphics adapter), especially on Microsoft Windows and OS/2 operating systems. The BMP file format is capable of storing 2D digital images of arbitrary width, height, and resolution, both monochrome and color, in various color depths, and optionally with data compression, alpha channels, and color profiles. The Windows Metafile (WMF) specification covers the BMP file format.</p><p id="p-0558" num="0560">An image scaling is the process of resizing a digital image. Scaling is a non-trivial process that involves a trade-off between efficiency, smoothness and sharpness. With bitmap graphics, as the size of an image is reduced or enlarged, the pixels that form the image become increasingly visible, making the image appear &#x201c;soft&#x201d; if pixels are averaged, or jagged if not. With vector graphics, the trade-off may be in processing power for re-rendering the image, which may be noticeable as slow re-rendering with still graphics, or slower frame rate and frame skipping in computer animation.</p><p id="p-0559" num="0561">Apart from fitting a smaller display area, image size is most commonly decreased (or subsampled or downsampled) in order to produce thumbnails. Enlarging an image (upsampling or interpolating) is generally common for making smaller imagery fit a bigger screen in fullscreen mode, for example. In &#x201c;zooming&#x201d; a bitmap image, it is not possible to discover any more information in the image than already exists, and image quality inevitably suffers. However, there are several methods of increasing the number of pixels that an image contains, which evens out the appearance of the original pixels. Typically scaling of an image, such as enlarging or reducing the image, involves manipulation of one or more pixels of the original image into one or more pixels in the target image. In many applications, image scaling is required to be executed in real-time, requiring processing power. Scaling or resizing of an image is typically measured as the ratio (in %, for example) of the number of pixels of the resulting image relative to the number of pixels in the original image. Some image scaling schemes are simple and may be quickly and efficiently processed, such as the examples shown in <figref idref="DRAWINGS">FIG. <b>36</b><i>a</i></figref>. An original image is shown in grid <b>362</b><i>a, </i>including an exemplary pixel <b>363</b>, and the image after image scaling of 400% is shown as grid <b>362</b><i>b, </i>where the single pixel <b>363</b> is manipulated into four pixels <b>363</b><i>a, </i><b>363</b><i>b, </i><b>363</b><i>c, </i>and <b>363</b><i>d </i>arranged as a 2&#xd7;2 square matrix. Similarly, each of the pixels in the original image is converted into 4 pixels arranged as a square, where all the newly generated pixels have the same bit value (&#x2018;0&#x2019; or &#x2018;1&#x2019;) in a bitmap, or the color value in case of multiple bits per pixel. Similarly, an original image is shown in grid <b>365</b><i>a, </i>including an exemplary pixel <b>364</b>, and the image after image scaling of 900% is shown as grid <b>365</b><i>b, </i>where the single pixel <b>364</b> is manipulated into nine pixels <b>364</b><i>a, </i><b>364</b><i>b, </i><b>364</b><i>c, </i><b>364</b><i>d, </i><b>364</b><i>e, </i><b>364</b><i>f, </i><b>364</b><i>g, </i><b>364</b><i>h, </i>and <b>364</b><i>i </i>arranged as a 3&#xd7;3 square. Similarly, each of the pixels in the original image is converted into 9 pixels arranged as a square, where all the newly generated pixels have the same bit value (&#x2018;0&#x2019; or &#x2018;1&#x2019;) in a bitmap, or the color value in case of multiple bits per pixel.</p><p id="p-0560" num="0562">Some image reduction schemes are simple and may be quickly and efficiently processed, such as the examples shown in <figref idref="DRAWINGS">FIG. <b>36</b><i>b</i></figref>. An original image is shown in grid <b>366</b><i>b, </i>including an exemplary 4 pixels <b>368</b><i>a, </i><b>368</b><i>b, </i><b>368</b><i>c, </i>and <b>369</b><i>d </i>arranged as a 2&#xd7;2 square, and the image after image downscaling of 25% is shown as grid <b>366</b><i>a, </i>where a single pixel <b>368</b> is represents the four pixels. Similarly, each group of 2&#xd7;2 pixels in the original image is converted into a single pixel, where all the newly generated pixels are an average of the original 4 pixels value (&#x2018;0&#x2019; or &#x2018;1&#x2019; in a bitmap, or the color value in case of multiple bits per pixel). Similarly, an original image is shown in a grid <b>367</b><i>b, </i>including an exemplary 9 pixels <b>369</b><i>a, </i><b>369</b><i>b, </i><b>369</b><i>c, </i><b>369</b><i>d, </i><b>369</b><i>e, </i><b>369</b><i>f, </i><b>369</b><i>g, </i><b>369</b><i>h, </i>and <b>369</b><i>i, </i>arranged as a 3&#xd7;3 square, and the image after image downscaling of 1/9 (11.11%) is shown as a single pixel <b>369</b> in the grid <b>367</b><i>a, </i>where the single pixel <b>369</b> represents the 9 pixels. Similarly, each 3&#xd7;3 pixels matrix in the original image is converted into a single pixel, where all the newly generated pixel is an average of the original 9 pixel value (&#x2018;0&#x2019; or &#x2018;1&#x2019; in a bitmap, or the color value in case of multiple bits per pixel).</p><p id="p-0561" num="0563">Referring now to a flowchart <b>360</b> in <figref idref="DRAWINGS">FIG. <b>36</b></figref>, which may be executed by any network element, describing a method for combining quick scaling schemes with another scaling scheme, for achieving quicker and more efficient downscaling scheme. The original image, designated as IMG(<b>0</b>) and the scaling requested (in %) is obtained in a &#x2018;Receive IMG(<b>0</b>), Scaling (%)&#x2019; step <b>361</b><i>a. </i>The parameter N is zeroed in an &#x2018;N&#x2190;0&#x2019; step <b>361</b><i>b, </i>denoting the flowchart initial state. If the scaling required is above 50% as is checked in a &#x2018;Scaling&#x3e;50%?&#x2019; step <b>361</b><i>c, </i>then the current image in the N-th cycle designated as IMG(N), is scaled using any scaling or resizing method in a &#x2018;Scale IMG(N)&#x2019; step <b>361</b><i>d, </i>and the method ends in an &#x2018;END&#x2019; step <b>361</b><i>e. </i>In the case the scaling required is below 50%, a 50% scaling is executed using a quick and simple scaling scheme as described above, in a &#x2018;Scale 50%&#x2019; step <b>361</b><i>f. </i>The cycle counter N is raised by 1 in a &#x2018;N&#x2190;N+1&#x2019; step <b>361</b><i>g, </i>and then the image is scaled 200% and the requested scaling (received in the initial &#x2018;Receive IMG(<b>0</b>), Scaling (%)&#x2019; step <b>361</b><i>a</i>) is doubled, in a &#x2018;Resize 200%, Scale&#x2190;Scale*2&#x2019; step <b>361</b><i>h, </i>and the process is repeated until the scaling is above 50%. In such a scheme, in case a scaling of 30% is required, a scaling of 50% will be followed by another scaling of 60% (30%*2), resulting a total of scaling of 30% as originally required.</p><p id="p-0562" num="0564">When using a graphics-based human interface, when an element is dragged from a location to another location on a screen, the dragging is typically limited by the outer limits of the parent object, as schematically shown in views <b>370</b><i>a </i>and <b>370</b><i>b </i>in <figref idref="DRAWINGS">FIG. <b>37</b></figref>. In the view <b>370</b><i>a, </i>a box-shaped object (<b>1</b>) <b>373</b> is located within the area of a parent object (<b>2</b>) <b>372</b>, which in turn is within the area of its parent object (<b>3</b>) <b>371</b>. A user may attempt to drag the object (<b>1</b>) <b>373</b> to a left bottom corner of the screen, as illustrated by the hand <b>375</b> and the dashed line <b>374</b>, to a location which is external to the object (<b>3</b>) <b>371</b> defined area. In many cases, the dragging of the object (<b>1</b>) <b>373</b> may not exceed its parent object (<b>2</b>) <b>372</b> periphery, and thus the dragging is limited to the left bottom limit of the object (<b>2</b>) <b>372</b> as shown in view <b>370</b><i>b. </i>It may be beneficial to allow the object (<b>1</b>) <b>373</b> to be dragged as requested by the user along the dragging line <b>374</b> to the left bottom corner as shown by view <b>370</b><i>c </i>in <figref idref="DRAWINGS">FIG. <b>37</b><i>a</i></figref>. In one example, such dragging external to a limited low-level object area may be executed by transferring (or &#x2018;inheriting&#x2019;) the dragging request to higher level objects (such as object (<b>2</b>) <b>372</b> and object (<b>3</b>) <b>371</b>, where such dragging is allowed.</p><p id="p-0563" num="0565">Referring now to a flowchart <b>380</b> shown in <figref idref="DRAWINGS">FIG. <b>38</b></figref>, which may be executed by any network element, and is schematically describing the transfer of a dragging request to higher levels until such dragging is allowed. The element to be dragged is identified as an object (<b>1</b>) in a &#x2018;Receive Object (<b>1</b>)&#x2019; step <b>381</b><i>a, </i>located in a current located designated as (current_X, current_Y), denoting the (x,y) coordinated on the screen. For example, object (<b>1</b>) <b>373</b> (shown in views <b>370</b><i>a </i>and <b>370</b><i>b</i>) and its associated current coordinates are identified. The new location coordinates, designated as (new_X, new_Y) to which the object (<b>1</b>) is to be dragged (such as the drag line <b>374</b>), is received in a &#x2018;Receive New Location&#x2019; step <b>381</b><i>b, </i>hence a requested movement can be calculated as (new_X&#x2212;current_X, new_Y&#x2212;current_+Y). The cycles of the flowchart <b>380</b> are monitored by a cycle counter N, which is set to 1 at a &#x2018;N&#x2190;1&#x2019; step <b>381</b><i>c. </i></p><p id="p-0564" num="0566">In a &#x2018;Location Beyond Object (N+1) Limits?&#x2019; step <b>381</b><i>d </i>the requested new location (new_X, new_Y) is checked to be within the limits of the parent (object (N+1)) of the current object (N). For example, the object (<b>1</b>) <b>373</b> new location is checked to be within the limits of object (<b>2</b>) <b>372</b>. In the case where the requested new location exceeds the limits of the parent (object (N+<b>1</b>)), the counter N in raised by 1 in a &#x2018;N&#x2190;N+1&#x2019; step <b>381</b><i>e, </i>and the check is repeated with the new object in a &#x2018;Location Beyond Object (N+1) Limits?&#x2019; step <b>381</b><i>d. </i>In the example shown in view <b>370</b><i>a, </i>the required new location is outside the area of an object (<b>2</b>) <b>372</b>, hence the counter will be increased, and the new location will now be checked versus the object (<b>3</b>) <b>371</b>. In a case where the new location (new_X, new_Y) is found to be within the limits of the parent (object (N+1)), then in a &#x2018;Move Objects (<b>1</b>, <b>2</b>, . . . N) to New Location&#x2019; step <b>381</b><i>f </i>the object (<b>1</b>), as well as all its parent objects, such as object (<b>2</b>), object (<b>3</b>), . . . object (N), are shifted according to dragging requested (new_X&#x2212;current_X, new_Y&#x2212;current+Y), so that the object (<b>1</b>) reaches the required new location (new_X, new_Y). Such movement is exampled in a view <b>370</b><i>c, </i>where the object (<b>1</b>) <b>373</b> is shown in its new location, and where the object (<b>2</b>) <b>372</b> is shown also after being moved as required in order to allow for the object (<b>1</b>) <b>373</b> movement.</p><p id="p-0565" num="0567">Any device herein may be connected to the Internet using a wireless access, such as via a WLAN, such as the device <b>11</b><i>a </i>shown in an arrangement <b>20</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>2</b><i>b</i></figref>. In one example shown in an arrangement <b>390</b> in <figref idref="DRAWINGS">FIG. <b>39</b></figref>, a device <b>391</b> (which may correspond to any device or network element herein) may be in the range of 3 WAPs <b>26</b><i>b, </i><b>26</b><i>c </i>and <b>26</b><i>d, </i>which are all password protected, and each of the WAPs is allowing connection to the Internet. In a case where the user of the device <b>391</b> is not aware of the password, no connection to the Internet is easily available. In an emergency, where no other communication means are available, there may be an urgent need to communicate via one of the WAPs, such as to the Internet, for example in order to call for help. In such a case, it may be beneficial to guess a password used by one (or more) of the WAPs, in order to be able to communicate over the Internet (or any other network backbone). The device <b>391</b> may include locally (such as in storage memory <b>25</b><i>c</i>), or be connected to, a database <b>392</b>, which may comprise a list of passwords that may be suitable for use with the WAPs. The database <b>392</b> may be periodically updated by the device <b>391</b>, or may be updated by accessing and fetching passwords from other databases over the Internet.</p><p id="p-0566" num="0568">A flowchart <b>400</b> in <figref idref="DRAWINGS">FIG. <b>40</b></figref>, which may be executed by any network element, describes a method for guessing passwords, for example to be used for communicating via WAPs, based on a geographical location, a user history, or a WAP vendor. Starting in a &#x2018;Select WAP&#x2019; step <b>401</b><i>a, </i>one of the WAPs is selected. In the case of a presence of a single WAP, it is the one to select. If few WAPs are available, such as in the system <b>390</b> shown in <figref idref="DRAWINGS">FIG. <b>39</b></figref>, one of the WAPs is selected, such as WAP <b>26</b><i>b, </i>randomly or according to set criteria. The selected WAP is then checked to be password protected in a &#x2018;Password Protected?&#x2019; step <b>401</b><i>b. </i>Upon detecting that the WAP is not &#x2018;locked&#x2019; and no password is thus not required, a connection with the selected WAP is established in a &#x2018;Connect&#x2019; step <b>401</b><i>c, </i>and the device (such as the device <b>391</b>) may then communicate via the selected WAP (such as the WAP <b>26</b><i>b</i>) over the Internet.</p><p id="p-0567" num="0569">Commonly users or devices in a certain geographical location (such as city or country) are more likely to use certain passwords, due to the tendency of the local population (having similar demographics, for example), to choose similar or same words. Hence, in a case wherein the selected WAP is password-protected, the device <b>391</b> fetches from the database <b>392</b> and tries various passwords associated with the local geographical location in a &#x2018;Location Based&#x2019; step <b>401</b><i>d. </i>If one of the tried guessed password is indeed successful, and a connectivity is achieved with the selected WAP, as checked in an &#x2018;Access?&#x2019; step <b>401</b><i>e, </i>then a connection to the selected WAP is established in a &#x2018;Connect&#x2019; step <b>401</b><i>c, </i>and the device (such as device <b>391</b>) may then communicate via the selected WAP (such as WAP <b>26</b><i>b</i>) over the Internet. In order to simplify remembering and handling multiple passwords, users commonly use the same password or a minimal set of correlated passwords for many purposes. Hence, in the case none of the location based guessed passwords was found suitable, the device <b>391</b> fetches from database <b>392</b> a list of passwords that were previously used, even if used for another WAP. If one of the tried guessed password is indeed successful, and connectivity is achieved with the selected WAP, as checked in an &#x2018;Access?&#x2019; step <b>401</b><i>g</i>, a connection with the selected WAP is established in a &#x2018;Connect&#x2019; step <b>401</b><i>c, </i>and the device (such as device <b>391</b>) may then communicate via the selected WAP (such as WAP <b>26</b><i>b</i>) over the Internet. Typically WAPs are manufactured and shipped having a default (vendor set) password. In many cases, the user of a WAP does not change the default password, and the database <b>392</b> may store a list of such default passwords, associated with various manufacturers and WAP types. Typically, as part of communicating with a WAP, the WAP type (e.g., model number) or the WAP manufacturer identifier or name (or both), are exchanged as part of the handshaking process. In a &#x2018;Vendor Based&#x2019; step <b>401</b><i>h, </i>the device <b>391</b> tries a list of passwords based on the WAP type or vendor, or based on a list of all known manufacturers default values. If one of the tried guessed password is indeed successful, and connectivity is achieved with the selected WAP, as checked in an &#x2018;Access?&#x2019; step <b>401</b><i>i, </i>a connection with the selected WAP is established in a &#x2018;Connect&#x2019; step <b>401</b><i>c, </i>and the device (such as the device <b>391</b>) may then communicate via the selected WAP (such as the WAP <b>26</b><i>b</i>) over the Internet. If none of the former password guessing techniques is successful, and in case other WAPs are available, the device <b>391</b> may select another WAP, such as WAP <b>26</b><i>c </i>in system <b>390</b>, in a &#x2018;Select Another WAP&#x2019; step <b>401</b><i>j, </i>and repeat the passwords guessing with the newly selected WAP.</p><p id="p-0568" num="0570">Referring to <figref idref="DRAWINGS">FIG. <b>41</b></figref> showing a system <b>400</b><i>a, </i>which is based on the system <b>390</b> shown in <figref idref="DRAWINGS">FIG. <b>39</b></figref>, comprising also a locked WAP <b>26</b><i>e </i>and a locked WAP <b>26</b><i>f. </i>The system is shown to include two devices, a device #<b>1</b> <b>391</b><i>a </i>(which may correspond to device <b>391</b> in the system <b>390</b>) having a password database <b>392</b><i>a </i>in the memory, and a device #<b>2</b> <b>391</b><i>b </i>(which may also correspond to device <b>391</b> in the system <b>390</b>) having a password database <b>392</b><i>b </i>in the memory. The device #<b>1</b> <b>391</b><i>a </i>is located in the range of the WAP <b>26</b><i>d, </i>and may communicate with this WAP over a WiFi communication link <b>404</b><i>d, </i>is located in the range of the WAP <b>26</b><i>b, </i>and may communicate with this WAP over a WiFi communication link <b>404</b><i>b, </i>and is located in the range of WAP <b>26</b><i>c, </i>and may communicate with this WAP over a WiFi communication link <b>404</b><i>c. </i>Similarly, the device #<b>2</b> <b>391</b><i>b </i>is located in the range of the WAP <b>26</b><i>b, </i>and may communicate with this WAP over a WiFi communication link <b>404</b><i>a, </i>is located in the range of the WAP <b>26</b><i>c, </i>and may communicate with this WAP over a WiFi communication link <b>404</b><i>g, </i>is located in the range of the WAP <b>26</b><i>e</i>, and may communicate with this WAP over a WiFi communication link <b>404</b><i>e, </i>and is located in the range of the WAP <b>26</b><i>f, </i>and may communicate with this WAP over a WiFi communication link <b>404</b><i>f. </i>Hence, both two devices <b>391</b><i>a </i>and <b>391</b><i>b </i>may communicate with the WAPs <b>26</b><i>b </i>and <b>26</b><i>c. </i>The two devices may share information about the authentication with these WAPs. Furthermore, an authentication server <b>403</b> may include a database <b>392</b><i>c </i>storing passwords (and other authentication means), and may share the database <b>392</b><i>c </i>with the two devices <b>391</b><i>a </i>and <b>391</b><i>b. </i></p><p id="p-0569" num="0571">For each of the communication links, a device may assign a level of sharing, associated with the intention of a user of the device to share the passwords, stored in the local database or stored in the database <b>392</b><i>c </i>of the authentication server <b>403</b>, with other users or devices. For example, the device #<b>1</b> <b>391</b><i>a </i>may assign a level of &#x2018;Private&#x2019; to the communication link <b>404</b><i>d </i>with the WAP <b>26</b><i>d, </i>denoting that the password (or other credentials) associated with this connection is not to be shared with others, for example, since the WAP <b>26</b><i>d </i>is the user private network at home. Similarly, the user of the device #<b>2</b> <b>391</b><i>b </i>may assign a level of &#x2018;Private&#x2019; to the communication links <b>404</b><i>e </i>and <b>404</b><i>f. </i>Alternatively or in addition, a device (such as the device #<b>1</b> <b>391</b><i>a </i>or the device #<b>2</b> <b>391</b><i>b</i>) may assign a level of &#x2018;Friends&#x2019; to a password, associated with an intention to share the available password with a limited number of devices or users ('friends'), as shown regarding to communication links <b>404</b><i>c </i>and <b>404</b><i>g </i>in the system <b>400</b><i>a. </i>Further, a device (such as the device #<b>1</b> <b>391</b><i>a </i>or the device #<b>2</b> <b>391</b><i>b</i>) may assign a level of &#x2018;All&#x2019; to a password, associated with an intention to share the available password with any device or user, as shown regarding to communication links <b>404</b><i>a </i>and <b>404</b><i>b </i>in the system <b>400</b><i>a. </i>The user and authentication database <b>392</b><i>c </i>keeps the connection levels between the users of the system (i.e., who is friends with who). The clients update this central database <b>392</b><i>c </i>when new authentication information about a WAP is acquired, such as when the authentication information no longer works, or when updated or new authentication information is known. Once deployed in large numbers, the size of the authentication database <b>392</b><i>c </i>becomes significant and large. Thus the update from the central database <b>392</b><i>c </i>to the clients can be done in parts, such as loading only the information that a device is most likely to require, for example, to limit the size of the database to local geography, and/or by getting all access points located in close proximity to all (or popular) points of entries in various countries. For example, a device may periodically connect to the central database <b>392</b><i>c, </i>and may fetch therefrom an update of list of relevant passwords, and store these passwords in the local database, such as the database <b>392</b><i>a </i>or <b>392</b><i>b. </i>Further, the device may also update the central database <b>392</b><i>c </i>of any new information it has acquired regarding authentication methods (such as passwords) regarding to various WAPs. The size of the information that is loaded into the device may be limited, and the device may get an update on authentication information only regarding to WAPs that may be of interest to that device.</p><p id="p-0570" num="0572">A flowchart <b>400</b><i>b </i>shown in <figref idref="DRAWINGS">FIG. <b>42</b></figref> describes an example of the system <b>400</b><i>a </i>operation. In a &#x2018;WAP connection&#x2019; step <b>402</b><i>a, </i>a request from a device (such as the device #<b>1</b> <b>391</b><i>a </i>or the device #<b>2</b> <b>391</b><i>b</i>) to connect to a WAP (such as the WAP <b>26</b><i>d </i>or the WAP <b>26</b><i>f</i>) is intercepted, typically in order to access the Internet. First, using a protocol handshake or any other scheme, the device checks if authentication is required by the specific WAP, as part of an &#x2018;Authentication Required?&#x2019; step <b>402</b><i>b. </i>If no authentication is required, the device may connect to the WAP in a &#x2018;Connect&#x2019; step <b>402</b><i>c. </i>In the case the WAP required authentication for connecting to, the device checks the local authentication database (such as the database <b>391</b><i>a </i>or the database <b>391</b><i>b</i>), as part of a &#x2018;Locally Stored?&#x2019; step <b>402</b><i>d. </i>If the relevant authentication information is locally available, the device may connect using this information in a &#x2018;Connect Using Local Data&#x2019; step <b>402</b><i>e. </i>In the case of successful connection to the WAP, as checked in a &#x2018;Successful?&#x2019; step <b>402</b><i>i, </i>the device may send an update to the central database <b>392</b><i>c </i>in the authentication server <b>403</b>, notifying or updating it regarding the validity and regarding the authentication information associated with the WAP.</p><p id="p-0571" num="0573">In the case there is no locally available password regarding the respective WAP, the device may connect to the authentication server <b>403</b> for fetching authentication information from the central database <b>392</b><i>c. </i>The server <b>403</b> checks the availability of the requested password in a &#x2018;Server Stored?&#x2019; step <b>402</b><i>g. </i>If no authentication information is found to be stored in the central database <b>392</b><i>c, </i>the authentication server <b>403</b> accordingly replies to the requesting device. Upon receiving of the server <b>403</b> response, the device may be prompted that no authentication information is available for the WAP, in a &#x2018;No Success&#x2019; step <b>402</b><i>k. </i>The user then may select another WAP (if available), and repeat the process (with the newly selected WAP) as part of the &#x2018;WAP Connection&#x2019; step <b>402</b><i>a. </i></p><p id="p-0572" num="0574">Alternatively or in addition, the device may try the password of the WAP in a &#x2018;Guess Password&#x2019; step <b>402</b><i>i, </i>and such guessing scheme may consist of, include, or be based on, the guessing method described in the flowchart <b>400</b> in <figref idref="DRAWINGS">FIG. <b>40</b></figref>. If the password guessing in the &#x2018;Guess Password&#x2019; step <b>402</b><i>i </i>is successful, as checked in a &#x2018;Successful?&#x2019; step <b>402</b><i>j, </i>the device may send the successfully guessed password to the server <b>403</b> to be stored in the database <b>392</b><i>c, </i>as part of an &#x2018;Update Database&#x2019; step <b>402</b><i>m, </i>so this password may be used by other devices (if allowed) when connecting to this WAP. In the case wherein a password is stored in the central database <b>392</b><i>c </i>for this WAP, the authentication server <b>403</b> fetches the stored password, and sends it to the requesting device, which then uses this password for connecting to the WAP, in a &#x2018;Receive from Server &#x26; Connect&#x2019; step <b>402</b><i>h. </i>If the connection is successful, as checked in a &#x2018;Successful?&#x2019; step <b>402</b><i>l, </i>the device may send a message to the server <b>403</b>, notifying it that the password fetched is indeed valid. However, if the connection is not successful, for example, since the password was changed or is otherwise not valid, the device may send this information to the server <b>403</b>, allowing it to delete the non-valid password from the central database <b>392</b><i>c, </i>in a &#x2018;Delete from database&#x2019; step <b>402</b><i>n. </i></p><p id="p-0573" num="0575">As part of sending the authentication server <b>403</b> a new password, such as in &#x2018;Update Database&#x2019; step <b>402</b><i>m, </i>the sending device may associate a level of sharing with such password, such as &#x2018;Private&#x2019; (i.e., don't share with anyone), Friends' (i.e., only share with friends), &#x2018;Family&#x2019; (i.e. only share with family), or &#x2018;All&#x2019;. When fetching a password from the central database <b>392</b><i>c, </i>such as in &#x2018;Request from Server&#x2019; step <b>402</b><i>f, </i>the server <b>403</b> returns the stored password only if the requesting device is authorized to receive this information. For example, if the password is marked as &#x2018;Friends&#x2019;, only devices (or users) that are identified as &#x2018;friends&#x2019; may fetch the stored password.</p><p id="p-0574" num="0576">Referring to an architecture <b>440</b> shown in <figref idref="DRAWINGS">FIG. <b>44</b></figref>, which is based on the architecture <b>430</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, describing an example of a software and hardware interface in a WDM-based operating system, which may be part of any device (or server) described herein. In the arrangement <b>440</b>, the device may assume the role of a tunnels-using client device (such as the client device #<b>1</b> <b>31</b><i>a </i>or the client device #<b>2</b> <b>31</b><i>b</i>) and thus executes a &#x2018;Client (Tunnel) Flowchart&#x2019; <b>441</b><i>a, </i>which may be a part of, or the whole of, the client device related flowcharts, such as the flowchart <b>60</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the flowchart <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, or the flowchart <b>100</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>10</b><i>a</i></figref>. Alternatively or in addition, the device may assume the role of a Peers/Agents-using client device (such as the client device #<b>1</b> <b>201</b><i>a</i>) and thus executes a &#x2018;Client (Peers) Flowchart&#x2019; <b>441</b><i>a, </i>which may be a part of, or the whole of, the client device related flowcharts, such as the flowcharts <b>230</b>, <b>230</b><i>a, </i>and <b>230</b><i>b, </i>respectively shown in <figref idref="DRAWINGS">FIGS. <b>23</b>, <b>23</b></figref><i>a</i>, and <b>23</b><i>b</i>. Alternatively or in addition, the device may assume the role of a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a, </i>the tunnel device #<b>2</b> <b>33</b><i>b, </i>or the tunnel device #<b>3</b> <b>33</b><i>c</i>), and thus executes a &#x2018;Tunnel Flowchart&#x2019; <b>441</b><i>c, </i>which may be a part of, or the whole of, the tunnel device related flowcharts, such as the flowchart <b>70</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. Alternatively or in addition, the device may assume the role of an agent device (such as the agent device #<b>1</b> <b>103</b><i>a, </i>the agent device #<b>2</b> <b>103</b><i>b, </i>or the agent device #<b>3</b> <b>103</b><i>c</i>), and thus executes an &#x2018;Agent Flowchart&#x2019; <b>441</b><i>d, </i>which may be a part of, or the whole of, the agent device related flowcharts, such as the flowchart <b>240</b> shown in <figref idref="DRAWINGS">FIG. <b>24</b></figref>. Alternatively or in addition, the device may assume the role of a peer device (such as the peer device #<b>1</b> <b>102</b><i>a, </i>the peer device #<b>2</b> <b>102</b><i>b, </i>or the peer device #<b>3</b> <b>102</b><i>c</i>), and thus executes a &#x2018;Peer Flowchart&#x2019; <b>441</b><i>e, </i>which may be a part of, or the whole of, the agent device related flowcharts, such as the flowchart <b>240</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>24</b><i>a</i></figref>. Similarly, the device may execute a web browser application <b>441</b><i>f, </i>that may use the acceleration applications above for faster operation.</p><p id="p-0575" num="0577">While the arrangement <b>10</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> includes a single communication interface <b>29</b> connecting to a LAN <b>14</b>, currently many computerized devices and systems include multiple communication interfaces, such as Communication Interface #<b>1</b> <b>443</b><i>a, </i>Communication Interface #<b>2</b> <b>443</b><i>b, </i>and Communication Interface #<b>3</b> <b>443</b><i>c, </i>shown as part of the architecture <b>440</b> (corresponding to the peripherals #<b>1</b> <b>439</b><i>a, </i>#<b>2</b> <b>439</b><i>b, </i>and #<b>3</b> <b>439</b><i>c, </i>shown as part of the architecture <b>430</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>). While three (3) interfaces are shown, any number of such interfaces may be equally used. Typically, each communication interface enables communication over a distinct network type, so that the multiple communication interfaces allow for concurrent communication over multiple networks. Each network may be a wired network, which is based on conductive medium, such as a coaxial cable, twisted-pair, powerlines, or telephone lines, or may be a wireless network which is based on a non-conductive medium, and is using RF, light, or sound guided, or any other over-the-air propagation. Further, a network may be NFC, PAN, LAN, MAN, WAN, WPAN, WLAN (such as WiFi), WMAN, or WWAN. Further, the communication may be based on a cellular communication. A network may be half-duplex, full-duplex, or unidirectional, and may use modulation such as AM, FM, or PM. Furthermore, a network may be packet-based or circuit-switched. The various communication interfaces and the respective protocols are serviced by the kernel space <b>430</b><i>b </i>Communications Drivers Stack <b>442</b> (corresponding to the drivers stack <b>436</b> shown in the architecture <b>430</b>). The data to be sent or received via the communication interfaces is transferred via applicable queues serving to buffer the transferred data, such as an OS Queue #<b>1</b> <b>443</b><i>a, </i>an OS Queue #<b>2</b> <b>443</b><i>b, </i>and an OS Queue #<b>3</b> <b>443</b><i>c, </i>using underlying sockets such as a Socket #<b>1</b> <b>444</b><i>a </i>serving OS Queue #<b>1</b> <b>443</b><i>a, </i>a Socket #<b>2</b> <b>444</b><i>b </i>serving OS Queue #<b>2</b> <b>443</b><i>b, </i>and a Socket #<b>3</b> <b>444</b><i>c </i>serving OS Queue #<b>3</b> <b>443</b><i>c. </i>A queue (such as queue #<b>1</b> <b>443</b><i>a</i>) may be loaded with data, such as data to be sent, and next data that may use the same queue may need to wait until the former data in that queue is vacated, and only then the newly introduced data will be handled. In one example, the allocation of data to the queues may be static, and not changing in time. Alternatively or in addition, the allocation to the various OS queues may be adaptive. For example, at the same time the first data is handled, another queue (such as queue #<b>2</b> <b>443</b><i>b</i>) may be empty, and thus may be used for faster handling of the new data. An adaptive queue mechanism is described, for example, in U.S. Patent Application No. 2006/0187830 to Nam, entitled: &#x201c;Adaptive Queue Mechanism for Efficient Realtime Packet Transfer and Adaptive Queue Establishment System thereof&#x201d;, and improved technique for handling events in a multipathing system employing event queueing is described in U.S. Pat. No. 8,452,901 to Sandstrom et al., entitled: &#x201c;Ordered Kernel Queue for Multipathing Events&#x201d;, which are all incorporated in their entirety for all purposes as if fully set forth herein.</p><p id="p-0576" num="0578">An adaptive system involving real-time moving data between sockets and queues upon their availability is shown as an architecture <b>457</b> in <figref idref="DRAWINGS">FIG. <b>45</b></figref>, which may be part of any network element. Dynamic queues are added to the transmit data path, from an application (in the User Space) and the communication interfaces, allowing better usage of the system resources, in particular the various sockets and OS queues. A Dynamic Queue #<b>1</b> <b>459</b><i>a </i>is added to cooperated with the OS queue #<b>1</b> <b>443</b><i>a </i>and the socket #<b>1</b> <b>444</b><i>a, </i>a Dynamic Queue #<b>2</b> <b>459</b><i>b </i>is added to cooperated with the OS queue #<b>2</b> <b>443</b><i>b </i>and the socket #<b>2</b> <b>444</b><i>b, </i>and a Dynamic Queue #<b>3</b> <b>459</b><i>c </i>is added to cooperated with the OS queue #<b>3</b> <b>443</b><i>c </i>and the socket #<b>3</b> <b>444</b><i>c. </i>The dynamic queues are data allocated, managed, and supervised by a Dynamic Queues Manager <b>458</b> added software module, which may execute a flowchart <b>460</b> shown in <figref idref="DRAWINGS">FIG. <b>46</b></figref>. The dynamic queues manager <b>458</b> checks the status of the queues and sockets in the system, and shifts the data to be transmitted between the various queues and sockets to obtain higher system efficiency. For example, in a case one queue is loaded while another queue is empty, the manager <b>458</b> may remove data from a loaded queue and shifts the data to the empty one.</p><p id="p-0577" num="0579">The flowchart <b>460</b>, which may be executed by any network element, starts at a &#x2018;Data to Send&#x2019; step <b>461</b><i>a, </i>where data to be sent from the device is intercepted from an application. In a &#x2018;Obtain Sockets Status&#x2019; step <b>461</b><i>b, </i>the status of all sockets (and related queues) is checked. For example, if the data was already loaded into one of the queues relating to a socket, the waiting time for the socket to transmit all loaded data is estimated. Further, the characteristics of the socket and its underlying communication interface, such as BW and RTT (based on previous transactions), is also fetched. Based on the obtained information in the &#x2018;Obtain Sockets Status&#x2019; step <b>461</b><i>b, </i>one of the sockets is selected as the optimal one, in a &#x2018;Select Optimal Socket&#x2019; step <b>461</b><i>c. </i>The optimal socket (and related queues) may be selected based on the time it is estimated that the data will be fully transmitted from the device and the applicable queues will be rendered empty. The selected optimal socket route queues are then checked in an &#x2018;Empty?&#x2019; step <b>461</b><i>d </i>to be empty. In the case the optimal socket is empty, the data is routed to the selected socket, such as to the OS queue #<b>1</b> <b>443</b><i>a, </i>to be queued for being sent via the socket #<b>1</b> <b>444</b><i>a </i>and a respective communication interface, in an &#x2018;Add to Queue&#x2019; step <b>461</b><i>e. </i>In the case the selected route via the socket (e.g., socket #<b>1</b> <b>444</b><i>a</i>) is not empty, the manager <b>458</b> checks in a &#x2018;Cancelled?&#x2019; step <b>461</b><i>f </i>whether the data that is currently stored in that route has been cancelled by the application that requested this data transfer, or whether it was previously cancelled by the manager <b>458</b>. In the case the data transmitting was indeed cancelled, the respective cancelled operation is cancelled and the data is removed from the queues in a &#x2018;Remove Data&#x2019; step <b>461</b><i>g, </i>and the new data to be sent is loaded to be transmitted via this route, in the &#x2018;Add to Queue&#x2019; step <b>461</b><i>e. </i>In the case the data transmitting process has not been cancelled, the socket (and its respective queues) is declared as unavailable in a &#x2018;Socket Unavailable&#x2019; step <b>461</b><i>h</i>, and another optimal socket (different from the last selected one) is selected in the &#x2018;Select Optimal Socket&#x2019; step <b>461</b><i>c. </i></p><p id="p-0578" num="0580">Any transfer of data between any two network elements, may use, or be based on, a compression scheme (which may be any compression scheme), such as the communication between a client device (such as the client device #<b>1</b> <b>31</b><i>a</i>) and the acceleration server <b>32</b>, that is a part of the illustrated messaging chart <b>50</b>, such as the &#x2018;Sign in&#x2019; <b>56</b><i>b, </i>&#x2018;Request List&#x2019; <b>56</b><i>c, </i>&#x2018;Send List&#x2019; <b>56</b><i>d, </i>or any other communications between these elements. Alternatively or in addition, the same or other compression scheme may be used in the communication between a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>) and the acceleration server <b>32</b>, that is a part of the illustrated messaging chart <b>50</b>, such as the &#x2018;Sign in&#x2019; <b>56</b><i>a </i>or any other communications between these elements. Alternatively or in addition, the same or other compression scheme may be used in the communication between a client device (such as the client device #<b>1</b> <b>31</b><i>a</i>) and a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>), that is a part of the illustrated messaging in the timing chart <b>50</b>, such as the &#x2018;Initiate Pre-Connection&#x2019; <b>56</b><i>e, </i>&#x2018;Pre-Connection&#x2019; <b>56</b><i>f, </i>&#x2018;Content Request&#x2019; <b>56</b><i>g, </i>&#x2018;Send Content&#x2019; <b>56</b><i>j, </i>or any other communications between these elements. Alternatively or in addition, the same or other compression scheme may be used in the communication between a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>) and a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>), that is a part of the illustrated messaging chart <b>50</b>, such as the &#x2018;Content Request&#x2019; <b>56</b><i>h, </i>&#x2018;Send Content&#x2019; <b>56</b><i>i, </i>or any other communications between these elements.</p><p id="p-0579" num="0581">Alternatively or in addition, the same or other compression scheme may be used in the communication between an agent device (such as the agent device #<b>1</b> <b>103</b><i>a</i>) and the acceleration server <b>202</b>, that is a part of the illustrated messaging chart <b>220</b>, such as the &#x2018;Sign In&#x2019; <b>226</b><i>a, </i>or any other communications between these elements. Alternatively or in addition, the same or other compression scheme may be used in the communication between a client device (such as the client device #<b>1</b> <b>210</b><i>a</i>) and the acceleration server <b>202</b>, that is a part of the illustrated messaging chart <b>220</b>, such as the &#x2018;Sign In&#x2019; <b>226</b><i>d, </i>&#x2018;Request List&#x2019; <b>226</b><i>e, </i>&#x2018;Send List&#x2019; <b>226</b><i>f, </i>or any other communications between these elements. Alternatively or in addition, the same or other compression scheme may be used in the communication between a client device (such as the client device #<b>1</b> <b>210</b><i>a</i>) and an agent device (such as the agent device #<b>1</b> <b>103</b><i>a</i>), that is a part of the illustrated messaging chart <b>220</b>, such as the &#x2018;Request List&#x2019; <b>226</b><i>g, </i>&#x2018;Send List&#x2019; <b>226</b><i>h, </i>or any other communications between these elements. Alternatively or in addition, the same or other compression scheme may be used in the communication between a client device (such as the client device #<b>1</b> <b>210</b><i>a</i>) and a peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>), that is a part of the illustrated messaging chart <b>220</b>, such as the &#x2018;Chunk Request&#x2019; <b>226</b><i>i, </i>&#x2018;Send Chunk&#x2019; <b>226</b><i>j, </i>or any other communications between these elements.</p><p id="p-0580" num="0582">The same compression scheme may be used in all of the above communications. Alternatively or in addition, no compression or different compression scheme may be used in each of the above communication. A compression scheme used may be lossy or lossless (non-lossy). Further, a compression scheme may be a dictionary-based scheme. Furthermore, the compression may be according to, or based on, a standard compression algorithm which may be JPEG (Joint Photographic Experts Group) and MPEG (Moving Picture Experts Group), ITU-T H.261, ITU-T H.263, ITU-T H.264, or ITU-T CCIR 601. Further, the compression scheme may be according to, or based on, Lempel-Ziv (LZ) or Huffman encoding (or both) compression methods, such as LZ, DEFLATE, SHRI, LZX, or LZW. Further, a dictionary-based compression scheme may be used that is according to, or based on, a local dictionary as described herein. In the case wherein the data transferred consists of, or include, video data, the compression scheme may be an intraframe or interframe compression.</p><p id="p-0581" num="0583">Devices communicating over a network, such as over the Internet <b>113</b>, may include the same software components or applications, such as the same operating system or the same web browser, and may further retrieve and store the same or similar content from the Internet <b>113</b>. Such stored content similarities may be used in order to build a dictionary to use in a lossless compression scheme.</p><p id="p-0582" num="0584">Referring now to a lossless dictionary-based system <b>470</b><i>b </i>shown in <figref idref="DRAWINGS">FIG. <b>47</b></figref>, which is based on the system <b>470</b> shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In addition to the shared dictionary <b>473</b><i>a, </i>the encoder <b>474</b><i>a </i>(corresponding to the encoder <b>474</b>) shown as part of the encoding device <b>471</b><i>a </i>(corresponding to the encoding device <b>471</b>) which may be part of any network element, is using also a local dictionary <b>478</b><i>a. </i>The compression may use only the shared dictionary <b>473</b><i>a, </i>only the local dictionary <b>478</b><i>a, </i>or both. Similarly, the decoder <b>477</b><i>a </i>(corresponding to the encoding device <b>471</b><i>a</i>) shown as part of the decoding device <b>472</b><i>a </i>(corresponding to the decoding device <b>472</b>) which may be part of any network element, is using also a local dictionary <b>478</b><i>b. </i>Further, the decoding device <b>472</b><i>a </i>which is the receiving device, may transmit feedback over connection <b>479</b><i>b </i>of the decoding device <b>472</b><i>a, </i>communicating over the network <b>480</b> to the connection <b>479</b><i>a </i>of the encoding device <b>471</b><i>a. </i></p><p id="p-0583" num="0585">The building of the local dictionaries <b>478</b><i>a </i>and <b>478</b><i>b </i>in the respective encoding device <b>471</b><i>a </i>and the decoding device <b>472</b><i>a </i>is shown as a &#x2018;Local Dictionary Building&#x2019; flowchart <b>481</b> in <figref idref="DRAWINGS">FIG. <b>48</b></figref>, which may be executed by any network element. In the first step (such as upon a device power-up or upon launching the respective application), the device allocates a storage space in its memory (such as in its storage device <b>25</b><i>c</i>) for the local dictionary in an &#x2018;Allocate Memory&#x2019; step <b>481</b><i>a. </i>For example, a buffer of the size of 1 GB may be allocated for serving as a dictionary. Alternatively or in addition, a portion of an available hard-disk storage area may be allocated. Next, a local dictionary (such as dictionaries <b>478</b><i>a </i>and <b>478</b><i>b</i>) is built in each of the devices in a &#x2018;Build Local Dictionary&#x2019; step <b>481</b><i>b. </i>The device (such as the encoding device <b>471</b><i>a </i>or the decoding device <b>472</b><i>a</i>) scans the content stored in all its storage devices, such as the storage device <b>25</b><i>c, </i>the main memory <b>25</b><i>a, </i>and the ROM <b>25</b><i>b, </i>and partition it into chunks. The partition into chunks may involve the chunks being non-overlapping, equally-sized parts. In one example, a chunk size may be 2 KB (Kilo-Bytes), and in the case the content to be partitioned is not an exact multiple of 2 KB, the &#x2018;last&#x2019; chunk will padded and filled with &#x2018;space&#x2019; characters (or any other no content data). Each of the content in the chunks is identified by a chunk identifier, where each chunk identifier is associated with one, and only one, chunk, and the local dictionary stores the identifiers for the chunks. The identifiers of the chunks may be their calculated checksum, or the CRC of the content of the chunk is calculated, and used as the chunk identifier. For example, CRC-32 may be used, allowing each chunk (such as 16 KB size) to be identified by 33-bit identifier. Alternatively or in addition, a chunk identifier is based on a hash function of the chunk content. Since the same rules regarding partitioning into chunks and identifying the chunks are used by both the encoding device <b>471</b><i>a </i>and the decoding device <b>472</b><i>a, </i>and since it is assumed that some identical content is stored in both devices, the resulting local dictionaries <b>478</b><i>a </i>and <b>478</b><i>b </i>will have many common entries, that can be used for dictionary-based lossless compression.</p><p id="p-0584" num="0586">Since the storage area allocated in the &#x2018;Allocate Memory&#x2019; step <b>481</b><i>a </i>may be limited and may not store all the chunks' identifiers, priorities may be assigned to parts of the partitioned content, and only identifiers of chunks associated with a high priority content will be stored as part of the local dictionary. Such probabilities are allocated as part of an &#x2018;Allocate Probabilities&#x2019; step <b>481</b><i>c, </i>and may involve assigning higher probability, leading to higher priority for being included in the local dictionary, to files and data that are likely to be stored in both devices. For example, files of the operating system may be assigned higher probability since they are likely to be stored in both devices, while locally generated data may be associated with a lower probability.</p><p id="p-0585" num="0587">The encoding device <b>471</b><i>a </i>may execute a &#x2018;Sending Data&#x2019; flowchart <b>482</b> shown in <figref idref="DRAWINGS">FIG. <b>48</b></figref>, which may be executed by any network element. Upon receiving data to send in a &#x2018;Data to Send&#x2019; step <b>482</b><i>a, </i>such as receiving DATA_<b>1</b> in input port <b>475</b><i>a </i>of the encoder <b>474</b><i>a, </i>the encoder <b>474</b><i>a </i>compresses the received data in a &#x2018;Compress Using Both Dictionaries&#x2019; step <b>482</b><i>b. </i>The compression scheme may use either the local dictionary <b>478</b><i>a, </i>or the shared dictionary <b>473</b><i>a, </i>or both, where chunks to be transmitted are replaced with their identifiers as stored in one of these dictionaries. In one example, the local dictionary <b>478</b><i>a </i>is first fetched for a chunk identifier, and only if such identifier do not exist in that dictionary, the shared dictionary is used according to any compression scheme. The compressed data DATA_<b>2</b> at encoder <b>474</b><i>a </i>output port <b>475</b><i>b </i>is then sent via the network <b>480</b> to the decoding device <b>472</b><i>a. </i></p><p id="p-0586" num="0588">Upon receiving data, such as the DATA_<b>2</b> from the network <b>480</b>, the decoding device executes a &#x2018;Receiving Data&#x2019; flowchart <b>483</b>, shown in <figref idref="DRAWINGS">FIG. <b>48</b></figref>, which may be executed by any network element. The data is received at the decoder (or decompressor) <b>477</b><i>a </i>input port <b>476</b><i>a, </i>in a &#x2018;Data Received&#x2019; step <b>483</b><i>a. </i>The decoder <b>477</b><i>a </i>decompress the received data in a &#x2018;Decompress&#x2019; step <b>483</b><i>b, </i>such as by replacing the received identifiers with the actual chunks for reconstructing the original data DATA_<b>1</b>, and outputting it at the port <b>476</b><i>b. </i>However, a received chunk identifier (or multiple identifiers) may not be found in the local dictionary <b>478</b><i>b, </i>as checked in a &#x2018;Successful?&#x2019; step <b>483</b><i>c. </i>In the case an identifier is not located, the decoder <b>477</b><i>a </i>sends via the Feedback connection <b>479</b><i>b, </i>a retransmit request over the network <b>480</b>, in a &#x2018;Send Retransmit Request&#x2019; step <b>483</b><i>d. </i>In the case the decompression was successful, or after sending the retransmit request, the decoder <b>477</b><i>a </i>handles the next received chunk (if exists) by reverting to the &#x2018;Data Received&#x2019; step <b>483</b><i>a. </i></p><p id="p-0587" num="0589">The retransmit request is received at the connection <b>479</b><i>a </i>of the encoder <b>474</b><i>a, </i>and is handled as part of a &#x2018;Retransmit Request&#x2019; step <b>482</b><i>d. </i>The encoder <b>474</b><i>a </i>retransmits the chunk for which an identifier was not found in the decoding device <b>472</b><i>a. </i>The encoder <b>474</b><i>a </i>may send the chunk in an uncompressed form. Alternatively or in addition, if the unidentifiable chunk was compressed using the local dictionary <b>478</b><i>a, </i>the encoder may now retransmit the chunk using the shared dictionary <b>473</b><i>a. </i>The shared dictionaries <b>473</b><i>a </i>and <b>473</b><i>b </i>may be built and used using any known dictionary-based compression scheme. Alternatively or in addition, the shared dictionaries <b>473</b><i>a </i>and <b>473</b><i>b </i>may be based on content and dictionaries received from other network elements.</p><p id="p-0588" num="0590">Using a compression scheme allows for reducing the time interval required in order to transfer a content from an encoding device (such as the encoding device <b>471</b><i>a</i>) to a decoding device (such as the encoding device <b>472</b><i>a</i>), by reducing the number of bits that are actually transferred, while allowing to fully reconstruct the entire content. For example, in a case where the content to be transferred is about the size of 100 Kb, using lossless compression may allow for transmitting and receiving only 80 Kb, while allowing the reconstruction of the whole 100 Kb size content, hence saving 20% of the total content size. Assuming the content is transferred over a communication medium (such as the network <b>480</b>) that is associated with RTT<sub>1 </sub>and BW<sub>1</sub>, the time saved due to the compression can be calculated to be BITS_REDUCED/BW<sub>1</sub>, where BITS_REDUCED denotes the size of the saved content that is not transmitted over the network due to the compression, such as 20 Kb (100 Kb&#x2212;80 Kb) in the above example. In one example, assuming the saved part of the content is transmitted separately and hence the RTT<sub>1 </sub>is associated with its transmission, the time saved may be calculated to be RTT<sub>1</sub>+BITS_REDUCED/BW<sub>1</sub>. It is noted that in a case wherein the processing time due to the compression and decompression is not negligible (denoted COMPRESS_TIME), the added time associated with these activities may be reduced from the calculated saved time above, to be SAVED_TIME=RTT<sub>1</sub>+BITS_REDUCED/BW<sub>1</sub>&#x2212;COMPRESS-TIME.</p><p id="p-0589" num="0591">In the case wherein a retransmission is required, there is time-consuming overhead added to the total transfer time, relating to the retransmission request from the decoding device to the encoding device, such as the &#x2018;Send Retransmit Request&#x2019; step <b>483</b><i>d, </i>the &#x2018;Retransmit Received&#x2019; step <b>482</b><i>d, </i>and the &#x2018;Retransmit Using Shared Dictionary&#x2019; step <b>482</b><i>b, </i>and the associated overhead of handling these steps, and the actual retransmission process. Assuming the communication medium (such as the network <b>480</b>) used to send the retransmitted message from the decoding device to the encoding device is associated with RTT<sub>2 </sub>and BW<sub>2</sub>, the added time period for the sending of the retransmitted message (the &#x2018;penalty&#x2019;) can be calculated to be RTT<sub>2</sub>+MESSAGE_SIZE/BW<sub>2</sub>, where the MESSAGE_SIZE relates to the size of the retransmitted message. Further, the retransmission itself of the content part that was not successfully compressed when first transmitted, causes a delay of RTT<sub>1</sub>+RETRANSMIT_SIZE/BW<sub>1</sub>, hence the total delay associated with retransmission may be calculated to be RTT<sub>2</sub>+MESSAGE_SIZE/BW<sub>2</sub>+RTT<sub>1</sub>+RETRANSMIT_SIZE/BW<sub>1</sub>. It is noted that in a case wherein the processing time due to the retransmission, the re-compression and the re-decompression (assuming another compression scheme is used) is not negligible (denoted RECOMPRESS_TIME), the added time associated with these activities may be added to the calculated added time above, so that the retransmission total added time (&#x2018;penalty&#x2019;) may be PENALTY=RECOMPRESS_TIME+RTT<sub>2</sub>+RETRANSMIT_SIZE/BW<sub>2</sub>+RTT<sub>1</sub>+MESSAGE_SIZE/BW<sub>1</sub>. Hence, while the net time saved as part of a compression scheme may be calculated to be the saved time period, deducting the total retransmission related time period, and thus the actual time saving, denoted as an ACTUAL_SAVE and equal to SAVED_TIME&#x2212;PENALTY, may be calculated as ACTUAL_SAVE=(RTT<sub>1</sub>+BITS_REDUCED/BW<sub>1</sub>&#x2212;COMPRESS-TIME)&#x2212;(RECOMPRESS_TIME+RTT<sub>2</sub>+MESSAGE_SIZE/BW<sub>2</sub>+RTT<sub>1</sub>+RETRANSMIT_SIZE/BW<sub>1</sub>). In the case the ACTUAL_SAVE is negative (ACTUAL_SAVE&#x3c;0), the using of the compression scheme is not efficient, as there is no actual saving of any latency in the effective total content transmission time.</p><p id="p-0590" num="0592">The need for retransmission may be estimated, and thus the time saving in using a compression scheme may be estimated, and used for deciding to use a compression scheme, or what compression scheme to use. In one example, a probability of retransmission is allocated to each content (or a part thereof). The probability may be estimated based on the probability that a random device may store such content, based on former communication sessions, based on a receiving device characteristics (such as being a laptop, a desktop, a smartphone, or a mobile device), based on the receiving device operating system (such as Windows or Android), or based on the receiving device IP address. Based on the assigned retransmission probability, the estimated time savings using various compression schemes may be estimated, and the estimation may be used in order to select between compression schemes. Assuming a probability P for a successful compression, the probability for a retransmission is 1&#x2212;P, and hence the estimated time saving (EST_ACTUAL_SAVE) can be calculated as EST_ACTUAL_SAVE=SAVED_TIME&#x2212;(1&#x2212;P)*PENALTY, hence in the case of P=1 (successful compression, no retransmission), the saved time will be the SAVED_TIME, and in case of P=0 (retransmission guaranteed), the estimated saved time is SAVED_TIME&#x2212;PENALTY. In the case the EST_ACTUAL_SAVE is negative (or zero), whereby no actual time saving is expected to be achieved, an alternative (or none) compression scheme should be used.</p><p id="p-0591" num="0593">Referring now to a flowchart <b>484</b> shown in <figref idref="DRAWINGS">FIG. <b>48</b><i>a</i></figref>, which may be part of the &#x2018;Compress Using Both Dictionaries&#x2019; step <b>482</b><i>b </i>of the flowchart <b>482</b>. The content or data to be compressed before transmission is checked, and a probability of successful compression using a local dictionary (such as the dictionary <b>478</b><i>a</i>), defined as a compression where no retransmission is required, is allocated as part of an &#x2018;Allocate Probability&#x2019; step <b>484</b><i>a. </i>Using the allocated probability, the saved time is estimated in an &#x2018;Estimate Saved Time&#x2019; step <b>484</b><i>b, </i>for example based on the expression EST_ACTUAL_SAVE=SAVED_TIME&#x2212;(1&#x2212;P)*PENALTY described above. The actual estimated time saving (such as EST_ACTUAL_SAVE) is checked in a &#x2018;Saved Time&#x3e;0?&#x2019; step <b>484</b><i>c. </i>In a case where the estimated time is positive, suggesting that there is a latency reduction by using a compression based on the local dictionary <b>478</b><i>a </i>method, a compression based on the local dictionary <b>478</b><i>a </i>follows in a &#x2018;Compress Using Local Dictionary&#x2019; step <b>484</b><i>d. </i>In a case where the estimated saved time is negative, suggesting that no time is saved using a local dictionary based compression scheme, a compression based on the shared dictionary <b>478</b><i>a </i>(or sending the data uncompressed) follows in a &#x2018;Compress Using Shared Dictionary&#x2019; step <b>484</b><i>e. </i></p><p id="p-0592" num="0594">Referring to a system <b>490</b> shown in <figref idref="DRAWINGS">FIG. <b>49</b></figref>, showing a device #<b>1</b> <b>491</b><i>a, </i>which may consist of, comprise of, or is included in, a tunnel-based client device (such as the client device #<b>1</b> <b>31</b><i>a</i>), a peer-based client device (such as the client device #<b>1</b> <b>31</b><i>a</i>), or any other network element, a device #<b>2</b> <b>491</b><i>b, </i>which may consist of, comprise of, or is included in, a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>), a peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>), or any other network element, and the data server #<b>1</b> <b>22</b><i>a, </i>connected for exchanging information over the Internet <b>113</b>. The data server #<b>1</b> <b>22</b><i>a </i>may store a content that is identified by a URL (or by any other identifier type). Further copies of the content may be stored in a memory <b>493</b><i>a </i>being part of the device #<b>1</b> <b>491</b><i>a, </i>and in a memory <b>493</b><i>b </i>being part of the device #<b>2</b> <b>491</b><i>b. </i>The copies of the content stored in the devices may be the result of fetching it from the data server #<b>1</b> <b>22</b><i>a </i>as part of previous interactions. In one example, an application in the device #<b>1</b> <b>491</b><i>a </i>requests the same content. As described in the &#x2018;Locally cached?&#x2019; step <b>331</b><i>c </i>in the flowchart <b>330</b>, it is more efficient to retrieve the requested content from the local memory (such as the memory <b>493</b><i>a</i>) as described in the &#x2018;Fetch from Local cache&#x2019; step <b>331</b><i>b </i>in the flowchart <b>330</b>, than to spend resources in order to again fetch the same content from the data server #<b>1</b> <b>22</b><i>a. </i></p><p id="p-0593" num="0595">However, while identified by the same identifier (such as a URL), the content in the data server #<b>1</b> <b>22</b><i>a </i>may have been changed or updated since it was fetched by the device #<b>1</b> <b>493</b><i>a </i>or by the device #<b>2</b> <b>491</b><i>b, </i>thus the copies stored in these devices may not anymore be valid or updated. In such a scenario, the locally stored non-valid stored copy should be ignored and discarded, and not used anymore, and hence a fresh content relating to the URL needs to be fetched from the data server #<b>1</b> <b>22</b><i>a, </i>or from another location. Further, a validity period may be associated with a content or its copy, where the content is ensured to be valid until the validity period expires. In one example, the validity of a copy of a content is verified by comparing a part of a validated (or original) content, to the respective part of the checked copy. In the case the two parts are the same, the copy is declared as valid, assuming the rest of the copy of the content is the same as the updated content.</p><p id="p-0594" num="0596">Referring to a flowchart <b>490</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>49</b><i>a</i></figref>, describing a method for validating a copy of a content. The request for the content (such as by using a URL or any other content identifier) is obtained in an &#x2018;Obtain Content Request&#x2019; <b>494</b><i>a. </i>In a &#x2018;Local Copy Valid&#x2019; step <b>494</b><i>b </i>(which may be part of the &#x2018;Locally Cached&#x2019; step <b>331</b><i>c</i>) the validity of the content, if known (such as by checking that the associated period has not yet expired), is checked. In the case the locally stored copy (such as in the memory <b>493</b><i>a </i>of the device #<b>1</b> <b>491</b><i>a</i>) is determined to be valid, the locally stored content is used in a &#x2018;Use Local Copy&#x2019; step <b>494</b><i>c, </i>which corresponds to the &#x2018;Fetch from Local Cache&#x2019; step <b>331</b><i>b </i>in the flowchart <b>330</b>. In the case the validity of the locally stored copy is suspected, a part of the content (preferably a small part) is fetched from the data server #<b>1</b> <b>22</b><i>a </i>in a &#x2018;Fetch Slice From Server&#x2019; step <b>494</b><i>d. </i>The requested and fetched part of the content may be a slice or chunk, as described herein. Alternatively or in addition, a fixed number of bytes may be used. Further, the size of the fetched part may be 5% or 10% of the total size of the content. The part of the content may be the first part, the last part, or any other part of the content.</p><p id="p-0595" num="0597">In a &#x2018;Same as Local Copy?&#x2019; step <b>494</b><i>e, </i>the fetched part of the content is compared with the respective part of the locally stored copy of the content. In the case the two checked parts are found to consist of the same information, the locally cached content is determined to be valid, and is used as a response to the content request in the &#x2018;Content Request&#x2019; step <b>494</b><i>a </i>as part of the &#x2018;Use Local Copy&#x2019; step <b>494</b><i>c. </i>In the case where the two checked parts are different, the locally cached content is determined to be non-valid. Next, a slice of a copy of the content is requested and fetched from another network element, such as from the device #<b>2</b> <b>491</b><i>b </i>in a &#x2018;Fetch Slice From Device&#x2019; step <b>494</b><i>f, </i>and the fetched slice is checked in a &#x2018;same as Server Slice?&#x2019; step <b>494</b><i>g, </i>and compared versus the slice that was fetched from the data server #<b>1</b> <b>22</b><i>a </i>in the &#x2018;Fetch Slice From Server&#x2019; step <b>494</b><i>d. </i>In the case where the two checked parts are found to consist of the same information, the cached content in the network element (such as in the memory <b>493</b><i>b </i>of the device #<b>2</b> <b>491</b><i>b</i>) is determined to be valid, and the device #<b>1</b> <b>491</b><i>a </i>may fetch the content therefrom in a &#x2018;Fetch Content From Device&#x2019; step <b>494</b><i>h. </i>In one example, such fetching may use any of the methods described herein, for example, the device #<b>2</b> <b>491</b><i>b </i>may be used as a peer device. Alternatively or in addition, the device #<b>1</b> <b>491</b><i>a </i>may fetch the updated content from the data server #<b>1</b> <b>22</b><i>a </i>itself, corresponding to the &#x2018;Fetch from Server&#x2019; step <b>331</b><i>e </i>in the flowchart <b>330</b>. In the case where the two checked parts are different, the cached content in the network element (such as in the memory <b>493</b><i>b </i>of the device #<b>2</b> <b>491</b><i>b</i>) is determined to be non-valid, and thus the device #<b>1</b> <b>491</b><i>a </i>can only fetch the updated content from the data server #<b>1</b> <b>22</b><i>a, </i>as part of a &#x2018;Fetch Content From Server&#x2019; <b>494</b><i>i, </i>corresponding to the &#x2018;Fetch from Server&#x2019; step <b>331</b><i>e </i>in the flowchart <b>330</b>.</p><p id="p-0596" num="0598">The steps involved in the actual validating of the local content copy are considered part of a &#x2018;Content Validation&#x2019; flowchart <b>496</b>, that is part of the flowchart <b>490</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>49</b><i>a</i></figref>. In a &#x2018;Same as Local Copy&#x2019; step <b>494</b><i>e </i>and a &#x2018;Same as Server Slice&#x2019; step <b>494</b><i>f, </i>two parts of the content are compared. The actual information in the compared parts may be compared in a bit-by-bit (or byte-by-byte) level. Alternatively or in addition, the checksums, the CRCs (or any other hash function), HTTP headers, or any other information representative of the parts information may be used for determining of the parts are the same.</p><p id="p-0597" num="0599">In one example, a network element (device) periodically checks and validates the content stored in it. Hence, when the content is required, local copy may be used for either local use or as a peer device, allowing for faster response to a request for the locally stored content. A network element may thus execute a flowchart <b>490</b><i>b </i>shown in <figref idref="DRAWINGS">FIG. <b>49</b><i>b</i></figref>. The validation process is considered as a low-priority task, so in an &#x2018;Idle?&#x2019; step <b>495</b><i>a, </i>the activity of the network element is checked, such as checking the CPU utilization, the available storage size, or the available communication bandwidth. In the case the activity is above a set threshold, the higher-priority activities are given precedence, and the validation activity is not activated, and the element remains in the &#x2018;Idle?&#x2019; step <b>495</b><i>a. </i>Upon availability of enough resources and determination that no other more important tasks are to be activated, the device scans the local memory (or cache) in a &#x2018;Scan Cache&#x2019; step <b>495</b><i>b, </i>and the entries of the various content copies are checked for validity. In the case where all the content parts are found to be valid in a &#x2018;Non-Valid Content?&#x2019; step <b>495</b><i>c, </i>the device resumes to the idling of the validation process in the &#x2018;Idle?&#x2019; step <b>495</b><i>a, </i>since no validation activity is required. For each of all content entries that are found to be non-valid, the time left until its validity expiration is checked, and is associated with the respective content entry, in an &#x2018;Associate Expiration Time&#x2019; step <b>495</b><i>d. </i>It is noted that some content entries may be determined to be not important, and thus will not be part of the validation process. Out of the content entries that are considered as important, the device selects the content entry that is the first to expire, in a &#x2018;Select Non-Valid Content&#x2019; step <b>495</b><i>e. </i>The selected content is then validated in a &#x2018;Content Validation&#x2019; step <b>495</b><i>f, </i>which corresponds to the &#x2018;Content Validation&#x2019; flowchart <b>496</b> shown as part of the flowchart <b>490</b><i>a </i>in <figref idref="DRAWINGS">FIG. <b>49</b><i>a</i></figref>. After validating the selected content, the memory is re-scanned for non-valid content in the &#x2018;Scan Cache&#x2019; step <b>495</b><i>b, </i>and the validating process is until all important and non-valid content entries are validated.</p><p id="p-0598" num="0600">As shown in the system <b>500</b> in <figref idref="DRAWINGS">FIG. <b>50</b></figref>, a network element <b>504</b> may connect to another network element <b>501</b> via the gateway #<b>1</b> <b>505</b><i>a. </i>Due to many reasons, the network element <b>504</b> may disconnect for a short time from the gateway #<b>1</b> <b>505</b><i>a, </i>and then may re-connect to the same gateway <b>505</b><i>a </i>or to another gateway. In such a case, the application <b>506</b> detects the connection disruption with the gateway <b>505</b><i>a, </i>and lose the connectivity during the time there is no connection to any gateway. In a case where the application is a web browser, such short loss of connectivity may cause service disruption, such as the &#x201c;404 page not found&#x201d; message to a user. Further, recovering from such loss of connection may be time consuming and employs valuable resources.</p><p id="p-0599" num="0601">A Virtual Gateway Service <b>512</b> (VGS) may be used to reduce the period of re-connection, and to reduce the harmful impact on the network element <b>504</b> operations, as shown in a system <b>510</b> in <figref idref="DRAWINGS">FIG. <b>51</b></figref>. The network element <b>504</b> may use either the gateway #<b>1</b> <b>505</b><i>a </i>or a gateway #<b>2</b> <b>505</b><i>b </i>for connecting to the network element <b>501</b>. The VGS <b>512</b> is a software stored in the network element <b>504</b> memory <b>508</b>, and operating as an intermediate level between the OS <b>507</b> and the physical layer connecting to the LAN <b>503</b>. The VGS <b>512</b> intercepts requests from the operating system <b>507</b> to the network for receiving configuration information, and receives on the configuration information from the gateway #<b>1</b> <b>505</b><i>a. </i>This information is fed back to the OS <b>507</b>, hence serving as a proxy (or an agent) for a configuration information between the OS <b>507</b> and the gateway #<b>1</b> <b>505</b><i>a. </i>Alternatively or in addition, an intercepted request from the OS <b>507</b> may be responding directly by the VGS <b>512</b>. For example, in a case of an intercepted IP request, the VGS may locally provide an IP address.</p><p id="p-0600" num="0602">In one example, the network element <b>504</b> may disconnect from the gateway #<b>1</b> <b>505</b><i>a, </i>and may connect to the gateway #<b>2</b> <b>505</b><i>b </i>shortly after. The VGS <b>512</b> may simulate to the operating system <b>507</b> a gateway response, so that the OS <b>507</b> may not detect the disconnection from gateway #<b>1</b> <b>505</b><i>a, </i>and as such may not report an error or a change of a status. When the re-connection to the new gateway #<b>2</b> <b>505</b><i>b </i>has been done, the VGS <b>512</b> may request new configuration information, while not notifying or changing the operating system <b>507</b> status. Thus, from the perspective of the operating system <b>507</b>, it is continuously connected to a gateway and a network, and the actual disconnection is not sensed by the OS <b>507</b>. However, in a case of a long disconnection (from a network or a gateway), the VGS <b>512</b> senses such a disconnection (such as longer than pre-defined time period), and accordingly notifies the operating system <b>507</b>, thus providing the operating system <b>507</b> and the application <b>506</b> the ability to correctly respond correctly to the situation, such as to notify the user.</p><p id="p-0601" num="0603">The VGS <b>512</b> may execute a flowchart <b>510</b><i>a </i>shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> la. Upon connecting to a network such as the LAN <b>503</b>, the OS <b>507</b> (via the VGS <b>512</b>) sends an IP request to the gateway <b>505</b><i>a </i>identified on the network <b>503</b>. During such initialization process, the VGS <b>512</b> is transparent, and allows the OS <b>507</b> to complete the regular process of initializing of a communication session. Afterwards, any request for IP address, for any configuration information, or any other initialization access, to the gateway <b>505</b><i>a </i>is intercepted as part of an &#x2018;Intercept Gateway Access&#x2019; step <b>511</b><i>a. </i>In a case where the intercepted (or trapped) request is an IP request, as detected in an &#x2018;IP Request?&#x2019; step <b>511</b><i>b, </i>the VGS <b>512</b> serves effectively as a NAT, and provides an IP address for the OS <b>507</b> to use, as part of a &#x2018;Return Valid IP Address&#x2019; step <b>511</b><i>c. </i>The VGS <b>512</b> continues to serve (from the OS <b>507</b> point of view) as an external proxy/NAT or simulates a connection with a gateway as part of an &#x2018;Activate Virtual Gateway&#x2019; step <b>511</b><i>d. </i>In a &#x2018;Gateway Disconnected?&#x2019; step <b>511</b><i>e, </i>the VGS <b>512</b> checks the status of the actual connection to the gateway, such as the gateway #<b>1</b> <b>505</b><i>a. </i>If no actual disconnection is detected, the VGS <b>512</b> idles until a new IP request is intercepted as part of the &#x2018;IP Request?&#x2019; step <b>511</b><i>b. </i>If the actual connection to the gateway #<b>1</b> <b>505</b><i>a </i>is not available, the VGS <b>512</b> tries to get an actual externally-sourced IP address, such as from the gateway #<b>1</b> <b>505</b><i>a, </i>in a &#x2018;Get External IP Address&#x2019; step <b>511</b><i>f. </i>If no network connection is available, the VGS <b>512</b> may skip this step. In parallel, a timer set to a time period (such as X milliseconds) is started in a &#x2018;Start Timer&#x2019; step <b>511</b><i>g, </i>for measuring the disconnection related time. As long as the timer has not expired, the VGS <b>512</b> checks if an external IP address was obtained in an &#x2018;External IP Received?&#x2019; step <b>511</b><i>h, </i>as a response to the request sent in the &#x2018;Get External IP Address&#x2019; step <b>511</b><i>f. </i>If an actual IP address was received before the timer expiration, as checked in a &#x2018;Timer Expired?&#x2019; step <b>511</b><i>i, </i>such as from an alternative gateway that may be the gateway #<b>2</b> <b>505</b><i>b, </i>the received IP address is returned for the use of the OS <b>507</b>, allowing for a quick switchover between the gateways, and for normal NAT/proxy service to the OS <b>507</b>. However, if the timer has expired and no IP address was obtained, the VGS <b>512</b> notifies the OS <b>507</b> that the connection was lost, allowing for the operating system <b>507</b> to react to the disconnect state in the way it was programmed to.</p><p id="p-0602" num="0604">A concept of writing cache data to the free portion of the memory is introduced in U.S. Pat. No. 8,135,912 to Shribman et al., entitled: &#x201c;System and Method of Increasing Cache Size&#x201d;. The stored information is transparent to the operating system, and thus more cache size is available without degrading the amount of memory that is available for the user to use. The memory arrangement in such a prior art system is shown in <figref idref="DRAWINGS">FIG. <b>52</b></figref>, where the file system first writes the OS data <b>62002</b>, after which the cache data <b>62004</b> is written, followed by a not-used (free) space <b>62006</b>. The problem with this memory management approach is that when the file system overwrites the cache data when adding data to the OS data <b>62002</b>. In such a system where the free space <b>62006</b> is still available, it would be beneficial to have a system where such further OS writes would not overwrite the cached data while free space is available. Such a memory arrangement is shown in <figref idref="DRAWINGS">FIG. <b>53</b></figref>. The OS data <b>62012</b> is first stored, whereas the cache data <b>62016</b> is stored on the other side of the memory, starting at the furthest position from the start of the writing of the OS data <b>62012</b>, so that the OS data <b>62012</b> overwrites the cache data only when a free space <b>62014</b> is completely used. It may also be desirable to have a system that cleans up the cache data, so that data that is no longer needed is removed, to maintain the free space and avoid the cache data being overwritten.</p><p id="p-0603" num="0605"><figref idref="DRAWINGS">FIG. <b>54</b></figref> is a flowchart of a system for writing cached data in this modified method, as well as for cleaning up the cache periodically to allow for a free space in the system and thus less data overwrites. In a step <b>62202</b> the cache_pointer is set to the point on the storage location that is furthest from the starting point of where the OS data is written to when the storage device is empty. In a step <b>62204</b>, it is checked whether cache data (cache_data) need to be written to the storage device. If not, then in a step <b>62206</b> it is checked whether system resources are idle enough to warrant a cache cleanup to be performed. If there is more cache to write, then in a step <b>62208</b> the cache_pointer is moved back (i.e., &#x2018;towards&#x2019; the OS data) by the size of cache_data, and then in a step <b>62210</b> the cache_data is written to the storage device as the referenced patent instructs how to do (i.e., without notifying the operating system so that this space is still viewed as empty by the OS). This moving back of the pointer is novel, since it creates a situation where the data is written in a &#x2018;forward&#x2019; direction (in the same direction to which the OS data is written to), which is typically the faster writing direction for storage devices, as they are optimized for writing OS data.</p><p id="p-0604" num="0606">When the cleanup is performed, then in a step <b>62214</b> it is checked whether the free space is close to running out (e.g., is it under x % of the total available storage size, where x can be 10%, or under y Bytes free where Y is 1 GB for example). If this threshold has been reached, then in a step <b>62216</b> the least relevant cache is searched for to be removed. The criteria for less relevant could be in that it has expired, or that it is accessed the least, or any of other prior art cache purge methods. This cache item is removed.</p><p id="p-0605" num="0607">A cache system such as that described in U.S. Pat. No. 8,135,912 to Shribman et al. entitled: &#x201c;System and Method of Increasing Cache Size&#x201d;, creates a very large cache size (cache_size) but at the expense of the reliability of reading the cache back after writing it, where the probability for a cache miss (i.e., to try to read back the cached element and to fail) at a certain point in time would be P, where P&#x3c;1.</p><p id="p-0606" num="0608">In some cases, the cache_size is significantly bigger than required for the system operation. In such a case, <figref idref="DRAWINGS">FIG. <b>55</b></figref> is a diagram of how P can be increased (i.e., reliability can be increased) at the cost of the cache_size. <figref idref="DRAWINGS">FIG. <b>55</b></figref> offers to create two zones of writing the cache data in the storage device, where each element in the cache is written once to each zone. This way, the cache_size is reduced by half (since each element is written twice), and P would be reduced to P{circumflex over (&#x2003;)}2, since the probability of not reading back P would be to miss it in both of the zones. Thus, while the size of the cache is reduced linearly (cut in half), the probability of getting a cache miss is reduced exponentially (P{circumflex over (&#x2003;)}2).</p><p id="p-0607" num="0609"><figref idref="DRAWINGS">FIG. <b>56</b></figref> is a flowchart for how this could be implemented. In a step <b>63202</b>, a &#x2018;cache read&#x2019; or a &#x2018;cache write&#x2019; command is received by the module, and in a step <b>63204</b>, it checks if it is a read command or a write command. If it is a read command, then in a step <b>63206</b> the module looks up in the cache index to find the two locations to which the cache was written, and in a step <b>63208</b> attempts to read the cache entry from the first location. A step <b>63210</b> checks if the cache entry was found in that read. If it was, then return a step <b>63212</b> the data that was read. If it was not found, then in a step <b>63220</b> read the cache entry from the second location and return it if found in the step <b>63212</b> or return data_not_found if not found in the second location as well. In the case of a write command, two different free locations are identified in a step <b>63214</b> and the cache data is written to those two locations in a step <b>63216</b>. The cache index is updated with these two locations so that the cache entry can be found in future writes. <figref idref="DRAWINGS">FIG. <b>57</b></figref> shows that in a similar manner, the amount of times that a cache element is written to the storage device can be increased from 2 as shown in <figref idref="DRAWINGS">FIGS. <b>55</b> and <b>56</b></figref>, to any number N, where in such a case the available cache size is reduced from (cache_size) to (cache_sizeN), and the probability of a cache miss is reduced from (P) to (P{circumflex over (&#x2003;)}N).</p><p id="p-0608" num="0610">(NDCACHE&#x2014;Non-Deterministic volatile memory CACHE). In a computing device, the Random Access Memory (RAM) is a limited resource. When the operating system uses the RAM, it typically increases the speed of the application. However, excessive use of the RAM for an application limits the use of the RAM by other applications and thus limits their speed. One such use of the RAM is for caching information in order to speed up the speed of the program's operation. Such cached data may be data retrieved from the network, or be the result of a complicated operation, etc. Operating systems make use of the RAM for caching purposes, and typically leave some of the RAM free to be used later. If this free RAM, memory could be used to store additional cache without significantly affecting system performance in other ways that would be beneficial.</p><p id="p-0609" num="0611"><figref idref="DRAWINGS">FIG. <b>58</b></figref> is a diagram of the state of the art implementation of address space mapping. A physical address <b>64004</b> is a memory address that is represented in the form of a binary number on the address bus circuitry in order to enable the data bus to access a particular storage cell of main memory, or a register of memory mapped I/O device. In a computer with a virtual memory <b>64002</b>, the term physical address is used mostly to differentiate from a virtual address. In particular, in computers utilizing Memory Management Unit (MMU) to translate memory addresses, the virtual and physical addresses refer to an address before and after MMU translation respectively.</p><p id="p-0610" num="0612"><figref idref="DRAWINGS">FIG. <b>59</b></figref> is a diagram of a prior art MMU and TLB, in which the CPU <b>64002</b> requires a translation of a logical address into a physical address <b>64008</b> in order to read or write to it. For the translation, it sends the logical address to the MMU <b>64004</b>, which uses a cache called a Translation Lookaside Buffer (TLB) <b>64006</b> to map the virtual address to a physical address <b>64008</b>. Modern MMUs <b>64004</b> typically divide the virtual address space into pages, each having a size which is a power of <b>2</b>, usually a few kilobytes, but they may be much larger. The bottom n bits of the address (the offset within a page) are left unchanged. The upper address bits are the (virtual) page number. The MMU <b>64004</b> normally translates virtual page numbers to physical page numbers via an associative cache called TLB <b>64006</b>. When the TLB <b>64006</b> lacks a translation, a slower mechanism involving hardware-specific data structures or software assistance is used. The data found in such data structures are typically called page table entries (PTEs), and the data structure itself is typically called a page table. The physical page number is combined with the page offset to give the complete physical address.</p><p id="p-0611" num="0613">Sometimes, a TLB <b>64006</b> entry or PTE prohibits access to a virtual page, perhaps because no physical random access memory has been allocated to that virtual page. In this case, the MMU <b>64004</b> signals a page fault to the CPU <b>64002</b>. The operating system (OS) then handles the situation, perhaps by trying to find a spare frame of RAM and set up a new PTE to map it to the requested virtual address. If no RAM is free, it may be necessary to choose an existing page (known as a victim), using some replacement algorithm or &#x2018;eviction algorithm&#x2019;, and save it to another form of storage (e.g., hard disk)&#x2014;typically known as &#x201c;paging&#x201d;.</p><p id="p-0612" num="0614"><figref idref="DRAWINGS">FIG. <b>60</b></figref> is a diagram of prior art on how an MMU works. The TLB <b>64402</b> receives a virtual address from the CPU. If it finds the associated physical memory within the TLB <b>64402</b>, then it returns the Physical address associated with this virtual memory, to the CPU. If it does not find the address in the TLB <b>64402</b>, then it looks it up in the Page Table <b>64404</b>. If there is an association there, then the physical address associated with the virtual address is returned. If there is no such association, then the Page Table Exception Handler <b>64406</b> is activated. It uses a database and a set of drivers to figure out how to map the virtual memory to physical memory (often by allocating new memory, loading information on to that memory from disk, and mapping it to a virtual memory). The data is then loaded into the physical page in <b>64408</b>, and the physical address is returned to the CPU.</p><p id="p-0613" num="0615"><figref idref="DRAWINGS">FIG. <b>61</b></figref> is a diagram of prior art on how the MMU's page table exception handler works. When a page table exception occurs, the page table exception handler is invoked, as per <figref idref="DRAWINGS">FIG. <b>59</b></figref>. The page table exception handler <b>64802</b> first identifies in a step <b>64804</b> the driver responsible for this data segment. This is typically stored in the page table. For example, the driver for a specific virtual memory segment may determine that this part of the virtual memory should be mapped to real physical memory, or it may determine that it is mapped to an <b>10</b> device such as a camera and the contents should be read from the camera's sensors. Then, the driver assigned determines whether a new physical memory segment needs to be assigned to this virtual address space or not. If more physical memory is required, then in a step <b>64808</b> the OS determines whether there is such physical memory available to the system. If there isn't free physical memory, then in the step <b>64808</b> the OS determines which physical page to &#x2018;purge&#x2019; out of memory based on any number of &#x2018;eviction algorithms&#x2019; (e.g., least recently used is discarded). The driver assigned to this memory space determines in which manner this information is purged&#x2014;i.e., is it simply discarded, or saved to disk, etc. The MMU then evicts in a step <b>64810</b> the physical page by either swapping it to disk, erasing it, or whatever method the driver associated with it determined. If in a step <b>64806</b> it is determined that there is enough free physical memory to create the new page, then the driver determines in a step <b>64814</b> the method by which to load the data into the physical memory or to otherwise map the virtual address to an IO device, etc., and then loads in a step <b>64816</b> the data into the physical memory or maps it as required. The virtual memory map to the physical address is then sent to the TLB <b>64818</b>, and the request is resolved for the CPU.</p><p id="p-0614" num="0616">The prior art memory management can be described as deterministic, because information that is stored in the physical memory by the application is always retrievable, even in case that physical memory is purged, since the driver for that memory segment that is purged typically saves the data before discarding it. There is a &#x2018;cost&#x2019; to this determinism, in that there is a load and purge time to the physical memory, since when purging this physical memory it needs to be written to a different medium, and then loaded back from the medium before it can be read. In cases where an application wishes to store cache data in the volatile memory in order to save time in re-calculating an algorithm, or in order to not load it again from the web, or in other cases, it does not need the determinism offered by the state of the art memory management systems, but it does need high access speeds, since if the speeds are not high, then it may be more beneficial to the system to re-calculate the algorithm or to re-fetch the information from the web, and not to do a page fault which is costly in time. In addition, the more physical memory available for the cache, the faster that the applications can run. However, the more physical memory allocated to cache of one application, the less is available for other uses, and thus the system performance may be degraded. Therefore, it is beneficial to design a system that can gain from higher speeds associated with non-determinism in the memory management, and that can use the maximum possible physical memory without deteriorating the performance of other applications.</p><p id="p-0615" num="0617"><figref idref="DRAWINGS">FIG. <b>62</b></figref> is a flowchart of how a non-deterministic physical memory caching system may be implemented. In a step <b>65002</b> an application requests from the operating system a non-deterministic physical memory cache (NDCACHE). The OS allocates in a step <b>65004</b> the physical memory for the cache, and maps it to virtual memory, and marks these pages with an &#x2018;NDCACHE&#x2019; flag. If the eviction algorithm of the OS decides to swap out in a step <b>65006</b> a physical page which is marked with an &#x2018;NDCACHE&#x2019; flag, then that page is discarded in a step <b>65010</b> without being stored back to non volatile memory&#x2014;it is simply removed from the page table, and will be allocated to a new page and the new data will overwrite the old. If the OS is running out in a step <b>65008</b> of physical memory (this may be determined via a variety of ways that will be described later on in the document), then the OS discards one or more NDCACHE pages from memory to clear up memory for the OS. For example, it may clear up four pages, check if that is enough for the OS, and clear more if needed. When the application wishes to read in a step <b>65014</b> a virtual memory that was requested as an NDCACHE memory, and is now a regular memory (since the NDCACHE memory was swapped out and thus discarded), it receives back a &#x2018;DOES NOT EXIST&#x2019; message to indicate that this memory was lost and thus the cache data requested no longer exists. During a read or write transaction to or from an NDCACHE page in a step <b>65016</b>, that page is locked so that the eviction algorithm does not purge it during that action.</p><p id="p-0616" num="0618"><figref idref="DRAWINGS">FIG. <b>63</b></figref> is a suggested Application Programming Interface (API) for an NDCACHE implementation. This suggested API is similar to the file system API (http://en.wikipedia.org/wiki/File_system_API) in POSIX (http://en.wikipedia.org/wiki/POSIX). To start a new NDCACHE type cache, an application first will call the function NDCACHE_OPEN <b>6504</b>, which returns a handle to the NDCACHE (FILEDS) that is referenced by NAME. The NAME that is passed to the function is a unique name for that cache that is used between different processes accessing this page, similar to how a filename is used in the file system POSIX API. If the NDCACHE specified by NAME exists, then the function simply returns a handle to the existing cache. If it does not exist, then NULL is returned by the function. However, if the CREATE_FLAG passed to the function is turned on, then upon opening an NDCACHE specified by NAME that does not yet exist, such an NDCACHE is created and the function returns the handle to that NDCACHE. If such a cache already exists and the TRUNCATE_FLAG is set, then that cache is erased, and a handle to this empty cache is returned by the function.</p><p id="p-0617" num="0619">NDCACHE_READ and NDCACHE_WRITE <b>65404</b> are the functions used to read from the NDCACHE and write to the NDCACHE (respectively) that is referenced by the FILEDS that was initially received from the NDCACHE_OPEN function. The BUFFER is an allocated memory that the application can use to read the information to (in case of NDCACHE_READ) or to write from (in case of NDCACHE_WRITE). The OFFSET is the offset (in bytes, for example) within the NDCACHE referenced, to start the read, or to start the write, from. SIZE is the number of bytes to read or to write. NDCACHE_CLOSE <b>65406</b> is called to close the handle to the NDCACHE referenced by FILEDS. After all handles to an NDCACHE are closed, the OS may decide to swap it out based on its eviction algorithms. NDCACHE_UNLINK <b>6508</b> is called to remove the NDCACHE entry referenced by FILEDS from the operating system's page table, thus effectively deleting this NDCACHE.</p><p id="p-0618" num="0620">A file system is a means to organize data by providing procedures to store, retrieve and update data, as well as manage the available space on the device(s) which contain it. A file system is tuned to the specific characteristics of the device. There is usually a tight coupling between the operating system and the file system. Some filesystems provide mechanisms to control access to the data and metadata. Ensuring reliability is a major responsibility of a filesystem. Some filesystems provide a means for multiple programs to update data in the same file at nearly the same time.</p><p id="p-0619" num="0621">File systems are used on data storage devices such as hard disk drives, floppy disks, optical discs, memory storage devices, remote servers, etc. File systems may provide access to data on a file server by acting as clients for a network protocol (e.g. NFS or SMB clients), or they may be virtual and exist only as an access method for virtual data (e.g. procfs). This is distinguished from a directory service and registry. A File system is implemented in a file system driver which implements a standard file system API for using it, and is coupled to a storage device or other storage strategy (like mapping to existing memory).</p><p id="p-0620" num="0622"><figref idref="DRAWINGS">FIG. <b>64</b></figref> shows the prior art method of mounting a file system. A computer <b>66202</b> has a file system directory structure <b>66204</b>, which in various directories represent space on various storage devices. The block device <b>66208</b> is such a storage device on which data may be stored. The file system driver <b>66206</b> links between the block device <b>66208</b> and a certain directory in the file system <b>66204</b>. The file system driver is configured to be called by the OS on a specific point in the OS directory structure (in this example in &#x201c;Amp&#x201d;). Every file call to that directory initiates a call to the File System Driver <b>66206</b>, which may use a memory device such as the block device <b>66208</b> to store &#x26; retrieve information. This linking of a storage device to a directory is called &#x2018;mounting a file system&#x2019;.</p><p id="p-0621" num="0623"><figref idref="DRAWINGS">FIG. <b>65</b></figref> is a prior art diagram of the TMPFS file system. TMPFS is a common name for a temporary file storage facility on many Unix-like operating systems. It is intended to appear as a mounted file system, but stored in volatile memory instead of a persistent storage device. A similar construction is a RAM disk, which appears as a virtual disk drive and hosts a disk file system. The computer <b>66402</b> has a directory structure <b>66404</b> in which the TMP directory is mapped to the TMPFS file system driver <b>66406</b>, such that when file system calls are made on files within the TMP directory, they are performed on data that is stored in a volatile memory <b>66408</b>.</p><p id="p-0622" num="0624">A secondary implementation of an NDCACHE may use simple file system mounting. This implementation is simple in that it does not require kernel mode modifications, or some minimal modifications to the TMPFS file storage facility that is available on many unix-like operating systems.</p><p id="p-0623" num="0625"><figref idref="DRAWINGS">FIG. <b>66</b></figref> is a flowchart of a possible implementation of an NDCACHE by using a TMPFS file system. In a step <b>66602</b> a TMPFS is created and mounted, with an initial size of X bytes, where X can be <b>1</b>GB for example, to be used for the NDCACHE. In a step <b>66604</b>, the system checks whether the operating system would benefit from having additional volatile memory. This can be done in various methods known to those in the art. For example, this can be done by checking every Y ms (for example every 20 ms) if less than a certain amount of free memory exists in the system (could be less than 200 MB for example), or if above a certain amount of memory swaps occurred recently (could be more than 2 swaps per second for example), or if the kernel cache space is reduced to under a certain size (could be under 2 GB for example). This can also be done by listening to &#x2018;stress&#x2019; operating system calls such as &#x201c;low memory&#x201d; type calls&#x2014;if these are called then the operating system probably would benefit from having additional volatile memory. This could also be checked by attaching a callback on the swapping out of memory of the TMPFS file and deleting it instead of swapping it out.</p><p id="p-0624" num="0626">If any of the above events in a step <b>66606</b> occurred, then the OS would benefit from having more volatile memory. This is checked in a step <b>66608</b>. If the OS would not benefit from more memory, then continue to the step <b>66604</b>. If it would, then in a step <b>66610</b> the NDCACHE is reduced by deleting a number of elements from it, so that its size is reduced by Z bytes (for example by 200 MB). In a step <b>66612</b> shows various strategies by which elements may be reduced from the NDCACHE: delete the least recently used (LRU), the least frequently used (LFU), the largest elements by bytes, or the smallest elements by size. This TMPFS size reduction thus frees space for the operating system. This system described in <figref idref="DRAWINGS">FIG. <b>66</b></figref> thus describes an implementation of an NDCACHE, since the application gains a physical memory cache, that is swapped out (partially or completely) as the operating system requires more physical memory for its operation.</p><p id="p-0625" num="0627">Hence, a method of increasing the size of the memory (which is a physical memory) available to applications by which an application may request memory which is specially marked, is disclosed, where the application is able to read and write to this physical memory, and where if the operating system needs more memory then this specially marked memory is discarded. If the specially marked memory space is swapped by the operating system, then it is simply discarded. If the operating system would benefit by having more memory available to it, it reduces the size of the memory allocated to the specially marked cache. The method may be implemented by a TMPFS system that allocates physical memory to this special cache, where if the operating system would benefit by having more memory available to it, it reduces the size of the TMPFS allocated to this specially marked cache</p><p id="p-0626" num="0628">The second implementation of the NDCACHE&#x2014;the calls to TMPFS are from user mode to kernel mode, and thus may take thousands of CPU cycles to complete. It is thus desirable to avoid calls between user mode and kernel mode if possible, to improve a performance of the system to get minimum cycles per an NDCACHE call.</p><p id="p-0627" num="0629">A system with higher performance can be achieved by implementing the NDCACHE as a user mode module that communicates with an NDCACHE kernel module, as described in <figref idref="DRAWINGS">FIG. <b>67</b></figref>. Block <b>67202</b> is the user mode space of the computing device, and block <b>67208</b> is the kernel space. The application <b>67204</b> is running in the user mode <b>67202</b> and using an API (NDCACHE calls) that is implemented in an NDCACHE user mode implementation <b>67206</b>. It uses system calls to communicate with the NDCACHE kernel mode implementation <b>67210</b>.</p><p id="p-0628" num="0630"><figref idref="DRAWINGS">FIG. <b>68</b></figref> is a description of the API relating to a third implementation method of the NDCACHE. The block <b>67402</b> is pseudo code that describes how an NDCACHE would be allocated and written to. First, a FILEDS handle is created by opening a file that is handled by the NDCACHE_DRIVER, which is the kernel module for NDCACHE events, along with the NDCACHE_NAME, which is the specific name of the NDCACHE that is being accessed. Then, a pointer directly to the NDCACHE memory is received by doing an NDCACHE_LOOKUP on the NDCACHE_NAME. This lookup returns a pointer to the memory of the specific NDCACHE, and if such a cache does not exist, P is assigned NULL. If indeed no such NDCACHE exists, then it needs to be created. In such a case, the pointer P is assigned a memory map of a certain size (in this specific implementation it is <b>1</b>MB, but this could be other sizes), where this memory is declared as shared memory so that it may be used by multiple processes.</p><p id="p-0629" num="0631">Then the first memory position in P (P[<b>0</b>]) is increased (so that if this was a new assignment of memory, then P is now 1), to indicate that there is content in this NDCACHE. Then the program continues by writing the data to P, starting at P[<b>1</b>]. If the cache exists (i.e. was not allocated by this call), then do the NDCACHE WRITE( ) function.</p><p id="p-0630" num="0632"><figref idref="DRAWINGS">FIG. <b>69</b></figref> shows how such an allocation would look like&#x2014;the first byte of the allocation is the lock flag (P[<b>0</b>] in the above code), which indicates that there is content within this NDCACHE of <b>1</b>MB that was allocated, and the 1 MB is comprised of a series of 4 KB allocations. <figref idref="DRAWINGS">FIG. <b>70</b></figref> is an implementation of the NDCACHE_READO and NDCACHE_WRITE( ). First, it is checked whether the cache still exists, by checking the first byte of the NDCACHE range. If it is zero, then that NDCACHE was swapped out, and thus the program returns to the application MEM_NOT_FOUND. Then the program increments the first byte of the NDCACHE range. If it equals &#x2018;1&#x2019;, then it was zero when incremented&#x2014;i.e., the NDCACHE range was swapped out and cannot be used. The program then returns the first byte to zero, and returns MEM_NOT_FOUND to the application. Now the NDCACHE range is locked (because the first byte is non-zero), and the range is read in to buffer or written from the buffer to the range, as the case may be for NDCACHE_READ or NDCACHE_WRITE respectively. After finishing the read or write, the program then decrements the lock flag to release the lock on the range by indicating it has completed the read/write and returns.</p><p id="p-0631" num="0633"><figref idref="DRAWINGS">FIG. <b>71</b></figref> is the implementation of the eviction algorithm of the NDCACHE kernel module (the NDCACHE_DRIVER). In prior art operating systems, the eviction algorithm is called when the OS needs more physical memory&#x2014;it then calls the eviction calls of the various drivers handling memory for them to clear out selected portions of the memory. Some of these drivers are programmed to copy segments of the memory in to other storage devices (such as a hard drive) and then to clear the physical memory for other uses, while other drivers may choose other forms of action. The eviction algorithm for the NDCACHE_DRIVER is described in block <b>67802</b>. Upon being called, it removes all associated memory ranges associated with LOCK_FLAG that is 0 (which means that the memory range is not in use). If more memory needs to be freed, then it can also remove the ranges who's LOCK_FLAG is 1, since they are in use but not locked. It does not remove memory ranges who's LOCK_FLAG is greater than 1, since they are currently locked by a read or write operation. As an example, there may be several NDCACHES in use, each of them of various sizes. When the eviction algorithm is called, it removes those NDCACHES associated with a lock flag that is 0 or 1, but not greater than one. Further implementations of this may choose to not remove all the NDCACHEs possible, but only enough NDCACHEs so that the OS has enough free memory (e.g. 50 MB) to continue normal operation.</p><p id="p-0632" num="0634">Block <b>67804</b> describes how the swapping out of memory ranges by an NDCACHE_DRIVER is done: Once the eviction algorithm of the NDCACHE_DRIVER decided to free a range, it maps the virtual memory pointers to an &#x201c;all zero&#x201d; range in &#x2018;read only&#x2019; mode (for example by mapping to devzero. This quickly sets the memory and the LOCK_FLAG to zero, thus freeing the physical memory for the OS to use, and marking it as empty towards the applications using the NDCACHE.</p><p id="p-0633" num="0635"><figref idref="DRAWINGS">FIG. <b>72</b></figref> is a diagram that shows the system for the fourth method of implementation for the NDCACHE, which allows for parts of the NDCACHE to be removed while keeping other parts in the memory. For example, where not all the memory ranges handled by the NDCACHE driver are attempted to be freed, but only a certain amount that will enable the OS to have more free space to operate (e.g., freeing ranges until 200 MB are free).</p><p id="p-0634" num="0636">In the previous implementation methods, an NDCACHE element in the previous implementations is assigned in one block. The problem is that this whole block is swapped out even if only a certain part needs to be swapped out by the OS (all or nothing type of approach). It is desirable to have an implementation where only portions of the allocation may be swapped out (for example, the NDCACHE element could be a whole file, and it may be useful if parts of it are swapped out). In block <b>68002</b> there are a group of pages in the physical memory of a computer (page #<b>1</b>, Page #<b>2</b>, . . . Page #N), in this example each of the pages is a range of 4 KB. In block <b>68004</b>, there is a group of flags in an area of the physical memory allocated to be the management area of the NDCACHE, where there is one such flag for every page in the memory, that is allocated to the NDCACHE. Each flag in the management area in block <b>68004</b> is actually a &#x2018;lock flag&#x2019; from the previous implementation of the NDCACHE and is used in the same way, but is done per page, so that each lock flag correlates with one page in the memory. Thus, the NDCACHE may allocate a large file from Page #<b>1</b> to Page #N, and when the OS needs more free memory then the NDCACHE's eviction algorithm may choose to free a certain memory size for the OS (e.g. 4 MB), and only remove the first 1,000 pages from this NDCACHE, instead of removing the whole cache.</p><p id="p-0635" num="0637">Hence, an NDCACHE system is disclosed, where each NDCACHE is mapped to a multitude of physical memory pages, and where there is one lock_flag associated with each such physical memory page, so that when the operating system of the computing device needs more physical memory, it can release only some of the physical pages associated with this NDCACHE.</p><p id="p-0636" num="0638"><figref idref="DRAWINGS">FIG. <b>73</b></figref> is a flowchart for implementing the fourth implementation of an NDCACHE. When an NDCACHE is requested by an application, the application calls the initialization function and specifies the size of the requested NDCACHE. In a step <b>68202</b>, physical memory is allocated for the NDCACHE as was requested by the calling application (e.g. 20 MB). The prior art OS responds by allocating such a memory segment (if available), where this memory segment is provided as series of blocks of physical pages, of a certain size as determined by the OS (e.g. 4 MB per page). In a step <b>68204</b>, a management area is allocated, where in this area there is one LOCK_FLAG for every physical page that is allocated in the step <b>68202</b>. Thus this memory size is equal to [MEM ALLOCATED]/[SIZEOF(MEMORY_PAGE)]*[SIZEOF(INT)]. For example, on an OS where a page size is 4 KB, the memory allocated for the NDCACHE is 20 MB, and an integer is 4 Bytes, the size for allocating a management area is=20 MB/4 KB*4 B=5 k*4 B=20 kB (for storing 5,000 flags of 4 bytes each).</p><p id="p-0637" num="0639">The normal operation (read/write) of the NDCACHE in the fourth implementation is similar to the earlier implementations, but where the memory for the NDCACHE is the series of memory pages allocated to the NDCACHE, and the LOCK_FLAG is not for the whole memory range allocated to the NDCACHE, but for each of the pages in that memory range, and when the eviction algorithm needs to free memory for the OS, it can evict a portion of the memory ranges, freeing up the memory range and its corresponding LOCK_FLAG from the management area.</p><p id="p-0638" num="0640"><figref idref="DRAWINGS">FIG. <b>74</b></figref> describes an improvement in the fourth method of implementation of an NDCACHE. The following are three problems with the fourth method of implementation that may be improved:</p><p id="p-0639" num="0641">1. When an NDCACHE that is smaller than the OS's memory page size (typically 4 kB) is requested, a full page (e.g. 4 kB) is allocated and thus there is waste in allocating more than is needed.</p><p id="p-0640" num="0642">2. When an NDCACHE that is larger than the page size is requested, the allocation needs to be done in multiple parts (once for each page), thus degrading performance and degrading the ease of use of the API.</p><p id="p-0641" num="0643">3. The fourth implementation does not conform to the &#x2018;malloc&#x2019;/&#x2018;free&#x2019; paradigm, which makes it more difficult to integrate in to existing and new solutions</p><p id="p-0642" num="0644">In this improvement, when a new NDCACHE is allocated, when allocating the pages in memory <b>69002</b> for the NDCACHE, a secondary management area <b>69004</b> is allocated at the first page, such that it includes a pointer to the first LOCK_FLAG in the management area <b>69006</b>, and a counter of how many pages are allocated to this NDCACHE (&#x201c;N&#x201d;) is maintained. Thus, when allocating multiple pages for an NDCACHE, the secondary management area <b>69004</b> includes all the information needed to use all pages and lock flags.</p><p id="p-0643" num="0645"><figref idref="DRAWINGS">FIG. <b>75</b></figref> is a flowchart of the initialization process for the improvement on the fourth method. In a step <b>69202</b> when the NDCACHE is requested by the application, a memory range (P) is allocated for the NDCACHE. Its size is the size of the memory requested+sizeof(T) where T is the area required for the secondary management area. Then in a step <b>69204</b> space is allocated for the management area to hold the LOCK_FLAGs for each of the memory pages required by the new NDCACHE. Then, a secondary management area (T) is defined in a step <b>69206</b>, and into it is inserted a pointer (T-&#x3e;PTR) to the management area and an integer (T-&#x3e;N) that represents the number of pages in this NDCACHE's memory range. In a step <b>69208</b> the pointer P is changed such that P=P+SIZEOF(T). This is so that P now points to the start of the main memory range (right after the secondary management area). Lastly, in a step <b>69210</b> the program returns the pointer (P+SIZEOF(T)) to the calling application, which is a pointer to the place in the memory where the NDCACHE memory itself starts (right after the secondary management section).</p><p id="p-0644" num="0646">Note that the allocations for these memory ranges can use any of the existing malloc/free implementation algorithms to allocate memory from the main NDCACHE pool to this allocation. The malloc and free can be done over mmap with the implementation of NDCACHE shown in the fourth implementation, which makes this a non-deterministic cache. Also note that if the allocation is less than one page size, T-&#x3e;N could still span more than one page, if for example this page already contains part of a previous allocation and this this new allocation causes the allocation to overrun to the next page.</p><p id="p-0645" num="0647"><figref idref="DRAWINGS">FIG. <b>76</b></figref> is a flowchart of the actions of reading from or writing to the NDCACHE for the improvement on the fourth method of implementation. In a step <b>69602</b>, the read/write is described. The read/write is done in the same way as in the fourth implementation with two exceptions: Lock(P)/unlock(P): First evaluates that T-&#x3e;N is not zero. If it is zero, then the NDCACHE was swapped and needs to return mem_not_found. If T-&#x3e;N is not zero, lock all pages that this NDCACHE element spans by locking the N LOCK_FLAGS starting at the T-&#x3e;PTR LOCK_FLAG. When reading/writing from/to the NDCACHE, not limited to one page of memory (can use the complete allocated size). In a step <b>69606</b> the deleting of the allocation&#x2014;NDCACHE_CLOSE(P)&#x2212; is described. The NDCACHE is freed by calling the OS free( ) function and providing to it the pointer of (P-SIZEOF(T)) where P is the pointer to the main memory range, and T is the secondary management area, so that the memory freed is both the secondary management area as well as the main memory area.</p><p id="p-0646" num="0648">A further note about NDCACHE: There is an advantage to being able to use named objects for NDCACHE&#x2014;i.e., for the NDCACHE objects to be named so that they can be used by multiple processes, and also lets the virtual memory related to these named objects to be freed on swap. This can be implemented over the systems described previously by adding a hash table where in the open/create of the object, this name is looked up in the hash table, and if found provides back a pointer to an existing object.</p><p id="p-0647" num="0649">There are applications that may benefit from understanding when the computer's resources are idle. For example, a screensaver monitors the mouse and keyboard movements for idleness, and after a preset amount of idle time, it activates its display program. Further, the idling period may be utilized for performing non-time sensitive activities, such as upodating and maintenance. For example, idling is detected as part of the &#x2018;Idle?&#x2019; step <b>495</b><i>a </i>in the flowchart <b>490</b><i>b. </i>Other cases are for a web site to monitor inactivity of a keyboard or mouse input, and to log out as a consequence.</p><p id="p-0648" num="0650"><figref idref="DRAWINGS">FIG. <b>77</b></figref> is a flowchart of an idle monitor that uses new inputs to define idleness of a computing device or its operator. Such a flowchart may be executed by any network element herein. In a step <b>70002</b>, an application wishes to be notified of when idleness has occurred, and so notifies the idle monitor program, provides a CallBack function (CB)&#x2014;a function to call when the idleness occurs&#x2014;and defines the type of idleness on which to call this function (PARAIVIS) and the duration of time they should be idle for the CB to be called. The program then scans in a step <b>70004</b> &#x2018;idleness&#x2019; resources and tracks for how long each has been idle. These resources include the following: Bits being sent or received to/from communication device&#x2014;i.e. idleness of communication. Storage device read or write&#x2014;i.e. idleness of the 10 with storage devices. Temperature changes in any of the device's temperature gauges&#x2014;i.e., idleness of the environment. Non-idleness of the environment could signal that there is movement in the environment of this computing device, or that the temperature around is shifting. CPU busy over certain threshold (could be 5% for example)&#x2014;i.e. idleness to a degree of the computing resources. Camera senses motion&#x2014;i.e. idleness of the physical surrounding of the computing device (movement of persons for example can trigger this to not be idle)</p><p id="p-0649" num="0651">Light sensor senses changes in light intensity or structure&#x2014;i.e., idleness of the physical surrounding of the computing device (movement of persons, for example, can trigger this to not be idle):</p><p id="p-0650" num="0652">Accelerometer that senses movement or orientation change</p><p id="p-0651" num="0653">HD accelerometer that senses movement</p><p id="p-0652" num="0654">GPS sensor that senses movement</p><p id="p-0653" num="0655">If any of the above sensors is idle in a step <b>70006</b>, then check in a step <b>70008</b> whether all sensors included in PARAMS are idle and have been idle for the amount of time as described in T. If they have all been idle for this time, call the CB.</p><p id="p-0654" num="0656">Hence, in a system monitoring the idleness of a computing device, the following sensors may be included in a list of devices to be monitored for idleness: Bits being sent or received to/from communication device, storage device read or write, temperature changes in any of the device's temperature gauges, CPU busy over certain threshold, camera senses motion, light sensor senses changes in light intensity or structure, Accelerometer that senses movement or orientation change, HD accelerometer that senses movement, GPS sensor that senses movement in location or hight</p><p id="p-0655" num="0657">In storage devices with moving media, physical seek times are typically long relative to the read or write times because of the read/write head movement, and thus should be avoided where possible. Also in storage devices, writing to the storage device is typically less urgent as reading from it, since the writing is typically to archive existing information, whereas reading data is used for actionable results (such as displaying data on the screen) and thus may be blocking.</p><p id="p-0656" num="0658">In prior art systems, reading and writing occur randomly, and thus when the typically higher priority reading is occurring, it could possibly be after a write has occurred, and thus the reading head is typically not close to the place where the information should be read from. Delaying the writing of data until storage device read/write is idle can speed up the read time, since there's then no need to wait for write to end before reading and also eliminates many seek cycles.</p><p id="p-0657" num="0659"><figref idref="DRAWINGS">FIG. <b>78</b></figref> is a diagram of a system to reduce the read times from a storage device <b>71008</b>. It includes the OS <b>71002</b>, which calls the storage read time reduction module <b>71004</b> when accessing the disk. This module uses the storage device idle monitor <b>71006</b> to determine when the storage device is idle. When the storage read time reduction module <b>71004</b> wishes to write to disk, it first ensures that the disk has been idle for a pre-determined amount of time (eg. 30 ms) before writing to the storage device. If the storage device is busy, it increases the chance that while the OS is writing data to the disk, a disk read will occur, which will be slowed down by the read time and seek time back to the place to read from. Thus, with the system described by the diagram in <figref idref="DRAWINGS">FIG. <b>78</b></figref>, such conflicts (of having a read while a write is in action) are reduced. Thus, when the storage device idle monitor reports non-idleness, then the data to be written to the disk is written to the write queue <b>71010</b> instead of to the disk.</p><p id="p-0658" num="0660">This concept may be broadened by looking not only at the idleness of the storage device <b>71008</b> by the storage device idle monitor <b>71006</b>, but by incorporating an idleness monitor that checks for a much broader set of idleness parameters such as keyboard inputs, mouse inputs, network communication, etc., since any kind of non-idleness on the computing device typically correlates to reads from the storage device, and thus storage writes should be avoided during such periods of non-idleness.</p><p id="p-0659" num="0661">Hence, in a computing system comprised of a storage device and a processor, a method for reducing the average time to read data from such storage device is disclosed, by which storage writes are only performed when the storage device has been idle for a certain amount of time (eg. 30 ms). Other parameters may be checked for idleness, such as the keyboard input, the mouse input, the network communication, etc.</p><p id="p-0660" num="0662"><figref idref="DRAWINGS">FIG. <b>79</b></figref> is a flowchart of an implementation of a storage read time reduction module SRTRM. If the SRTRM received a write command in a step <b>71202</b> then it checks in a step <b>71204</b> whether the write queue has enough free space for queuing this request. If it does, then the request is queued in a step <b>71206</b> until the storage device is idle at which time it will be written to it. If the write queue does not have enough space to queue the new write data, then the program writes in a step <b>71205</b> the new request data to the storage device. If the SRTRM has not received a write command, then it checks in a step <b>71208</b> whether the disk been idle from read commands for x milliseconds (x could be 30 for example). Alternatively or in addition, can use other parameters for idleness to determine idleness for the purpose of writing, such as mouse movement, etc.). If idleness for x milliseconds is determined, then a segment of the write queue (e.g., 500 KB) is written from the queue to the storage device.</p><p id="p-0661" num="0663">When a network element is connected to a WAP, it sometimes shortly disconnects and then reconnects. This short disconnection (sometimes referred to as &#x2018;cutoff&#x2019;) may occur due to an &#x2018;explicit user disconnect&#x2019; reason, where the user explicitly requests to disconnect from the WAP, such as due to poor service from the WAP, or because other reasons, such as turning off the network element, and disconnecting from the network (for example by turning off the WiFi switch). When the network element tries to re-connect to the WAP, it is typically preferred to first try to connect to &#x2018;favorite&#x2019; WAPs, which are commonly WAPs that the network element has already successfully previously connected to. In one example, a WAP is determined as a &#x2018;favorite&#x2019; WAP when providing high signal strength. <figref idref="DRAWINGS">FIG. <b>81</b></figref> shows a prior art diagram of a network element <b>41002</b> that is trying to connect to WAPs defined as part of a &#x2018;favorite&#x2019; group <b>42006</b>. The network element <b>41002</b> may disconnect explicitly from one of these &#x2018;favorite&#x2019; devices <b>42006</b>, for example due to poor connection or otherwise poor service, and afterwards, when the network element <b>41002</b> software tries to re-connect to a WAP, it may try to re-connect again to that problematic WAP, resulting in again a poor service. It is therefore beneficial to distinguish between &#x2018;explicit user disconnect&#x2019; reasons and &#x2018;other&#x2019; reasons associated with each WAP in the favorite group <b>42006</b>, and to first try to connect to the WAPs associated with disconnection due to &#x2018;other&#x2019; reasons.</p><p id="p-0662" num="0664"><figref idref="DRAWINGS">FIG. <b>82</b></figref> shows such a system, where the favorites group <b>41206</b> is subdivided to two sub-groups: an &#x201c;explicit user disconnect&#x201d; group <b>41220</b>, which is the group of WAPs which the user chose to disconnect from, and an &#x201c;other&#x201d; group <b>41210</b>, which is a group of the favorite WAPs (shown to include only a single WAP) that were disconnected due to &#x2018;other&#x2019; reasons, and a WAP will preferably and firstly be selected from the latter group.</p><p id="p-0663" num="0665"><figref idref="DRAWINGS">FIG. <b>83</b></figref> shows a flowchart relating to implementing such a system. In a step <b>41402</b>, it is checked if the client has just disconnected from a WAP, and then in a step <b>41404</b> a variable designated as last_dv is set to the recently disconnected WAP. A proactive disconnection by the user, such as by user pressing &#x2018;disconnect&#x2019;, is checked in a step <b>41406</b>. A poor performance disconnection is checked in a step <b>41408</b>, and as part of this step the WAP is checked to be not responding, or responding slowly. In a case the WAP was found to be disconnected not because of poor performance, then the last_dv is set as &#x201c;other&#x201d; in a step <b>41410</b>, and thus this WAP is highly prioritized, and will be first to be selected, followed by the rest of the &#x201c;Other&#x201d; WAPs, and the &#x201c;explicit user disconnect&#x201d; related WAPs are the last to be selected. If the WAP was found to be disconnected due to poor performance, then the last_dv is marked as &#x201c;explicit user disconnect&#x201d; in a step <b>41412</b>. <figref idref="DRAWINGS">FIG. <b>80</b></figref> shows a flowchart of an algorithm that describes how network elements may attempt to connect to multiple WAPs, allowing for a quick connection to a selected one of the WAPs. While exampled herein regarding connection to a WAP, any other communication device, such as a switch, router, or a gateway, using a wireless or wired connection, may be equally applied.</p><p id="p-0664" num="0666">Typical connections (including data paths and communication links) via a network, and in particular via a packet-based network such as the Internet <b>113</b>, are associated with a reliability that is less than 100%. The reliability is typically measured as the number of packets that do not reach their destination intact, but can also be measured by their latency, bandwidth, and other factors. <figref idref="DRAWINGS">FIG. <b>84</b></figref> is a diagram of a common arrangement, where a Network Element <b>1</b> (NE<b>1</b>) <b>25</b> communicates with another Network Element <b>2</b> (NE<b>2</b>) <b>26</b>, where there are only multiple unreliable connections available between the two elements. Typically, a connection for fetching by the NE<b>1</b> <b>25</b> of a part of, or all of, a content from the NE<b>2</b> <b>26</b>, is established using only a single connection <b>24004</b>, out of these available unreliable connections. For example, in a case where Voice over IP (VoIP) call is carried between the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b> over one of these unreliable connections, that drops, for example, 1% of the packets, then 1 out of every 100 packets of the call will be lost, resulting in a low quality call. The other available unreliable connections between the two network elements may be used to increase the reliability, as shown schematically in <figref idref="DRAWINGS">FIGS. <b>85</b>, <b>86</b>, and <b>87</b></figref>, illustrating the utilizing of additional connections for increased connection reliability.</p><p id="p-0665" num="0667"><figref idref="DRAWINGS">FIG. <b>85</b></figref> shows a using of the multiple unreliable connections <b>24204</b> for communication between the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b>, implemented by a special program that is installed on both the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b>. This program transmits each packet from the NE<b>1</b> <b>25</b> to the NE<b>2</b> <b>26</b>, or vice versa, over two or more data routes. Thus, the resulted unreliability is decreased by a factor received by multiplying the unreliability of the routes, and the used bandwidth is increased by a factor corresponding to the number of routes used. In one example, 3 (three) data routes are used, and assuming each data route reliability 99% (i.e., 99 out of 100 packets typically reach their destination intact) whereby the unreliability of a single connection is 1%, then the resulted unreliability of the new scheme is 1% (unreliability){circumflex over (&#x2003;)}3 (number of routes)=0.0001%, and the available bandwidth is triple the bandwidth available when using a single data path. Multiple routes may be implemented by using a program that uses available multiple network interfaces of the network elements, where packets are sent the packet over two or more of the available interfaces, or alternatively by using peer devices (such as the peer device #<b>1</b> <b>102</b><i>a </i>and the peer device #<b>2</b> <b>102</b><i>b</i>) as described herein or in the '604 Patent.</p><p id="p-0666" num="0668">In one example, the program may be installed on only one of the network elements. In such a scheme, a network element designated as a reliability proxy may be used, on which the program is installed. Preferably, the reliability proxy may use multiple connections to the other network element. A scheme using a reliability proxy is shown in <figref idref="DRAWINGS">FIG. <b>86</b></figref>, used for communication between the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b>, and the program is installed on the NE<b>1</b> <b>25</b> but not on the NE<b>2</b> <b>26</b>. The NE<b>1</b> <b>25</b> queries a reliability proxy network server <b>24301</b> and provides the server the identifier (e.g., IP address) of the NE<b>2</b> <b>26</b>. The server <b>24301</b> responds by providing the NE<b>1</b> <b>25</b> the identifier (e.g., IP address) of a Reliability Proxy (RP) <b>24308</b> to be used. The RP <b>24308</b> is a network element on which the program is installed, and which has a connection <b>24310</b> to NE<b>2</b> <b>26</b>, which is preferably more reliable than the direct connection between the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b>. The NE<b>1</b> <b>25</b> then communicates with the RP <b>24308</b> via multiple routes <b>24306</b>, and the RP <b>24308</b> communicates with NE<b>2</b> <b>26</b> through the reliable connection <b>24310</b>. Thus, the information is reliably carried over the routes <b>24306</b>, providing a more reliable connection than the single route that may be used, since the original route <b>24004</b> is included in <b>24306</b>, and using additional routes improves the reliability, and since route <b>24310</b> is more reliable by selection, the total obtained reliability is higher than a single direct connection between the two devices.</p><p id="p-0667" num="0669">It is also possible to use this method in a configuration where neither the NE<b>1</b> <b>25</b> nor the NE<b>2</b> <b>26</b> includes the program installed, as shown in <figref idref="DRAWINGS">FIG. <b>87</b></figref>. In this scheme, the NE<b>1</b> <b>25</b> is manually configured to use the reliability proxy <b>24404</b> as a reliability proxy, and that reliability proxy then uses a reliability proxy network server <b>24401</b> to find a reliability proxy <b>24406</b> that can be used to communicate with the NE<b>2</b> <b>26</b>.</p><p id="p-0668" num="0670">A flowchart of the program is shown in <figref idref="DRAWINGS">FIG. <b>88</b></figref>. The program is activated in a step <b>24602</b> when the NE<b>1</b> <b>25</b> requests to communicate with the NE<b>2</b> <b>26</b>. The program then checks in a step <b>24604</b> whether the existing direct connection between the two network elements is good enough, such as by using the RTT and BW of the direct connection route. If the existing route is good enough, then a direct communication is initiated in the step <b>24606</b>, as known in the art. However, if the existing route is not good enough, then in a step <b>24622</b> the program checks whether the NE<b>2</b> <b>26</b> has the program installed. The network elements on which the program is installed report to the server upon being online, and the server logs this information in a reliability database This can be done by sending a query to the NE<b>2</b> <b>26</b>, so that if the program exists, the device so acknowledges, or by requesting such information from the reliability proxy network server by using the server reliability database. If the NE<b>2</b> <b>26</b> does have the program installed, then a direct communication is used between the NE<b>1</b> <b>25</b> and NE<b>2</b> <b>26</b>, using multiple routes (as in <figref idref="DRAWINGS">FIG. <b>85</b></figref>), as described in <figref idref="DRAWINGS">FIG. <b>89</b></figref>. If the NE<b>2</b> <b>26</b> does not have the program installed, then a request is sent in a step <b>24608</b> to the Reliability Proxy Network Server (RPNS) for a proxy to use for the communication. The response received in a step <b>25610</b> from the RPNS provides an identifier of a Reliability Proxy Device (RPD) that may use a data path to the NE<b>2</b> <b>26</b> that is more reliable than a direct connection from the NE<b>1</b> <b>25</b> to the NE<b>2</b> <b>26</b>, if such a path exists. The NE<b>1</b> <b>25</b> then sends in a step <b>24612</b> the information to the RPD via the multiple routes between them as described in <figref idref="DRAWINGS">FIG. <b>89</b></figref>. If there is no such data path, then a direct communication is established, such as in the step <b>24606</b>.</p><p id="p-0669" num="0671">A method of transmitting packets in parallel over multiple routes, between the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b>, is described in <figref idref="DRAWINGS">FIG. <b>89</b></figref>. In a step <b>24702</b> NE<b>1</b> <b>25</b> receives from a routing unit the number of routes available to the NE<b>2</b> <b>26</b>, and the reliability associated with each one of the routes. In a step <b>24704</b>, the routes to be uses are selected as follows: A Desired Reliability (DR) is first set, and the available routes are ranked based on their reliability, where the highest reliability is listed first as Route #<b>1</b>, assuming to be associated with a reliability of R<b>1</b>, the second reliable route is listed second as Route #<b>2</b>, assuming to be associated with a reliability of R<b>2</b>, and so on, until the less reliable route is Route #N with an associated reliability of the RN. The routes to use are determined by multiplying (<b>1</b>-R<b>1</b>)*(<b>1</b>-R<b>2</b>)*(<b>1</b>-R<b>3</b>) . . . , until the product is lower than DR. Note that (<b>1</b>-Rn) is the &#x201c;unreliability&#x201d; of a route n whose reliability is Rn, and thus the product of the &#x2018;unreliability&#x2019; of the routes is the un-reliability of the parallel use of the multiple routes, assuming that the routes R<b>1</b>, R<b>2</b>, . . . Rx are used for this particular communication between the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b>. During the communication session between the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b>, each packet to be transmitted is carried in a step <b>24706</b> over all the selected routes. On the receiving side, each unique packet received is passed in a step <b>24708</b> to the application, and other similar packets received from the other routes are discarded. In the case of a missing packet over the fastest connection, that packet is expected to be received via the second fastest connection.</p><p id="p-0670" num="0672">In addition to packet loss, unreliable connections typically frequently disconnect. In such a case, the communicating devices try to reconnect, and often succeed. However, such a disconnection may create discontinuity that may be detected by the communicating applications, and may impact their performance, such as a producing a &#x201c;404 page not found&#x201d; message in a web browser. However, if the disconnection is not detected by the applications until the re-connection is established, the discontinuity could be avoided. Thus, it is desirable to delay for a short time the signaling to the applications, until the connection is re-established, as described in a flowchart in <figref idref="DRAWINGS">FIG. <b>90</b></figref>.</p><p id="p-0671" num="0673">In a step <b>24802</b> the NE<b>1</b> <b>25</b> initiates a communication with other network element, such as the NE<b>2</b> <b>26</b>. The connection from the NE<b>1</b> <b>25</b> to the NE<b>2</b> <b>26</b> is established in a step <b>24804</b> through a Reliability Proxy program (RP) in each of the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b> (if such an RP exists). If the RP does not exist in the NE<b>1</b> <b>25</b>, then it can be configured to use an external device as a Reliability Proxy (RP). If the RP does not exist in the NE<b>2</b> <b>26</b>, then the NE<b>1</b> <b>25</b> requests an RP from the reliability proxy network server, and communicates with it, instead of communicating directly with the NE<b>2</b> <b>26</b>, where the RP will proxy the messages to the NE<b>2</b> <b>26</b> so that effectively the NE<b>1</b> <b>25</b> is communicating with the NE<b>2</b> <b>26</b>.</p><p id="p-0672" num="0674">The connection between the RPs may be disconnected as determined in a step <b>24810</b> (whether the RPs are within the NE<b>1</b> <b>25</b> and the NE<b>2</b> <b>26</b>, or external to them). If the connection was disconnected, then in a step <b>24812</b> the reliability proxies hold the connection between them and the operating system that they are acting as a proxy for, for a set short amount of time that it would take to re-connect the broken connection in a reasonable scenario (e.g., 200 ms). Holding the connection may be performed in a way similar to the virtual application gateway described in <figref idref="DRAWINGS">FIG. <b>51</b></figref>. During the period that the connection to the operating system is held, the RPs try to reconnect with each other in a step <b>24814</b>. If the re-connection succeeds within the set time, then communication resumes without a break from the operating system perspective. However, if the re-connection did not succeed in the set amount of time, then the OS is notified of the disconnection.</p><p id="p-0673" num="0675">The systems and methods herein may use redundant communication routes (or data paths), that may be based on standby redundancy, (a.k.a. Backup Redundancy), where one of the data paths or the associated hardware is considered as a primary unit, and the other data path (or the associated hardware) is considered as the secondary unit, serving as back up to the primary unit. The secondary unit typically does not monitor the system, but is there just as a spare. The standby unit is not usually kept in sync with the primary unit, so it must reconcile its input and output signals on the takeover of the communication. This approach does lend itself to give a &#x201c;bump&#x201d; on transfer, meaning the secondary operation may not be coordinated with the last system state of the primary unit. Such mechanism may require a watchdog, which monitors the system to decide when a switchover condition is met, and command the system to switch control to the standby unit. Standby redundancy configurations commonly employ two basic types, namely &#x2018;Cold Standby&#x2019; and &#x2018;Hot Standby&#x2019;.</p><p id="p-0674" num="0676">In a cold standby scheme, the secondary unit is either powered off or otherwise non-active in the system operation, thus preserving the reliability of the unit. The drawback of this design is that the downtime is greater than in hot standby, because the standby unit needs to be powered up or activated, and brought online into a known state.</p><p id="p-0675" num="0677">In a hot standby scheme, the secondary unit is powered up or otherwise kept operational, and can optionally monitor the system. The secondary unit may serve as the watchdog and/or voter to decide when to switch over, thus eliminating the need for an additional hardware for this job. This design does not preserve the reliability of the standby unit as well as the cold standby design. However, it shortens the downtime, which in turn increases the availability of the system. Some flavors of Hot Standby are similar to Dual Modular Redundancy (DMR) or Parallel Redundancy. The main difference between Hot Standby and DMR is how tightly the primary and the secondary are synchronized. DMR completely synchronizes the primary and secondary units.</p><p id="p-0676" num="0678">While a redundancy of two was exampled above, where two data paths and two hardware devices were used, a redundancy involving three or more data paths or systems may be equally used. The term &#x2018;N&#x2019; Modular Redundancy, (a.k.a. Parallel Redundancy) refers to the approach of having multiply units or data paths running in parallel. All units are highly synchronized and receive the same input information at the same time. Their output values are then compared and a voter decides which output values should be used. This model easily provides bumpless switchovers. This model typically has faster switchover times than Hot Standby models, thus the system availability is very high, but because all the units are powered up and actively engaged with the system operation, the system is at more risk of encountering a common mode failure across all the units.</p><p id="p-0677" num="0679">Deciding which unit is correct can be challenging if only two units are used. If more than two units are used, the problem is simpler, usually the majority wins or the two that agree win. In N Modular Redundancy, there are three main typologies: Dual Modular Redundancy, Triple Modular Redundancy, and Quadruple Redundancy. The Quadruple Modular Redundancy (QMR) is fundamentally similar to the TMR but using four units instead of three to increase the reliability. The obvious drawback is the 4&#xd7; increase in system cost.</p><p id="p-0678" num="0680">Dual Modular Redundancy (DMR) uses two functional equivalent units, thus either can control or support the system operation. The most challenging aspect of DMR is determining when to switch over to the secondary unit. Because both units are monitoring the application, a mechanism is needed to decide what to do if they disagree. Either a tiebreaker vote or simply the secondary unit may be designated as the default winner, assuming it is more trustworthy than the primary unit. Triple Modular Redundancy (TMR) uses three functionally equivalent units to provide a redundant backup. This approach is very common in aerospace applications where the cost of failure is extremely high. TMR is more reliable than DMR due to two main aspects. The most obvious reason is that two &#x201c;standby&#x201d; units are used instead of just one. The other reason is that in a technique called diversity platforms or diversity programming may be applied. In this technique, different software or hardware platforms are used on the redundant systems to prevent common mode failure. The voter decides which unit will actively control the application. With TMR, the decision of which system to trust is made democratically and the majority rules. If three different answers are obtained, the voter must decide which system to trust or shut down the entire system, thus the switchover decision is straightforward and fast.</p><p id="p-0679" num="0681">Another redundancy topology is 1:N Redundancy, where a single backup is used for multiple systems, and this backup is able to function in the place of any single one of the active systems. This technique offers redundancy at a much lower cost than the other models by using one standby unit for several primary units. This approach only works well when the primary units all have very similar functions, thus allowing the standby to back up any of the primary units if one of them fails. While the redundant data paths have been exampled with regard to the added reliability and availability, redundant data paths may as well be used in order to provide higher aggregated data rate, allowing for faster response and faster transfer of data over the multiple data paths.</p><p id="p-0680" num="0682">A client device may connect to one of multiple sources for fetching data therefrom. The client device may estimate in advance the Bandwidth (BW) and Round Trip Time (RTT) relating to a connection to each of the sources, in order to estimate the best source to use. Further, a client device may use several available peer devices for loading chunks therefrom. A chunk may, include, for example, 16 KB of data. Assuming that there are two peers devices, designated as P<b>1</b> and P<b>2</b>, respectively associated with the following BW/RTT times: P<b>1</b>_BW=2,000 Kb/s P<b>1</b>_RTT=30 ms and P<b>2</b>_BW=4,000 Kb/s P<b>2</b> RTT=70 ms, then the estimated time for a transaction using P<b>1</b> would be 30 ms+16,000*8/2,000,000=30 ms+64 ms=94 ms, whereas a transaction using P<b>2</b> would be 60 ms+16,000*8/4,000,000=70 ms+32 ms=102 ms. In such a case, it would be beneficial for the client device to select and use P<b>1</b>. Other examples of such networks include an HTTP client that may access two different web servers for obtaining a certain URL, such as the original web server, and a CDN storing the URL content. However, the client device may not have previously (or lately) communicated with a source, and thus may not possess the BW and the RTT data needed for the evaluation. In such a case, it would be beneficial to have an algorithm for estimating BT/RTT with the source.</p><p id="p-0681" num="0683"><figref idref="DRAWINGS">FIG. <b>91</b></figref> shows a network that includes a client device <b>2</b> and four available sources <b>20802</b>, <b>20804</b>, <b>20806</b>, and <b>20808</b>, as well as a database <b>20810</b> in the client device <b>2</b> that keeps track of the IPs, BW and RTTs of the various sources that were previously communicated with. This database <b>20810</b> may also include the time of the last connection, as well as other data. The database <b>20810</b> may sort the sources according to their respective IPs, such that if a source_<b>1</b> is shown in the table (representing the database <b>20810</b>) in a column that is left to a source_<b>2</b> related column, then necessarily the IP of source_<b>1</b> is smaller than the IP of source_<b>2</b>.</p><p id="p-0682" num="0684">In the example shown in <figref idref="DRAWINGS">FIG. <b>91</b></figref>, the Client <b>2</b> has previously connected with the source_<b>1</b> <b>20802</b> and with the source <b>4</b> <b>20808</b>, and hence stores in the database <b>20810</b> the BW and RTT for these two sources. The Client <b>2</b> may require evaluating the BW and RTT to source_<b>2</b> <b>20804</b>, in order to determine whether to use it, or to seek for an alternative source (or not to communicate at all).</p><p id="p-0683" num="0685">In such a case, the client needs to assess the BW and RTT of the source_<b>2</b>. A good estimation (or a guess) may assume that the values of the BW and RTT of the source_<b>2</b> are between the values of BW and RTT of source <b>1</b> and source <b>4</b>, which are the sources of either side of the source_<b>2</b> (in terms of IP address), based on the information stored in the database <b>20810</b>. The estimated values of the source_<b>2</b> related BW and RTT might be derived in various ways. For example, using proportional estimation, so that when the BW and RTT of source <b>1</b> are respectively BW<b>1</b> and RTT<b>1</b>, for source <b>4</b> they are respectively BW<b>4</b> and RTT<b>4</b>, and for source <b>2</b> they are respectively BW<b>2</b> and RTT<b>2</b>, then BW<b>2</b> and RTT<b>2</b> can be calculated by their relative IP distance from BW<b>1</b> and BW<b>4</b> and between RTT<b>1</b> and RTT<b>4</b>. Other ways to calculate can be a regular average, such as BW<b>2</b>=(BW<b>1</b>+BW<b>4</b>)/2.</p><p id="p-0684" num="0686">Alternatively or in addition, the database <b>20810</b> may reside on a server on the network, and thus a client device may request and fetch therefrom information about connecting to various sources, even those that it has not previously or lately connected with, based on connections with other client devices that have communicated with it and logged their results to this networked database.</p><p id="p-0685" num="0687"><figref idref="DRAWINGS">FIG. <b>92</b></figref> shows a flowchart for estimating a source related BW and RTT. In a step <b>21002</b>, the client device is maintaining a database <b>20810</b> of network elements that it has communicated with, where for each of these network elements the associated BW and RTT of the connection, and optionally the time of a connection for each, is stored. In the database <b>20810</b>, the network elements are sorted by their IP distance from the client device, where the IP distance is the difference between the IP of the source and the IP of the client. The client device is requesting in a step <b>21004</b> to communicate with a source (source_x), and thus first assesses the BW and RTT that relates to the source_x. In a step <b>21012</b>, it is checked whether relevant information about the BW and RTT to source_x already exists in the database <b>20810</b>. It is noted that this database may be local&#x2014;in the client device, or available via a network and thus accessible by multiple clients. If the source_x entry exists in the database, then these stored values of the BW and the RTT are assumed for the source_x. If not, then the client gets information from the database about the BW and RTT for the two sources that are associated with IP addresses on either side, such as a lower one and a higher one, of the source_x (in terms of IP distance). The client device uses these two data points to assess the BW and RTT, using any of a variety of methods, such as using a regular average or a weighted average.</p><p id="p-0686" num="0688">A large database may be used to store data relating to the connections characteristics (such as BW and RTT) to various network elements. Over time this data accumulates, and may be reduced by storing only valuable information, as shown in a flowchart <figref idref="DRAWINGS">FIG. <b>93</b></figref>, describing a method for storing only the data pertaining to certain network elements, which are indicative of other network elements in their vicinity.</p><p id="p-0687" num="0689">The system initializes in a step <b>21202</b>, when the system starts for the first time, before the database is initialized. As part of an initialization process, a database is created, with entries that signify logarithmic IP distances from the local network element. Thus, a first entry will be for an IP_dist=1, a second for an IP_dist=2, a third for an IP_dist=4, a fourth for an IP_dist=8, etc., until the farthest IP distance possible in the network that the local network element is operating in (for an IPv4 network example, the smallest IP address is 0.0.0.0 and the largest address is 255.255.255.255, the largest IP distance is half of the difference between these two addresses).</p><p id="p-0688" num="0690">In a step <b>21204</b>, it is checked whether the database is accessed for reading or writing. The database is accessed for reading when a program requests the estimated BW &#x26; RTT between the local network element (associated with IP that is designated as a HOST_IP), and a certain network element to which this local network element is considering to communicate with (associated with IP that is designated as IP_NEW). The database is accessed for writing when the local network element has completed a communication session to another network element, or otherwise found out information about the BW &#x26; RTT to that network element in other ways, and requests to write the newly learned data (NEW_BW, NEW_RTT) to the database so that the system can make later better assessments of the BW &#x26; RTT.</p><p id="p-0689" num="0691">Next, the IP distance (IP_DISTANCE) is calculated in a step <b>21206</b> between the HOST_IP to the IP_NEW by finding the number of IPs that are between the HOST_IP and the IP_NEW. Note that in the case of using IP distance, this method considers that the IP addresses are &#x2018;connected at the edges&#x2019;, meaning that the first address (0.0.0.0 in IPv4) is 1 IP address away from the last address (255.255.255.255 in IPv4), and thus there are two different IP distances between each 2 points. The IP_DISTANCE is calculated as the minimum between these two distances. In a step <b>21208</b>, the logarithmic distance (DIST) from HOST_IP to the NEW_IP is calculated. The DIST is calculated as the Round_down(log_b<b>2</b>(IP_DISTANCE)&#x2014;where the rounding down the log (in base <b>2</b>) of the IP_DISTANCE between HOST_IP and IP_NEW. If the database action was for a READ action, then in a step <b>21212</b> the BW &#x26; RTT are read from the entry [DIST] of the database. If the database action was for a WRITE action, then in a step <b>21214</b> the NEW_BW &#x26; NEW_RTT are written to the entry [DIST]. Note that the NEW_BW &#x26; NEW_RTT may also be written to the database in other methods, in order to keep track also of historical data. For example, the NEW_BW &#x26; NEW_RTT may be averaged in with the other data samples (by keeping the latest average and the number of samples in the database), or in any other similar methods.</p><p id="p-0690" num="0692">When network elements use BW &#x26; RTT values from the tables, they could benefit from &#x2018;teaching&#x2019; each other about the information they already have about BW &#x26; RTT between them and other network elements. <figref idref="DRAWINGS">FIG. <b>94</b></figref> is a flowchart showing a method where network elements can share BW &#x26; RTT information so that a network element that wishes to communicate with a network element that it has not recently communicate with, may assess the BW &#x26; RTT to it by learning from the experience of other network elements that have recently communicated with that network element. The method starts with scheduling an update of other network elements in a step <b>21404</b>. The scheduling can be set to either happen at constant time intervals, when the local host is idle, when both the local host and other network element to be updated are idle, or when finished communicating with other network element. If the scheduled event of updating other network elements with the table from the local network element, then a list is created in a step <b>21408</b> of which of the network elements to update. This can be all the network elements that have been recently communicated with, or a central server that will be updated and update other network elements, or by getting a list from such a central server. The BW &#x26; RTT of this local host are then communicated to the elements in this list.</p><p id="p-0691" num="0693">In a step <b>21410</b> the local host receives a BW &#x26; RTT table (UPDATE_DB) from a different network element associated with an IP that is IP_ELEMENT. Then, for each non-empty entry in the UPDATE_DB (entry marked as &#x2018;E&#x2019;), the following set of actions is performed: First, in a step <b>21414</b> the IP of the network element that provided the UPDATE_DB (IP_ELEMENT) is looked up in the local network element database, and the resulting BW and RTT are stored in memory as BW_ELEMENT and RTT_ELEMENT (these are the BW and RTT between the local network element and the network element that is providing the UPDATE_DB). Then, in a step <b>21416</b>, the BW &#x26; RTT in entry &#x2018;E&#x2019; are stored in memory as BW_E and RTT_E. In a step <b>21418</b>, the IP distance from the network element to the &#x2018;E&#x2019; associated IP is calculated and stored in the data base as IP_DIST_E. In a step <b>21420</b>, the local database entry for the IP distance of (IP_ELEMENT_DIST+IP_DIST_E) is updated where the BW value receives the value of BW_HOST+BW_E and the RTT value receives the value of RTT_HOST+RTT_E.</p><p id="p-0692" num="0694">The term &#x2018;network element&#x2019; (or &#x2018;element&#x2019;) is used herein to include, but not limited to, a tunnel-based client device (such as the client device #<b>1</b> <b>31</b><i>a</i>), a tunnel-based acceleration server (such as the acceleration server <b>32</b>), a tunnel device (such as the tunnel device #<b>1</b> <b>33</b><i>a</i>), a peer-based client device (such as the client device #<b>1</b> <b>31</b><i>a</i>), an agent device (such as the agent device #<b>1</b> <b>103</b><i>a</i>), a peer device (such as the peer device #<b>1</b> <b>102</b><i>a</i>), a peer-based acceleration server (such as the acceleration server <b>202</b>), or a data server (such as the data server #<b>1</b> <b>22</b><i>a</i>). The terms &#x2018;chunk&#x2019; and &#x2018;slice&#x2019; are interchangeably used herein to include, but not limited to, a part of, or the entire of, a content. Any memory, storage, database, or cache mentioned herein may consist of, comprise, use, or be included in, the local cache as described in U.S. Pat. No. 8,135,912 to the Shribman et al., entitled: &#x201c;System and Method of Increasing Cache Size&#x201d;.</p><p id="p-0693" num="0695">The steps described herein may be sequential, and performed in the described order. For example, in a case where a step is performed in response to another step, or upon completion of another step, the steps are executed one after the other. However, in case where two or more steps are not explicitly described as being sequentially executed, these steps may be executed in any order, or may be simultaneously performed. Two or more steps may be executed by two different network elements, or in the same network element, and may be executed in parallel using multiprocessing or multitasking.</p><p id="p-0694" num="0696">A tangible machine-readable medium (such as a storage) may have a set of instructions detailing part (or all) of the methods and steps described herein stored thereon, so that when executed by one or more processors, may cause the one or more processors to perform part of, or all of, the methods and steps described herein. Any of the network elements may be a computing device that comprises a processor and a computer-readable memory (or any other tangible machine-readable medium), and the computer-readable memory may comprise computer-readable instructions such that, when read by the processor, the instructions causes the processor to perform the one or more of the methods or steps described herein.</p><p id="p-0695" num="0697">Any device or network element herein may comprise, consists of, or include a Personal Computer (PC), a desktop computer, a mobile computer, a laptop computer, a notebook computer, a tablet computer, a server computer, a handheld computer, a handheld device, a Personal Digital Assistant (PDA) device, a cellular handset, a handheld PDA device, an on-board device, an off-board device, a hybrid device, a vehicular device, a non-vehicular device, a mobile or portable device, a non-mobile or a non-portable device. Further, any device or network element herein may comprise, consist of, or include a major appliance (white goods) and may be an air conditioner, dishwasher, clothes dryer, drying cabinet, freezer, refrigerator, kitchen stove, water heater, washing machine, trash compactor, microwave oven and induction cooker. The appliance may similarly be a &#x2018;small&#x2019; appliance such as TV set, CD or DVD player, camcorder, still camera, clock, alarm clock, video game console, HiFi or home cinema, telephone or answering machine.</p><p id="p-0696" num="0698">The term &#x2018;host&#x2019; or &#x2018;network host&#x2019; is used herein to include, but not limited to, a computer or other device connected to a computer network, such as the Internet. A network host may offer information resources, services, and applications to users or other nodes on the network, and is typically assigned a network layer host address. Computers participating in networks that use the Internet Protocol Suite may also be called IP hosts, and computers participating in the Internet are called Internet hosts, or Internet nodes. Internet hosts and other IP hosts have one or more IP addresses assigned to their network interfaces. The addresses are configured either manually by an administrator, automatically at start-up by means of the Dynamic Host Configuration Protocol (DHCP), or by stateless address autoconfiguration methods. Network hosts that participate in applications that use the client-server model of computing, are classified as server or client systems. Network hosts may also function as nodes in peer-to-peer applications, in which all nodes share and consume resources in an equipotent manner.</p><p id="p-0697" num="0699">The arrangements and methods described herein may be implemented using hardware, software or a combination of both. The term &#x201c;software integration&#x201d; or any other reference to the integration of two programs or processes herein, is used herein to include, but not limited to, software components (e.g., programs, modules, functions, processes, etc.) that are (directly or via another component) combined, working or functioning together or form a whole, commonly for sharing a common purpose or set of objectives. Such software integration can take the form of sharing the same program code, exchanging data, being managed by the same manager program, executed by the same processor, stored on the same medium, sharing the same GUI or other user interface, sharing peripheral hardware (such as a monitor, printer, keyboard and memory), sharing data or a database, or being part of a single package. The term &#x201c;hardware integration&#x201d; or integration of hardware components is used herein to include, but not limited to, hardware components that are (directly or via another component) combined, working or functioning together or form a whole, commonly for sharing a common purpose or set of objectives. Such hardware integration can take the form of sharing the same power source (or power supply) or sharing other resources, exchanging data or control (e.g., by communicating), being managed by the same manager, physically connected or attached, sharing peripheral hardware connection (such as a monitor, printer, keyboard and memory), being part of a single package or mounted in a single enclosure (or any other physical collocating), sharing a communication port, or used or controlled with the same software or hardware. The term &#x201c;integration&#x201d; herein is used herein to include as applicable, but not limited to, a software integration, a hardware integration, or any combination thereof.</p><p id="p-0698" num="0700">Any networking protocol may be utilized for exchanging information between the network elements (e.g., clients, tunnels, peers, servers) within the network (such as the Internet). For example, it is contemplated that communications can be performed using TCP/IP. Generally, HTTP and HTTPS are utilized on top of TCP/IP as the message transport envelope. These two protocols are able to deal with firewall technology better than other message management techniques. However, partners may choose to use a message-queuing system instead of HTTP and HTTPS if greater communications reliability is needed. A non-limiting example of a message queuing system is IBM's MQ-Series or the Microsoft Message Queue (MSMQ). The system described hereinafter is suited for both HTTP/HTTPS, message-queuing systems, and other communications transport protocol technologies. Furthermore, depending on the differing business and technical requirements of the various partners within the network, the physical network may embrace and utilize multiple communication protocol technologies.</p><p id="p-0699" num="0701">The term &#x201c;port&#x201d; refers to a place of access to a device, electrical circuit or network, where energy or signal may be supplied or withdrawn. The term &#x201c;interface&#x201d; of a networked device refers to a physical interface, a logical interface (e.g., a portion of a physical interface or sometimes referred to in the industry as a sub-interface&#x2014;for example, such as, but not limited to a particular VLAN associated with a network interface), and/or a virtual interface (e.g., traffic grouped together based on some characteristic&#x2014;for example, such as, but not limited to, a tunnel interface). As used herein, the term &#x201c;independent&#x201d; relating to two (or more) elements, processes, or functionalities, refers to a scenario where one does not affect nor preclude the other. For example, independent communication such as over a pair of independent data routes means that communication over one data route does not affect nor preclude the communication over the other data routes.</p><p id="p-0700" num="0702">Some embodiments may be used in conjunction with various devices, network elements, and systems, for example, a Personal Computer (PC), a desktop computer, a mobile computer, a laptop computer, a notebook computer, a tablet computer, a server computer, a handheld computer, a handheld device, a Personal Digital Assistant (PDA) device, a cellular handset, a handheld PDA device, an on-board device, an off-board device, a hybrid device, a vehicular device, a non-vehicular device, a mobile or portable device, a non-mobile or non-portable device, a wireless communication station, a wireless communication device, a wireless Access Point (AP), a wired or wireless router, a wired or wireless modem, a wired or wireless network, a Local Area Network (LAN), a Wireless LAN (WLAN), a Metropolitan Area Network (MAN), a Wireless MAN (WMAN), a Wide Area Network (WAN), a Wireless WAN (WWAN), a Personal Area Network (PAN), a Wireless PAN (WPAN), devices and/or networks operating substantially in accordance with existing IEEE 802.11, 802.11a, 802.11b, 802.11g, 802.11k, 802.11n, 802.11r, 802.16, 802.16d, 802.16e, 802.20, 802.21 standards and/or future versions and/or derivatives of the above standards, units and/or devices which are part of the above networks, one way and/or two-way radio communication systems, cellular radio-telephone communication systems, a cellular telephone, a wireless telephone, a Personal Communication Systems (PCS) device, a PDA device which incorporates a wireless communication device, a mobile or portable Global Positioning System (GPS) device, a device which incorporates a GPS receiver or transceiver or chip, a device which incorporates an RFID element or chip, a Multiple Input Multiple Output (MIMO) transceiver or device, a Single Input Multiple Output (SIMO) transceiver or device, a Multiple Input Single Output (MISO) transceiver or device, a device having one or more internal antennas and/or external antennas, Digital Video Broadcast (DVB) devices or systems, multi-standard radio devices or systems, a wired or wireless handheld device (e.g., BlackBerry, Palm Treo), a Wireless Application Protocol (WAP) device, or the like.</p><p id="p-0701" num="0703">As used herein, the terms &#x201c;program&#x201d;, &#x201c;programmable&#x201d;, and &#x201c;computer program&#x201d; are meant to include any sequence or human or machine cognizable steps which perform a function. Such programs are not inherently related to any particular computer or other apparatus, and may be rendered in virtually any programming language or environment including, for example, C/C++, Fortran, COBOL, PASCAL, assembly language, markup languages (e.g., HTML, SGML, XML, VoXML), and the likes, as well as object-oriented environments such as the Common Object Request Broker Architecture (CORBA), Java&#x2122; (including J2ME, Java Beans, etc.) and the likes, as well as in firmware or other implementations. Generally, program modules include routines, programs, objects, components, data structures, etc., that performs particular tasks or implement particular abstract data types. The term &#x201c;application program&#x201d; (also referred to as &#x2018;application&#x2019;, &#x2018;software application&#x2019;, or &#x2018;application software&#x2019;) is used herein to include, but not limited to, a computer program designed to perform a specific function directly for a user, or for another application program. Application software is typically a set of one or more programs designed to carry out operations for a specific application. Commonly, an application software is dependent on system software that manages and integrates computer capabilities, but does not directly perform tasks that benefit the user, such as an operating system, to execute. Examples of types of application software may include accounting software, media players, and office suites. Applications may be bundled with the computer and its system software, or may be published separately, and further may be developed and coded as a proprietary, or as an open-source, software. Most applications are designed to help people perform an activity.</p><p id="p-0702" num="0704">The terms &#x201c;task&#x201d; and &#x201c;process&#x201d; are used generically herein to describe any type of running programs, including, but not limited to a computer process, task, thread, executing application, operating system, user process, device driver, native code, machine or other language, etc., and can be interactive and/or non-interactive, executing locally and/or remotely, executing in foreground and/or background, executing in the user and/or operating system address spaces, a routine of a library and/or standalone application, and is not limited to any particular memory partitioning technique. The steps, connections, and processing of signals and information illustrated in the figures, including, but not limited to any block and flow diagrams and message sequence charts, may typically be performed in the same or in a different serial or parallel ordering and/or by different components and/or processes, threads, etc., and/or over different connections and be combined with other functions in other embodiments, unless this disables the embodiment or a sequence is explicitly or implicitly required (e.g., for a sequence of reading the value, processing the value&#x2014;the value must be obtained prior to processing it, although some of the associated processing may be performed prior to, concurrently with, and/or after the read operation). Where certain process steps are described in a particular order or where alphabetic and/or alphanumeric labels are used to identify certain steps, the embodiments are not limited to any particular order of carrying out such steps. In particular, the labels are used merely for convenient identification of steps, and are not intended to imply, specify or require a particular order for carrying out such steps. Furthermore, other embodiments may use more or less steps than those discussed herein. They may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.</p><p id="p-0703" num="0705">The corresponding structures, materials, acts, and equivalents of all means plus function elements in the claims below are intended to include any structure, or material, for performing the function in combination with other claimed elements as specifically claimed. The description of the present invention has been presented for purposes of illustration and description, but is not intended to be exhaustive or limited to the invention in the form disclosed. The present invention should not be considered limited to the particular embodiments described above, but rather should be understood to cover all aspects of the invention as fairly set out in the attached claims. Various modifications, equivalent processes, as well as numerous structures to which the present invention may be applicable, will be readily apparent to those skilled in the art to which the present invention is directed upon review of the present disclosure.</p><p id="p-0704" num="0706">All publications, standards, patents, and patent applications cited in this specification are incorporated herein by reference as if each individual publication, patent, or patent application were specifically and individually indicated to be incorporated by reference and set forth in its entirety herein.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for use with first, second, and third contents respectively identified in the Internet by first, second, and third Uniform Resource Locators (URLs) and stored in a web server, and for use with first, second, and third client devices located in a same country, the method comprising:<claim-text>receiving, by the first client device from a first server over the Internet, the first URL;</claim-text><claim-text>sending, by the first client device to the web server over the Internet, the first URL in response to the receiving of the first URL;</claim-text><claim-text>receiving, by the first client device from the web server over the Internet, the first content in response to the sending of the first URL;</claim-text><claim-text>sending, by the first client device to the first server over the Internet, the first content in response to the receiving of the first content;</claim-text><claim-text>receiving, by the second client device from the first server over the Internet, the second URL;</claim-text><claim-text>sending, by the second client device to the web server over the Internet, the second URL in response to the receiving of the second URL;</claim-text><claim-text>receiving, by the second client device from the web server over the Internet, the second content in response to the sending of the second URL;</claim-text><claim-text>sending, by the second client device over the Internet to the first server, the second content in response to the receiving of the second content;</claim-text><claim-text>receiving, by the third client device from the first server over the Internet, the third URL;</claim-text><claim-text>sending, by the third client device to the web server over the Internet, the third URL in response to the receiving of the third URL;</claim-text><claim-text>receiving, by the third client device from the web server over the Internet, the third content in response to the sending of the third URL; and</claim-text><claim-text>sending, by the third client device over the Internet to the first server, the third content in response to the receiving of the third content, wherein the first server is not a client device.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first client device comprises a first consumer mobile device, wherein the second client device comprises a second consumer mobile device, and wherein the third client device comprises a third consumer mobile device.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first content includes, consists of, or comprises, a part or whole of a first web-page, wherein the second content includes, consists of, or comprises, a part or whole of a second web-page that is distinct from first web-page, and wherein the third content includes, consists of, or comprises, a part or whole of a third web-page that is distinct from the first and second web-pages.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising sending, by the first client device to the first server, a physical geographical location of the first client device; sending, by the second client device to the first server, a physical geographical location of the second client device; and sending, by the third client device to the first server, a physical geographical location of the third client device.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first server is further storing, operating, or using, a server operating system.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the server operating system consists or, comprises of, or is based on, Microsoft Windows Server&#xae;, Linux, or UNIX, or any combination thereof.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the server operating system consists or, comprises of, or is based on, Microsoft Windows Server&#xae; 2003 R2, 2008, 2008 R2, 2012, or 2012 R2 variant, Linux&#x2122; or GNU/Linux based Debian GNU/Linux, Debian GNU/kFreeBSD, Debian GNU/Hurd, Fedora&#x2122;, Gentoo&#x2122;, Linspire&#x2122;, Mandriva, Red Hat&#xae; Linux, SuSE, and Ubuntu&#xae;, UNIX&#xae; variant Solaris&#x2122;, AIX&#xae;, Mac&#x2122; OS X, FreeBSD&#xae;, OpenBSD, NetBSD&#xae;, or any combination thereof.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each of the first, second, and third content respectively includes, consists of, or comprises, a part or whole of a computer file, audio data, voice data, multimedia data, video data, an image, music data, or a computer program.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, for use with a group of client devices that are each identified in the Internet using a respective IP address and that are each associated with a physical geographical location, wherein the group includes the first, second, and third client devices.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising selecting, by the first server, the first client device from the group; selecting, by the first server, the second client device from the group; and selecting, by the first server, the third client device from the group.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the selecting of the first, second, and third client device respectively comprises randomly selecting from the devices in the group.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the selecting of the first, second, or third client device comprises selecting based on their respective physical geographical locations.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein each of the physical geographical locations respectively includes at least a state or province, a city, a street, a ZIP code, a longitude and latitude, or any combination thereof.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the physical geographical location of each device in the group is respectively estimated based on a geolocation.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the geolocation is based on W3C Geolocation API.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the selecting of the first, second, or third client device is respectively based on a respective value of IP addresses of the devices in the group.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the selecting of the first, second, or third client device is based on past activities of the devices in the group.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the selecting of the first, second, or third client device is based on a timing of a last communication with the devices in the group.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first, second, or third client device stores, operates, or uses, a client operating system.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising, by the respective first, second, or third client device, operating, or using, the client operating system.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The method according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the client operating system consists or, comprises of, or is based on, Microsoft Windows 7, Microsoft Windows XP, Microsoft Windows 8, Microsoft Windows 8.1, Linux, Google Chrome OS, or any combination thereof.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The method according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the client operating system is a mobile operating system.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The method according to <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the mobile operating system consists of, comprises, or is based on, Android version 2.2 (Froyo), Android version 2.3 (Gingerbread), Android version 4.0 (Ice Cream Sandwich), Android Version 4.2 (Jelly Bean), Android version 4.4 (KitKat), Apple iOS version 3, Apple iOS version 4, Apple iOS version 5, Apple iOS version 6, Apple iOS version 7, Microsoft Windows&#xae; Phone version 7, Microsoft Windows&#xae; Phone version 8, Microsoft Windows&#xae; Phone version 9, Blackberry&#xae; operating system, or any combination thereof.</claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first, second, or third client device comprises, or consists of, a smartphone.</claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first, second, and third client devices are located in the same city, in the same street, or in the same ZIP code.</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising initiating, by the first client device, communication with the first server, and wherein the receiving of the first URL by the first client device is in response to the initiating by the first client device.</claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The method according to <claim-ref idref="CLM-00026">claim 26</claim-ref>, further comprising initiating, by the second client device, communication with the first server, and wherein the receiving of the second URL by the second client device is in response to the initiating by the second client device.</claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>measuring, by the first client device, a utilization level of a resource; and</claim-text><claim-text>sending, by the first client device, a message that is based on the measured utilization level.</claim-text></claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. The method according to <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the message comprises the measured utilization level.</claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. The method according to <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the measuring of the utilization level comprises periodically measuring of the utilization level.</claim-text></claim><claim id="CLM-00031" num="00031"><claim-text><b>31</b>. The method according to <claim-ref idref="CLM-00030">claim 30</claim-ref>, wherein the sending of the message comprises periodically sending of the message.</claim-text></claim><claim id="CLM-00032" num="00032"><claim-text><b>32</b>. The method according to <claim-ref idref="CLM-00031">claim 31</claim-ref>, wherein the sending of the message is performed every 10, 20, 30, 50, or 100 milliseconds, every 1, 2, 3, 5, or 10 seconds, or every 1, 2, 3, 5, or 10 minutes.</claim-text></claim><claim id="CLM-00033" num="00033"><claim-text><b>33</b>. The method according to <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the measuring of the utilization level comprises continuously measuring of the utilization level.</claim-text></claim><claim id="CLM-00034" num="00034"><claim-text><b>34</b>. The method according to <claim-ref idref="CLM-00028">claim 28</claim-ref>, for use with a criterion associated with the utilization level of the resource, the method further comprising determining, by the first client device, whether the measured utilization level satisfies the criterion.</claim-text></claim><claim id="CLM-00035" num="00035"><claim-text><b>35</b>. The method according to <claim-ref idref="CLM-00034">claim 34</claim-ref>, wherein the sending of the message is in response to determining that the measured utilization level satisfies the criterion.</claim-text></claim><claim id="CLM-00036" num="00036"><claim-text><b>36</b>. The method according to <claim-ref idref="CLM-00034">claim 34</claim-ref>, for use with a threshold level, and wherein the criterion is satisfied when the measured utilization level is above or below the threshold level.</claim-text></claim><claim id="CLM-00037" num="00037"><claim-text><b>37</b>. The method according to <claim-ref idref="CLM-00028">claim 28</claim-ref>, for use with a threshold level, wherein the receiving of the message is in response to the measured utilization level crossing the threshold level.</claim-text></claim><claim id="CLM-00038" num="00038"><claim-text><b>38</b>. The method according to <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the resource comprises, or consists of, a hardware component or a using of the hardware component, in the first client device.</claim-text></claim><claim id="CLM-00039" num="00039"><claim-text><b>39</b>. The method according to <claim-ref idref="CLM-00038">claim 38</claim-ref>, wherein the hardware component comprises, or consists of, a processor or Central Processing Unit (CPU) operation.</claim-text></claim><claim id="CLM-00040" num="00040"><claim-text><b>40</b>. The method according to <claim-ref idref="CLM-00039">claim 39</claim-ref>, wherein the resource utilization is based on, or comprises, the processor or CPU time of executing one or more threads or processes, wherein the resource utilization is based on, or comprises, the processor or CPU idling time, or wherein the resource utilization is based on, or comprises, the processor or CPU executing a system idle process.</claim-text></claim><claim id="CLM-00041" num="00041"><claim-text><b>41</b>. The method according to <claim-ref idref="CLM-00038">claim 38</claim-ref>, wherein the hardware component comprises, or consists of, a memory, and wherein the resource utilization is based on, or comprises, an amount of used or unused location or space of the memory.</claim-text></claim><claim id="CLM-00042" num="00042"><claim-text><b>42</b>. The method according to <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the resource comprises, or consists of, input or output capability.</claim-text></claim><claim id="CLM-00043" num="00043"><claim-text><b>43</b>. The method according to <claim-ref idref="CLM-00042">claim 42</claim-ref>, wherein the resource comprises, or consists of, communication bandwidth of communication with another device over the Internet.</claim-text></claim><claim id="CLM-00044" num="00044"><claim-text><b>44</b>. The method according to <claim-ref idref="CLM-00043">claim 43</claim-ref>, wherein the resource comprises, or consists of, communication bandwidth of communication with the first server over the Internet, or wherein the resource utilization is based on, or according to, IETF RFC 2914.</claim-text></claim><claim id="CLM-00045" num="00045"><claim-text><b>45</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising periodically sending, by the first client device, an &#x2018;heartbeat&#x2019; message that comprises a status of the first client device, or is in response to the status of the first client device.</claim-text></claim><claim id="CLM-00046" num="00046"><claim-text><b>46</b>. The method according to <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein the status is based on the measured utilization level.</claim-text></claim><claim id="CLM-00047" num="00047"><claim-text><b>47</b>. The method according to <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein a time period between sent multiple &#x2018;heartbeat&#x2019; messages is at least 10 milliseconds, 20 milliseconds, 30 milliseconds, 50 milliseconds, 100 milliseconds, 1 second, 2 seconds, 3 seconds, 5 seconds, 10 seconds, 20 seconds, 30 seconds, 50 seconds, 100 seconds, 1 minute, 2 minutes, 3 minutes, minutes 5, or 10 minutes.</claim-text></claim><claim id="CLM-00048" num="00048"><claim-text><b>48</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising executing, by the first client device, a first web browser application.</claim-text></claim><claim id="CLM-00049" num="00049"><claim-text><b>49</b>. The method according to <claim-ref idref="CLM-00048">claim 48</claim-ref>, wherein the sending, by the first client device to the web server of the first URL uses the first web browser application.</claim-text></claim><claim id="CLM-00050" num="00050"><claim-text><b>50</b>. The method according to <claim-ref idref="CLM-00048">claim 48</claim-ref>, wherein the executing of the first web browser application is in response to the receiving of the first URL from the first server.</claim-text></claim><claim id="CLM-00051" num="00051"><claim-text><b>51</b>. The method according to <claim-ref idref="CLM-00048">claim 48</claim-ref>, further comprising executing, by the second client device, a second web browser application.</claim-text></claim><claim id="CLM-00052" num="00052"><claim-text><b>52</b>. The method according to <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the sending, by the second client device to the web server of the second URL uses the second web browser application.</claim-text></claim><claim id="CLM-00053" num="00053"><claim-text><b>53</b>. The method according to <claim-ref idref="CLM-00052">claim 52</claim-ref>, wherein the executing of the second web browser application is in response to the receiving of the second URL from the first server.</claim-text></claim><claim id="CLM-00054" num="00054"><claim-text><b>54</b>. The method according to <claim-ref idref="CLM-00048">claim 48</claim-ref>, wherein the web browser consists of, comprises of, or based on, Opera&#x2122;, or Mozilla Fire fox&#xae;.</claim-text></claim><claim id="CLM-00055" num="00055"><claim-text><b>55</b>. The method according to <claim-ref idref="CLM-00048">claim 48</claim-ref>, wherein the web browser consists of, comprises of, or based on, Microsoft Internet Explorer or Google Chrome.</claim-text></claim><claim id="CLM-00056" num="00056"><claim-text><b>56</b>. The method according to <claim-ref idref="CLM-00048">claim 48</claim-ref>, wherein the web browser is a mobile web browser.</claim-text></claim><claim id="CLM-00057" num="00057"><claim-text><b>57</b>. The method according to <claim-ref idref="CLM-00056">claim 56</claim-ref>, wherein the mobile web browser consists of, comprises of, or based on, Safari, Opera Mini&#x2122;, Android web browser, or any combination thereof.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005217A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005217</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364576</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>17</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>17</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>17</main-group><subgroup>005</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>17</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20081</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20084</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2210</main-group><subgroup>56</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS OF HIERARCHICAL IMPLICIT REPRESENTATION IN OCTREE FOR 3D MODELING</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>TENCENT AMERICA LLC</orgname><address><city>Palo Alto</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>CHEN</last-name><first-name>Weikai</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>WANG</last-name><first-name>Bo</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>LIU</last-name><first-name>Songrun</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>YANG</last-name><first-name>Bo</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An electronic apparatus performs a method of representing a 3D shape that includes: dividing a 3D space enclosing the 3D shape into a plurality of 3D spaces with a hierarchical octree structure; generating local implicit functions, and each of the local implicit functions corresponds to a respective 3D space of the plurality of 3D spaces; and reconstructing a representation of the 3D shape from the local implicit functions with the hierarchical octree structure. In some embodiments, the 3D space is recursively subdivided into the child octants according to the surface occupancy and richness of the geometry of the 3D shape, and a respective local implicit function is generated corresponding to a geometry of a part of the surface.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="91.02mm" wi="158.75mm" file="US20230005217A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="215.56mm" wi="136.48mm" orientation="landscape" file="US20230005217A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="213.44mm" wi="135.89mm" orientation="landscape" file="US20230005217A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="230.55mm" wi="124.88mm" orientation="landscape" file="US20230005217A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="223.94mm" wi="136.06mm" orientation="landscape" file="US20230005217A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="171.53mm" wi="135.47mm" file="US20230005217A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="203.28mm" wi="147.24mm" file="US20230005217A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="209.47mm" wi="141.56mm" orientation="landscape" file="US20230005217A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present disclosure relates generally to image technologies, and in particular, to image processing and three-dimensional (3D) model formation methods and systems.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Geometric 3D representation has been central to the tasks in computer vision and computer graphics, ranging from high-level applications, such as scene understanding, objection recognition and classification, to low-level tasks, including 3D shape reconstruction, interpolation, and manipulation.</p><p id="p-0004" num="0003">While explicit 3D representations have been used in recent 3D learning approaches, none of those representations can satisfy all the desirable properties. Point cloud and voxel representations struggle to capture the fine-scale shape details&#x2014;often at the cost of prohibitive memory requirements. Mesh-based learning approaches typically rely on deforming a template model, limiting its scalability to handle arbitrary topologies. The advent of neural implicit function has recently brought impressive advances to the state-of-the-art across a range of 3D modeling and reconstruction tasks. However, using only a global function for encoding the entirety of all shapes, the aforementioned methods often suffer from limited reconstruction accuracy and shape generality.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0005" num="0004">To accommodate with various application scenarios, a universal and effective 3D representation for 3D deep learning should have the following properties: (1) compatibility with arbitrary topologies, (2) sufficient capacity of modeling fine geometric details, (3) scalability to intricate shapes, (4) support efficient encoding of shape priors, (5) compact memory footprint, and (6) high computational efficiency.</p><p id="p-0006" num="0005">Localized implicit function is a flexible neural implicit representation that can handle arbitrary topologies. Localized implicit function is a powerful 3D shape representation of objects and scenes at different scales. However, the regular subdivision of 3D space employed by these approaches fails to consider the sparsity of the surface occupancy and the varying granularities of geometric details. As a result, its memory footprint grows cubically with the input volume, leading to a prohibitive computational cost even at a moderately dense decomposition of a regular-sized input volume.</p><p id="p-0007" num="0006">In some embodiments, the method and system disclosed herein is called OctField. OctField combines the good ends of both localized implicit representations and the hierarchical data structure. By adaptively allocating local implicit functions according to the surface occupancy and the richness of geometry, OctField is able to achieve high modeling accuracy with a low memory and computational budget. In particular, the 3D space is decomposed into hierarchical local regions using the octree structure, where the finest octant encodes the partial shape within its enclosed space using a learned implicit function. The decomposition protocol not only considers the surface occupancy but also the richness of the geometry. The octants that carry an embedded implicit kernel are only allocated around the surface. Moreover, only the octants containing intricate geometries are further divided. This ensures an adaptive memory and computation allocation so that the richer surface details are captured with more local implicit functions&#x2014;hence with higher modeling accuracy. In contrast, the unoccupied regions are not allocated with any implicit kernels to save the memory and computational budget.</p><p id="p-0008" num="0007">In some embodiments, the octree itself is a non-differentiable discrete data structure. A novel differentiable hierarchical encoder-decoder network is implemented that learns both the octree structure and the geometry features simultaneously. In particular, the construction of octree is formulated as a probabilistic process where the probability of subdividing an octant is predicted by a Multilayer perceptron (MLP) layer. This makes it possible to learn discrete octree structure in a fully differentiable manner. In addition, the network is trained in manner similar to a Variational Autoencoders (VAE) such that the trained latent space and decoder can be used for a variety of downstream applications including shape reconstruction, generation, interpolation, and single-view reconstruction, etc.</p><p id="p-0009" num="0008">Systems and methods of a novel 3D representation are disclosed herein that introduce hierarchical octree structure to the organization of local implicit functions to achieve significantly higher-precision modeling capability with even lower memory and computational budget. The 3D space is adaptively subdivided according to the surface occupancy and the richness of part geometry. As octree is discrete and non-differentiable, a novel hierarchical encoder-decoder network is also introduced that can learn both discrete octree structure and surface geometry in a differentiable manner in a deep neural network.</p><p id="p-0010" num="0009">According to a first aspect of the present application, a method of representing a 3D shape includes: dividing a 3D space enclosing the 3D shape into a plurality of 3D spaces with a hierarchical octree structure; generating local implicit functions, and each of the local implicit functions corresponds to a respective 3D space of the plurality of 3D spaces; and reconstructing a representation of the 3D shape from the local implicit functions with the hierarchical octree structure.</p><p id="p-0011" num="0010">In some embodiments, the dividing the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure includes: recursively subdividing the 3D space into child octants according to surface occupancy and richness of geometry of the 3D shape.</p><p id="p-0012" num="0011">In some embodiments, the dividing the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure includes: training a neural network to divide the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure.</p><p id="p-0013" num="0012">In some embodiments, the generating the local implicit functions includes: in accordance with a determination that a respective 3D space encloses part of a surface of the 3D shape, generating a respective local implicit function corresponding to a geometry of the part of the surface.</p><p id="p-0014" num="0013">In some embodiments, the generating the respective local implicit function corresponding to the geometry of the part of the surface includes: training a neural network to recognize the geometry of the part of the surface and to generate a respective local implicit function corresponding to the geometry of the part of the surface.</p><p id="p-0015" num="0014">In some embodiments, the reconstructing the representation of the 3D shape from the local implicit functions with the hierarchical octree structure includes: reconstructing a 3D surface of the 3D shape within the respective 3D space with a respective local implicit function using geometry feature and 3D location of the 3D surface; and converting the local implicit functions within the hierarchical octree structure to a 3D mesh output.</p><p id="p-0016" num="0015">According to a second aspect of the present application, an electronic apparatus includes one or more processing units, memory and a plurality of programs stored in the memory. The programs, when executed by the one or more processing units, cause the electronic apparatus to perform the one or more methods as described above.</p><p id="p-0017" num="0016">According to a third aspect of the present application, a non-transitory computer readable storage medium stores a plurality of programs for execution by an electronic apparatus having one or more processing units. The programs, when executed by the one or more processing units, cause the electronic apparatus to perform the one or more methods as described above.</p><p id="p-0018" num="0017">Note that the various embodiments described above can be combined with any other embodiments described herein. The features and advantages described in the specification are not all inclusive and, in particular, many additional features and advantages will be apparent to one of ordinary skill in the art in view of the drawings, specification, and claims. Moreover, it should be noted that the language used in the specification has been principally selected for readability and instructional purposes, and may not have been selected to delineate or circumscribe the inventive subject matter.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0019" num="0018">So that the present disclosure can be understood in greater detail, a more particular description may be had by reference to the features of various embodiments, some of which are illustrated in the appended drawings. The appended drawings, however, merely illustrate pertinent features of the present disclosure and are therefore not to be considered limiting, for the description may admit to other effective features.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an exemplary process of representing a 3D shape by assigning local implicit functions to an octree structure in accordance with some implementations of the present disclosure.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an exemplary OctField utilizing an octree structure to achieve a hierarchical implicit representation in accordance with some implementations of the present disclosure.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram with an exemplary 2D illustration of the hierarchical encoder-decoder network in accordance with some implementations of the present disclosure.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an exemplary architecture of local encoder {&#x3b5;<sub>i</sub>} and decoder {D<sub>i</sub>} in accordance with some implementations of the present disclosure.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating an exemplary 3D shape representation process using OctField in accordance with some implementations of the present disclosure.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the shape reconstruction comparison between OctField and the baseline methods: Adaptive O-CNN (AOCNN), Local Implicit Grids (LIG), OCCNet, IM-Net in accordance with some implementations of the present disclosure.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a schematic diagram of an exemplary hardware structure of an image processing apparatus in accordance with some implementations of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0027" num="0026">In accordance with common practice, the various features illustrated in the drawings may not be drawn to scale. Accordingly, the dimensions of the various features may be arbitrarily expanded or reduced for clarity. In addition, some of the drawings may not depict all of the components of a given system, method or device. Finally, like reference numerals may be used to denote like features throughout the specification and figures.</p><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0028" num="0027">Reference will now be made in detail to specific implementations, examples of which are illustrated in the accompanying drawings. In the following detailed description, numerous non-limiting specific details are set forth in order to assist in understanding the subject matter presented herein. But it will be apparent to one of ordinary skill in the art that various alternatives may be used without departing from the scope of claims and the subject matter may be practiced without these specific details. For example, it will be apparent to one of ordinary skill in the art that the subject matter presented herein can be implemented on many types of electronic devices.</p><p id="p-0029" num="0028">Before the embodiments of the present application are further described in detail, names and terms involved in the embodiments of the present application are described, and the names and terms involved in the embodiments of the present application have the following explanations.</p><p id="p-0030" num="0029">Multilayer perceptron (MLP): a class of feedforward artificial neural network (ANN) including at least three layers of nodes: an input layer, a hidden layer and an output layer</p><p id="p-0031" num="0030">Variational Autoencoders (VAE): generative models using a variational approach for latent representation learning whose posterior is approximated by a neural network, forming an autoencoder-like architecture.</p><p id="p-0032" num="0031">Convolutional neural network (CNN): a class of deep neural networks, most commonly applied to analyzing visual imagery.</p><p id="p-0033" num="0032">Kullback-Leibler (KL) divergence: a measure of how one probability distribution is different from a reference probability distribution.</p><p id="p-0034" num="0033">IM-Net: an implicit field decoder for shape generation that is trained to perform the value assignment to each point in 3D space by means of a binary classifier to indicates whether the point is outside the shape or not.</p><p id="p-0035" num="0034">Occupancy networks (OCCNet): a representation for learning-based 3D reconstruction that implicitly represents the 3D surface as the continuous decision boundary of a deep neural network classifier.</p><p id="p-0036" num="0035">Local Implicit Grids (LIG): a 3D shape representation that trains an autoencoder to learn an embedding of local crops of 3D shapes at a geometric scale shared by surfaces and decodes a set of latent codes on a regular grid of overlapping crops.</p><p id="p-0037" num="0036">Adaptive Octree-based Convolutional Neural Network (AOCNN). A Patch-based Deep Representation of 3D Shapes that takes the planar patch normal and displacement as input and performs 3D convolutions only at the octants at each level.</p><p id="p-0038" num="0037">PointNet++: a deep learning method on point sets that has learning layers to adaptively combine features from multiple scales and it is a hierarchical neural network that applies a nested partitioning of the input point set.</p><p id="p-0039" num="0038">Typical methods based on local implicit functions include Local implicit grid (LIG) and Local deep implicit functions for 3D shape (LDIF). Most 3D shapes are typically consisting of large smooth regions and small-scale sharp features. In addition, the surface of interest often consumes only a small portion of the entire space, leading to an extremely sparse space occupancy. However, the method based on local implicit functions fails to take the varying geometry richness and sparsity of surface into account. That leads to low computational efficiency and inefficient space subdivision. In particular, LIG subdivides the 3D space into regular girds in which most of the grid cells do not contain any geometry shapes of interest, leading to a waste of computational resources. As a result, both LIG and LDIF cannot scale to high-precision reconstruction of large scenes.</p><p id="p-0040" num="0039">Neural Geometric Level of Details (NGLD) provides a fast rendering method of neural signed distance field (SDF). NGLD does not consider the geometry richness of surface. In addition, NGLD does not encode the structural information in an encoder-decoder framework. As a result, NGLD struggles to reconstruct 3D shapes with fine intricate details, especially when the target shape parts contain strong semantic structure.</p><p id="p-0041" num="0040">To address the limitation of local implicit functions as described above, a novel 3D representation called OctField is disclosed herein, that introduces hierarchies to the organization of the local implicit functions to achieve a better memory efficiency and a stronger modeling capacity. OctField leverages a hierarchical data structure, Octree, to adaptively subdivide the 3D space according to the surface occupancy and the richness of geometrical details. In particular, regions enclosing intricate geometries are further subdivided to allocate more implicit kernels for higher modeling accuracy. In contrast, the stop of subdivision for octants containing smooth part geometry as a single implicit kernel would suffice for modeling. Further, implicit functions are not allocated in the unoccupied regions. Hence, OctField could obtain significantly increased representation accuracy with a slightly deeper octree subdivision, as the modeling capacity has been highly optimized to accommodate the varying granularity of surface details.</p><p id="p-0042" num="0041">The systems and methods disclosed herein tackle the problems of NGLD discussed above with two solutions. First, a novel octree construction method is introduced that is adaptive to varying geometry granularities. Specifically, during the octree construction, OctField will further subdivides the cells that contain fine surface details. Therefore, at training and test time, more implicit functions will be allocated for modeling the parts with intricate geometry details, leading to a higher reconstruction accuracy. Second, a novel hierarchical network is implemented that recursively incorporates structural information into the encoder and decoder networks. This enables the systems and methods to fully leverage structural semantics of the 3D shape that could provide useful guidance of a surface modeling. The systems and methods disclosed herein are able to achieve reconstruction quality that is higher than NGLD.</p><p id="p-0043" num="0042">In some embodiments, OctField is a learnable hierarchical implicit representation for 3D surfaces that allows high-precision encoding of intricate surfaces with low memory and computational budget. The inefficiency issue of the state-of-the-art 3D modeling and reconstruction methods based on local implicit functions is resolved. In particular, a hierarchical octree structure is implemented to adaptively subdivide the 3D space according to the surface occupancy and the richness of part geometry. As octree is discrete and non-differentiable, a novel hierarchical network is further utilized that recursively encodes and decodes both octree structure and surface geometry in a differentiable manner. The methods and systems disclosed herein features the advantages of both localized implicit representation and the hierarchical data structure. By associating a local implicit function with each octant cell, the 3D representation can model large-scale shape with fine-level details using compact storage. The 3D representation also reduces the computational cost. Therefore, the method and systems disclosed herein can speed up inference in evaluation. Based on the differentiable network, OctField can be applied in in a variety of tasks including 3D shape reconstruction, shape completion from partial and noisy inputs, and image-based 3D reconstruction, etc.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an exemplary process <b>100</b> of representing a 3D shape by assigning local implicit functions to an octree structure in accordance with some implementations of the present disclosure.</p><p id="p-0045" num="0044">In some embodiments, the process includes two phases: training <b>102</b> and testing <b>104</b>. During the training <b>102</b>, the adaptive octree cells for a 3D shape <b>106</b> is first constructed in the training set in the octree construction step <b>108</b>. Then a hierarchical encoder-decoder network is utilized to perform encoder-decoder training <b>110</b>, which generates trained local decoders <b>112</b> that are deployed in testing <b>104</b>. At test time, either a partial 3D input <b>114</b>, such as a partial point cloud or mesh, and/or 2D images <b>116</b> can be accepted as the input. First, the feature extracted from the input is mapped <b>118</b> to the latent space of the trained local decoders <b>112</b>. Then a hierarchical feature decoding <b>120</b> by a decoder is performed to obtain the constructed implicit field. After applying the constructed implicit field to mesh conversion <b>122</b>, the output mesh <b>124</b> is reconstructed.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an exemplary OctField utilizing an octree structure to achieve a hierarchical implicit representation in accordance with some implementations of the present disclosure. The part of geometry enclosed by an octant is represented by a local implicit function. OctField is subdivided more adaptively in areas with rich geometric details to obtain higher modeling accuracy.</p><p id="p-0047" num="0046">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, OctField leverages a hierarchical data structure, Octree, to adaptively subdivide the 3D space according to the surface occupancy and the richness of geometrical details. In particular, regions enclosing intricate geometries will be further subdivided to allocate more implicit kernels for higher modeling accuracy. In contrast, subdivision is stopped for octants containing smooth part geometry as a single implicit kernel that would suffice for modeling. Further, any implicit functions are not allocated in the unoccupied regions. Hence, OctField could obtain significantly higher representation accuracy with a slightly deeper octree subdivision, as the modeling capacity has been adaptively optimized to accommodate the varying granularity of surface details. In particular, intricate parts such as jet engines, tail-planes and the undercarriage are automatically subdivided to engage more implicit kernels for higher modeling accuracy, while parts with regular shapes on the fuselage is encoded using a coarser-level representation that suffices.</p><p id="p-0048" num="0047">In some embodiments, the implicit function associated with each octant is designed to model only part of the entire shape. To build an octree for the input model, the 3D shape is first uniformly scaled into an axis-aligned bounding box region <b>202</b> and then the bounding box region is recursively subdivided into child octants with different level of depth in a breadth-first order. <figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a leaf octant region at depth <b>3</b>, and some other intermediate octants at depth <b>4</b>. The decomposition protocol not only considers the surface occupancy but also the richness of geometry. As show in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the octants that carry an embedded implicit kernel will only be allocated around the surface. At each octant, the enclosed surface is continuously decoded from the local latent code.</p><p id="p-0049" num="0048">In some embodiments, Octree construction is implemented. The octant to be subdivided has to satisfy two requirements simultaneously: (1) the octant encloses the surface of interest; and (2) its enclosed geometry needs to have sufficient complexity that is worth subdividing. The normal variation of the surface is used as an indicator of its geometric complexity. Specifically, the normal variation of a surface patch S is formulated as follows:</p><p id="p-0050" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>v</i>(<i>S</i>)=<i>E</i><sub>i</sub>(<i>v</i>(<i>n</i><sup>i</sup><sub>x</sub>)+<i>v</i>(<i>n</i><sup>i</sup><sub>y</sub>)+<i>V</i>(<i>n</i><sup>i</sup><sub>z</sub>)) &#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0051" num="0049">where the n<sup>i</sup><sub>x</sub>, n<sup>i</sup><sub>y</sub>, n<sup>i</sup><sub>z </sub>are the x, y, z-component of the normal vector n<sup>i </sup>at the i-th sampling point on the surface; v( ) calculates the variations of the input while E<sub>i </sub>( ) returns the expectation. In some embodiments, regular sampling is performed on the surface where the sampling points are pre-computed. The decomposition is repeated until the pre-defined depth d is reached or v(S) is smaller than a pre-set threshold &#x3c4;. In some embodiments, &#x3c4;=0.1 is set throughout the construction.</p><p id="p-0052" num="0050">In some embodiments, Local Implicit Representation is implemented. The implicit function associated with each octant is designed to model only part of the entire shape. This enables more training samples and eases the training as most 3D shapes share similar geometry at smaller scales. At each octant, the enclosed surface is continuously decoded from the local latent code. However, as the finest octant may have different sizes, when querying for the value of the local implicit function, the input world coordinate x against the center of the octant x<sub>i </sub>is normalized. Formally, the signed distance to the surface is encoded as:</p><p id="p-0053" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>f</i>(<i>c</i><sub>i</sub><i>,x</i>)=<i>D</i><sub>&#x3b8;d</sub>(<i>c</i><sub>i</sub><i>,N</i>(<i>x&#x2212;x</i><sub>i</sub>)) &#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0054" num="0051">where D<sub>&#x3b8;d </sub>is the learned implicit decoder with trainable parameter &#x3b8;d, c<sub>i </sub>is the local latent code and N ( ) normalizes the input coordinate into the range of [&#x2212;1, 1] according to the bounding box of the octant. To prevent the discontinuities across the octant boundaries, each octant is enlarged such that it overlaps with its neighboring octant at the same level. In this implementation, each octant has 50% overlap along the axis direction with its neighbors. When the implicit value at the overlapping regions is queried, tri-linear interpolation is performed over all the octants that intersect with this query position.</p><p id="p-0055" num="0052"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram with an exemplary 2D illustration of the hierarchical encoder-decoder network in accordance with some implementations of the present disclosure.</p><p id="p-0056" num="0053">The hierarchical encoder-decoder network as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> (also shown as <b>110</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) is a recursive encoder-decoder structure. The encoder of the network is composed of a hierarchy of local encoders that encode local geometry feature and octree structure into the latent code. A 3D voxel Convolutional Neural Network (CNN) is employed for extracting the geometry features. After constructing the octree (also shown as <b>108</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) for the input model, the surface enclosed in each octant is voxelized in a resolution of 32<sup>3</sup>. The encoding process starts from the octants at the finest level in a bottom-up manner.</p><p id="p-0057" num="0054">In some embodiments, the recursive encoder-decoder network is trained in a VAE manner. The voxel 3D CNN is implemented to encode the octants' geometry, and recursively aggregate the structure and geometry features using a hierarchy of local encoder {&#x3b5;<sub>i</sub>}. The decoding is implemented using a hierarchy of local decoders {D<sub>i</sub>} with a mirrored structure with respect to the encoder. Both the structure and geometry information are recursively decoded and the local surfaces are recovered using the implicit octant decoder within each octant.</p><p id="p-0058" num="0055"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an exemplary architecture of local encoder {&#x3b5;<sub>i</sub>} and decoder {D<sub>i</sub>} in accordance with some implementations of the present disclosure.</p><p id="p-0059" num="0056"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows the details of local encoder and decoder. For each octant, its binary indicator (h<sub>i</sub>, k<sub>i</sub>) is first computed which marks whether it encloses part of the surface and whether it needs further subdivision according to its enclosed geometry. Then, the geometry feature g<sub>i </sub>is extracted by passing its enclosed voxelized geometry to the voxel CNN. Next, the octant latent feature is obtained by concatenating g<sub>k </sub>with its structure features (h<sub>k</sub>, k<sub>k</sub>). The recursive feature encoding and aggregation is performed until the root node has been processed. At the end of encoder, the VAE reparameterization technique is used to encourage the distribution of the latent space to fit a normal distribution.</p><p id="p-0060" num="0057">The hierarchical decoder aims to decode the octree structure and local octant codes from the input global feature. On the contrary to the encoder, the decoding process starts from the root node and recursively decodes the latent code of its child octants in a top-down manner. For each octant, the structure and geometry features (h<sub>i</sub>, k<sub>i</sub>, g<sub>i</sub>) are decoded. The two indicators determine whether the child octants need to be decoded or subdivided. For those octants that need to be subdivided, all the 8 child octants are decoded at one time from the geometry features. This process is repeated until no octants need to be subdivided. Finally, a local implicit decoder is used to reconstruct the 3D surface within the octant by feeding its latent geometry feature and 3D query location.</p><p id="p-0061" num="0058">In some embodiments, a hierarchical OctField network is implemented. To enable a differentiable framework for learning the octree structure and its encoded geometry, a novel hierarchical encoder-decoder network is implemented that organizes local encoders and decoders in a recursive manner. Both the octree structure information and the geometry feature are embedded into the latent code of each octant. As shown in the right part of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the latent code e<sub>i</sub>=(g<sub>i</sub>, &#x3b1;<sub>i</sub>, &#x3b2;<sub>i</sub>) for octant O<sub>i </sub>is a concatenation of three parts: (1) a geometry feature g<sub>i </sub>that encodes the local 3D shape; (2) a binary occupancy indicator &#x3b1;<sub>i </sub>that indicates whether the octant encloses any 3D surface; and (3) a binary geometry subdivision indicator &#x3b2;<sub>i </sub>that denotes whether the enclosed geometry is intricate enough that needs further subdivision. How this configuration of latent vector guides the recursive decoding and encoding in the network is further illustrated herein. Note that, unlike the prior tree structure-based generative models, the method and systems disclosed herein does not require a manually labeled part hierarchy, e.g. the dataset, for training, and can generate the hierarchical structure automatically using our octree construction algorithm.</p><p id="p-0062" num="0059">In some embodiments, a hierarchical encoder is implemented. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> the encoder E of the network is composed of a hierarchy of local encoders {&#x3b5;<sub>i</sub>} that encodes local geometry feature and octree structure into the latent code. While the framework supports general geometry encoders, a 3D voxel CNN &#x3bd; is employed for extracting geometry features due to its simplicity of implementation. After constructing the octree for the input model, the surface enclosed in each octant is voxelized in a resolution of 32<sup>3</sup>.</p><p id="p-0063" num="0060">In some embodiments, the encoding process starts from the octants at the finest level in a bottom-up manner. For each octant O<sub>i</sub>, its binary indicators (&#x3b1;<sub>i</sub>, &#x3b2;<sub>i</sub>) are first computed according to its enclosed geometry. In particular, &#x3b1;<sub>i </sub>is set to 1 if there exist surfaces inside O<sub>i </sub>and is set to 0 if otherwise; &#x3b2;<sub>i </sub>is set to 1 if O<sub>i</sub>'s enclosed geometry (if &#x3b1;<sub>i</sub>=1) satisfies the subdivision criteria and is set to 0 if otherwise. O<sub>i</sub>'s geometry feature g<sub>i </sub>is then extracted by passing its enclosed voxelized geometry G<sub>i </sub>to the voxel CNN &#x3bd;. When proceeding to a higher level, the network will aggregate the children's latent features to its parent octant. In particular, for a parent octant O<sub>k</sub>, the octant features of its children is denoted as {e<sub>cj</sub>=(g<sub>cj</sub>, &#x3b1;<sub>cj</sub>, &#x3b2;<sub>cj</sub>)|c<sub>j</sub>&#x2208;C<sub>k</sub>}, where C<sub>i </sub>represents the child octants of O<sub>k</sub>. Its encoder &#x3b5;<sub>k </sub>then aggregates the latent features of O<sub>k</sub>'S child octants into O<sub>k</sub>'S geometry feature g<sub>k</sub>:</p><p id="p-0064" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>g</i><sub>k</sub>=&#x3b5;<sub>k</sub>(<i>e</i><sub>c0</sub><i>, e</i><sub>c1</sub><i>, . . . , e</i><sub>c7</sub>). &#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0065" num="0061">In some embodiments, O<sub>k</sub>'s latent feature is then obtained by concatenating g<sub>k </sub>with O<sub>k</sub>'s structure features (&#x3b1;<sub>k</sub>, &#x3b2;<sub>k</sub>). The recursive feature encoding and aggregation is performed until the root node has been processed. Specifically, the encoder &#x3b5;<sub>i </sub>consists of a single-layer perceptron (SLP), one max pooling layer and another SLP for output. At the end of encoder, the VAE reparameterization technique is leveraged to encourage the distribution of the latent space to fit a normal distribution. Note that all the local encoders &#x3b5;<sub>i </sub>share its parameters to leverage the similarity of local geometries and to reduce the network parameters.</p><p id="p-0066" num="0062">In some embodiments, the hierarchical decoder D aims to decode the octree structure and local octant codes from the input global feature. It consists of a hierarchy of local decoders {D<sub>i</sub>} with a mirrored structure with respect to the encoder E. On the contrary to E, the decoding process starts from the root node and recursively decodes the latent code of its child octants in a top-down manner. Specifically, for a parent octant O<sub>k </sub>with geometry feature g<sub>k</sub>, the geometry features of its child octants is decoded using the decoder D<sub>k</sub>:</p><p id="p-0067" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(<i>e</i><sub>c0</sub><i>, e</i><sub>c1</sub><i>, . . . , e</i><sub>c7</sub>)=<i>D</i><sub>k</sub>(<i>g</i><sub>k</sub>), &#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0068" num="0063">where c<sub>j</sub>&#x2208;C<sub>k </sub>denotes the child octant of O<sub>k </sub>and e<sub>cj</sub>=(g<sub>cj</sub>, &#x3b1;<sub>cj</sub>, &#x3b2;<sub>cj</sub>) stands for the geometric feature and two indicators of the child octant O<sub>cj</sub>. The two indicators provide the probability of whether the child octants need to be decoded or subdivided. Note that all the 8 child octants are decoded at one time.</p><p id="p-0069" num="0064">In particular, D<sub>k </sub>consists of two SLPs and two classifiers (see <figref idref="DRAWINGS">FIG. <b>4</b></figref>). g<sub>k </sub>is first decoded into hidden vectors v<sub>cj </sub>for all 8 child octants by a SLP. To decode the structure information, two classifiers I<sub>g </sub>and I<sub>h </sub>are applied to infer the probability of surface occupancy and the necessity of further subdivision, respectively. For child octant O<sub>cj</sub>, its hidden vector v<sub>cj </sub>is fed into I<sub>g </sub>and I<sub>h</sub>, and calculate &#x3b1;<sub>cj</sub>=I<sub>g</sub>(v<sub>cj</sub>) and &#x3b2;<sub>cj</sub>=I<sub>h</sub>(v<sub>cj</sub>). For predicting the g<sub>cj</sub>, the other SLP is applied on v<sub>cj</sub>. If &#x3b1;<sub>cj</sub>&#x3c;0.5, it indicates that O<sub>cj </sub>does not contain any geometry and will not be further processed. If &#x3b1;<sub>cj</sub>&#x3e;0.5, it means that O<sub>cj </sub>is occupied by the surface and the value of &#x3b2;<sub>cj </sub>is further checked. If &#x3b2;<sub>cj</sub>&#x3c;0.5, the octant is not further divided and its enclosed surface is inferred using the implicit octant decoder G and the geometric feature g<sub>cj</sub>. If &#x3b2;<sub>cj</sub>&#x3e;0.5, the octant is subdivided by predicting the latent features of its child octants with the same procedure. This process is repeated until no octants need to be subdivided.</p><p id="p-0070" num="0065">The total loss consists of geometric loss, structure loss, subdivision loss, and Kullback-Leibler (KL) divergence loss. Geometric loss is binary cross entropy (BCE) loss on point samples in 3D space. Structure and subdivision loss are BCE loss of classifying whether the octants are occupied and need to be subdivided respectively.</p><p id="p-0071" num="0066">In some embodiments, a local implicit decoder G is used to reconstruct the 3D surface within the octant. For octant O<sub>i</sub>, its latent geometry feature g<sub>i </sub>and the 3D query location x are fed to the implicit decoder G for signed distance prediction. G is trained with binary cross entropy loss on the point samples. The training loss for octant O<sub>i </sub>is:</p><p id="p-0072" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>Lgeo</mi>     <mo>=</mo>     <mfrac>      <mrow>       <msub>        <mo>&#x2211;</mo>        <mrow>         <mi>j</mi>         <mo>&#x2208;</mo>         <mi>P</mi>        </mrow>       </msub>       <mrow>        <mrow>         <mi>Lc</mi>         <mo>&#x2061;</mo>         <mo>(</mo>         <mrow>          <mrow>           <mi>G</mi>           <mo>&#x2061;</mo>           <mo>(</mo>           <mrow>            <mi>gi</mi>            <mo>,</mo>            <mi>xj</mi>           </mrow>           <mo>)</mo>          </mrow>          <mo>,</mo>          <mrow>           <mi>F</mi>           <mo>&#x2061;</mo>           <mo>(</mo>           <mi>xj</mi>           <mo>)</mo>          </mrow>         </mrow>         <mo>)</mo>        </mrow>        <mo>&#xb7;</mo>        <mi>wj</mi>       </mrow>      </mrow>      <mrow>       <msub>        <mo>&#x2211;</mo>        <mrow>         <mi>j</mi>         <mo>&#x2208;</mo>         <mi>P</mi>        </mrow>       </msub>       <msub>        <mi>w</mi>        <mi>j</mi>       </msub>      </mrow>     </mfrac>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>5</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0073" num="0067">where F( ) returns the ground-truth label (inside/outside) for input point, Lc (&#x22c5;,&#x22c5;) is the binary cross entropy loss, P denotes the set of sampling points, w<sub>j </sub>describes the inverse of sampling density near x<sub>j </sub>for compensating the density change. Note that G is pre-trained on all the local shape crops to encode stronger shape prior.</p><p id="p-0074" num="0068">In some embodiments, in order to obtain stronger supervision, the local geometry of all the octants that are occupied by the surface is recovered regardless if it belongs to the finest level. Hence, the total loss for training the hierarchical encoder-decoder network is formulated as follows:</p><p id="p-0075" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>L</i><sub>total</sub><i>=E</i><sub>Oi&#x2208;O</sub>[&#x3bb;<i>L</i>geo+<i>L</i><sub>h</sub><i>+L</i><sub>k</sub><i>+&#x3b2;L</i><sub>KL</sub>]&#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0076" num="0069">where L<sub>h </sub>and L<sub>k </sub>denote the binary cross entropy loss of classifying whether the octant contains geometry and needs to be subdivided, respectively, L<sub>KL </sub>is the KL divergence loss, and E[ ] returns the expected value over the set of all octants O that enclose surface geometry. In some embodiments, &#x3bb;=10.0, &#x3b2;=0.01 are set.</p><p id="p-0077" num="0070"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating an exemplary 3D shape representation process using OctField in accordance with some implementations of the present disclosure.</p><p id="p-0078" num="0071">The process <b>500</b> of representing the 3D shape, includes a step <b>502</b> of dividing a 3D space enclosing the 3D shape into a plurality of 3D spaces with a hierarchical octree structure.</p><p id="p-0079" num="0072">The process <b>500</b> also includes a step <b>504</b> of generating local implicit functions, and each of the local implicit functions corresponds to a respective 3D space of the plurality of 3D spaces.</p><p id="p-0080" num="0073">The process <b>500</b> additionally includes a step <b>506</b> of reconstructing a representation of the 3D shape from the local implicit functions with the hierarchical octree structure.</p><p id="p-0081" num="0074">Additional implementations may include one or more of the following features.</p><p id="p-0082" num="0075">In some embodiments, the step <b>502</b> of dividing the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure includes: recursively subdividing the 3D space into child octants according to surface occupancy and richness of geometry of the 3D shape.</p><p id="p-0083" num="0076">In some embodiments, the step <b>502</b> of dividing the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure includes: training a neural network to divide the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure.</p><p id="p-0084" num="0077">In some embodiments, training the neural network to divide the 3D space includes: inputting into the neural network a training set of 3D shapes with constructed octree cells; mapping features extracted from the training set to latent space of hierarchical local encoders; and extracting the features of the latent space into the plurality of 3D spaces with the hierarchical octree structure through hierarchical local decoders.</p><p id="p-0085" num="0078">In some embodiments, mapping the features extracted from the training set to the latent space of the hierarchical local encoders includes: computing by the neural network a first binary indicator from learning the training set that indicates whether a respective 3D space encloses part of a surface of the 3D shape; computing by the neural network a second binary indicator from learning the training set that indicates whether the respective 3D space needs further subdivision according to an enclosed geometry of the surface; and extracting a geometry feature of the respective 3D space by passing the enclosed geometry to the neural network. In some embodiments, the hierarchical local encoders encode the features extracted from the training set in a bottom-up order until a root node of the hierarchical octree structure has been processed.</p><p id="p-0086" num="0079">In some embodiments, the neural network is a 3D voxel convolutional neural network.</p><p id="p-0087" num="0080">In some embodiments, extracting the features of the latent space into the plurality of 3D spaces with the hierarchical octree structure through the hierarchical local decoders includes: extracting a first binary indicator that indicates whether a respective 3D space encloses part of a surface of the 3D shape; extracting a second binary indicator that indicates whether the respective 3D space needs further subdivision according to an enclosed geometry of the surface; and extracting geometry features from the respective 3D space. In some embodiments, the hierarchical local decoders extract the latent space in a top-down order until no octants need to be subdivided within the hierarchical octree structure.</p><p id="p-0088" num="0081">In some embodiments, the step <b>504</b> of generating the local implicit functions includes: in accordance with a determination that a respective 3D space encloses part of a surface of the 3D shape, generating a respective local implicit function corresponding to a geometry of the part of the surface.</p><p id="p-0089" num="0082">In some embodiments, the step <b>504</b> of generating the respective local implicit function corresponding to the geometry of the part of the surface includes: training a neural network to recognize the geometry of the part of the surface and to generate a respective local implicit function corresponding to the geometry of the part of the surface.</p><p id="p-0090" num="0083">In some embodiments, the step <b>506</b> of reconstructing the representation of the 3D shape from the local implicit functions with the hierarchical octree structure includes: reconstructing a 3D surface of the 3D shape within the respective 3D space with a respective local implicit function using geometry feature and 3D location of the 3D surface; and converting the local implicit functions within the hierarchical octree structure to a 3D mesh output.</p><p id="p-0091" num="0084">In some embodiments, the 3D shape includes a partial 3D shape comprising a 3D partial point cloud or a 3D mesh.</p><p id="p-0092" num="0085">In some embodiments, the 3D shape includes a 2D image.</p><p id="p-0093" num="0086">Table 1 shows quantitative evaluation on shape reconstruction of the OctField compared with other baselines according to some implementations of the present disclosure. As shown in Table 1, OctField can achieve the best performance on average score and in each category by comparing with four baselines: IM-Net, OCCNet, Local Implicit Grids (LIG), Adaptive O-CNN (AOCNN). <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the shape reconstruction comparison between OctField and the baseline methods: AOCNN, LIG, OCCNet, IM-Net in accordance with some implementations of the present disclosure. The shape reconstruction results for different methods are illustrated in columns in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0094" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="217pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 1</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Quantitative evaluation on shape reconstruction of the OctField </entry></row><row><entry>compared with other baselines according</entry></row><row><entry>to some implementations of the present disclosure.</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="42pt" align="left"/><colspec colname="2" colwidth="35pt" align="left"/><colspec colname="3" colwidth="119pt" align="center"/><colspec colname="4" colwidth="21pt" align="center"/><tbody valign="top"><row><entry/><entry/><entry>DataSet</entry><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="8"><colspec colname="1" colwidth="42pt" align="left"/><colspec colname="2" colwidth="35pt" align="left"/><colspec colname="3" colwidth="28pt" align="center"/><colspec colname="4" colwidth="21pt" align="center"/><colspec colname="5" colwidth="28pt" align="center"/><colspec colname="6" colwidth="21pt" align="center"/><colspec colname="7" colwidth="21pt" align="center"/><colspec colname="8" colwidth="21pt" align="center"/><tbody valign="top"><row><entry>Metric</entry><entry>Method</entry><entry>Plane</entry><entry>Car</entry><entry>Chair</entry><entry>Table</entry><entry>Sofa</entry><entry>Mean</entry></row><row><entry namest="1" nameend="8" align="center" rowsep="1"/></row><row><entry>CD&#x2193; &#xd7;</entry><entry>IM-Net</entry><entry>4.21</entry><entry>15.14</entry><entry>&#x2002;6.99</entry><entry>8.03</entry><entry>7.95</entry><entry>&#x2002;8.46</entry></row><row><entry>10<sup>&#x2212;4</sup></entry><entry>OccNet</entry><entry>5.62</entry><entry>13.54</entry><entry>&#x2002;7.87</entry><entry>7.47</entry><entry>8.60</entry><entry>&#x2002;8.62</entry></row><row><entry/><entry>LIG</entry><entry>2.50</entry><entry>&#x2002;5.46</entry><entry>&#x2002;2.37</entry><entry>2.81</entry><entry>3.23</entry><entry>&#x2002;3.27</entry></row><row><entry/><entry>AOCNN</entry><entry>6.90</entry><entry>16.61</entry><entry>10.80</entry><entry>9.15</entry><entry>9.40</entry><entry>10.57</entry></row><row><entry/><entry>OctField</entry><entry>2.29</entry><entry>&#x2002;4.84</entry><entry>&#x2002;2.19</entry><entry>2.53</entry><entry>3.02</entry><entry>&#x2002;2.97</entry></row><row><entry/><entry>IM-Net</entry><entry>3.39</entry><entry>&#x2002;4.46</entry><entry>&#x2002;3.77</entry><entry>3.16</entry><entry>2.51</entry><entry>&#x2002;3.45</entry></row><row><entry/><entry>OccNet</entry><entry>3.46</entry><entry>&#x2002;4.93</entry><entry>&#x2002;4.16</entry><entry>3.34</entry><entry>2.81</entry><entry>&#x2002;3.74</entry></row><row><entry>EMD&#x2193; &#xd7;</entry><entry>LIG</entry><entry>2.57</entry><entry>&#x2002;4.08</entry><entry>&#x2002;2.18</entry><entry>2.27</entry><entry>2.06</entry><entry>&#x2002;2.63</entry></row><row><entry>10<sup>&#x2212;2</sup></entry><entry>AOCNN</entry><entry>4.26</entry><entry>&#x2002;5.63</entry><entry>&#x2002;6.76</entry><entry>4.78</entry><entry>3.49</entry><entry>&#x2002;4.98</entry></row><row><entry/><entry>OctField</entry><entry>2.47</entry><entry>&#x2002;2.79</entry><entry>&#x2002;2.13</entry><entry>1.70</entry><entry>1.84</entry><entry>&#x2002;2.19</entry></row><row><entry namest="1" nameend="8" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0095" num="0087">In addition, comparisons with LDIF are provided and (CD, IoU) results (0.20, 92.8) on Chair category are better than those of LDIF (0.34, 87.5). Compared with the existing methods based on octrees and implicit functions, the OctField method can achieve better reconstruction accuracy.</p><p id="p-0096" num="0088">Table 2 shows the memory consumption with respect to different levels of decomposition of OctField compared with LIG according to some implementations of the present disclosure.</p><p id="p-0097" num="0089">Moreover, the average inference time for the objects reported in Table 1 above is 114.6 second for LIG and 5.4 second for OctField. For the large scene, LIG uses 114.9 second while OctField uses 22.7 second. Compared with the local implicit function representation with regular subdivision of 3D space, the representation of OctField uses less memory and computational cost.</p><p id="p-0098" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="217pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 2</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>The memory consumption with respect to different levels of decomposition </entry></row><row><entry>of OctField compared with LIG according to some implementations of </entry></row><row><entry>the present disclosure. </entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="1" colwidth="70pt" align="center"/><colspec colname="2" colwidth="42pt" align="center"/><colspec colname="3" colwidth="28pt" align="center"/><colspec colname="4" colwidth="28pt" align="center"/><colspec colname="5" colwidth="28pt" align="center"/><colspec colname="6" colwidth="21pt" align="center"/><tbody valign="top"><row><entry/><entry>level </entry><entry>1 </entry><entry>2 </entry><entry>3 </entry><entry>4</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="1" colwidth="70pt" align="center"/><colspec colname="2" colwidth="42pt" align="center"/><colspec colname="3" colwidth="28pt" align="char" char="."/><colspec colname="4" colwidth="28pt" align="char" char="."/><colspec colname="5" colwidth="28pt" align="char" char="."/><colspec colname="6" colwidth="21pt" align="char" char="."/><tbody valign="top"><row><entry>Number of cells </entry><entry>LIG </entry><entry>8 </entry><entry>64 </entry><entry>512 </entry><entry>4096 </entry></row><row><entry/><entry>OctField </entry><entry>8 </entry><entry>30 </entry><entry>200 </entry><entry>1000 </entry></row><row><entry>Memory (GB) </entry><entry>LIG </entry><entry>0.1 </entry><entry>0.6 </entry><entry>5 </entry><entry>40 </entry></row><row><entry/><entry>OctField </entry><entry>0.2 </entry><entry>1.2 </entry><entry>4.8 </entry><entry>23</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0099" num="0090">In some embodiments, the 3D voxel CNNs of local encoders can also be replaced with other encoders that extract geometry feature such as PointNet++ for point clouds.</p><p id="p-0100" num="0091">Further embodiments also include various subsets of the above embodiments combined or otherwise re-arranged in various other embodiments.</p><p id="p-0101" num="0092">Herein, an image processing apparatus of the embodiments of the present application is implemented with reference to descriptions of accompanying drawings. The image processing apparatus may be implemented in various forms, for example, different types of computer devices such as a server or a terminal (for example, a desktop computer, a notebook computer, or a smartphone). A hardware structure of the image processing apparatus of the embodiments of the present application is further described below. It may be understood that <figref idref="DRAWINGS">FIG. <b>7</b></figref> merely shows an exemplary structure, rather than all structures, of the image processing apparatus, and a partial or entire structure shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> may be implemented according to requirements.</p><p id="p-0102" num="0093">Referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a schematic diagram of an optional hardware structure of an image processing apparatus according to an embodiment of the present application, and in an actual application, may be applied to the server or various terminals running an application program. An image processing apparatus <b>700</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> includes: at least one processor <b>701</b>, a memory <b>702</b>, a user interface <b>703</b>, and at least one network interface <b>704</b>. Components in the image processing apparatus <b>700</b> are coupled together by means of a bus system <b>705</b>. It may be understood that the bus <b>705</b> is configured to implement connection and communication between the components. The bus system <b>705</b>, besides including a data bus, may further include a power bus, a control bus, and a status signal bus. However, for a purpose of a clear explanation, all buses are marked as the bus system <b>705</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0103" num="0094">The user interface <b>703</b> may include a display, a keyboard, a mouse, a trackball, a click wheel, a key, a button, a touchpad, a touchscreen, or the like.</p><p id="p-0104" num="0095">It may be understood that the memory <b>702</b> may be a volatile memory or a non-volatile memory, or may include both a volatile memory and a non-volatile memory.</p><p id="p-0105" num="0096">The memory <b>702</b> in the embodiments of the present application is configured to store different types of data to support operations of the image processing apparatus <b>700</b>. Examples of the data include: any computer program, such as an executable program <b>7021</b> and an operating system <b>7022</b>, used to perform operations on the image processing apparatus <b>700</b>, and a program used to perform the image processing method of the embodiments of the present application may be included in the executable program <b>7021</b>.</p><p id="p-0106" num="0097">The image processing method disclosed in the embodiments of the present application may be applied to the processor <b>701</b>, or may be performed by the processor <b>701</b>. The processor <b>701</b> may be an integrated circuit chip and has a signal processing capability. In an implementation process, each step of the image processing method may be completed by using an integrated logic circuit of hardware in the processor <b>701</b> or an instruction in a software form. The foregoing processor <b>701</b> may be a general-purpose processor, a digital signal processor (DSP), another programmable logic device, a discrete gate, a transistor logic device, a discrete hardware component, or the like. The processor <b>701</b> may implement or execute methods, steps, and logical block diagrams provided in the embodiments of the present application. The general purpose processor may be a microprocessor, any conventional processor, or the like. The steps in the method provided in the embodiments of the present application may be directly performed by a hardware decoding processor, or may be performed by combining hardware and software modules in a decoding processor. The software module may be located in a storage medium. The storage medium is located in the memory <b>702</b>. The processor <b>701</b> reads information in the memory <b>702</b> and performs steps of the image processing method provided in the embodiments of the present application by combining the information with hardware thereof.</p><p id="p-0107" num="0098">In some embodiments, the image processing and OctField formation can be accomplished on a group of servers or a cloud on a network.</p><p id="p-0108" num="0099">In one or more examples, the functions described may be implemented in hardware, software, firmware, or any combination thereof. If implemented in software, the functions may be stored on or transmitted over, as one or more instructions or code, a computer-readable medium and executed by a hardware-based processing unit. Computer-readable media may include computer-readable storage media, which corresponds to a tangible medium such as data storage media, or communication media including any medium that facilitates transfer of a computer program from one place to another, e.g., according to a communication protocol. In this manner, computer-readable media generally may correspond to (1) tangible computer-readable storage media that is non-transitory or (2) a communication medium such as a signal or carrier wave. Data storage media may be any available media that can be accessed by one or more computers or one or more processors to retrieve instructions, code and/or data structures for implementation of the implementations described in the present application. A computer program product may include a computer-readable medium.</p><p id="p-0109" num="0100">The terminology used in the description of the implementations herein is for the purpose of describing particular implementations only and is not intended to limit the scope of claims. As used in the description of the implementations and the appended claims, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will also be understood that the term &#x201c;and/or&#x201d; as used herein refers to and encompasses any and all possible combinations of one or more of the associated listed items. It will be further understood that the terms &#x201c;comprises&#x201d; and/or &#x201c;comprising,&#x201d; when used in this specification, specify the presence of stated features, elements, and/or components, but do not preclude the presence or addition of one or more other features, elements, components, and/or groups thereof.</p><p id="p-0110" num="0101">It will also be understood that, although the terms first, second, etc. may be used herein to describe various elements, these elements should not be limited by these terms. These terms are only used to distinguish one element from another. For example, a first electrode could be termed a second electrode, and, similarly, a second electrode could be termed a first electrode, without departing from the scope of the implementations. The first electrode and the second electrode are both electrodes, but they are not the same electrode.</p><p id="p-0111" num="0102">The description of the present application has been presented for purposes of illustration and description, and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications, variations, and alternative implementations will be apparent to those of ordinary skill in the art having the benefit of the teachings presented in the foregoing descriptions and the associated drawings. The embodiment was chosen and described in order to best explain the principles of the invention, the practical application, and to enable others skilled in the art to understand the invention for various implementations and to best utilize the underlying principles and various implementations with various modifications as are suited to the particular use contemplated. Therefore, it is to be understood that the scope of claims is not to be limited to the specific examples of the implementations disclosed and that modifications and other implementations are intended to be included within the scope of the appended claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230005217A1-20230105-M00001.NB"><img id="EMI-M00001" he="9.91mm" wi="76.20mm" file="US20230005217A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of representing a 3D shape, comprising:<claim-text>dividing a 3D space enclosing the 3D shape into a plurality of 3D spaces with a hierarchical octree structure;</claim-text><claim-text>generating local implicit functions, each of the local implicit functions corresponding to a respective 3D space of the plurality of 3D spaces; and</claim-text><claim-text>reconstructing a representation of the 3D shape from the local implicit functions with the hierarchical octree structure.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein dividing the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure comprises:<claim-text>recursively subdividing the 3D space into child octants according to surface occupancy and richness of geometry of the 3D shape.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein dividing the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure comprises:<claim-text>training a neural network to divide the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein training the neural network to divide the 3D space includes:<claim-text>inputting into the neural network a training set of 3D shapes with constructed octree cells;</claim-text><claim-text>mapping features extracted from the training set to latent space of hierarchical local encoders; and</claim-text><claim-text>extracting the features of the latent space into the plurality of 3D spaces with the hierarchical octree structure through hierarchical local decoders.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein mapping the features extracted from the training set to the latent space of the hierarchical local encoders includes:<claim-text>computing by the neural network a first binary indicator from learning the training set that indicates whether a respective 3D space encloses part of a surface of the 3D shape;</claim-text><claim-text>computing by the neural network a second binary indicator from learning the training set that indicates whether the respective 3D space needs further subdivision according to an enclosed geometry of the surface; and</claim-text><claim-text>extracting a geometry feature of the respective 3D space by passing the enclosed geometry to the neural network;</claim-text><claim-text>wherein the hierarchical local encoders encode the features extracted from the training set in a bottom-up order until a root node of the hierarchical octree structure has been processed.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the neural network is a 3D voxel convolutional neural network.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein extracting the features of the latent space into the plurality of 3D spaces with the hierarchical octree structure through the hierarchical local decoders includes:<claim-text>extracting a first binary indicator that indicates whether a respective 3D space encloses part of a surface of the 3D shape;</claim-text><claim-text>extracting a second binary indicator that indicates whether the respective 3D space needs further subdivision according to an enclosed geometry of the surface; and</claim-text><claim-text>extracting geometry features from the respective 3D space;</claim-text><claim-text>wherein the hierarchical local decoders extract the latent space in a top-down order until no octants need to be subdivide within the hierarchical octree structure.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the local implicit functions includes:<claim-text>in accordance with a determination that a respective 3D space encloses part of a surface of the 3D shape, generating a respective local implicit function corresponding to a geometry of the part of the surface.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein generating the respective local implicit function corresponding to the geometry of the part of the surface includes:<claim-text>training a neural network to recognize the geometry of the part of the surface and to generate a respective local implicit function corresponding to the geometry of the part of the surface.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein reconstructing the representation of the 3D shape from the local implicit functions with the hierarchical octree structure includes:<claim-text>reconstructing a 3D surface of the 3D shape within the respective 3D space with a respective local implicit function using geometry feature and 3D location of the 3D surface; and</claim-text><claim-text>converting the local implicit functions within the hierarchical octree structure to a 3D mesh output.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the 3D shape includes a partial 3D shape comprising a 3D partial point cloud or a 3D mesh.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the 3D shape includes a 2D image.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. An electronic apparatus comprising one or more processing units, memory coupled to the one or more processing units, and a plurality of programs stored in the memory that, when executed by the one or more processing units, cause the electronic apparatus to perform a plurality of operations of representing a 3D shape, comprising:<claim-text>dividing a 3D space enclosing the 3D shape into a plurality of 3D spaces with a hierarchical octree structure;</claim-text><claim-text>generating local implicit functions, each of the local implicit functions corresponding to a respective 3D space of the plurality of 3D spaces; and</claim-text><claim-text>reconstructing a representation of the 3D shape from the local implicit functions with the hierarchical octree structure.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The electronic apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein dividing the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure comprises:<claim-text>recursively subdividing the 3D space into child octants according to surface occupancy and richness of geometry of the 3D shape.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The electronic apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein dividing the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure comprises:<claim-text>training a neural network to divide the 3D space enclosing the 3D shape into the plurality of 3D spaces with the hierarchical octree structure.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The electronic apparatus according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein training the neural network to divide the 3D space includes:<claim-text>inputting into the neural network a training set of 3D shapes with constructed octree cells;</claim-text><claim-text>mapping features extracted from the training set to latent space of hierarchical local encoders; and</claim-text><claim-text>extracting the features of the latent space into the plurality of 3D spaces with the hierarchical octree structure through hierarchical local decoders.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The electronic apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein generating the local implicit functions includes:<claim-text>in accordance with a determination that a respective 3D space encloses part of a surface of the 3D shape, generating a respective local implicit function corresponding to a geometry of the part of the surface.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The electronic apparatus according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein generating the respective local implicit function corresponding to the geometry of the part of the surface includes:<claim-text>training a neural network to recognize the geometry of the part of the surface and to generate a respective local implicit function corresponding to the geometry of the part of the surface.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The electronic apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein reconstructing the representation of the 3D shape from the local implicit functions with the hierarchical octree structure includes:<claim-text>reconstructing a 3D surface of the 3D shape within the respective 3D space with a respective local implicit function using geometry feature and 3D location of the 3D surface; and</claim-text><claim-text>converting the local implicit functions within the hierarchical octree structure to a 3D mesh output.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A non-transitory computer readable storage medium storing a plurality of programs for execution by an electronic apparatus having one or more processing units, wherein the plurality of programs, when executed by the one or more processing units, cause the electronic apparatus to perform a plurality of operations of representing a 3D shape, comprising:<claim-text>dividing a 3D space enclosing the 3D shape into a plurality of 3D spaces with a hierarchical octree structure;</claim-text><claim-text>generating local implicit functions, each of the local implicit functions corresponding to a respective 3D space of the plurality of 3D spaces; and</claim-text><claim-text>reconstructing a representation of the 3D shape from the local implicit functions with the hierarchical octree structure.</claim-text></claim-text></claim></claims></us-patent-application>
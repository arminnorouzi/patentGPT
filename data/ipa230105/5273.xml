<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005274A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005274</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17757226</doc-number><date>20200326</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-225136</doc-number><date>20191213</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>58</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>W</subclass><main-group>60</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>58</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>60</main-group><subgroup>0015</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2420</main-group><subgroup>42</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">SECURITY SYSTEM AND MONITORING METHOD</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>DAIWA TSUSHIN CO., LTD</orgname><address><city>Ishikawa</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>IWAMOTO</last-name><first-name>Hidenari</first-name><address><city>Kanazawa-shi, Ishikawa</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/013675</doc-number><date>20200326</date></document-id><us-371c12-date><date>20220612</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A security system includes: an autonomous vehicle; a camera installed in the autonomous vehicle; and a crime determination unit that makes a determination regarding a crime on the basis of an image captured by the camera. The autonomous vehicle is a shared car shared by residents within a region; in response to a request, the autonomous vehicle automatically picks up at the departure point of the residents and automatically moves to the destination of the residents; and the camera take pictures of the moving section to the starting point and the moving section from the starting point to the destination; and the crime determination unit determines a crime based on the images taken in the moving section to the departure point and the moving section from the starting point to the destination.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="134.28mm" wi="118.03mm" file="US20230005274A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="181.44mm" wi="131.15mm" file="US20230005274A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="159.94mm" wi="120.06mm" file="US20230005274A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="157.40mm" wi="101.85mm" file="US20230005274A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="157.06mm" wi="97.87mm" file="US20230005274A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="163.32mm" wi="122.43mm" file="US20230005274A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="195.07mm" wi="81.62mm" file="US20230005274A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><p id="p-0002" num="0001">The present application is a National Phase of International Application Number PCT/JP2020/013675, filed Mar. 26, 2020, and claims priority based on Japanese Patent Application No. 2019-225136, filed Dec. 13, 2019.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present invention relates to a security system and a monitoring method.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0004" num="0003">For example, patent Literature 1 discloses an autonomous driving system includes an acquisitioner provided in each of a plurality of mobile objects and configured to acquire information about surroundings of the mobile object when the mobile object is moving; and a controller configured to determine a patrol plan for each of a plurality of regions on the basis of the information acquired by the acquisitioner of some mobile objects among the plurality of mobile objects that have moved in the same region; and create an operation command according to the patrol plan for each region determined by the controller.</p><heading id="h-0003" level="1">PATENT LITERATURE</heading><p id="p-0005" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0004">[PTL 1] Japanese Unexamined Patent Application Publication No. JP2019-117574</li></ul></p><heading id="h-0004" level="1">SUMMARY OF INVENTION</heading><heading id="h-0005" level="1">Technical Problem</heading><p id="p-0006" num="0005">An objective of the present invention is to provide a security system that monitors by a patrol route that takes into account human behavior.</p><heading id="h-0006" level="1">Solution to Problem</heading><p id="p-0007" num="0006">The security system according to the present invention includes a plurality of autonomous vehicles; a camera installed in each of said plurality of autonomous vehicles; and a crime determination unit that determines a crime based on an image taken by the camera.</p><p id="p-0008" num="0007">Preferably, the autonomous vehicle is a shared vehicle shared by residents in the area, and the crime determination unit determines a crime that may occur in the area.</p><p id="p-0009" num="0008">Preferably, in response to a request from the residents, the autonomous vehicle automatically picks up at the departure point of the residents and automatically moves to the destination of the residents; and the camera take pictures of the moving section to the starting point and the moving section from the starting point to the destination; and the crime determination unit determines a crime based on the images taken in the moving section to the departure point and the moving section from the starting point to the destination.</p><p id="p-0010" num="0009">Preferably, it also has a charger installed in a common facility in the area, the automatic vehicle is an electric vehicle, and while charging in the vicinity of the charger, waiting until requested by the residents, and after taking the residents to their destination, returns to the vicinity of the charger; and the camera shots from the timing of departure from the vicinity of the charger to the time of returning to the vicinity of the charger, according to the request of the residents; and the criminal determination unit makes a determination regarding the crime based on the images taken from the vicinity of the charger to the return to the vicinity of the charger.</p><p id="p-0011" num="0010">Further, in the monitoring method according to the present invention, the step of moving the autonomous vehicle shared by the residents at the request of the residents; and the step of photographing the outside of the vehicle by the camera installed in the autonomous vehicle; and the step of making a determination regarding a crime based on the image taken by the computer.</p><heading id="h-0007" level="1">Advantageous Effects of Invention</heading><p id="p-0012" num="0011">It is possible to perform monitoring by a patrol route that takes into account human behavior.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0008" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a drawing illustrating the whole structure of the security system <b>1</b>.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram explaining the monitoring area in the security system <b>1</b>.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a drawing illustrating the hardware configuration of management server <b>2</b>.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a drawing mainly illustrating the part related to information processing in the hardware configuration of the autonomous vehicle <b>3</b>.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a drawing illustrating the functional structure of the management server <b>2</b> and the autonomous vehicle <b>3</b>.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart explaining the monitoring process (S<b>10</b>) by a security system <b>1</b>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0009" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0019" num="0018">Hereinafter, embodiments of the present invention are described while referencing the drawings.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a drawing illustrating the whole structure of the security system <b>1</b>.</p><p id="p-0021" num="0020">As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the security system <b>1</b> includes a management server <b>2</b> that manages the degree of danger in the area, an autonomous vehicle <b>3</b> that moves by automatic driving, a charger <b>4</b> provided at the departure/arrival point of the autonomous vehicle <b>3</b>, and a mobile terminal <b>60</b> used by residents in the area. And these configurations are connected to each other via a communication network <b>80</b> such as a wireless public line.</p><p id="p-0022" num="0021">The management server <b>2</b> is an example of the crime determination unit according to the present invention, and is a computer terminal on which the monitoring program <b>22</b> is installed. The management server <b>2</b> of this example determines the possibility of a crime based on an image taken by a camera <b>308</b> installed in the autonomous vehicle <b>3</b>.</p><p id="p-0023" num="0022">The autonomous vehicle <b>3</b> is a level <b>3</b> or higher vehicle car that moves by self-driving. For example, the autonomous vehicle <b>3</b> is a level <b>5</b> electric vehicle that realizes fully automatic driving. The autonomous vehicle of this example is a self-driving electric vehicle (share car) shared by local residents. The autonomous vehicle <b>3</b> may configured takes a picture of the face of the occupant, authenticates the face of the local resident based on the taken image, and moves to the destination of the resident only when the face recognition is successful.</p><p id="p-0024" num="0023">The charger <b>4</b> is a charger for charging the battery built in the autonomous vehicle <b>3</b>, for example, it is installed in a common facility in the area. The charger <b>4</b> of this example is installed in the parking lot of a public hall. The charger <b>4</b> may configure to automatically start charging when the autonomous vehicle comes to a predetermined area (near area). The mobile terminal <b>60</b> is, for example, a smart phone used by local residents, and an application for using the autonomous vehicle <b>3</b> is installed. The communication network <b>80</b> is, for example, an Internet network including a wireless public line and a wireless LAN.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram explaining the monitoring area in the security system <b>1</b>.</p><p id="p-0026" num="0025">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the automatic vehicle <b>3</b> departs from the charger <b>4</b> of the public hall and picks up the residents to the departure place of the residents in response to the vehicle allocation request from the residents' mobile terminal <b>60</b>. After getting on the requested residents, move to the destination of the residents, get off the residents, and then return to the charger <b>4</b> of the public hall. During these movements, the camera <b>308</b> of the autonomous vehicle <b>3</b> photographs the surroundings, and the management server <b>2</b> determines the possibility of a crime based on the captured images.</p><p id="p-0027" num="0026">That is, in the security system <b>1</b>, the route (the starting point and the destination designated by the residents) that takes into account the behavior of the residents is monitored. Furthermore, by starting from the common facilities in the area such as public halls, the common facilities in the area can be monitored intensively. In addition, the frequency of surveillance patrols depends on the frequency of outings of residents. For example, when crimes are likely to occur, such as local festivals and fireworks displays, surveillance patrols can be focused on.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a drawing illustrating the hardware configuration of management server <b>2</b>.</p><p id="p-0029" num="0028">As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the management server <b>2</b> includes a CPU <b>200</b>, a memory <b>202</b>, an HDD <b>204</b>, a network interface <b>206</b> (network IF<b>206</b>), a display device <b>208</b>, and an input device <b>210</b>, which are interconnected via a bus <b>212</b>.</p><p id="p-0030" num="0029">The CPU <b>200</b> is, for example a central processing unit.</p><p id="p-0031" num="0030">The memory <b>202</b> is, for example, a volatile memory and functions as a main storage device.</p><p id="p-0032" num="0031">The HDD <b>204</b> is, for example, a hard disk drive and functions as a nonvolatile storage device configured to store a computer program (for example, the monitoring program <b>22</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>) and other data files (for example, image data taken in the past).</p><p id="p-0033" num="0032">The network IF <b>206</b> is an interface for wired or wireless communication. For example, the network IF <b>206</b> enables communication on the autonomous vehicle <b>3</b>.</p><p id="p-0034" num="0033">The display device <b>208</b> is, for example, a liquid crystal display.</p><p id="p-0035" num="0034">The input device <b>210</b> is, for example, a keyboard and a mouse.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a drawing mainly illustrating the part related to information processing in the hardware configuration of the autonomous vehicle <b>3</b>. In addition to the configuration illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the autonomous vehicle <b>3</b> includes a hardware configuration for functioning as a self-driving electric vehicle.</p><p id="p-0037" num="0036">As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the autonomous vehicle <b>3</b> includes a CPU <b>300</b>, a memory <b>302</b>, an HDD <b>304</b>, a network interface <b>306</b> (network IF <b>306</b>), a camera <b>308</b>, and a GPS receiver <b>310</b>, which are interconnected via a bus <b>312</b>.</p><p id="p-0038" num="0037">The CPU <b>300</b> is, for example, a central processing unit.</p><p id="p-0039" num="0038">The memory <b>302</b> is, for example, a volatile memory and functions as a main storage device.</p><p id="p-0040" num="0039">The HDD <b>304</b> is, for example, a hard disk drive and functions as a nonvolatile storage device configured to store a computer program (for example, the monitoring program <b>22</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref>) and other data files.</p><p id="p-0041" num="0040">The network IF <b>306</b> is an interface for wired or wireless communication. For example, the network IF <b>206</b> enables communication on the management server <b>2</b>.</p><p id="p-0042" num="0041">The camera <b>308</b> is a camera that photographs the surroundings of the autonomous vehicle <b>3</b>, for example, a camera built in a drive recorder.</p><p id="p-0043" num="0042">The GPS receiver <b>310</b> is an example of a position characteristic device that identifies the position of the autonomous vehicle <b>3</b>, for example, a GPS receiver provided in a car navigation system.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a drawing illustrating the functional structure of the management server <b>2</b> and the autonomous vehicle <b>3</b>.</p><p id="p-0045" num="0044">As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the monitoring program is installed on the management server <b>2</b>, and the image database <b>260</b> (image DB <b>260</b>) is configured.</p><p id="p-0046" num="0045">In addition, the patrol program <b>32</b> is installed in the autonomous vehicle <b>3</b>.</p><p id="p-0047" num="0046">The monitoring program <b>22</b> has a vehicle allocation unit <b>220</b>, an image receiving unit <b>222</b>, a crime determination unit <b>224</b>, and a reporting unit <b>226</b>.</p><p id="p-0048" num="0047">The patrol program <b>32</b> includes a request receiving unit <b>320</b>, a route determining unit <b>322</b>, an automatic driving unit <b>324</b>, a camera control unit <b>326</b>, and an image transfer unit <b>328</b>.</p><p id="p-0049" num="0048">Note that part or all of the monitoring program and the patrol program <b>32</b> may be realized by hardware such as an ASIC, or may be realized by borrowing a part of the functions of the OS (Operating System).</p><p id="p-0050" num="0049">In the patrol program <b>32</b>, the request receiving unit <b>320</b> receives a request for vehicle allocation from the residents via the management server <b>2</b>. For example, the request receiving unit <b>320</b> receives the location information of the departure place of the resident and the location information of the destination of the resident as a vehicle allocation request from the mobile terminal <b>60</b>. The location information of the resident's destination can be sequentially added even after the resident gets on the autonomous vehicle <b>3</b>.</p><p id="p-0051" num="0050">The route determination unit <b>322</b> determines the movement route of the autonomous vehicle <b>3</b> based on the vehicle allocation request received by the request reception unit <b>320</b>. For example, the route determination unit <b>322</b> determines a route from the current location to the departure point of the resident, a route from the departure point of the resident to the destination of the resident, and a route from the destination of the resident to the charger <b>4</b>. The route determination unit <b>322</b> changes the route according to the added or changed destination of the resident when the destination of the resident is added or changed by the request receiving unit <b>320</b>.</p><p id="p-0052" num="0051">The automatic driving unit <b>324</b> automatically drives the automatic vehicle <b>3</b> on the route determined by the route determining unit <b>322</b>. When the automatic driving unit <b>324</b> starts the automatic driving of the automatic vehicle <b>3</b>, the camera control unit <b>326</b> controls the camera <b>308</b> to start photographing the surroundings; and when the automatic vehicle <b>3</b> returns to the vicinity of the charger <b>4</b> and the automatic driving unit <b>324</b> finishes the automatic driving, the shooting by the camera <b>308</b> is finished.</p><p id="p-0053" num="0052">The image transfer unit <b>328</b> sequentially transmits the image data of the image taken by the camera <b>308</b> and the position information indicating the place where the image was taken to the management server <b>2</b>. For example, the image transfer unit <b>328</b> immediately transmits the image data of the image taken by the camera <b>308</b> and the position information of the shooting location to the management server <b>2</b>.</p><p id="p-0054" num="0053">The monitoring program <b>22</b>, determines the automatic vehicle <b>3</b> to be assigned from the automatic vehicles <b>3</b> waiting in the vicinity of the charger <b>4</b>, when the vehicle allocation unit <b>220</b> receives a vehicle allocation request from the local residents; and transmit a vehicle allocation request (including location information of the departure place) to the autonomous vehicle <b>3</b>. For example, when the vehicle allocation unit <b>220</b> receives a vehicle allocation request from the resident's mobile terminal <b>60</b>, the vehicle allocation unit <b>220</b> determines the autonomous vehicle <b>3</b> to be assigned based on the charging status, from among the autonomous vehicles <b>3</b> waiting in the vicinity of the charger <b>4</b>.</p><p id="p-0055" num="0054">The image receiving unit <b>222</b> receives the image data of the image taken by the camera <b>308</b> of the autonomous vehicle <b>3</b> and the position information of the photographing location from the autonomous vehicle <b>3</b>. The image receiving unit <b>222</b> of this example receives the image data of the captured image and the position information of the photographing location in real time from the autonomous vehicle <b>3</b>.</p><p id="p-0056" num="0055">The crime determination unit <b>224</b> makes a determination regarding a crime based on the image data received by the image reception unit <b>222</b>. The determination regarding a crime is, for example, determination of the presence or absence of a crime, calculation of a crime occurrence probability, or the like. For example, the crime determination unit <b>224</b> compares the received image data with the image data taken at the same place in the past based on the image data and the position information of the shooting place received by the image receiving unit <b>222</b>; and calculates the probability of occurrence. The crime determination unit <b>224</b> of this example calculates the probability of crime occurrence by deep learning based on the image data taken, the position information of the shooting place, and the shooting time.</p><p id="p-0057" num="0056">The reporting unit <b>226</b> reports on the occurrence of a crime based on the determination result by the crime determination unit <b>224</b>. For example, when the probability of crime occurrence calculated by the crime judgment unit <b>224</b> is equal to or higher than the reference value, the reporting unit <b>226</b> obtains the calculated crime occurrence probability and the location information of the shooting location; and informs the police, the security company, or the public hall etc.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart explaining the monitoring process (S<b>10</b>) by a security system <b>1</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, in step <b>100</b> (S<b>100</b>), the management server <b>2</b> waits until the vehicle allocation request is received from the resident's mobile terminal <b>60</b> (S<b>100</b>: No), and move to S<b>105</b> processing when the vehicle allocation request is received (S<b>100</b>: Yes).</p><p id="p-0059" num="0058">In step <b>105</b> (S<b>105</b>), the vehicle allocation unit <b>220</b> of the management server <b>2</b> compares the charging states of the autonomous vehicle <b>3</b>, selects the autonomous vehicle <b>3</b> having a larger remaining charge; and transmits to the selected autonomous vehicle <b>3</b>, the location information of the resident's departure place and the location information of the resident's destination.</p><p id="p-0060" num="0059">When the request receiving unit <b>320</b> of the selected autonomous vehicle <b>3</b> receives the request from the vehicle allocation unit <b>220</b>, it outputs the received position information of the departure place and the destination to the route determination unit <b>322</b> and instructs the route determination.</p><p id="p-0061" num="0060">The route determination unit <b>322</b> determines the route based on the position information of the departure place and the destination input from the request reception unit <b>320</b> and the position information of the current location.</p><p id="p-0062" num="0061">In step <b>110</b> (S<b>110</b>), the automatic driving unit <b>324</b> starts the automatic driving of the automatic vehicle <b>3</b> according to the route determined by the route determining unit <b>322</b>.</p><p id="p-0063" num="0062">In step <b>115</b> (S<b>115</b>), the camera control unit <b>326</b> controls the camera <b>308</b> while the automatic driving unit <b>324</b> is automatically driving the automatic vehicle <b>3</b>, and photographs the surroundings of the automatic vehicle <b>3</b>. The image transfer unit <b>328</b> transmits the image data taken by the camera <b>308</b>, the position information of the shooting location, and the shooting time to the management server <b>2</b>.</p><p id="p-0064" num="0063">In step <b>120</b> (S<b>120</b>), the image receiving unit <b>222</b> of the management server <b>2</b> outputs the image data received from the image transfer unit <b>328</b>, the position information of the shooting location, and the shooting time to the crime determination unit <b>224</b>.</p><p id="p-0065" num="0064">The crime determination unit <b>224</b> calculates the crime occurrence probability based on the image data received by the image reception unit <b>222</b>, the position information of the shooting location, and the shooting time.</p><p id="p-0066" num="0065">In step <b>125</b> (S<b>125</b>), the reporting unit <b>226</b> determines whether or not the crime occurrence probability calculated by the crime determination unit <b>224</b> is equal to or higher than the reference value; and when the crime occurrence probability is above the reference value, shifts to the processing S<b>130</b>, and when the crime occurrence probability is less than the reference value, shifts to the processing of S<b>135</b>.</p><p id="p-0067" num="0066">In step <b>130</b> (S<b>130</b>), the reporting unit <b>226</b> transmits the crime occurrence probability and the location information of the shooting location to the police, the security company, and the public hall.</p><p id="p-0068" num="0067">In step <b>135</b> (S<b>135</b>), the automatic driving unit <b>324</b> determines whether or not the vehicle has returned to the vicinity of the charger <b>4</b>; and if the vehicle returns to the vicinity of the charger <b>4</b> (S<b>135</b>: Yes), the automatic driving unit completes the automatic operation and instructs the camera control unit <b>326</b> to end the shooting. The camera control unit <b>326</b> ends the shooting by the camera <b>308</b> in response to the instruction from the automatic driving unit <b>324</b>.</p><p id="p-0069" num="0068">If the automatic driving unit <b>324</b> has not returned to the vicinity of the charger <b>4</b> (S<b>135</b>: No), the automatic driving unit <b>324</b> returns to the process of S<b>110</b> and continues the automatic operation.</p><p id="p-0070" num="0069">As described above, according to the security system <b>1</b> of the present embodiment, the occurrence of a crime is determined based on the image taken by the autonomous vehicle <b>3</b> shared by the local residents. As a result, it is possible to automatically patrol and monitor the flow lines of local residents. Especially in depopulated areas, it is not efficient to install fixed cameras for surveillance throughout the area.</p><p id="p-0071" num="0070">Furthermore, in such areas, public transportation tends to be in short supply, but as in this example, the means of transportation for the residents is secured by patrol monitoring with the autonomous vehicle <b>3</b> shared by the local residents. At the same time, it is possible to patrol and monitor the areas used by local residents during activity hours. Even if the number of vacant houses and abandoned cultivated land increases, it is possible to suppress unnecessary patrol monitoring of such areas.</p><p id="p-0072" num="0071">In the above embodiment, the mode of patrol monitoring using the autonomous vehicle <b>3</b> has been described, but the autonomous vehicle <b>3</b> may be replaced with a drone and patrol monitoring may be performed by a camera built in the drone. At that time, the drone monitors while delivering the package to the residents' homes or the like by, for example, automatic driving. Further, the autonomous vehicle <b>3</b> may patrol and monitor while delivering the luggage.</p><p id="p-0073" num="0072">In the above embodiment, the embodiment in which the autonomous vehicle <b>3</b> stands by in the vicinity of the charger <b>4</b> has been described; but the autonomous vehicle <b>3</b> may take pictures with a camera while predicting the use of the local residents based on the past usage history of the local residents, and patrolling the expected place, as in the case of a cruising taxi business.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An security system comprising:<claim-text>a plurality of autonomous vehicles;</claim-text><claim-text>a camera installed in each of said plurality of autonomous vehicles; and a processor coupled to each of said plurality of autonomous vehicles and processor configured to:</claim-text><claim-text>determine a crime based on an image taken by the camera.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The security system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the plurality of autonomous vehicles are shared vehicles shared by residents in the area; and the processor is further configured to:</claim-text><claim-text>determine a crime that may occur in the area.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The security system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the processor is configured to:<claim-text>in response to a request from the residents, the autonomous vehicle automatically picks up at the departure point of the residents and automatically moves to the destination of the residents;</claim-text><claim-text>the camera take pictures of the moving section to the starting point and the moving section from the starting point to the destination; and</claim-text><claim-text>determine a crime based on the images taken in the moving section to the departure point and the moving section from the starting point to the destination.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The security system according to <claim-ref idref="CLM-00003">claim 3</claim-ref> further comprising:<claim-text>a charger installed in a common facility in the area;</claim-text><claim-text>the plurality of automatic vehicles are electric vehicles, and the processor is further configured to:</claim-text><claim-text>charging in the vicinity of the charger, waiting until requested by the residents, and after taking the residents to their destination, returns to the vicinity of the charger;</claim-text><claim-text>the camera shots from the timing of departure from the vicinity of the charger to the time of returning to the vicinity of the charger, according to the request of the residents;</claim-text><claim-text>determine a crime based on the images taken from the vicinity of the charger to the return to the vicinity of the charger.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. An monitoring method comprising the steps of:<claim-text>moving an autonomous vehicle shared by the residents at the request of the residents;</claim-text><claim-text>photographing the outside of the vehicle by the camera installed in the autonomous vehicle; and</claim-text><claim-text>determine a crime based on the photographed image by a computer.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001930A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001930</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17455137</doc-number><date>20211116</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>IN</country><doc-number>202141029579</doc-number><date>20210701</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>W</subclass><main-group>40</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>W</subclass><main-group>50</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>W</subclass><main-group>50</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>50</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>40</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>50</main-group><subgroup>0098</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>50</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00838</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00369</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>50</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2040</main-group><subgroup>0809</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2040</main-group><subgroup>0872</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2040</main-group><subgroup>0881</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2050</main-group><subgroup>143</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2050</main-group><subgroup>146</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2540</main-group><subgroup>043</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2540</main-group><subgroup>221</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2540</main-group><subgroup>223</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2540</main-group><subgroup>227</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2556</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30196</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30268</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD AND SYSTEM FOR DRIVER POSTURE MONITORING</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Harman International Industries, Incorporated</orgname><address><city>Stamford</city><state>CT</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Moidunny</last-name><first-name>Jabir Kannathvalappil</first-name><address><city>Thrissur</city><country>IN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Various systems and methods are provided for determining a posture of an occupant of a vehicle. In one embodiment, a method comprises capturing images of an occupant in a vehicle via a vehicle camera, determining a current posture of the occupant and a recommended posture for the occupant based on the captured images and body measurements of the occupant, and outputting a guidance based on a difference between the current posture and the recommended posture. In this way, a comfort of the occupant may be increased by guiding the occupant toward a more ergonomic posture.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="67.73mm" wi="79.33mm" file="US20230001930A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="243.67mm" wi="131.49mm" orientation="landscape" file="US20230001930A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="260.01mm" wi="131.83mm" orientation="landscape" file="US20230001930A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="256.79mm" wi="163.58mm" file="US20230001930A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="261.87mm" wi="86.87mm" file="US20230001930A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="175.43mm" wi="162.98mm" file="US20230001930A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application claims priority to Indian Patent Application No. 202141029579, entitled &#x201c;METHOD AND SYSTEM FOR DRIVER POSTURE MONITORING&#x201d;, and filed on Jul. 1, 2021. The entire contents of the above-listed application is hereby incorporated by reference for all purposes.</p><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to a camera-based driver assistance system.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Driving posture may affect the health and comfort of an operator of a vehicle. However, it may be difficult for the operator to monitor their own posture while focusing on vehicle operation. As another example, different vehicle occupants, including different operators during different vehicle trips, may have different sizes, including height, weight, and proportions. Therefore, seat settings for one occupant may not facilitate optimal posture for another occupant, and it may be difficult for the occupant to find comfortable and ergonomic seat settings through manual adjustment (e.g., controlled by the occupant). Furthermore, a seat position that is optimal during a vehicle trip may not be optimal for entering or exiting the vehicle for the particular occupant, leading to discomfort or increased physical exertion.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">In various embodiments, the issues described above may be addressed by a method comprising capturing images of an occupant in a vehicle via a vehicle camera, determining a current posture of the occupant and a recommended posture for the occupant based on the captured images and body measurements of the occupant, and outputting a guidance based on a difference between the current posture and the recommended posture. As one example, the body measurements may be received via a user interface, measured via a vehicle sensor, and/or estimated based on the captured images. For example, a surface area and volume of the occupant may be estimated from depth and/or visible light information received from the vehicle camera, and the surface area and volume may be used to estimate a body mass index of the occupant. As another example, determining the current posture of the occupant may include determining a position of a seat in which the occupant is sitting, such as a seat angle, tilt, and longitudinal position, and determining a body position of the occupant relative to the seat, such as a distance from the occupant's head to a headrest of the seat. As a further example, determining the recommended posture may include determining a desired position of the seat and determining a desired body position of the occupant relative to the seat. For example, a computing system may compare the current posture of the occupant to the recommended posture and output the guidance as a message for the occupant to adjust their posture in response to a threshold (or significant) difference between the current posture of the occupant and the recommended posture or a message to maintain their current posture in response to a less than threshold (or insignificant) difference. In this way, a comfort of the occupant may be increased and a physical strain of the occupant may be decreased.</p><p id="p-0006" num="0005">It should be understood that the summary above is provided to introduce in simplified form a selection of concepts that are further described in the detailed description. It is not meant to identify key or essential features of the claimed subject matter, the scope of which is defined uniquely by the claims that follow the detailed description. Furthermore, the claimed subject matter is not limited to implementations that solve any disadvantages noted above or in any part of this disclosure.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0007" num="0006">The disclosure may be better understood from reading the following description of non-limiting embodiments, with reference to the attached drawings, wherein below:</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>1</b></figref> systematically shows a vehicle system, according to one or more embodiments of the present disclosure;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a block diagram of a flow of data during occupant posture detection and recommendation, according to one or more embodiments of the present disclosure;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a flow chart of a method for determining occupant posture, according to one or more embodiments;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example of a recommended driving posture, according to one or more embodiments of the present disclosure;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a first example of an incorrect driving posture, according to one or more embodiments of the present disclosure;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a second example of an incorrect driving posture, according to one or more embodiments of the present disclosure; and</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows a flow chart of a method for automatically adjusting a seat position during vehicle ingress or egress, according to one or more embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0015" num="0014">The following description relates to systems and methods to increase vehicle occupant comfort via a driver monitoring system. The driver monitoring system may include a camera mounted in a vehicle, such as the vehicle shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. A computing system may process and analyze images received from the camera to determine a posture of the occupant, such as a driver (e.g., operator) or a passenger of the vehicle, and guide posture corrections, such as according to the data flow block diagram shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As an example, the computing system may receive images acquired by the camera as well as body measurement data of the occupant. The computing system may use image and data processing resources included in an in-vehicle processing system, a mobile processing system, or a networked processing system (e.g., cloud computing) to identify suitable posture choices, which may be output via a user interface, such as according to the method of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref> show various measurements and relationships between the driver, a seat, and a steering wheel that the computing system may analyze in determining the posture of the driver. In particular, an exemplary recommended posture is shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, while <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref> provide examples of incorrect driver posture that may lead to driver discomfort or fatigue. A flow chart of a method for automatically adjusting a seat position to facilitate ingress or egress is shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, which may use the images and body measurement data analyzed in the method of <figref idref="DRAWINGS">FIG. <b>3</b></figref> to personalize the seat position for each unique vehicle occupant. In this way, driver and passenger comfort may be increased from vehicle entry to vehicle exit and with minimal input from the occupants.</p><p id="p-0016" num="0015">Turning now to the figures, <figref idref="DRAWINGS">FIG. <b>1</b></figref> schematically shows an exemplary vehicle <b>100</b>. The vehicle <b>100</b> includes a dashboard <b>102</b>, a driver seat <b>104</b>, a first passenger seat <b>106</b>, a second passenger seat <b>108</b>, and a third passenger seat <b>110</b>. In other examples, the vehicle <b>100</b> may include more or fewer passenger seats. The driver seat <b>104</b> and the first passenger seat <b>106</b> are located in a front of the vehicle, proximate to the dashboard <b>102</b>, and therefore may be referred to as front seats. The second passenger seat <b>108</b> and the third passenger seat <b>110</b> are located at a rear of the vehicle and may be referred to as back (or rear) seats. Additionally, the vehicle <b>100</b> includes a plurality of integrated speakers <b>114</b>, which may be arranged around a periphery of the vehicle <b>100</b>. In some embodiments, the integrated speakers <b>114</b> are electronically coupled to an electronic control system of the vehicle, such as to a computing system <b>120</b>, via a wired connection. In other embodiments, the integrated speakers <b>114</b> may wirelessly communicate with the computing system <b>120</b>. As an example, an audio file may be selected by an occupant of the vehicle <b>100</b>, such as a driver passenger, via a user interface <b>116</b>, and the selected audio file may be projected via the integrated speakers <b>114</b>. In some examples, audio alerts may be generated by the computing system <b>120</b> and also may be projected by the integrated speakers <b>114</b>, such as will be elaborated herein.</p><p id="p-0017" num="0016">The vehicle <b>100</b> further includes a steering wheel <b>112</b> and a steering column <b>122</b>, through which the driver may input steering commands for the vehicle <b>100</b>. The steering column <b>122</b> may be adjustable so that the driver may change a height and/or tilt of the steering wheel <b>112</b> by adjusting the steering column <b>122</b>. In some examples, the steering column <b>122</b> may be adjusted by the driver disengaging a lever or lock on the steering column <b>122</b> and manually moving the steering column <b>122</b> and/or steering wheel <b>112</b> to adjust the height and/or tilt of the steering wheel <b>112</b>. In other examples, the position of the steering column <b>122</b> and the steering wheel <b>112</b> may be adjusted via an electric motor integrated within the steering column <b>122</b>. The driver may input adjustments to the electric motor, such as via an interface (e.g., a button or switch) positioned on the steering column <b>122</b>, or the computing system <b>120</b> may actuate the electric motor to adjust the position of the steering column <b>122</b> and the steering wheel <b>112</b> based on a stored setting for the driver.</p><p id="p-0018" num="0017">The vehicle <b>100</b> further includes a camera <b>118</b>. The camera <b>118</b> may be included in a driver monitoring system (e.g., a driver attention monitor). In the embodiment shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the camera <b>118</b> is positioned to the side of the driver seat <b>104</b>, which may aid in monitoring the driver in profile. However, in other examples, the camera <b>118</b> may be positioned in other locations in the vehicle, such as on the steering column <b>122</b> and directly in front of the driver seat <b>104</b>. The camera <b>118</b> may include one or more optical (e.g., visible light) cameras, one or more infrared (IR) cameras, or a combination of optical and IR cameras having one or more view angles. In some examples, the camera <b>118</b> may have interior view angles as well as exterior view angles. In some examples, the camera <b>118</b> may include more than one lens and more than one image sensor. For example, the camera <b>118</b> may include a first lens that directs light to a first, visible light image sensor (e.g., a charge-coupled device or a metal-oxide-semiconductor) and a second lens that directs light to a second, thermal imaging sensor (e.g., a focal plane array), enabling the camera <b>118</b> to collect light of different wavelength ranges for producing both visible and thermal images. In some examples, the camera <b>118</b> may further include a depth camera and/or sensor, such as a time-of-flight camera or a LiDAR sensor.</p><p id="p-0019" num="0018">In some examples, the camera <b>118</b> may be a digital camera configured to acquire a series of images (e.g., frames) at a programmable frequency (e.g., frame rate) and may be electronically and/or communicatively coupled to the computing system <b>120</b>. Further, the camera <b>118</b> may output acquired images to the computing system <b>120</b> in real-time so that they may be processed in real-time by the computing system <b>120</b> and/or a computer network, as will be elaborated herein with particular respect to <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>6</b></figref>. As used herein, the term &#x201c;real-time&#x201d; denotes a process that occurs instantaneously and without intentional delay. &#x201c;Real-time&#x201d; may refer to a response time of less than or equal to about 1 second, for example. In some examples, &#x201c;real-time&#x201d; may refer to simultaneous or substantially simultaneous processing, detection, or identification. Further, in some examples, the camera <b>118</b> may be calibrated with respect to a world coordinate system (e.g., world space x, y, z).</p><p id="p-0020" num="0019">The vehicle <b>100</b> may further include a driver seat sensor <b>124</b> coupled to or within the driver seat <b>104</b> and a passenger seat sensor <b>126</b> coupled to or within the first passenger seat <b>106</b>. The back seats may also include seat sensors, such as a passenger seat sensor <b>128</b> coupled to the second passenger seat <b>108</b> and a passenger seat sensor <b>130</b> coupled to the third passenger seat <b>110</b>. The driver seat sensor <b>124</b> and the passenger seat sensor <b>126</b> may each include one or a plurality of sensors, such as a weight sensor, a pressure sensor, and one or more seat position sensors that output a measurement signal to the computing system <b>120</b>. For example, the output of the weight sensor or pressure sensor may be used by the computing system <b>120</b> to determine whether or not the respective seat is occupied, and if occupied, a weight of a person occupying the seat. As another example, the output of the one or more seat position sensors may be used by the computing system <b>120</b> to determine one or more of a seat height, a longitudinal position with respect to the dashboard <b>102</b> and the back seats, and an angle (e.g., tilt) of a seat back of the corresponding seat. In other examples, the seat position may be additionally or alternatively determined based on images acquired by the camera <b>118</b>, such as will be elaborated herein.</p><p id="p-0021" num="0020">In some examples, the vehicle <b>100</b> further includes a driver seat motor <b>134</b> coupled to or positioned within the driver seat <b>104</b> and a passenger seat motor <b>138</b> coupled to or positioned within the first passenger seat <b>106</b>. Although not shown, in some embodiments, the back seats may also include seat motors. The driver seat motor <b>134</b> may be used to adjust the seat position, including the seat height, the longitudinal seat position, and the angle of the seat back of the driver seat <b>104</b> and may include an adjustment input <b>136</b>. For example, the adjustment input <b>136</b> may include one or more toggles, buttons, and switches. The driver may input desired driver seat position adjustments to the driver seat motor <b>134</b> via the adjustment input <b>136</b>, and the driver seat motor <b>134</b> may move the driver seat <b>104</b> accordingly in substantially real-time. In other examples, the driver seat motor <b>134</b> may adjust the driver seat position based on inputs received from the computing system <b>120</b>, such as will be described with respect to <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The passenger seat motor <b>138</b> may adjust a seat position of the passenger seat <b>106</b> based on inputs received from an adjustment input <b>140</b> and/or based on inputs received from the computing system <b>120</b> in an analogous manner. Further, in some examples, the computing system <b>120</b> may determine the seat position of the corresponding seat based on feedback from the driver seat motor <b>134</b> and the passenger seat motor <b>138</b>. Although not shown, in some embodiments, the back seats may be adjustable in a similar manner.</p><p id="p-0022" num="0021">The computing system <b>120</b> may receive inputs via the user interface <b>116</b> as well as output information to the user interface <b>116</b>. The user interface <b>116</b> may be included in a digital cockpit or advanced driver assistance system (ADAS), for example, and may include a display and one or more input devices. The one or more input devices may include one or more touchscreens, knobs, dials, hard buttons, and soft buttons for receiving user input from a vehicle occupant.</p><p id="p-0023" num="0022">The computing system <b>120</b> includes a processor <b>142</b> configured to execute machine readable instructions stored in a memory <b>144</b>. The processor <b>142</b> may be single core or multi-core, and the programs executed by processor <b>142</b> may be configured for parallel or distributed processing. In some embodiments, the processor <b>142</b> is a microcontroller. The processor <b>142</b> may optionally include individual components that are distributed throughout two or more devices, which may be remotely located and/or configured for coordinated processing. In some embodiments, one or more aspects of the processor <b>142</b> may be virtualized and executed by remotely-accessible networked computing devices configured in a cloud computing configuration. For example, the computing system <b>120</b> may be communicatively coupled with a wireless network <b>132</b> via a transceiver <b>146</b>, and the computing system <b>120</b> may communicate with the networked computing devices via the wireless network <b>132</b>. Additionally or alternatively, the computing system <b>120</b> may directly communicate with the networked computing devices via short-range communication protocols, such as Bluetooth&#xae;. In some embodiments, the computing system <b>120</b> may include other electronic components capable of carrying out processing functions, such as a digital signal processor, a field-programmable gate array (FPGA), or a graphic board. In some embodiments, the processor <b>142</b> may include multiple electronic components capable of carrying out processing functions. For example, the processor <b>142</b> may include two or more electronic components selected from a plurality of possible electronic components, including a central processor, a digital signal processor, a field-programmable gate array, and a graphics board. In still further embodiments, the processor <b>142</b> may be configured as a graphical processing unit (GPU), including parallel computing architecture and parallel processing capabilities.</p><p id="p-0024" num="0023">Further, the memory <b>144</b> may include any non-transitory tangible computer readable medium in which programming instructions are stored. As used herein, the term &#x201c;tangible computer readable medium&#x201d; is expressly defined to include any type of computer readable storage. The example methods described herein may be implemented using coded instruction (e.g., computer readable instructions) stored on a non-transitory computer readable medium such as a flash memory, a read-only memory (ROM), a random-access memory (RAM), a cache, or any other storage media in which information is stored for any duration (e.g. for extended period time periods, permanently, brief instances, for temporarily buffering, and/or for caching of the information). Computer memory of computer readable storage mediums as referenced herein may include volatile and non-volatile or removable and non-removable media for a storage of electronically formatted information, such as computer readable program instructions or modules of computer readable program instructions, data, etc. that may be stand-alone or as part of a computing device. Examples of computer memory may include any other medium which can be used to store the desired electronic format of information and which can be accessed by the processor or processors or at least a portion of a computing device. In various embodiments, the memory <b>144</b> may include an SD memory card, an internal and/or external hard disk, USB memory device, or a similar modular memory.</p><p id="p-0025" num="0024">Further still, in some examples, the computing system <b>120</b> may include a plurality of sub-systems or modules tasks with performing specific functions related to performing image acquisition and analysis. As used herein, the terms &#x201c;system,&#x201d; &#x201c;unit,&#x201d; or &#x201c;module&#x201d; may include a hardware and/or software system that operates to perform one or more functions. For example, a module, unit, or system may include a computer processor, controller, or other logic-based device that performs operations based on instructions stored on a tangible and non-transitory computer readable storage medium, such as a computer memory. Alternatively, a module, unit, or system may include a hard-wired device that performs operations based on hard-wired logic of the device. Various modules or units shown in the attached figures may represent the hardware that operates based on software or hardwired instructions, the software that directs hardware to perform the operations, or a combination thereof.</p><p id="p-0026" num="0025">&#x201c;Systems,&#x201d; &#x201c;units,&#x201d; or &#x201c;modules&#x201d; may include or represent hardware and associated instructions (e.g., software stored on a tangible and non-transitory computer readable storage medium) that perform one or more operations described herein. The hardware may include electronic circuits that include and/or are connected to one or more logic-based devices, such as microprocessors, processors, controllers, or the like. These devices may be off-the-shelf devices that are appropriately programmed or instructed to perform operations described herein from the instructions described above. Additionally or alternatively, one or more of these devices may be hard-wired with logic circuits to perform these operations. For example, as will be elaborated herein with respect to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the computing system <b>120</b> may determine an occupant posture based on the images received from the camera <b>118</b>, determine a desired (e.g., recommended) occupant posture based on body measurements, and output an alert in response to the occupant posture not matching the recommended occupant posture.</p><p id="p-0027" num="0026">A data flow between various devices in performing the occupant posture guidance will now be described. Turning to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a block diagram of an example data flow <b>200</b> is shown. A camera <b>218</b> provides image data to a computing system <b>220</b>. The camera <b>218</b> may be similar to, or the same as, the camera <b>118</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and the computing system <b>220</b> may be similar to, or the same as, the computing system <b>120</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The computing system <b>220</b> includes an image acquisition module <b>232</b>, an image analysis module <b>234</b>, and an advanced driver assistance system (ADAS) module <b>236</b>. The image acquisition module <b>232</b> may send and receive data with the camera <b>218</b>. For example, the image acquisition module <b>232</b> may control acquisition settings of the camera <b>218</b>, such as aperture, light sensitivity, focal depth, field of view, shutter speed, frame rate, etc. In some examples, the camera <b>218</b> may operate at a frame rate in a range between 4-24 frames per second to substantially continuously capture images of a vehicle interior. In other examples, the frame rate may be lower, such as one frame per second or per multiple seconds (e.g., 30-60 seconds), or higher (e.g., 30 frames per second). As one example, the frame rate may be selected based on a processing speed of the image analysis module <b>234</b> so that each image may be fully analyzed before the image analysis module <b>234</b> receives a next image in the sequence.</p><p id="p-0028" num="0027">Further, the image acquisition module <b>232</b> may update the acquisition settings of the camera <b>218</b> based on feedback received from the image analysis module <b>234</b>. For example, the image analysis module <b>234</b> may determine that the images acquired by the camera <b>218</b> are too dark and update one or more of the aperture, the light sensitivity, and the shutter speed at the image acquisition module <b>232</b> accordingly.</p><p id="p-0029" num="0028">The image analysis module <b>234</b> may access images/videos (e.g., an image library) stored in memory and analyze the images received from the camera <b>218</b> in real-time to identify one or more features within each of the received image. As one example, the image analysis module <b>234</b> may compare a real-time image received from the camera <b>218</b> to one stored in memory to identify occupants within the vehicle interior, including a driver and/or a non-driver occupant (e.g., passenger). Additionally or alternatively, the image analysis module <b>234</b> may use a computer vision model or algorithm to identify the driver and/or non-driver occupant. In some examples, the image analysis module <b>234</b> may further analyze the image, such as using a biometric algorithm that performs facial recognition, to positively identify the occupant(s). As an illustrative example, the biometric algorithm may compare a face of the driver to identification photos of all known drivers of the vehicle to positively identify the driver. Further, the computing system <b>220</b> may store user-specific settings and information, including ingress and egress seat settings associated with each known/repeated vehicle occupant, in memory, such as will be elaborated herein with respect to <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>7</b></figref>.</p><p id="p-0030" num="0029">In some examples, the image analysis module <b>234</b> may construct a model of each occupant that includes skeletal tracking. The skeletal tracking may identify various skeletal joints of the occupant (e.g., the driver or the passenger), which may correspond to actual joints of the occupant, centroids of various anatomical structures, terminal ends of the occupant's extremities, and/or points without a direct anatomical link within the occupant (e.g., not corresponding to a particular anatomical structure), and map a simplified virtual skeleton onto the occupant. As each joint of the occupant has at least three degrees of freedom (e.g., world space x, y, z), each joint of the virtual skeleton used for the skeletal tracking may be defined with a three-dimensional (3D) position, and changes in that 3D position may denote movement. In some examples, each joint of the virtual skeleton may also be defined with respect to rotational angle within the 3D world space and with respect to a centerline of the virtual skeleton. In some examples, the image analysis module <b>234</b> may use depth and/or visible light information acquired by the camera <b>218</b> to define an envelope of the occupant (e.g., the surface area and volume of the occupant), which in turn may be used to approximate a size of the occupant (e.g., a body mass index, height, etc.). As will be elaborated herein and illustrated with respect to <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref>, the virtual skeleton may be used to determine limb lengths and joint angles. The limb lengths and joint angles may be used by the image analysis module <b>234</b>, alone or in combination with the envelope, to determine a 3D posture estimation as well as a recommended (e.g., desired) posture for the particular occupant that will increase comfort and/or health given the size and limb lengths of the individual. Additional details will be described below with respect to <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0031" num="0030">In some examples, the computing system <b>220</b> may receive body measurement inputs from the occupant(s) in addition to or as an alternative to determining the envelope. For example, the ADAS module <b>236</b> may prompt the occupant to input height and weight measurements via a user interface <b>216</b>, which may be similar to, or the same as, the user interface <b>116</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In particular, the height and weight measurements may be received via an input device <b>240</b>, and the ADAS module <b>236</b> may share the received information with the image analysis module <b>234</b>. In some examples, the user interface <b>216</b> may be included in a smartphone (or tablet, smartwatch, etc.), and the smartphone may run a companion application that interfaces with the ADAS module <b>236</b> of the in-vehicle computing system <b>220</b> to receive inputs from the occupant and provide alert outputs.</p><p id="p-0032" num="0031">In some examples, the computing system <b>220</b> may additionally or alternatively receive occupant weight measurements from seat sensors. For example, a driver seat sensor (e.g., the driver seat sensor <b>124</b>) may output a driver weight measurement to the computing system <b>220</b>, and the weight measurement may be used by the image analysis module <b>234</b>, alone or in combination with the images from the camera <b>218</b> and/or the measurements received via the input device <b>240</b>, to determine body measurements of the driver.</p><p id="p-0033" num="0032">Further, it may be understood that in some examples, the image analysis module <b>234</b> may be included in the in-vehicle computing system <b>220</b> or accessed via a user-provided mobile computing system, such as a smartphone, computer, or tablet. As another example, the image analysis module <b>234</b> may be included via a networked computing system such as a cloud computer or a similar computing environment and accessed remotely (e.g., via a wireless network, such as the wireless network <b>132</b> shown in <figref idref="DRAWINGS">FIG. <b>0</b>.<b>1</b></figref>). As such, although the image analysis module <b>234</b> is shown within the computing system <b>220</b> in the example shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in other embodiments, at least portions of the image analysis module <b>234</b> may be stored in computing devices and/or networks outside of the computing system <b>220</b> that are communicatively coupled to the computing system <b>220</b>.</p><p id="p-0034" num="0033">Once the computing system <b>220</b> detects considerable difference between the 3D posture estimation and the recommended posture, the computing system <b>220</b> may notify the occupant using the user interface <b>216</b>. As one example, the ADAS module <b>236</b> may interface with the user interface <b>216</b> to output an alert via a display <b>238</b> and/or speakers <b>214</b>. The speakers <b>214</b> may be in-vehicle speakers, such as the integrated speakers <b>114</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, or speakers of the smartphone running the companion app. Similarly, the display <b>238</b> may be integrated in the vehicle or may be a display of the smartphone running the companion app. For example, the display <b>238</b> may output alert messages/symbols, and the speakers <b>214</b> may play alert sounds/prompts. The display <b>238</b> and/or the speakers <b>214</b> may also communicate a recommended sitting posture.</p><p id="p-0035" num="0034">A method for performing the data flow of <figref idref="DRAWINGS">FIG. <b>2</b></figref> will now be described. Turning to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, an example method <b>300</b> for determining a posture of a vehicle occupant and outputting postural guidance alerts is shown. The method <b>300</b> may be executed by a processor of a computing system (e.g., the computing system <b>120</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or the computing system <b>220</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>) based on instructions stored on a memory of the computing system (e.g., the memory <b>144</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>). The method <b>300</b> will be described with regard to the systems and components of <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>2</b></figref>; however, it may be understood that the method may be implemented with other systems and components without departing from the scope of the present disclosure. For clarity, the method <b>300</b> will be described with respect to one occupant, which may be a driver or a passenger of the vehicle, although the method <b>300</b> may be used to determine the posture of more than one occupant at the same time.</p><p id="p-0036" num="0035">In some examples, the method <b>300</b> may be executed in response to a new occupant being detected and/or in response to the occupant adjusting their seat. As another example, additionally or alternatively, the method <b>300</b> may be executed at a pre-determined frequency during vehicle operation, such as every 10 minutes, every 30 minutes, every 60 minutes, etc. In some examples, a user may select or adjust the pre-determined frequency. Further, in some examples, the method <b>300</b> may be temporarily disabled (e.g., automatically or by the occupant) and/or modified during poor visibility (e.g., fog, heavy rain, snow) or poor road conditions (e.g., slick, icy, or bumpy) while the vehicle is operating at a non-zero speed, as will be elaborated below.</p><p id="p-0037" num="0036">At <b>302</b>, the method <b>300</b> includes receiving images from a camera. As described above with respect to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the camera may include one or more optical, infrared, and depth cameras and may include one or more view angles for capturing images. Further, the camera may capture a sequence of images at a pre-programmed frequency, such as a frequency in a range from 8-24 frames per second. Alternatively, the pre-programmed frequency may be greater than 24 frames per second or less than 8 frames per second. The computing system may receive the images captured by the camera as they are acquired via wired or wireless communication methods, such as Ethernet, USB, Bluetooth&#xae;, and WiFi.</p><p id="p-0038" num="0037">At <b>304</b>, the method <b>300</b> includes analyzing the images received from the camera to determine occupant posture. As described above with respect to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the computing system may include an image analysis module (e.g., the image analysis module <b>234</b>) that analyzes the images received from the camera in real-time to identify one or more features of the occupant in each of the received images. For example, the image analysis module may use one or any combination of an image library, a model, and an algorithm for recognizing the vehicle occupant as well as interior features of the vehicle, such as a seat the occupant is sitting in, a steering wheel, etc. As one example, the computing system may distinguish the driver from one or more additional vehicle occupants based on the location of the driver relative to the steering wheel.</p><p id="p-0039" num="0038">In some embodiments, the computing system may perform facial recognition (e.g., via a biometric algorithm) to determine an identity of the occupant. For example, the identity may include a name or user identification number that is associated with previously received/measured/estimated body measurements, recommended postures, seat settings, or other preferences. When the occupant is unknown, such as when the occupant has not been previously identified, the computing system may create a new user identification number and store images of the occupant for future facial recognition.</p><p id="p-0040" num="0039">Analyzing the images received from the camera to determine occupant posture includes determining occupant body measurements, as indicated at <b>306</b>. The body measurements may include, but are not limited to, an arm length, a foot length or shoe size, a thigh length, a height, a neck length, and a waist circumference, a weight, and a body mass index (BMI). In some examples, the occupant inputs at least one of the body measurements via a user interface (e.g., the user interface <b>116</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or the user interface <b>216</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The user interface may be integrated in the vehicle or may be included in a mobile device (e.g., a smartphone, tablet, or smartwatch) that is running a companion application and is in communication with the computing system. For example, the user interface may prompt the occupant to enter and/or update body measurements at a pre-determined frequency (e.g., once a month) or when a new occupant is detected. As another example, additionally or alternatively, the computing system may receive information regarding at least one of the occupant body measurements from an in-vehicle sensor, such as a weight sensor positioned in the seat (e.g., the driver seat sensor <b>124</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>).</p><p id="p-0041" num="0040">Additionally or alternatively, the computing system may estimate at least one of the body measurements based on the received images. For example, depth and/or visible light information acquired by the camera may be used to define a surface area and/or volume of the occupant, which in turn may be used to determine the various body measurements. Further, skeletal tracking may be used to identify joints (e.g., joint angles) and limb lengths. As described above with respect to <figref idref="DRAWINGS">FIG. <b>2</b></figref> and as will be illustrated in <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref>, the computing system may model a virtual skeleton of the occupant to determine joint angles and limb lengths.</p><p id="p-0042" num="0041">Analyzing the images received from the camera to determine occupant posture includes determining a seat position, as indicated at <b>308</b>. The seat position may include, for example, a seat height, a seat angle (e.g., of a seat back relative to a seat cushion), a seat tilt (e.g., of the seat cushion), and a longitudinal seat position. For example, the computing system may identify the seat, including the seat back, the seat cushion, and a headrest, via a computer vision or image recognition algorithm and geometrically analyze the seat back relative to the seat cushion, the seat relative to the dashboard, etc. to determine the seat position. Additionally or alternatively, the computing system may determine the seat position based on an output of a seat position sensor and/or based on feedback from (or a setting of) a seat motor.</p><p id="p-0043" num="0042">When the occupant is the driver, analyzing the images received from the camera to determine occupant posture includes determining a steering wheel position, as optionally indicated at <b>310</b>. The steering wheel position may include a steering wheel height and tilt angle, for example. The computing system may identify the steering wheel via a computer vision or image recognition algorithm and geometrically analyze the steering wheel relative to the dashboard, relative to a ceiling of the vehicle, relative to a floor of the vehicle, etc. to determine the steering wheel position. Additionally or alternatively, the computing system may determine the steering wheel position based on feedback from (or a setting of) an electronic motor within a steering column that is used to adjust the position of the steering wheel.</p><p id="p-0044" num="0043">Analyzing the images received from the camera to determine occupant posture includes determining the occupant's body position relative to the seat, as indicated at <b>312</b>. For example, the occupant's body position relative to the seat may include a distance between the occupant's head and the headrest, a distance between the occupant's shoulders relative to the seat back, a distance between the occupant's hips relative to the seat back and seat cushion, and a distance between the occupant's knees and the seat cushion. The distance for each of the above examples may be zero or non-zero. An example where the distance between the occupant's head and the headrest is zero will be described with respect to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, while examples where the distance between the occupant's head and the headrest is non-zero will be described with respect to <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>. Further, the computing device may estimate the various distances described above according to a real world measurement scale (e.g., inches), a pixel-based scale, or another measurement scale that enables the computing device to compare distances from image to image. For example, the computing system may use an edge detection algorithm to determine a first boundary of the driver's head and a second boundary of the headrest and then determine a number of pixels in a shortest path directly between the first boundary and the second boundary.</p><p id="p-0045" num="0044">When the occupant is the driver, analyzing the images received from the camera to determine occupant posture further includes determining the occupant's body position relative to the steering wheel, as optionally indicated at <b>314</b>. For example, the occupant's body position relative to the steering wheel may include a clearance distance between the steering wheel and the torso, a clearance between the steering wheel and the thigh, etc. As an example, the computing system may use an edge detection algorithm to determine a first boundary of the steering wheel and a second boundary of the driver's torso and then determine a distance (e.g., in a real-world measurement unit, a number of pixels, or another measurement scale) in a shortest path directly between the first boundary and the second boundary.</p><p id="p-0046" num="0045">At <b>316</b>, the method <b>300</b> includes determining a recommended posture based on the body measurements of the occupant. The computing system may use these body measurements to deduce the recommended sitting posture according to posture recommendations that are stored in memory. For example, the posture recommendations may apply a plurality of body component-specific rules for ergonomic and effective vehicle operation that may be adaptable to a wide variety of body measurements. The posture recommendations may include, but are not limited to, a threshold seat angle range, a threshold clearance distance between the steering wheel and the torso, a threshold clearance between the steering wheel and the thigh, a threshold distance between the head and the headrest, a threshold knee angle range, a threshold hip angle range, a threshold elbow angle range, etc. For example, the computing system may input the body measurements of the occupant into one or more look-up tables or algorithms, which may output the specific posture recommendations for the given body measurements. As one example, the threshold clearance distance between the steering wheel and the torso may be larger for individuals having longer limbs (e.g., longer arms and/or legs) than individuals having shorter limbs. As another example, the threshold distance between the head and the headrest may be the same regardless of body measurements. The look-up table(s) or algorithm(s) may further output a recommended seat position and a recommended steering wheel position that will produce the recommended posture according to the posture recommendations for the given body measurements. Further, in some examples, the posture recommendations may undergo machine learning so that the plurality of body component-specific rules may be updated or refined according to data gathered for the specific occupant or similarly sized occupants.</p><p id="p-0047" num="0046">Further, in some examples, the occupant may input physical limitations that may affect their posture. As one example, the occupant may have a disability or degenerative condition that renders them unable to sit according to the standard body component-specific rules. As such, the computing system may adjust the plurality of body component-specific rules for the given occupant based on the input physical limitations. As an illustrative example, the occupant may have a permanent spinal curvature that may restrict their ability to sit with their shoulders and head back. As such, the occupant may activate accessibility settings and input information regarding a back range of motion.</p><p id="p-0048" num="0047">In some examples, the computing system may further take into account driving conditions, including weather conditions, terrain conditions, a length of time of a current vehicle trip, etc. For example, the plurality of body component-specific rules may be adjusted or relaxed during poor driving conditions so that the occupant, particularly when the occupant is the driver, may have a greater range of movement within the recommended posture. For example, during poor visibility conditions, the driver may instinctively angle their body forward (e.g., toward the steering wheel). As another example, the plurality of body component-specific rules may be less relaxed during a long trip to prevent fatigue.</p><p id="p-0049" num="0048">At <b>318</b>, the method <b>300</b> includes determining a postural difference between the recommended posture and the determined occupant posture. For example, the computing system may compare the actual sitting posture determined from the images from the camera and the recommended posture determined from the body measurements by comparing each specific posture recommendation to the determined posture. That is, the actual seat position may be compared to the recommended seat position, an actual elbow angle of the occupant may be compared to the threshold elbow angle range, etc. In some examples, the computing system may differently weight each posture component (e.g., seat position, steering wheel position, elbow angle, hip angle, various clearance distances) according to its posture contribution. For example, because the seat position may some or all of the various clearance distances and joint angles, the seat position may be more heavily weighted in the comparison, and so smaller differences in the seat position (e.g., one or more of the seat angle, seat height, and longitudinal position) may have a larger impact in determining if the postural difference is significant, as will be described below. As such, the postural difference may include a weighted sum, at least in some examples.</p><p id="p-0050" num="0049">At <b>320</b>, the method <b>300</b> includes determining if the postural difference is significant. A level of significance in the postural difference may be inferred using statistical analysis, such as common thumb rules. In some examples, the computing system may consider the body mass index as an additional factor in the inferencing. For example, an overweight body mass index may adversely affect postural dynamics and hence, even minor postural differences may be considered significant for such persons.</p><p id="p-0051" num="0050">Additionally or alternatively, the method may include determining if the postural difference is greater than or equal to a threshold postural difference, such as by summing or tabulating a magnitude difference or a percentage difference of all of the deviations between the occupant posture and the recommended posture and comparing the sum to the threshold postural difference. The threshold postural difference may be a non-zero magnitude difference or percentage difference that is stored in memory that corresponds to a significant postural difference, for example. As mentioned above, some posture components may be weighted more heavily in the determination.</p><p id="p-0052" num="0051">If the postural difference significant (e.g., statistically significant) or is greater than or equal to the threshold difference, the method <b>300</b> proceeds to <b>322</b> and includes outputting a postural guidance alert to adjust posture. For example, the user interface may output a visual (e.g., via a display) and/or audible (e.g., via speakers) postural guidance alert to adjust posture. As one example, the postural guidance alert may include a recommendation that the occupant adjust their posture. As another example, the postural guidance alert may include instructions for posture adjustments that are likely to result in the recommend posture. For example, the postural guidance alert may include messages such as &#x201c;increase set incline&#x201d; when the seat angle is too far reclined or &#x201c;position head against headrest&#x201d; when the distance between the occupant's head and the headrest is greater than the threshold distance. As still another example, additionally or alternatively, the postural guidance alert may include haptic feedback given via the seat or the steering wheel.</p><p id="p-0053" num="0052">If the postural difference is not significant or is less than the threshold difference, the method <b>300</b> proceeds to <b>324</b> and includes outputting a postural guidance alert to maintain posture. For example, because the occupant posture is determined to be substantially the same as the recommended posture when the postural difference is not significant, the occupant may be encouraged to maintain their current posture. In some examples, the user interface may output a symbol or other message, such as a green check mark next to a posture item on a display or a chime output via the speakers, to inform the occupant that they are sitting in the recommended posture and to maintain their current posture. However, in other examples, the user interface may not output any visual or audible message regarding the occupant posture when the postural difference is not significant, and the message to maintain posture may be implied based on the absence of posture changing guidance.</p><p id="p-0054" num="0053">At <b>326</b>, the method <b>300</b> includes determining a seat position for ingress (e.g., entering the vehicle) and a seat position for egress (e.g., exiting the vehicle) based on the body measurements of the occupant. For example, it may be desirable to change the seat angle, the seat tilt, and the seat longitudinal position to make it easier to enter or exit the vehicle. As one example, the longitudinal position may be further back for an occupant with a longer leg length and/or larger BMI compared with the longitudinal position for an occupant with a shorter leg length and/or smaller BMI. In some examples, the seat position for ingress is the same as the seat position for egress, while in other examples, the seat positions may be different for ingress and egress. The determined seat position for ingress and the determined seat position for egress may be stored in the memory of the computing system for recall during ingress/egress, as will be elaborated below with respect to <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The method <b>300</b> may then end.</p><p id="p-0055" num="0054">Exemplary parameters or components that may be used by a computing system (e.g., the computing system <b>120</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or the computing system <b>220</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>) in determining a driver posture will now be described with reference to <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref>. Features of <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref> that are the same throughout the different driver postures are numbered the same and will not be reintroduced between figures, while parameters (e.g., angles and distances) that change between the different driver postures are numbered differently, as will be elaborated below. For example, each of <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref> illustrates a side view of a driver <b>402</b> sitting in a driver seat <b>404</b>, which may be the driver seat <b>104</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, for example. The driver seat <b>404</b> includes a headrest <b>404</b><i>a</i>, a seat back <b>404</b><i>b</i>, and a seat cushion <b>404</b><i>c</i>. The seat back <b>404</b><i>b </i>has a length <b>406</b>, and the seat cushion <b>404</b><i>c </i>has a length <b>410</b>. Further, the driver seat <b>404</b> is coupled to a floor of the vehicle (not shown) via a seat base <b>440</b>. The seat base <b>440</b> is fixedly coupled (e.g., bolted) to the floor of the vehicle and does not move with respect to the floor of the vehicle. However, the driver seat <b>404</b> may move relative to the seat base. For example, a vertical position (e.g., seat height) and a longitudinal position (e.g., how forward or back the seat is with respect to the front and back of the vehicle) of the driver seat <b>404</b> may be adjusted with respect to the seat base <b>440</b>. Each of <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref> further includes a steering wheel <b>412</b>, which may be the steering wheel <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, for example, and a pedal <b>444</b>, which may represent an accelerator pedal, a brake pedal, or a clutch.</p><p id="p-0056" num="0055">A virtual skeleton <b>408</b> is mapped onto (e.g., overlaid on) the driver <b>402</b> and includes nodes representing joints and dashed lines representing the general connectivity of the joints. In the example shown, the virtual skeleton <b>408</b> maps ankle, knee, hip, wrist, elbow, shoulder, and neck joints. The virtual skeleton <b>408</b> may be used by the computing system to aid in determining the driver posture, such as described above with respect to <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>. For example, the virtual skeleton <b>408</b>, and thus the driver <b>402</b>, has a torso length <b>418</b> extending between the neck joint and a midpoint between hip joints (e.g., at a pelvis), an upper leg (e.g., thigh) length <b>420</b> extending between the hip joint and the knee joint, a lower leg (e.g., shin) length <b>424</b> extending between the ankle joint and the knee joint, an upper arm length <b>428</b> extending between the shoulder joint and the elbow joint, and a lower arm length <b>430</b> extending between the elbow joint and the wrist joint. Although not shown in <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref>, other body measurements may also be estimated, such as an angle of a head <b>416</b> of the driver <b>402</b>, a foot length and angle, etc. As such, <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>6</b></figref> are meant to illustrate non-limiting examples of different body measurements that may be obtained according to the systems and methods described herein and illustrate one exemplary embodiment of postural mapping using a virtual skeleton.</p><p id="p-0057" num="0056">Referring now to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a first posture <b>400</b> is shown. The first posture <b>400</b> is one example of a recommended driving posture that follows posture recommendations for ergonomic and effective vehicle operation, such as described with respect to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In the first posture <b>400</b>, the driver seat <b>404</b> is positioned at a seat angle <b>414</b>, and the head <b>416</b> is in contact with the headrest <b>404</b><i>a </i>such that there is no distance (e.g., space) between the head <b>416</b> and the headrest <b>404</b><i>a</i>. For example, the seat angle <b>414</b> may be within a threshold range for driver comfort and vision. The threshold range may extend from 93 to 100 degrees and may vary based on the body measurements of the driver <b>402</b>. For example, the threshold range may be between 94 and 99 degrees for a first driver, between 93 and 101 degrees for a second driver, and between 94 and 97 degrees for a third driver. The threshold range may help ensure that the driver <b>402</b> is not so reclined that vehicle operation is obstructed and not so inclined that comfort is reduced.</p><p id="p-0058" num="0057">The first posture <b>400</b> further includes a first clearance distance <b>434</b> between the steering wheel <b>412</b> and the torso of the driver <b>402</b>, a second clearance distance <b>436</b> between the steering wheel <b>412</b> and the thigh of the driver <b>402</b>, and a longitudinal seat position represented by a distance <b>442</b> between a forward-most upper corner of the seat base <b>440</b> (with respect to the vehicle) and a forward-most edge of the seat cushion <b>404</b><i>c</i>. However, the computing system may use other references in determining the longitudinal seat position. Although not shown in the present example, a seat height may also be determined.</p><p id="p-0059" num="0058">The first posture <b>400</b> further includes a knee angle <b>426</b>, a hip angle <b>422</b>, and an elbow angle <b>432</b>. The knee angle <b>426</b> is formed at the knee joint between the lower leg length <b>424</b> and the upper leg length <b>420</b>, the hip angle is formed at the hip joint between the upper leg length <b>420</b> and the torso length <b>418</b>, and the elbow angle <b>432</b> is formed at the elbow joint between the lower arm length <b>430</b> and the upper arm length <b>428</b>. Note that although <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a two-dimensional illustration of a 3D scene, the knee angle <b>426</b>, the hip angle <b>422</b>, and the elbow angle <b>432</b> may be defined in three dimensions (e.g., using x, y, and z world coordinates).</p><p id="p-0060" num="0059">Due to the longitudinal seat position represented by the distance <b>442</b> and the seat angle <b>414</b>, the first clearance distance <b>434</b> and the second clearance distance <b>436</b> provide sufficient room for the driver to maneuver without contacting the steering wheel <b>412</b>. Further, the knee angle <b>426</b> allows the driver to fully depress the pedal <b>444</b> without fully unbending the knee joint. Further, because the driver's arms are bent at the obtuse elbow angle <b>432</b>, the driver may easily reach the steering wheel <b>412</b>.</p><p id="p-0061" num="0060">Referring now to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a second posture <b>500</b> is shown. The second posture <b>500</b> is a first example of an incorrect driving posture that may cause driver strain and/or degrade the driver's ability to operate the vehicle. In the second posture <b>500</b>, the driver seat <b>404</b> is positioned at a seat angle <b>514</b> and has a longitudinal position with a distance <b>542</b> between the forward-most upper corner of the seat base <b>440</b> and a forward-most edge of the seat cushion <b>404</b><i>c</i>. The seat angle <b>514</b> is less than the seat angle <b>414</b> of the first posture <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> and is outside of the threshold range for driver comfort and vision. For example, the seat angle <b>514</b> may be approximately 90 degrees, causing the seat back <b>404</b><i>b </i>to be so vertically upright that the driver <b>402</b> hunches forward toward the steering wheel <b>412</b>. As a result, a hip angle <b>522</b> of the driver <b>402</b> in the second posture <b>500</b> is also less than the hip angle <b>422</b> of the first posture <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>. The distance <b>542</b> of the second posture <b>500</b> is greater than the distance <b>442</b> of the first posture <b>400</b>. Thus, the longitudinal position of the seat <b>404</b> is further forward in the second posture <b>500</b> than in the first posture <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>. As a result of both the further forward longitudinal position and the smaller seat angle <b>514</b>, both a first clearance distance <b>534</b> between the steering wheel <b>412</b> and the torso of the driver <b>402</b> and the second clearance distance <b>536</b> between the steering wheel <b>412</b> and the knee of the driver <b>402</b> are less than the first clearance distance <b>434</b> and the second clearance distance <b>436</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, respectively. As a result of the smaller second clearance distance <b>536</b>, the driver <b>402</b> may be more likely to contact the steering wheel <b>412</b> with a knee. Further, the head <b>416</b> is a distance <b>538</b> from the headrest <b>404</b><i>a</i>. As a result, the driver <b>402</b> may expend additional energy and experience muscle fatigue by leaning forward instead of resting the head <b>416</b> against the headrest <b>404</b><i>a </i>and may be closer to the steering wheel <b>412</b> than desired for vehicle operation.</p><p id="p-0062" num="0061">The second posture <b>500</b> further includes a knee angle <b>526</b> and an elbow angle <b>532</b>. Because the first clearance distance <b>534</b> in the second posture <b>500</b> is smaller than the first clearance distance <b>434</b> in the first posture <b>400</b>, the elbow angle <b>532</b> is smaller (e.g., more acute) than the elbow angle <b>432</b> of the first posture <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Similarly, the knee angle <b>526</b> is smaller (e.g., more acute) than the knee angle <b>426</b> of the first posture <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Overall, the driver <b>402</b> is positioned inefficiently and in a manner that may cause strain and/or fatigue, making the second posture <b>500</b> undesirable. The computing system may provide feedback accordingly so that the driver may adjust from the second posture <b>500</b> to the first posture <b>400</b>, such as according to the method of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. For example, the computing system may recommend increasing the seat angle <b>514</b>, decreasing the distance <b>542</b>, resting the head <b>416</b> on the headrest <b>404</b><i>a</i>, etc.</p><p id="p-0063" num="0062">Continuing to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a third posture <b>600</b> is shown. The third posture <b>600</b> is a second example of an incorrect driving posture that may cause driver strain and/or degrade the driver's ability to operate the vehicle. In the third posture <b>600</b>, the driver seat <b>404</b> is positioned at a seat angle <b>614</b> and has a longitudinal position with a distance <b>642</b> between the forward-most upper corner of the seat base <b>440</b> and a forward-most edge of the seat cushion <b>404</b><i>c</i>. The seat angle <b>614</b> is greater than the seat angle <b>414</b> of the first posture <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> and is outside of the threshold range for driver comfort and vision. For example, the seat angle <b>614</b> may be approximately 105 degrees, causing the seat back <b>404</b><i>b </i>to be further reclined than desired. Further, the distance <b>642</b> of the third posture <b>600</b> is less than the distance <b>442</b> of the first posture <b>400</b>. Thus, the longitudinal position of the seat <b>404</b> is further backward in the third posture <b>600</b> than in the first posture <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>. As a result of both the further backward longitudinal position and the larger seat angle <b>614</b>, both a first clearance distance <b>634</b> between the steering wheel <b>412</b> and the torso of the driver <b>402</b> and the second clearance distance <b>636</b> between the steering wheel <b>412</b> and the knee of the driver <b>402</b> are greater than the first clearance distance <b>434</b> and the second clearance distance <b>436</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, respectively. In particular, the larger first clearance distance <b>634</b> is such that the arms of the driver <b>402</b> are nearly fully extended to reach the steering wheel <b>412</b>. As a result, an elbow angle <b>632</b> is greater than the elbow angle <b>432</b> of the first posture <b>400</b> and nears 180 degrees.</p><p id="p-0064" num="0063">Further, a hip angle <b>622</b> of the driver <b>402</b> in the third posture <b>600</b> is greater than the hip angle <b>422</b> of the first posture <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> due to the greater seat angle <b>614</b> (e.g., the seat is more reclined). As another example, the head <b>416</b> has a distance <b>638</b> from the headrest <b>404</b><i>a</i>. Even though the distance <b>638</b> is less than the distance <b>538</b> of the second position of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the driver <b>402</b> still may expend additional energy and experience muscle fatigue by not resting the head <b>416</b> against the headrest <b>404</b><i>a. </i></p><p id="p-0065" num="0064">The third posture <b>600</b> further includes a knee angle <b>626</b>. Because the longitudinal seat position is further back than in the first posture <b>400</b>, the knee angle <b>626</b> is greater (e.g., more obtuse) than the knee angle <b>426</b> in the first posture <b>400</b>. For example, the knee angle <b>626</b> is such that the leg is approaching a fully extended position. As a result, the driver <b>402</b> may be unable to fully depress the pedal <b>444</b> without sliding forward in the seat <b>404</b>, away from the seat back <b>404</b><i>b</i>. Overall, the driver <b>402</b> is positioned inefficiently and in a manner that may cause strain and/or fatigue due to the seat angle <b>614</b> being outside of the threshold range, making the third posture <b>600</b> undesirable. The computing system may provide feedback accordingly so that the driver may adjust from the third posture <b>600</b> to the first posture <b>400</b>, such as according to the method of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. For example, the computing system may recommend decreasing the seat angle <b>614</b>, increasing the distance <b>642</b>, resting the head <b>416</b> on the headrest <b>404</b><i>a</i>, etc.</p><p id="p-0066" num="0065">Turning now to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, an example method <b>700</b> is shown for adjusting a seat position during vehicle ingress or egress. The method <b>700</b> may be executed by a processor of a computing system (e.g., the computing system <b>120</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or the computing system <b>220</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>) based on instructions stored on a memory of the computing system (e.g., the memory <b>144</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>). The method <b>700</b> will be described with regard to the systems and components of <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>2</b></figref>; however, it may be understood that the method may be implemented with other systems and components without departing from the scope of the present disclosure. For clarity, the method <b>700</b> will be described with respect to one vehicle seat, which may be a driver seat or a passenger seat of the vehicle, although the method <b>700</b> may be used to adjust more than one seat at the same time. Further, the method <b>700</b> may be executed whenever vehicle ingress or egress is indicated, such as will be elaborated below.</p><p id="p-0067" num="0066">At <b>702</b>, the method <b>700</b> includes identifying an individual performing ingress or egress. In some examples, the computing system may identify the individual performing ingress or egress based on a unique identity of a key fob or smart key carried by the individual, a biometric parameter used by the individual for vehicle unlock (e.g., thumbprint, facial recognition, etc.), and/or a signal received from a mobile device carried by the individual (e.g., a smartphone, tablet, or smartwatch). As another example, the computing system may receive images from a camera (e.g., the camera <b>118</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or the camera <b>218</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>) and perform facial recognition to identify the individual, such as described with respect to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. If the individual is not currently known to the computing system, the computing system may assign a new user identification number and store images of the individual for future facial recognition, at least in some examples.</p><p id="p-0068" num="0067">At <b>704</b>, the method <b>700</b> includes determining if the individual is performing ingress. For example, the individual may be performing ingress when the individual is outside of the vehicle, when the vehicle is unlocked while being at rest, in response to a door being opened while being at rest, in response to a remote start, and so forth. As such, the vehicle being unlocked while at rest, the door being opened while the vehicle is at rest, the remote start, detecting a proximity of a key fob, etc. all provide indications of ingress. In contrast, the individual may not be performing ingress, and may thus be performing egress, when the individual is already inside of the vehicle, in response to the vehicle being shut down, in response to an ignition key being removed, etc. As such, the occupant being inside the vehicle at the time of vehicle shutdown and the ignition key being removed provide indications of egress.</p><p id="p-0069" num="0068">If the individual is performing ingress, the method <b>700</b> proceeds to <b>706</b> and includes adjusting the seat to an ingress position for the identified individual. If the individual is not known and body measurement information is not known, a default ingress position may be used. Otherwise, when the individual is known and/or the computing system has body measurement information, the computing system may determine the ingress position, such described with respect to the method of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The ingress position may include settings for a seat tilt, a seat angle, a seat height, and a seat longitudinal position. The computing system may adjust the seat tilt, the seat angle, the seat height, and/or the seat longitudinal position to the ingress position via a seat motor.</p><p id="p-0070" num="0069">At <b>708</b>, the method <b>700</b> includes adjusting the seat to a position for vehicle operation. For example, the computing system may further adjust the seat position from the ingress position after the individual enters the vehicle and is positioned within the seat and before the vehicle starts moving. In some examples, the position for vehicle operation may be the most recently used seat settings for the identified individual that are stored in memory. If the individual is not known and body measurement information is not known, a default seat position may be used. In some examples, the computing system may determine the seat position based on body measurements of the individual, when available, such described with respect to the method of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The seat position for vehicle operation may include settings for the seat tilt, the seat angle, the seat height, and the seat longitudinal position that are expected to be comfortable and ergonomic for the given individual. Further, some or all of the settings for the seat position for vehicle operation may be different than the seat settings for ingress. As such, the computing system may adjust the seat tilt, the seat angle, the seat height, and the seat longitudinal position to the seat position for the vehicle operation via the seat motor.</p><p id="p-0071" num="0070">At <b>710</b>, the method <b>700</b> includes performing posture monitoring during vehicle operation, such as according to the method of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In this way, a likelihood that the individual remains in a comfortable and ergonomic position during vehicle operation is increased. The method <b>700</b> may then end.</p><p id="p-0072" num="0071">Returning to <b>704</b>, if the individual is not performing ingress (e.g., the individual is performing egress), the method <b>700</b> proceeds to <b>712</b> and includes adjusting the seat to an egress position for the identified individual. If the individual is not known and body measurement information is not known, a default egress position may be used. Otherwise, when the individual is known and/or the computing system has body measurement information, the computing system may determine the egress position, such described with respect to the method of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The egress position may include settings for the seat tilt, the seat angle, the seat height, and the seat longitudinal position, any or all of which may be the same as or different from the seat settings for ingress as well as the seat settings for vehicle operation. The computing system may adjust the seat tilt, the seat angle, the seat height, and/or the seat longitudinal position to the egress position via the seat motor. Thus, the individual may be able to comfortably exit the vehicle, and the method <b>700</b> may end.</p><p id="p-0073" num="0072">In this way, a comfort of an occupant of a vehicle, such as a driver or a non-driver passenger, may be increased while entering the vehicle, while the vehicle is in operation, and while exiting the vehicle. Further, because posture monitoring is automated by a computing system, the driver may focus on operating the vehicle instead of monitoring their own posture. Further still, an amount of time it takes for the driver to achieve an ergonomic and effective driving posture may be reduced using the posture guidance. For example, the driver may not spend time trying out different seat adjustments and steering wheel adjustments to see what feels more comfortable but may instead allow the computing system to determine optimal settings for their body measurements. As such, the driver may follow adjustment prompts to achieve the optimal settings.</p><p id="p-0074" num="0073">The technical effect of monitoring a sitting posture of a vehicle occupant and providing feedback in response to the sitting posture being significantly different from a recommended posture is that a comfort of the vehicle occupant may be increased.</p><p id="p-0075" num="0074">The disclosure also provides support for a method, comprising: capturing images of an occupant in a vehicle via a vehicle camera, determining a current posture of the occupant and a recommended posture for the occupant based on the captured images and body measurements of the occupant, and outputting a guidance based on a difference between the current posture and the recommended posture. In a first example of the method, at least one of the body measurements is received via a user interface. In a second example of the method, optionally including the first example, at least one of the body measurements is measured via a sensor of the vehicle. In a third example of the method, optionally including one or both of the first and second examples, the method further comprises: estimating at least one of the body measurements based on the captured images. In a fourth example of the method, optionally including one or more or each of the first through third examples, estimating the at least one of the body measurements based on the captured images comprises determining a surface area and volume of the occupant using at least one of depth and visible light information from the captured images. In a fifth example of the method, optionally including one or more or each of the first through fourth examples, the occupant is sitting in a seat, and determining the current posture of the occupant comprises: determining a seat position of the seat, and determining a body position of the occupant relative to the seat. In a sixth example of the method, optionally including one or more or each of the first through fifth examples, the seat position of the seat includes an angle of a seat back of the seat, a tilt of a seat cushion of the seat, and a longitudinal position of the seat within the vehicle, the body position of the occupant relative to the seat includes a distance from a head of the occupant to a headrest of the seat, and determining the recommended posture for the occupant comprises determining a desired angle of the seat back, a desired tilt of the seat cushion, a desired longitudinal position of the seat within the vehicle, and a desired distance from the head of the occupant to the headrest of the seat based on the body measurements of the occupant and a plurality of body component-specific posture rules. In a seventh example of the method, optionally including one or more or each of the first through sixth examples, outputting the guidance based on the difference between the current posture and the recommended posture comprises: determining a first difference between the angle of the seat back of the seat and the desired angle of the seat back of the seat, a second difference between the tilt of the seat cushion of the seat and the desired tilt of the seat cushion, a third difference between the longitudinal position of the seat within the vehicle and the desired longitudinal position of the seat within the vehicle, and a fourth difference between the distance from the head of the occupant to the headrest of the seat and the desired distance, outputting the guidance to adjust posture in response to a weighted sum of the first difference, the second difference, the third difference, and the fourth difference being greater than or equal to a threshold difference, and outputting the guidance to maintain posture in response to the weighted sum being less than the threshold difference. In an eighth example of the method, optionally including one or more or each of the first through seventh examples, the occupant is a driver of the vehicle, and determining the current posture of the occupant further comprises: determining a position of a steering wheel, and determining the body position of the occupant relative to the steering wheel. In a ninth example of the method, optionally including one or more or each of the first through eighth examples, the position of the steering wheel includes a height of the steering wheel and a tilt of the steering wheel, the body position of the occupant relative to the steering wheel includes a first clearance distance between the steering wheel and a torso of the occupant and a second clearance distance between the steering wheel and a thigh of the occupant, and determining the recommended posture for the occupant comprises determining a desired height of the steering wheel, a desired tilt of the steering wheel, a desired first clearance distance, and a desired second clearance distance based on the body measurements of the occupant and a plurality of body component-specific posture rules. In a tenth example of the method, optionally including one or more or each of the first through ninth examples, outputting the guidance based on the difference between the current posture and the recommended posture comprises: determining a first difference between the height of the steering wheel and the desired height of the steering wheel, a second difference between the tilt of the steering wheel and the desired tilt of the steering wheel, a third difference between the first clearance distance and the desired first clearance distance, and a fourth difference between the second clearance distance and the desired second clearance distance, and outputting the guidance as a visual and/or audible alert in response to a weighted sum of the first difference, the second difference, the third difference, and the fourth difference being greater than a threshold difference.</p><p id="p-0076" num="0075">The disclosure also provides support for a method, comprising: receiving image data from a camera of a vehicle, providing feedback for a posture of an occupant in a seat of the vehicle based on the image data received from the camera and body measurements of the occupant, and adjusting a position of the seat for an ingress and an egress of the occupant based on the image data received from the camera and the body measurements of the occupant. In a first example of the method, providing the feedback for the posture of the occupant of the vehicle based on the image data received from the camera and body measurements of the occupant comprises: analyzing the image data received from the camera to determine a current position of the seat, a current position of the occupant relative to the seat, and the body measurements of the occupant, determining a desired position for the seat and a desired position of the occupant relative to the seat by applying the body measurements of the occupant to a plurality of body component-specific posture recommendations, and outputting a postural guidance alert in response to a statistically significant difference between the current position of the seat and the desired position for the seat or the current position of the occupant relative to the seat and the desired position of the occupant relative to the seat. In a second example of the method, optionally including the first example, adjusting the position of the seat for the ingress and the egress of the occupant based on the image data received from the camera comprises: determining a first position of the seat for the ingress of the occupant and a second position of the seat for the egress of the occupant based on the body measurements of the occupant, adjusting the seat to the first position in response to an indication of the ingress of the occupant, and adjusting the seat to the second position in response to an indication of the egress of the occupant. In a third example of the method, optionally including one or both of the first and second examples, adjusting the position of the seat for the ingress and the egress of the occupant based on the image data received from the camera comprises: identifying the occupant by inputting the image data received from the camera into a biometric algorithm, receiving a stored seat position for the ingress and the egress associated with the identified occupant, and actuating a seat motor to adjust the position of the seat to the stored seat position for the ingress and the egress in response to an indication of the ingress or the egress.</p><p id="p-0077" num="0076">The disclosure also provides support for a system for a vehicle, comprising: a camera, and a computing system including instructions stored in non-transitory memory that, when executed, cause the computing system to: receive images captured of an occupant in the vehicle from the camera, determine body measurements of the occupant from the received images, determine a current posture of the occupant from the received images, determine a recommended posture for the occupant based on the determined body measurements, and output an alert responsive to a difference between the current posture and the recommended posture exceeding a threshold difference. In a first example of the system, the occupant is positioned in a seat of the vehicle, and wherein to determine the current posture of the occupant from the received images, the computing system includes further instructions stored in the non-transitory memory that, when executed, cause the computing system to: determine a plurality of posture components of the occupant from the received images, the plurality of posture components including an angle of each joint of the occupant, a position of the occupant relative to the seat of the vehicle, and seat position settings of the seat. In a second example of the system, optionally including the first example, to determine the recommended posture for the occupant based on the determined body measurements, the computing system includes further instructions stored in the non-transitory memory that, when executed, cause the computing system to: determine a plurality of recommended posture components for the occupant based on the body measurements and a plurality of body component-specific posture recommendations, the plurality of recommended posture components including a recommended angle of each joint, a recommended position of the occupant relative to the seat, and recommended seat position settings. In a third example of the system, optionally including one or both of the first and second examples, to output the alert responsive to the difference between the current posture and the recommended posture exceeding the threshold difference, the computing system includes further instructions stored in the non-transitory memory that, when executed, cause the computing system to: determine differences between each of the plurality of posture components of the occupant and each of the corresponding plurality of recommended posture components, and output the alert responsive to a sum of the differences exceeding the threshold difference. In a fourth example of the system, optionally including one or more or each of the first through third examples, the alert includes instructions for achieving the recommended posture, including instructions for achieving the recommended seat position settings and the recommended position of the occupant relative to the seat.</p><p id="p-0078" num="0077">The description of embodiments has been presented for purposes of illustration and description. Suitable modifications and variations to the embodiments may be performed in light of the above description or may be acquired from practicing the methods. For example, unless otherwise noted, one or more of the described methods may be performed by a suitable device and/or combination of devices, such as the embodiments described above with respect to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>2</b></figref>. The methods may be performed by executing stored instructions with one or more logic devices (e.g., processors) in combination with one or more hardware elements, such as storage devices, memory, hardware network interfaces/antennas, switches, clock circuits, and so on. The described methods and associated actions may also be performed in various orders in addition to the order described in this application, in parallel, and/or simultaneously. The described systems are exemplary in nature, and may include additional elements and/or omit elements. The subject matter of the present disclosure includes all novel and non-obvious combinations and sub-combinations of the various systems and configurations, and other features, functions, and/or properties disclosed.</p><p id="p-0079" num="0078">As used in this application, an element or step recited in the singular and proceeded with the word &#x201c;a&#x201d; or &#x201c;an&#x201d; should be understood as not excluding plural of said elements or steps, unless such exclusion is stated. Furthermore, references to &#x201c;one embodiment&#x201d; or &#x201c;one example&#x201d; of the present disclosure are not intended to be interpreted as excluding the existence of additional embodiments that also incorporate the recited features. The terms &#x201c;first,&#x201d; &#x201c;second,&#x201d; &#x201c;third,&#x201d; and so on are used merely as labels and are not intended to impose numerical requirements or a particular positional order on their objects unless explicitly stated to the contrary.</p><p id="p-0080" num="0079">The following claims particularly point out subject matter from the above disclosure that is regarded as novel and non-obvious. These claims may refer to &#x201c;an&#x201d; element or &#x201c;a first&#x201d; element or the equivalent thereof. Such claims should be understood to include incorporation of one or more such elements, neither requiring nor excluding two or more such elements. Other combinations and sub-combinations of the disclosed features, functions, elements, and/or properties may be claimed through amendment of the present claims or through presentation of new claims in this or a related application. Such claims, whether broader, narrower, equal, or different in scope to the original claims, also are regarded as included within the subject matter of the present disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method, comprising:<claim-text>capturing images of an occupant in a vehicle via a vehicle camera;</claim-text><claim-text>determining a current posture of the occupant and a recommended posture for the occupant based on the captured images and body measurements of the occupant; and</claim-text><claim-text>outputting a guidance based on a difference between the current posture and the recommended posture.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one of the body measurements is received via a user interface.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one of the body measurements is measured via a sensor of the vehicle.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising estimating at least one of the body measurements based on the captured images.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein estimating the at least one of the body measurements based on the captured images comprises determining a surface area and volume of the occupant using at least one of depth and visible light information from the captured images.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the occupant is sitting in a seat, and determining the current posture of the occupant comprises:<claim-text>determining a seat position of the seat; and</claim-text><claim-text>determining a body position of the occupant relative to the seat.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein:<claim-text>the seat position of the seat includes an angle of a seat back of the seat, a tilt of a seat cushion of the seat, and a longitudinal position of the seat within the vehicle;</claim-text><claim-text>the body position of the occupant relative to the seat includes a distance from a head of the occupant to a headrest of the seat; and</claim-text><claim-text>determining the recommended posture for the occupant comprises determining a desired angle of the seat back, a desired tilt of the seat cushion, a desired longitudinal position of the seat within the vehicle, and a desired distance from the head of the occupant to the headrest of the seat based on the body measurements of the occupant and a plurality of body component-specific posture rules.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein outputting the guidance based on the difference between the current posture and the recommended posture comprises:<claim-text>determining a first difference between the angle of the seat back of the seat and the desired angle of the seat back of the seat, a second difference between the tilt of the seat cushion of the seat and the desired tilt of the seat cushion, a third difference between the longitudinal position of the seat within the vehicle and the desired longitudinal position of the seat within the vehicle, and a fourth difference between the distance from the head of the occupant to the headrest of the seat and the desired distance;</claim-text><claim-text>outputting the guidance to adjust posture in response to a weighted sum of the first difference, the second difference, the third difference, and the fourth difference being greater than or equal to a threshold difference; and</claim-text><claim-text>outputting the guidance to maintain posture in response to the weighted sum being less than the threshold difference.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the occupant is a driver of the vehicle, and determining the current posture of the occupant further comprises:<claim-text>determining a position of a steering wheel; and</claim-text><claim-text>determining the body position of the occupant relative to the steering wheel.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein:<claim-text>the position of the steering wheel includes a height of the steering wheel and a tilt of the steering wheel;</claim-text><claim-text>the body position of the occupant relative to the steering wheel includes a first clearance distance between the steering wheel and a torso of the occupant and a second clearance distance between the steering wheel and a thigh of the occupant; and</claim-text><claim-text>determining the recommended posture for the occupant comprises determining a desired height of the steering wheel, a desired tilt of the steering wheel, a desired first clearance distance, and a desired second clearance distance based on the body measurements of the occupant and a plurality of body component-specific posture rules.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein outputting the guidance based on the difference between the current posture and the recommended posture comprises:<claim-text>determining a first difference between the height of the steering wheel and the desired height of the steering wheel, a second difference between the tilt of the steering wheel and the desired tilt of the steering wheel, a third difference between the first clearance distance and the desired first clearance distance, and a fourth difference between the second clearance distance and the desired second clearance distance; and</claim-text><claim-text>outputting the guidance as a visual and/or audible alert in response to a weighted sum of the first difference, the second difference, the third difference, and the fourth difference being greater than a threshold difference.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A method, comprising:<claim-text>receiving image data from a camera of a vehicle;</claim-text><claim-text>providing feedback for a posture of an occupant in a seat of the vehicle based on the image data received from the camera and body measurements of the occupant; and</claim-text><claim-text>adjusting a position of the seat for an ingress and an egress of the occupant based on the image data received from the camera and the body measurements of the occupant.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein providing the feedback for the posture of the occupant of the vehicle based on the image data received from the camera and body measurements of the occupant comprises:<claim-text>analyzing the image data received from the camera to determine a current position of the seat, a current position of the occupant relative to the seat, and the body measurements of the occupant;</claim-text><claim-text>determining a desired position for the seat and a desired position of the occupant relative to the seat by applying the body measurements of the occupant to a plurality of body component-specific posture recommendations; and</claim-text><claim-text>outputting a postural guidance alert in response to a statistically significant difference between the current position of the seat and the desired position for the seat or the current position of the occupant relative to the seat and the desired position of the occupant relative to the seat.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein adjusting the position of the seat for the ingress and the egress of the occupant based on the image data received from the camera comprises:<claim-text>determining a first position of the seat for the ingress of the occupant and a second position of the seat for the egress of the occupant based on the body measurements of the occupant;</claim-text><claim-text>adjusting the seat to the first position in response to an indication of the ingress of the occupant; and</claim-text><claim-text>adjusting the seat to the second position in response to an indication of the egress of the occupant.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein adjusting the position of the seat for the ingress and the egress of the occupant based on the image data received from the camera comprises:<claim-text>identifying the occupant by inputting the image data received from the camera into a biometric algorithm;</claim-text><claim-text>receiving a stored seat position for the ingress and the egress associated with the identified occupant; and</claim-text><claim-text>actuating a seat motor to adjust the position of the seat to the stored seat position for the ingress and the egress in response to an indication of the ingress or the egress.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A system for a vehicle, comprising:<claim-text>a camera; and</claim-text><claim-text>a computing system including instructions stored in non-transitory memory that, when executed, cause the computing system to:<claim-text>receive images captured of an occupant in the vehicle from the camera;</claim-text><claim-text>determine body measurements of the occupant from the received images;</claim-text><claim-text>determine a current posture of the occupant from the received images;</claim-text><claim-text>determine a recommended posture for the occupant based on the determined body measurements; and</claim-text><claim-text>output an alert responsive to a difference between the current posture and the recommended posture exceeding a threshold difference.</claim-text></claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the occupant is positioned in a seat of the vehicle, and wherein to determine the current posture of the occupant from the received images, the computing system includes further instructions stored in the non-transitory memory that, when executed, cause the computing system to:<claim-text>determine a plurality of posture components of the occupant from the received images, the plurality of posture components including an angle of each joint of the occupant, a position of the occupant relative to the seat of the vehicle, and seat position settings of the seat.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein to determine the recommended posture for the occupant based on the determined body measurements, the computing system includes further instructions stored in the non-transitory memory that, when executed, cause the computing system to:<claim-text>determine a plurality of recommended posture components for the occupant based on the body measurements and a plurality of body component-specific posture recommendations, the plurality of recommended posture components including a recommended angle of each joint, a recommended position of the occupant relative to the seat, and recommended seat position settings.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein to output the alert responsive to the difference between the current posture and the recommended posture exceeding the threshold difference, the computing system includes further instructions stored in the non-transitory memory that, when executed, cause the computing system to:<claim-text>determine differences between each of the plurality of posture components of the occupant and each of the corresponding plurality of recommended posture components; and</claim-text><claim-text>output the alert responsive to a sum of the differences exceeding the threshold difference.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the alert includes instructions for achieving the recommended posture, including instructions for achieving the recommended seat position settings and the recommended position of the occupant relative to the seat.</claim-text></claim></claims></us-patent-application>
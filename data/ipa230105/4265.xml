<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004266A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004266</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363997</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0484</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0484</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e43">STRUCTURING COMMUNICATION AND CONTENT FOR DETECTED ACTIVITY AREAS</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Microsoft Technology Licensing, LLC</orgname><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Helvik</last-name><first-name>Torbj&#xf8;rn</first-name><address><city>Oslo</city><country>NO</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Eide</last-name><first-name>Andreas</first-name><address><city>Oslo</city><country>NO</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Bergstrand</last-name><first-name>Kjetil Krogvig</first-name><address><city>Kolbotn</city><country>NO</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Rydningen</last-name><first-name>Lene Christin</first-name><address><city>Berlin</city><country>DE</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Techniques for detecting one or more focus areas of a user and structuring activities and content around the focus area(s) are disclosed. The activities of a user, the people associated with the activities, and/or the content associated with the activities are automatically inferred or detected based on the channels of collaboration associated with the focus area(s). Example channels of collaboration include, but are not limited to, electronic mail, instant messages, documents, and in-person and online meetings. Some or all of the activities, people, and/or content are grouped into one or more focus areas, where a focus area relates to an endeavor in which the user focuses on over a period of time. Some or all of the focus areas are presented to the user.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="132.08mm" wi="158.75mm" file="US20230004266A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="159.34mm" wi="130.13mm" file="US20230004266A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="224.20mm" wi="127.08mm" file="US20230004266A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="149.10mm" wi="81.53mm" file="US20230004266A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="219.12mm" wi="142.49mm" file="US20230004266A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="121.84mm" wi="82.97mm" file="US20230004266A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="164.51mm" wi="145.03mm" orientation="landscape" file="US20230004266A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="153.92mm" wi="111.00mm" orientation="landscape" file="US20230004266A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="143.93mm" wi="81.53mm" file="US20230004266A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="182.80mm" wi="140.63mm" orientation="landscape" file="US20230004266A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="182.80mm" wi="148.42mm" orientation="landscape" file="US20230004266A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="170.94mm" wi="118.03mm" file="US20230004266A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="167.47mm" wi="155.36mm" file="US20230004266A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="166.71mm" wi="153.50mm" file="US20230004266A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">As the number of tasks, meetings, electronic communications, documents, and other responsibilities a person manages in a day continues to increase, it may be difficult to keep track of these activities as well as the content that relates to the activities. For example, organizing, finding, and viewing emails, online meetings, and documents, as well as tracking the status of various tasks, can be challenging. Typically, these functions are performed manually, and curating the data associated with the activities can be frustrating and time consuming. Additionally, it can be difficult and time consuming for a person to manage the data such that old or less relevant data is archived, and current data is monitored.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0003" num="0002">Techniques for detecting one or more focus areas of a user and structuring activities and content around the focus area(s) are disclosed. In one embodiment, the activities, the people associated with the activities, and/or the content associated with the focus area(s) are automatically inferred or detected based on the channels of collaboration associated with the focus area(s), such as electronic mail (&#x201c;email&#x201d;), instant messages, documents, meetings, and the like. Some or all of the activity data that is associated with the activities is grouped into one or more focus areas, where a focus area relates to an endeavor in which a user focuses on over a period of time. A focus area can include one or more persons and content (collectively &#x201c;focus data&#x201d;) that are related to the endeavor. In one embodiment, an endeavor is a collaboration with one or more other persons and includes several tasks, associated content, and communications. Example focus areas include, but are not limited to, product development of Product A, a kitchen renovation, Project B, and recruiting.</p><p id="p-0004" num="0003">Any suitable type of focus data can be presented in a focus area. For example, focus data such as documents, meetings, tasks, and communications can be displayed in a focus area. In one aspect, the one or more focus areas are presented to a person as a feed that is updated in real-time, in substantially real-time, at selected times, and/or on demand. Thus, as the activity data (e.g., activities, people, and content) the user focuses on changes over time, the focus data included in a focus area changes as well (e.g., hourly, daily, on demand).</p><p id="p-0005" num="0004">In one aspect, a method includes determining an endeavor that a user has focused on over a period of time, where the endeavor is associated with activity data (e.g., entities and content items) that is received, generated, referenced, and identified by the user. The relationships between the entities and the content items are determined and based on the relationships, a portion of the entities and the content items are clustered into one or more focus areas. The focus area(s) is populated with focus area data that includes all or a subset of the activity data related to that focus area. The focus area is presented or caused to be presented, and one or more updates are provided to the focus data in the focus area. The one or more updates change the focus data presented in the focus area.</p><p id="p-0006" num="0005">In another aspect, a system includes a processing device and a storage device operably connected to the processing device. The storage device stores instructions, that when executed by the processing device, cause operations to be performed. The operations include determining one or more endeavors that a user has focused on over a period of time, each endeavor comprising entities and content items, and determining relationships between the entities and the content items. The entities and the content items are grouped into one or more focus areas. At least one focus area is populated with focus data that is associated with the entities and the content in that focus area. The plurality of focus areas is provided for presented or is caused to be provided for presented. One or more updates is provided to the focus data in at least one focus area. The one or more updates changes the focus data presented in the at least one focus area.</p><p id="p-0007" num="0006">In yet another aspect, a method includes determining an endeavor that a user has focused on over a period of time, where the determining includes: analyzing activity data associated with one or more activities of the user to determine content items associated with the endeavor; detecting one or more people associated with the content items to determine one or more entities; and determining relationships between the entities and the content items. At least some of the entities and the content items are clustered into a focus area based on the relationships, and the focus area is populated with focus data associated with the entities and the content items that are clustered in the focus area. The focus area is presented or is caused be presented as a feed by providing one or more updates to the focus data in the focus area in real-time, in substantially real-time, at selected times, or on demand. The one or more updates changes the focus data presented in the focus area.</p><p id="p-0008" num="0007">This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0009" num="0008">Non-limiting and non-exhaustive examples are described with reference to the following Figures. The elements of the drawings are not necessarily to scale relative to each other. Identical reference numerals have been used, where possible, to designate identical features that are common to the figures.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram of a first system in which aspects of the present disclosure may be practiced;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a block diagram of a second system in which aspects of the present disclosure may be practiced;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a flowchart of a method of generating focus areas in accordance with some embodiments;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example node-edge graph in accordance with some embodiments;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates clusters of nodes in the node-edge graph shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> in accordance with some embodiments;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a flowchart of a first method of presenting focus areas in accordance with some embodiments;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example GUI that presents focus areas in a first context in accordance with some embodiments;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example GUI that enables a user to select data to be included in focus areas in accordance with some embodiments;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a flowchart of a second method of presenting focus areas in accordance with some embodiments;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an example GUI that presents one or more focus areas in accordance with some embodiments;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a block diagram depicting example physical components of a computing device with which aspects of the disclosure may be practiced;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIGS. <b>12</b>A-<b>12</b>B</figref> illustrate block diagrams illustrating a mobile computing device with which aspects of the present disclosure may be practiced; and</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates a block diagram of a distributed computing system in which aspects of the present disclosure may be practiced.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0023" num="0022">In the following detailed description, references are made to the accompanying drawings that form a part hereof, and in which are shown by way of illustrations specific embodiments or examples. These aspects may be combined, other aspects may be utilized, and structural changes may be made without departing from the present disclosure. Embodiments may be practiced as methods, systems, or devices. Accordingly, embodiments may take the form of a hardware implementation, an entirely software implementation, or an implementation combining software and hardware aspects. The following detailed description is therefore not to be taken in a limiting sense, and the scope of the present disclosure is defined by the appended claims and their equivalents.</p><p id="p-0024" num="0023">Generally, embodiments disclosed herein provide techniques for detecting one or more focus areas of a user and structuring activities and content around the focus area(s). In one embodiment, the user's activities, the people associated with the activities, and the content associated with the activities are automatically inferred or detected based on the channels of collaboration associated with the activities, such as electronic mail (&#x201c;email&#x201d;), instant messages, documents, meetings, and the like. For example, artificial intelligence or one or more machine learning mechanisms (e.g., models, algorithms, or applications) are used to infer the user's activities, the people associated with the activities, and the content associated with the activities. Some or all of this data (&#x201c;activity data&#x201d;) is analyzed to determine one or more focus areas the user has focused on over a period of time. A focus area includes focus data, which is some or all of the activity data related to the focus area. Focus data such as documents, meetings, tasks, and communications can be presented in a focus area. Example communications include, but are not limited to, electronic mail (&#x201c;email&#x201d;), text messages, online chats, and instant messages. In one aspect, one or more focus areas are presented to the user as a feed that is updated in real-time, in substantially real-time, at predefined intervals, or on demand. Thus, as the activities, people, and content the user focuses on changes over time, the focus data included in a focus area changes as well (e.g., hourly, daily, or on demand).</p><p id="p-0025" num="0024">Technical advantages of the disclosed embodiments include automatically assisting users in achieving goals, monitoring the statuses of activities, and completing the activities. Since the focus data in a focus area changes over time based on the user's activities and the content associated with the activities, the challenges of staying up to date on the various activities are reduced. The focus data is provided to a user in a manner that assists the user in visualizing the activities and accessing different workflows to the activities. Additionally or alternatively, the embodiments enable a user to quickly locate current content as well as older content that relate to a particular focus area.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram of a first system in which aspects of the present disclosure may be practiced. The system <b>100</b> includes a computing device <b>102</b> that includes one or more storage devices (collectively referred to as storage device <b>104</b>) and one or more processing devices (collectively referred to as processing device <b>106</b>). The storage device <b>104</b> stores computer-executable instructions or one or more software applications <b>108</b>. A user <b>110</b> interacts with the software application(s) to perform various actions. The actions can include sending, receiving, redirecting, creating, modifying, deleting, and viewing electronic communications <b>112</b>. Example electronic communications include, but are not limited to, emails, text messages, instant messages, online chats, video messages, audio messages, and posts in social media.</p><p id="p-0027" num="0026">The actions may further include creating, deleting, viewing, and/or editing documents <b>114</b>, and organizing and/or attending in person and online meetings <b>116</b>. Other actions can include working on, or managing one or more projects <b>118</b> and setting, modifying, deleting, monitoring, and/or completing tasks <b>120</b>. Some of the tasks <b>120</b> may be related to or in advancement of the project(s) <b>118</b>, while other tasks can be related to other business or personal actions.</p><p id="p-0028" num="0027">These activities by the user <b>110</b> create, delete, and modify activity data <b>122</b>. The activity data <b>122</b> includes data such as emails, various types of documents, meetings and other calendar information, contacts (people), text messages, and the like. As will be described in more detail later, a focus analyzer application <b>124</b> is operable to analyze the activity data <b>122</b> produced, received, and/or stored over a given period of time (the &#x201c;focus time period&#x201d;) to generate one or more focus areas for the user <b>110</b>. At least some of the activity data <b>122</b> associated with a particular endeavor is grouped into a focus area. The data associated with a generated focus area is stored in focus data <b>126</b>.</p><p id="p-0029" num="0028">The focus time period can be any suitable amount of time, such as a week, a month, or three months. The focus time period may be the same for each focus area or the time period for at least one focus area can differ from another focus area. As some focus areas will have shorter lifespans than other focus areas, each focus time period is adjustable. In some embodiments, the user <b>110</b> may set the amount of time for each focus time period or the user <b>110</b> can reset the focus time period after a focus area is generated.</p><p id="p-0030" num="0029">A focus updater application <b>128</b> is operable to analyze the activity data <b>122</b> to determine select activity data to include in a focus area, where the select activity data is the focus data. For example, the focus data <b>126</b> can be the most recent (or more recent) activity data <b>122</b>, important activity data <b>122</b>, and/or the activity data <b>122</b> the user <b>110</b> spent the most time on during the focus time period. Additionally, the focus updater application <b>128</b> is operable to analyze the activity data <b>122</b> periodically, at selected times, and/or on demand to identify updates to the focus data <b>126</b> in one or more of the focus areas. In general, the focus updater application <b>128</b> analyzes the activity data <b>122</b> more frequently than the focus analyzer application <b>124</b>. In one embodiment, the focus updater application <b>128</b> is operable to analyze the activity data <b>122</b> in real-time as the user <b>110</b> interacts with the computing device <b>102</b>. In another embodiment, the focus updater application <b>128</b> is operable to analyze the data <b>122</b> at selected times to update the focus data <b>126</b>.</p><p id="p-0031" num="0030">The focus analyzer application <b>124</b> and the focus updater application <b>128</b> are implemented as one software application or as different software applications. In some embodiments, one or both of the focus analyzer application <b>124</b> and the focus updater application <b>128</b> include machine learning mechanisms (e.g., models, algorithms, or applications) that are adaptable over time. The focus analyzer application <b>124</b> and/or the focus updater application <b>128</b> learns over time and becomes more efficient and effective at generating focus areas and/or updating focus areas. The machine learning mechanism(s) learn over time based on the user's <b>110</b> interactions with the presentation of the focus areas, the user's <b>110</b> adjustments to the focus areas, adjustments to the focus data <b>126</b>, adjustments to the activity data <b>122</b>, and other types of user interactions.</p><p id="p-0032" num="0031">In a non-limiting nonexclusive example, a topic the user <b>110</b> focuses on over a period of time is a task the user <b>110</b> is working on with two additional persons A and B. The user <b>110</b> and the persons A and B have exchanged electronic communications regarding the task. The user <b>110</b> has also created a document for the task and edited a second document that was produced by the person A. Thus, a focus area may be generated for the task that includes some or all of the electronic communications, the first document, the second document as well as the identities of the user <b>110</b>, the person A, and the person B.</p><p id="p-0033" num="0032">Some or all of the generated focus areas are provided to one or more output devices (collective referred to as output device <b>130</b>). The output device <b>130</b> can be included in the computing device <b>102</b> or the output device <b>130</b> may be operably connected to the computing device <b>102</b>. An example output device includes, but is not limited to, a display device, a speaker, a printer, and a display screen included or operably connected to a second computing device (e.g., a tablet, a mobile phone).</p><p id="p-0034" num="0033">In one embodiment, the focus areas are presented to the user <b>110</b> based on the context of the user <b>110</b>. The context of the user <b>110</b> is based on one or more factors. The application(s) the user has opened or is interacting with can be one factor. Another factor may be what actions the user is performing prior to or in parallel with the presentation of the focus areas. In a non-limiting nonexclusive example, the focus data in the focus areas is arranged into one view when the user <b>110</b> is working in one application, such as an email application. The same focus areas or different focus areas are arranged into another view when the user <b>110</b> is working in another application, such as a collaborative application.</p><p id="p-0035" num="0034">The computing device <b>102</b> can be any suitable type of computing device. Example computing devices include a laptop computer, a tablet, a mobile telephone, a smart phone, a smart watch, a wearable computer, a desktop computer, a gaming device/computer (e.g., Xbox), a television, or a server computing device. These example computing devices are for example purposes only and should not be considered as limiting.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a block diagram of a second system in which aspects of the present disclosure may be practiced. The system <b>200</b> is a distributed system that includes the computing device <b>102</b>, a second computing device <b>202</b>, and a third computing device <b>204</b>. The second and the third computing devices <b>202</b>, <b>204</b> are each operably connected to the computing device <b>102</b> through one or more networks (collectively network <b>206</b>).</p><p id="p-0037" num="0036">The second computing device <b>202</b> includes one or more storage devices (collectively storage device <b>208</b>) that stores applications <b>210</b> (e.g., at least some of the applications <b>108</b>), the focus analyzer application <b>124</b>, and the focus data <b>126</b>. One or more processing devices (collectively processing device <b>212</b>) are operable to execute the applications <b>210</b> and the focus analyzer application <b>124</b>. One or more storage devices (storage device <b>214</b>) are operably connected to the second computing device <b>202</b> and to the third computing device <b>204</b> through one or more networks (collectively network <b>216</b>). The storage device <b>214</b> stores the activity data <b>122</b> that the focus analyzer application <b>124</b> and the focus updater application <b>128</b> analyze to generate the focus areas. Thus, during execution of the focus analyzer application <b>124</b>, the focus analyzer application <b>124</b> is operable to access the activity data <b>122</b> over the network <b>216</b> to generate the focus areas.</p><p id="p-0038" num="0037">The third computing device <b>204</b> includes one or more storage devices (collectively storage device <b>218</b>) that store the focus updater application <b>128</b>. One or more processing devices (collectively processing device <b>220</b>) are operable to execute the focus updater application <b>128</b>. The focus updater application <b>128</b> is operable to access the focus data <b>126</b> through the network <b>206</b> to update the focus data <b>126</b> in one or more of the focus areas. The focus updater application <b>128</b> is also operable to access the activity data <b>122</b> through the network <b>216</b> to analyze the activity data <b>122</b> and update the focus data <b>126</b> in one or more of the focus areas.</p><p id="p-0039" num="0038">Networks <b>206</b>, <b>216</b> are illustrative of any suitable type of network, for example, an intranet, and/or a distributed computing network (e.g., the Internet) over which the computing devices <b>102</b>, <b>202</b>, <b>204</b> may communicate with each other and with the storage devices <b>214</b>. Additionally, the computing devices <b>202</b>, <b>204</b> can each be any suitable computing device, such as a mobile telephone, a smart phone, a tablet, a smart watch, a wearable computer, a personal computer a desktop computer, a laptop computer, a gaming device/computer (e.g., Xbox), a television, or a server computing device. Although <figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts three computing devices <b>102</b>, <b>202</b>, <b>204</b> and one storage device <b>214</b>, other embodiments are not limited to this configuration. The system <b>200</b> can include any suitable number of computing devices and/or storage devices.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a flowchart of a method of generating focus areas in accordance with some embodiments. Initially, as shown in block <b>300</b>, the activity data associated with a user's activities (e.g., activity data <b>122</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>), or with the user's activities and the activities associated with one or more other persons, over the focus time period is analyzed. As noted earlier, the focus time period can be any suitable time period, such as one minute, one hour, one week, or one month. One or more persons, businesses, organizations, and/or departments (&#x201c;entities&#x201d;) and content are identified in the activity data at block <b>302</b>.</p><p id="p-0041" num="0040">The relationships between the content and the one or more entities identified at block <b>302</b> (e.g., person, document, email, organization, project) are determined at block <b>304</b>. For example, when the user drafts, edits or views a document (e.g., an activity), a relationship exists between the user and the document. Relationships can also exist between the document and other persons who interacted with the document. Additionally, the document may have been prepared as part of a task or a project. Thus, a relationship exists between the document and the task or project.</p><p id="p-0042" num="0041">In some embodiments, the operations in blocks <b>302</b> and <b>304</b> construct a graph, where the nodes in the graph represent items (e.g., a person, a document, an organization, an email, a project, etc.) and the edges represent relationships between the nodes. <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example node-edge graph in accordance with some embodiments. The example nodes represent entities (E), documents (D), communications (C), tasks (T), and projects (P). The node-edge graphs in other embodiments can include additional or different nodes.</p><p id="p-0043" num="0042">Entities include persons, organizations, departments, and the like. Documents (D) include, but are not limited to, word processing documents, and spreadsheet documents, presentation documents, and transcripts of meetings. Communications (C) include emails, text messages, instant messages, and online chats. Tasks (T) include any suitable activities performed as part of a goal or a project. The work or completion of a task can produce documents, communications, and other data. The tasks further include activities such as in-person or online meetings, appointments, and events. Projects relate to the work or tasks that are directed at an objective (e.g., new product development).</p><p id="p-0044" num="0043">As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the node-edges graph <b>400</b> includes entity nodes <b>402</b>, <b>404</b>, <b>406</b>, <b>408</b>, document nodes <b>410</b>, <b>412</b>, <b>414</b>, task nodes <b>416</b>, <b>418</b>, project node <b>420</b>, and communication node <b>422</b>. An edge <b>424</b> connects the node <b>402</b> to the node <b>416</b> and represents a relationship (&#x201c;worked on&#x201d;) between the entity E<b>1</b> and the task T<b>1</b>, where the entity E<b>1</b> (e.g., a person) worked on the task T<b>1</b>. An edge <b>426</b> connects the node <b>414</b> to the node <b>416</b> and represents a relationship (&#x201c;relates to&#x201d;) between the document D<b>3</b> and the task T<b>1</b>, where the document D<b>3</b> relates to the task T<b>1</b>. An edge <b>428</b> connects the node <b>402</b> to the node <b>410</b> and represents a relationship (&#x201c;edited&#x201d;) between the entity E<b>1</b> and the document D<b>1</b>, where the entity E<b>1</b> edited the document D<b>1</b>. An edge <b>430</b> connects the node <b>402</b> to the node <b>412</b> and represents a relationship (&#x201c;viewed&#x201d;) between the entity E<b>1</b> and the document D<b>2</b>, where the entity E<b>1</b> viewed the document D<b>2</b>. An edge <b>432</b> connects the node <b>404</b> to the node <b>410</b> and represents a relationship (&#x201c;viewed&#x201d;) between the entity E<b>2</b> and the document D<b>1</b>, where the entity E<b>2</b> viewed the document D<b>1</b>. An edge <b>434</b> connects the node <b>412</b> to the node <b>422</b> and represents a relationship (&#x201c;attached to&#x201d;) between the document D<b>2</b> and the communication Cl, where the document D<b>2</b> is attached to the communication Cl. An edge <b>436</b> connects the node <b>406</b> to the node <b>412</b> and represents a relationship (&#x201c;viewed&#x201d;) between the entity E<b>3</b> and the document D<b>2</b>, where the entity E<b>3</b> viewed the document D<b>2</b>. An edge <b>438</b> connects the node <b>406</b> to the node <b>422</b> and represents a relationship (&#x201c;sent&#x201d;) between the entity E<b>3</b> and the communication Cl, where the entity E<b>3</b> sent the communication Cl. An edge <b>440</b> connects the node <b>406</b> to the node <b>418</b> and represents a relationship (&#x201c;completed&#x201d;) between the entity E<b>3</b> and the task T<b>2</b>, where the entity E<b>3</b> completed the task T<b>2</b>. An edge <b>442</b> connects the node <b>406</b> to the node <b>420</b> and represents a relationship (&#x201c;works on&#x201d;) between the entity E<b>3</b> and the project P<b>1</b>, where the entity E<b>3</b> works on the project P<b>1</b>. An edge <b>444</b> connects the node <b>408</b> to the node <b>418</b> and represents a relationship (&#x201c;worked on&#x201d;) between the entity E<b>4</b> and the task T<b>2</b>, where the entity E<b>4</b> worked on the task T<b>2</b>. An edge <b>446</b> connects the node <b>408</b> to the node <b>420</b> and represents a relationship (&#x201c;is part of&#x201d;) between the task T<b>2</b> and the project P<b>1</b>, where the task T<b>2</b> is part of the project P<b>1</b>. An edge <b>448</b> connects the node <b>418</b> to the node <b>420</b> and represents a relationship (&#x201c;works on&#x201d;) between the entity E<b>4</b> and the project P<b>1</b>, where the entity E<b>4</b> works on the project P<b>1</b>. An edge <b>450</b> connects the node <b>408</b> to the node <b>414</b> and represents a relationship (&#x201c;viewed&#x201d;) between the entity E<b>4</b> and the document D<b>3</b>, where the entity E<b>4</b> viewed the document D<b>3</b>.</p><p id="p-0045" num="0044">Next, as shown in block <b>306</b>, one or more weights are applied to some or all of the nodes in the node-edge graph <b>400</b>. In one embodiment, a weight captures the amount of attention, time, and effort the user spends, or is likely to spend on the item(s) represented by the node(s). Additionally or alternatively, a weight may represent how recently the user interacted with the item represented by the node. Generally, recent interactions can be assigned higher weights than older interactions.</p><p id="p-0046" num="0045">The strengths of the relationships between the items (e.g., the nodes) are determined at block <b>308</b>. Factors that can be considered when determining the strength of a relationship include, but are not limited to, the semantic similarity between the subject matter of the items represented by the nodes, the amount of time the user spent on the item represented by a node (e.g., how much time a user spent on a document), the recency of the interaction(s) with the items within the focus time period, the number of interactions, the people involved, and the subject matter of the communications and tasks (where related subject matter produces a stronger relationship). Another factor may be the number of overlaps between the people involved. For example, the higher the number of overlaps between E<b>1</b> and E<b>3</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref> the stronger the relationship between the E<b>1</b> and E<b>3</b>. For example, in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the entity E<b>1</b> and the entity E<b>3</b> both interacted with document D<b>2</b>, which is one overlap. In contrast, there are no overlaps between the entity E<b>3</b> and the entity E<b>4</b>. Thus, the relationship between the entities E<b>1</b>, E<b>3</b> may be stronger than the relationship between the entities E<b>3</b>, E<b>4</b>.</p><p id="p-0047" num="0046">In embodiments that apply weights to the items (e.g., nodes) at block <b>306</b>, the weights may impact the relationship strength considerations, where the weights can be positive or negative. A positive weight can be used to increase the strength of a relationship, while a negative weight can be used to decrease the strength of the relationship.</p><p id="p-0048" num="0047">Additionally or alternatively, the temporal relationship between two items can be a factor. For example, if the entity E<b>1</b> accesses document D<b>1</b> and document D<b>2</b> (<figref idref="DRAWINGS">FIG. <b>4</b></figref>) close in time, the temporal relationship between the accesses indicates the documents are related and the strength of the relationship between the two documents D<b>1</b>, D<b>2</b> can be increased. Similarly, if the entity E<b>1</b> accesses document D<b>1</b> and document D<b>2</b> (<figref idref="DRAWINGS">FIG. <b>4</b></figref>) farther apart in time, the temporal relationship indicates the documents may or may not be related and the strength of the relationship between the two documents D<b>1</b>, D<b>2</b> can be reduced.</p><p id="p-0049" num="0048">In some embodiments, the storage locations for the documents, the communications, and the data associated with the activities performed for the tasks and projects, as well as the storage locations of the data generated by the entities may be factors to consider. As one example, when the data is stored in the same storage location or in related storage locations, the strengths of the relationships between the data can be stronger compared to the relationships for data that is stored in separate or unassociated storage locations.</p><p id="p-0050" num="0049">Referring again to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the items (e.g., the entities and the content) are grouped into one or more focus areas at block <b>310</b>. In one example embodiment, the focus area(s) is formed based on topic modeling techniques that use people as the words. Additionally or alternatively, the one or more focus areas are formed using the people and select phrases or topics as the words.</p><p id="p-0051" num="0050">In other embodiments, the one or more focus areas are formed using an algorithm or algorithms that find communities in a graph based on optimizing a quantity known as Newmans Modularity. Other embodiments can use additional or other techniques for forming the focus area(s).</p><p id="p-0052" num="0051">In a non-limiting nonexclusive embodiment, N sets of people that the user works with on separate activities is determined, where N is any suitable number. Each set of people may include one or more people. For example, three (3) to ten (10) sets of people are detected in one embodiment. For each set of people, the activities performed by the user and the people in the set are determined. The activities can be the activities that the user or another person spent time on during the focus time period. Additionally or alternatively, a number of activities, select phrases and/or words in the data are determined. The activities, phrases, and/or words can be used to determine which data is related to particular focus areas (e.g., particular activities and/or content).</p><p id="p-0053" num="0052">In some embodiments, the clustering is performed using embeddings that represent the people and the content (e.g., documents, emails). Since the embeddings are vectors, it is easier to apply further machine learning applications to the vectors, including clustering. For example, in one aspect a neural-net based clustering method is used to cluster the items (e.g., the nodes).</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates clusters of nodes in the node-edge graph shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> in accordance with some embodiments. The example node clusters are grouped into four clusters, CL<b>1</b>, CL<b>2</b>, CL<b>3</b>, and CL<b>4</b>. Each cluster CL<b>1</b>, CL<b>2</b>, CL<b>3</b>, and CL<b>4</b> represents a focus area. Thus, in the illustrated example, there are four focus areas.</p><p id="p-0055" num="0054">At block <b>312</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the focus areas are then populated with data associated with the focus areas. In one embodiment, the focus updater application <b>128</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref> detects the most recent, the important, and/or the time-consuming activities to be included in the focus areas. As discussed earlier, the focus areas in some embodiments operate as feeds where the data included in the focus areas is determined or updated in real-time or at selected times. Thus, block <b>312</b> repeats at certain intervals or at selected times in such embodiments.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a flowchart of a first method of presenting focus areas in accordance with some embodiments. Generally, the method shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is executed after the focus areas have been determined. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is described in conjunction with a current focus area. Other embodiments can identify and produce multiple focus areas.</p><p id="p-0057" num="0056">Initially, as shown in block <b>600</b>, a context of a user is determined. In one embodiment, the context is used to detect a current focus area the user is working on at the time. For example, the user can be drafting a document that is related to task A. The system may detect this based on the subject matter of the document, the storage location of the document, the person or people who have interacted with the document, and/or other factors associated with the document.</p><p id="p-0058" num="0057">Next, as shown in block <b>602</b>, the focus data for the current focus area is arranged in the focus area. In some instances, only a select amount of the focus data may be provided in the current focus area based on the available area in a GUI that will be used to display the focus area. Additionally or alternatively, the focus data in the top M activities may be presented, where M is a number that is greater than or equal to one. In some instances, the focus data presented in the current focus area is based on the application the user is using at the time. For example, if the user is drafting an email, one or more additional emails may be presented in the current focus area, where the one or more additional emails are associated with the current focus area and are emails that were drafted, received, forwarded, and/or replied to by the user.</p><p id="p-0059" num="0058">At block <b>604</b>, the current focus area is provided to one or more output devices for presentation. In one embodiment, the current focus area is displayed in the user interface of the software application open or launched at the time. A determination is made at block <b>606</b> as to whether the focus data in the current focus area is to be updated in the presentation. The focus data can be updated based on several factors. First, the focus updater application <b>128</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may have detected more recent activity data that is associated the focus area. Additionally or alternatively, a user can adjust or customize the focus data presented in the focus area. For example, a user can move (e.g., drag) focus data into the displayed focus area, or the user may remove or delete focus data from the focus area. In one embodiment, a user can delete focus data by selecting the focus data that is displayed in the focus area and selecting a delete menu option (see <figref idref="DRAWINGS">FIG. <b>7</b></figref>), or right-clicking on the focus data and selecting a delete option in a contextual menu to remove the focus data. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the user may select or deselect the subject matter to be considered when generating the focus areas or updating the focus areas. The selection or deselection of the subject matter can be performed, for example, in a settings menu.</p><p id="p-0060" num="0059">If a determination is made at block <b>606</b> that the focus data in the current focus area will not be updated, the method waits at block <b>606</b>. When a determination is made at block <b>606</b> that the focus data in the current focus area will be updated, the method continues at block <b>608</b> where the focus data is updated, which in turn modifies the focus data presented in the focus area.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example GUI that presents focus areas in a first context in accordance with some embodiments. The GUI <b>700</b> is an example GUI of a collaborative application that presents two focus areas <b>702</b>, <b>704</b>. In one embodiment, the focus areas <b>702</b>, <b>704</b> are displayed when the collaborative application is first launched. In other embodiments, the focus areas <b>702</b>, <b>704</b> are presented when the user <b>706</b> enters the phrase &#x201c;focus areas&#x201d; in the search tool <b>708</b>, searches for an item using the search tool <b>708</b> (e.g., Project A), and/or in response to the user <b>706</b> selecting the icon <b>709</b>.</p><p id="p-0062" num="0061">As discussed previously, the focus areas <b>702</b>, <b>704</b> display focus data that relate to a particular endeavor of the user. In a non-limiting example, the focus data is the most recent (or more recent) activity data <b>122</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>), important activity data <b>122</b>, and/or the activity data <b>122</b> the user <b>110</b> spent the most time on during the focus time period. In the illustrated embodiment, the focus area <b>702</b> presents focus data associated with Project A and the focus area <b>704</b> displays focus data associated with Task A. The graphics <b>716</b>, <b>718</b>, and <b>720</b> may each be an image of the person or an image or representation (e.g., an avatar) selected by the person.</p><p id="p-0063" num="0062">The focus data in the focus area <b>702</b> includes listings <b>710</b>, <b>712</b>, <b>714</b>. Each listing <b>710</b>, <b>712</b>, <b>714</b> provides information on a recent activity that is associated with Project A. For example, the example listing <b>710</b> relates to a mention of the user <b>706</b> in a communication by the person <b>716</b> named Tom S. The communication can be an email, a text message, or an online chat. The listing <b>710</b> may provide additional information on the communication, including the date and/or time of the communication, select text in the communication that mentions or relates to the user <b>706</b> (e.g., &#x201c;can you take a look at this . . . &#x201d;), and/or additional people that are mentioned in or were recipients of the communication.</p><p id="p-0064" num="0063">The listing <b>712</b> relates to a communication to the user <b>706</b> from the person <b>718</b> named Kathy. The listing <b>712</b> specifies the communication is a reply email that was received from Kathy at 2:24 pm. Tom and two other people (+2) also received the email.</p><p id="p-0065" num="0064">The listing <b>714</b> relates to a document entitled &#x201c;Budget Review&#x201d; that is associated with Project A. The listing <b>714</b> specifies the document was modified by the person <b>720</b> (&#x201c;Mary&#x201d;) yesterday. An icon <b>722</b> that represents the document is included in the listing <b>714</b>. In some embodiments, the icon <b>722</b> is a link that when selected by the user <b>706</b>, causes the document to open or causes presentation of the folder that stores the document.</p><p id="p-0066" num="0065">The display of the focus area <b>702</b> provides an area <b>724</b> that displays graphics of the people <b>716</b>, <b>718</b>, <b>720</b> that are associated with the listings <b>710</b>, <b>712</b>, <b>714</b>. In some embodiments, the graphics are links that when selected present information on the person. Example information includes, but is not limited to, a phone number, an email address, and/or the person's title or role on Project A. Additionally or alternatively, the area <b>724</b> can display the graphics of other or additional people, such as people working on Project A, or people the user <b>706</b> has recently interacted with in the focus time period.</p><p id="p-0067" num="0066">The focus area <b>702</b> can also include an input element <b>726</b> that enables the user <b>706</b> to view more focus data related to Project A. The input element <b>726</b> can be any suitable type of input element, including, but not limited to, a button and a checkbox. When the input element <b>726</b> is selected, the focus area <b>702</b> can expand to include more focus data that is associated with Project A (e.g., see <figref idref="DRAWINGS">FIG. <b>10</b></figref>).</p><p id="p-0068" num="0067">The focus area <b>704</b> presents focus data associated with Task A. The focus data in the focus area <b>704</b> includes listings <b>728</b>, <b>730</b>, <b>732</b>. Each listing provides information on an activity (e.g., recent, important, and/or time intensive activity) that is associated with Task A. For example, the example listing <b>728</b> relates to a document entitled &#x201c;June Review.&#x201d; The document can be a presentation, a word processing document, a spreadsheet, or any other suitable type of document. The representative listing <b>728</b> provides additional information on the document, including the date of the review (Jun. 3, 2021) and a group of people who participated in the review (Team A). An icon <b>734</b> that represents the document is included in the listing <b>728</b>. In some embodiments, the icon <b>734</b> is a link to the document or to the storage location (e.g., the folder) of the document.</p><p id="p-0069" num="0068">The listing <b>730</b> relates to document entitled &#x201c;Task A Specifications.&#x201d; The listing <b>730</b> also indicates the document was updated on Jun. 3, 2021. In one embodiment, the activities in the listings <b>728</b>, <b>730</b> are related as indicated by the reference to the June review in listing <b>730</b>. The listing also includes an icon <b>736</b> that represents the document. In some embodiments, the icon <b>736</b> is a link to the document.</p><p id="p-0070" num="0069">The listing <b>732</b> relates to a transcript of the June meeting. The example transcript is an audio transcript, but other embodiments are not limited to this type of transcript. In some embodiments, the transcript can be a written transcript. An icon <b>738</b> that represents the audio transcript is included in the listing <b>732</b>. In some embodiments, the icon <b>738</b> is a link that when selected by the user <b>706</b>, causes an audio player to open to play the audio transcript, or causes the presentation of the folder that stores the audio transcript.</p><p id="p-0071" num="0070">As described previously, a user can adjust or customize the focus data presented in a focus area. For example, a user can move (e.g., drag) focus data into a displayed focus area (e.g., focus area <b>704</b>), or into the GUI <b>700</b> to cause a focus area that provides related focus data to be presented. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a user may delete a listing and/or a focus area by selecting (e.g., clicking on) the listing or the focus area and selecting a delete menu option <b>740</b>. Additionally or alternatively, the user can right-click on the listing, the focus area, and/or the GUI <b>700</b> and select a delete option that is presented in a contextual menu to delete the focus data. A user may add focus data (e.g., a listing and/or a focus area) by selecting an add menu option <b>742</b>. A file explorer or other file management tool can be displayed to enable the user <b>706</b> to select the focus data to be added to the GUI <b>700</b>.</p><p id="p-0072" num="0071">A user may also select or deselect the activities and/or activity data to be considered when generating the focus areas or updating the focus areas. In <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the user <b>706</b> can select the settings menu option <b>744</b> to cause a settings menu to be displayed. <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example GUI that enables a user to select data to be included in focus areas in accordance with some embodiments. The GUI <b>800</b> provides a user with a variety of activities and/or activity data to select for a focus area.</p><p id="p-0073" num="0072">The representative activity includes Task D, and the illustrated activity data includes an Email from Bob on Task A, a June Budget Meeting, a Project B Document, and an Entity C (e.g., a person or enterprise). The GUI <b>800</b> also includes an &#x201c;Other&#x201d; option. Different and/or additional activities and/or activity data can be shown in other embodiments.</p><p id="p-0074" num="0073">An input element <b>802</b> is provided for each activity or activity data. The input element <b>802</b> enables the user to select the activity or activity data that the user prefers for a focus area. In one embodiment, the selection of an activity or activity data does not guarantee that a focus area associated with the activity and/or activity data will be generated. Instead, the selection of the activity and/or activity data indicates the focus area associated with the activity or activity data is to be considered when the focus areas are generated. Each input element <b>802</b> can be any suitable type of input element, including a checkbox, a toggle switch, a drop-down menu, and a radio button.</p><p id="p-0075" num="0074">The activity of &#x201c;Task D&#x201d; further includes an input element <b>804</b> that enables the user to set the amount of time for the focus time period for that activity. Like the input element <b>802</b>, the input element <b>804</b> can be any suitable type of input element, including a drop-down menu and a text field. Although the input element <b>804</b> is only shown with &#x201c;Task D&#x201d; in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the input element <b>804</b> can be included with additional activities and/or activity data in other embodiments. Additionally or alternatively, the GUI <b>800</b> can include an input element <b>804</b> that enables the user to enter an amount of time that acts as a default focus time period for all of the activity(ies) and/or activity data.</p><p id="p-0076" num="0075">When the input element <b>802</b> for &#x201c;Other&#x201d; is selected, a user is enabled to select an activity or a particular activity data using the input element <b>806</b>. The input element <b>806</b> may be any suitable type of input element, including a drop-down menu and a text field. In some embodiments, selection of the input element <b>806</b> can cause a file explorer or other file management tool to be presented to enable the user to locate and select the activity data. Alternatively, the input element <b>806</b> may be a drop-down menu or other type of contextual menu that enables the user to select a software application to launch or open. Once open, the user may select the activity data through the GUI of the software application. For example, a user can select an email software application to open and then select one or more emails.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a flowchart of a second method of presenting focus areas in accordance with some embodiments. As described earlier, the focus areas can be selected for presentation based on a context associated with the user. In some instances, the display of the focus areas is modified for a new context when the context changes. The method shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts an example method of presenting focus areas in different contexts.</p><p id="p-0078" num="0077">Initially, as shown in block <b>900</b>, one or more focus areas are arranged and presented based on a first context. As discussed earlier, the context is used to detect one or more current focus areas the user is working on at the time. A determination is made at block <b>902</b> as to whether the user is in, or is associated with, a new context. If not, the method waits at block <b>902</b>. When a determination is made at block <b>902</b> that the user in a new context, the method continues at block <b>904</b> where the focus data (e.g., focus data <b>126</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) is analyzed to provide the focus data for the focus area(s) associated with the new context.</p><p id="p-0079" num="0078">Next, as shown in block <b>906</b>, the focus area(s) and the focus data within each focus area are arranged into a presentation. For example, only a select amount of the focus data may be provided in a focus area based on the available area in a GUI that will be used to display the focus area. Additionally or alternatively, the focus data in the top M activities may be presented, where M is a number that is greater than or equal to one. The one or more focus areas are provided to one or more output devices for presentation in the new context (block <b>908</b>).</p><p id="p-0080" num="0079">In some embodiments, the new context is based on a software application the user has opened or closed. <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an example GUI that presents one or more focus areas in accordance with some embodiments. The example GUI <b>1000</b> is a personal information management software application that includes email <b>1002</b>, a calendar <b>1004</b>, and contacts <b>1006</b>. The GUI <b>1000</b> presents several focus areas.</p><p id="p-0081" num="0080">The panel <b>1008</b> displays a communication <b>1010</b> that is associated with a new focus area (section <b>1012</b>). The section <b>1014</b> presents a document <b>1016</b> entitled Project A and a document <b>1018</b> entitled Task B Planning. The documents <b>1016</b>, <b>1018</b> are associated with active focus areas, or the focus areas in which the user and/or other persons are currently working on and producing new activity data that may be included in the focus areas. The section <b>1020</b> displays a communication <b>1022</b> that has been archived. The communication <b>1022</b>, as well as other types of data, may be archived based on one or more factors. Data can be archived based on how much time has passed since any person (e.g., the user) performed an activity that is associated with the focus area, the completion of a project or a task, and/or whether the user is no longer associated with the focus area (e.g., no longer working or a part of Project B). The archive section <b>1020</b> enables the user to find data in the focus areas that are no longer active. In one embodiment, the data associated with an archived focus area is stored in the focus data (e.g., focus data <b>126</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>). The length of time in which the data in the archived focus areas is stored can be selected by a user, may be a default amount of time, or can be based on a data storage compliance policy.</p><p id="p-0082" num="0081">A panel <b>1024</b> in the GUI <b>1000</b> is used to present additional focus data about a particular focus area. The panel <b>1024</b> includes one or more tabs that are used to organize the focus data. In the illustrated embodiment, the panel <b>1024</b> includes an Overview tab <b>1026</b>, a Content tab <b>1028</b>, a Tasks tab <b>1030</b>, and a People tab <b>1032</b>. When the Overview tab <b>1026</b> is selected (as shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>), the panel <b>1024</b> presents an overview of recent activities that are associated with Project A. For example, the document <b>1016</b> in the panel <b>1008</b> is selected, as indicated by the dotted box. In response to the selection of the document <b>1016</b>, additional focus data about Project A is presented in the panel <b>1024</b>.</p><p id="p-0083" num="0082">The Overview includes a listing <b>1034</b> for an online chat related to Project A (and referenced in the listing <b>1016</b>). The listing can include information such as the date and time of the chat and the participants in the chat. The illustrated information includes an excerpt of the chat to provide the user with a brief overview of the subject matter of the chat.</p><p id="p-0084" num="0083">A listing <b>1036</b> for a meeting related to Project A is also displayed in the panel <b>1024</b>. The information in the listing <b>1036</b> specifies the title of the meeting, the time of the meeting, the people in the meeting, and that the user is also invited to the meeting. A link <b>1038</b> to a calendar invite or calendar software application is attached to the listing <b>1036</b>.</p><p id="p-0085" num="0084">The Content tab <b>1028</b>, when selected, can display different types of recent content that is associated with Project A. The content can include documents, communications, and the like. Different tasks associated with Project A are presented in the panel <b>1024</b> when the Tasks tab <b>1030</b> is selected. The people associated with Project A are displayed in the panel <b>1024</b> when the People tab <b>1032</b> is selected. In some embodiments, information for the people is also displayed, such as phone numbers, email addresses, and the function or title of the person on Project A.</p><p id="p-0086" num="0085">The panel <b>1024</b> can also present a section <b>1040</b> that provides information about Project A. In the illustrated embodiment, the information includes a description of Project A, the people associated with Project A, and one or more terms <b>1042</b> for Project A. The terms &#x201c;Term A&#x201d;, &#x201c;Term B&#x201d;, and &#x201c;Term C&#x201d; can be used to review the activity data (e.g., activity data <b>122</b> in FIG. <b>1</b>) when generating and/or updating the focus areas. In some instances, a user can edit the terms to add or delete terms via the section <b>1040</b>. For example, a user can type in a new term into the section <b>1040</b>.</p><p id="p-0087" num="0086">In other embodiments, instead of displaying the panels <b>1008</b>, <b>1024</b>, the GUI <b>1000</b> can present less information for the focus areas, or can display the icon <b>709</b> or a small panel <b>1044</b> that the user can select to cause some or all of the panels <b>1008</b>, <b>1024</b> to be displayed. As noted earlier, the arrangement of the focus areas, the amount of focus data provided in each focus area, and amount of space used in the GUI to present the focus areas can be based on the context of the user.</p><p id="p-0088" num="0087"><figref idref="DRAWINGS">FIGS. <b>11</b>-<b>13</b></figref> and the associated descriptions provide a discussion of a variety of operating environments in which aspects of the disclosure may be practiced. However, the devices and systems illustrated and discussed with respect to <figref idref="DRAWINGS">FIGS. <b>11</b>-<b>13</b></figref> are for purposes of example and illustration and are not limiting of a vast number of electronic device configurations that may be utilize for practicing aspects of the disclosure, as described herein.</p><p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a block diagram illustrating physical components (e.g., hardware) of an electronic device with which aspects of the disclosure may be practiced. In a basic configuration, the electronic device <b>1100</b> may include at least one processing device <b>1102</b> and a memory <b>1104</b>. Any suitable processing device <b>1102</b> can be used. For example, the processing device <b>1102</b> may be a microprocessor, an application specific integrated circuit, a field programmable gate array, or combinations thereof.</p><p id="p-0090" num="0089">Depending on the configuration and type of the electronic device <b>1100</b>, the memory <b>1104</b> may comprise, but is not limited to, volatile storage (e.g., random access memory), non-volatile storage (e.g., read-only memory), flash memory, or any combination of such memories. The memory <b>1104</b> may include a number of program modules and data files, such as an operating system <b>1106</b>, program modules <b>1108</b>, and a focus area software application <b>1110</b>. While executing on the processing device <b>1102</b>, the focus area software application <b>1110</b> may perform and/or cause to be performed processes including, but not limited to, the aspects as described herein.</p><p id="p-0091" num="0090">The operating system <b>1106</b>, for example, may be suitable for controlling the operation of the electronic device <b>1100</b>. Furthermore, embodiments of the disclosure may be practiced in conjunction with a graphics library, other operating systems, or any other application program and is not limited to any particular application or system. This basic configuration is illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref> by those components within a dashed line <b>1112</b>.</p><p id="p-0092" num="0091">The electronic device <b>1100</b> may have additional features or functionality. For example, the electronic device <b>1100</b> may also include additional data storage devices (removable and/or non-removable) such as, for example, magnetic disks, optical disks, or tape. Such additional storage is illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref> by a removable storage device <b>1114</b> and a non-removable storage device <b>1116</b>.</p><p id="p-0093" num="0092">The electronic device <b>1100</b> may also have one or more input device(s) <b>1118</b> such as a keyboard, a trackpad, a mouse, a pen, a sound or voice input device, a touch, force and/or swipe input device, etc. The output device(s) <b>1120</b> such as a display, speakers, a printer, etc. may also be included. The aforementioned devices are examples and others may be used. The electronic device <b>1100</b> may include one or more communication devices <b>1122</b> allowing communications with other electronic devices <b>1124</b>. Examples of suitable communication devices <b>1122</b> include, but are not limited to, radio frequency (RF) transmitter, receiver, and/or transceiver circuitry; universal serial bus (USB), parallel, and/or serial ports.</p><p id="p-0094" num="0093">The term computer-readable media as used herein may include storage media or devices. The storage media or devices may include volatile and nonvolatile, removable, and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, or program modules.</p><p id="p-0095" num="0094">The memory <b>1104</b>, the removable storage device <b>1114</b>, and the non-removable storage device <b>1116</b> are all examples of storage devices. Each storage device may include RAM, ROM, electrically erasable read-only memory (EEPROM), flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other article of manufacture which can be used to store information and which can be accessed by the electronic device <b>1100</b>. Any such storage device may be part of the electronic device <b>1100</b>. In one embodiment, the storage device does not include a carrier wave or other propagated or modulated data signal.</p><p id="p-0096" num="0095">Communication media may be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media. The term &#x201c;modulated data signal&#x201d; may describe a signal that has one or more characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media may include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared, and other wireless media.</p><p id="p-0097" num="0096">Furthermore, embodiments of the disclosure may be practiced in an electrical circuit comprising discrete electronic elements, packaged or integrated electronic chips containing logic gates, a circuit utilizing a microprocessor, or on a single chip containing electronic elements or microprocessors. For example, embodiments of the disclosure may be practiced via a system-on-a-chip (SOC) where each or many of the components illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref> may be integrated onto a single integrated circuit. Such an SOC device may include one or more processing units, graphics units, communications units, system virtualization units and various application functionality all of which are integrated (or &#x201c;burned&#x201d;) onto the chip substrate as a single integrated circuit.</p><p id="p-0098" num="0097">When operating via an SOC, the functionality described herein, with respect to the capability of client to switch protocols may be operated via application-specific logic integrated with other components of the electronic device <b>1100</b> on the single integrated circuit (chip). Embodiments of the disclosure may also be practiced using other technologies capable of performing logical operations such as, for example, AND, OR, and NOT, including but not limited to mechanical, optical, fluidic, and quantum technologies. In addition, embodiments of the disclosure may be practiced within a general-purpose computer or in any other circuits or systems.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIGS. <b>12</b>A-<b>12</b>B</figref> illustrate a mobile electronic device <b>1200</b>, for example, a mobile telephone, a smart phone, wearable computer (such as a smart watch), a tablet computer, a laptop computer, and the like, with which embodiments of the disclosure may be practiced. With reference to <figref idref="DRAWINGS">FIG. <b>12</b>A</figref>, one aspect of a mobile electronic device <b>1200</b> for implementing the aspects described herein is illustrated.</p><p id="p-0100" num="0099">In a basic configuration, the mobile electronic device <b>1200</b> is a handheld computer having both input elements and output elements. The mobile electronic device <b>1200</b> typically includes a display <b>1202</b> and one or more input buttons <b>1204</b> that allow the user to enter information into the mobile electronic device <b>1200</b>. The display <b>1202</b> of the mobile electronic device <b>1200</b> may also function as an input device (e.g., a display that accepts touch and/or force input).</p><p id="p-0101" num="0100">If included, an optional side input element <b>1206</b> allows further user input. The side input element <b>1206</b> may be a rotary switch, a button, or any other type of manual input element. In alternative aspects, mobile electronic device <b>1200</b> may incorporate more or less input elements. For example, the display <b>1202</b> may not be a touch screen in some embodiments. In yet another alternative embodiment, the mobile electronic device <b>1200</b> is a portable phone system, such as a cellular phone. The mobile electronic device <b>1200</b> may also include an optional keypad <b>1208</b>. Optional keypad <b>1208</b> may be a physical keypad or a &#x201c;soft&#x201d; keypad generated on the touch screen display.</p><p id="p-0102" num="0101">In various embodiments, the output elements include the display <b>1202</b> for showing a graphical user interface (GUI) of a client or developer portal, a visual indicator <b>1210</b> (e.g., a light emitting diode), and/or an audio transducer <b>1212</b> (e.g., a speaker). In some aspects, the mobile electronic device <b>1200</b> incorporates a vibration transducer for providing the user with tactile feedback. In yet another aspect, the mobile electronic device <b>1200</b> incorporates input and/or output ports, such as an audio input (e.g., a microphone jack), an audio output (e.g., a headphone jack), and a video output (e.g., a HDMI port) for sending signals to or receiving signals from an external device.</p><p id="p-0103" num="0102"><figref idref="DRAWINGS">FIG. <b>12</b>B</figref> is a block diagram illustrating the architecture of one aspect of a mobile electronic device <b>1200</b>. That is, the mobile electronic device <b>1200</b> can incorporate a system (e.g., an architecture) <b>1214</b> to implement some aspects. In one embodiment, the system <b>1214</b> is implemented as a &#x201c;smart phone&#x201d; capable of running one or more applications (e.g., browser, email, calendaring, contact managers, messaging clients, games, media clients/players, diagramming, and sharing applications and so on). In some aspects, the system <b>1214</b> is integrated as an electronic device, such as an integrated personal digital assistant (PDA) and wireless phone.</p><p id="p-0104" num="0103">One or more application programs <b>1216</b> may be loaded into the memory <b>1218</b> and run on or in association with the operating system <b>1220</b>. Examples of the application programs include a phone dialer program, an electronic communication program (e.g., email program, instant message program), a triggering application program, a word processing program, a spreadsheet program, an Internet browser program, and so forth.</p><p id="p-0105" num="0104">The system <b>1214</b> also includes a non-volatile storage area <b>1222</b> within the memory <b>1218</b>. The non-volatile storage area <b>1222</b> may be used to store persistent information that should not be lost when the system <b>1214</b> is powered down.</p><p id="p-0106" num="0105">The application programs <b>1216</b> may use and store information in the non-volatile storage area <b>1222</b>, such as email, attachments or other messages used by an email application, and the like. A synchronization application (not shown) also resides on the system <b>1214</b> and is programmed to interact with a corresponding synchronization application resident on a host computer to keep the information stored in the non-volatile storage area <b>1222</b> synchronized with corresponding information stored at the host computer.</p><p id="p-0107" num="0106">The system <b>1214</b> has a power supply <b>1224</b>, which may be implemented as one or more batteries. The power supply <b>1224</b> may further include an external power source, such as an AC adapter or a powered docking cradle that supplements or recharges the batteries.</p><p id="p-0108" num="0107">The system <b>1214</b> may also include a radio interface layer <b>1226</b> that performs the function of transmitting and receiving radio frequency communications. The radio interface layer <b>1226</b> facilitates wireless connectivity between the system <b>1214</b> and the &#x201c;outside world,&#x201d; via a communications carrier or service provider. Transmissions to and from the radio interface layer <b>1226</b> are conducted under control of the operating system <b>1220</b>. In other words, communications received by the radio interface layer <b>1226</b> may be disseminated to the application programs <b>1216</b> via the operating system <b>1220</b>, and vice versa.</p><p id="p-0109" num="0108">The visual indicator <b>1210</b> may be used to provide visual notifications, and/or an audio interface <b>1228</b> may be used for producing audible notifications via an audio transducer (e.g., audio transducer <b>1212</b> illustrated in <figref idref="DRAWINGS">FIG. <b>12</b>A</figref>). In the illustrated embodiment, the visual indicator <b>1210</b> is a light emitting diode (LED) and the audio transducer <b>1212</b> may be a speaker. These devices may be directly coupled to the power supply <b>1224</b> so that when activated, they remain on for a duration dictated by the notification mechanism even though the processor <b>1230</b> and other components might shut down for conserving battery power. The LED may be programmed to remain on indefinitely until the user takes action to indicate the powered-on status of the device.</p><p id="p-0110" num="0109">The audio interface <b>1228</b> is used to provide audible signals to and receive audible signals from the user (e.g., voice input such as described above). For example, in addition to being coupled to the audio transducer <b>1212</b>, the audio interface <b>1228</b> may also be coupled to a microphone to receive audible input, such as to facilitate a telephone conversation.</p><p id="p-0111" num="0110">The system <b>1214</b> may further include a video interface <b>1232</b> that enables an operation of peripheral device <b>1234</b> (e.g., on-board camera) to record still images, video stream, and the like.</p><p id="p-0112" num="0111">A mobile electronic device <b>1200</b> implementing the system <b>1214</b> may have additional features or functionality. For example, the mobile electronic device <b>1200</b> may also include additional data storage devices (removable and/or non-removable) such as, magnetic disks, optical disks, or tape. Such additional storage is illustrated in <figref idref="DRAWINGS">FIG. <b>12</b>B</figref> by the non-volatile storage area <b>1222</b>.</p><p id="p-0113" num="0112">Data/information generated or captured by the mobile electronic device <b>1200</b> and stored via the system <b>1214</b> may be stored locally on the mobile electronic device <b>1200</b>, as described above, or the data may be stored on any number of storage media that may be accessed by the device via the radio interface layer <b>1226</b> or via a wired connection between the mobile electronic device <b>1200</b> and a separate electronic device associated with the mobile electronic device <b>1200</b>, for example, a server-computing device in a distributed computing network, such as the Internet (e.g., server computing device <b>1318</b> in <figref idref="DRAWINGS">FIG. <b>13</b></figref>). As should be appreciated such data/information may be accessed via the mobile electronic device <b>1200</b> via the radio interface layer <b>1226</b> or via a distributed computing network. Similarly, such data/information may be readily transferred between electronic devices for storage and use according to well-known data/information transfer and storage means, including email and collaborative data/information sharing systems.</p><p id="p-0114" num="0113">As should be appreciated, <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>12</b>B</figref> are described for purposes of illustrating the present methods and systems and is not intended to limit the disclosure to a particular sequence of steps or a particular combination of hardware or software components.</p><p id="p-0115" num="0114"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates a block diagram of a distributed system in which aspects of the disclosure may be practiced. The system includes a general computing device <b>1304</b> (e.g., a desktop computer), a tablet computing device <b>1306</b>, and/or a mobile computing device <b>1308</b>. The general computing device <b>1304</b>, the tablet computing device <b>1306</b>, and the mobile computing device <b>1308</b> can each include the components, or be connected to the components, that are shown associated with the electronic device <b>1100</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref> or the mobile electronic device <b>1200</b> in <figref idref="DRAWINGS">FIGS. <b>12</b>A-<b>12</b>B</figref>.</p><p id="p-0116" num="0115">The general computing device <b>1304</b>, the tablet computing device <b>1306</b>, and the mobile computing device <b>1308</b> are each configured to access one or more networks (represented by network <b>1310</b>) to interact with the focus area application <b>1312</b> (e.g., focus analyzer application and focus updater application) stored in one or more storage devices (represented by storage device <b>1314</b>) and executed on one or more server computing devices (represented by server computing device <b>1316</b>). In some aspects, the server computing device <b>1316</b> can access and/or receive various types of services, communications, documents and information transmitted from other sources, such as a web portal <b>1318</b>, an electronic communications services <b>1320</b>, directory services <b>1322</b>, instant messaging and/or text services <b>1324</b>, and/or social networking services <b>1326</b>. In some instances, these sources may provide robust reporting, analytics, data compilation and/or storage service, etc., whereas other services may provide search engines or other access to data and information, images, graphics, videos, document processing and the like.</p><p id="p-0117" num="0116">As should be appreciated, <figref idref="DRAWINGS">FIG. <b>13</b></figref> is described for purposes of illustrating the present methods and systems and is not intended to limit the disclosure to a particular sequence of steps or a particular combination of hardware or software components.</p><p id="p-0118" num="0117">Aspects of the present disclosure, for example, are described above with reference to block diagrams and/or operational illustrations of methods, systems, GUIs, and computer program products according to aspects of the disclosure. As discussed earlier, the operations noted in the blocks may occur out of the order as shown in any flowchart. For example, two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order, depending upon the functionality/acts involved. Additionally, the functionality or elements shown in one GUI can be used in another GUI, and vice versa.</p><p id="p-0119" num="0118">The description and illustration of one or more aspects provided in this application are not intended to limit or restrict the scope of the disclosure as claimed in any way. The aspects, examples, and details provided in this application are considered sufficient to convey possession and enable others to make and use the best mode of claimed disclosure. The claimed disclosure should not be construed as being limited to any aspect, example, or detail provided in this application. Regardless of whether shown and described in combination or separately, the various features (both structural and methodological) are intended to be selectively included or omitted to produce an embodiment with a particular set of features. Having been provided with the description and illustration of the present application, one skilled in the art may envision variations, modifications, and alternative aspects falling within the spirit of the broader aspects of the general inventive concept embodied in this application that do not depart from the broader scope of the claimed disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method, comprising:<claim-text>determining an endeavor that a user has focused on over a period of time, the endeavor comprising entities and content items;</claim-text><claim-text>determining relationships between the entities and the content items, wherein the relationships indicate interactions between the entities and the content items;</claim-text><claim-text>determining strengths of the relationships based on the interactions;</claim-text><claim-text>clustering a portion of the entities and the content items into a focus area based on the relationships;</claim-text><claim-text>populating the focus area with focus data associated with the entities and the content items in the focus area;</claim-text><claim-text>causing the focus area to be presented; and</claim-text><claim-text>providing one or more updates to the focus data in the focus area that changes the focus data presented in the focus area.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the endeavor that the user has focused on over time comprises:<claim-text>analyzing activity data associated with one or more activities of the user to determine the content items; and</claim-text><claim-text>detecting one or more people associated with the content items to determine the entities.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining a context associated with the user prior to causing the focus area to be presented; and</claim-text><claim-text>determining the focus area is the focus area the user is currently focusing on based on the context.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein:<claim-text>the context is a first context; and</claim-text><claim-text>the method further comprises:<claim-text>determining the user is associated with a different second context;</claim-text><claim-text>determining a second focus area the user is currently focusing on based on the second context;</claim-text><claim-text>arranging the focus data for presentation based on the second context;</claim-text><claim-text>causing the second focus area to be presented within the second context; and</claim-text><claim-text>providing one or more updates to the focus data in the second focus area.</claim-text></claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein providing the one or more updates to the focus data in the focus area comprises providing, at selected times, the one or more updates to the focus data in the focus area.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein clustering the entities and the content items into the focus area based on the relationships comprises clustering the entities and the content items into the focus area based on topic modeling that uses the entities as words.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein clustering the entities and the content items into the focus area based on the relationships comprises clustering the entities and the content items into the focus area based on the relationships and the strengths of the relationships.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the content items comprise one or more of communications, documents, tasks, meetings, or projects.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the strength of each relationship is determined based on a semantic similarity between one content item and another content item.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the strength of each relationship is determined based on at least one of:<claim-text>an amount of time the user spent on a content item;</claim-text><claim-text>a recency of a content item within the period of time;</claim-text><claim-text>a number of activities performed for a content item; and</claim-text><claim-text>a subject matter of one or more content items.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A system, comprising:<claim-text>a processing device; and<claim-text>a storage device storing instructions, that when executed by the processing device, cause operations to be performed, the operations comprising:<claim-text>determining a plurality of endeavors that a user has focused on over a period of time, each endeavor comprising entities and content items;</claim-text><claim-text>determining relationships between the entities and the content items, wherein the relationships indicate interactions between the entities and the content items;</claim-text><claim-text>determining strengths of the relationships based on the interactions;</claim-text><claim-text>clustering the entities and the content items into a plurality of focus areas;</claim-text><claim-text>populating each focus area with focus data associated with the entities and the content in that focus area;</claim-text><claim-text>causing the plurality of focus areas to be presented; and</claim-text><claim-text>repeatedly providing one or more updates to the focus data in at least one focus area, the one or more updates changing the focus data presented in the at least one focus area.</claim-text></claim-text></claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein determining the plurality of endeavors comprises:<claim-text>analyzing activity data associated with one or more activities of the user to determine the content items; and</claim-text><claim-text>detecting one or more persons associated with the content items to determine the entities.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the storage device stores further instructions for:<claim-text>determining a context associated with the user prior to causing the plurality of focus areas to be presented; and</claim-text><claim-text>determining each focus data in the plurality of focus areas is a focus area the user is currently working on based on the context.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein:<claim-text>the context is a first context; and</claim-text><claim-text>the storage device stores further instructions for:<claim-text>determining the user is associated with a different second context;</claim-text><claim-text>populating the plurality of focus areas with focus data based on the second context;</claim-text><claim-text>arranging the focus data for presentation based on the second context;</claim-text><claim-text>causing the plurality of focus areas to be presented within the second context; and</claim-text><claim-text>repeatedly providing one or more updates to the focus data in at least one focus area.</claim-text></claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein repeatedly providing the one or more updates to the focus data in the at least one focus area comprises:<claim-text>determining in real-time if an update to the focus data in the at least one focus area is available; and</claim-text><claim-text>providing, when the update is available, the update to the focus data in the at least one focus area.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein clustering the entities and the content items into the plurality of focus areas based on the relationships comprises clustering the entities and the content items into the plurality of focus areas based on the relationships and the strengths of the relationships.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein causing the plurality of focus areas to be presented comprises causing the plurality of focus areas to be presented in a graphical user interface of a software application.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A method, comprising:<claim-text>determining an endeavor that a user has focused on over a period of time, the determining comprising:<claim-text>analyzing activity data associated with one or more activities of the user to determine the content items;</claim-text><claim-text>detecting one or more people associated with the content items to determine the entities; and</claim-text><claim-text>determining relationships between the entities and the content items, wherein the relationships indicate interactions between the entities and the content items;</claim-text></claim-text><claim-text>determining strengths of the relationships based on the interactions;</claim-text><claim-text>clustering some of the entities and the content items into a focus area based on the relationships;</claim-text><claim-text>populating the focus area with focus data associated with the entities and the content items clustered in the focus area; and</claim-text><claim-text>causing the focus area to be presented as a feed by repeatedly providing one or more updates to the focus data in the focus area, the one or more updates changing the focus data presented in the focus area.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising:<claim-text>determining a context associated with the user prior to causing the focus area to be presented; and</claim-text><claim-text>determining the focus area is a focus area the user is currently working on based on the context.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein:<claim-text>the context is a first context; and</claim-text><claim-text>the method further comprises:<claim-text>determining the user is associated with a different second context;</claim-text><claim-text>determining a second focus area the user is currently working on based on the second context;</claim-text><claim-text>arranging the focus data for presentation based on the second context;</claim-text><claim-text>causing the second focus area to be presented within the second context; and</claim-text><claim-text>providing one or more updates to the focus data in the second focus area.</claim-text></claim-text></claim-text></claim></claims></us-patent-application>
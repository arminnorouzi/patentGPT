<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003506A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003506</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17942548</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-052313</doc-number><date>20200324</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>B</subclass><main-group>11</main-group><subgroup>02</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>62</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>13</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>17</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>44</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>74</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>B</subclass><main-group>11</main-group><subgroup>02</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>62</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>12</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>13</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>17</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>44</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>761</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">DIMENSION MEASUREMENT METHOD AND DIMENSION MEASUREMENT DEVICE</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/006668</doc-number><date>20210222</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17942548</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Panasonic Intellectual Property Management Co., Ltd.</orgname><address><city>Osaka</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>FUKUDA</last-name><first-name>Masaki</first-name><address><city>Osaka</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>MATSUNOBU</last-name><first-name>Toru</first-name><address><city>Osaka</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>YOSHIKAWA</last-name><first-name>Satoshi</first-name><address><city>Hyogo</city><country>JP</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>TERANISHI</last-name><first-name>Kensho</first-name><address><city>Osaka</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A dimension measurement method includes: extracting a plurality of lines from a plurality of images generated by shooting a target area from a plurality of viewpoints, and generating a line segment model which is a three-dimensional model of the target area that is expressed using the plurality of lines; calculating a dimension of a particular part inside the target area, using the line segment model; and outputting the dimension calculated.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="59.77mm" wi="119.97mm" file="US20230003506A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="231.06mm" wi="122.00mm" file="US20230003506A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="233.76mm" wi="121.58mm" file="US20230003506A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="224.11mm" wi="75.78mm" file="US20230003506A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="244.09mm" wi="171.28mm" orientation="landscape" file="US20230003506A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="227.08mm" wi="118.53mm" file="US20230003506A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="244.69mm" wi="153.92mm" file="US20230003506A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="212.51mm" wi="95.08mm" file="US20230003506A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="209.80mm" wi="95.25mm" file="US20230003506A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="244.01mm" wi="95.00mm" file="US20230003506A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="209.72mm" wi="95.33mm" file="US20230003506A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="94.83mm" wi="110.83mm" file="US20230003506A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This is a continuation application of PCT International Application No. PCT/JP2021/006668 filed on Feb. 22, 2021, designating the United States of America, which is based on and claims priority of Japanese Patent Application No. 2020-052313 filed on Mar. 24, 2020. The entire disclosures of the above-identified applications, including the specifications, drawings and claims are incorporated herein by reference in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to a dimension measurement method and a dimension measurement device.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">In the measurement of building structures, and so on, the burden on a worker can be reduced by generating a three-dimensional model using a plurality of images that have been shot. For example, Patent Literature (PTL) 1 discloses a method of calculating the shape of a structure by performing point cloud measurement using a multi-viewpoint image measurement method based on a plurality of images.</p><heading id="h-0004" level="1">CITATION LIST</heading><heading id="h-0005" level="1">Patent Literature</heading><p id="p-0005" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0004">PTL 1: Japanese Unexamined Patent Application Publication No. 2019-152533</li></ul></p><heading id="h-0006" level="1">SUMMARY</heading><heading id="h-0007" level="1">Technical Problem</heading><p id="p-0006" num="0005">In such measurement using a three-dimensional model, there is a demand for reducing the processing amount. The present disclosure has as an object to provide a dimension measurement method or a dimension measuring device that can reduce the processing amount.</p><heading id="h-0008" level="1">Solution to Problem</heading><p id="p-0007" num="0006">A dimension measurement method according to an aspect of the present disclosure includes: extracting a plurality of lines from a plurality of images generated by shooting a target area from a plurality of viewpoints, and generating a line segment model which is a three-dimensional model of the target area that is expressed using the plurality of lines; calculating a dimension of a particular part inside the target area, using the line segment model; and outputting the dimension calculated.</p><heading id="h-0009" level="1">Advantageous Effects</heading><p id="p-0008" num="0007">The present disclosure is capable of providing a dimension measurement method or a dimension measuring device that is capable of reducing the processing amount.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0010" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0009" num="0008">These and other advantages and features will become apparent from the following description thereof taken in conjunction with the accompanying Drawings, by way of non-limiting examples of embodiments disclosed herein.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of dimension measurement according to an embodiment.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of dimension measurement according to an embodiment.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of a dimension measurement device according to an embodiment.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of an imaging unit according to an embodiment.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram of a controller according to an embodiment.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram of a dimension measurer according to an embodiment.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a sequence diagram of a dimension measurement process according to an embodiment.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of image shooting according to an embodiment.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of a line segment reconstruction process according to an embodiment.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a schematic diagram for describing line segment reconstruction according to an embodiment.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a schematic diagram for describing line segment reconstruction according to an embodiment.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a schematic diagram for describing line segment reconstruction according to an embodiment.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram illustrating an example of a screen display according to an embodiment.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating an example of a screen display according to an embodiment.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram illustrating an example of a screen display according to an embodiment.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram illustrating an example of a screen display according to an embodiment.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a diagram illustrating an example of a screen display according to an embodiment.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a flowchart of a dimension measurement process according to an embodiment.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram illustrating an example of a screen display according to an embodiment.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a diagram illustrating an example of a screen display according to an embodiment.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a flowchart of a dimension measurement process according to an embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0011" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0031" num="0030">A dimension measurement method according to an aspect of the present disclosure includes: generating, using a plurality of images generated by shooting a target area from a plurality of viewpoints, a line segment model which is a three-dimensional model of the target area that is expressed using lines; calculating a dimension of a particular part inside the target area, using the line segment model; and outputting the dimension calculated.</p><p id="p-0032" num="0031">Accordingly, the dimension measurement method is capable of reducing the processing amount by calculating the dimension using a line segment model. For example, compared to a case where the shape of the target area is represented by a point cloud, by representing only an edge of the target area using a line, the processing amount can be reduced. Specifically, in a dimension measurement method which uses a three-dimensional model in which, aside from edges of the target area, a plane of the target area is also represented by a point cloud, in order to perform measurement for an edge of the target area, it is necessary to extract only the point cloud representing the edge from the three-dimensional model. In contrast, according to a dimension measurement method according to an aspect of the present disclosure, the line segment model only includes the point cloud representing edges of the target area, and thus it is not necessary to extract the point cloud representing the edge. Furthermore, the data amount of the line segment model according to an aspect of the present disclosure is less than the data amount of a three-dimensional model in which a plane of the target area is also expressed by a point cloud.</p><p id="p-0033" num="0032">For example, the dimension measurement method may further include displaying a user interface including the line segment model, and the particular part may be determined based on lines which are included in the line segment model and specified by a user via the user interface.</p><p id="p-0034" num="0033">Accordingly, by having the user select a plurality of lines from a line segment model, the dimension of the particular part which is based on the selected plurality of lines is measured. Accordingly, the user can easily measure the dimension of the desired part.</p><p id="p-0035" num="0034">For example, the dimension may be a distance between two lines selected by the user via the user interface.</p><p id="p-0036" num="0035">Accordingly, by having the user select two lines from the line segment model, the distance between the selected two lines is measured. Accordingly, the user can easily measure the dimension of the desired part.</p><p id="p-0037" num="0036">For example, the dimension may be a distance between a line and a plane that are selected by the user via the user interface.</p><p id="p-0038" num="0037">Accordingly, by having the user select a plurality of lines from the line segment model, a dimension between the line and the plane which is based on the selected plurality of lines is measured. Accordingly, the user can easily measure the dimension of the desired part.</p><p id="p-0039" num="0038">For example, the plane may be defined by two lines selected by the user via the user interface.</p><p id="p-0040" num="0039">Accordingly, the user can easily select a desired plane.</p><p id="p-0041" num="0040">For example, the dimension measurement method may further include presenting, to the user, a message prompting the user to shoot an entirety of a target object included in the target area, when the entirety of a target object is not included in an image that has been shot.</p><p id="p-0042" num="0041">Accordingly, the dimension measurement method is able to generate a line segment model using an image generated by shooting the entirety of the target object, and thus is able to improve the accuracy of the line segment model. Therefore, the dimension measurement method can improve dimension measurement accuracy.</p><p id="p-0043" num="0042">For example, the lines may be a line segment.</p><p id="p-0044" num="0043">Accordingly, the dimension measurement method is able to generate a line segment model using a line segment which has both ends, without having to use the portion that is cut off in the image, and thus is able to improve the accuracy of the line segment model.</p><p id="p-0045" num="0044">Furthermore, a dimension measurement device according to an aspect of the present disclosure includes: a processor and a memory. Using the memory, the processor generates, using a plurality of images generated by shooting a target area, a line segment model which is a three-dimensional model of the target area that is expressed using lines; calculates a dimension of a particular part inside the target area, using the line segment model; and outputs the dimension calculated.</p><p id="p-0046" num="0045">Accordingly, the dimension measurement device is capable of reducing the processing amount by calculating the dimension using a line segment model.</p><p id="p-0047" num="0046">Furthermore, a dimension measurement device according to another aspect of the present disclosure includes: an input interface, a processor, and an output interface. Images shot from a plurality of viewpoints of a target area are inputted to the input interface. The processor generates a three-dimensional model that represents the target area using lines, based on the images. The processor calculates the dimensions of a particular part of the three-dimensional model. The calculated dimensions are outputted from an output interface.</p><p id="p-0048" num="0047">It should be noted that these generic and specific aspects may be implemented as a system, a method, an integrated circuit, a computer program, or a computer-readable recording medium such as a CD-ROM, or may be implemented as any combination of a system, a method, an integrated circuit, a computer program, and a recording medium.</p><p id="p-0049" num="0048">Hereinafter, embodiments will be specifically described with reference to the Drawings. It should be noted that each of the embodiments described hereafter illustrates a specific example of the present disclosure. The numerical values, shapes, materials, structural components, the arrangement and connection of the structural components, steps, the processing order of the steps, etc., shown in the following embodiments are mere examples, and are therefore not intended to limit the present disclosure. Furthermore, among the structural components in the following embodiments, structural components not recited in the independent claims are described as optional structural components.</p><heading id="h-0012" level="1">Embodiment</heading><p id="p-0050" num="0049">In the construction industry, the shortage of manpower is becoming severe, and thus it is necessary to improve efficiency of site management operations. Furthermore, there is a demand for improving efficiency of inspection tasks for which a considerable number of man-hours is allotted among site management operations. In dimension measurement included in the inspection tasks, a person has to perform the measurements using a tape measure, for example, and thus the burden on the worker is great.</p><p id="p-0051" num="0050">The present embodiment will describe a device and a method that can automatically measure dimensions of a target from video shot using a camera, in a mobile terminal, for example.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b></figref> are diagrams illustrating examples of a dimension measurement. <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example of a kitchen in which, for example, height L<b>1</b> of a kitchen counter and distance L<b>2</b> from the floor to an electric outlet are to be measured. Here, each of L<b>1</b> and L<b>2</b> is defined as a distance between a plane and a line. For example, L<b>1</b> is the distance between the floor (a plane) and one side of the counter (a line).</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example of a front door area in which, for example, door undercut L<b>3</b> (i.e., the distance between the floor and the bottom side of the door), tile width L<b>4</b>, and door gap L<b>5</b> are to be measured. In this example, L<b>3</b> is a distance between a line and a plane, and L<b>4</b> and L<b>5</b> are distances between a line and a line. In this manner, in the present embodiment, distances between a line and a line or a line and a plane are measured.</p><p id="p-0054" num="0053">Next, the configuration of a dimension measurement device according to the present embodiment will be described. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of dimension measurement device <b>100</b> according to the present embodiment. Dimension measurement device <b>100</b> includes imaging unit <b>200</b>, controller <b>300</b>, dimension measurer <b>400</b>, and user interface <b>500</b>. For example, this dimension measurement device <b>100</b> is included in a tablet terminal or a mobile terminal such as a smart phone, etc.</p><p id="p-0055" num="0054">Imaging unit <b>200</b> shoots images (a moving image or a still image). Controller <b>300</b> controls imaging unit <b>200</b>, dimension measurer <b>400</b>, and user interface <b>500</b>. Dimension measurer <b>400</b> generates a line segment model which is a three-dimensional model represented by line segments, by performing line segment reconstruction using an image shot by imaging unit <b>200</b>. Stated differently, a line segment model is a model obtained by removing shapes (for example, planes) other than line segments from a three-dimensional model. Furthermore, dimension measurer <b>400</b> measures, using a line segment model, a dimension (distance) of a part specified by a user.</p><p id="p-0056" num="0055">It should be noted that, a three-dimensional model is a representation of a shot measurement target made on a computer. The three-dimensional model, for example, has position information of respective three-dimensional parts on the measurement target. Furthermore, aside from line segments, the line segment model may be a three-dimensional model represented using lines. Here, a line refers to a line segment which has two ends, a half-line which has only one end, a line which has no ends, or a combination thereof. Furthermore, having no ends means that the ends are cut off in the image, for example.</p><p id="p-0057" num="0056">User interface <b>500</b> receives input from a user. Furthermore, user interface <b>500</b> presents information to the user. For example, user interface <b>500</b> is a display and a touch panel. It should be noted that, user interface <b>500</b> is not limited to the above examples, and may be any user interface. For example, user interface <b>500</b> may include a microphone, a speaker, and so on.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram illustrating the configuration of imaging unit <b>200</b>. Imaging unit <b>200</b> includes camera <b>201</b> and platform <b>202</b>. Camera <b>201</b> includes storage <b>211</b>, controller <b>212</b>, optical system <b>213</b>, and image sensor <b>214</b>. Storage <b>211</b> stores images shot by image sensor <b>214</b>. Controller <b>212</b> controls storage <b>211</b>, optical system <b>213</b>, and image sensor <b>214</b>. Optical system <b>213</b> includes a lens, and so on, for allowing light to enter image sensor <b>214</b>. Image sensor <b>214</b> shoots an image. Platform <b>202</b> controls the shooting direction of camera <b>201</b>.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating the configuration of controller <b>300</b>. Controller <b>300</b> includes imaging controller <b>301</b>, UI controller <b>302</b>, dimension measurement controller <b>303</b>, and storage <b>304</b>. Image controller <b>301</b> controls imaging unit <b>200</b>. UI controller <b>302</b> controls user interface <b>500</b>. Dimension measurement controller <b>303</b> controls dimension measurer <b>400</b>. Storage <b>304</b> stores images shot by imaging unit <b>200</b>, a line segment model generated by dimension measurer <b>400</b>, and so on.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating the configuration of dimension measurer <b>400</b>. Dimension measurer <b>400</b> includes image obtainer <b>401</b>, preprocessor <b>402</b>, line segment reconstructor <b>403</b>, plane estimator <b>404</b>, and measurer <b>405</b>. Image obtainer <b>401</b> obtains images shot by imaging unit <b>200</b>. Preprocessor <b>402</b> performs preprocessing on the obtained images. Line segment reconstructor <b>403</b> generates a line segment model by performing line segment reconstruction using the pre-processed images. Plane estimator <b>404</b> estimates a plane included in the line segment model. Measurer <b>405</b> measures, using a line segment model, the distance between line segments or the distance between a line segment and a plane.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a sequence diagram of a dimension measurement process by dimension measurement device <b>100</b>. This example is an example of a case of measuring the distance between a line segment and a plane. First, the user performs a shooting start instruction via the user interface (S<b>11</b>). For example, the start instruction is performed by the selection of a menu or the activation of an application, or the like, on a screen.</p><p id="p-0062" num="0061">When controller <b>300</b> receives the start instruction, controller <b>300</b> sends a shooting instruction to imaging unit <b>200</b>. Imaging unit <b>200</b> shoots images (still images) in accordance with the shooting instruction (S<b>12</b>). Here, the images (still images) obtained are two or more images of the same target object (or target space) shot from different viewpoints. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of the shooting of the images. For example, the user shoots images of the target object (for example, the kitchen) from different positions using a single imaging device (for example, a tablet terminal).</p><p id="p-0063" num="0062">It should be noted that imaging unit <b>200</b> does not necessarily have to be included in dimension measurement device <b>100</b>, and may be included in a terminal different from the terminal in which dimension measurement device <b>100</b> is included. In this case, the images shot by imaging unit <b>200</b> are sent to dimension measurement device <b>100</b> via any communication means such as wireless communication, etc.</p><p id="p-0064" num="0063">Furthermore, the images may be a plurality of images shot using a plurality of fixed cameras. Furthermore, the images may be images from two viewpoints shot from one position using a stereo camera. Furthermore, the images may be a plurality of frames included in a moving image shot by a single camera while moving. Furthermore, the images may be a combination of the above.</p><p id="p-0065" num="0064">The shot images are sent to dimension measurer <b>400</b> via controller <b>300</b>. Dimension measurer <b>400</b> generates a line segment model by performing line segment reconstruction using the images (S<b>13</b>).</p><p id="p-0066" num="0065">Hereinafter, the line segment reconstruction process (S<b>13</b>) will be described. <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of the line segment reconstruction process (S<b>13</b>). Furthermore, <figref idref="DRAWINGS">FIG. <b>10</b></figref> to <figref idref="DRAWINGS">FIG. <b>12</b></figref> are schematic diagrams for describing the line segment reconstruction.</p><p id="p-0067" num="0066">First, as illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> dimension measurer <b>400</b> detects the line segments included in the respective images (S<b>31</b>). Next, dimension measurer <b>400</b> calculates the feature amount of each line segment (S<b>32</b>). Next, as illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, dimension measurer <b>400</b> performs matching of line segments between images, using the calculated feature amounts (S<b>33</b>). Specifically, dimension measurer <b>400</b> detects corresponding line segments which are line segments that correspond to each other (i.e., are the same) between images. Next, as illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, dimension measurer <b>400</b> estimates the camera parameters (three-dimensional positions and orientations) of the respective images and the three-dimensional position of the line segment, by geometrical calculation using the relationship between the corresponding lines (S<b>34</b>).</p><p id="p-0068" num="0067">It should be noted that the above-described line segment reconstruction method is one example, and any commonly known method may be used. For example, dimension measurer <b>400</b> may generate, using a plurality of images, a three-dimensional model represented by point cloud data (point cloud), and generate a line segment model by detecting line segments included in the generated three-dimensional model.</p><p id="p-0069" num="0068">Description of <figref idref="DRAWINGS">FIG. <b>7</b></figref> will be carried out again. The line segment model generated by line segment reconstruction (S<b>13</b>) is sent to controller <b>300</b>. Controller <b>300</b> generates, using the line segment model, a line segment model image of the line segment model as seen from a predetermined direction, and sends the line segment model image to user interface <b>500</b> (S<b>14</b>).</p><p id="p-0070" num="0069">User interface <b>500</b> displays a UI (user interface) including the line segment model image. <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram illustrating an example of a screen display in the above case. It should be noted that, with regard to this screen display, the user may change viewpoint positions and perform scaling. In other words, the viewpoint of a line segment model displayed may be manipulable by the user. Furthermore, a line segment model image may be displayed superimposed on an image. The image may be a real time image that is currently being shot, or may be an image shot in the past. Specifically, the viewpoint of the line segment model displayed may be the same as the viewpoint of the image onto which the line segment model is superimposed.</p><p id="p-0071" num="0070">The user selects, in the screen display, two or more line segments for selecting a plane (S<b>15</b>). <figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating an example of a screen display in the above case. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, line segment A and line segment B are selected. Information indicating the selected line segments is sent to dimension measurer <b>400</b> via controller <b>300</b>.</p><p id="p-0072" num="0071">Dimension measurer <b>400</b> estimates, based on the information on the selected line segments, a plane that includes the selected line segments (S<b>16</b>). For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, plane C (the floor) including line segment A and line segment B is detected. The information of the estimated plane is sent to controller <b>300</b>. Controller <b>300</b> superimposes the information of the plane onto the line segment model image, and outputs the image obtained to the user interface <b>500</b> (S<b>17</b>).</p><p id="p-0073" num="0072">User interface <b>500</b> displays the image received. The user selects, in the display screen, the line segment and the plane which are the dimension measurement targets (S<b>18</b>). <figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram illustrating an example of a screen display in the above case. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, line segment D and plane C are selected.</p><p id="p-0074" num="0073">It should be noted that, when only one plane is estimated in the plane estimation (S<b>16</b>), the plane may be automatically selected without performing the plane selection by the user. Alternatively, whether such plane may be selected or not may be confirmed with the user. It should be noted that the plane estimation may be performed automatically by dimension measurer <b>400</b> using a shot image or, in the case where a point cloud model is generated, using the point cloud model. In this case, since a plurality of planes are estimated, the user selects, from the plurality of planes, the plane which is the dimension measurement target.</p><p id="p-0075" num="0074">The information of the selected dimension measurement target is sent to dimension measurer <b>400</b>. Dimension measurer <b>400</b> measures, using the line segment model, the dimensions of the dimension measurement targets (S<b>19</b>). Specifically, dimension measurer <b>400</b> measures the distance between the line segment and the plane that are selected using the line segment model. Here, the distance between the line segment and the plane is, for example, the minimum distance between the line segment and the plane.</p><p id="p-0076" num="0075">The result of the dimension measurement is sent to controller <b>300</b>. Controller <b>300</b> generates dimension information indicating the result of the dimension measurement, and sends the dimension information to user interface <b>500</b> (S<b>20</b>). User interface <b>500</b> displays the dimension information (S<b>21</b>). <figref idref="DRAWINGS">FIG. <b>17</b></figref> is a diagram illustrating an example of a screen display in the above case. As illustrated in <figref idref="DRAWINGS">FIG. <b>17</b></figref>, information indicating the part for which the dimension is measured and the dimension (distance) are displayed.</p><p id="p-0077" num="0076">It should be noted that, in the case where the line segment and the plane are not parallel, the minimum distance between one point (for example, the center point) on the line segment and the plane may be calculated. Alternatively, the minimum distances between respective points on the line segment and the plane may be calculated, and the average value or the median value of the calculated minimum distances may be calculated. Alternatively, a plurality values out of the smallest value, the biggest value, the average value, and the median value of the minimum distances may be calculated, and the calculated values may be presented to the user. Furthermore, the fact that the line segment and the plane are not parallel may be notified to the user.</p><p id="p-0078" num="0077">It should be noted that, in each screen display in which a user operation is required, a message, or the like, that prompts operation by the user or indicates the details of the operation may be displayed. Furthermore, although an example in which text, or the like, is used as a method of presenting information to the user is given in the foregoing description, any method, such as icon displays or voice output, etc., may be used.</p><p id="p-0079" num="0078">Furthermore, although an example in which the line segment which is the dimension measurement target is selected (S<b>18</b>) after the plane estimation (S<b>15</b> to S<b>17</b>) is performed is described here, the line segment which is the dimension measurement target may be selected first, and the plane estimation (S<b>15</b> to S<b>17</b>) performed thereafter.</p><p id="p-0080" num="0079">Furthermore, although an example in which the distance between a line segment and a plane is measured is described here, the distance between two line segments may be measured. In this case, the two line segments which are the dimension measurement targets are selected in S<b>18</b> without performing S<b>15</b> to S<b>17</b>.</p><p id="p-0081" num="0080">Furthermore, the distance between two planes may be measured. In this case, two planes are estimated by performing S<b>15</b> to S<b>17</b> twice. Furthermore, a point and a line segment or a point and a plane may be specified by the user, and the distance between the point and the line segment or the distance between the point and the plane may be measured.</p><p id="p-0082" num="0081">Furthermore, dimension measurement device <b>100</b> may have any one or a plurality functions from among a function of measuring the distance between a line segment and a plane, a function of measuring the distance between a line segment and a line segment, or other functions (e.g., function of measuring the distance between a plane and a plane, a point and a line segment, or a point and a plane). In the case of having a plurality of functions, the function to be used may be specified by the user at a predetermined timing (for example, at the start of S<b>11</b> or S<b>15</b>, etc.), and may be specified by the user at an arbitrary timing. Furthermore, the functions may be switched automatically according to the result of the user's selection of a line segment or a plane. For example, when two line segments are selected as dimension measurement targets by the user, the distance between the two line segments may be measured, and when a line segment and a plane are selected as dimension measurement targets by the user, the distance between the line segment and the plane may be measured.</p><p id="p-0083" num="0082">Next, the flow of processing by dimension measurer <b>400</b> will be described. <figref idref="DRAWINGS">FIG. <b>18</b></figref> is a flowchart of the dimension measurement process of dimension measurer <b>400</b>. First, image obtainer <b>401</b> obtains images shot by imaging unit <b>200</b> (S<b>41</b>).</p><p id="p-0084" num="0083">Next, preprocessor <b>402</b> performs preprocessing on the obtained images (S<b>42</b>). Preprocessing is, for example, brightness adjustment, noise removal, resolution conversion, color space conversion, lens distortion correction, projective transformation, affine transformation, edge enhancement, trimming, or a combination thereof. It should be noted that the preprocessing may be performed in line with the timing at which the dimension measurement is performed, or may be performed in advance. The preprocessed images obtained through the performance of image preprocessing by preprocessor <b>402</b> may be stored in storage <b>304</b> included in controller <b>300</b>. It should be noted that the preprocessing by preprocessor <b>402</b> need not be executed. For this reason, dimension measurer <b>400</b> need not include preprocessor <b>402</b>.</p><p id="p-0085" num="0084">Next, line segment reconstructor <b>403</b> performs line segment reconstruction for calculating the three-dimensional shape of objects in a predetermined space, using images shot by imaging unit <b>200</b> (S<b>43</b>). Specifically, for each of the images, line segment reconstructor <b>403</b> detects line segments, performs inter-image correspondence, and calculates, by geometrical calculation using the correspondence relationship, a line segment model consisting of the three-dimensional line segments of the predetermined space.</p><p id="p-0086" num="0085">Plane estimator <b>404</b> estimates a three-dimensional plane using the line segment model. First, in order to estimate a plane, plane estimator <b>404</b> selects line segments included in the plane (S<b>44</b>). For example, these line segments are selected based on a user operation. It should be noted that plane estimator <b>404</b> may perform this selection automatically. Next, plane estimator <b>404</b> estimates a plane including the selected line segments (S<b>45</b>). It should be noted that the plane estimation process by plane estimator <b>404</b> need not be performed. For this reason, dimension measurer <b>400</b> need not include plane estimator <b>404</b>.</p><p id="p-0087" num="0086">Next, measurer <b>405</b> selects two line segments, or a line segment and a plane, which are the dimension measurement targets (S<b>46</b>). For example, this selection is performed based on a user operation. It should be noted that measurer <b>405</b> may perform this selection automatically. Next, measurer <b>405</b> calculates the distance between the two line segments, or between the line segment and the plane, that were selected (S<b>47</b>). Furthermore, the calculated distance is, for example, displayed on user interface <b>500</b>.</p><p id="p-0088" num="0087">Here, since mapping is performed using line segments in the line segment reconstruction, accuracy deteriorates when the target object is cut off in an image, that is, when the entirety of the target object does not fit within the image. Therefore, in such a case, dimension measurement device <b>100</b> may instruct the user to perform image shooting again. For example, dimension measurement device <b>100</b> detects an edge inside the image, and determines that the edge (i.e., the target object) is cut off when the detected edge continues up to a border of the image.</p><p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram illustrating an example of a screen display in which the entirety of a target object (i.e., a kitchen counter) does not fit within the screen display. <figref idref="DRAWINGS">FIG. <b>20</b></figref> is a diagram illustrating an example of a screen display on which a message is displayed in the above case. It should be noted that such a message may be displayed after shooting of a still image, or may be displayed in a state where real-time moving images are displayed on the monitor prior to shooting a still image, or may be displayed during shooting of a moving image. Furthermore, such a warning to the user may be performed by icon display or by voice.</p><p id="p-0090" num="0089">Furthermore, as to the images for line segment reconstruction, when three or more images are to be used, dimension measurement device <b>100</b> may select, from a plurality of images, two or more images showing the entirety of the target object, and line segment reconstruction may be performed using the two or more images. In other words, dimension measurement device <b>100</b> may perform the line segment reconstruction without using an image in which the target object is cut off.</p><p id="p-0091" num="0090">As described above, the dimension measurement device according to the present embodiment performs the processes illustrated in <figref idref="DRAWINGS">FIG. <b>21</b></figref>. The dimension measurement device generates, using a plurality of images generated by shooting a target area from a plurality of viewpoints, a line segment model which is a three-dimensional model of the target area represented by lines (S<b>51</b>). Next, the dimension measurement device calculates a dimension of a particular part inside the target area, using the line segment model (S<b>52</b>). Next, the dimension measurement device outputs the dimension calculated (S<b>53</b>). For example, dimension measurement device <b>100</b> presents to the user, or outputs to another device, the calculated dimension.</p><p id="p-0092" num="0091">Accordingly, the dimension measurement device is capable of reducing the processing amount by calculating the dimension using a line segment model. Furthermore, the selection operation by a user can be done easily compared to the case where the user is required to select two points, for example. Specifically, in order to accurately measure height L<b>1</b> of the kitchen counter illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> by specifying two points, the user needs to specify the nearest two points of the floor and the top surface of the kitchen counter. In contrast, in the case of specifying a line and a line or a line and a plane as in the present embodiment, the shortest distance between the line and the line or the line and the plane is automatically measured, and thus the selection operation by the user is simplified.</p><p id="p-0093" num="0092">For example, the dimension measurement device further displays a user interface including the line segment model. The particular part is determined based on lines which are included in the line segment model and specified by a user via the user interface. Accordingly, by having the user select lines from a line segment model, the dimension of the particular part which is based on the selected lines is measured. Accordingly, the user can easily measure the dimension of the desired part.</p><p id="p-0094" num="0093">For example, the dimension of the particular part is a distance between two lines selected by the user via the user interface. Accordingly, by having the user select two lines from the line segment model, the distance between the selected two lines is measured. Accordingly, the user can easily measure the dimension of the desired part.</p><p id="p-0095" num="0094">For example, the dimension of the particular part is the distance between a line and a plane that are selected by the user via the user interface. Accordingly, by having the user select lines from the line segment model, a dimension between the line and the plane which are based on the selected lines is measured. Accordingly, the user can easily measure the dimension of the desired part.</p><p id="p-0096" num="0095">For example, the plane selected by the user is a plane defined by two lines selected by the user via the user interface. Accordingly, the user can easily select a desired plane.</p><p id="p-0097" num="0096">For example, when an entirety of a target object included in the target area is not included in an image that is shot, the dimension measurement device presents, to the user, a message prompting the user to shoot the entirety of the target object. Accordingly, the dimension measurement device is able to generate a line segment model using an image generated by shooting the entirety of the target object, and thus is able to improve the accuracy of the line segment model. Therefore, the dimension measurement device can improve dimension measurement accuracy.</p><p id="p-0098" num="0097">For example, the line is a line segment. Accordingly, the dimension measurement device is able to generate a line segment model using a line segment which has both ends, without having to use a portion that is cut off in the image, and thus is able to improve the accuracy of the line segment model.</p><p id="p-0099" num="0098">For example, the dimension measurement device includes a processor and memory, and, using the memory, the processor performs the above-described processes.</p><p id="p-0100" num="0099">Although a dimension measurement device, and so on, according to the present embodiment has been described above, the present disclosure is not limited to this embodiment.</p><p id="p-0101" num="0100">Furthermore, each of the processing units included in the dimension measurement device, and so on, according to the foregoing embodiment is implemented typically as an LSI which is an integrated circuit. These processing units may be configured as individual chips or may be configured so that a part or all of the processing units are included in a single chip.</p><p id="p-0102" num="0101">Furthermore, the method of circuit integration is not limited to LSIs, and implementation through a dedicated circuit or a general-purpose processor is also possible. A field programmable gate array (FPGA) that allows for programming after the manufacture of an LSI, or a reconfigurable processor that allows for reconfiguration of the connection and the setting of circuit cells inside an LSI may be employed.</p><p id="p-0103" num="0102">Furthermore, although in each of the foregoing embodiments, the respective structural components are configured using dedicated hardware, the respective structural components may be implemented by executing software programs suitable for the respective structural components. The respective structural components may be implemented by a program executer such as a CPU or a processor reading and executing a software program recorded on a recording medium such as a hard disk or a semiconductor memory.</p><p id="p-0104" num="0103">Furthermore, the present disclosure may be implemented as a dimension measurement method, and the like, performed by a dimension measurement device, and the like.</p><p id="p-0105" num="0104">Furthermore, the separation of the function blocks in the block diagrams is merely an example, and plural function blocks may be implemented as a single function block, a single function block may be separated into plural function blocks, or part of functions of a function block may be transferred to another function block. Furthermore, the functions of function blocks having similar functions may be processed, in parallel or by time-sharing, by a single hardware or software.</p><p id="p-0106" num="0105">Furthermore, the sequence in which respective steps in the flowcharts are executed is given as an example to describe the present disclosure in specific terms, and thus other sequences are possible. Furthermore, part of the above-described steps may be executed simultaneously (in parallel) with another step.</p><p id="p-0107" num="0106">Although a dimension measurement device, and so on, according to one or more aspects are described above based on the foregoing embodiment, the present disclosure is not limited to this embodiment. Forms obtained by various modifications to the embodiments that may be conceived by a person of ordinary skill in the art or forms obtained by combining structural components in different embodiments, for as long as they do not depart from the essence of the present invention, may be included in the one or more aspects.</p><heading id="h-0013" level="1">INDUSTRIAL APPLICABILITY</heading><p id="p-0108" num="0107">The present disclosure is applicable to a dimension measurement device.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A dimension measurement method comprising:<claim-text>extracting a plurality of lines from a plurality of images generated by shooting a target area from a plurality of viewpoints, and generating a line segment model which is a three-dimensional model of the target area that is expressed using the plurality of lines;</claim-text><claim-text>calculating a dimension of a particular part inside the target area, using the line segment model; and</claim-text><claim-text>outputting the dimension calculated.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The dimension measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>displaying a user interface including the line segment model, wherein</claim-text><claim-text>the particular part is determined based on lines included in the line segment model, the lines being specified by a user via the user interface.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The dimension measurement method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the dimension is a distance between two lines selected by the user via the user interface.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The dimension measurement method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the dimension is a distance between a line and a plane that are selected by the user via the user interface.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The dimension measurement method according to claim <claim-ref idref="CLM-00004">4</claim-ref>, wherein<claim-text>the plane is defined by two lines selected by the user via the user interface.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The dimension measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>presenting a message to a user when an entirety of a target object included in the target area is not included in an image that has been shot, the message prompting the user to shoot the entirety of the target object.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The dimension measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the line segment model is a model generated by removing shapes other than a line from the three-dimensional model.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The dimension measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the line segment model is generated by performing line segment reconstruction using the plurality of images.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The dimension measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the generating of the line segment model includes:<claim-text>calculating respective feature amounts of the plurality of lines; and</claim-text><claim-text>estimating respective three-dimensional positions of the plurality of lines using the respective feature amounts.</claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The dimension measurement method according to claim <claim-ref idref="CLM-00001">1</claim-ref>, wherein<claim-text>the generating of the line segment model includes detecting, from among lines included in each of the plurality of images, corresponding lines between the plurality of images.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The dimension measurement method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>each of the plurality of lines is a line segment.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A dimension measurement device comprising:<claim-text>a processor; and</claim-text><claim-text>memory, wherein</claim-text><claim-text>using the memory, the processor:<claim-text>extracts a plurality of lines from a plurality of images generated by shooting a target area, and generates a line segment model which is a three-dimensional model of the target area that is expressed using the plurality of lines;</claim-text><claim-text>calculates a dimension of a particular part inside the target area, using the line segment model; and</claim-text><claim-text>outputs the dimension calculated.</claim-text></claim-text></claim-text></claim></claims></us-patent-application>
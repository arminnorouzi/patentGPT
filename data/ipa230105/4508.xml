<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004509A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004509</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17729023</doc-number><date>20220426</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-110233</doc-number><date>20210701</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>13</main-group><subgroup>28</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>15</main-group><subgroup>163</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>13</main-group><subgroup>28</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>15</main-group><subgroup>163</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">INFORMATION PROCESSING DEVICE, CONTROL METHOD, AND STORAGE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>FUJITSU LIMITED</orgname><address><city>Kawasaki-shi</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Hyoudou</last-name><first-name>Kazuki</first-name><address><city>Chofu</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>FUJITSU LIMITED</orgname><role>03</role><address><city>Kawasaki-shi</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An information processing device includes a field programmable gate array configured to store route information in flow control, and forward packets according to the route information; one or more memories configured to store a flow cache that includes at least a part of the route information; and one or more processors coupled to the one or more memories and the one or more processors configured to divide the route information into a plurality of division areas; and acquire hit information extracted from each of the entries in a first division area of the plurality of division areas to delete a part of entries of the flow cache stored in the one or more memories, the first division area including flows whose number is greater than a threshold value.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="109.39mm" wi="158.75mm" file="US20230004509A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="179.41mm" wi="147.74mm" orientation="landscape" file="US20230004509A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="250.36mm" wi="162.31mm" orientation="landscape" file="US20230004509A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="193.04mm" wi="110.57mm" orientation="landscape" file="US20230004509A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="253.75mm" wi="130.64mm" orientation="landscape" file="US20230004509A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="108.97mm" wi="114.13mm" file="US20230004509A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="207.69mm" wi="125.65mm" file="US20230004509A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="192.70mm" wi="115.65mm" file="US20230004509A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="250.02mm" wi="164.00mm" file="US20230004509A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="186.01mm" wi="137.41mm" orientation="landscape" file="US20230004509A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="257.47mm" wi="162.14mm" orientation="landscape" file="US20230004509A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is based upon and claims the benefit of priority of the prior Japanese Patent Application No. 2021-110233, filed on Jul. 1, 2021, the entire contents of which are incorporated herein by reference.</p><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The embodiments discussed herein are related to an information processing device, a control method, and a storage medium.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">In recent years, network functions virtualization (NFV), which implements the functions of network equipment as software on a virtualization platform of a general-purpose server, has been known.</p><p id="p-0005" num="0004">In NFV, a plurality of virtual network functions (VNFs) can be accommodated in one server, using server virtualization technique.</p><p id="p-0006" num="0005">In NFV, communication between VNFs and communication between VNFs and external networks are relayed using virtual switches and virtual routers. Virtual relay devices such as virtual switches and virtual routers achieve the functions of switches and routers in networks, by software.</p><p id="p-0007" num="0006">The virtual relay device is configured to forward a flow containing a plurality of packets and includes a relay unit and a control unit.</p><p id="p-0008" num="0007">The relay unit is configured to forward the packet and sends the input packet to the forwarding destination based on relay rules. A set of relay rules registered in the relay unit may also be referred to as a flow cache.</p><p id="p-0009" num="0008">The control unit controls the relay unit. The control unit, for example, registers an action-resolved rule in the flow cache of the relay unit according to a preset registration rule and the received packet and creates and deletes virtual ports in response to external instructions. The registration rule is, for example, a media access control (MAC) table, a routing table, an access control list (ACL), or a combination thereof.</p><p id="p-0010" num="0009">In addition, in the virtual relay device, aging is performed on the flow (registration flow) registered in the relay rule.</p><p id="p-0011" num="0010">In the aging, entries for which hits have not been made for a certain period of time are deleted (aged out) from the flow cache (relay rule) of the relay unit.</p><p id="p-0012" num="0011">This removes undesired entries from the flow cache (relay rule) and streamlines lookups. In addition, in a virtualized environment, migration of virtual machines (VMs) and the like (host movement) will cause disadvantages such as being blocked from relaying properly to the original destination if relay rules before the movement continue to remain, but performing the aging also solves such disadvantages.</p><p id="p-0013" num="0012">In NFV, the relay performance of the virtual relay device is important because the communication within the same host increases significantly compared with prior virtual environments due to the service chain or the like.</p><p id="p-0014" num="0013">In a prior software-implemented virtual relay device, the packet relay itself involves a large amount of central processing unit (CPU) capability, which wastes computational resources that are originally expected be provided to applications. This makes it difficult to meet the performance requirements of NFV.</p><p id="p-0015" num="0014">Thus, functions as a relay unit with heavy processing in the virtual relay device is offloaded to hardware such as a field programmable gate array (FPGA) and a smart network interface card (NIC). Offloading some functions achieved by software to hardware may also be referred to as hardware offload.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram exemplarily illustrating a configuration of a prior hardware-offloaded virtual relay device.</p><p id="p-0017" num="0016">This prior virtual relay device <b>500</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> includes an FPGA control unit <b>501</b> and an FPGA <b>502</b>.</p><p id="p-0018" num="0017">The virtual relay device <b>500</b> is achieved by a computer equipped with the FPGA <b>502</b>.</p><p id="p-0019" num="0018">The FPGA <b>502</b> achieves functions as a relay unit of a virtual relay device. For example, in the virtual relay device <b>500</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the functions as a relay unit are hardware-offloaded to the FPGA <b>502</b>.</p><p id="p-0020" num="0019">The FPGA <b>502</b> includes a direct memory access (DMA) <b>503</b>, a register group <b>504</b>, an offload relay unit <b>508</b>, and a large-capacity memory <b>505</b>.</p><p id="p-0021" num="0020">The DMA <b>503</b> forwards data from the FPGA <b>502</b> to the FPGA control unit <b>501</b> by DMA. The register group <b>504</b> stores various types of data generated in the FPGA <b>502</b>.</p><p id="p-0022" num="0021">The large-capacity memory <b>505</b> stores a forwarding information base (FIB) <b>5051</b>. The FIB <b>5051</b> included in the FPGA <b>502</b> may also be referred to as an FPGA FIB <b>5051</b>. Information on the flow cache of a software relay unit <b>507</b> is offloaded to the FPGA FIB <b>5051</b> (flow offload).</p><p id="p-0023" num="0022">The FPGA FIB <b>5051</b> is information representing relay rules and is configured as a hash table reserved in a continuous area in the storage area of the large-capacity memory <b>505</b>. The FPGA FIB <b>5051</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> is configured as a table whose entries have match rules, actions, and entry flag fields.</p><p id="p-0024" num="0023">In the entry flag field, two-bit information made up of one-bit information (flag) representing valid or invalidity of the entry and one-bit information (flag) representing the presence or absence of a hit is recorded.</p><p id="p-0025" num="0024">The match rule is information for identifying the flow, and for example, a combination of the input port identifier (ID) and the header information of the packet, or the like may also be used. The action is information indicating the handling of a packet that matches the match rule, in which, for example, forward or drop, designation of the output port, rewriting of header information, and the like are prescribed.</p><p id="p-0026" num="0025">In the FPGA FIB <b>5051</b>, the action is registered in association with the match rule. The offload relay unit <b>508</b>, which will be described later, performs processing defined in the action for a packet of a flow corresponding to the match rule.</p><p id="p-0027" num="0026">An entry ID (entry id) is set for each entry. The entry ID is calculated from the hash value of the key (matching rule).</p><p id="p-0028" num="0027">The offload relay unit <b>508</b> refers to the FPGA FIB <b>5051</b> using the hash value calculated based on destination information (such as the Internet protocol (IP) address) of a packet targeted for processing and acquires an action to be performed on the corresponding packet. The offload relay unit <b>508</b> performs the action acquired from the FPGA FIB <b>5051</b> on the packet targeted for processing. The offload relay unit <b>508</b> functions as a fast path.</p><p id="p-0029" num="0028">When the flow of the packet targeted for processing is not registered in the FPGA FIB <b>5051</b>, the offload relay unit <b>508</b> inquires of the FPGA control unit <b>501</b> to cause the FPGA control unit <b>501</b> to resolve the destination.</p><p id="p-0030" num="0029">The FPGA control unit <b>501</b> is achieved by a processor (not illustrated) of a computer constituting the virtual relay device <b>500</b> by executing a program.</p><p id="p-0031" num="0030">The FPGA control unit <b>501</b> has functions as a control unit <b>506</b> and the software relay unit <b>507</b>.</p><p id="p-0032" num="0031">The software relay unit <b>507</b> includes a flow cache. The flow cache stores the result of destination resolution performed by the control unit <b>506</b>. When an inquiry for the action for the flow of the packet is received from the FPGA <b>502</b>, the software relay unit <b>507</b> refers to the flow cache. When the inquired flow is registered in the flow cache, the software relay unit <b>507</b> responds to the FPGA <b>502</b> with the corresponding action.</p><p id="p-0033" num="0032">In the FPGA <b>502</b>, the packet is forwarded using information on the received action. In addition, in the FPGA <b>502</b>, the responded action is registered in the FPGA FIB <b>5051</b>.</p><p id="p-0034" num="0033">In the software relay unit <b>507</b> of the FPGA control unit <b>501</b>, when the inquired flow is not registered in the flow cache, the control unit <b>506</b> determines the action (resolves the destination) based on the registration rule. The determined action is registered in the flow cache of the software relay unit <b>507</b> and also is responded to the FPGA <b>502</b>. The software relay unit <b>507</b> functions as a slow path.</p><p id="p-0035" num="0034">Japanese National Publication of International Patent Application No. 2020-502828, and Japanese Laid-open Patent Publication No. 2016-134876 are disclosed as related art.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0036" num="0035">According to an aspect of the embodiments, an information processing device includes a field programmable gate array configured to store route information in flow control, and forward packets according to the route information; one or more memories configured to store a flow cache that includes at least a part of the route information; and one or more processors coupled to the one or more memories and the one or more processors configured to divide the route information into a plurality of division areas; and acquire hit information extracted from each of the entries in a first division area of the plurality of division areas to delete a part of entries of the flow cache stored in the one or more memories, the first division area including flows whose number is greater than a threshold value.</p><p id="p-0037" num="0036">The object and advantages of the invention will be realized and attained by means of the elements and combinations particularly pointed out in the claims.</p><p id="p-0038" num="0037">It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are not restrictive of the invention.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram exemplarily illustrating a hardware configuration of an information processing device that achieves a function of a virtual router as an example of an embodiment;</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating a functional configuration of a virtual relay device as an example of the embodiment;</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram exemplarily illustrating an entry of an FIB in the virtual relay device as an example of the embodiment;</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram for explaining a management approach for the FIB in the virtual relay device as an example of the embodiment;</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram exemplarily illustrating a digest output instruction in the virtual relay device as an example of the embodiment;</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart for explaining a process at the time of flow registration in a relay control unit of the virtual relay device as an example of the embodiment;</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart for explaining a process at the time of flow deletion in the relay control unit of the virtual relay device as an example of the embodiment;</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart for explaining a process of an offload flow hit information confirmation unit in the virtual relay device as an example of the embodiment;</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating a total time taken at the time of acquiring hit information by the virtual relay device as an example of the embodiment in comparison with a total time taken at the time of acquiring the hit information by each of approaches of indirect access only and digest output only; and</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram exemplarily illustrating a configuration of a prior hardware-offloaded virtual relay device.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0049" num="0048">In order to age out the flow cache, the FPGA control unit <b>501</b> has to refer to hit information of the flow in the FPGA FIB <b>5051</b>.</p><p id="p-0050" num="0049">However, in such a hardware-offloaded prior virtual relay device, the FPGA control unit <b>501</b> (the control unit <b>506</b> and the software relay unit <b>507</b>) achieved by software is not allowed to directly access the large-capacity memory <b>505</b> on the FPGA <b>502</b>.</p><p id="p-0051" num="0050">Therefore, the FPGA control unit <b>501</b> acquires the hit information in the FPGA FIB <b>5051</b> via indirect access using the register group <b>504</b>.</p><p id="p-0052" num="0051">However, such indirect access using the register group <b>504</b> has a large delay, and when the number of offloaded flows grows greater, the time taken for hit information confirmation processing for age-out becomes enormous.</p><p id="p-0053" num="0052">When aging processing is performed by indirect access using the register group <b>504</b>, for example, if it takes 40&#x3bc; seconds to age out one entry in the FPGA FIB <b>5051</b>, it takes as much as about 1300 seconds for 32 million entries. Here, even if the usage rate of the FPGA FIB <b>5051</b> is 50%, it takes 600 seconds (10 minutes) or more, which is impractical.</p><p id="p-0054" num="0053">One of the objects of the present embodiments is to reduce the time taken for acquiring hit information for performing aging.</p><p id="p-0055" num="0054">According to one embodiment, the time taken for acquiring hit information for performing aging may be reduced.</p><p id="p-0056" num="0055">In order to lessen the time taken for age-out processing in a virtual relay device that has been hardware-offloaded to the FPGA as illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, it is conceivable to create digest information that summarizes only hit information of each entry of the FIB (FPGA FIB), inside the FPGA.</p><p id="p-0057" num="0056">For example, the software relay unit of the FPGA control unit issues a digest information creation request to the FPGA, and the FPGA creates the digest information summarizing only the hit information of each entry of the FIB in response to this creation request. The FPGA forwards the created digest information to a memory area (host memory area) accessible from the FPGA control unit (software) via DMA.</p><p id="p-0058" num="0057">Here, since the generation time for the digest information and the forwarding time for the generated digest information to the host memory area depend only on the total number of entries of the FIB, it is completed in a fixed time irrespective of the number of offload flows. In addition, since the access to the FIB is internal processing of the FPGA, it is also much faster than indirect access via registers from software.</p><p id="p-0059" num="0058">However, in such an approach of creating the digest, it still takes time to generate the digest because all entries of the FPGA FIB are inspected regardless of the presence or absence of flow registration.</p><p id="p-0060" num="0059">For example, when the number of registration flows of the FPGA FIB is small, the indirect access approach using registers is completed in a shorter time in some cases. In addition, the occurrence of avoidable access to an entry without registration in the FPGA FIB consumes memory bandwidth, and there is a possibility of degrading the packet relay performance during digest generation.</p><p id="p-0061" num="0060">Thus, in a virtual relay device <b>1</b> (refer to <figref idref="DRAWINGS">FIG. <b>2</b></figref>) as an example of an embodiment, creation of a digest of hit information while reducing avoidable access to the FPGA FIB is achieved.</p><p id="p-0062" num="0061">Hereinafter, embodiments relating to a relay device, a control method, and a control program will be described with reference to the drawings. Note that the embodiments to be described below are merely examples, and there is no intention to exclude application of various modifications and techniques not explicitly described in the embodiments. For example, the present embodiments may be variously modified and carried out without departing from the spirit thereof. Furthermore, each drawing is not intended to include only components illustrated in the drawing and may include another function and the like.</p><p id="p-0063" num="0062">(A) Configuration</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram exemplarily illustrating a hardware configuration of an information processing device <b>20</b> that achieves a function of the virtual relay device <b>1</b> (refer to the reference sign <b>1</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) as an example of an embodiment.</p><p id="p-0065" num="0064">The information processing device <b>20</b> may also be, for example, a computer having a server function. The information processing device <b>20</b> is configured to achieve a function as the virtual relay device (relay device) <b>1</b> and has a packet relay function.</p><p id="p-0066" num="0065">The virtual relay device <b>1</b> may also be, for example, a virtual switch that achieves a function as a switch or may also be a virtual router that achieves a function as a router.</p><p id="p-0067" num="0066">As exemplarily illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the information processing device <b>20</b> includes a central processing unit (CPU) <b>2</b>, a host memory <b>3</b>, an FPGA network interface card (NIC) <b>4</b>, and a storage <b>5</b>.</p><p id="p-0068" num="0067">The host memory <b>3</b> and the CPU <b>2</b> are connected via a memory bus. In addition, the CPU <b>2</b> and the FPGA NIC <b>4</b> are connected via an input/output (I/O) bus #<b>1</b>, and the CPU <b>2</b> and the storage <b>5</b> are connected via an I/O bus #<b>2</b>, separately.</p><p id="p-0069" num="0068">The CPU <b>2</b> is a processing device that performs various kinds of control and arithmetic operations and achieves various functions by executing an operating system (OS) and programs stored in the host memory <b>3</b>. For example, the CPU <b>2</b> achieves a function as a relay control unit <b>200</b> (refer to <figref idref="DRAWINGS">FIG. <b>2</b></figref>) of the virtual relay device <b>1</b>, which will be described later.</p><p id="p-0070" num="0069">Note that a program (control program) for achieving functions as the relay control unit <b>200</b> is provided in a form recorded in a computer-readable recording medium, for example, a flexible disk, a compact disc (CD) (CD-read only memory (ROM), CD-recordable (R), CD-rewritable (RW), or the like), a digital versatile disc (DVD) (DVD-ROM, DVD-RAM, DVD-R, DVD+R, DVD-RW, DVD+RW, high definition (HD) DVD, or the like), a Blu-ray disc, a magnetic disk, an optical disc, a magneto-optical disk, or the like. Then, the computer reads the program from the recording medium to forward the program to an internal storage device or an external storage device and stores the program to use. In addition, for example, the program may also be recorded in a storage device (recording medium) such as a magnetic disk, an optical disc, or a magneto-optical disk and provided from the storage device to the computer via a communication route.</p><p id="p-0071" num="0070">When the functions as the relay control unit <b>200</b> are achieved, the program stored in an internal storage device (the host memory <b>3</b> in the present embodiment) is executed by a microprocessor (the CPU <b>2</b> in the present embodiment) of the computer. At this time, the computer may also read and execute the program recorded in the recording medium.</p><p id="p-0072" num="0071">The host memory <b>3</b> is a random access memory (RAM) used as a main storage device of the information processing device <b>20</b> and is used as a primary storage memory or a working memory. The host memory <b>3</b> temporarily stores at least a part of the OS and the application programs to be executed by the CPU <b>2</b>. Furthermore, the host memory <b>3</b> stores various types of data involved in processing by the CPU <b>2</b>. The application programs may also include the control program (not illustrated) executed by the CPU <b>2</b> in order for the information processing device <b>20</b> to achieve the functions as the relay control unit <b>200</b> of the virtual relay device <b>1</b> of the present embodiment.</p><p id="p-0073" num="0072">The storage <b>5</b> is a storage device such as a hard disk drive (HDD), a solid state drive (SSD), or a storage class memory (SCM) and is configured to store various kinds of data.</p><p id="p-0074" num="0073">The FPGA NIC <b>4</b> is an interface card prepared with an FPGA <b>10</b>. The FPGA NIC <b>4</b> may also be referred to as a smart NIC <b>4</b>.</p><p id="p-0075" num="0074">The FPGA NIC <b>4</b> has a memory (not illustrated). The corresponding memory stores a program (configuration data) to be a base of a logic circuit in the FPGA <b>10</b>.</p><p id="p-0076" num="0075">The FPGA <b>10</b> is a device in which the circuit design of a digital circuit is electrically changeable. The FPGA <b>10</b> is a large scale integration circuit (LSI) having a great number of logical gates. The FPGA <b>10</b> functions as a predetermined logic circuit by writing configuration data describing a logical relationship and a connection relationship between logical gates, to a configuration RAM (not illustrated) included in the FPGA <b>10</b>.</p><p id="p-0077" num="0076">When the power of the FPGA <b>10</b> is turned on, a program file (bitstream data) is loaded in the FPGA <b>10</b> and loaded into a static random access memory (SRAM) (not illustrated) in the FPGA <b>10</b>.</p><p id="p-0078" num="0077">Each bit of the bitstream data loaded into the SRAM serves as an information source of a user circuit achieved on the FPGA <b>10</b>, and a resource mounted in the FPGA <b>10</b> is customized to achieve a predetermined circuit. In the present information processing device <b>20</b>, the FPGA <b>10</b> achieves some functions of the virtual relay device <b>1</b>.</p><p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating a functional configuration of the virtual relay device <b>1</b> as an example of the embodiment.</p><p id="p-0080" num="0079">The virtual relay device <b>1</b> exemplarily illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes the relay control unit <b>200</b> and a packet processing unit <b>100</b>.</p><p id="p-0081" num="0080">The packet processing unit <b>100</b> is configured to process a packet of the input flow and is achieved by the FPGA <b>10</b>.</p><p id="p-0082" num="0081">This means that, in the present virtual relay device <b>1</b>, functions as the packet processing unit <b>100</b> are hardware-offloaded to the FPGA <b>10</b>.</p><p id="p-0083" num="0082">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the packet processing unit <b>100</b> (FPGA <b>10</b>) includes a DMA controller/IO bus controller <b>101</b>, a virtual port processing unit <b>102</b>, a register group <b>103</b>, an offload relay unit <b>104</b>, a digest processing unit <b>105</b>, and an FPGA memory <b>108</b>.</p><p id="p-0084" num="0083">The DMA controller/IO bus controller <b>101</b> achieves data forwarding with the host memory <b>3</b> by DMA. The DMA controller/IO bus controller <b>101</b> reads a hit information digest <b>106</b> created by the digest processing unit <b>105</b>, which will be described later, from the FPGA memory <b>108</b> and stores the read hit information digest <b>106</b> in a predetermined storage area (hit information digest write area <b>201</b>) of the host memory <b>3</b>.</p><p id="p-0085" num="0084">The virtual port processing unit <b>102</b> manages virtual ports that are forwarding sources and forwarding destinations of packets targeted for processing.</p><p id="p-0086" num="0085">The register group <b>103</b> includes a plurality of registers. The registers store data and the like exchanged with the relay control unit <b>200</b> (CPU <b>2</b>). For example, a first register of the register group <b>103</b> stores a digest output instruction output by a hit information digest output instruction generation unit <b>203</b>, which will be described later. A second register of the register group <b>103</b> stores a hit information acquisition request output from a per-flow hit information confirmation unit <b>204</b>, which will be described later. In addition, a third register of the register group <b>103</b> stores hit information (hit information confirmation response) created by the digest processing unit <b>105</b>, which will be described later, in response to that hit information acquisition request.</p><p id="p-0087" num="0086">The offload relay unit <b>104</b> processes, for example, a packet (a packet targeted for processing) received from a virtual machine (VM) (not illustrated) or the like with reference to an FIB <b>107</b>. The offload relay unit <b>104</b> calculates a hash value based on, for example, the IP address and port number of the transmission source, the IP address and port number of the transmission destination, and the like in the flow of the packet that has been received and refers to the FIB <b>107</b> based on this calculated hash value. Consequently, an action to be performed on the packet targeted for processing is acquired. The offload relay unit <b>104</b> processes the packet in accordance with the acquired action.</p><p id="p-0088" num="0087">In addition, when the flow of the packet that has been received is not registered in the FIB <b>107</b>, the offload relay unit <b>104</b> inquires of the relay control unit <b>200</b> for the action to be performed on the corresponding flow and causes the relay control unit <b>200</b> to resolve the destination. The fact that the flow of the packet that has been received is not registered in the FIB <b>107</b> may also be referred to as a flow miss.</p><p id="p-0089" num="0088">The FPGA memory <b>108</b> stores data generated by the FPGA <b>10</b> and information used by the FPGA <b>10</b>.</p><p id="p-0090" num="0089">The FIB <b>107</b> is formed in the FPGA memory <b>108</b>. The FIB <b>107</b> is route information representing a relay rule to be referred to when the offload relay unit <b>104</b>, which will be described later, forwards a packet. The FIB <b>107</b> is configured as, for example, a hash table reserved in a continuous area in the storage area of the FPGA memory <b>108</b>. The FIB <b>107</b> may also be referred to as an FPGA FIB <b>107</b>.</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram exemplarily illustrating an entry of the FIB <b>107</b> in the virtual relay device <b>1</b> as an example of the embodiment.</p><p id="p-0092" num="0091">The entry of the FIB <b>107</b> exemplarily illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> has a valid bit, a hit bit, a match rule, and an action, and an entry ID is set for this entry. The entry ID is generated (calculated) based on the hash value of the match rule.</p><p id="p-0093" num="0092">The match rule is information for identifying the flow, and for example, a combination of the input port ID and the header information of the packet, or the like may also be used. The action is information indicating the handling of a packet that matches the match rule, in which, for example, forward or drop, designation of the output port, rewriting of header information, and the like are prescribed.</p><p id="p-0094" num="0093">The valid bit is a value (flag) indicating whether the corresponding entry is valid or invalid, where, for example, 1 is set when the corresponding entry is valid, and 0 is set when the corresponding entry is invalid.</p><p id="p-0095" num="0094">The hit bit is a value indicating whether or not the entry is accessed, where, for example, 1 is set when the entry is referred to (a hit is made), and 0 is set when the entry is not referred to (no hit is made). The hit bit value in the entry of the FIB <b>107</b> will be sometimes referred to as hit information.</p><p id="p-0096" num="0095">Hereinafter, the flow registered in the FPGA FIB <b>107</b> will be sometimes referred to as an offload flow.</p><p id="p-0097" num="0096">In addition, in the present virtual relay device <b>1</b>, the area (continuous area) of the FIB <b>107</b> is divided into a plurality of areas (division areas) and managed.</p><p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram for explaining a management approach for the FIB <b>107</b> in the virtual relay device <b>1</b> as an example of the embodiment. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the reference sign A indicates the FIB <b>107</b> before division, and the reference sign B indicates the FIB <b>107</b> in a divided state.</p><p id="p-0099" num="0098">This <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example in which the FIB <b>107</b> with 32 million entries (refer to the reference sign A) is divided into 32 areas (division areas) each with one million entries (refer to the reference sign B) and managed.</p><p id="p-0100" num="0099">In the present embodiment, the bit width of the registers of the register group <b>103</b> is assumed as, for example, 32 bits, and in line with this, the FIB <b>107</b> is divided into 32 areas of division areas #<b>0</b> to #<b>31</b> and managed.</p><p id="p-0101" num="0100">In addition, the hit information digest <b>106</b> is stored in a predetermined storage area of the FPGA memory <b>108</b>. The hit information digest <b>106</b> is information representing the hit information (hit bit) of each entry of the FPGA FIB <b>107</b> and is configured as a bit string in which a plurality of bits corresponding to each entry of the FPGA FIB <b>107</b> is arranged.</p><p id="p-0102" num="0101">In the hit information digest <b>106</b>, the hit information (hit bit) read from each entry of the FPGA FIB <b>107</b> by the digest processing unit <b>105</b>, which will be described later, is registered at each corresponding bit position.</p><p id="p-0103" num="0102">The digest processing unit <b>105</b> creates digest information about the FIB <b>107</b>. The digest information is obtained by extracting only the hit bit values of the entries in the FIB <b>107</b> and arranging the extracted hit bit values in the order of the entry ID. By referring to this digest information, an area accessed in the FIB <b>107</b> may be grasped.</p><p id="p-0104" num="0103">In addition, for the plurality of division areas constituting the FIB <b>107</b>, the digest processing unit <b>105</b> is capable of creating the digest information in units of division areas.</p><p id="p-0105" num="0104">Then, the digest processing unit <b>105</b> creates the digest information only for a division area for which the creation of the digest information is instructed in the digest output instruction created by the hit information digest output instruction generation unit <b>203</b>, among the plurality of division areas constituting the FIB <b>107</b>.</p><p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram exemplarily illustrating the digest output instruction in the virtual relay device <b>1</b> as an example of the embodiment.</p><p id="p-0107" num="0106">The digest output instruction is configured as a bit string in which the same number (N: N=32 in the present embodiment) of bits as the number of division areas constituting the FPGA FIB <b>107</b> are arranged, and each bit corresponds to the division areas of the FIB <b>107</b> on a one-to-one basis.</p><p id="p-0108" num="0107">In addition, the value of each bit in the digest output instruction represents whether or not the digest information is to be created for the corresponding division area, where, for example, 1 is set for a division area for which the digest information is to be created, and 0 is set for a division area for which the digest information is not to be created.</p><p id="p-0109" num="0108">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, it is indicated that the digest information is to be created for the division area #<b>1</b>, but the digest information is not to be created for the other division areas.</p><p id="p-0110" num="0109">The digest processing unit <b>105</b> creates the digest information only for a division area for which 1 (to be created) is set in the digest output instruction, in accordance with the digest output instruction read from the first register of the register group.</p><p id="p-0111" num="0110">The digest processing unit <b>105</b> accesses the FPGA FIB <b>107</b> only for a division area for which 1 (to be created) is set in the digest output instruction and extracts the hit information (hit bit) of each entry included in this division area. In the FPGA memory <b>108</b>, the digest processing unit <b>105</b> stores the extracted hit information of each entry in the corresponding memory positions (areas) in the hit information digest <b>106</b>. Note that the digest processing unit <b>105</b> sets zero (conducts zero padding) in a memory position in the hit information digest <b>106</b> corresponding to a division area for which 0 (not to be created) is set in the digest output instruction.</p><p id="p-0112" num="0111">The digest processing unit <b>105</b> may also skip the process of creating the digest information for division areas for which 0 (not to be created) is set in the digest output instruction or alternatively, may also fill memory areas corresponding to these division areas in the hit information digest <b>106</b> with zeros.</p><p id="p-0113" num="0112">In the hit information digest <b>106</b>, the digest information is stored only in an area corresponding to a digest output division area.</p><p id="p-0114" num="0113">The digest processing unit <b>105</b> writes a copy of the hit information digest <b>106</b> to the hit information digest write area <b>201</b> of the host memory <b>3</b> via the DMA controller/IO bus controller <b>101</b>. The copy of the hit information digest <b>106</b> contains the digest information of all the areas of the FPGA FIB <b>107</b>.</p><p id="p-0115" num="0114">The relay control unit <b>200</b> is achieved by the CPU <b>2</b> of the information processing device <b>20</b> constituting the present virtual relay device <b>1</b> by executing a program.</p><p id="p-0116" num="0115">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the relay control unit <b>200</b> has functions as a control unit <b>210</b>, a software relay unit <b>211</b>, the hit information digest write area <b>201</b>, an offload flow hit information confirmation unit <b>202</b>, an offload flow count management table <b>205</b>, an offload flow database (DB) <b>206</b>, and a flow offload processing unit <b>207</b>.</p><p id="p-0117" num="0116">The control unit <b>210</b> resolves the destination for the flow. The control unit <b>210</b> determines the action (resolves the destination) in accordance with a preset registration rule <b>212</b>. The registration rule <b>212</b> may also be, for example, an ACL. In addition, the control unit <b>210</b> may also analyze destination information based on, for example, a border gateway protocol (BGP), which is a route control protocol.</p><p id="p-0118" num="0117">The control unit <b>210</b> notifies the software relay unit <b>211</b> of information regarding the flow for which the destination has been resolved and causes the software relay unit <b>211</b> to register the information in a flow cache <b>213</b>.</p><p id="p-0119" num="0118">In addition, the control unit <b>210</b> performs aging on the flow cache <b>213</b> to delete (age out) entries for which hits have not been made for a certain period of time. When performing this aging, the control unit <b>210</b> refers to the hit information in each entry of the FPGA FIB <b>107</b>.</p><p id="p-0120" num="0119">The software relay unit <b>211</b> includes the flow cache <b>213</b>. The flow cache <b>213</b> stores the result of destination resolution performed by the control unit <b>210</b>. When an inquiry for the action for the flow of a packet is received from the packet processing unit <b>100</b>, the software relay unit <b>211</b> refers to the flow cache <b>213</b>. When the inquired flow is registered in the flow cache <b>213</b>, the software relay unit <b>211</b> responds to the packet processing unit <b>100</b> with the corresponding action.</p><p id="p-0121" num="0120">In the packet processing unit <b>100</b>, the packet is forwarded using information on the received action. In addition, in the packet processing unit <b>100</b>, the responded action is registered in the FIB <b>107</b>.</p><p id="p-0122" num="0121">In the software relay unit <b>211</b>, when the inquired flow is not registered in the flow cache <b>213</b>, the control unit <b>210</b> described above determines the action (resolves the destination) based on the registration rule <b>212</b>. The determined action is registered in the flow cache <b>213</b> of the software relay unit <b>211</b> and also is responded to the packet processing unit <b>100</b>. The software relay unit <b>211</b> functions as a slow path.</p><p id="p-0123" num="0122">The hit information digest write area <b>201</b> is formed in a predetermined storage area in the host memory <b>3</b>.</p><p id="p-0124" num="0123">A copy of the hit information digest <b>106</b> is written to this hit information digest write area <b>201</b> by the digest processing unit <b>105</b> of the packet processing unit <b>100</b> via the DMA controller/IO bus controller <b>101</b>.</p><p id="p-0125" num="0124">The flow offload processing unit <b>207</b> manages the number of offload flows for each division area in the FIB <b>107</b>. The number of offload flows denotes the number of flows (offload flows) set in the FPGA FIB <b>107</b>.</p><p id="p-0126" num="0125">The offload flow DB <b>206</b> manages information regarding the flows (offload flows) set in the FPGA FIB <b>107</b>. By referring to this offload flow DB <b>206</b>, the flows set in the FPGA FIB <b>107</b> may be grasped.</p><p id="p-0127" num="0126">For example, the offload flow DB <b>206</b> manages the storage position of each flow (offload flow) in the FPGA FIB <b>107</b>. This makes it easier to know in which division area in the FPGA FIB <b>107</b> each flow is stored.</p><p id="p-0128" num="0127">The flow offload processing unit <b>207</b> manages the number of offload flows for each division area, using the offload flow count management table <b>205</b>.</p><p id="p-0129" num="0128">In the offload flow count management table <b>205</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the number of offload flows is associated with the division area.</p><p id="p-0130" num="0129">When a flow (offload flow) is registered in the FIB <b>107</b>, the flow offload processing unit <b>207</b> increases (increments) the value of the number of offload flows of the corresponding division area by one. In addition, when an offload flow is deleted from the FIB <b>107</b>, the flow offload processing unit <b>207</b> subtracts one from (decrements) the value of the number of offload flows of the corresponding division area.</p><p id="p-0131" num="0130">The information constituting the offload flow count management table <b>205</b> is stored in, for example, a predetermined storage area of the host memory <b>3</b>. In addition, the offload flow count management table <b>205</b> is updated by an address calculation unit <b>208</b>, which will be described later.</p><p id="p-0132" num="0131">Furthermore, the flow offload processing unit <b>207</b> manages the flows (offload flows) registered in the FPGA FIB <b>107</b>, using the offload flow DB <b>206</b>.</p><p id="p-0133" num="0132">The offload flow DB <b>206</b>, for example, manages information specifying the flow and information indicating the registration position of the flow in the FIB <b>107</b> in association with each other. The information indicating the registration position of the flow in the FIB <b>107</b> may also be, for example, the address and the division area number in the FPGA memory <b>108</b>.</p><p id="p-0134" num="0133">When an FPGA FIB registration unit <b>209</b>, which will be described later, registers a flow in the FPGA FIB <b>107</b>, the flow offload processing unit <b>207</b> registers the corresponding flow in the offload flow DB <b>206</b>. In addition, when the FPGA FIB registration unit <b>209</b> deletes a flow from the FPGA FIB <b>107</b>, the flow offload processing unit <b>207</b> deletes the flow from the offload flow DB <b>206</b>.</p><p id="p-0135" num="0134">The flow offload processing unit <b>207</b> has functions as the address calculation unit <b>208</b> and the FPGA FIB registration unit <b>209</b>.</p><p id="p-0136" num="0135">For a flow (a flow targeted for registration) in which a flow miss has been detected by the packet processing unit <b>100</b>, the address calculation unit <b>208</b> performs arithmetic processing for registering information on the action responded by the control unit <b>210</b> or the software relay unit <b>211</b> in the FIB <b>107</b> of the packet processing unit <b>100</b>.</p><p id="p-0137" num="0136">The address calculation unit <b>208</b> calculates the registration entry position (address) in the FIB <b>107</b> from the hash value (CRC or the like) of the flow to be registered (registration flow). CRC is an abbreviation for cyclic redundancy check. The address calculation unit <b>208</b> may employ, for example, a remainder obtained by dividing the hash value of the registration flow by the total number of entries in the FIB <b>107</b> (the total number of FIB entries), as the registration entry position. Such a registration entry position is represented by following formula (1).</p><p id="p-0138" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Registration Entry Position=CRC32 (Flow) &#x26; (Total Number of FIB Entries&#x2212;1)&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0139" num="0137">In above formula (1), the sign &#x2018;&#x26;&#x2019; represents a bitwise AND. In addition, above formula (1) indicates a case where the total number of entries is two to the power of N.</p><p id="p-0140" num="0138">The address calculation unit <b>208</b> calculates a division area in which the registration flow is to be stored in the FIB <b>107</b>, from a value obtained by dividing the registration entry position calculated by above formula (1) by the number of entries in the division areas of the FIB <b>107</b>. The number that specifies the division area is referred to as the division area number. The division area number is represented by following formula (2).</p><p id="p-0141" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Division Area Number=Registration Entry Position/(Number of Entries in Division Areas)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0142" num="0139">The address calculation unit <b>208</b> manages the number of offload flows for each division area, using the offload flow count management table <b>205</b>. When a flow is registered in or deleted from the FIB <b>107</b>, the address calculation unit <b>208</b> increments or decrements the value of the entry in the offload flow count management table <b>205</b> corresponding to the division area number calculated using above formula (2).</p><p id="p-0143" num="0140">The FPGA FIB registration unit <b>209</b> registers the registration flow in the FPGA FIB <b>107</b>. The FPGA FIB registration unit <b>209</b> stores information on the registration flow (the match rule, the action, and the like) in the registration entry position calculated by the address calculation unit <b>208</b>.</p><p id="p-0144" num="0141">The offload flow hit information confirmation unit <b>202</b> has functions as the hit information digest output instruction generation unit <b>203</b> and the per-flow hit information confirmation unit <b>204</b>. The processing of the offload flow hit information confirmation unit <b>202</b> is repeatedly executed at regular intervals (for example, one-minute intervals).</p><p id="p-0145" num="0142">The hit information digest output instruction generation unit <b>203</b> verifies whether or not to cause the digest information to be output (created), based on the number of offload flows for each division area of the FPGA FIB <b>107</b>. Then, the hit information digest output instruction generation unit <b>203</b> creates the digest output instruction in which this verification result is reflected. When causing the digest information to be output for at least one division area, the hit information digest output instruction generation unit <b>203</b> issues the digest output instruction to the packet processing unit <b>100</b> (FPGA <b>10</b>).</p><p id="p-0146" num="0143">The hit information digest output instruction generation unit <b>203</b> compares the number of offload flows in each division area in the offload flow count management table <b>205</b> with a threshold value (digest output verification threshold value). The number of offload flows in the offload flow count management table <b>205</b> may also be referred to as the number of registration flows.</p><p id="p-0147" num="0144">When the number of offload flows exceeds the threshold value, the hit information digest output instruction generation unit <b>203</b> verifies that the digest information is to be output for the corresponding division area (digest output is to be made). In addition, when the number of offload flows is equal to or less than the threshold value, the hit information digest output instruction generation unit <b>203</b> verifies that the digest information of the division area is not to be output (no digest output is to be made).</p><p id="p-0148" num="0145">The hit information digest output instruction generation unit <b>203</b> verifies whether or not to cause the digest information to be output, for all the division areas constituting the FIB <b>107</b> and creates the digest output instruction in which this verification result is reflected.</p><p id="p-0149" num="0146">For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, in a bit string containing bits in correspondence with the division areas, the hit information digest output instruction generation unit <b>203</b> sets 1 in correspondence with a division area for which the digest output is verified to be made and sets 0 in correspondence with a division area for which no digest output is verified to be made.</p><p id="p-0150" num="0147">In the present virtual relay device <b>1</b>, when the time taken for the software relay unit <b>211</b> to acquire the hit information of an entry of the FPGA FIB <b>107</b> via the third register of the register group <b>103</b> exceeds the time taken for creating the digest information of a division area of the FPGA FIB <b>107</b>, the digest information regarding the corresponding division area is written in the hit information digest write area <b>201</b>.</p><p id="p-0151" num="0148">Hereinafter, the acquisition of the hit information of an entry of the FPGA FIB <b>107</b> via the third register of the register group <b>103</b> by the relay control unit <b>200</b> will be sometimes referred to as indirect access. In addition, the creation of the digest information of a division area of the FPGA FIB <b>107</b> and the output of the created digest information to the hit information digest write area <b>201</b> by the digest processing unit <b>105</b> will be sometimes referred to as digest output.</p><p id="p-0152" num="0149">The number of offload flows satisfying inequality (3) indicated below may also be used as the digest output verification threshold value.</p><p id="p-0153" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(Time Taken for Indirect Access to Entry of FPGA FIB 107)&#xd7;Number of Offload Flows&#x3e;(Time to Create Digest Information of Division Area)&#x2003;&#x2003; (3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0154" num="0150">Based on above inequality (3), the digest output verification threshold value can be represented by following inequality (4).</p><p id="p-0155" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Digest Output Verification Threshold Value&#x3e;(Time to Create Digest Information of Division Area)/(Time Taken for Indirect Access to Entry of FPGA FIB 107)&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0156" num="0151">Here, as the time taken for the indirect access to an entry of the FPGA FIB <b>107</b>, for example, the time measured in advance may also be set as a parameter at the time of starting up the control program of the present virtual relay device <b>1</b>. In addition, the measurements may be taken at the time of starting up the control program of the present virtual relay device <b>1</b>, and this measured value may also be automatically set.</p><p id="p-0157" num="0152">Furthermore, as the time to create the digest information of a division area, a value obtained by dividing the time taken for generating the digest of the entire FPGA FIB <b>107</b> by the number of divisions (total number of division areas) of the FPGA FIB <b>107</b> may also be used. Note that the time taken for generating the digest of the entire FPGA FIB <b>107</b> may also be measured in advance similarly to the time taken for the indirect access, or may also be automatically measured at the time of initialization of the present virtual relay device <b>1</b>, and may be changed and carried out as appropriate.</p><p id="p-0158" num="0153">A division area in which the number of offload flows is greater than the digest output verification threshold value may also be referred to as a digest output division area. In addition, a division area in which the number of offload flows is equal to or less than the digest output verification threshold value may also be referred to as an indirect access division area.</p><p id="p-0159" num="0154">The hit information digest output instruction generation unit <b>203</b> creates the digest output instruction (refer to <figref idref="DRAWINGS">FIG. <b>5</b></figref>) that the digest processing unit <b>105</b> of the packet processing unit <b>100</b> is to be notified of.</p><p id="p-0160" num="0155">In a bit string (digest output instruction) in which a plurality of (N: N=32 in the present embodiment) bits corresponding to a plurality of (N) division areas constituting the FIB <b>107</b> is arranged, the hit information digest output instruction generation unit <b>203</b> sets 1 in a bit corresponding to a division area for which the digest information has been determined to be created. In addition, in the corresponding bit string, the hit information digest output instruction generation unit <b>203</b> sets 0 in a bit corresponding to a division area for which the digest information is determined not to be created.</p><p id="p-0161" num="0156">The hit information digest output instruction generation unit <b>203</b> stores the created digest output instruction in the first register of the register group <b>103</b> of the FPGA <b>10</b>.</p><p id="p-0162" num="0157">After the output of the digest information by the digest processing unit <b>105</b> of the packet processing unit <b>100</b> is completed, the per-flow hit information confirmation unit <b>204</b> confirms the hit information (hit bit) in the entry of the FPGA FIB <b>107</b> individually for all the offload flows registered in the offload flow DB.</p><p id="p-0163" num="0158">In addition, when confirming the hit information (hit bit) in the entry of the FPGA FIB <b>107</b>, the per-flow hit information confirmation unit <b>204</b> refers to the digest output instruction created by the hit information digest output instruction generation unit <b>203</b> to determine the method of confirming the hit information for each flow.</p><p id="p-0164" num="0159">The per-flow hit information confirmation unit <b>204</b> refers to the offload flow DB <b>206</b> to specify division areas in which each flow is stored in the FPGA FIB <b>107</b>.</p><p id="p-0165" num="0160">Then, the per-flow hit information confirmation unit <b>204</b> refers to the digest output instruction and, for a division area in which the flow targeted for processing is stored, confirms whether 1 is set (to be created) or 0 is set (not to be created) in the digest output instruction.</p><p id="p-0166" num="0161">The digest information has been created by the digest processing unit <b>105</b> for a division area for which 1 is set in the digest output instruction, and the created digest information has been stored in the hit information digest write area <b>201</b>. Thus, for a flow registered in a division area for which 1 is set in the digest output instruction in this manner, the per-flow hit information confirmation unit <b>204</b> reads and confirms the digest information stored in the hit information digest write area <b>201</b>.</p><p id="p-0167" num="0162">On the other hand, for a division area for which 0 is set in the digest output instruction, the digest information has not been created by the digest processing unit <b>105</b>. Thus, for a flow registered in a division area for which 0 is set in the digest output instruction in this manner, the per-flow hit information confirmation unit <b>204</b> issues a hit information acquisition request to the second register of the register group <b>103</b> for each flow and reads and confirms a hit information confirmation response stored in the third register of the register group <b>103</b> in response to the hit information acquisition request. For example, for a flow registered in a division area for which 0 is set in the digest output instruction, the per-flow hit information confirmation unit <b>204</b> acquires the hit information via the second and third registers of the register group <b>103</b> of the FPGA <b>10</b>.</p><p id="p-0168" num="0163">(B) Operation</p><p id="p-0169" num="0164">A process at the time of registering a flow in the relay control unit <b>200</b> of the virtual relay device <b>1</b> as an example of the embodiment configured as described above will be described with reference to the flowchart (steps A<b>1</b> to A<b>8</b>) illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0170" num="0165">In step A<b>1</b>, the software relay unit <b>211</b> acquires information (flow information) on a flow to be newly registered, from the control unit <b>210</b>.</p><p id="p-0171" num="0166">In step A<b>2</b>, the software relay unit <b>211</b> registers the corresponding flow to be newly registered, in the flow cache <b>213</b>.</p><p id="p-0172" num="0167">In step A<b>3</b>, the software relay unit <b>211</b> converts the flow into a format registerable in the FPGA FIB <b>107</b>.</p><p id="p-0173" num="0168">In step A<b>4</b>, the software relay unit <b>211</b> computes the hash value from the search key of the converted flow.</p><p id="p-0174" num="0169">In step A<b>5</b>, the software relay unit <b>211</b> calculates the registration address and the division area from the hash value calculated in step A<b>4</b>.</p><p id="p-0175" num="0170">In step A<b>6</b>, the software relay unit <b>211</b> increments the number of counts in the offload flow count management table <b>205</b> by one for the number of offloads corresponding to the division area determined in step A<b>5</b>.</p><p id="p-0176" num="0171">In step A<b>7</b>, the software relay unit <b>211</b> adds the division area and address information in the FPGA FIB <b>107</b> in which the corresponding flow is to be registered, to the information (flow information) on the corresponding flow to be newly registered and registers the added information in the offload flow DB <b>206</b>.</p><p id="p-0177" num="0172">In step A<b>8</b>, the flow is registered in the FPGA FIB <b>107</b>, and the process is ended.</p><p id="p-0178" num="0173">Next, a process at the time of deleting a flow in the relay control unit <b>200</b> of the virtual relay device <b>1</b> as an example of the embodiment will be described with reference to the flowchart (steps B<b>1</b> to B<b>7</b>) illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0179" num="0174">In step B<b>1</b>, the software relay unit <b>211</b> acquires the flow information on a flow to be deleted, from the control unit <b>210</b>.</p><p id="p-0180" num="0175">In step B<b>2</b>, the software relay unit <b>211</b> deletes the corresponding flow to be deleted, from the flow cache <b>213</b>.</p><p id="p-0181" num="0176">In step B<b>3</b>, the software relay unit <b>211</b> converts the flow into a format registerable in the FPGA FIB <b>107</b>.</p><p id="p-0182" num="0177">In step B<b>4</b>, the software relay unit <b>211</b> computes the hash value from the search key of the converted flow.</p><p id="p-0183" num="0178">In step B<b>5</b>, the software relay unit <b>211</b> calculates the registration address and the division area from the hash value calculated in step B<b>4</b>.</p><p id="p-0184" num="0179">In step B<b>6</b>, the software relay unit <b>211</b> decrements the number of counts in the offload flow count management table <b>205</b> by one for the number of offloads corresponding to the division area determined in step B<b>5</b>.</p><p id="p-0185" num="0180">In step B<b>7</b>, the software relay unit <b>211</b> deletes the flow information on the corresponding flow to be deleted, from the offload flow DB <b>206</b>. In addition, the software relay unit <b>211</b> deletes the flow from the FPGA FIB <b>107</b> and ends the process.</p><p id="p-0186" num="0181">Next, a process of the offload flow hit information confirmation unit <b>202</b> in the virtual relay device <b>1</b> as an example of the embodiment will be described with reference to the flowchart (steps C<b>1</b> to C<b>16</b>) illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0187" num="0182">In step C<b>1</b>, the hit information digest output instruction generation unit <b>203</b> initializes a variable D used for the digest output instruction with zero. The variable D is a bit string in which the same number (N: N=32 in the present embodiment) of bits as the number of division areas constituting the FPGA FIB <b>107</b> are arranged, and the corresponding bit string is prepared in correspondence with the division areas constituting the FPGA FIB <b>107</b>. For example, an i-th bit (bit i) in the variable D corresponds to a division area #i. The variable D may also be referred to as a bit string D.</p><p id="p-0188" num="0183">In step C<b>2</b>, a loop process for repeatedly carrying out the control up to step C<b>6</b> is started for all the division areas existing in the FPGA FIB <b>107</b>.</p><p id="p-0189" num="0184">In step C<b>3</b>, the hit information digest output instruction generation unit <b>203</b> acquires the number of offload flows (Ocnt_i) in the offload flow count management table <b>205</b> corresponding to the division area i.</p><p id="p-0190" num="0185">In step C<b>4</b>, the hit information digest output instruction generation unit <b>203</b> confirms whether the number of offload flows (Ocnt_i) corresponding to the division area i exceeds the threshold value (digest output verification threshold value). When the number of offload flows (Ocnt_i) corresponding the division area i does not exceed the threshold value as a result of the confirmation (refer to the NO route in step C<b>4</b>), the process proceeds to step C<b>6</b>.</p><p id="p-0191" num="0186">On the other hand, as a result of the confirmation in step C<b>4</b>, when the number of offload flows (Ocnt_i) corresponding to the division area i exceeds the threshold value (refer to the YES route in step C<b>4</b>), the process proceeds to step C<b>5</b>.</p><p id="p-0192" num="0187">In step C<b>5</b>, the hit information digest output instruction generation unit <b>203</b> sets 1 in the bit i in the variable D. Thereafter, the process proceeds to step C<b>6</b>.</p><p id="p-0193" num="0188">In step C<b>6</b>, a loop end process corresponding to step C<b>2</b> is carried out. Here, when the process for all the division areas is completed, the control advances to step C<b>7</b>.</p><p id="p-0194" num="0189">In step C<b>7</b>, the hit information digest output instruction generation unit <b>203</b> issues the variable D to the FPGA <b>10</b> as a digest output instruction. The issued digest output instruction is stored in the first register of the register group <b>103</b>.</p><p id="p-0195" num="0190">In step C<b>8</b>, the offload flow hit information confirmation unit <b>202</b> waits until a notification of the completion of the digest generation from the FPGA <b>10</b> is acknowledged. When a notification of the completion of the digest generation from the FPGA <b>10</b> is acknowledged, the process proceeds to step C<b>9</b>.</p><p id="p-0196" num="0191">In step C<b>9</b>, a loop process for repeatedly carrying out control up to step C<b>16</b> is started for all the flows (offload flows) registered in the offload flow DB <b>206</b>. The flow registered in the offload flow DB <b>206</b> is represented by the reference sign f.</p><p id="p-0197" num="0192">In step C<b>10</b>, the per-flow hit information confirmation unit <b>204</b> acquires information on the division area i in which the flow f is registered, from the offload flow DB <b>206</b>.</p><p id="p-0198" num="0193">In step C<b>11</b>, the per-flow hit information confirmation unit <b>204</b> confirms whether the bit i in the digest output instruction (bit string D) has 1. As a result of the confirmation, when the bit i has 0 (refer to the NO route in step C<b>11</b>), the process proceeds to step C<b>12</b>.</p><p id="p-0199" num="0194">In step C<b>12</b>, the per-flow hit information confirmation unit <b>204</b> acquires the hit information of the entry of the FPGA FIB <b>107</b> via the third register of the register group <b>103</b> by the indirect access. For example, the per-flow hit information confirmation unit <b>204</b> reads and acquires the hit information (hit information confirmation response) stored in the third register of the register group <b>103</b>. Thereafter, the process proceeds to step C<b>15</b>.</p><p id="p-0200" num="0195">On the other hand, when the bit i has 1 as a result of the confirmation in step C<b>11</b> (refer to the YES route in step C<b>11</b>), the process proceeds to step C<b>13</b>.</p><p id="p-0201" num="0196">In step C<b>13</b>, the per-flow hit information confirmation unit <b>204</b> refers to the offload flow DB <b>206</b> to acquire the address where the flow f is registered in the FPGA FIB <b>107</b>.</p><p id="p-0202" num="0197">In step C<b>14</b>, the per-flow hit information confirmation unit <b>204</b> acquires the hit information corresponding to the address where the flow f is registered, from the copy of the hit information digest <b>106</b> stored in the hit information digest write area <b>201</b>. Thereafter, the process proceeds to step C<b>15</b>.</p><p id="p-0203" num="0198">In step C<b>15</b>, the per-flow hit information confirmation unit <b>204</b> notifies the control unit <b>210</b> of the hit information of the flow f. Based on this hit information, the hit status of each entry of the FPGA FIB <b>107</b> is grasped, and aging is performed to delete (age out) an entry for which a hit has not been made for a certain period of time.</p><p id="p-0204" num="0199">In step C<b>16</b>, a loop end process corresponding to step C<b>9</b> is carried out. Here, when the process for all the flows (offload flows) registered in the offload flow DB <b>206</b> is completed, the process is ended.</p><p id="p-0205" num="0200">(C) Effects</p><p id="p-0206" num="0201">As described above, according to the virtual relay device <b>1</b> as an example of the embodiment, the FPGA FIB <b>107</b> is divided into a plurality of areas (division areas), and the number of offload flows is managed for each division area, using the offload flow count management table <b>205</b>. Then, the hit information digest output instruction generation unit <b>203</b> switches between the indirect access and the digest output according to the number of offload flows for each division area to acquire the hit information in the FPGA FIB <b>107</b>. This enables the reduction of the time taken for acquiring the hit information for performing aging.</p><p id="p-0207" num="0202">For a division area (digest output division area) in which the number of offload flows is greater than the digest output verification threshold value, the hit information digest output instruction generation unit <b>203</b> causes the digest information to be created with the digest output instruction to the FPGA <b>10</b> (packet processing unit <b>100</b>).</p><p id="p-0208" num="0203">In the packet processing unit <b>100</b> (FPGA <b>10</b>), the digest processing unit <b>105</b> refers to the digest output instruction to create the digest information only for the digest output division area and registers the created digest information in the corresponding location in the hit information digest <b>106</b>.</p><p id="p-0209" num="0204">A copy of the hit information digest <b>106</b> created in this manner is stored in the hit information digest write area <b>201</b> of the host memory <b>3</b> via the DMA controller/IO bus controller <b>101</b>.</p><p id="p-0210" num="0205">This allows the per-flow hit information confirmation unit <b>204</b>, in the relay control unit <b>200</b>, to acquire the hit information of the flow stored in the digest output division area from the copy of the hit information digest <b>106</b> stored in the hit information digest write area <b>201</b>. Since the hit information digest write area <b>201</b> is formed in the host memory <b>3</b>, the per-flow hit information confirmation unit <b>204</b>, which inclusively means the control unit <b>210</b>, may reduce the time involved in acquiring the hit information of the flow stored in the digest output division area.</p><p id="p-0211" num="0206">In addition, at this time, since the digest processing unit <b>105</b> creates the digest information only for the digest output division area of the FPGA FIB <b>107</b>, the access to the FPGA FIB <b>107</b> for creating the hit information may be reduced. This may suppress a degradation in lookup performance during acquisition of the hit information.</p><p id="p-0212" num="0207">In addition, for the division area (indirect access division area) in which the number of offload flows is equal to or less than the digest output verification threshold value, the per-flow hit information confirmation unit <b>204</b> acquires the hit information of the entry of the FPGA FIB <b>107</b> by the indirect access via the third register of the register group <b>103</b>. For example, the per-flow hit information confirmation unit <b>204</b> reads and acquires the hit information (hit information confirmation response) stored in the third register of the register group <b>103</b>.</p><p id="p-0213" num="0208">The time taken for this acquisition of the hit information of the entry of the FPGA FIB <b>107</b> by the indirect access via the register increases according to the number of offload flows targeted for acquisition. In the present virtual relay device <b>1</b>, since the per-flow hit information confirmation unit <b>204</b> performs the acquisition for a division area in which the number of offload flows is equal to or less than the digest output verification threshold value, the per-flow hit information confirmation unit <b>204</b>, which inclusively means the control unit <b>210</b>, may reduce the time involved in acquiring the hit information for the indirect access division area.</p><p id="p-0214" num="0209"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating a total time taken at the time of acquiring the hit information by the virtual relay device <b>1</b> as an example of the embodiment in comparison with a total time taken at the time of acquiring the hit information by each of approaches of the indirect access (prior approach) only and the digest output only.</p><p id="p-0215" num="0210">In this <figref idref="DRAWINGS">FIG. <b>9</b></figref>, a simulation result of the relationship between the number of registration flows and the hit information acquisition time is illustrated as a graph, where the horizontal axis indicates the number of registration flows (number of offload flows) in the FPGA FIB <b>107</b>, and the vertical axis indicates the total time taken at the time of acquiring the hit information.</p><p id="p-0216" num="0211">In <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the reference sign A indicates a case where the hit information is acquired only by the indirect access via the register, and it can be seen that the time taken for acquiring the hit information increases according to the number of registration flows. In addition, the reference sign B indicates a case where the hit information is acquired only by the digest output, and it can be seen that the time taken for acquiring the hit information is unvaried regardless of the number of registration flows. The reference sign C indicates the result by the present virtual relay device <b>1</b>, and it can be seen that the hit information may be acquired in a shorter time than both of the approach only by the indirect access and the approach only by the digest output, regardless of the number of registration flows.</p><p id="p-0217" num="0212">According to the present virtual relay device <b>1</b>, even in terms of the maximum time taken for acquiring the hit information, the hit information may be acquired in a shorter time than the time taken only by the digest output.</p><p id="p-0218" num="0213">(D) Others</p><p id="p-0219" num="0214">Each configuration and each process of the present embodiments may be selected or omitted as needed or may also be appropriately combined.</p><p id="p-0220" num="0215">Then, the disclosed technique is not limited to the embodiments described above, and various modifications may be made and carried out without departing from the spirit of the present embodiments.</p><p id="p-0221" num="0216">Furthermore, the present embodiments may be carried out and manufactured by those skilled in the art according to the disclosure described above.</p><p id="p-0222" num="0217">All examples and conditional language provided herein are intended for the pedagogical purposes of aiding the reader in understanding the invention and the concepts contributed by the inventor to further the art, and are not to be construed as limitations to such specifically recited examples and conditions, nor does the organization of such examples in the specification relate to a showing of the superiority and inferiority of the invention. Although one or more embodiments of the present invention have been described in detail, it should be understood that the various changes, substitutions, and alterations could be made hereto without departing from the spirit and scope of the invention.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An information processing device comprising:<claim-text>a field programmable gate array configured to:<claim-text>store route information in flow control, and</claim-text><claim-text>forward packets according to the route information;</claim-text></claim-text><claim-text>one or more memories configured to store a flow cache that includes at least a part of the route information; and</claim-text><claim-text>one or more processors coupled to the one or more memories and the one or more processors configured to:<claim-text>divide the route information into a plurality of division areas; and</claim-text><claim-text>acquire hit information extracted from each of the entries in a first division area of the plurality of division areas to delete a part of entries of the flow cache stored in the one or more memories, the first division area including flows whose number is greater than a threshold value.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are further configured to<claim-text>create a digest output instruction that instructs creation of digest information indicating a summary of the hit information extracted from each of the plurality of the entries included in the first division area, wherein</claim-text><claim-text>the field programmable gate array is further configured to:<claim-text>create the digest information in response to the digest output instruction, and</claim-text><claim-text>forward the created digest information to the one or more memories by direct memory access.</claim-text></claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The information processing device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the threshold value is determined based on a value obtained by dividing a time period to create the digest information of the division areas by a time period to acquire the hit information extracted from each of the entries of a second division area including flows whose number is equal to or less than the threshold value stored in a register of the field programmable gate array.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The information processing device according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the one or more processors are further configured to<claim-text>acquire the hit information extracted from the second division area via the register for each of the entries to delete a part of entries of the flow cache stored in the one or more memories.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. A control method for a computer to execute a process comprising:<claim-text>causing a field programmable gate array to forward packets according to route information in flow control;</claim-text><claim-text>dividing the route information into a plurality of division areas; and</claim-text><claim-text>acquiring hit information extracted from each of the entries in a first division area of the plurality of division areas to delete a part of entries of flow cache including at least a part of the route information, the first division area including flows whose number is greater than a threshold value.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The control method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the process further comprising<claim-text>causing the field programmable gate array to:<claim-text>create digest information indicating a summary of the hit information extracted from each of the plurality of the entries included in the first division area, and</claim-text><claim-text>forward the created digest information to one or more memories by direct memory access.</claim-text></claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The control method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the threshold value is determined based on a value obtained by dividing a time period to create the digest information of the division areas by a time period to acquire the hit information extracted from each of the entries of a second division area including flows whose number is equal to or less than the threshold value stored in a register of the field programmable gate array.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The control method according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the process further comprising<claim-text>acquiring the hit information extracted from the second division area via the register for each of the entries to delete a part of entries of the flow cache.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A non-transitory computer-readable storage medium storing a control program that causes at least one computer to execute a process, the process comprising:<claim-text>causing a field programmable gate array to forward packets according to route information in flow control;</claim-text><claim-text>dividing the route information into a plurality of division areas; and</claim-text><claim-text>acquiring hit information extracted from each of the entries in a first division area of the plurality of division areas to delete a part of entries of flow cache including at least a part of the route information, the first division area including flows whose number is greater than a threshold value.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The non-transitory computer-readable storage medium according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the process further comprising<claim-text>causing the field programmable gate array to:<claim-text>create digest information indicating a summary of the hit information extracted from each of the plurality of the entries included in the first division area, and</claim-text><claim-text>forward the created digest information to one or more memories by direct memory access.</claim-text></claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The non-transitory computer-readable storage medium according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein<claim-text>the threshold value is determined based on a value obtained by dividing a time period to create the digest information of the division areas by a time period to acquire the hit information extracted from each of the entries of a second division area including flows whose number is equal to or less than the threshold value stored in a register of the field programmable gate array.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The non-transitory computer-readable storage medium according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the process further comprising<claim-text>acquiring the hit information extracted from the second division area via the register for each of the entries to delete a part of entries of the flow cache.</claim-text></claim-text></claim></claims></us-patent-application>
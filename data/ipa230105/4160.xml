<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004161A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004161</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17366490</doc-number><date>20210702</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>02</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0214</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0088</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0274</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>2201</main-group><subgroup>0201</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEM AND METHOD FOR GROUNDTRUTHING AND REMARKING MAPPED LANDMARK DATA</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>CNH Industrial America LLC</orgname><address><city>New Holland</city><state>PA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>McClelland</last-name><first-name>Brett Carson</first-name><address><city>Chicago</city><state>IL</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><orgname>CNH Industrial America LLC</orgname><role>02</role></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A control system for an autonomous work vehicle includes a controller configured to obtain map data for an area that the autonomous work vehicle is traversing, wherein the map data includes mapped landmarks. The controller is configured to determine a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor and to determine a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle. The controller is configured to determine a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle. The controller is configured to determine whether the landmark is accurately mapped in the map data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="139.70mm" wi="122.51mm" file="US20230004161A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="150.54mm" wi="124.54mm" file="US20230004161A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="215.05mm" wi="139.11mm" orientation="landscape" file="US20230004161A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="202.10mm" wi="146.05mm" file="US20230004161A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">The disclosure relates generally to an autonomous work vehicle.</p><p id="p-0003" num="0002">Certain self-driving work vehicles (e.g., autonomous work vehicles, semi-autonomous vehicles, work vehicles with autoguidance systems, etc.) are configured to traverse portions of a field with and/or without operator input. In planning a mission or operation for the work vehicle, a map is utilized that includes mapped data about landmarks (e.g., telephone poles, ditches, trees, etc.) within the area of the mission or operation. The mapped data for the landmarks are initially recorded by a user who drives around and mark these obstacles utilizing Global Navigation Satellite System (GNSS) and/or inertial measurement units (IMU) devices. When operating an autonomous work vehicle it is important to have confidence in the map data. Unfortunately, as time passes, the accuracy of the mapped landmarks on the map degrades (e.g., due to continental drift, global positioning system (GPS) drift, correction inaccuracy, etc.). This poses a problem for autonomous work vehicles as they need to avoid hitting these landmarks, but pass by very closely.</p><heading id="h-0002" level="1">BRIEF DESCRIPTION</heading><p id="p-0004" num="0003">Certain embodiments commensurate in scope with the originally claimed subject matter are summarized below. These embodiments are not intended to limit the scope of the claimed subject matter, but rather these embodiments are intended only to provide a brief summary of possible forms of the disclosure. Indeed, the disclosure may encompass a variety of forms that may be similar to or different from the embodiments set forth below.</p><p id="p-0005" num="0004">In one embodiment, a control system for an autonomous work vehicle includes at least one controller including a memory and a processor. The at least one controller is configured to obtain map data for an area that the autonomous work vehicle is traversing, wherein the map data includes mapped landmarks. In addition, the at least one controller is configured to determine a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor. Further, the at least one controller is configured to determine a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle. Even further, the at least one controller is configured to determine a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle. Still further, the at least one controller is configured to determine whether the landmark is accurately mapped in the map data.</p><p id="p-0006" num="0005">In another embodiment, one or more tangible, non-transitory, machine-readable media include instructions configured to cause a processor to obtain map data for an area that an autonomous work vehicle is traversing, wherein the map data includes mapped landmarks. In addition, the instructions are configured to cause the processor to determine a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor. Further, the instructions are configured to cause the processor to determine a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle. Even further, the instructions are configured to cause the processor to determine a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle. Still further, the instructions are configured to cause the processor to determine whether the landmark is accurately mapped in the map data.</p><p id="p-0007" num="0006">In a further embodiment, a method for groundtruthing and remarking mapped landmark data utilized by an autonomous work vehicle includes obtaining, via a controller, map data for an area that the autonomous work vehicle is traversing, wherein the map data includes mapped landmarks. The method also includes determining, via the controller, a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor. The method further includes determining, via the controller, a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle. The method even further includes determining, via the controller, a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle. The method still further includes determining, via the controller, whether the landmark is accurately mapped in the map data.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">DRAWINGS</heading><p id="p-0008" num="0007">These and other features, aspects, and advantages of the present disclosure will become better understood when the following detailed description is read with reference to the accompanying drawings in which like characters represent like parts throughout the drawings, wherein:</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram of an embodiment of a vehicle (e.g., autonomous vehicle) operating within an agricultural field;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of an embodiment of computing systems for the agricultural vehicle of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and for a remote operations system; and</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram of an embodiment of a method for groundtruthing and remarking mapped landmark data utilized by the vehicle in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0012" num="0011">One or more specific embodiments of the present disclosure will be described below. In an effort to provide a concise description of these embodiments, all features of an actual implementation may not be described in the specification. It should be appreciated that in the development of any such actual implementation, as in any engineering or design project, numerous implementation-specific decisions must be made to achieve the developers' specific goals, such as compliance with system-related and business-related constraints, which may vary from one implementation to another. Moreover, it should be appreciated that such a development effort might be complex and time consuming, but would nevertheless be a routine undertaking of design, fabrication, and manufacture for those of ordinary skill having the benefit of this disclosure.</p><p id="p-0013" num="0012">When introducing elements of various embodiments of the present disclosure, the articles &#x201c;a,&#x201d; &#x201c;an,&#x201d; &#x201c;the,&#x201d; and &#x201c;said&#x201d; are intended to mean that there are one or more of the elements. The terms &#x201c;comprising,&#x201d; &#x201c;including,&#x201d; and &#x201c;having&#x201d; are intended to be inclusive and mean that there may be additional elements other than the listed elements.</p><p id="p-0014" num="0013">The present disclosure is generally directed to autonomous or self-driving work vehicles. As will be explained below, the embodiments below describe systems and methods for groundtruthing and remarking mapped landmark data. In some embodiments, a control system obtains map data for an area (e.g., field) that an autonomous vehicle is traversing, wherein the map data includes mapped landmarks. The control system may utilize different sensors on the autonomous work vehicle to determine a current position of the autonomous work vehicle and to determine a distance between a landmark in the area and the autonomous work vehicle. The control system may compare this distance to an estimated difference between the autonomous work vehicle and the landmark based on both the map data and the current position of the autonomous work vehicle. From this comparison, an accuracy of the map data with regard to the mapped landmark may be determined and, if needed, a corrective action taken. The disclosed embodiments ensures that the autonomous vehicle may safely navigate an area having obstacles.</p><p id="p-0015" num="0014">Turning now to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the figure is a schematic diagram of an embodiment of a vehicle <b>10</b> (e.g., work vehicle or agricultural vehicle) towing an agricultural implement <b>12</b> within an area <b>14</b> (e.g., agricultural field). The vehicle <b>10</b> may be an autonomous work vehicle, semi-autonomous work vehicle, or work vehicle with autoguidance system. The vehicle <b>10</b> may additionally include in-vehicle cab, in which an operator sits during operation of the vehicle <b>10</b>. In the illustrated embodiment, the work vehicle <b>12</b> is configured to operate at least partially autonomously (e.g., without input from an operator present in the cab of the work vehicle <b>12</b>). An automatic system (e.g., control system) may direct the work vehicle <b>10</b> and the agricultural implement <b>12</b> throughout the agricultural field <b>14</b> without direct control (e.g., steering control, speed control, etc.) by an operator. Further, the vehicle <b>10</b> may be remotely operated in addition to or alternative to being driven by an automated system. While in the depicted embodiment, the vehicle <b>10</b> is depicted as an agricultural tractor, in other embodiments, the vehicle <b>10</b> may be a construction vehicle, a mining vehicle, a passenger vehicle, or the like. The vehicle <b>10</b> or other prime mover is configured to tow the agricultural implement <b>12</b> throughout the field <b>14</b> along a direction of travel <b>16</b>. In certain embodiments, the vehicle <b>10</b> is steered (e.g., via a teleoperator or an automated system) to traverse the field along substantially parallel rows <b>18</b>. However, it should be appreciated that the vehicle <b>10</b> may be steered to traverse the field along other routes (e.g., along a spiral paths, curved paths, obstacle avoidance paths, and so on) in alternative embodiments. As will be appreciated, the agricultural implement <b>12</b> may be any suitable implement for performing agricultural operations throughout the field <b>14</b>. For example, in certain embodiments, the agricultural implement <b>12</b> may be a tillage tool, a fertilizer application tool, a seeding or planting tool, or a harvesting tool, among others. While the agricultural implement <b>12</b> is towed by the vehicle <b>10</b> in the illustrated embodiment, it should be appreciated that in alternative embodiments, the agricultural implement may be integrated within the vehicle <b>10</b>. In certain embodiments, the vehicle <b>10</b> may not include or be coupled to an implement. As described earlier, it should be noted that the techniques describe herein may be used for operations other than agricultural operations. For example, mining operations, construction operations, automotive operations, and so on.</p><p id="p-0016" num="0015">As the vehicle <b>10</b> and the agricultural implement <b>12</b> traverse the field (e.g., via autonomous operation without operator input), the vehicle <b>10</b> and the agricultural implement <b>12</b> may encounter various obstacles (e.g., field and/or soil conditions, as well as certain structures). Such field and/or soil conditions and structures may be defined as features for purposes of the description herein. For example, the vehicle <b>10</b> and the agricultural implement <b>12</b> may encounter features or obstacles such as a pond <b>20</b>, a tree stand <b>22</b>, a building, fence, or other standing structure <b>24</b> (e.g., telephone pole), transport trailer <b>26</b>, and miscellaneous features <b>28</b>, inclines, ditches, muddy soil, and so on. The miscellaneous features <b>28</b> may include water pumps, above ground fixed or movable equipment (e.g., irrigation equipment, planting equipment), and so on. In certain embodiments, the tractor <b>10</b> includes a mapping system used to operate in the field <b>14</b>. The mapping system may be communicatively and/or operatively coupled to a remote operations system <b>30</b>, which may include a mapping server. The remote operations system <b>30</b> may be located geographically distant from the vehicle system <b>10</b>. It is to be noted that in other embodiments the server is disposed in the vehicle system <b>10</b>. The mapping system enables the vehicle to utilize a map or map data that includes mapped landmark data (i.e., landmarks marked on a map).</p><p id="p-0017" num="0016">In addition to mapping support, in some embodiments the remote operations system <b>30</b> may be communicatively coupled to the vehicle <b>10</b> to provide for control instructions (e.g., wireless control) suitable for operating on the field <b>14</b>. The field <b>14</b> may include a field boundary <b>32</b>, as well as the various features, such as the pond <b>20</b>, the tree stand <b>22</b>, the building or other standing structure <b>24</b>, the transport trailer <b>26</b>, wet areas of the field <b>14</b> to be avoided, soft areas of the field to be avoided, the miscellaneous features <b>28</b>, and so on. As the vehicle <b>10</b> operates, the automated system (or remote operator) may steer to follow a desired or planned pattern (e.g., up and down the field) or route based on the map data to avoid obstacles. A control system of the vehicle <b>10</b> may utilize sensors to groundtruth and remark mapped landmark data to ensure the vehicle <b>10</b> avoids the obstacles.</p><p id="p-0018" num="0017">It may be useful to illustrate a system that utilizes groundtruthing and remarking mapped landmark data during operations of the agricultural vehicle <b>10</b>. Accordingly, and turning now to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the figure is a schematic diagram of an embodiment of a control system <b>36</b> that may be employed to control (e.g., autonomously control without operator input) operations of the agricultural vehicle <b>10</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In the illustrated embodiment, a control system <b>36</b> includes a spatial location system <b>38</b>, which is mounted to the agricultural vehicle <b>10</b> and configured to determine a position, and in certain embodiments a velocity, of the agricultural vehicle <b>10</b>. As will be appreciated, the spatial location system <b>38</b> may include any suitable system including one or more sensors <b>40</b> (e.g., receivers or devices) configured to measure and/or determine the position of the autonomous agricultural vehicle <b>10</b>, such as a global positioning system (GPS) receiver, Global Navigation Satellite System (GNSS) such as GLONASS, and/or other similar system configured to communicate with two or more satellites in orbit (e.g., GPS, GLONASS, Galileo, BeiDou, etc.) to determine the location, heading, speed, etc. of the work vehicle <b>10</b> and/or implement <b>12</b>. The spatial location system <b>38</b> may additionally use real time kinematic (RTK) techniques to enhance positioning accuracy. Further, the spatial location system <b>38</b> may include inertial measurement units (IMU), which may be used in dead-reckoning processes to validate motion of the GPS position against acceleration measurements. For example, the IMUs may be used for terrain compensation to correct or eliminate motion of the GPS position due to pitch and roll of the work vehicle <b>10</b> and/or agricultural implement <b>12</b>. In certain embodiments, the spatial location system <b>38</b> may be configured to determine the position of the work vehicle <b>10</b> and the agricultural implement <b>12</b> relative to a fixed global coordinate system (e.g., via the GPS) or a fixed local coordinate system.</p><p id="p-0019" num="0018">In the illustrated embodiment, the control system <b>36</b> includes a steering control system <b>46</b> configured to control a direction of movement of the agricultural vehicle <b>10</b>, and a speed control system <b>48</b> configured to control a speed of the agricultural vehicle <b>10</b>. In addition, the control system <b>36</b> includes a controller <b>49</b>, which is communicatively coupled to the spatial locating device <b>38</b>, to the steering control system <b>46</b>, and to the speed control system <b>48</b>. The controller <b>49</b> is configured to autonomously control the operation of the vehicle <b>10</b> as it traverses an area (e.g., field). In certain embodiments, the controller <b>49</b> is configured to receive inputs via a communications system <b>50</b> to control the agricultural vehicle <b>10</b> during certain phases of agricultural operations. The controller <b>49</b> may also be operatively coupled to certain vehicle protection systems <b>51</b>, such as an automatic braking system <b>52</b>, a collision avoidance system <b>54</b>, a rollover avoidance system <b>56</b>, and so on. The vehicle protection systems <b>51</b> may be communicatively coupled to one or more sensors <b>58</b>, such as cameras, radar, stereo vision, distance sensors, lasers (e.g., LADAR), and so on, suitable for detecting objects and distances to objects, and the like. The sensors <b>58</b> may also be used by the controller <b>49</b> for driving operations, for example, to provide for collision information, and the like.</p><p id="p-0020" num="0019">Also shown is a mapping client system <b>60</b> that may provide a map or map data that includes mapped landmark data that may be useful in field operations (e.g., planning and navigating a route through the field that avoids obstacles). The map may be stored in a memory <b>65</b> of the controller <b>49</b>. The recorded map data may be inaccurate due to a variety of reasons (e.g., GPS drift, continental drift, correction inaccuracy, etc.). In certain embodiments, the mapping client system <b>60</b> may be communicatively coupled to a user interface system <b>53</b> having a display <b>55</b> and provide visual maps as well as certain information overlaid and/or adjacent to the maps. The mapping client system <b>60</b> may be communicatively coupled to a mapping server system <b>76</b>. In certain embodiments, the mapping server <b>76</b> may provide a map or map data that includes mapped landmark data for the area for use by the mapping client system <b>66</b>. The map may be one or multiple maps stored in a memory <b>74</b> of the mapping client system <b>66</b>. The mapping server <b>76</b> may be disposed in the vehicle <b>10</b> as an in-vehicle system. When disposed inside the vehicle <b>10</b>, the mapping server <b>76</b> may be communicatively coupled to the mapping client system <b>60</b> via wired conduits and/or via wireless (e.g., WiFi, mesh networks, and so on). In some cases, the mapping server <b>76</b> may be used by more than one client (e.g., more than one vehicle, regardless of whether the mapping server <b>76</b> is disposed inside of the vehicle or at the remote location <b>30</b>.</p><p id="p-0021" num="0020">In certain embodiments, the controller <b>49</b> is an electronic controller having electrical circuitry configured to process data from the spatial locating device <b>38</b>, the vehicle protection systems <b>51</b>, the sensors <b>58</b>, and/or other components of the control system <b>36</b>. In the illustrated embodiment, the controller <b>49</b> includes a processor, such as the illustrated microprocessor <b>63</b>, and a memory device <b>65</b>. The controller <b>49</b> may also include one or more storage devices and/or other suitable components. The processor <b>63</b> may be used to execute software, such as software for controlling the agricultural vehicle, software for determining vehicle position, identifying obstacles, determining distances of obstacles from the vehicle <b>10</b>, groundtruthing and remarking mapped landmark data, software to perform steering calibration, and so forth.</p><p id="p-0022" num="0021">Moreover, the processor <b>63</b> may include multiple microprocessors, one or more &#x201c;general-purpose&#x201d; microprocessors, one or more special-purpose microprocessors, and/or one or more application specific integrated circuits (ASICS), or some combination thereof. For example, the processor <b>63</b> may include one or more reduced instruction set (RISC) processors.</p><p id="p-0023" num="0022">The memory device <b>65</b> may include a volatile memory, such as random access memory (RAM), and/or a nonvolatile memory, such as read-only memory (ROM). The memory device <b>65</b> may store a variety of information and may be used for various purposes. For example, the memory device <b>65</b> may store processor-executable instructions (e.g., firmware or software) for the processor <b>63</b> to execute, such as instructions for controlling the agricultural vehicle, determining vehicle position, identifying obstacles, determining distances of obstacles from the vehicle <b>10</b>, groundtruthing and remarking mapped landmark data, and so forth. The storage device(s) (e.g., nonvolatile storage) may include ROM, flash memory, a hard drive, or any other suitable optical, magnetic, or solid-state storage medium, or a combination thereof. The storage device(s) may store data (e.g., position data, vehicle geometry data, maps, etc.), instructions (e.g., software or firmware for controlling the agricultural vehicle, etc.), and any other suitable data.</p><p id="p-0024" num="0023">In certain embodiments, the steering control system <b>46</b> may rotate one or more wheels and/or tracks of the agricultural vehicle (e.g., via hydraulic actuators) to steer the agricultural vehicle along a desired route (e.g., as guided by an automated system or a remote operator using the remote operations system <b>30</b>). By way of example, the wheel angle may be rotated for front wheels/tracks, rear wheels/tracks, and/or intermediate wheels/tracks of the agricultural vehicle, either individually or in groups. A braking control system <b>67</b> may independently vary the braking force on each lateral side of the agricultural vehicle to direct the agricultural vehicle along a path. Similarly, torque vectoring may be used differentially apply torque from an engine to wheels and/or tracks on each lateral side of the agricultural vehicle, thereby directing the agricultural vehicle along a path. In further embodiments, the steering control system <b>46</b> may include other and/or additional systems to facilitate directing the agricultural vehicle along a path through the field.</p><p id="p-0025" num="0024">In certain embodiments, the speed control system <b>48</b> may include an engine output control system, a transmission control system, or a combination thereof. The engine output control system may vary the output of the engine to control the speed of the agricultural vehicle. For example, the engine output control system may vary a throttle setting of the engine, a fuel/air mixture of the engine, a timing of the engine, other suitable engine parameters to control engine output, or a combination thereof. In addition, the transmission control system may adjust gear selection within a transmission to control the speed of the agricultural vehicle. Furthermore, the braking control system may adjust braking force, thereby controlling the speed of the agricultural vehicle. In further embodiments, the speed control system may include other and/or additional systems to facilitate adjusting the speed of the agricultural vehicle.</p><p id="p-0026" num="0025">The systems <b>46</b>, <b>48</b>, and/or <b>67</b> may be remotely controlled autonomously via the control system <b>36</b> or via remote operations, e.g., by using the user interface <b>62</b> at a remote location. It is to be noted that remote control may include control from a location geographically distant to the vehicle <b>10</b> but may also include control where the human operator may be besides the vehicle <b>10</b> and may observe the vehicle <b>10</b> locally during operations.</p><p id="p-0027" num="0026">In certain embodiments, the control system <b>36</b> may also control operation of the agricultural implement <b>12</b> coupled to the agricultural vehicle <b>10</b>. For example, the control system <b>36</b> may include an implement control system/implement controller configured to control a steering angle of the implement <b>12</b> (e.g., via an implement steering control system having a wheel angle control system and/or a differential braking system) and/or a speed of the agricultural vehicle/implement system <b>12</b> (e.g., via an implement speed control system having a braking control system).</p><p id="p-0028" num="0027">In certain embodiments, the user interface <b>53</b> is configured to enable an operator (e.g., inside of the vehicle <b>10</b> cab or standing proximate to the agricultural vehicle <b>10</b> but outside the cab) to control certain parameter associated with operation of the agricultural vehicle <b>10</b>. For example, the user interface <b>53</b> may include a switch that enables the operator to configure the agricultural vehicle for manual operation. In addition, the user interface <b>53</b> may include a battery cut-off switch, an engine ignition switch, a stop button, or a combination thereof, among other controls. In certain embodiments, the user interface <b>53</b> includes a display <b>56</b> configured to present information to the operator, such as a map with visual representation of certain parameter(s) associated with operation of the agricultural vehicle (e.g., engine power, fuel level, oil pressure, water temperature, etc.), a visual representation of certain parameter(s) associated with operation of an implement coupled to the agricultural vehicle (e.g., seed level, penetration depth of ground engaging tools, orientation(s)/position(s) of certain components of the implement, etc.), or a combination thereof, In certain embodiments, the display <b>55</b> may include a touch screen interface that enables the operator to control certain parameters associated with operation of the agricultural vehicle and/or the implement.</p><p id="p-0029" num="0028">In the illustrated embodiment, the control system <b>36</b> may include manual controls configured to enable an operator to control the agricultural vehicle while remote control is disengaged. The manual controls may include manual steering control, manual transmission control, manual braking control, or a combination thereof, among other controls. In the illustrated embodiment, the manual controls are communicatively coupled to the controller <b>49</b>. The controller <b>49</b> is configured to disengage automatic control of the agricultural vehicle upon receiving a signal indicative of manual control of the agricultural vehicle. Accordingly, if an operator controls the agricultural vehicle manually, the automatic control terminates, thereby enabling the operator to control the agricultural vehicle.</p><p id="p-0030" num="0029">In the illustrated embodiment, the control system <b>36</b> includes the communications system <b>50</b> communicatively coupled to the remote operations system <b>30</b>. In certain embodiments, the communications system <b>50</b> is configured to establish a communication link with a corresponding communications system <b>61</b> of the remote operations system <b>30</b>, thereby facilitating communication between the remote operations system <b>30</b> and the control system <b>36</b> of the autonomous agricultural vehicle. For example, the remote operations system <b>30</b> may include a control system <b>71</b> having the user interface <b>62</b> having a display <b>64</b> that enables a remote operator to provide instructions to a controller <b>66</b> (e.g., instructions to initiate control of the agricultural vehicle <b>10</b>, instructions to remotely drive the agricultural vehicle, instructions to direct the agricultural vehicle along a path, instructions to command the steering control <b>46</b>, braking control <b>67</b>, and/or speed control <b>48</b>, instructions to, etc.). For example, joysticks, keyboards, trackballs, and so on, may be used to provide the user interface <b>62</b> with inputs used to then derive commands to control or otherwise drive the vehicle <b>10</b> remotely.</p><p id="p-0031" num="0030">In the illustrated embodiment, the controller <b>66</b> includes a processor, such as the illustrated microprocessor <b>72</b>, and a memory device <b>74</b>. The controller <b>66</b> may also include one or more storage devices and/or other suitable components. The processor <b>72</b> may be used to execute software, such as software for controlling the agricultural vehicle <b>10</b> remotely, software for determining vehicle orientation, software for determining vehicle position, identifying obstacles, determining distances of obstacles from the vehicle <b>10</b>, groundtruthing and remarking mapped landmark data, and so forth. Moreover, the processor <b>72</b> may include multiple microprocessors, one or more &#x201c;general-purpose&#x201d; microprocessors, one or more special-purpose microprocessors, and/or one or more application specific integrated circuits (ASICS), or some combination thereof. For example, the processor <b>50</b> may include one or more reduced instruction set (RISC) processors.</p><p id="p-0032" num="0031">The memory device <b>74</b> may include a volatile memory, such as random access memory (RAM), and/or a nonvolatile memory, such as read-only memory (ROM). The memory device <b>74</b> may store a variety of information and may be used for various purposes. For example, the memory device <b>74</b> may store processor-executable instructions (e.g., firmware or software) for the processor <b>72</b> to execute, such as instructions for controlling the agricultural vehicle <b>10</b> remotely, instructions for determining vehicle orientation, for determining vehicle position, identifying obstacles, determining distances of obstacles from the vehicle <b>10</b>, groundtruthing and remarking mapped landmark data and so forth. The storage device(s) (e.g., nonvolatile storage) may include ROM, flash memory, a hard drive, or any other suitable optical, magnetic, or solid-state storage medium, or a combination thereof. The storage device(s) may store data (e.g., position data, vehicle geometry data, etc.), instructions (e.g., software or firmware for controlling the agricultural vehicle, mapping software or firmware, etc.), and any other suitable data.</p><p id="p-0033" num="0032">The communication systems <b>50</b>, <b>61</b> may operate at any suitable frequency range within the electromagnetic spectrum. For example, in certain embodiments, the communication systems <b>50</b>, <b>61</b> may broadcast and receive radio waves within a frequency range of about 1 GHz to about 10 GHz. In addition, the communication systems <b>50</b>, <b>61</b> may utilize any suitable communication protocol, such as a standard protocol (e.g., Wi-Fi, Bluetooth, etc.) or a proprietary protocol.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram of an embodiment of a method <b>80</b> for groundtruthing and remarking mapped landmark data utilized by the vehicle <b>10</b> (e.g., autonomous vehicle) in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The method <b>80</b> may be performed by a component of the control system <b>36</b> of the vehicle <b>10</b> (e.g., controller <b>49</b>) utilizing other components of the vehicle <b>10</b> (e.g., spatial location system <b>38</b>, sensors <b>58</b>, etc.). One or more steps of the method <b>80</b> may occur simultaneously or in a different order from that illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The method <b>80</b> includes obtaining a map or map data <b>82</b> (block <b>84</b>). The map data <b>82</b> is of an area or field that the vehicle (e.g., autonomous vehicle) is traversing. The map data <b>82</b> includes mapped landmarks that were previously recorded. The map data <b>82</b> may be stored in and accessed from a memory (e.g., memory <b>65</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref> of the controller <b>49</b>) on the vehicle. In certain embodiments, the map data <b>82</b> may be obtained from a remote operations system (e.g., a memory <b>74</b> of the mapping client system <b>66</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The method <b>80</b> also includes determining a position of the vehicle based on feedback from sensors on the vehicle (e.g., sensors <b>40</b> of the spatial location system <b>38</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) (block <b>86</b>). The method <b>80</b> further includes, as the vehicle traverses the area or field along a preplanned route based on the map data <b>82</b>, detecting an obstacle or landmark utilizing sensors on the vehicle (e.g., sensors <b>58</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) (block <b>88</b>). The detected obstacle or landmark should be a mapped landmark on the map data <b>82</b>. In certain embodiments, the obstacle or landmark may not be marked in the map data <b>82</b> if the obstacle or landmark recently appeared.</p><p id="p-0035" num="0034">The method <b>80</b> includes determining a distance (e.g., actual distance) between the detected obstacle or landmark and the vehicle based on the feedback from the sensors that detected the obstacle or landmark (e.g., sensors <b>58</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) and the current position of the vehicle (e.g., based on the feedback from the sensors <b>40</b> of the spatial location system <b>38</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) (block <b>90</b>). The method <b>80</b> also includes estimating a distance (e.g., estimated distance) between the vehicle and the detected obstacle or landmark based on the mapped location of the obstacle or landmark in the map data <b>82</b> and the current position of the vehicle (e.g., based on the feedback from the sensors <b>40</b> of the spatial location system <b>38</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) (block <b>92</b>). The method <b>80</b> further includes determining a difference between the actual distance and the estimated distance between the vehicle and the landmark (block <b>94</b>).</p><p id="p-0036" num="0035">The method <b>80</b> includes determining whether the detected landmark is accurately mapped in the map data <b>82</b> (block <b>96</b>). In certain embodiments, determining whether the detected landmark is accurately mapped includes comparing the difference between the actual distance and the estimated distance to predetermined threshold (e.g., distance threshold). For example, the threshold may be <b>1</b>, <b>2</b>, <b>3</b> inches or another distance. The threshold may be set to reflect a significant difference that may impact the route of the vehicle. If the difference between the actual distance and the estimated distance is at or less than the threshold, the method <b>80</b> includes validating the map data <b>82</b> (block <b>98</b>) and the vehicle can continue along its preplanned route. If the difference between the actual distance and the estimated distance is greater than the threshold, the method <b>80</b> includes invalidating the map data <b>82</b> (block <b>100</b>). In certain embodiments, if a certain number of detected obstacles or landmarks (e.g., <b>2</b>, <b>3</b>, or more) are inaccurately mapped, the entire map may be invalidated as opposed to just the portion related to a particular mapped landmark or obstacle.</p><p id="p-0037" num="0036">In response to invalidating the map data <b>82</b>, the method <b>80</b> may include updating (e.g., remarking) the map data <b>82</b> so that the landmark is accurately mapped (block <b>102</b>). The updated map data <b>82</b>, besides being stored on the vehicle, may be communicated to a remote operations system (e.g., a memory <b>74</b> of the mapping client system <b>66</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) so that the map data <b>82</b> may be utilized by other vehicles.</p><p id="p-0038" num="0037">In response to invalidating the map data <b>82</b>, the method <b>80</b> may also include causing the vehicle to take a corrective action (block <b>104</b>). The corrective action may include stopping the vehicle. In certain embodiments, the corrective action may include dynamically changing the route of the vehicle to avoid the landmark and then return to the route as previously planned after avoiding the landmark.</p><p id="p-0039" num="0038">While only certain features of the disclosure have been illustrated and described herein, many modifications and changes will occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the true spirit of the disclosure.</p><p id="p-0040" num="0039">The techniques presented and claimed herein are referenced and applied to material objects and concrete examples of a practical nature that demonstrably improve the present technical field and, as such, are not abstract, intangible or purely theoretical. Further, if any claims appended to the end of this specification contain one or more elements designated as &#x201c;means for [perform]ing [a function]. . . &#x201d; or &#x201c;step for [perform]ing [a function]. . . &#x201d;, it is intended that such elements are to be interpreted under 35 U.S.C. 112(f). However, for any claims containing elements designated in any other manner, it is intended that such elements are not to be interpreted under 35 U.S.C. 112(f).</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A control system for an autonomous work vehicle, comprising:<claim-text>at least one controller comprising a memory and a processor, wherein the at least one controller is configured to:<claim-text>obtain map data for an area that the autonomous work vehicle is traversing, wherein the map data includes mapped landmarks;</claim-text><claim-text>determine a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor;</claim-text><claim-text>determine a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle;</claim-text><claim-text>determine a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle; and</claim-text><claim-text>determine whether the landmark is accurately mapped in the map data.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one controller is configured to compare the difference to a predetermined threshold to determine whether the landmark is accurately mapped in the map data.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The control system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the controller is configured to validate that the landmark is accurately mapped in the map data when the difference is at or less than the threshold.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The control system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the controller is configured to invalidate the map data for the landmark when the difference is greater than the threshold.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The control system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the controller is configured to update the map data for the landmark so that that the landmark is accurately mapped in the map data.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is configured to cause the autonomous work vehicle to take a corrective action when the landmark is not accurately mapped in the map data.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The control system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the corrective action comprises stopping the autonomous work vehicle.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The control system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the corrective action comprises dynamically changing a route of the autonomous work vehicle to avoid the landmark.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The control system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the correction comprises, upon dynamically changing the route, returning to the route as previously planned after avoiding the landmark.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. One or more tangible, non-transitory, machine readable media comprising instructions configured to cause a processor to:<claim-text>obtain map data for an area that an autonomous work vehicle is traversing, wherein the map data includes mapped landmarks;</claim-text><claim-text>determine a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor;</claim-text><claim-text>determine a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle;</claim-text><claim-text>determine a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle; and</claim-text><claim-text>determine whether the landmark is accurately mapped in the map data.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The one or more tangible, non-transitory, machine-readable media of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the instructions are configured to compare the difference to a predetermined threshold to determine whether the landmark is accurately mapped in the map data.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The one or more tangible, non-transitory, machine-readable media of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the instructions are configured to validate that the landmark is accurately mapped in the map data when the difference is at or less than the threshold.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The one or more tangible, non-transitory, machine-readable media of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the instructions are configured to invalidate the map data for the landmark when the difference is greater than the threshold.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The one or more tangible, non-transitory, machine-readable media of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the instructions are configured to update the map data for the landmark so that that the landmark is accurately mapped in the map data.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The one or more tangible, non-transitory, machine-readable media of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the instructions are configured to cause the autonomous work vehicle to take a corrective action when the landmark is not accurately mapped in the map data.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The one or more tangible, non-transitory, machine-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the corrective action comprises stopping the autonomous work vehicle.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The one or more tangible, non-transitory, machine-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the corrective action comprises dynamically changing a route of the autonomous work vehicle to avoid the landmark and then returning to the route as previously planned after avoiding the landmark.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A method for groundtruthing and remarking mapped landmark data utilized by an autonomous work vehicle, comprising:<claim-text>obtaining, via a controller, map data for an area that the autonomous work vehicle is traversing, wherein the map data includes mapped landmarks;</claim-text><claim-text>determining, via the controller a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor;</claim-text><claim-text>determining, via the controller, a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle;</claim-text><claim-text>determining, via the controller, a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle; and</claim-text><claim-text>determining, via the controller, whether the landmark is accurately mapped in the map data.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, comprising comparing, via the controller, the difference to a predetermined threshold to determine whether the landmark is accurately mapped in the map data.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, comprising validating, via the controller, that the landmark is accurately mapped in the map data when the difference is at or less than the threshold and invalidating, via the controller, the map data for the landmark when the difference is greater than the threshold.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230002189A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230002189</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17941645</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>66</class><subclass>B</subclass><main-group>1</main-group><subgroup>46</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>66</class><subclass>B</subclass><main-group>3</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>66</class><subclass>B</subclass><main-group>1</main-group><subgroup>34</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>1</main-group><subgroup>468</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>3</main-group><subgroup>006</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>1</main-group><subgroup>3461</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>2201</main-group><subgroup>4615</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>2201</main-group><subgroup>103</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>2201</main-group><subgroup>4638</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>2201</main-group><subgroup>4676</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>2201</main-group><subgroup>401</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>2201</main-group><subgroup>403</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>2201</main-group><subgroup>104</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>66</class><subclass>B</subclass><main-group>2201</main-group><subgroup>402</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>172</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">ACCESS CONTROL SYSTEM, AN ELEVATOR SYSTEM, AND A METHOD FOR CONTROLLING AN ACCESS CONTROL SYSTEM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/FI2020/050244</doc-number><date>20200415</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17941645</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>KONE Corporation</orgname><address><city>Helsinki</city><country>FI</country></address></addressbook><residence><country>FI</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LAURILA</last-name><first-name>Jussi</first-name><address><city>Helsinki</city><country>FI</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>RAUTA</last-name><first-name>Visa</first-name><address><city>Helsinki</city><country>FI</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>KONE Corporation</orgname><role>03</role><address><city>Helsinki</city><country>FI</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An access control system for an elevator system includes a gate device allowing access for users via the gate device, at least one imaging device for obtaining image data, at least one sensor device for obtaining sensor data, at least one indication device, and a control unit. The control unit is configured to: receive the image data from the at least one imaging device, detect a user approaching the gate device based on the received image data, obtain destination floor information including at least two destination floors, control the at least one indication device to generate a first visual indication including the at least two destination floors, and detect a destination floor selected by the user from among the at least two destination floors based on sensor data received from the at least one sensor device. An elevator system includes an access control system and to a method for controlling an access control system is disclosed.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="234.95mm" wi="106.85mm" file="US20230002189A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="215.90mm" wi="162.90mm" file="US20230002189A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="196.77mm" wi="156.80mm" file="US20230002189A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="196.77mm" wi="156.80mm" file="US20230002189A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="196.77mm" wi="156.80mm" file="US20230002189A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="237.83mm" wi="152.57mm" file="US20230002189A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The invention concerns in general the technical field of access control. Especially the invention concerns access control of elevators.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Typically, gate devices, such as security gates and turnstiles, may comprise access control. The access control enables that only authorized users may have access through the gate device. The access control may be based on using keycards; tags; identification codes; such as personal identity number (PIN) code, ID number; and/or biometric technologies, such as fingerprint, facial recognition, iris recognition, retinal scan, voice recognition, etc. The gate devices may be communicatively coupled to an elevator system enabling a generation of an elevator call in response to identification of an authorized user with the gate device.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">The following presents a simplified summary in order to provide basic understanding of some aspects of various invention embodiments. The summary is not an extensive overview of the invention. It is neither intended to identify key or critical elements of the invention nor to delineate the scope of the invention. The following summary merely presents some concepts of the invention in a simplified form as a prelude to a more detailed description of exemplifying embodiments of the invention.</p><p id="p-0005" num="0004">An objective of the invention is to present an access control system, an elevator system, and a method for controlling an access control system. Another objective of the invention is that the access control system, the elevator system, and the method for controlling an access control system enable an effortless selection of a destination floor.</p><p id="p-0006" num="0005">The objectives of the invention are reached by an access control system, an elevator system, and a method as defined by the respective independent claims.</p><p id="p-0007" num="0006">According to a first aspect, an access control system for an elevator system is provided, wherein the access control system comprises: a gate device allowing access for users via the gate device, at least one imaging device for obtaining image data, at least one sensor device for obtaining sensor data, at least one indication device, and a control unit configured to: receive the image data from the at least one imaging device, detect a user approaching the gate device based on the received image data, obtain destination floor information comprising at least two destination floors, control the at least one indication device to generate a first visual indication comprising the at least two destination floors, and detect a destination floor selected by the user from among the at least two destination floors based on sensor data received from the at least one sensor device.</p><p id="p-0008" num="0007">The generation of the first visual indication may comprise projection of the first visual indication on a surface in a vicinity of the gate device, the first visual indication may comprise an indication element for each of the at least two destination floors.</p><p id="p-0009" num="0008">The detection of the destination floor selected by the user may comprise detection of at least partial deformation of at least one indication element, wherein if one indication element with at least partial deformation is detected, said one indication element may represent the destination floor selected by the user; or if two or more indication elements with at least partial deformation are detected, the indication element with a greater deformation may represent the destination floor selected by the user, or no selection by the user is detected.</p><p id="p-0010" num="0009">Alternatively or in addition, the control unit may be configured to provide the detected destination floor selection by the user to an external database and/or an elevator control system.</p><p id="p-0011" num="0010">The elevator control system may be configured to generate an elevator call to allocate an elevator car to the destination floor selected by the user in response to receiving the detected destination floor selection by the user from the control unit.</p><p id="p-0012" num="0011">The control unit may further be configured to receive an elevator car identification information of the elevator car to which an elevator call is generated from the elevator control system.</p><p id="p-0013" num="0012">Alternatively, the control unit may further be configured to provide to the elevator control system an elevator car identification information of an elevator car for generating an elevator call to allocate said elevator car to the destination floor selected by the user.</p><p id="p-0014" num="0013">The control unit may further be configured to control the at least one indication device to project a second visual indication on a surface in a vicinity of the gate device or the user, wherein the second visual indication may comprise the elevator car identification information; and/or wherein the system may further comprise one or more displays, and the control unit may be configured to control the one or more displays to display the elevator car identification information.</p><p id="p-0015" num="0014">The at least two destination floors may comprise one or more default destination floors defined based on a time of day, one or more destination floors defined based on a current traffic flow, and/or one or more destination floors defined based on an exceptional situation.</p><p id="p-0016" num="0015">The detection of the user may further comprise identification of an authorized user based on the received image data and prestored data associated with the authorized users by using facial recognition-based identification.</p><p id="p-0017" num="0016">Furthermore, the at least two destination floors comprise: one or more default destination floors defined based on a time of day, one or more destination floors defined based on a current traffic flow, one or more destination floors defined based on an exceptional situation, one or more default destination floors assigned for said authorized user, one or more destination floors set by the said authorized user, one or more destination floors defined based on previously selected destination floors by said authorized user, and/or a destination floor defined based on a scheduled event for said authorized user, wherein the scheduled event is obtained from an external storage unit to which the scheduled event is stored.</p><p id="p-0018" num="0017">According to a second aspect, an elevator system is provided, wherein the elevator system comprises: at least two elevator cars each travelling along a respective elevator shaft, an elevator control system, and an access control system as described above comprising at least one gate device.</p><p id="p-0019" num="0018">According to a third aspect, A method for controlling an access control system is provided, wherein the method comprises: receiving image data from at least one imaging device, detecting a user approaching a gate device based on the received image data, obtaining destination floor information comprising at least two destination floors, controlling at least one indication device to provide a first visual indication comprising the at least two destination floors, and detecting a destination floor selected by the user from among the at least two destination floors based on sensor data received from at least one sensor device.</p><p id="p-0020" num="0019">The providing of the first visual indication may comprise projecting the first visual indication on a surface in a vicinity of the gate device, the first visual indication may comprise an indication element for each of the at least two destination floors.</p><p id="p-0021" num="0020">The detecting the destination floor selected by the user may comprise detecting at least partial deformation of at least one indication element, wherein if one indication element with at least partial deformation is detected, said one indication element may represent the destination floor selected by the user; or if two or more indication elements with at least partial deformation are detected, the indication element with a greater deformation may represent the destination floor selected by the user, or no selection by the user is detected.</p><p id="p-0022" num="0021">The method may further comprise providing the detected destination floor selection by the user to an external database and/or an elevator control system.</p><p id="p-0023" num="0022">The method may further comprise generating an elevator call to allocate an elevator car to the destination floor selected by the user in response to receiving the detected destination floor selection by the user.</p><p id="p-0024" num="0023">The method may further comprise receiving an elevator car identification information of the elevator car to which an elevator call is generated from the elevator control system.</p><p id="p-0025" num="0024">The method may further comprise providing to the elevator control system an elevator car identification information of an elevator car for generating an elevator call to allocate said elevator car to the destination floor selected by the user.</p><p id="p-0026" num="0025">The method may further comprise: controlling the at least one indication device to project a second visual indication on a surface in a vicinity of the gate device or the user, wherein the second visual indication comprises the elevator car identification information, and/or controlling one or more displays to display the elevator car identification information.</p><p id="p-0027" num="0026">The at least two destination floors may comprise: one or more default destination floors defined based on a time of day, one or more destination floors defined based on a current traffic flow, and/or one or more destination floors defined based on an exceptional situation.</p><p id="p-0028" num="0027">The step of detecting the user may further comprise identifying an authorized user based on the received image data and prestored data associated with authorized users by using facial recognition-based identification.</p><p id="p-0029" num="0028">Furthermore, the at least two destination floors may comprise: one or more default destination floors defined based on a time of day, one or more destination floors defined based on a current traffic flow, one or more destination floors defined based on an exceptional situation, one or more default destination floors assigned for said authorized user, one or more destination floors set by the said authorized user, one or more destination floors defined based on previously selected destination floors by said authorized user, and/or a destination floor defined based on a scheduled event for said authorized user, wherein the scheduled event is obtained from an external storage unit to which the scheduled event is stored.</p><p id="p-0030" num="0029">Various exemplifying and non-limiting embodiments of the invention both as to constructions and to methods of operation, together with additional objects and advantages thereof, will be best understood from the following description of specific exemplifying and non-limiting embodiments when read in connection with the accompanying drawings.</p><p id="p-0031" num="0030">The verbs &#x201c;to comprise&#x201d; and &#x201c;to include&#x201d; are used in this document as open limitations that neither exclude nor require the existence of unrecited features. The features recited in dependent claims are mutually freely combinable unless otherwise explicitly stated. Furthermore, it is to be understood that the use of &#x201c;a&#x201d; or &#x201c;an&#x201d;, i.e. a singular form, throughout this document does not exclude a plurality.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF FIGURES</heading><p id="p-0032" num="0031">The embodiments of the invention are illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates schematically an example environment according to the invention, wherein different embodiments according to the invention may be implemented.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>C</figref> illustrate schematically example situations according to the invention.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates schematically an example of a method according to the invention.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates schematically an example of components of a control unit according to the invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DESCRIPTION OF THE EXEMPLIFYING EMBODIMENTS</heading><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates schematically an example environment according to the invention, wherein an access control system <b>100</b> according to the invention may be implemented. The example environment is an elevator environment, i.e. an elevator system <b>120</b>. The elevator system <b>120</b> may comprise at least two elevator cars A-D each travelling along a respective elevator shaft, an elevator control system (for sake of clarity not shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>), and an access control system <b>100</b> according to the invention. The elevator control system may be configured to control the operations of the elevator system <b>120</b>, e.g. generate elevator call(s) to allocate the elevator cars A-D. The elevator control system may locate in a machine room of the elevator system <b>120</b> or in one of landings. The access control system <b>100</b> comprises at least one gate device <b>102</b> allowing access for users <b>112</b> via the at least one gate device <b>102</b>, at least one imaging device <b>104</b> for obtaining image data, at least one sensor device <b>106</b> for obtaining sensor data, at least one indication device <b>108</b>, and a control unit <b>110</b>. The invention is described next by using one gate device <b>102</b>. However, the invention is not limited to that and the access control system <b>100</b> according to the invention may comprise more than one gate device <b>102</b> each configured to operate as will be described by referring to the one gate device <b>102</b>.</p><p id="p-0038" num="0037">The at least one imaging device <b>104</b> may comprise an optical imaging device, e.g. at least one camera. The at least one imaging device <b>104</b> may enable detection and/or identification of a user <b>112</b> at a distance away from the gate device <b>102</b>. The distance may be e.g. between 0 to 10 meters from the gate device <b>102</b> and preferably between 1 to 2 meters, 1 to 3 meters or 1 to 5 meters. The at least one imaging device <b>104</b> may be arranged to the gate device <b>102</b> as illustrated in the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or in a vicinity of, i.e. close to, the gate device <b>102</b>, e.g. to a wall, a ceiling and/or to a separate support device.</p><p id="p-0039" num="0038">The control unit <b>110</b> may be external entity or it may be implemented as a part of the gate device <b>102</b>. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the control unit <b>110</b> is an external entity. The external entity herein means an entity that locates separate from the gate device <b>102</b>. The implementation of the external control unit <b>110</b> may be done as a stand-alone entity or as a distributed computing environment between a plurality of stand-alone devices, such as a plurality of servers providing distributed computing resource. The control unit <b>110</b> may be configured to control the operations of the access control system <b>100</b>. The control unit <b>110</b> may be communicatively coupled to the gate device <b>102</b>, the at least one imaging device <b>104</b>, the at least one sensor device <b>106</b> and the at least one indication device <b>108</b>. The communication between the control unit <b>110</b> and the other entities of the system may be based on one or more known communication technologies, either wired or wireless.</p><p id="p-0040" num="0039">The control unit <b>110</b> is configured to receive the image data from the at least one imaging device <b>104</b> and detect a user <b>112</b> approaching the gate device <b>102</b> based on the received image data. In response to detection of the user <b>112</b> approaching the gate device <b>102</b>, the control unit <b>102</b> is configured to obtain destination floor information comprising at least two destination floors. The process of obtaining the destination floor information may depend on whether the user <b>112</b> is identified as an authorized user or not. If the user <b>112</b> is not identified as an authorized user, e.g. any user entering a building in which the elevator system <b>120</b> resides, the at least two destination floors may comprise one or more default destination floors defined based on a time of day, one or more destination floors defined based on a current traffic flow, and/or one or more destination floors defined based on an exceptional situation, e.g. a fault state of one or more elevator cars A-D. The at least two destination floors may be obtained from a memory or a database connected to the control unit <b>110</b> or from a cloud service accessible via a network connection.</p><p id="p-0041" num="0040">According to an example of the invention, the detection of the user <b>112</b> may further comprise identification of an authorized user based on the received image data and prestored data associated with the authorized users by using facial recognition-based identification. The control unit <b>110</b> may be configured to determine based on the received image data and prestored data associated with the authorized users, whether the image data relates to an authorized user or not. In other words, the received image data may be compared to the prestored data in order to find a possible match from the prestored data. The prestored data may be stored in a memory or database connected to the control unit <b>110</b>, or in a cloud service accessible via a network connection. For example, if the access control system <b>100</b> is arranged in a building, image data relating to people regularly residing, e.g. working or living, in the building may have been prestored in the memory or database. For the authorized users the destination floors may be suggested more versatile. Moreover, for the authorized users <b>112</b> user specific destination floors may be obtained.</p><p id="p-0042" num="0041">If the user <b>112</b> is identified as an authorized user, the at least two destination floors may comprise one or more default destination floors defined based on a time of day; one or more destination floors defined based on a current traffic flow; one or more destination floors defined based on an exceptional situation, e.g. a fault state of one or more elevator cars A-D; one or more default destination floors assigned for said authorized user; one or more destination floors set by the said authorized user; one or more destination floors defined based on previously selected destination floors by said authorized user; and/or a destination floor defined based on a scheduled event for said authorized user, wherein the scheduled event is obtained from an external storage unit, such as a database, to which the scheduled event is stored. For example, if a meeting in a specific floor is scheduled for said authorized user the at least two destination floors may comprise said specific floor to which the meeting is scheduled. The one or more default destination floors assigned for said authorized user may comprise e.g. a home floor and/or an office floor of said authorized user. The one or more destination floors set by the said authorized user may comprise any floor of the building predefined by said authorized user. According to an example, machine learning techniques may be used to define the one or more destination floors defined based on previously selected destination floors by said authorized user. The at least two destination floors may be obtained from a memory or a database connected to the control unit <b>110</b> or from a cloud service accessible via a network connection.</p><p id="p-0043" num="0042">The gate device <b>102</b> may comprise a barrier device, such as door panel(s), turnstile, boom or any other barrier device, for preventing users without an access via the gate device <b>102</b>. The gate device <b>102</b> may be by default at a state allowing an unrestricted access via the gate device <b>102</b>. In other words, the gate device <b>102</b> is maintained at the state allowing the unrestricted access via the gate device <b>102</b>. If the received image data relates to a user without an access via the gate device <b>102</b>, the control unit <b>110</b> may be configured to control the barrier device to prevent, i.e. restrict, the access via the gate device <b>102</b>, e.g. by closing the barrier device of the gate device <b>102</b>. Alternatively, the gate device <b>102</b> may be by default at a state preventing, i.e. restricting, the access of the users via the gate device <b>102</b>, i.e. the gate device <b>102</b> may be in a closed state. If the received image data do not relate to a user without an access via the gate device <b>102</b>, the control unit <b>110</b> may be configured to control the barrier device to provide the access via the gate device <b>102</b>, e.g. by opening the barrier device of the gate device <b>102</b>.</p><p id="p-0044" num="0043">The control unit <b>102</b> is further configured to control the at least one indication device <b>108</b> to generate a first visual indication for the user <b>112</b>. The first visual indication comprises the obtained at least two destination floors. The at least one indication device <b>108</b> may comprise a projector device and the generation of the first visual indication may comprise projection, by the projection device, of the first visual indication on a surface in a vicinity of, i.e. close to, the gate device <b>102</b>, e.g. in front of the gate device <b>102</b> viewed from the passage direction of the user <b>112</b> via the gate device <b>102</b> and/or on at least one assumed passage route of the user <b>112</b> passing through the gate device <b>102</b>. The first visual indication may comprise an indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>for each of the at least two destination floors. The at least one indication device <b>108</b> may be arranged to the gate device <b>102</b> as illustrated in the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> or in a vicinity of, i.e. close to, the gate device <b>102</b>, e.g. to a wall, a ceiling and/or to a separate support device. Furthermore, the control unit <b>110</b> is configured to detect a destination floor selected by the user <b>112</b> from among the at least two destination floors based on sensor data received from the at least one sensor device <b>106</b>. The at least one sensor device <b>106</b> may comprise an optical sensor, e.g. a camera, a detection system based on radio waves, e.g. a radar, and/or an indoor positioning system. The at least one sensor device <b>106</b> may be arranged to the gate device <b>102</b> or in a vicinity of, i.e. close to, the gate device <b>102</b>, e.g. to a wall, a ceiling and/or to a separate support device. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref> the at least sensor device <b>106</b> is arrange to a wall. However, the invention is not limited to that and the at least one sensor device <b>106</b> may be arranged anywhere within the elevator environment <b>120</b> between the gate device <b>102</b> and the elevator cars A-D travelling along the elevator shafts so that the at least one sensor device <b>106</b> may detect the destination floor selected by the user <b>112</b>.</p><p id="p-0045" num="0044">According to an example of the invention, the detection of the destination floor selected by the user <b>112</b> may comprise detection of at least partial deformation of at least one indication element <b>202</b><i>a</i>-<b>202</b><i>n</i>. The deformation at least partial deformation of at least one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>may indicate that the user <b>112</b> passes over said at least one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>in order to select the destination floor comprised in said at least one indication element <b>202</b><i>a</i>-<b>202</b><i>n</i>. If one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>with at least partial deformation is detected, said one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>represents the destination floor selected by the user <b>112</b>. Alternatively, if two or more indication elements <b>202</b><i>a</i>-<b>202</b><i>n </i>with at least partial deformation are detected, the indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>with a greater deformation represents the destination floor selected by the user <b>112</b>, or no selection by the user <b>112</b> is detected. For example, if the received sensor data indicates e.g. 40% deformation of one indication element <b>202</b><i>a</i>-<b>202</b><i>n</i>, e.g. the indication element <b>202</b><i>b</i>, and e.g. 60% deformation of another indication element <b>202</b><i>a</i>-<b>202</b><i>n</i>, e.g. the indication element <b>202</b><i>b</i>, the control unit <b>110</b> may detect, i.e. infer that the user has selected the indication element with the 60% deformation or the control unit <b>110</b> may detect that no selection by the user <b>112</b> is detected, because the selection by the user <b>112</b> is considered as unclear selection.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> illustrates a non-limiting example situation, wherein the control unit <b>110</b> is detected the user <b>112</b> approaching the gate device <b>102</b> based on the imaged data received from the at least one imaging device <b>104</b>. In response to detection of the user <b>112</b> approaching the gate device <b>102</b>, the control unit <b>102</b> is configured to obtain destination floor information comprising three destination floors in this example. The example destination floors are floor <b>8</b>, where a caf&#xe9; is located in this example, floor <b>10</b>, where a spa is located in this example, and floor <b>4</b>, where meeting rooms are located in this example. Moreover, in the example situation of <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> the control unit <b>102</b> is further configured to control the at least one indication device <b>108</b> to project the first visual indication on the surface in the vicinity of the gate device <b>102</b>, e.g. at least one assumed passage route <b>201</b> of the user <b>112</b>, wherein the first visual indication comprises three indication elements <b>202</b><i>a</i>-<b>202</b><i>n</i>, i.e. one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>for each of the three destination floor in this example. The indication element <b>202</b><i>a </i>for the floor <b>8</b>, the indication element <b>202</b><i>b </i>for the floor <b>10</b>, and the indication element <b>202</b><i>c </i>for the floor <b>4</b>.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates a non-limiting example situation, wherein the user <b>112</b> is passing over the indication element <b>202</b><i>a</i>, i.e. the indication element for the floor <b>8</b>, causing that at least partial deformation of the indication element <b>202</b><i>a </i>may detected based on the based on sensor data received from the at least one sensor device <b>106</b>. This detection indicates that the user <b>112</b> has selected the destination floor <b>8</b> from among the three example destination floors. The line <b>201</b> illustrates a passage route of the user <b>112</b> along which the user <b>112</b> passes.</p><p id="p-0048" num="0047">According to an example according to the invention, the control <b>110</b> unit may be configured to provide the detected destination floor selection by the user <b>112</b> to an external database and/or to the elevator control system. The elevator control system may be configured to generate an elevator call to allocate an elevator car A-D to the destination floor selected by the user <b>112</b> in response to receiving the detected destination floor selection by the user <b>112</b> from the control unit <b>110</b>. The control unit <b>110</b> may further be configured to receive an elevator car identification information of the elevator car A-D to which an elevator call is generated from the elevator control system. This may be preferable especially in high-traffic situations, i.e. when a multiplicity of users is using the elevator system <b>120</b> at the same time, e.g. during rush hours. In the high-traffic situations an optimal allocation of the elevator cars A-D by the elevator control system is important in order to reduce a waiting time of the users.</p><p id="p-0049" num="0048">Alternatively, the control unit <b>110</b> may be configured to provide to the elevator control system an elevator car identification information of an elevator car A-D for generating an elevator call to allocate said elevator car A-D to the destination floor selected by the user <b>112</b>. This may be preferable especially in low-traffic situations, i.e. when only few users are using the elevator system <b>120</b>. In the low-traffic situations the optimal allocation is not so important enabling that the elevator car A-D to be allocated to the destination floor selected by the user <b>112</b> may be decided by the control unit <b>110</b>.</p><p id="p-0050" num="0049">The control unit <b>110</b> may further be configured to control the at least one indication device <b>108</b> to project a second visual indication on a surface in a vicinity of the gate device <b>102</b> or the user <b>112</b>, e.g. in front of the user viewed from the passage direction of the user <b>112</b>, i.e. on the route <b>201</b> of the user <b>112</b>, wherein the second visual indication may comprise an indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>indicating the elevator car identification information. Alternatively or in addition, when the system <b>100</b> further comprises one or more displays <b>204</b>, the control unit <b>110</b> may be configured to control the one or more displays <b>204</b> to display the elevator car identification information for the user <b>112</b>. This enables a simple way to inform the user <b>112</b> which elevator car A-D is allocated for the destination floor selected by the user <b>112</b> already when the user <b>112</b> is approaching the elevators A-D.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>2</b>C</figref> illustrates a non-limiting example situation, wherein the second visual indication comprising the elevator identification information is projected in front of the user <b>112</b> with an indication element <b>202</b><i>c</i>. In addition, in the example of <figref idref="DRAWINGS">FIG. <b>2</b>C</figref> the system <b>100</b> comprises a display <b>204</b> to display the elevator car identification information for the user <b>112</b>. The example display <b>204</b> is arranged on a wall in a an elevator hallway, but the invention is not limited to that the one or more displays <b>204</b> may be located anywhere in the elevator hallway. In the example of <figref idref="DRAWINGS">FIG. <b>2</b>C</figref> an elevator call to allocate the elevator car A to the destination floor selected by the user <b>112</b>, i.e. the floor <b>8</b>, is generated and projected in front of the user <b>112</b> with the indication element <b>202</b><i>c. </i></p><p id="p-0052" num="0051">Next an example of the method according to the invention is described by referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. <figref idref="DRAWINGS">FIG. <b>3</b></figref> schematically illustrates the invention as a flow chart.</p><p id="p-0053" num="0052">At a step <b>302</b>, the control unit <b>110</b> receives image data from the at least one imaging device <b>104</b>. At a step <b>304</b>, the control unit <b>110</b> detects a user <b>112</b> approaching the gate device <b>102</b> based on the received image data.</p><p id="p-0054" num="0053">At a step <b>306</b>, in response to detection of the user <b>112</b> approaching the gate device <b>102</b>, the control unit <b>102</b> obtains destination floor information comprising at least two destination floors. The process of obtaining the destination floor information may depend on whether the user is identified as an authorized user or not. If the user is not identified as an authorized user, e.g. any user entering a building in which the elevator system <b>120</b> resides, the at least two destination floors may comprise one or more default destination floors defined based on a time of day, one or more destination floors defined based on a current traffic flow, and/or one or more destination floors defined based on an exceptional situation, e.g. a fault state of one or more elevator cars A-D.</p><p id="p-0055" num="0054">According to an example of the invention the detection of the user <b>112</b> at the step <b>304</b> may further comprise identification of an authorized user based on the received image data and prestored data associated with the authorized users by using facial recognition-based identification. The control unit <b>110</b> may determine based on the received image data and prestored data associated with the authorized, whether the image data relates to an authorized user or not. In other words, the received image data may be compared to the prestored data in order to find a possible match from the prestored data. The prestored data may be stored in a memory or database connected to the control unit <b>110</b>, or in a cloud service accessible via a network connection. For example, if the access control system <b>100</b> is arranged in a building, image data relating to people regularly residing, e.g. working or living, in the building may have been prestored in the memory or database. For the authorized users the destination floors may be suggested more versatile. Moreover, for the authorized users <b>112</b> user specific destination floors may be obtained.</p><p id="p-0056" num="0055">If the user <b>112</b> is identified as an authorized user, the at least two destination floors may comprise one or more default destination floors defined based on a time of day; one or more destination floors defined based on a current traffic flow; one or more destination floors defined based on an exceptional situation, e.g. a fault state of one or more elevator cars A-D; one or more default destination floors assigned for said authorized user; one or more destination floors set by the said authorized user; one or more destination floors defined based on previously selected destination floors by said authorized user; and/or a destination floor defined based on a scheduled event for said authorized user, wherein the scheduled event is obtained from an external storage unit, such as a database, to which the scheduled event is stored. For example, if a meeting in a specific floor is scheduled for said authorized user the at least two destination floors may comprise said specific floor to which the meeting is scheduled. The one or more default destination floors assigned for said authorized user may comprise e.g. a home floor and/or an office floor of said authorized user.</p><p id="p-0057" num="0056">The one or more destination floors set by the said authorized user may comprise any floor of the building predefined by said authorized user. According to an example, machine learning techniques may be used to define the one or more destination floors defined based on previously selected destination floors by said authorized user. The at least two destination floors may be obtained from a memory or a database connected to the control unit <b>110</b> or from a cloud service accessible via a network connection.</p><p id="p-0058" num="0057">At a step <b>308</b>, the control unit <b>102</b> controls the at least one indication device <b>108</b> to generate a first visual indication for the user <b>112</b>. The first visual indication comprises the obtained at least two destination floors. The first visual indication may comprise an indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>for each of the at least two destination floors.</p><p id="p-0059" num="0058">At a step <b>310</b>, the control unit <b>110</b> detects a destination floor selected by the user <b>112</b> from among the at least two destination floors based on sensor data received from the at least one sensor device <b>106</b>. According to an example of the invention, the detection of the destination floor selected by the user may comprise detection of at least partial deformation of at least one indication element <b>202</b><i>a</i>-<b>202</b><i>n</i>. The deformation at least partial deformation of at least one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>may indicate that the user <b>112</b> passes over said at least one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>in order to select the destination floor comprised in said at least one indication element <b>202</b><i>a</i>-<b>202</b><i>n</i>. If one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>with at least partial deformation is detected, said one indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>represents the destination floor selected by the user <b>112</b>. Alternatively, if two or more indication elements <b>202</b><i>a</i>-<b>202</b><i>n </i>with at least partial deformation are detected, the indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>with a greater deformation represents the destination floor selected by the user <b>112</b>, or no selection by the user <b>112</b> is detected.</p><p id="p-0060" num="0059">According to an example of the invention, the method may further comprise providing by the control unit <b>110</b> the detected destination floor selection by the user <b>112</b> to an external database and/or to the elevator control system. The elevator control system may generate an elevator call to allocate an elevator car A-D to the destination floor selected by the user <b>112</b> in response to receiving the detected destination floor selection by the user <b>112</b> from the control unit <b>110</b>. The control unit <b>110</b> may further receive an elevator car identification information of the elevator car A-D to which an elevator call is generated from the elevator control system. This may be preferable especially in high-traffic situations as discussed above.</p><p id="p-0061" num="0060">Alternatively, the method may further comprise providing by the control unit <b>110</b> to the elevator control system an elevator car identification information of an elevator car A-D for generating an elevator call to allocate said elevator car A-D to the destination floor selected by the user <b>112</b>. This may be preferable especially in low-traffic situations as discussed above.</p><p id="p-0062" num="0061">According to an example of the invention, the method may further comprise controlling by the control unit <b>110</b> the at least one indication device <b>108</b> to project a second visual indication on a surface in a vicinity of the user <b>112</b>, e.g. in front of the user <b>112</b>, i.e. on the route <b>201</b> of the user <b>112</b>, wherein the second visual indication may comprise an indication element <b>202</b><i>a</i>-<b>202</b><i>n </i>indicating the elevator car identification information. Alternatively or in addition, when the system <b>100</b> further comprises one or more displays <b>204</b>, the control unit <b>110</b> may be configured to control the one or more displays <b>204</b> to display the elevator car identification information for the user <b>112</b>. This enables a simple way to inform the user <b>112</b> which elevator car A-D is allocated for the destination floor selected by the user <b>112</b> already when the user <b>112</b> is approaching the elevators A-D.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>4</b></figref> schematically illustrates an example of components of the control unit <b>110</b> according to the invention. The control unit <b>110</b> may comprise a processing unit <b>410</b> comprising one or more processors, a memory unit <b>420</b> comprising one or more memories, a communication unit <b>430</b> comprising one or more communication devices, and possibly a user interface (UI) unit <b>450</b>. The memory unit <b>420</b> may store portions of computer program code <b>425</b> and any other data, and the processing unit <b>410</b> may cause the control unit <b>110</b> to operate as described by executing at least some portions of the computer program code <b>425</b> stored in the memory unit <b>420</b>. The communication unit <b>430</b> may be based on at least one known communication technologies, either wired or wireless, in order to exchange pieces of information as described earlier. The communication unit <b>430</b> provides an interface for communication with any external unit, such as the gate device <b>102</b>, the at least one imaging device <b>104</b>, the at least one sensor device <b>106</b> and the at least one indication device <b>108</b>, the elevator control system, database and/or any external systems. The communication unit <b>430</b> may comprise one or more communication devices, e.g. radio transceiver, antenna, etc. The user interface <b>440</b> may comprise I/O devices, such as buttons, keyboard, touch screen, microphone, loudspeaker, display and so on, for receiving input and outputting information. The computer program <b>425</b> may be stored in a non-statutory tangible computer readable medium, e.g. an USB stick or a CD-ROM disc.</p><p id="p-0064" num="0063">The specific examples provided in the description given above should not be construed as limiting the applicability and/or the interpretation of the appended claims. Lists and groups of examples provided in the description given above are not exhaustive unless otherwise explicitly stated.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An access control system for an elevator system comprising:<claim-text>a gate device allowing access for users via the gate device;</claim-text><claim-text>at least one imaging device for obtaining image data;</claim-text><claim-text>at least one sensor device for obtaining sensor data;</claim-text><claim-text>at least one indication device; and</claim-text><claim-text>a control unit configured to:<claim-text>receive the image data from the at least one imaging device;</claim-text><claim-text>detect a user approaching the gate device based on the received image data;</claim-text><claim-text>obtain destination floor information comprising at least two destination floors;</claim-text><claim-text>control the at least one indication device to generate a first visual indication comprising the at least two destination floors; and</claim-text><claim-text>detect a destination floor selected by the user from among the at least two destination floors based on sensor data received from the at least one sensor device.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The access control system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generation of the first visual indication comprises projection of the first visual indication on a surface in a vicinity of the gate device, and wherein the first visual indication comprises an indication element for each of the at least two destination floors.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The access control system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the detection of the destination floor selected by the user comprises detection of at least partial deformation of at least one indication element, wherein:<claim-text>if one indication element with at least partial deformation is detected, said one indication element represents the destination floor selected by the user; or</claim-text><claim-text>if two or more indication elements with at least partial deformation are detected, the indication element with a greater deformation represents the destination floor selected by the user, or no selection by the user is detected.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The access control system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control unit is configured to provide the detected destination floor selection by the user to an external database and/or an elevator control system.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The access control system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the elevator control system is configured to generate an elevator call to allocate an elevator car to the destination floor selected by the user in response to receiving the detected destination floor selection by the user from the control unit.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The access control system according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the control unit is further configured to receive an elevator car identification information of the elevator car to which an elevator call is generated from the elevator control system.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The access control system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the control unit is further configured to provide to the elevator control system an elevator car identification information of an elevator car for generating an elevator call to allocate said elevator car to the destination floor selected by the user.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The access control system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the control unit is further configured to control the at least one indication device to project a second visual indication on a surface in a vicinity of the gate device or the user, wherein the second visual indication comprises the elevator car identification information; and/or<claim-text>wherein the system further comprises one or more displays, and the control unit is configured to control the one or more displays to display the elevator car identification information.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The access control system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least two destination floors comprise:<claim-text>one or more default destination floors defined based on a time of day;</claim-text><claim-text>one or more destination floors defined based on a current traffic flow; and/or</claim-text><claim-text>one or more destination floors defined based on an exceptional situation.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The access control system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the detection of the user further comprises identification of an authorized user based on the received image data and prestored data associated with the authorized users by using facial recognition-based identification.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The access control system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the at least two destination floors comprise:<claim-text>one or more default destination floors defined based on a time of day;</claim-text><claim-text>one or more destination floors defined based on a current traffic flow;</claim-text><claim-text>one or more destination floors defined based on an exceptional situation;</claim-text><claim-text>one or more default destination floors assigned for said authorized user;</claim-text><claim-text>one or more destination floors set by the said authorized user;</claim-text><claim-text>one or more destination floors defined based on previously selected destination floors by said authorized user; and/or</claim-text><claim-text>a destination floor defined based on a scheduled event for said authorized user, wherein the scheduled event is obtained from an external storage unit to which the scheduled event is stored.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An elevator system comprising:<claim-text>at least two elevator cars each travelling along a respective elevator shaft;</claim-text><claim-text>an elevator control system; and</claim-text><claim-text>the access control system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> comprising at least one gate device.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A method for controlling the access control system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, the method comprising:<claim-text>receiving image data from at least one imaging device;</claim-text><claim-text>detecting a user approaching a gate device based on the received image data;</claim-text><claim-text>obtaining destination floor information comprising at least two destination floors;</claim-text><claim-text>controlling at least one indication device to provide a first visual indication comprising the at least two destination floors; and</claim-text><claim-text>detecting a destination floor selected by the user from among the at least two destination floors based on sensor data received from at least one sensor device.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the providing of the first visual indication comprises projecting the first visual indication on a surface in a vicinity of the gate device, and wherein the first visual indication comprises an indication element for each of the at least two destination floors.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the detecting the destination floor selected by the user comprises detecting at least partial deformation of at least one indication element, wherein:<claim-text>if one indication element with at least partial deformation is detected, said one indication element represents the destination floor selected by the user; or</claim-text><claim-text>if two or more indication elements with at least partial deformation are detected, the indication element with a greater deformation represents the destination floor selected by the user, or no selection by the user is detected.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref> further comprising providing the detected destination floor selection by the user to an external database and/or an elevator control system.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method according to <claim-ref idref="CLM-00016">claim 16</claim-ref> further comprising generating an elevator call to allocate an elevator car to the destination floor selected by the user in response to receiving the detected destination floor selection by the user.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method according to <claim-ref idref="CLM-00017">claim 17</claim-ref> further comprising receiving an elevator car identification information of the elevator car to which an elevator call is generated from the elevator control system.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the method further comprises providing to the elevator control system an elevator car identification information of an elevator car for generating an elevator call to allocate said elevator car to the destination floor selected by the user.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method according to <claim-ref idref="CLM-00018">claim 18</claim-ref> further comprising:<claim-text>controlling the at least one indication device to project a second visual indication on a surface in a vicinity of the gate device or the user, wherein the second visual indication comprises the elevator car identification information; and/or</claim-text><claim-text>controlling one or more displays to display the elevator car identification information.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the at least two destination floors comprise:<claim-text>one or more default destination floors defined based on a time of day;</claim-text><claim-text>one or more destination floors defined based on a current traffic flow; and/or</claim-text><claim-text>one or more destination floors defined based on an exceptional situation.</claim-text></claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the step of detecting the user further comprises identifying an authorized user based on the received image data and prestored data associated with authorized users by using facial recognition-based identification.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The method according to <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the at least two destination floors comprise:<claim-text>one or more default destination floors defined based on a time of day;</claim-text><claim-text>one or more destination floors defined based on a current traffic flow;</claim-text><claim-text>one or more destination floors defined based on an exceptional situation; one or more default destination floors assigned for said authorized user;</claim-text><claim-text>one or more destination floors set by the said authorized user;</claim-text><claim-text>one or more destination floors defined based on previously selected destination floors by said authorized user; and/or</claim-text><claim-text>a destination floor defined based on a scheduled event for said authorized user, wherein the scheduled event is obtained from an external storage unit to which the scheduled event is stored.</claim-text></claim-text></claim></claims></us-patent-application>
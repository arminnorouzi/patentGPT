<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004432A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004432</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364338</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>50</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>34</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>455</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>505</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>3476</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>45558</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>2009</main-group><subgroup>45591</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Tenant-Level Monitoring</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>salesforce.com, inc.</orgname><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Wilding</last-name><first-name>Mark F.</first-name><address><city>Issaquah</city><state>WA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Techniques are disclosed relating to monitoring behavior of a computing system shared by multiple tenants. In some embodiments, a computer cluster is maintained that hosts containers accessible to a plurality of tenants of the computer cluster. First telemetry data collected about a particular one of the plurality of tenants is received from a container hosted at a first of a plurality of servers of the computer cluster. The first telemetry data identifies the particular tenant's consumption of a resource provided by the container. In response to the computer cluster migrating the container from the first server to a second of the plurality of servers, second telemetry data collected about the particular tenant's consumption of the resource is received from the migrated container hosted at the second server. An analysis is performed of the first and second telemetry data to identify whether the particular tenant's consumption of the resource has changed.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="218.27mm" wi="70.10mm" file="US20230004432A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="253.32mm" wi="158.33mm" file="US20230004432A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="219.20mm" wi="163.24mm" orientation="landscape" file="US20230004432A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="127.93mm" wi="168.23mm" file="US20230004432A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="187.03mm" wi="161.71mm" file="US20230004432A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="235.03mm" wi="72.14mm" file="US20230004432A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="196.26mm" wi="124.46mm" file="US20230004432A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><heading id="h-0002" level="1">Technical Field</heading><p id="p-0002" num="0001">This disclosure relates generally to distributed computing systems and, more specifically, to monitoring behavior of a distributed computing system shared by multiple tenants.</p><heading id="h-0003" level="1">Description of the Related Art</heading><p id="p-0003" num="0002">In an enterprise environment, a company may operate multiple servers that provide various services for its environment. To appropriately manage these servers, software may be installed that tracks various metrics about the servers over time. For example, it may be helpful track a given server's processor and memory usage, network bandwidth consumption, etc. These metrics can then be used to facilitate planning and scaling. For example, if a particular server providing an important service starts routinely running up against processor or memory constraints, an administrator could discern from these metrics that it may make sense to upgrade the server or purchase additional servers. These metrics can also be used for diagnosing problems such as discerning a faulty network connection when a server's pack loss suddenly spikes.</p><p id="p-0004" num="0003">The computing industry, however, is starting to move away from a traditional model in which a company may operate its own servers to a cloud computing model in which multiple companies are tenants of a shared computing cluster that hosts their content. Advantages of this approach are that expensive underlying hardware can be more efficiently used and individual companies are not responsible for maintaining it. The new approach, however, proposes a challenge for traditional computing system monitoring techniques.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of one embodiment of a system for monitoring tenants hosted by a distributed computing system.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating one embodiment of components within a host server of the distributed computing system to facilitate monitoring.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating one embodiment of a curation and analytics unit of the monitoring system.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating one embodiment of an analysis of telemetry data collected by the monitoring system.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flow diagram illustrating one embodiment of a method performed by components within the monitoring system.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating one embodiment of an exemplary computer system.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0011" num="0010">In large computing clusters having high numbers of tenants, tenants may be frequently relocated from one group of servers to another as tenant demands and available resources change over time. This added tenant mobility can result in traditional server metrics being far less useful as it can be difficult to establish some baseline that can be used to identify problems. For example, if a given server's memory and processor consumptions change, it may be difficult to discern whether this change is attributable to some problem or merely resultant from a change in the tenants currently assigned to the server. General system health may also be a crude way for diagnosing specific problems.</p><p id="p-0012" num="0011">Large computing clusters may also generate enough metadata making it impossible for an administrative user to process all this metadata. For example, an administrative user may begin his or her investigation based on a small number of signals such as an alert and attempt to drill down from these signals. This user, however, may struggle with the vast amount and diversity of monitoring information, any of which could be closely related to the root cause of some problem being investigated. Manually diagnosing a problem in this manner thus becomes an inherently slow and expensive process.</p><p id="p-0013" num="0012">The present disclosure describes embodiments in which tenant telemetry data is collected on a per-tenant basis and processed using automated analysis. As will be discussed below in various embodiments, a computer cluster hosts containers accessible to multiple tenants of the computer cluster. These containers may, for example, belong to individual tenants and include applications and/or data, which are accessed by the tenant's users. As containers are moved around among various servers implementing the computer cluster, telemetry data may be collected on a per-tenant basis about a given tenant's use of underlying resources. These resources may be components within a given container such as applications, libraries, data, etc. These resources may also be resources external to a given container, but accessible to a tenant through the container. Examples of these resources may include underlying infrastructure (such as a server's processors, memory, persistent storage, network interfaces), a host operating system running on the server, other applications executing on the server, etc. This telemetry data may also be collected from various sources such as from the containers themselves, the underlying infrastructure at a given host server, a container manager, etc.</p><p id="p-0014" num="0013">In various embodiments, this telemetry data is aggregated for multiple tenants scattered across the cluster and processed for analysis. As part of performing this analysis, a computing system may examine various metrics about a particular tenant over time to establish a baseline for the tenant's usage of resources and identify whether a deviation has occurred from this baseline, which may be indicative of some underlying issue. For example, received telemetry data might indicate that users of a particular tenant access a particular application for three hours a day on average. If this drops to a few minutes a day, the computing system may identify this deviation and raise it to the attention of an administrator as this deviation may be reflective of an underlying problem&#x2014;e.g., that an update to the application's user interface was not well received by the users. In various embodiments, this analysis considers numerous metrics and may further be able to leverage metrics collected about other tenants. For example, if a source of a problem was successfully identified for a first tenant having particular issues, the knowledge of this source might be helpful to another tenant suffering from another problem, which appears to have similar issues. In such an embodiment, the computing system may flag the issue to the other tenant before an admin has even reported the issue and suggest the source of the problem identified for the first tenant&#x2014;e.g., that a particular driver is known to be faulty when configured in a particular manner.</p><p id="p-0015" num="0014">In many instances, this approach to automating analysis and identification of problems (and their corresponding causes) can dramatically reduce human effort. The approach can also improve the availability and quality of underlying telemetry data as a computing system may be capable of investigating thousands or even millions of metrics/signals.</p><p id="p-0016" num="0015">Turning now to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a block diagram of a monitoring system <b>10</b> is depicted. In the illustrated embodiment, monitoring system <b>10</b> includes a distributed computing system <b>100</b> that includes multiple host servers <b>110</b>, which interface with client devices <b>20</b>. Monitoring system <b>10</b> also includes a curation and analytics unit <b>120</b> and a database <b>130</b>. In other embodiments, system <b>10</b> may be implemented differently than shown&#x2014;e.g., system <b>100</b> may include more host servers <b>110</b>, which may include more containers <b>112</b>.</p><p id="p-0017" num="0016">Distributed computing system <b>100</b>, in various embodiments, is a computer cluster (shown as a cloud) that includes multiple host servers <b>110</b> working together to provide various services. Host servers <b>110</b>, in some embodiments, are server blades housed in multiple server racks, which may be located in a server farm. In some embodiments, servers <b>110</b> may be spread across multiple availability zones (AZs), which may reside in different geographic regions. In illustrated embodiment, distributed computing system <b>100</b> hosts tenant content using containers <b>112</b>. In various embodiments, containers <b>112</b> are software constructs that include program instructions and/or data packaged in a manner that facilitates easy deployment and relocation. Accordingly, a given container <b>112</b> may include program instructions for one or more applications as well as their dependencies such as system libraries, runtime tools, drivers, a guest operating system, etc. Examples of containers <b>112</b> may include virtual machines, control groups (Cgroups), namespaces, Linux containers (LXCs), Docker&#xae; containers, Heroku&#xae; dynos, etc. In some embodiments, containers <b>112</b> may belong to a single tenant, which may have multiple containers <b>112</b>. In some embodiments, containers <b>112</b> may be shared by multiple tenants&#x2014;and containers <b>112</b> may contain other containers <b>112</b>.</p><p id="p-0018" num="0017">Tenants using containers <b>112</b> may be enterprise-level companies with large numbers of users or smaller entities with only one or two users. As a result, a given tenant's demands may vary widely from one tenant to the next. A given tenant's demands may also vary over time. For example, a small startup company may operate a small number containers that place only a small load a single host server <b>110</b>, but, over time, this company may grow in size and place a greater load on distributed computing system <b>100</b>. Because tenant demands are subject to change, in various embodiments, distributed computing system <b>100</b> may migrate containers <b>112</b> from one host server <b>1100</b> to another. For example, as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, distributed computing system <b>100</b> may perform a migration <b>116</b> of a container <b>112</b> being accessed by client devices <b>20</b> of a tenant B from host server <b>110</b>A to host server <b>110</b>B. This migration <b>116</b> may be performed because, for example, tenant A's container <b>112</b> is consuming a considerable amount of host servers <b>110</b>A's memory and host server <b>110</b>B has additional performance bandwidth. As noted above, however, this added mobility may render general performance metrics collected about host servers <b>110</b> less useful than if tenant locations were static.</p><p id="p-0019" num="0018">In various embodiments, however, host servers <b>110</b> collect telemetry data <b>118</b> on a per-tenant basis and as a tenant is moved around distributed computing system <b>100</b> (or more specifically as containers <b>112</b> accessed by a tenant are migrated from one set of host servers <b>110</b> to the next). This telemetry data <b>118</b> may include various metrics about a tenant's usage/consumption of resources <b>114</b> provided by containers <b>112</b>. As will be discussed, these resources <b>114</b> may include components within a container <b>112</b> such as applications and data or components external to a container <b>112</b> such as processors, memory, network interfaces, drivers, operating systems, databases, web servers, external applications, etc. Some examples of resource usage metrics in telemetry data <b>118</b> may include a time value indicative of how long a user of the tenant has used an application, a frequency value indicative of how frequently a user has used the application, etc. In some embodiments, telemetry data <b>118</b> includes usage pattern information such as individual feature usage, data growth rate, overall feature usage measured in time, number of logins, etc. In some embodiments, telemetry data <b>118</b> includes metrics indicative of the underlying user experience such as latency information identifying how long it takes a user to get a response with accessing particular features, an error rate associated with a user's interactions, etc. As will also be discussed, telemetry data <b>118</b> may be collected from a variety of sources within a host server <b>110</b> such as applications within a container <b>112</b>, the underlying substrate hosting a container <b>112</b>, a container manager, etc. Various examples of telemetry data <b>118</b> and sources of telemetry data <b>118</b> are discussed in greater detail below with respect to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0020" num="0019">Telemetry curation and analytics unit <b>120</b>, in various embodiments, curates tenant telemetry data <b>118</b> collected from various host servers <b>110</b>. In some embodiments, telemetry curation and analytics unit <b>120</b> may be executing on one or more of host servers <b>110</b>; however, in other embodiments, unit <b>120</b> may be implemented on separate computing system. As will be described in greater detail below with respect to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, telemetry curation and analytics unit <b>120</b> may receive vast amounts of data <b>118</b> and preprocesses the data <b>118</b> to pull out the high-value metrics/signals, which can be used to identify potential problems. In doing so, unit <b>120</b> may reduce the overall data set (e.g., by 95% in some embodiments). Telemetry curation and analytics unit <b>120</b> may also format and reorganize data <b>118</b> in a manner that is more conduce to analysis. For example, in the illustrated embodiment, telemetry curation and analytics <b>120</b> stores data <b>118</b> in database <b>130</b>, which is organized based on tenant.</p><p id="p-0021" num="0020">Telemetry curation and analytics unit <b>120</b>, in various embodiments, is further operable to analyze telemetry data <b>118</b> received from multiple host servers <b>110</b> and pertaining to multiple tenants. As will be described in greater detail below with respect to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, unit <b>120</b> may attempt to correlate various metrics based on time to discern whether certain events may be related (e.g., a jump in user latency and a recent change to an operating system configuration). Unit <b>120</b> may also apply one or more algorithms to discern pattern changes over time, which may be used identify potential problems. These algorithms may, for example, look at a tenant's (or its users') historical trends based on telemetry data <b>118</b> collected over time. These algorithms may also look at trends across multiple tenants. In some embodiments, unit <b>120</b> may also provide a user interface (e.g., a dashboard) for presenting analysis results and receiving feedback from a tenant admin. Telemetry curation and analytics unit <b>120</b> will be discussed in greater detail below with respect to <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0022" num="0021">Various examples of possible sources of telemetry data <b>118</b> will now be discussed.</p><p id="p-0023" num="0022">Turning now to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a block diagram of host server <b>110</b> is depicted. In the illustrated embodiment, host server <b>110</b> includes an assortment of containers <b>112</b>A-D providing access to various resources <b>114</b>A-G. Host server <b>110</b> also includes a container manager <b>220</b>, an underlying subtracted layer <b>230</b>, and a telemetry transport <b>240</b>. In other embodiments, host server <b>110</b> may be implemented differently.</p><p id="p-0024" num="0023">As shown, container <b>112</b>A may include two resources <b>114</b>: an application <b>114</b>A and tenant data <b>114</b>B. In the illustrated embodiment, application <b>114</b>A is executable to collect and provide its own telemetry data <b>118</b>. In some embodiments, application <b>114</b>A may be provided by an operator of distributed computing system <b>100</b> or incorporate a plugin provided by the operator and that collects telemetry data <b>118</b>. Telemetry data <b>118</b> associated with application <b>114</b>A may include, for example, usage information about a tenant's users such as what features of application <b>114</b>A were accessed, how long were the features accessed, when were the features accessed, what features were most popular among users, how many logins occurred, etc. In the illustrated embodiment, tenant data <b>114</b>B is data that is operated on by application <b>114</b>A and may belong to a particular tenant. Telemetry data <b>118</b> associated with data <b>114</b>B may include, for example, the size of data <b>114</b>B, the growth rate of data <b>114</b>B, access and update frequencies of data <b>114</b>B, etc.</p><p id="p-0025" num="0024">Container <b>112</b>B may include a monitoring agent <b>210</b> and another two resources: tenant application <b>114</b>C and virtual hardware <b>114</b>D. In the illustrated embodiment, tenant application <b>114</b>C is an application developed by a tenant that does not have the ability to report telemetry data <b>118</b>. As a result, monitoring agent <b>210</b> may be included to collect and report data <b>118</b>. In some embodiments, agent <b>210</b> may read logs produced by application <b>114</b>C, configuration files used by application <b>114</b>C, etc. in order to obtain telemetry data <b>118</b>. In the illustrated embodiment, virtual hardware <b>114</b>D is a virtual resource presented by container <b>112</b>B to facilitate execution of application <b>114</b>C and may correspond to physical hardware in substrate layer <b>230</b>. For example, container <b>112</b>B may present a virtual network interface that is usable by application <b>114</b>C to convey network traffic with a client device <b>20</b> over a physical network interface of host server <b>110</b>. In such an embodiment, monitoring agent <b>210</b> may interface with the software presenting virtual hardware <b>114</b>D in order to provide telemetry data <b>118</b> about the use of this virtual hardware <b>114</b>D (or the underlying physical hardware). For example, telemetry data <b>118</b> may identify an average network latency and an average network bandwidth consumed by application <b>114</b>C to communicate with a tenant's client devices <b>20</b>.</p><p id="p-0026" num="0025">Containers <b>112</b>C and <b>112</b>D may reside on top of an external service <b>114</b>E (which may be a resource <b>114</b>) and include respective data sets <b>114</b>F and <b>114</b>G belonging to different tenants (which may be yet another resource <b>114</b>). In some embodiments, external service <b>114</b>E may be provide by an application that is shared by multiple tenants and may reside within its own container <b>112</b> (not shown). For example, in one embodiment, external service <b>114</b>E is a database provided by a database application that can process concurrent transactions and service database queries. In the illustrated embodiment, containers <b>112</b>C and <b>112</b>D are used to ensure isolation of one tenant's data <b>114</b> from another's data <b>114</b>. Thus, in the databases example, tenant B cannot submit a query and receive back data <b>114</b>F belonging to tenant A. These containers <b>112</b>C and <b>112</b>D may also enable one tenant to be moved to another corresponding external service <b>114</b>E located at another host server <b>110</b> within minimal intrusion&#x2014;e.g., if tenant A's data <b>114</b>F (or more generally container <b>112</b>C) becomes too large for the current host server <b>110</b>. In some embodiments, external service <b>114</b>E (or a monitoring agent in container <b>112</b>C) may report telemetry data <b>118</b> about a tenant's use of external service <b>114</b>E and about a tenant's container <b>112</b> being hosted by service <b>114</b>E. Continuing with the database example, telemetry data provided by service <b>114</b>E may include the volume of queries, the frequency of queries (including top queries of a particular tenant), the complexities of servicing queries, the size of data <b>114</b>F, rates for data insertions into the database, etc.</p><p id="p-0027" num="0026">In various embodiments, tenant telemetry data <b>118</b> may also originate from sources others than containers <b>112</b>. For example, in the illustrated embodiment, tenant telemetry data <b>118</b> is also provided by container manager <b>220</b> and substrate layer <b>230</b>.</p><p id="p-0028" num="0027">Container manager <b>220</b>, in various embodiments, manages containers <b>112</b> on host server <b>110</b>. Accordingly, manager <b>220</b> may instantiate and provision containers <b>112</b>. Manager <b>220</b> may also monitor container <b>112</b> health and take remedial actions based on their health, such as restarting containers <b>112</b> and instantiating new ones. In some embodiments, manager <b>220</b> may also receive containers <b>112</b> migrated from other servers <b>110</b> and cause them to be run on host server <b>110</b>. As manager <b>220</b> performs various actions with respect to containers <b>112</b>, in some embodiments, manager <b>220</b> may produce telemetry data <b>118</b>, which can be collected and provided to curation and analytics unit <b>120</b>. In some embodiments, manager <b>220</b> may be implemented using Kubernetes&#xae;, Docker&#xae;, etc.</p><p id="p-0029" num="0028">Substrate layer <b>230</b>, in various embodiments, is the underlying components of host server <b>110</b> that facilitate hosting containers <b>112</b>. This layer <b>230</b> may include hardware components such as processors, memory, persistent storage, network interfaces, input/output devices, etc. This layer <b>230</b> may also include software components such as a hypervisor, operating system, drivers, APIs, etc. In some embodiments, these components may produce telemetry data <b>118</b>&#x2014;and may also correspond to resources <b>114</b> accessible via containers <b>112</b>. Telemetry data <b>118</b> may thus include various usage metrics such as the amount of current processor and memory usage are being consumed by a tenant's containers <b>112</b>.</p><p id="p-0030" num="0029">Telemetry transport <b>240</b>, in various embodiments, handles the aggregation and transportation of tenant telemetry data <b>118</b> from a host server to curation and analytics unit <b>120</b>. In some embodiments, this may include translating aggregated telemetry data <b>118</b> into a format that can be better understood by downstream components such as curation and analytics unit <b>120</b>. This may include tagging telemetry data <b>118</b> with unique identifiers of tenants, so that unit <b>120</b> can discern what data <b>118</b> pertains to what tenant. Telemetry transport <b>240</b> may also time stamp data <b>118</b>. In various embodiments, transport <b>240</b> also packetizes data <b>118</b> for transport over a network connection to the computing system hosting curation and analytics unit <b>120</b>. Transport <b>240</b> may then establish the network connection to stream data <b>118</b> to unit <b>120</b>. In some embodiments, transport <b>240</b> may be designed to stream content to curation and analytics unit <b>120</b> within milliseconds of data <b>118</b> being created.</p><p id="p-0031" num="0030">Turning now to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a block diagram of curation of analytics unit <b>120</b> is depicted. In the illustrated embodiment, curation and analytics unit <b>120</b> includes a curation engine <b>310</b>, which may have access to a cold storage <b>314</b>. Curation and analytics unit <b>120</b> also includes analytics engine <b>320</b>, which may present a user interface dashboard <b>324</b>. In some embodiments, unit <b>120</b> may be implemented differently than shown.</p><p id="p-0032" num="0031">Curation engine <b>310</b>, in various embodiments, handles the curation of telemetry data <b>118</b> received from various host servers <b>110</b>. On intake, curation engine <b>310</b> may perform some initial preprocessing of telemetry data <b>118</b> to extract the most valuable metrics from the telemetry data in order to reduce the working data size without losing significant value. For example, curation engine <b>310</b> may concentrate on extracting anomalies, sketches/rollups, summaries, alerts, activity timelines, and other signals from encoded domain expertise. Curation engine <b>310</b> may also focus on information that can be used to establish a baseline and identify when a deviation occurs&#x2014;e.g., even a sudden drop in the number of errors per minute might be a valuable indicator of a potential problem. As engine <b>310</b> processes incoming tenant telemetry data <b>118</b>, engine <b>310</b> may send the raw telemetry data <b>312</b>A on to cold storage <b>314</b> and separate out interesting data <b>118</b>, which it sends as processed telemetry data <b>312</b>B to database <b>130</b>.</p><p id="p-0033" num="0032">Cold storage <b>314</b>, in various embodiments, is configured to store raw/unfiltered telemetry data <b>312</b>A as it comes in, so that it can potentially be analyzed later if more in-depth information is desired. As this data <b>312</b>A, in some embodiments, may run into the petabytes, storage <b>314</b> may be designed to store large quantities of data <b>312</b>A at much lower cost but may offer less performance than database <b>130</b>. In some embodiments, however, cold storage <b>314</b> may use compression to reduce the size of data <b>312</b>A. In contrast, database <b>130</b>, which is functioning as the hot storage in the illustrated embodiment, stores a much smaller data set <b>312</b>B (e.g., 1% the size of raw telemetry data <b>312</b>A), which has been processed and organized in manner that improves performance of the analysis.</p><p id="p-0034" num="0033">Analysis engine <b>320</b>, in various embodiments, handles the analysis of telemetry data <b>118</b>. As will be discussed with <figref idref="DRAWINGS">FIG. <b>4</b></figref>, engine <b>320</b> may correlate telemetry data <b>118</b> from various sources by organizing the data <b>118</b> based on time. This may be used, for example, to determine that several events occurring within the same time intervals may be related to one another. These events may also be associated with individual users, users belonging to the same tenant, users across multiple tenants. Correlating telemetry data <b>118</b> in this manner may also allow engine <b>320</b> to identify patterns in tenant behavior, which can be used to establish baselines and identify anomalies when substantial deviations from these baselines occur. For example, engine <b>320</b> may correlate a production issue occurring at a particular time with its impact on a particular tenant due to changes in the particular tenant's usage patterns after that particular time.</p><p id="p-0035" num="0034">Analytics engine <b>320</b> may use any suitable algorithm to analyze telemetry data <b>118</b>. In some embodiments, engine <b>320</b> uses multiple rule-based algorithms. For example, engine <b>320</b> may use an algorithm that flags particular events when metrics associated with those events satisfy some preestablished threshold such as an average latency for client devices <b>20</b> exceeding some high water mark. In some embodiments engine <b>320</b> uses multiple machine learning algorithms. For example, engine <b>320</b> may train up a neural network that is effective at identifying particular metrics/signals as being important and discerning when those metrics/signals are indicative of particular problems. In some embodiments, different algorithms may be applied in different phases. For example, in one embodiment, engine <b>320</b> may use rule-based algorithms on intake of telemetry data <b>118</b> and one or more machine learning algorithms on processed telemetry data <b>312</b>B collected over time. While, in some embodiments, these algorithms may be broadly applicable, in some embodiments, these algorithms may be tailored to specific services, specific tenants, etc. As noted above, these algorithms may, in general, be able to process large amounts of telemetry data <b>118</b> from multiple tenants far more quickly and efficiently than any manual analysis.</p><p id="p-0036" num="0035">User interface dashboard <b>324</b>, in various embodiments, is a user interface than can present various information including analysis results <b>322</b> produced by analytics engine <b>320</b>. In some embodiments, these results <b>322</b> may include notifications of potential problems that have been identified by analysis engine <b>320</b> prior to a tenant (or a tenant's administrator) flagging a problem. For example, analysis results <b>322</b> might indicate that a particular update pushed by a tenant has caused a change in its users' behaviors&#x2014;something that may have gone unnoticed by the administrator. In the illustrated embodiment, dashboard <b>324</b> also provides a way for a tenant to provide feedback to monitoring system <b>10</b> by, for example, submitting user tickets <b>326</b>&#x2014;although, in other embodiment, feedback may be provided differently. This feedback may then be used by engine <b>320</b> to provide a bridge between tenant reported issues and identified production issues. For example, a user may phone an administrator of tenant and describe a problem including identifying when that problem was initially discovered. The administrator may then submit this information via a ticket <b>326</b>, which can be used by engine <b>320</b> to drill down on particular telemetry data <b>118</b> that appears to be relevant to the user's description e.g., the particular data <b>118</b> pertains to particular service flagged by the user as performing poorly, the data <b>118</b> was collected around the time when the problem was first identified, the data <b>118</b> relates to one or more resources <b>114</b> being used by the service, etc. Engine <b>320</b> may then compare this particular data <b>118</b> against data <b>118</b> from other users or other tenants. Engine <b>320</b> may then present a result <b>322</b> that identifies interesting information about the user's situation such as that the user's graphics driver was updated last Friday and there is one other user who has the same graphics driver and had similar problems before. In some embodiments, the fact that a tenant reported issue (e.g., via a ticket <b>326</b>) can help to train a machine learning algorithm used by engine <b>320</b>. In addition to troubleshooting, results <b>322</b> provided by dashboard <b>324</b> may also be used for forecasting, forward planning, obtaining broader insights, etc.</p><p id="p-0037" num="0036">On example of an analysis will now be discussed next.</p><p id="p-0038" num="0037">Turning now to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a block diagram of analysis <b>400</b> of telemetry data <b>118</b> is depicted. As noted above, various sets of received telemetry data <b>118</b> may be organized by tenant and correlated based on the occurrences of events over time. For example, in the illustrated embodiment, data <b>118</b> is organized into a multi-dimensional array <b>410</b> where one of the dimensions is time intervals <b>412</b>.</p><p id="p-0039" num="0038">Although arrays <b>410</b> may include any suitable information, in the example depicted in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, array <b>410</b> includes service/business-relevant metrics, workload classification metrics, top SQL queries, error log summaries, event summaries, database engine metric summaries, network summaries, operating system configuration summaries, long lived events, etc. Service/business-relevant metrics may include various metrics indicative of a tenant's experience such as the latencies that users experiencing when accessing resources <b>114</b>, the errors that users are receiving, the availability (or lack of availability) of resources <b>114</b>, etc. Workload classification metrics may include metrics indicative of an amount of work load that a tenant is placing on resources <b>114</b> over time such as how many database insertions and deletions a tenant is performing with respect to a database resource, how much a tenant is using a particular resource <b>114</b> (as opposed to another resource <b>114</b>), etc. Top SQL queries may include the most frequently executed database queries run by a tenant using a database resource. Error log summary may include metrics such as numbers of server messages, warnings, etc. within a given interval <b>412</b>, rarities of errors, etc. Event log summary may include metrics such as identified rare events, rates at which particular events occurred, I/O rates, packet loss, TCP retransmissions, etc. Operating system configuration summary may include metrics identifying current configuration settings, what changes were made to settings during an interval <b>412</b>, etc. Long lived events may include events that occur over multiple intervals <b>412</b> such as brining up a new host server <b>110</b>.</p><p id="p-0040" num="0039">As this various telemetry data <b>118</b> is analyzed, analysis engine <b>320</b> may determine that various metrics have anomalies <b>422</b>, which may be indicative of an underlying problem. For example, engine <b>320</b> may identify some metrics indicative of the users of a tenant not having a great experience during a particular interval <b>412</b> such as users experiencing high latencies. During the same interval <b>412</b>, engine <b>320</b> may notice a spike in system workloads and that the top SQL statements being run changed dramatically. Engine <b>320</b> may also notice that some rare errors and atypical events have occurred. Engine <b>320</b> may also determine that a long lived event that routinely occurs has not gone well. An administrator may also submit a ticket <b>326</b> indicating that the tenant's users were having issues during a particular interval <b>412</b>. Being able to look at this information in aggregate, engine <b>320</b> may identify a signature <b>420</b> from these anomalies <b>422</b> that is indicative of a particular problem. Analytics engine <b>320</b> may then present its analysis results <b>322</b> via dashboard <b>324</b>.</p><p id="p-0041" num="0040">In the illustrated embodiment, telemetry data <b>118</b> for one tenant may be stacked based on time interval with telemetry data <b>118</b> from other tenants. If analysis engine <b>320</b> noticed similar anomalies <b>422</b> occurring in data <b>118</b> for another tenant during the interval, engine <b>320</b> may identify a similar problem signature and raise it to the attention of the other tenant via dashboard <b>324</b>. In some instances, this may allow the administrator to diagnose and fix a problem prior to the administrator receiving complaints from any of the tenant's users, for example. Analysis engine <b>320</b> may also be able indicate, via dashboard <b>324</b>, to another tenant what the signature <b>420</b> has traditionally meant and how to account for this problem.</p><p id="p-0042" num="0041">Turning now to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a flowchart of a method <b>500</b> is shown. Method <b>500</b> is one embodiment of a method performed by a computing system such as monitoring system <b>10</b>. In many instances, performance method <b>500</b> may allow for greater insight into a distributed computing system with multiple tenants.</p><p id="p-0043" num="0042">Method <b>500</b> begins, in step <b>505</b>, with maintaining a computer cluster (e.g., distributed computing system <b>100</b>) that hosts containers (e.g., containers <b>112</b>) accessible to a plurality of tenants of the computer cluster. In step <b>510</b>, first telemetry data (e.g., telemetry data <b>118</b>) collected about a particular one (e.g., tenant B) of the plurality of tenants is received from a container hosted at a first (e.g., host server <b>110</b>A) of a plurality of servers of the computer cluster. In various embodiments, the first telemetry data identifies the particular tenant's consumption of a resource (e.g., resource <b>114</b>) provided by the container. In step <b>515</b>, in response to the computer cluster migrating the container from the first server to a second (e.g., host server <b>110</b>B) of the plurality of servers, second telemetry data collected about the particular tenant's consumption of the resource is received from the migrated container hosted at the second server. In step <b>520</b>, analysis of the first and second telemetry data is performed to identify whether the particular tenant's consumption of the resource has changed.</p><heading id="h-0006" level="2">Exemplary Computer System</heading><p id="p-0044" num="0043">Turning now to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a block diagram of an exemplary computer system <b>600</b>, which may be used to implement one or more components monitoring system <b>10</b> (such as clients <b>20</b>, servers <b>110</b>, database <b>130</b>, etc.) is depicted. Computer system <b>600</b> includes a processor subsystem <b>680</b> that is coupled to a system memory <b>620</b> and I/O interfaces(s) <b>640</b> via an interconnect <b>660</b> (e.g., a system bus). I/O interface(s) <b>640</b> is coupled to one or more I/O devices <b>650</b>. Computer system <b>600</b> may be any of various types of devices, including, but not limited to, a server system, personal computer system, desktop computer, laptop or notebook computer, mainframe computer system, tablet computer, handheld computer, workstation, network computer, a consumer device such as a mobile phone, music player, or personal data assistant (PDA). Although a single computer system <b>600</b> is shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> for convenience, system <b>600</b> may also be implemented as two or more computer systems operating together.</p><p id="p-0045" num="0044">Processor subsystem <b>680</b> may include one or more processors or processing units. In various embodiments of computer system <b>600</b>, multiple instances of processor subsystem <b>680</b> may be coupled to interconnect <b>660</b>. In various embodiments, processor subsystem <b>680</b> (or each processor unit within <b>680</b>) may contain a cache or other form of on-board memory.</p><p id="p-0046" num="0045">System memory <b>620</b> is usable store program instructions executable by processor subsystem <b>680</b> to cause system <b>600</b> perform various operations described herein. System memory <b>620</b> may be implemented using different physical memory media, such as hard disk storage, floppy disk storage, removable disk storage, flash memory, random access memory (RAM&#x2014;SRAM, EDO RAM, SDRAM, DDR SDRAM, RAMBUS RAM, etc.), read only memory (PROM, EEPROM, etc.), and so on. Memory in computer system <b>600</b> is not limited to primary storage such as memory <b>620</b>. Rather, computer system <b>600</b> may also include other forms of storage such as cache memory in processor subsystem <b>680</b> and secondary storage on I/O Devices <b>650</b> (e.g., a hard drive, storage array, etc.). In some embodiments, these other forms of storage may also store program instructions executable by processor subsystem <b>680</b>. In some embodiments, memory <b>920</b> may containers <b>112</b>, curation and analytics unit <b>120</b>, and/or database <b>130</b>.</p><p id="p-0047" num="0046">I/O interfaces <b>640</b> may be any of various types of interfaces configured to couple to and communicate with other devices, according to various embodiments. In one embodiment, I/O interface <b>640</b> is a bridge chip (e.g., Southbridge) from a front-side to one or more back-side buses. I/O interfaces <b>640</b> may be coupled to one or more I/O devices <b>650</b> via one or more corresponding buses or other interfaces. Examples of I/O devices <b>650</b> include storage devices (hard drive, optical drive, removable flash drive, storage array, SAN, or their associated controller), network interface devices (e.g., to a local or wide-area network), or other devices (e.g., graphics, user interface devices, etc.). In one embodiment, computer system <b>600</b> is coupled to a network via a network interface device <b>650</b> (e.g., configured to communicate over WiFi, Bluetooth, Ethernet, etc.).</p><p id="p-0048" num="0047">Although specific embodiments have been described above, these embodiments are not intended to limit the scope of the present disclosure, even where only a single embodiment is described with respect to a particular feature. Examples of features provided in the disclosure are intended to be illustrative rather than restrictive unless stated otherwise. The above description is intended to cover such alternatives, modifications, and equivalents as would be apparent to a person skilled in the art having the benefit of this disclosure.</p><p id="p-0049" num="0048">The scope of the present disclosure includes any feature or combination of features disclosed herein (either explicitly or implicitly), or any generalization thereof, whether or not it mitigates any or all of the problems addressed herein. Accordingly, new claims may be formulated during prosecution of this application (or an application claiming priority thereto) to any such combination of features. In particular, with reference to the appended claims, features from dependent claims may be combined with those of the independent claims and features from respective independent claims may be combined in any appropriate manner and not merely in the specific combinations enumerated in the appended claims.</p><p id="p-0050" num="0049">The present disclosure includes references to &#x201c;an embodiment&#x201d; or groups of &#x201c;embodiments&#x201d; (e.g., &#x201c;some embodiments&#x201d; or &#x201c;various embodiments&#x201d;). Embodiments are different implementations or instances of the disclosed concepts. References to &#x201c;an embodiment,&#x201d; &#x201c;one embodiment,&#x201d; &#x201c;a particular embodiment,&#x201d; and the like do not necessarily refer to the same embodiment. A large number of possible embodiments are contemplated, including those specifically disclosed, as well as modifications or alternatives that fall within the spirit or scope of the disclosure.</p><p id="p-0051" num="0050">This disclosure may discuss potential advantages that may arise from the disclosed embodiments. Not all implementations of these embodiments will necessarily manifest any or all of the potential advantages. Whether an advantage is realized for a particular implementation depends on many factors, some of which are outside the scope of this disclosure. In fact, there are a number of reasons why an implementation that falls within the scope of the claims might not exhibit some or all of any disclosed advantages. For example, a particular implementation might include other circuitry outside the scope of the disclosure that, in conjunction with one of the disclosed embodiments, negates or diminishes one or more the disclosed advantages. Furthermore, suboptimal design execution of a particular implementation (e.g., implementation techniques or tools) could also negate or diminish disclosed advantages. Even assuming a skilled implementation, realization of advantages may still depend upon other factors such as the environmental circumstances in which the implementation is deployed. For example, inputs supplied to a particular implementation may prevent one or more problems addressed in this disclosure from arising on a particular occasion, with the result that the benefit of its solution may not be realized. Given the existence of possible factors external to this disclosure, it is expressly intended that any potential advantages described herein are not to be construed as claim limitations that must be met to demonstrate infringement. Rather, identification of such potential advantages is intended to illustrate the type(s) of improvement available to designers having the benefit of this disclosure. That such advantages are described permissively (e.g., stating that a particular advantage &#x201c;may arise&#x201d;) is not intended to convey doubt about whether such advantages can in fact be realized, but rather to recognize the technical reality that realization of such advantages often depends on additional factors.</p><p id="p-0052" num="0051">Unless stated otherwise, embodiments are non-limiting. That is, the disclosed embodiments are not intended to limit the scope of claims that are drafted based on this disclosure, even where only a single example is described with respect to a particular feature. The disclosed embodiments are intended to be illustrative rather than restrictive, absent any statements in the disclosure to the contrary. The application is thus intended to permit claims covering disclosed embodiments, as well as such alternatives, modifications, and equivalents that would be apparent to a person skilled in the art having the benefit of this disclosure.</p><p id="p-0053" num="0052">For example, features in this application may be combined in any suitable manner. Accordingly, new claims may be formulated during prosecution of this application (or an application claiming priority thereto) to any such combination of features. In particular, with reference to the appended claims, features from dependent claims may be combined with those of other dependent claims where appropriate, including claims that depend from other independent claims. Similarly, features from respective independent claims may be combined where appropriate.</p><p id="p-0054" num="0053">Accordingly, while the appended dependent claims may be drafted such that each depends on a single other claim, additional dependencies are also contemplated. Any combinations of features in the dependent that are consistent with this disclosure are contemplated and may be claimed in this or another application. In short, combinations are not limited to those specifically enumerated in the appended claims.</p><p id="p-0055" num="0054">Where appropriate, it is also contemplated that claims drafted in one format or statutory type (e.g., apparatus) are intended to support corresponding claims of another format or statutory type (e.g., method).</p><p id="p-0056" num="0055">Because this disclosure is a legal document, various terms and phrases may be subject to administrative and judicial interpretation. Public notice is hereby given that the following paragraphs, as well as definitions provided throughout the disclosure, are to be used in determining how to interpret claims that are drafted based on this disclosure.</p><p id="p-0057" num="0056">References to a singular form of an item (i.e., a noun or noun phrase preceded by &#x201c;a,&#x201d; &#x201c;an,&#x201d; or &#x201c;the&#x201d;) are, unless context clearly dictates otherwise, intended to mean &#x201c;one or more.&#x201d; Reference to &#x201c;an item&#x201d; in a claim thus does not, without accompanying context, preclude additional instances of the item. A &#x201c;plurality&#x201d; of items refers to a set of two or more of the items.</p><p id="p-0058" num="0057">The word &#x201c;may&#x201d; is used herein in a permissive sense (i.e., having the potential to, being able to) and not in a mandatory sense (i.e., must).</p><p id="p-0059" num="0058">The terms &#x201c;comprising&#x201d; and &#x201c;including,&#x201d; and forms thereof, are open-ended and mean &#x201c;including, but not limited to.&#x201d;</p><p id="p-0060" num="0059">When the term &#x201c;or&#x201d; is used in this disclosure with respect to a list of options, it will generally be understood to be used in the inclusive sense unless the context provides otherwise. Thus, a recitation of &#x201c;x or y&#x201d; is equivalent to &#x201c;x or y, or both,&#x201d; and thus covers 1) x but not y, 2) y but not x, and 3) both x and y. On the other hand, a phrase such as &#x201c;either x or y, but not both&#x201d; makes clear that &#x201c;or&#x201d; is being used in the exclusive sense.</p><p id="p-0061" num="0060">A recitation of &#x201c;w, x, y, or z, or any combination thereof&#x201d; or &#x201c;at least one of . . . w, x, y, and z&#x201d; is intended to cover all possibilities involving a single element up to the total number of elements in the set. For example, given the set [w, x, y, z], these phrasings cover any single element of the set (e.g., w but not x, y, or z), any two elements (e.g., w and x, but not y or z), any three elements (e.g., w, x, and y, but not z), and all four elements. The phrase &#x201c;at least one of . . . w, x, y, and z&#x201d; thus refers to at least one element of the set [w, x, y, z], thereby covering all possible combinations in this list of elements. This phrase is not to be interpreted to require that there is at least one instance of w, at least one instance of x, at least one instance of y, and at least one instance of z.</p><p id="p-0062" num="0061">Various &#x201c;labels&#x201d; may precede nouns or noun phrases in this disclosure. Unless context provides otherwise, different labels used for a feature (e.g., &#x201c;first circuit,&#x201d; &#x201c;second circuit,&#x201d; &#x201c;particular circuit,&#x201d; &#x201c;given circuit,&#x201d; etc.) refer to different instances of the feature. Additionally, the labels &#x201c;first,&#x201d; &#x201c;second,&#x201d; and &#x201c;third&#x201d; when applied to a feature do not imply any type of ordering (e.g., spatial, temporal, logical, etc.), unless stated otherwise.</p><p id="p-0063" num="0062">The phrase &#x201c;based on&#x201d; or is used to describe one or more factors that affect a determination. This term does not foreclose the possibility that additional factors may affect the determination. That is, a determination may be solely based on specified factors or based on the specified factors as well as other, unspecified factors. Consider the phrase &#x201c;determine A based on B.&#x201d; This phrase specifies that B is a factor that is used to determine A or that affects the determination of A. This phrase does not foreclose that the determination of A may also be based on some other factor, such as C. This phrase is also intended to cover an embodiment in which A is determined based solely on B. As used herein, the phrase &#x201c;based on&#x201d; is synonymous with the phrase &#x201c;based at least in part on.&#x201d;</p><p id="p-0064" num="0063">The phrases &#x201c;in response to&#x201d; and &#x201c;responsive to&#x201d; describe one or more factors that trigger an effect. This phrase does not foreclose the possibility that additional factors may affect or otherwise trigger the effect, either jointly with the specified factors or independent from the specified factors. That is, an effect may be solely in response to those factors, or may be in response to the specified factors as well as other, unspecified factors. Consider the phrase &#x201c;perform A in response to B.&#x201d; This phrase specifies that B is a factor that triggers the performance of A, or that triggers a particular result for A. This phrase does not foreclose that performing A may also be in response to some other factor, such as C. This phrase also does not foreclose that performing A may be jointly in response to B and C. This phrase is also intended to cover an embodiment in which A is performed solely in response to B. As used herein, the phrase &#x201c;responsive to&#x201d; is synonymous with the phrase &#x201c;responsive at least in part to.&#x201d; Similarly, the phrase &#x201c;in response to&#x201d; is synonymous with the phrase &#x201c;at least in part in response to.&#x201d;</p><p id="p-0065" num="0064">Within this disclosure, different entities (which may variously be referred to as &#x201c;units,&#x201d; &#x201c;circuits,&#x201d; other components, etc.) may be described or claimed as &#x201c;configured&#x201d; to perform one or more tasks or operations. This formulation&#x2014;[entity] configured to [perform one or more tasks]&#x2014;is used herein to refer to structure (i.e., something physical). More specifically, this formulation is used to indicate that this structure is arranged to perform the one or more tasks during operation. A structure can be said to be &#x201c;configured to&#x201d; perform some task even if the structure is not currently being operated. Thus, an entity described or recited as being &#x201c;configured to&#x201d; perform some task refers to something physical, such as a device, circuit, a system having a processor unit and a memory storing program instructions executable to implement the task, etc. This phrase is not used herein to refer to something intangible.</p><p id="p-0066" num="0065">In some cases, various units/circuits/components may be described herein as performing a set of task or operations. It is understood that those entities are &#x201c;configured to&#x201d; perform those tasks/operations, even if not specifically noted.</p><p id="p-0067" num="0066">The term &#x201c;configured to&#x201d; is not intended to mean &#x201c;configurable to.&#x201d; An unprogrammed FPGA, for example, would not be considered to be &#x201c;configured to&#x201d; perform a particular function. This unprogrammed FPGA may be &#x201c;configurable to&#x201d; perform that function, however. After appropriate programming, the FPGA may then be said to be &#x201c;configured to&#x201d; perform the particular function.</p><p id="p-0068" num="0067">For purposes of United States patent applications based on this disclosure, reciting in a claim that a structure is &#x201c;configured to&#x201d; perform one or more tasks is expressly intended not to invoke 35 U.S.C. &#xa7; 112(f) for that claim element. Should Applicant wish to invoke Section 112(f) during prosecution of a United States patent application based on this disclosure, it will recite claim elements using the &#x201c;means for&#x201d; [performing a function] construct.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A non-transitory computer readable medium having program instructions stored thereon that are capable of causing a computing system to implement operations comprising:<claim-text>maintaining a computer cluster that hosts containers accessible to a plurality of tenants of the computer cluster;</claim-text><claim-text>receiving, from a container hosted at a first of a plurality of servers of the computer cluster, first telemetry data collected about a particular one of the plurality of tenants, wherein the first telemetry data identifies the particular tenant's consumption of a resource provided by the container;</claim-text><claim-text>in response to the computer cluster migrating the container from the first server to a second of the plurality of servers, receiving, from the migrated container hosted at the second server, second telemetry data collected about the particular tenant's consumption of the resource; and</claim-text><claim-text>performing analysis of the first and second telemetry data to identify whether the particular tenant's consumption of the resource has changed.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the resource is an application executing within the container; and<claim-text>wherein the first and second telemetry includes usage metrics for a plurality of users of the particular tenant that interact with the application.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer readable medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the usage metrics includes a time value indicative of how long a user has used the application and a frequency value indicative of how frequently a user has used the application.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer readable medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein receiving the first telemetry data includes:<claim-text>a monitoring agent within the container reading a log produced by the application; and</claim-text><claim-text>receiving, from the monitoring agent, first telemetry data that includes information read from the log.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the resource is a hardware component of the first and second servers; and<claim-text>wherein the first and second telemetry data include utilizations of the hardware component by the particular tenant over time.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the operations further comprising:<claim-text>receiving telemetry data from a container manager that instantiates the container and determines to migrate the container from the first server to the second server; and</claim-text><claim-text>wherein the analysis is further based on the telemetry data from the container manager.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first and second telemetry data is tagged with a unique identifier of the particular tenant to indicate that the first and second telemetry data pertains to the particular tenant.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer readable medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the analysis includes:<claim-text>correlating telemetry data collected about the particular tenant by a plurality of sources, wherein the correlating is based on timing of events identified the correlated telemetry data; and</claim-text><claim-text>identifying a signature from ones of the events occurring with a same time interval, wherein the signature is indicative of a potential problem.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computer readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the operations comprising:<claim-text>presenting a notification of the potential problem to an administrator associated with the tenant via a user interface.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the analysis includes:<claim-text>correlating additional telemetry data collected about others of the plurality of tenants based on timing of events identified the additional correlated telemetry data; and</claim-text><claim-text>identifying the signature based on the events identified in the additional correlated telemetry data.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A method, comprising:<claim-text>instantiating, by a first host server of a computer cluster, a plurality of containers that provide resources used by a plurality of tenants of the computer cluster;</claim-text><claim-text>providing, by the first host server, first telemetry data collected from one or more of the containers associated with a particular one of the plurality of tenants, wherein the first telemetry data includes data about the particular tenant's use of one or more resources provided by the one or more containers; and</claim-text><claim-text>migrating, from the first host server to a second host server of the computer cluster, the one or more containers of the particular tenant, where the second host server is configured to provide second telemetry data about the particular tenant's use of the one or more resources for analysis.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the one or more resources include an application executing with one of the one or more containers; and<claim-text>wherein the first telemetry data includes data collected from a log produced by the application.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>collecting, by the first host server, hardware usage data identifying the one or more container's use of hardware resources of the first host server, wherein the hardware resources include processors and memory of the first host server; and</claim-text><claim-text>wherein the first telemetry data includes the hardware usage data.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>collecting telemetry data from a container manager that instantiated the plurality of containers; and</claim-text><claim-text>wherein the first telemetry data includes telemetry data collected from the container manager about the particular tenant.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>providing, by the first host server and to a computing system, telemetry data collected from the plurality of containers about the plurality of tenants' usage of resources provided by the containers; and</claim-text><claim-text>wherein the computing system is configured to identify a problem associated with the particular tenant by analyzing the first telemetry data, the second telemetry data, telemetry data collected about others of the plurality of tenants.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A non-transitory computer readable medium having program instructions stored thereon that are capable of causing a first server of a computer cluster to implement operations comprising:<claim-text>receiving containers migrated from other servers of the computer cluster, wherein the containers include one or more containers associated with a particular one of a plurality of tenants;</claim-text><claim-text>hosting the one or more containers along with containers associated with others of the plurality of tenants; and</claim-text><claim-text>reporting, to a computing system, telemetry data collected about the particular tenant's usage of one or more resources provided by the hosted one or more containers, wherein the reported telemetry data is usable in an analysis performed by the computing system to discern an alteration of the particular tenant's usage of the one or more resources.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The computer readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the one or more resources include a network interface used by a client device of the particular tenant to communicate with an application included in one of the hosted one or more containers; and<claim-text>wherein the reported telemetry data includes a latency value identifying a latency for communicating between the application and the client device via the network interface.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The computer readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the one or more resources include processors of the first server execute program instructions included in the one or more containers; and<claim-text>wherein the reported telemetry data include a current usage of the processors by the one or more containers associated with the particular tenant.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computer readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the one or more resources include data set included in one of the hosted one or more containers and accessed by an application executing on the first server; and<claim-text>wherein the reported telemetry data includes a size of the data set.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computer readable medium of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the reporting includes:<claim-text>tagging the telemetry data with a unique identifier of the particular tenant to enable the computing system differentiate between the telemetry data collected about the particular tenant's usage and telemetry data collected about others of the plurality of tenants.</claim-text></claim-text></claim></claims></us-patent-application>
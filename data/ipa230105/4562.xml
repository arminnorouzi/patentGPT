<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004563A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004563</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17882782</doc-number><date>20220808</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>2453</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>41</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>24549</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>4442</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>24542</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>24537</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHOD AND SYSTEM FOR PROVIDING A CONTEXT-SENSITIVE, NON-INTRUSIVE DATA PROCESSING OPTIMIZATION FRAMEWORK</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/CN2021/103461</doc-number><date>20210630</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17882782</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>HUAWEI TECHNOLOGIES CO., LTD.</orgname><address><city>Shenzhen</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>ZHANG</last-name><first-name>Zanqing</first-name><address><city>Toronto</city><country>CA</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>HUDZIA</last-name><first-name>Benoit</first-name><address><city>Dublin</city><country>IE</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>DING</last-name><first-name>Arven</first-name><address><city>Toronto</city><country>CA</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>YANG</last-name><first-name>Guo</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>LI</last-name><first-name>Zheng</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>ZHANG</last-name><first-name>Jingfang</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>LIU</last-name><first-name>Songling</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>LIAO</last-name><first-name>Denghong</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method of performing a data search in a data source by which an operator of a data search pipeline is just-in-time optimized and compiled, using an operator optimization module which optimizes and compiles an intermediate representation of the operator, considering runtime information, and optimization rules, to produce an operator that is optimized for the data search being performed. The method can be applied with one operator or with many operators applied in any sequence or tree structure according to a query plan, as determined by runtime information and optimization rules.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="113.03mm" wi="149.78mm" file="US20230004563A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="156.04mm" wi="116.59mm" orientation="landscape" file="US20230004563A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="153.59mm" wi="110.91mm" orientation="landscape" file="US20230004563A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="151.81mm" wi="123.44mm" orientation="landscape" file="US20230004563A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="154.43mm" wi="110.15mm" orientation="landscape" file="US20230004563A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="156.29mm" wi="117.26mm" orientation="landscape" file="US20230004563A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="156.21mm" wi="118.11mm" orientation="landscape" file="US20230004563A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="160.61mm" wi="121.58mm" orientation="landscape" file="US20230004563A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="157.23mm" wi="115.99mm" orientation="landscape" file="US20230004563A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="134.20mm" wi="124.63mm" orientation="landscape" file="US20230004563A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of Patent Cooperation Treaty Application No. PCT/CN2021/103461 filed on Jun. 30, 2021, the content of which is hereby incorporated by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">This invention pertains generally to the field of retrieving and processing information from a data source and in particular, to methods of retrieving information by using operators that are optimized and compiled based on the executed data search.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">As massive amounts of data become increasingly available, there is an increasing need for optimizing and speeding up data searches and access. Modern database systems can achieve efficient query processing by using cache-efficient algorithms and data structures, but to further improve query processing, by for example preventing as much as possible branch mispredictions and cache misses, database operators need to be highly tuned for CPU efficiency, which can be achieved by translating database queries to optimized machine code.</p><p id="p-0005" num="0004">To cope with a data source organized as a number of columns of different types, any of which might have to be processed at runtime, the data processing pipeline of a modem database system has to rely on generic logic. In order to manage the spectrum of datasets to be processed, this can often result in a number of for-loops, nested with branches.</p><p id="p-0006" num="0005">Typically, in order to maximize the performance of a search execution and to leverage the target machine optimization, a compiler pass can be applied to optimize a code base. With data processing logic typically written either in a programming language or SQL (structured query language), the compiler pass essentially acts as an interpreter of the code base.</p><p id="p-0007" num="0006">Existing approaches generate code based on a submitted data processing logic (i.e. SQL statements), but once the data processing logic is submitted, most of the variable aspect of the processing flow such as the data types, number of columns, and statistics, are fixed. Because the code used prior to optimization is generic, this can result in a high number of dead portions of code. There is a trade-off as the database architects must provide generic coding for flexibility, but they cannot develop highly specific code due to time and resource constraint.</p><p id="p-0008" num="0007">There is a need for methods and systems that can obviate or mitigate one or more limitations of the existing technique, by having operators in a data search pipeline optimized for each data search.</p><p id="p-0009" num="0008">This background information is provided to reveal information to be of possible relevance to the present disclosure. No admission is necessarily intended, nor should be construed, that any of the preceding information constitutes prior art against the present disclosure.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0010" num="0009">In some examples of the present disclosure, operators of a data search pipeline can be prepared by developers and be compiled into intermediate representation (IR) code, before a data search is called for. Upon execution of a data search, parameters of the data query, and of the data query processing engine, along with optimization rules, can be used to optimize the IR coded operators for the data query being performed, and compile them for the query processing engine hardware being used. Furthermore, to facilitate optimization, functions of the operator file that is to be optimized can be annotated or tagged.</p><p id="p-0011" num="0010">In embodiments, a data search includes runtime optimization and compilation of the pipeline operators, and it can be performed in less time than a data search would take with operators that are not optimized and compiled at runtime. In other words, because runtime optimization and compilation workflows according to embodiments can be performed quickly enough, a data search making use of such runtime optimization and compilation, and making use of the resulting optimized operators, can take less time than a data search would take, if it were performed with pre-compiled operators that are not optimized and compiled for the data search.</p><p id="p-0012" num="0011">In embodiments, an operator can be configured with a high level programming language, and be compiled into an intermediate representation (IR) version. Annotations can be used to tag functions which are to be specialized when the operator will be optimized and compiled for the data search at runtime. Optimization of an operator can make use of runtime information and optimization rules. When a data search is executed, an operator required by the data search can be optimized, compiled, and then executed to complete the data search.</p><p id="p-0013" num="0012">A system to perform a data search according to an embodiment should be able to compile an IR coded operator using runtime information of the query processing engine performing the data search. The system and the query processing engine can be separate entities or be combined into one entity with common components.</p><p id="p-0014" num="0013">Examples of the present disclosure include a method of performing a data search, and the method obtains at least one operator, runtime information of the data search, optimization rules, and obtains at least one optimized and compiled operator by optimizing and compiling the at least one operator according to the runtime information of the data search and the optimization rules. Then the method performs the data search using the at least one optimized and compiled operator.</p><p id="p-0015" num="0014">In the above example, an operator can be configured in a high level programming language, and compiled by a front-end compiler into an intermediate representation code of the at least one operator.</p><p id="p-0016" num="0015">In any of the above examples, an operator can include annotations tagging functions which are to be specialized when the at least one operator is being optimized and compiled for the data search at runtime.</p><p id="p-0017" num="0016">In any of the above examples, the runtime information can include includes data layout.</p><p id="p-0018" num="0017">In any of the above examples, the runtime information can include data statistics.</p><p id="p-0019" num="0018">In any of the above examples, the runtime information can include hardware information of the query processing engine.</p><p id="p-0020" num="0019">In any of the above examples, the optimization rules can include global algorithms.</p><p id="p-0021" num="0020">In any of the above examples, the optimization rules can be based on the runtime information.</p><p id="p-0022" num="0021">In any of the above examples the optimization rules can include algorithms specific to the at least one operator.</p><p id="p-0023" num="0022">In any of the above examples, optimizing an operator can include an application of at least one optimization to the code of an operator that increases the efficiency of a data search executing that operator.</p><p id="p-0024" num="0023">In any of the above examples, optimizing an operator can be performed after a data search is called for, and before the data search is complete, such that performing the data search includes executing at least one optimized operator.</p><p id="p-0025" num="0024">In any of the above examples, performing a data search can include optimizing and compiling many operators, which can subsequently be executed by the data search according to a query plan defined by the optimization and compilation.</p><p id="p-0026" num="0025">Some examples of the present disclosure include a system for performing a data search. The system comprises at least one processor, at least one storage medium for data, a query processing engine, a compiler, and at least one operator file configured with a programming language; wherein upon executing the query processing engine, the compiler is operative to obtain at least one optimized and compiled operator file by optimizing and compiling the at least one operator file according to the runtime information of the data search, and according to optimization rules; and wherein performing the data search includes executing the at least one optimized and compiled operator file.</p><p id="p-0027" num="0026">In the above example, prior to being optimized and executed by the query processing engine, the at least one operator file can be configured with a high level programming language and be compiled into intermediate representation code.</p><p id="p-0028" num="0027">In any of the above examples, a system can further include an operator specialization module that is operative to receive at least one operator file, as well as the runtime information from the query processing engine; and to have at least one operator file optimized and compiled based on runtime information.</p><p id="p-0029" num="0028">In any of the above examples, an operator file can be configured with a high level programming language and be compiled into an intermediate representation code.</p><p id="p-0030" num="0029">In any of the above examples, an operator file can include annotations tagging functions that are to be specialized when the operator coded, within the operator file is being optimized and compiled for the data search at runtime.</p><p id="p-0031" num="0030">In any of the above examples, the runtime information can include data layout.</p><p id="p-0032" num="0031">In any of the above examples, the runtime information can include data statistics.</p><p id="p-0033" num="0032">In any of the above examples, the runtime information can include hardware information.</p><p id="p-0034" num="0033">A computer program can include instructions which can, when the program is executed by a computer, cause the computer to carry out the above-mentioned methods.</p><p id="p-0035" num="0034">A computer-readable medium can include instructions which can, when executed by a computer, cause the computer to carry out the above-mentioned methods.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a data search processing pipeline, according to prior art.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> is a block diagram illustrating the compilation of a high-level coded operator into a compiled operator, according to prior art.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> is a block diagram illustrating the compilation of a high-level coded operator into a compiled operator, according to an embodiment of the present disclosure.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a process by which an operator can be specialized for a query, according to an embodiment of the present disclosure.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is block diagram illustrating of a process by which an operator can be specialized for a query, according to an embodiment of the present disclosure.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>5</b>A</figref> is a block diagram illustrating a method for producing an optimized operator, according to an embodiment of the present disclosure.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>5</b>B</figref> is a block diagram illustrating data search processing pipeline and where an optimized operator can be used within, according to an embodiment of the present disclosure.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating a pre-compiling flow and runtime specialization flow for producing an optimized operator, in accordance with embodiments of the present disclosure.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating a method may be involved in the preparation of operators to be used when a query is performed, according to an embodiment of the present disclosure.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram of an electronic device within a computing and communications environment that may be used for implementing devices and methods in accordance with representative embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0046" num="0045">Throughout the appended drawings, like features are identified by like reference numerals.</p><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0047" num="0046">Modern analytics applications, such as data search and data processing software, can combine multiple functions from different libraries and frameworks to build increasingly complex workflows. In the case of a data search application, functions can be organized as &#x201c;operators&#x201d;, which can be organized in a sequence, tree or more generally a query plan. Even though each function or operator may achieve high performance in isolation, the performance of the combined workflow is often an order of magnitude below hardware limits. Basically, this is due to a lack of hardware-specific support, lack of specialized operators for data operations, and the high cost of data transfer. To address the above-mentioned problem, embodiments include a framework for data-intensive applications, which can provide multi-level, just-in-time acceleration, optimization and compilation so as to support dynamic user defined functionality.</p><p id="p-0048" num="0047">An embodiment can be adaptive, flexible, and extensible. Moreover, it can be integrated incrementally into an existing framework, such as openLooKeng, Apache Spark, and others, without requiring the front-end application programming interface (API) of the existing framework to be modified. Embodiments have the capability to enable just-in-time code compilation, using runtime information, as well as out-of-band information.</p><p id="p-0049" num="0048">For a data search to retrieve data more efficiently, code generation with query specific information can be used. For example, code generation can allow a user to remove conditionals, to propagate constant offsets, pointers, etc., and to use inline virtual functions calls.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a data search processing pipeline, according to existing solutions. For a given data source <b>105</b>, a data search can activate a pipeline <b>110</b> of operations, each of which processes the data into a new form, until the requested data is produced. For example, a first operation can be reading <b>115</b> the data, a second operation can be filtering <b>120</b>, a third operation can be projecting <b>125</b>, a fourth operation can be aggregating <b>130</b>, and a final operation can be shuffling <b>135</b>. Each operation can be seen as a step towards presenting the requested data <b>140</b> from an original set of data <b>145</b> of the data source <b>105</b>. In some cases, code generation <b>150</b> can allow a user to remove conditionals, to propagate constant offsets, pointers, etc., and to use inline virtual functions calls.</p><p id="p-0051" num="0050">One approach is to allow code generation that leverages a specific data processing job. This can require much fewer branches, less instructions, and allow faster execution. However, for such specific code generation, the leveraging of expert domain knowledge often turns out to be complex, error-prone, and extremely difficult to debug. Thereafter, it could become very difficult in practice to maintain and extend such query compilers over time, because the complexity of a query compiler's codebase can increase to unmanageable levels as more and more optimizations are added.</p><p id="p-0052" num="0051">Embodiments include an architecture framework making query optimizers and compilers easier to build and to extend, ultimately allowing a programmer to create more sustainable compiler-based data management systems, and to dynamically define and tailor the processing of big data. This framework can improve data retrieval performance and hardware utilization, which wouldn't be possible with existing solutions.</p><p id="p-0053" num="0052">Embodiments include a modular query compiler that can be described using several abstraction levels. Each abstraction level can be responsible for expressing a subset of optimizations. This allows a separation of concerns between the different kinds of code optimizations. Further, through multiple levels of abstraction, an embodiment can allow a high-level query to progressively turn into low-level code, allowing for a more controlled approach to code generation.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> illustrates the compilation of a high-level coded operator into a compiled operator, according to existing solutions. A high-level (HL) language, such as SQL <b>205</b>, can be used to create operator code <b>210</b> that is generic, such that a compiled operator <b>212</b> can be similar for any query. Neither the initial operator code <b>210</b>, nor the compiled operator <b>212</b> is dependent on the search. Although <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> can represent a compilation of a single operator, in practice, a SQL query can generate a sequence of operators for performing retrieval, filtering, transformation, and perhaps other operations. For example, if a query is to identify from database employees whose ages are less than 25 years old, three operations and corresponding operators may be necessary: i. retrieving data from a database; ii. filtering the data by age; iii. filtering names from the output of the previous operation.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates the compilation of a high-level coded operator into a compiled operator, according to an embodiment of the present disclosure. The SQL language <b>205</b> or another high level (HL) code can be used to write an operator code <b>210</b>. However, the embodiment involves optimizing an operator for a given input data query and therefore, before fully compiling the operator code <b>215</b>, the information <b>220</b> including data type, statistics of data being queried, and SQL parameters can be received by an operator optimizer module <b>225</b>, and be applied to the operator code <b>210</b> so as to optimize the operator for the input data query.</p><p id="p-0056" num="0055">In an embodiment, an approach can be to leverage just-in-time compilation, such that an operator is optimized and compiled during query execution, in order to produce a result more quickly than if the operator was generic or not optimized. Optimization steps can include devising a query plan describing a flow of operations to be applied by operators to a data source, selecting algorithms for the operators, generating specialized operators, and optionally, a user can define how and when to apply the operators in the query plan (i.e. inject the operators). At this point, the database management system performing the query can execute the query plan using the injected optimized operators. Furthermore, to optimize an operator, an embodiment can leverage runtime information.</p><p id="p-0057" num="0056">To select an operation algorithm, an embodiment can optimize a combination of operators, data structures, access patterns, and the parallelism of operations. To select a proper approach, an embodiment can take in account various inputs, including information from the data engine processing a data query, or from the data search, such as data types, statistical information, and SQL parameters. For example, in an operator algorithm, the use of certain data types can allow the selection of certain hash algorithms (i.e. probed operators). This can be more efficient than using classical filtering that requires reading of individual rows. Furthermore, an embodiment can use statistical information to select a level of parallelism and an operator fusion mechanism.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a process by which an operator can be specialized for a query, according to an embodiment of the present disclosure. At any time before a data search, an operator, for operating on data <b>302</b> in database, can be written in high-level (HL) code such as C, C++, Rust or another high-level code as a high-level coded operator <b>305</b>. It can then be compiled into intermediate representation (IR) code in a template file referred to as a template or an operator.tpl file containing the IR coded operator <b>310</b>, where the &#x201c;.tpl&#x201d; extension refers to a template file type. As IR code, the operator can be received <b>312</b> at an operator specialization module <b>315</b>. When a query processing engine <b>320</b> executes a data search <b>360</b>, it can also trigger the execution of an operator specialization <b>345</b>, where the operator specialization module <b>315</b> can further take into consideration of metadata from the data search <b>360</b>, and from the query processing engine <b>320</b> (e.g. a big data engine), which can be an SQL (structured query language) engine <b>320</b> processing <b>325</b> a data query. The metadata can include parameters of the query processing engine (i.e. &#x201c;params&#x201d;, or system information) <b>330</b>, data statistics <b>335</b> i.e. statistical information about the data or data search, and data layout <b>340</b> of the data or data search. The IR coded operator <b>310</b> in the optimizer specialization module <b>315</b> can then be optimized for the data engine <b>320</b> and data search360, through an application programming interface (API) implementing just-in-time (JIT) compilation and optimization, thereby customizing (i.e. &#x201c;specializing&#x201d;) the operator for the query. This can be referred to as JIT API specialization <b>350</b>. The result can be a shared, in-memory operator file (i.e. operator.so), specialized for the query, which can be produced before the data search is completed, in order to improve the efficiency of the data search. The resulting operator.so file, which includes the optimized operator <b>355</b>, can be placed in the data search pipeline <b>365</b> as a specialized operator among other operators <b>368</b>, which can make the data processing pipeline execute faster than if the operator was not specialized. A data processing pipeline can include many operators <b>368</b> in sequence, as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, or in various other tree structures (not shown) allowing to produce a final result <b>370</b>. An optimized operator file <b>355</b> can also be shared and used as needed with other similar queries executed in parallel or in the future, and as such, it can be referred to as &#x201c;in-memory operator.so&#x201d; file <b>355</b>, where the &#x201c;.so&#x201d; extension refers to a shared object file type.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is another illustration of a process by which an operator can be specialized for a query, according to an embodiment of the present disclosure. Initially, an operator can be written in high-level (HL) code such as C++, Rust or another high-level code, and be referred to as an HL coded operator <b>305</b>, or more specifically a &#x201c;template.c&#x201d; file, a &#x201c;template.cpp&#x201d; file or a &#x201c;template.rs&#x201d; file. It can then be compiled <b>307</b> into intermediate representation (IR) code in a file referred to as a compiled template, containing IR coded operator <b>310</b>. These files are not created during a data search execution, but are rather prepared by a developer in anticipation of a data search, so as to be ready for further customization when a data search will be executed. In other words, a file containing an IR coded operator can be prepared at any time before a data search, and it is only when a data search will be executed that the IR coded operator of the file will be optimized and compiled for the data search execution. In some embodiments, the preparation <b>405</b> of an HL coded operator <b>305</b> into an IR coded operator <b>310</b> that is ready to be optimized for an anticipated queryso as to be utilized by an operator specialization module <b>315</b>. Embodiments include the preparation <b>405</b> of an IR coded operator <b>310</b> which can be further optimized, in combination with an optimization <b>350</b> of the IR coded operator <b>310</b> for a data search. Embodiments can include an operator specialization module <b>315</b> for optimizing an IR coded operator <b>310</b>. It should be appreciated that embodiments can be combined.</p><p id="p-0060" num="0059">Once an IR coded operator <b>310</b> is prepared <b>405</b> to be optimized, it can be received <b>312</b> by (i.e. loaded in) an operator specialization module <b>315</b>, which can optimize <b>350</b> the IR coded operator <b>310</b> into an operator that is optimized for a data query or data search using a given data engine, or in other words, an optimized operator <b>355</b>.</p><p id="p-0061" num="0060">In an embodiment, the optimization of an IR coded operator <b>310</b> can be performed in more than one step. One step can be to take into account metadata from the query and the query processing engine, i.e. the hardware involved in the search. This step can be referred to as &#x201c;hardening&#x201d; <b>410</b>, which is essentially optimizing the operator for the hardware of the query processing engine. Hardening involves crystallizing, defining, or giving more accurate values to certain variables of the IR coded operator <b>310</b> those were previously unknown. The metadata can include parameters <b>330</b> of the data search and query processing hardware being used, statistical data <b>335</b> of the data search, and data layouts <b>340</b> of the data search.</p><p id="p-0062" num="0061">If an IR code includes virtual function references to specific library functionalities, a compilation process can include the replacement of virtual function references with actual code from the library, and the hardening process can be applied after such replacement. The process of hardening <b>410</b> can be seen as an input <b>415</b> of metadata from a query, into an operator specialization module <b>315</b>.</p><p id="p-0063" num="0062">For implementing a data search according to embodiment in which an operator is especially adapted for the search itself, an embodiment can comprise two complementary work flows. One work flow can be performed during project build, at a time before a data search is executed and it can comprise the production of an operator template, created by a developer to be adaptable to certain data searches. A subsequent and complimentary method can be executed following a data search, but before its completion, and it can comprise optimizing an operator based on features of the data search itself. In another embodiment, this optimization based on a data search can be performed and completed within a short amount of time between the start of a data search execution, and the production of a result, such that the result is produced using the optimized operator.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>5</b>A</figref> illustrates a method to produce an optimized operator, according to an embodiment. A method can been seen as two work flows: a pre-compile work flow <b>505</b> and a runtime specialization work flow <b>510</b>. As an initial step, which can be performed at a time before the execution of a data search, a developer can create an operator in HL code such as C, C++, Rust or another HL code. The resulting file can be referred to as a HL coded operator <b>305</b>. Using an operator compiler <b>515</b> (e.g. Clang or another), which can in turn make use of a global compiler <b>520</b>, the HL coded operator <b>305</b> can be compiled into an IR coded operator <b>310</b>. In an embodiment, an HL coded operator <b>305</b> can be written such that once compiled in an IR coded operator, it can be adaptable to a variety of anticipated data searches from a query processing engine <b>320</b>. A copy of an IR coded operator <b>310</b> can be made to persist <b>517</b> in a pre-optimized state and can be saved to a file or maintained in a registry, such as to be available on demand for further use.</p><p id="p-0065" num="0064">At runtime, when a data search is called for, another workflow can be performed and it can be identified as a runtime specialization flow <b>510</b>. Upon execution of a data search, an operator specialization module <b>315</b> according to an embodiment can receive <b>312</b> an IR coded operator according to an embodiment. The operator specialization module <b>315</b> can also receive metadata from the data search itself, which can be used to specialize (i.e. customize or adapt) the IR coded operator <b>310</b>. The metadata can be provided by a query processing engine <b>320</b> performing the data search. The query processing engine <b>320</b> can include a metadata manager <b>525</b>, a statistics manager <b>530</b>, and a system information manager <b>535</b>, which can respectively provide data layouts <b>340</b>, data statistics <b>335</b>, and system information <b>330</b> to the operator specialization module <b>315</b> of an embodiment.</p><p id="p-0066" num="0065">An operator specialization module <b>315</b> according to an embodiment can also receive <b>540</b> optimization rules <b>545</b>, which can include global algorithms and also algorithms specific to certain operators.</p><p id="p-0067" num="0066">In an embodiment, once an operator specialization module <b>315</b> has received <b>312</b> an IR coded operator <b>310</b>, system information <b>330</b>, data statistics <b>335</b>, data layout <b>340</b> and optimization rules <b>545</b>, the IR coded operator <b>310</b> can be compiled with a global compiler <b>520</b>. In an embodiment, a global compiler <b>520</b> can be written using an infrastructure such as LLVM <b>550</b> or GCC, also an embodiment can alternatively make use of another compiling infrastructure instead. A compilation process can include applying optimizations to the IR coded operator <b>310</b>, that are specific to the data received, and in particular, specific to the data provided by the search being requested by the query processing engine <b>320</b>. Because it is being performed following a search request, it can be referred to as just-in-time (JIT) compiling and because its results can include an operator that is specialized for a particular search request, the compiler can be said to specialize the IR coded operation for the specific data search. For these reasons, the compiling at this step can be referred to as a step of JIT specializing and compiling <b>555</b> an IR coded operator <b>310</b>.</p><p id="p-0068" num="0067">In an embodiment, after an IR coded operator has been received <b>213</b> and just-in-time (JIT) specialized and compiled <b>555</b> by an operator specialization module <b>315</b>, the resulting file can be received <b>560</b> again by the operator specialization module <b>315</b>. The compilation <b>555</b> effectively corresponds to the creation of an optimized operator <b>355</b>. The specialization and compilation <b>555</b> can convert the IR coded operator into an optimized operator that is compiled for the specific target hardware <b>565</b> of a query processing engine <b>320</b>, such as for example a central processing unit (CPU), a graphics processing unit (GPU), a tensor processing unit (TPU), a field programmable gate array (FPGA) or other hardware. A runtime specialization flow <b>510</b> according to an embodiment as described can take an IR coded operator <b>310</b> as input, and produce an output an optimized operator <b>355</b>, that is both specialized for a data search being executed by a query processing engine <b>320</b>, and coded in the machine language of the target query processing engine <b>320</b> (i.e. compiled). Moreover, in embodiments, such production of an optimized operator according to an embodiment can take less time than a data search would take using an operator that is not optimized according to an embodiment.</p><p id="p-0069" num="0068">Once an optimized operator <b>355</b> has been produced within a pre-compile flow <b>505</b> and a runtime specialization flow <b>510</b> according to embodiments, it can be used as part of a pipeline <b>365</b> of operators by a query processing engine <b>320</b> to perform a data search.</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>5</b>B</figref> illustrates an optimized operator and where it can be used in a data search processing pipeline <b>365</b>, which is shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Typical operations in a query processing engine data processing pipeline can include filtering <b>570</b>, projecting <b>575</b> aggregating <b>580</b>, sorting <b>585</b> and other operations, and these can be performed in various sequences or tree structures. In an embodiment, the sequence and the tree structure of any of these operations can be replaced or defined by an optimized operator <b>355</b> created <b>350</b> via a pre-compile flow <b>505</b> and a runtime specialization flow <b>510</b> according to an embodiment.</p><p id="p-0071" num="0070">By having query operations, and therefore the query itself, optimized at a very low level (i.e. with IR or machine level coding), embodiments can enable a query execution to be adapted to the microarchitecture of a specific machine. A query that is compiled using such low-level code optimizations that also considers runtime data information, can be considered to be based on machine-level programming. Such queries can be classified in a taxonomy describing their results in terms of communication constraints, and other hardware-related constraints.</p><p id="p-0072" num="0071">An embodiment can include certain specialized modules for performing certain steps of a runtime specialization flow <b>510</b>. Further, a pre-compiling flow <b>505</b> and runtime specialization flow <b>510</b> can each process multiple operators at the same time, rather than just one as illustrated for simplicity in <figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref>.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a pre-compiling flow <b>505</b> and a runtime specialization flow <b>510</b>, in accordance with embodiments. To implement an embodiment, a developer can initially configure and write one or more operators in a high level programming language <b>305</b> such as C, C++, Rust or another programming language. Once written, a developer can use an operator compiler frontend <b>515</b> such as Clang (depending on which compiler infrastructure is used), to compile HL coded operators <b>305</b> into IR coded operators <b>310</b>. Within an HL coded operator <b>305</b>, a developer can specify which functions can be involved in specialization by an operator specialization module <b>315</b>, by annotating them. If the compiler to be used is built with an LLVM infrastructure for example, the annotations can be Clang annotations. The annotations can tag the functions such that once compiled into an IR coded operator <b>310</b>, the operator specialization module <b>315</b> can identify the annotated functions during the JIT specializing and compiling stage <b>555</b>. The specialization process of those functions can be customized via programmatic means of mapping inputs and context information with specific optimization rules.</p><p id="p-0074" num="0073">During a runtime specialization flow <b>510</b>, an IR coded operator <b>310</b> called for by a query can be received <b>312</b> by an operator specialization module <b>315</b> using a loading module referred to as an &#x201c;OperatorLoader&#x201d; <b>605</b>. In other words, during query/job execution, receiving an operator required by the query/job, in IR form (&#x201c;IR template file&#x201d;) into a module of IR code, can be performed with an OperatorLoader part of a compiler. When a data query or data search is requested by a query processing engine <b>320</b>, runtime information <b>610</b> can also be provided <b>615</b> to the operator specialization module <b>315</b>. In other words, during query/job execution, the query processing engine can provide runtime information about at least one of data layouts, data statistics and system information. This can be received generally <b>540</b> by the operator specialization module <b>315</b>, or more specifically, it can be received <b>610</b> by a specialized module referred to as HardenModule <b>620</b>, as described further below. The runtime information <b>610</b> can include information describing the system hardware <b>330</b>, information about the data layout <b>340</b> of the query, and statistical information about the data <b>335</b>.</p><p id="p-0075" num="0074">Parameters and variables of an operator specialization module <b>315</b> having received (i.e. loaded with) an IR coded operator <b>310</b> can be replaced with parameters and variables of the runtime information <b>610</b> by a process which can be referred to as hardening <b>615</b>, and be performed by a module referred to as &#x201c;HardenModule&#x201d; <b>620</b>. Because the operator specialization module <b>315</b> undergoes different stages, each stage can be identified differently such that when the operator specialization module <b>315</b> receives an IR coded operator <b>310</b> via a loading module <b>605</b>, the operator specialization module can be referred to as an operator IR module, IR operator module or simply IR module <b>625</b>, and after hardening <b>615</b> with a HardenModule <b>620</b>, it can be referred to as a Hardened IR module <b>630</b>. At this point, compilation <b>555</b> can be performed via a just-in-time compilation module JITModule <b>635</b>. The JITModule <b>635</b> is a compiler to JIT compile a hardened operator IR module, and to apply optimizations enabled by rules to further optimize the code, remove dead code, remove unnecessary branches, to apply function inlining, etc. Because compilation should be performed after a data query is initiated, the process of applying optimizations and performing compilation can be referred to as a just-in-time (JIT) compiling. During compilation <b>555</b>, optimizations to IR coded operators can take into account optimization rules <b>545</b>, which can be applied <b>555</b> by JITModule <b>635</b> to the IR coded operators <b>310</b>. The optimization rules <b>545</b> can include configuration and session values that are global, configuration and session values that are specific for one or many operators, and configuration and session values specific for the target hardware <b>565</b> of the query processing engine performing the data search. Operator code, resulting from optimizations and compilation <b>555</b>, including optimized operators <b>355</b>, can be configured with session and hardware values, globally or specifically for the operators.</p><p id="p-0076" num="0075">The optimizations applied <b>555</b> to operators in IR code can include removing dead code, removing unnecessary branches, function inlining and other optimizations. The just-in-time compilation module <b>635</b> performing the optimizations on IR coded operators can be referred to as a JITModule <b>635</b>. The output of a process, as represented in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, is one or many optimized operators <b>355</b>, as designed by a developer with HL code <b>305</b>, optimized at the IR level according to optimization rules <b>545</b> and runtime information <b>610</b>, and compiled <b>555</b> for the target hardware <b>565</b>, i.e. one or many optimized operators <b>355</b> in target machine code, that can be used in a processing pipeline <b>365</b> of a data search performed by a query processing engine <b>320</b>.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating steps that may be involved in the preparation of operators to be used when a query is performed, according to an embodiment. Initially, an operator specialization module <b>315</b> can receive a pre-compiled IR coded operator template <b>312</b>. If <b>705</b> a received IR coded operator <b>310</b> has dependent modules. A dependent module refers to a static function or library dependency that needs to be produced (i.e. emitted) along with the operator. The operator specialization module <b>315</b> can also receive <b>710</b> pre-compiled IR coded dependent modules. If <b>715</b> specialized values are available for function parameters in an operator, such as data layout information and input/output information, the operator specialization module can replace <b>720</b> them with the specialized values. If there are 725 specialization statistics <b>335</b> for the input data of the query (i.e. the data defining the query being processed), an operator specialization module can replace <b>730</b> statistical values pre-defined in an empty statistical object in an IR coded operator.</p><p id="p-0078" num="0077">An operator specialization module <b>315</b> can also receive <b>735</b> global optimization configurations. If <b>740</b> there are operator specific optimizations, the operator specialization module can override <b>745</b> an optimization(s) with an operator specific optimization(s).</p><p id="p-0079" num="0078">In an embodiment, an operator specialization module can be ready to JIT compile <b>750</b> and update an IR code based on optimizations as defined in previous steps. A compilation process can include, or be supplemented with, removing dead code, removing dead branches, adding logic to bypass (i.e. short circuit) unused portions of the code that would not be executed, based on information received such as that from a statistics object <b>755</b>, and other optimizations. If <b>760</b> special hardware is involved in the query processing engine, such as a field programmable gate array (FPGA), a graphics processing unit (GPU) or a tensor processing unit (TPU), a compilation process can include or be supplemented with the generation <b>760</b> of machine code for the special hardware. Otherwise, it can generate <b>765</b> machine code for a default target such as a local machine can suffice.</p><p id="p-0080" num="0079">Embodiments allow the expression of compiler optimizations that are available in presently existing query compilers, but also of compiler optimizations that are yet to be developed. More importantly, embodiments can provide a programmer with a large degree of flexibility, which is not found in query compilation of existing solutions.</p><p id="p-0081" num="0080">Embodiments allow the integration and support of hardware-specific solutions, as well as flexible data processing capabilities without having to reengineer the overall compilation flow of a query.</p><p id="p-0082" num="0081">Benefits of embodiments can include easy customization and maintainability of user defined optimizations. An embodiment can leverage runtime information <b>610</b> to further optimize a code <b>310</b>, which can ultimately result in better use of hardware resource <b>565</b> and faster operation of a cluster of nodes compromising a big data system <b>320</b>.</p><p id="p-0083" num="0082">Embodiments include the use of user-generated operators <b>310</b> that when a data search is executed, are ready to perform as pre-generated operators that can be dynamically optimized during runtime. This can provide user-specific requirements and enable a degree of optimization, flexibility, and user-friendliness that are improved over that of generic operators of the prior art.</p><p id="p-0084" num="0083">Embodiments include a monitoring system for collecting data from a query, job, and system, as well as metadata information from database data that can be consumed by a query optimizer, for enabling context-sensitive code generation and for optimizing a data processing pipeline.</p><p id="p-0085" num="0084">Embodiments include a pre-optimizer algorithm that can select appropriate optimization methods and operators for a query, based on the runtime information collected by a monitoring system.</p><p id="p-0086" num="0085">Embodiments include secondary level optimization for hardware-specific context, in order to allow an integration of hardware-specific optimization techniques that cannot be enabled via normal means without manual tuning. For example, if any of a CPU, a GPU, a TPU or an FPGA platform is available, ready to be used, and based on the data to be consumed, an optimizer can leverage them.</p><p id="p-0087" num="0086">Embodiments include a combination of described methods and systems through a just-in-time compiler operative to generate and execute optimized machine code for a selected target.</p><p id="p-0088" num="0087">Embodiments can store an optimized code, including optimized operators according to embodiment, in a cache for possible subsequent reuse.</p><p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram of an electronic device (ED) <b>952</b> illustrated within a computing and communications environment <b>950</b> that may be used for implementing the devices and methods disclosed herein. The electronic device <b>952</b> typically includes a processor <b>954</b>, such as a central processing unit (CPU), and may further include specialized processors such as a graphics processing unit (GPU), a tensor processing unit (TPU), a field programmable gate array (FPGA) or other such processor, a memory <b>956</b>, a network interface <b>958</b> and a bus <b>960</b> to connect the components of ED <b>952</b>. ED <b>952</b> may optionally also include components such as a mass storage device <b>962</b>, a video adapter <b>964</b>, and an I/O interface <b>968</b> (shown in dashed lines). An ED <b>952</b> according to an embodiment can also include a cache.</p><p id="p-0090" num="0089">The memory <b>956</b> may comprise any type of non-transitory system memory, readable by the processor <b>954</b>, such as static random-access memory (SRAM), dynamic random-access memory (DRAM), synchronous DRAM (SDRAM), read-only memory (ROM), or a combination thereof. In an embodiment, the memory <b>956</b> may include more than one type of memory, such as ROM for use at boot-up, and DRAM for program and data storage for use while executing programs. The bus <b>960</b> may be one or more of any type of several bus architectures including a memory bus or memory controller, a peripheral bus, or a video bus.</p><p id="p-0091" num="0090">The electronic device <b>952</b> may also include one or more network interfaces <b>958</b>, which may include at least one of a wired network interface and a wireless network interface. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, network interface <b>958</b> may include a wired network interface to connect to a network <b>974</b>, and also may include a radio access network interface <b>972</b> for connecting to other devices over a radio link. The network interfaces <b>958</b> allow the electronic device <b>952</b> to communicate with remote entities such as those connected to network <b>974</b>.</p><p id="p-0092" num="0091">The mass storage <b>962</b> may comprise any type of non-transitory storage device configured to store data, programs, and other information and to make the data, programs, and other information accessible via the bus <b>960</b>. The mass storage <b>962</b> may comprise, for example, one or more of a solid-state drive, hard disk drive, a magnetic disk drive, or an optical disk drive. In some embodiments, mass storage <b>962</b> may be remote to the electronic device <b>952</b> and accessible through use of a network interface such as interface <b>958</b>. In the illustrated embodiment, mass storage <b>962</b> is distinct from memory <b>956</b> where it is included and may generally perform storage tasks compatible with higher latency, but may generally provide lesser or no volatility. In some embodiments, mass storage <b>962</b> may be integrated with a heterogeneous memory <b>956</b>.</p><p id="p-0093" num="0092">In some embodiments, electronic device <b>952</b> may be a standalone device, while in other embodiments electronic device <b>952</b> may be resident within a data center. A data center, as will be understood in the art, is a collection of computing resources (typically in the form of servers) that can be used as a collective computing and storage resource. Within a data center, a plurality of servers can be connected together to provide a computing resource pool upon which virtualized entities can be instantiated. Data centers can be interconnected with each other to form networks consisting of pools computing and storage resources connected to each by connectivity resources. The connectivity resources may take the form of physical connections such as Ethernet or optical communications links, and in some instances may include wireless communication channels as well. If two different data centers are connected by a plurality of different communication channels, the links can be combined together using any of a number of techniques including the formation of link aggregation groups (LAGs). It should be understood that any or all of the computing, storage and connectivity resources (along with other resources within the network) can be divided between different sub-networks, in some cases in the form of a resource slice. If the resources across a number of connected data centers or other collection of nodes are sliced, different network slices can be created.</p><p id="p-0094" num="0093">In embodiments, an electronic device <b>952</b> can be used for compiling HL and IR code, for applying optimizations to IR code, for storing data, and for processing a data query though a pipeline of operators and/or optimized operators according to embodiments.</p><p id="p-0095" num="0094">Examples of the present disclosure include a method of performing a data search, the method comprising: obtaining at least one operator; obtaining runtime information of the data search; obtaining optimization rules; obtaining at least one optimized and compiled operator by optimizing and compiling the at least one operator according to the runtime information of the data search and the optimization rules; and performing the data search using the at least one optimized and compiled operator.</p><p id="p-0096" num="0095">In the above example, an operator can be configured in a high level programming language, and compiled by a front-end compiler into an intermediate representation code of the at least one operator.</p><p id="p-0097" num="0096">In any of the above examples, an operator can include annotations tagging functions which are to be specialized when the at least one operator is being optimized and compiled for the data search at runtime.</p><p id="p-0098" num="0097">In any of the above examples, the runtime information can include includes data layout.</p><p id="p-0099" num="0098">In any of the above examples, the runtime information can include data statistics.</p><p id="p-0100" num="0099">In any of the above examples, the runtime information can include hardware information of the query processing engine.</p><p id="p-0101" num="0100">In any of the above examples, the optimization rules can include global algorithms.</p><p id="p-0102" num="0101">In any of the above examples, the optimization rules can be based on the runtime information.</p><p id="p-0103" num="0102">In any of the above examples the optimization rules can include algorithms specific to the at least one operator.</p><p id="p-0104" num="0103">In any of the above examples, optimizing an operator can include an application of at least one optimization to the code of an operator that increases the efficiency of a data search executing that operator.</p><p id="p-0105" num="0104">In any of the above examples, optimizing an operator can be performed after a data search is called for, and before the data search is complete, such that performing the data search includes executing at least one optimized operator.</p><p id="p-0106" num="0105">In any of the above examples, performing a data search can include optimizing and compiling many operators, which can subsequently be executed by the data search according to a query plan defined by the optimization and compilation.</p><p id="p-0107" num="0106">Some examples of the present disclosure include a system for performing a data search comprising: at least one processor, storage medium for data, storage medium for a query processing engine, storage medium for a compiler, and storage medium for at least one operator file configured with a programming language; wherein upon executing the query processing engine, the compiler is operative to obtain at least one optimized and compiled operator file by optimizing and compiling the at least one operator file according to the runtime information of the data search, and according to optimization rules; and wherein performing the data search includes executing the at least one optimized and compiled operator file.</p><p id="p-0108" num="0107">In the above example, prior to being optimized and executed by the query processing engine, the at least one operator file can be configured with a high level programming language and be compiled into intermediate representation code.</p><p id="p-0109" num="0108">In any of the above examples, a system can further include an operator specialization module that is operative to receive at least one operator file, as well as the runtime information from the query processing engine; and to have at least one operator file optimized and compiled based on runtime information.</p><p id="p-0110" num="0109">In any of the above examples, an operator file can be configured with a high level programming language and be compiled into an intermediate representation code.</p><p id="p-0111" num="0110">In any of the above examples, an operator file can include annotations tagging functions that are to be specialized when the operator coded within the operator file is being optimized and compiled for the data search at runtime.</p><p id="p-0112" num="0111">In any of the above examples, the runtime information can include data layout.</p><p id="p-0113" num="0112">In any of the above examples, the runtime information can include data statistics.</p><p id="p-0114" num="0113">In any of the above examples, the runtime information can include hardware information.</p><p id="p-0115" num="0114">A computer program can include instructions which can, when the program is executed by a computer, cause the computer to carry out the method of any one of claims <b>1</b> to <b>12</b>.</p><p id="p-0116" num="0115">A computer-readable medium can include instructions which can, when executed by a computer, cause the computer to carry out the method of any one of claims <b>1</b> to <b>12</b>.</p><p id="p-0117" num="0116">Embodiments have been described above in conjunctions with aspects of the present invention upon which they can be implemented. Those skilled in the art will appreciate that embodiments may be implemented in conjunction with the aspect with which they are described, but may also be implemented with other embodiments of that aspect. When embodiments are mutually exclusive, or are otherwise incompatible with each other, it will be apparent to those skilled in the art. Some embodiments may be described in relation to one aspect, but may also be applicable to other aspects, as will be apparent to those of skill in the art.</p><p id="p-0118" num="0117">Although the present invention has been described with reference to specific features and embodiments thereof, it is evident that various modifications and combinations can be made thereto without departing from the invention. The specification and drawings are, accordingly, to be regarded simply as an illustration of the invention as defined by the appended claims, and are contemplated to cover any and all modifications, variations, combinations or equivalents that fall within the scope of the present invention.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of performing a data search, the method comprising:<claim-text>obtaining at least one operator;</claim-text><claim-text>obtaining runtime information of the data search;</claim-text><claim-text>obtaining optimization rules;</claim-text><claim-text>obtaining at least one optimized and compiled operator by optimizing and compiling the at least one operator according to the runtime information of the data search and the optimization rules; and</claim-text><claim-text>performing the data search using the at least one optimized and compiled operator.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one operator is configured in a high level programming language, and compiled by a front-end compiler into an intermediate representation code of the at least one operator.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one operator includes annotations tagging functions which are to be specialized when the at least one operator is being optimized and compiled for the data search at runtime.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the runtime information includes data layout.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the runtime information includes data statistics.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the runtime information includes hardware information of a query processing engine, which performs the data search.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the optimization rules include global algorithms.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the optimization rules are based on the runtime information.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the optimization rules include algorithms specific to the at least one operator.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein optimizing the at least one operator includes an application of at least one optimization to a code of the at least one operator that increases the efficiency of a data search executing the at least one operator.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein optimizing the at least one operator is performed after a data search is called for, and before the data search is complete, such that performing the data search includes executing the at least one optimized operator.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein performing a data search includes the optimizing and compiling many operators, which are subsequently executed by the data search according to a query plan defined by the data search.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A system for performing a data search comprising:<claim-text>at least one processor,</claim-text><claim-text>at least one storage medium for a query processing engine, a compiler, and at least one operator file configured with a programming language;</claim-text></claim-text><claim-text>wherein upon executing the query processing engine, the compiler is operative to obtain at least one optimized and compiled operator file by optimizing and compiling the at least one operator file according to the runtime information of the data search, and according to optimization rules; and wherein performing the data search includes executing the at least one optimized and compiled operator file.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein prior to being optimized and executed by the query processing engine, the at least one operator file is configured with a high level programming language and compiled into intermediate representation code.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising an operator specialization module that is operative to receive at least one operator file, as well as the runtime information from the query processing engine; and to have at least one operator file optimized and compiled based on runtime information.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein an operator file is configured with a high level programming language and compiled into an intermediate representation code.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein an operator file includes annotations tagging functions that are to be specialized when the operator coded within the operator file is being optimized and compiled for the data search at runtime.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the runtime information includes data layout.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the runtime information includes data statistics.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the runtime information includes hardware information of the query processing engine.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the optimization rules include global algorithms.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the optimization rules are based on the runtime information.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the optimization rules include algorithms specific to the at least one operator.</claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein optimizing the at least one operator is performed after a data search is called for, and before the data search is complete, such that performing the data search includes executing the at least one optimized operator.</claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein performing the data search includes the optimizing and compiling many operators, which are subsequently executed by the data search according to a query plan defined by the data search.</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. A computer-readable medium comprising instructions which, when executed by a computer, cause the computer to carry out the method of <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim></claims></us-patent-application>
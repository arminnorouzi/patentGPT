<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007084A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007084</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931529</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>202010230251.4</doc-number><date>20200327</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>131</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>41</main-group><subgroup>5009</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>131</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>41</main-group><subgroup>5009</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>1</main-group><subgroup>0002</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">EXTENDED REALITY DATA TRANSMISSION METHOD AND APPARATUS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/CN2021/081935</doc-number><date>20210320</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17931529</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>HUAWEI TECHNOLOGIES CO., LTD.</orgname><address><city>Shenzhen</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>DOU</last-name><first-name>Shengyue</first-name><address><city>Shanghai</city><country>CN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>WEI</last-name><first-name>Yuejun</first-name><address><city>Shanghai</city><country>CN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>TANG</last-name><first-name>Zhenfei</first-name><address><city>Shanghai</city><country>CN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>ZHOU</last-name><first-name>Guohua</first-name><address><city>Shanghai</city><country>CN</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>LI</last-name><first-name>Nijun</first-name><address><city>Shanghai</city><country>CN</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>HUAWEI TECHNOLOGIES CO., LTD.</orgname><role>03</role><address><city>Shenzhen</city><country>CN</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">This application provides an extended reality data transmission method and an apparatus. The method includes: determining that a data type is extended reality data; determining, based on the data type, to obtain, based on delay information and transmission error information, extended reality quality indicator XQI information corresponding to a target rate, where the XQI information indicates transmission quality of the extended reality data; and performing communication based on the XQI information.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="77.64mm" wi="158.75mm" file="US20230007084A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="221.91mm" wi="167.30mm" file="US20230007084A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="222.08mm" wi="167.98mm" file="US20230007084A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="203.28mm" wi="150.54mm" file="US20230007084A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="209.72mm" wi="163.32mm" file="US20230007084A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="66.80mm" wi="167.56mm" file="US20230007084A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="207.69mm" wi="163.24mm" file="US20230007084A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="208.53mm" wi="163.32mm" file="US20230007084A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="225.38mm" wi="166.29mm" file="US20230007084A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="86.61mm" wi="139.36mm" file="US20230007084A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of International Application No. PCT/CN2021/081935, filed on Mar. 20, 2021, which claims priority to Chinese Patent Application No. 202010230251.4, filed on Mar. 27, 2020. The disclosures of the aforementioned applications are hereby incorporated by reference in their entireties.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">This application relates to the field of communication technologies, and in particular, to an extended reality data transmission method and an apparatus.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">In a wireless communication network, an extended reality (XR) technology has advantages such as multi-view and strong interaction, can provide brand-new visual experience for a user, and has a great application value and great business potential. The XR includes technologies such as virtual reality (VR), augmented reality (AR), and mix reality (MR), and can be widely applied to various fields such as entertainment, gaming, healthcare, advertising, industry, online education, and engineering.</p><p id="p-0005" num="0004">XR data requires to be transmitted on the network in real time and at a high speed. Whether these requirements are met is usually determined depending on user experience. However, user experience of network transmission of the XR data is a subjective feeling of the user, and objective impact on the XR data during network transmission cannot be accurately measured. Consequently a network operator cannot be systematically helped to perform network optimization for the XR data. Therefore, how to measure the impact on the XR data during network transmission more systematically and objectively to guide network design and guide the network operator to optimize the network based on the XR data becomes an urgent problem to be resolved.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">Embodiments of this application provide an extended reality data transmission method and an apparatus.</p><p id="p-0007" num="0006">According to a first aspect, an embodiment of this application provides a communication method. The method may be performed by a terminal, a network device, a server, or a centralized controller, or may be performed by a component (for example, a processor, a chip, or a chip system) of a terminal, a network device, a server, or a centralized controller. The method includes: obtaining, based on delay information and transmission error information, extended reality quality indicator (XR quality indicator/index, XQI) information corresponding to a target rate, where the XQI information indicates transmission quality of extended reality data; and performing communication based on the XQI information. The XQI information corresponding to the target rate may also be understood as that the XQI indicated by the XQI information corresponds to the target rate. The obtaining, based on delay information and transmission error information, XQI information corresponding to a target rate may also be understood as that there is a correspondence between the XQI and a delay value indicated by the delay information and a transmission error rate indicated by the transmission error information. The performing communication based on the XQI information may be outputting the XQI information, or sending or receiving the XR data based on the XQI information.</p><p id="p-0008" num="0007">Because the XQI information can represent transmission quality of the XR data in a network, objective impact on the XR data in network transmission can be systematically evaluated by using the method, to guide a network design and guide a network operator to maintain and optimize the network based on a requirement of the XR data.</p><p id="p-0009" num="0008">Optionally, the delay information includes packet delay budget (PDB) information and/or delay variation information. The PDB information indicates a PDB, and the PDB indicates how long a data packet needs to be correctly transmitted. The delay variation information indicates a change of a delay. Optionally, the delay information further includes packet average delay information and/or delay variance information. The average delay information indicates an average value of the delay or the PDB in a period of time. The delay variance information indicates a variance of the delay. By using the foregoing specific delay information, delay impact on the XR data during transmission in the network can be evaluated from different dimensions, to guide a network design and guide a network operator to maintain and optimize the network according to a delay requirement of the XR data.</p><p id="p-0010" num="0009">Optionally, the transmission error information includes one or more of packet error rate (PER) information, block error rate (BLER) information, retransmission information, average packet loss rate information, burst packet loss rate information, or first packet response time information. The PER (which may also be referred to as a packet error rate) information indicates a ratio of a quantity of incorrectly received data packets to a total quantity of received data packets. The BLER information indicates a ratio of a quantity of incorrectly received data blocks to a total quantity of received data blocks. The retransmission information may indicate, for example, a quantity of hybrid automatic repeat request (HARQ) retransmission times, or acknowledgment response (ACK) or negative acknowledgment response (NACK) information reported by a terminal device to a base station. The average packet loss rate information may indicate a rate of packet loss in a period of time. The burst packet loss rate information may indicate a packet loss rate of a burst service from the beginning to the end. The first packet response time information may indicate time from starting to send the first packet to receiving an acknowledgment response (ACK) for the packet. By using the foregoing transmission error information, impact of transmission error on the XR data during transmission in the network can be evaluated from different dimensions, to guide a network operator to maintain and optimize the network according to a reliability requirement of the XR data.</p><p id="p-0011" num="0010">Optionally, the target rate includes a source rate and/or a network transmission rate of the XR data. The source rate of the XR data may be understood as a data rate of an XR video source and/or audio source, or may be understood as a data output rate of the XR video source and/or audio source at a source end. The network transmission rate may be understood as a transmission rate of data in an access network.</p><p id="p-0012" num="0011">The XQI information corresponding to the target rate is reflected by using the foregoing delay information and transmission error information that represent objective impact on network transmission, and the XQI information is mapped to the target rate, so that a more flexible indicator can be provided for transmission quality of the XR data in the network, to provide a controllable and quantifiable evaluation basis for network maintenance and optimization based on an XR data requirement.</p><p id="p-0013" num="0012">Optionally, there is a correspondence between a value range of the XQI and transmission quality of the XR data and/or user experience of the XR service. User experience of the XR service may be evaluated, for example, by using one or more of the following indicators: image definition, image smoothness, image distortion, image stereoscopy, image black borders, image smearing, sound quality, sound effect, angle of view, freezing, artifacts, dizziness, audio and video synchronization, interaction freedom, interaction operation response speed, interaction operation precision, or content loading speed. In this manner, subjective experience of a user on the XR data can be better reflected by using the XQI, so that an operator can be guided to perform more targeted optimization on network transmission of the XR data based on user experience.</p><p id="p-0014" num="0013">Optionally, the XQI information corresponds to a first extended reality data stream and a second extended reality data stream, where the XQI information includes first XQI information and second XQI information, the first XQI information corresponds to the first extended reality data stream, and the second XQI information corresponds to the second extended reality data stream. It may also be understood as that XQIs included in the XQI information correspond to a first extended reality data stream and a second extended reality data stream, where the XQIs include a first XQI and a second XQI, the first XQI corresponds to the first extended reality data stream, and the second XQI corresponds to the second extended reality data stream. The first extended reality data stream and the second extended reality data stream may be one of the following cases.<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0014">The first extended reality data stream includes an extended reality base layer data stream, and the second extended reality data stream includes an extended reality enhancement layer data stream. The extended reality base layer data stream and the extended reality enhancement layer data stream may be extended reality data streams obtained by encoding source data of the XR. The encoding may be, for example, high efficiency video coding (HEVC), scalability extension of HEVC (SHVC), or another video coding scheme that can distinguish different data streams. This is not limited in the present application.</li>        <li id="ul0002-0002" num="0015">The first extended reality data stream includes an extended reality in-field of view (FOV) data stream, and the second extended reality data stream includes an extended reality out-of-FOV data stream. The extended reality in-FOV data stream and the extended reality out-of-FOV data stream may be extended reality data streams obtained by performing FOV source coding on the source data of the XR. The FOV source coding may divide the source data of the XR into an in-view part and an out-of-view part, where the in-view part corresponds to the extended reality in-FOV data stream, and the out-of-view part corresponds to the extended reality out-of-FOV data stream.</li>    </ul>    </li></ul></p><p id="p-0015" num="0016">XQIs are independently allocated to different extended reality data streams, so that extended reality data with different transmission requirements can be differentiated. Different transmission policies are separately used for an extended reality data stream with a higher priority and an extended reality data stream with a lower priority, so that XR data can be transmitted more efficiently by using limited network resources.</p><p id="p-0016" num="0017">With reference to the first aspect, in some implementations of the first aspect, the XQI information (or an XQI indicated by the XQI information) is obtained based on the source rate, the network transmission rate, the delay information, and the transmission error information of the XR data. For example, when the network transmission rate is greater than or equal to the source rate of the XR data, the XQI is obtained based on the delay information and the transmission error information; or when the network transmission rate is less than the source rate of the XR data, the XQI is obtained based on the network transmission rate, the delay information, and the transmission error information. It may also be understood as that, when the network transmission rate is greater than or equal to the source rate of the XR data, there is a correspondence between the XQI and the delay information and the transmission error information; or when the network transmission rate is less than the source rate of the XR data, there is a correspondence between the XQI and the delay information, the transmission error information, and the network transmission rate. In this implementation, the source rate and the network transmission rate of the XR data can be better matched, so that the network operator can be guided to provide a more matched resource and mode for transmission of the XR data.</p><p id="p-0017" num="0018">With reference to the first aspect, in some implementations of the first aspect, capacity information may be further obtained based on the XQI information and the target rate. Optionally, the capacity information includes terminal capacity information and/or network capacity information. The terminal capacity information may be understood as an equivalent capacity of the terminal at a given target rate. The network capacity information may be understood as an equivalent capacity of the network when all terminals in the network are considered.</p><p id="p-0018" num="0019">With reference to the first aspect, in some implementations of the first aspect, for a terminal or a user included in a network, statistics may be further collected on distribution of an XQI of the terminal or the user, for example, a cumulative distribution function (CDF) of the XQI, to measure performance of supporting the XR service by the network. For example, in the CDF of the XQI, a proportion of terminals or users corresponding to the XQI may be obtained. For example, a larger XQI indicates better user experience. If a proportion of terminals or users corresponding to a large XQI is high, the network supports the XR service well. If a proportion of terminals or users corresponding to a small XQI is high, the network supports the XR service poorly.</p><p id="p-0019" num="0020">The capacity information is obtained based on the XQI information and the target rate, so that an overall network capacity can be quantitatively evaluated, and the network operator can be guided to adapt the network resource based on a capacity requirement of the XR data, to use the network resource more efficiently.</p><p id="p-0020" num="0021">With reference to the first aspect, in some implementations of the first aspect, first evaluation information and second evaluation information may be further obtained, and third evaluation information is obtained based on the XQI information, the first evaluation information, and the second evaluation information. The first evaluation information indicates source quality of the XR data, the second evaluation information indicates a capability of processing the XR data, the third evaluation information indicates user experience in an end-to-end process of the XR service, and the end-to-end process includes generation of the XR data, transmission of the XR data, and processing of the XR data. For example, the source quality of the XR data may be used to evaluate one or more of the following indicators of the XR video source and/or audio source: image content, image definition, image smoothness, image stereoscopy, image distortion, frame rate, audio quality, or rendering effect. The capability of processing the XR data, for example, may be used to evaluate a capability of an XR terminal to process and/or display the XR data, for example, a supported FOV angle and/or refresh rate. The capability of processing the XR data, for example, may be further used to evaluate one or more of indicators such as a battery life, wearing comfort, wearing fatigue, portability, or visual impairment friendliness of the XR terminal.</p><p id="p-0021" num="0022">User experience in the end-to-end process of the XR service can be obtained based on evaluation information about the data source, terminal, and transmission pipe of the XR service, so that an end-to-end comprehensive evaluation system can be established for the XR service, to guide the network operator to maintain and optimize the network based on the evaluation system to meet the requirement of the XR service.</p><p id="p-0022" num="0023">With reference to the first aspect, in some implementations of the first aspect, it may be further determined that a data type is extended reality data. The obtaining, based on delay information and transmission error information, XQI information corresponding to a target rate may be implemented as follows: determining, based on the data type, to obtain, based on delay information and transmission error information, XQI information corresponding to a target rate, where the XQI information indicates transmission quality of the extended reality data. In an implementation of determining that the data type is the extended reality data, data type information may be obtained, and it is determined, based on the data type information, that the data type is the extended reality data. For example, the data type information may indicate that the data type is the extended reality data. Optionally, the data type information may be obtained by receiving downlink control information (DCI) or higher layer signaling, or the data type information may be obtained by receiving uplink control information (UCI) or higher layer signaling. In another implementation of determining that the data type is the extended reality data, it may be determined, based on configuration information of a core network, that the data type information is the extended reality data. In another implementation of determining that the data type is the extended reality data, it may be determined, based on a service characteristic of the data, that the data type of the data is the extended reality data.</p><p id="p-0023" num="0024">In this implementation, after it is learned that the data type is the extended reality data, the XQI information indicating the transmission quality of the extended reality data is obtained based on a corresponding parameter, so that XQI-based transmission quality measurement and evaluation can be performed on the extended reality data more pertinently, to guide the network design for data of the XR type, and guide the network operator to maintain and optimize the network based on the requirement of the XR data.</p><p id="p-0024" num="0025">According to a second aspect, an embodiment of this application provides a communication method. The method may be performed by a terminal, a network device, a server, or a centralized controller, or may be performed by a component (for example, a processor, a chip, or a chip system) of a terminal, a network device, a server, or a centralized controller. The method includes: determining that a data type is extended reality data, and reporting XQI information or reporting information related to an XQI based on the data type. Optionally, the information related to the XQI includes one or more of PDB information, delay variation information, average delay information, delay variance information, PER information, BLER information, retransmission information, average packet loss rate information, burst packet loss rate information, or first packet response time information related to the extended reality data.</p><p id="p-0025" num="0026">With reference to the second aspect, in some implementations of the second aspect, when the XQI information is reported, to-be-reported XQI information may be further obtained based on delay information and transmission error information before the XQI information is reported.</p><p id="p-0026" num="0027">In the foregoing method and implementation, after it is learned that the data type is the extended reality data, the XQI information related to the extended reality data is reported or parameter information required by the XQI is obtained, so that XQI-based transmission quality measurement and evaluation can be performed on the extended reality data more pertinently, to guide the network design for data of the XR type, and guide the network operator to maintain and optimize the network based on the requirement of the XR data.</p><p id="p-0027" num="0028">According to a third aspect, an embodiment of this application provides an apparatus. The apparatus may implement the method according to any one of the first aspect or the implementations of the first aspect. The apparatus includes a corresponding unit or component configured to perform the foregoing method. The unit included in the apparatus may be implemented by software and/or hardware. For example, the apparatus may be a terminal, a network device, a server, or a centralized controller, or may be a chip, a chip system, or a processor that can support the terminal, the network device, the server, or the centralized controller in implementing the foregoing method.</p><p id="p-0028" num="0029">According to a fourth aspect, an embodiment of this application provides an apparatus. The apparatus may implement the method according to any one of the second aspect or the implementations of the second aspect. The apparatus includes a corresponding unit or component configured to perform the foregoing method. The unit included in the apparatus may be implemented by software and/or hardware. For example, the apparatus may be a terminal, a network device, a server, or a centralized controller, or may be a chip, a chip system, or a processor that can support the terminal, the network device, the server, or the centralized controller in implementing the foregoing method.</p><p id="p-0029" num="0030">According to a fifth aspect, an embodiment of this application provides an apparatus. The apparatus includes a processor. The processor is coupled to a memory. The memory is configured to store a program or instructions. When the program or the instructions are executed by the processor, the apparatus is enabled to implement the method according to any one of the first aspect or the implementations of the first aspect.</p><p id="p-0030" num="0031">According to a sixth aspect, an embodiment of this application provides an apparatus. The apparatus includes a processor. The processor is coupled to a memory. The memory is configured to store a program or instructions. When the program or the instructions are executed by the processor, the apparatus is enabled to implement the method according to any one of the second aspect or the implementations of the second aspect.</p><p id="p-0031" num="0032">According to a seventh aspect, an embodiment of this application provides a computer-readable medium, storing a computer program or instructions. When the computer program or the instructions are executed, a computer is enabled to perform the method in any one of the first aspect or the implementations of the first aspect.</p><p id="p-0032" num="0033">According to an eighth aspect, an embodiment of this application provides a computer-readable medium, storing a computer program or instructions. When the computer program or the instructions are executed, a computer is enabled to perform the method in any one of the second aspect or the implementations of the second aspect.</p><p id="p-0033" num="0034">According to a ninth aspect, an embodiment of this application provides a computer program product. The computer program product includes computer program code. When the computer program code is run on a computer, the computer is enabled to perform the method according to any one of the first aspect or the implementations of the first aspect.</p><p id="p-0034" num="0035">According to a tenth aspect, an embodiment of this application provides a computer program product. The computer program product includes computer program code. When the computer program code is run on a computer, the computer is enabled to perform the method according to any one of the second aspect or the implementations of the second aspect.</p><p id="p-0035" num="0036">According to an eleventh aspect, an embodiment of this application provides a chip. The chip includes a processor. The processor is coupled to a memory. The memory is configured to store a program or instructions. When the program or the instructions are executed by the processor, the chip is enabled to implement the method according to any one of the first aspect or the implementations of the first aspect.</p><p id="p-0036" num="0037">According to a twelfth aspect, an embodiment of this application provides a chip. The chip includes a processor. The processor is coupled to a memory. The memory is configured to store a program or instructions. When the program or the instructions are executed by the processor, the chip is enabled to implement the method according to any one of the second aspect or the implementations of the second aspect.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0037" num="0038"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of a communication system used in an embodiment of this application;</p><p id="p-0038" num="0039"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram of an example of an architecture of a communication system;</p><p id="p-0039" num="0040"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram of four service requirements;</p><p id="p-0040" num="0041"><figref idref="DRAWINGS">FIG. <b>4</b></figref> to <figref idref="DRAWINGS">FIG. <b>6</b></figref> are diagrams of several system architectures applicable to embodiments of this application;</p><p id="p-0041" num="0042"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, <figref idref="DRAWINGS">FIG. <b>8</b></figref>, and <figref idref="DRAWINGS">FIG. <b>9</b></figref> are flowcharts of several communication methods according to embodiments of this application;</p><p id="p-0042" num="0043"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram of a structure of a communication apparatus according to an embodiment of this application;</p><p id="p-0043" num="0044"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram of a structure of a terminal according to an embodiment of this application; and</p><p id="p-0044" num="0045"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram of another communication apparatus according to an embodiment of this application.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0045" num="0046">A method and an apparatus provided in embodiments of this application may be applied to a communication system. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of a structure of a communication system. The communication system <b>100</b> includes one or more network devices (a network device <b>110</b> and a network device <b>120</b> shown in the figure), and one or more terminals that communicate with the one or more network devices. A terminal <b>114</b> and a terminal <b>118</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> communicate with the network device <b>110</b>, and a terminal <b>124</b> and a terminal <b>128</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> communicate with the network device <b>120</b>. It may be understood that the network device and the terminal may also be referred to as communication devices.</p><p id="p-0046" num="0047">Technologies described in embodiments of the present application may be applied to various communication systems, for example, a 4th generation (4G) communication system, a 4.5G communication system, a 5G communication system, a system converged by a plurality of communication systems, and a future evolved communication system (for example, a 6G communication system). For example, the technologies may be applied to a long term evolution (LTE) system, a new radio (NR) system, a wireless fidelity (Wi-Fi) system, a wireless self-organizing system, a device-to-device direct communication system, a communication system related to the 3rd Generation Partnership Project (3GPP), and another communication system of this type.</p><p id="p-0047" num="0048"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram of an example of an architecture of a communication system. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a network device in a radio access network (RAN) includes a base station (for example, a gNodeB or a gNB) with an architecture in which a centralized unit (CU) and a distributed unit (DU) are separated. The RAN may be connected to a core network (for example, may be an LTE core network or a 5G core network). It may be understood that the base station is divided into the CU and the DU from the perspective of a logical function. The CU and the DU may be physically separated or deployed together. A plurality of DUs may share one CU. One DU may alternatively be connected to a plurality of CUs (not shown in the figure). The CU and the DU may be connected through an interface, for example, an F1 interface. The CU and the DU may be obtained through division based on protocol layers of a wireless network. For example, functions of a packet data convergence protocol (PDCP) layer and a radio resource control (RRC) layer are distributed to the CU, but functions of a radio link control (RLC) layer, a media access control (MAC) layer, and a physical layer are distributed to the DU. It may be understood that, division into processing functions of the CU and the DU based on the protocol layers is merely an example, and there may be other division. For example, the CU or the DU may have functions of more protocol layers through division. For example, the CU or the DU may alternatively have some processing functions of the protocol layers through division. In a design, some functions of the RLC layer and functions of a protocol layer above the RLC layer are distributed to the CU, and remaining functions of the RLC layer and functions of a protocol layer below the RLC layer are distributed to the DU. In another design, functions of the CU or the DU may alternatively be obtained through division based on a service type or another system requirement. For example, division is performed based on a delay, a function whose processing time needs to satisfy a delay requirement is distributed on the DU, and a function whose processing time does not need to satisfy the delay requirement is distributed on the CU. A network architecture shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may be applied to a 5G communication system, and may alternatively share one or more components or resources with an LTE system. In another design, the CU may alternatively have one or more functions of a core network. One or more CUs may be disposed in a centralized manner or a separated manner. For example, the CUs may be disposed on a network side for ease of centralized management. The DU may have a plurality of radio frequency functions, or the radio frequency functions may be remotely set.</p><p id="p-0048" num="0049">The function of the CU may be implemented by one entity, or may be used to further separate a control plane (CP) and a user plane (UP). The control plane of the CU (CU-CP) and the user plane of the CU (CU-UP) may be implemented by different function entities, and the CU-CP and the CU-UP may be coupled to the DU to jointly implement a function of the base station.</p><p id="p-0049" num="0050">It may be understood that embodiments provided in this application are also applicable to an architecture in which the CU and the DU are not separated.</p><p id="p-0050" num="0051">In this application, the network device may be any device having a wireless transceiver function. The network device includes but is not limited to: an evolved NodeB (NodeB or eNB or e-NodeB, evolved Node B) in LTE, a base station (gNodeB or gNB) or a transmission reception point (TRP) in NR, a base station that subsequently evolves in 3GPP, an access node in a Wi-Fi system, a wireless relay node, a wireless backhaul node, a core network device, and the like. The base station may be a macro base station, a micro base station, a picocell base station, a small cell, a relay station, a balloon station, or the like. A plurality of base stations may support networks using a same technology mentioned above, or may support networks using different technologies mentioned above. The base station may include one or more co-site or non-co-site TRPs. The network device may further be a server (for example, a cloud server), a radio controller in a cloud radio access network (CRAN) scenario, a CU, and/or a DU. The network device may alternatively be a server, a wearable device, a machine type communication device, a vehicle-mounted device, a smart screen, or the like. An example in which the network device is a base station is used for description below. The plurality of network devices may be base stations of a same type or base stations of different types. The base station may communicate with a terminal device, or may communicate with the terminal device through a relay station. The terminal device may communicate with a plurality of base stations using different technologies. For example, the terminal device may communicate with a base station supporting an LTE network, or may communicate with a base station supporting a 5G network, or may support dual connections to the base station supporting the LTE network and the base station supporting the 5G network.</p><p id="p-0051" num="0052">The terminal is a device with a wireless transmitting/receiving function. The terminal may be deployed on land, indoor or outdoor, or may be hand-held, wearable or vehicle-mounted; may be deployed on a water surface (for example, on a ship); or may be deployed in the air (for example, on an airplane, a balloon, or a satellite). The terminal may be a mobile phone, a tablet computer (Pad), a computer having a wireless transceiver function, a VR terminal device, an AR terminal device, an MR terminal device, a terminal in industrial control, a vehicle-mounted terminal device, a terminal in self driving, a terminal in assisted driving, a terminal in telemedicine, a terminal in a smart grid, a terminal in transportation safety, a terminal in a smart city, a terminal in a smart home, or the like. Application scenarios are not limited in embodiments of this application. Sometimes, the terminal may also be referred to as a terminal device, user equipment (UE), an access terminal device, a vehicle-mounted terminal, an industrial control terminal, a UE unit, a UE station, a mobile station, a remote station, a remote terminal device, a mobile device, a UE terminal device, a wireless communication device, a machine terminal, a UE agent, a UE apparatus, or the like. The terminal may be fixed or mobile.</p><p id="p-0052" num="0053">By way of example and not limitation, the terminal in this application may alternatively be a wearable device. The wearable device may also be referred to as a wearable intelligent device, and is a general term of a wearable device that is intelligently designed and developed for daily wear by using a wearable technology, for example, glasses, gloves, a watch, clothing, and shoes. The wearable device is a portable device that can be directly worn on a body or integrated into clothes or an accessory of a user. The wearable device is not merely a hardware device, and further implements a powerful function through software support, data exchange, and cloud interaction. Generalized wearable intelligent devices include full-featured and large-size devices that can implement complete or partial functions without depending on smartphones, such as smart watches or smart glasses, and devices that focus on only one type of application and need to work with other devices such as smartphones, such as various smart bands or smart jewelry for monitoring physical signs.</p><p id="p-0053" num="0054">In this application, the terminal may be a terminal in an internet of things (IoT) system. IoT is an important component in development of future information technologies. A main technical feature of the IoT is to connect an object to a network by using a communication technology, to implement an intelligent network of human-machine interconnection and thing-thing interconnection. The terminal in this application may be a terminal in machine type communication (MTC). The terminal in this application may be a vehicle-mounted module, a vehicle-mounted component, a vehicle-mounted chip, or a vehicle-mounted unit that is built in a vehicle as one or more components or units. The vehicle uses the vehicle-mounted module, the vehicle-mounted component, the vehicle-mounted chip, or the vehicle-mounted unit that is built in the vehicle, to implement a method in this application. Therefore, embodiments of this application may be applied to the internet of vehicles, for example, vehicle to everything (V2X), long term evolution-vehicle (LTE-V), or vehicle-to-vehicle (V2V).</p><p id="p-0054" num="0055">Alternatively, the terminal in this application may be a VR terminal, an AR terminal, or an MR terminal. The VR terminal, the AR terminal, and the MR terminal may all be referred to as XR terminals. The XR terminal may be, for example, a head mounted device (for example, a helmet or glasses), may be an all-in-one machine, or may be a television, a display, a car, a vehicle-mounted device, a tablet, or a smart screen. The XR terminal can present XR data to a user, and the user can experience diversified XR services by wearing or using the XR terminal. The XR terminal may access a network in a wireless or wired manner, for example, by using a Wi-Fi or 5G system.</p><p id="p-0055" num="0056">The XR technology has advantages such as multi-view and strong interaction, can provide brand-new visual experience for the user, and has great application value and business potential. The XR includes technologies such as VR, AR, and MR, and can be widely applied to various fields such as entertainment, gaming, healthcare, advertising, industry, online education, and engineering. The VR technology mainly refers to rendering visual and audio scenarios to simulate sensory stimulation of vision and audio in the real world to a user as much as possible. The VR technology usually requires the user to wear an XR terminal (for example, a head mounted device) to simulate vision and/or hearing of the user. The VR technology may further perform action tracking on the user, to update simulated visual and/or auditory content in time. The AR technology mainly refers to providing additional visual and/or auditory information or manually generated content in a real environment perceived by a user. The user may directly (where for example, sensing, processing, and rendering is not performed) or indirectly (where for example, transfer is performed in a manner such as using a sensor) perceive the real environment, and further enhancement processing is performed. The MR technology is to insert some virtual elements into a physical scenario, to provide a user with immersive experience in which these elements are part of the real scenario. The network device may process and transmit data (which may be referred to as XR data) generated in the XR service. For example, a network device in a cloud may perform rendering and encoding (for example, source coding) on source XR data, and transmit the XR data to an XR terminal by using a network device in a core network and/or an access network. The XR terminal provides diversified XR experience (for example, immersive experience, visual experience, interaction experience, or device experience) for the user by processing the XR data. The XR experience may be evaluated from a plurality of different dimensions, for example, including one or more of the following dimensions: image definition, image smoothness, image distortion, image stereoscopy, image black borders, image smearing, sound quality, sound effect, angle of view, freezing, artifacts, dizziness, audio and video synchronization, interaction freedom, interaction operation response speed, interaction operation precision, interaction content loading speed, terminal wearing comfort, terminal wearing fatigue, terminal battery life, terminal portability, terminal visual impairment friendliness, or the like.</p><p id="p-0056" num="0057">The data of the XR service includes one or more of VR data, AR data, MR data, video data, audio data, or picture data. A data transmission requirement of the XR service is different from data transmission requirements of an enhanced mobile broadband (eMBB) service, a massive machine type communication (mMTC) service, and an ultra-reliable low-latency communication (URLLC) service. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram of four service requirements. <figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a triangular pyramid. Four vertices of the triangular pyramid respectively represent focuses of data transmission requirements of the eMBB service, the mMTC service, the URLLC service, and the XR service. Different vertices represent different focuses of data transmission requirements of different services. The XR service may also be considered as a fourth-type service in a post-5G or 6G communication system, and may be referred to as a fourth-pole service for short. The eMBB service has a high requirement on a data rate, the mMTC service has a high requirement on coverage and a capacity, and the URLLC service has a high requirement on a latency and reliability. However, the XR service has a requirement for a low delay and a high rate, and whether the requirement of the XR service is met is generally determined depending on user experience. For example, when transmission of the XR data has a large delay or a low rate, the user may feel dizzy in viewing, resulting in poor visual experience of the user. However, user experience of network transmission of the XR data is a subjective feeling of the user, and impact on the XR data during network transmission cannot be accurately and objectively measured, so that a network operator cannot be systematically helped to perform network optimization for the XR data. Therefore, how to measure the impact on the XR data during network transmission more systematically and objectively to guide the network operator to optimize the network based on the XR data becomes an urgent problem to be resolved.</p><p id="p-0057" num="0058">An embodiment of this application provides a quality indication method for XR data transmission. In this method, transmission quality of the XR data is determined based on a performance parameter that can be obtained from a network. Objective impact on the XR data in network transmission can be systematically evaluated by using the method, to guide a network operator to maintain and optimize the network based on a requirement of the XR data.</p><p id="p-0058" num="0059">The following describes the technical solutions of this application in detail by using embodiments with reference to the accompanying drawings. The following embodiments and implementations may be combined with each other, and same or similar concepts or processes may not be described again in some embodiments. It should be understood that a function explained in this application may be implemented by using an independent hardware circuit, software running in combination with a processor/microprocessor or a general-purpose computer, an application-specific integrated circuit, and/or one or more digital signal processors. When described as a method, this application may alternatively be implemented in a computer processor and a memory coupled to the processor.</p><p id="p-0059" num="0060">For ease of understanding of embodiments of this application, some concepts or terms used in this application are first briefly described.</p><p id="p-0060" num="0061">1. Mean Opinion Score (MOS)</p><p id="p-0061" num="0062">The MOS (also referred to as a subjective average score or subjective evaluation opinion score) is a subjective quantitative method for evaluating voice quality. The MOS reflects a subjective perception of voice quality of the user. For example, a possible MOS in a 5-point scale is shown in Table 1.</p><p id="p-0062" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="offset" colwidth="56pt" align="left"/><colspec colname="1" colwidth="42pt" align="left"/><colspec colname="2" colwidth="119pt" align="center"/><thead><row><entry/><entry namest="offset" nameend="2" rowsep="1">TABLE 1</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row><row><entry/><entry>Voice quality</entry><entry>MOS</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>Excellent</entry><entry>5</entry></row><row><entry/><entry>Good</entry><entry>4</entry></row><row><entry/><entry>Accept</entry><entry>3</entry></row><row><entry/><entry>Poor</entry><entry>2</entry></row><row><entry/><entry>Bad</entry><entry>1</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0063" num="0063">2. Perceptual Objective Listening Quality Analysis (POLQA)</p><p id="p-0064" num="0064">The POLQA is a process-based voice quality measurement method that uses professional instruments to evaluate voice quality and obtain an evaluation conclusion.</p><p id="p-0065" num="0065">3. Voice Quality Indicator (VQI)</p><p id="p-0066" num="0066">The VQI (which may also be referred to as a voice quality indicator) is a voice quality evaluation method based on parameter estimation, and can obtain a voice quality score by calculating a main factor that affects voice quality. For example, a VQI value is obtained based on a frame error rate of voice data, to evaluate the voice quality.</p><p id="p-0067" num="0067">4. Video Multi-Method Assessment Fusion (VMAF)</p><p id="p-0068" num="0068">The VMAF (which may also be referred to as video multi-dimensional assessment fusion) may fuse multi-dimensional indicators (for example, a distortion degree and a distortion type) related to a video source, and obtain an assessment on video quality by using machine learning or an artificial intelligence algorithm. The VMAF can allocate a certain weight to each indicator in the multi-dimensional indicators, to reflect an advantage proportion of each indicator in the final evaluation, to obtain a more accurate evaluation score.</p><p id="p-0069" num="0069">5. Cloud Extended Reality (Cloud XR)</p><p id="p-0070" num="0070">The cloud XR (which may also be referred to as cloudification of XR) means that technologies such as cloud computing and cloud rendering are introduced into an application of the XR service, and a display output, a sound output, and the like of the cloud are encoded and compressed and then transmitted to an XR terminal by using a network.</p><p id="p-0071" num="0071">Embodiments provided in this application are applicable to a plurality of different scenarios. <figref idref="DRAWINGS">FIG. <b>4</b></figref> to <figref idref="DRAWINGS">FIG. <b>6</b></figref> are diagrams of several system architectures applicable to embodiments of this application.</p><p id="p-0072" num="0072"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram of a system network element applicable to an embodiment of this application. <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a system <b>400</b>, including a cloud server <b>410</b>, a core network and access network <b>420</b> (which may be referred to as a transmission network <b>420</b> for short, for example, an LTE, a 5G, or a 6G network), and an XR terminal <b>430</b>. The cloud server <b>410</b> may be configured to encode, decode, and render source XR data, the transmission network <b>420</b> may be configured to transmit XR data, and the XR terminal <b>430</b> provides diversified XR experience for a user by processing the XR data. It may be understood that another apparatus, for example, another terminal (for example, a mobile phone, a notebook computer, or a car) and/or a network device (for example, a relay, a Wi-Fi router, or a Wi-Fi access point), may be further included between the transmission network <b>420</b> and the XR terminal <b>430</b>. The XR terminal <b>430</b> obtains the XR data from the transmission network <b>420</b> by using the another terminal and/or the network device. Optionally, the system <b>400</b> further includes a centralized controller <b>440</b>. The centralized controller <b>440</b> may receive/collect data from one or more of the cloud server <b>410</b>, the transmission network <b>420</b>, or the XR terminal <b>430</b>, or may send data to one or more of the cloud server <b>410</b>, the transmission network <b>420</b>, or the XR terminal <b>430</b>. It may be understood that the centralized controller <b>440</b> may be deployed independently of the cloud server <b>410</b>, the transmission network <b>420</b>, and the XR terminal <b>430</b>, or may be deployed in the cloud server <b>410</b>, the transmission network <b>420</b>, or the XR terminal <b>430</b>. Alternatively, the centralized controller <b>440</b> may not be deployed, but the cloud server <b>410</b>, the transmission network <b>420</b>, or the XR terminal <b>430</b> implements a function of the centralized controller <b>440</b>.</p><p id="p-0073" num="0073"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram of another system network element applicable to an embodiment of this application. <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a system <b>500</b>, including an XR terminal <b>520</b> and another terminal <b>510</b>. The another terminal <b>510</b> is a terminal other than the XR terminal <b>520</b>, and the another terminal <b>510</b> may be an XR terminal, or may be an ordinary terminal (which may also be referred to as a non-XR terminal). The another terminal <b>510</b> may transmit XR data to the XR terminal <b>520</b>. Optionally, the system <b>500</b> further includes a centralized controller <b>530</b>. The centralized controller <b>530</b> may receive/collect data from the XR terminal <b>520</b> and/or the another terminal <b>510</b>, or may send data to the XR terminal <b>520</b> and/or the another terminal <b>510</b>. It may be understood that the centralized controller <b>530</b> may be deployed independently of the XR terminal <b>520</b> and the another terminal <b>510</b>, or may be deployed in the XR terminal <b>520</b> or the another terminal <b>510</b>. Alternatively, the centralized controller <b>530</b> may not be deployed, but the XR terminal <b>520</b> or the another terminal <b>510</b> implements a function of the centralized controller <b>530</b>.</p><p id="p-0074" num="0074"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram of another system network element applicable to an embodiment of this application. <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a system <b>600</b>, including an XR terminal <b>630</b>, a Wi-Fi router or Wi-Fi access point <b>620</b> (which may be referred to as a Wi-Fi apparatus <b>620</b> for short), and another terminal <b>610</b>. The another terminal <b>610</b> is a terminal other than the XR terminal <b>630</b>, and the another terminal <b>610</b> may be an XR terminal, or may be an ordinary terminal (which may also be referred to as a non-XR terminal). The another terminal <b>610</b> may transmit XR data to the XR terminal <b>630</b> by using the Wi-Fi apparatus <b>620</b>. Optionally, the system <b>600</b> further includes a centralized controller <b>640</b>. The centralized controller <b>640</b> may receive/collect data from one or more of the another terminal <b>610</b>, the Wi-Fi apparatus <b>620</b>, or the XR terminal <b>630</b>, or may send data to one or more of the another terminal <b>610</b>, the Wi-Fi apparatus <b>620</b>, or the XR terminal <b>630</b>. It may be understood that the centralized controller <b>640</b> may be deployed independently of the another terminal <b>610</b>, the Wi-Fi apparatus <b>620</b>, and the XR terminal <b>630</b>, or may be deployed in the another terminal <b>610</b>, the Wi-Fi apparatus <b>620</b>, or the XR terminal <b>630</b>. Alternatively, the centralized controller <b>640</b> may not be deployed, but the another terminal <b>610</b>, the Wi-Fi apparatus <b>620</b>, or the XR terminal <b>630</b> implements a function of the centralized controller <b>640</b>.</p><p id="p-0075" num="0075"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a flowchart of a communication method <b>700</b> according to an embodiment of this application. The method may be executed by a terminal (for example, an XR terminal), or may be executed by a chip, a chip system, a processor, or the like that supports the terminal in implementing the method. The method may be executed by a network device (for example, a core network device, an access network device, a Wi-Fi router, or a Wi-Fi access point), or may be executed by a chip, a chip system, a processor, or the like that supports the network device in implementing the method. The method may be executed by a server (for example, a cloud server), or may be executed by a chip, a chip system, a processor, or the like that supports the server in implementing the method. The method may be executed by a centralized controller, or may be executed by a chip, a chip system, a processor, or the like that supports the centralized controller in implementing the method. Execution bodies of parts in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> may be the same or may be different. As shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, the method <b>700</b> in this embodiment may include a part <b>710</b> and a part <b>720</b>.</p><p id="p-0076" num="0076">Part <b>710</b>: Obtain, based on delay information and transmission error information, extended reality quality indicator (XR quality data indicator/index, XQI) information corresponding to a target rate, where the XQI information indicates an XQI, and the XQI represents transmission quality of XR data. The XQI information corresponding to the target rate may also be understood as that the XQI indicated by the XQI information corresponds to the target rate. The XQI may also be referred to as a network transmission MOS, a network user experience indicator, or the like. This is not limited in the present application. The XQI represents transmission quality of the XR data in a network, and the network includes a core network and/or an access network. The delay information and the transmission error information may be delay information and transmission error information corresponding to the core network, or may be delay information and transmission error information corresponding to the access network, or may be delay information and transmission error information corresponding to the core network and the access network. Therefore, the XQI can reflect impact on transmission of the XR data in the core network and/or the access network, that is, can reflect quality of user experience on the XR service.</p><p id="p-0077" num="0077">Part <b>720</b>: Perform communication based on the XQI information. In an implementation, the performing communication based on the XQI information may be implemented as: outputting the XQI information. For example, an execution body that executes the method <b>700</b> may send the obtained XQI information to another network element in a system through a communication interface. For another example, an execution body that executes the method <b>700</b> may output, through a communication interface, the obtained XQI information to another component in a network element in which the execution body is located. In another implementation, the performing communication based on the XQI information may be implemented as: sending or receiving the XR data based on the XQI information.</p><p id="p-0078" num="0078">Because the XQI information can represent transmission quality of the XR data in a network, objective impact on the XR data in network transmission can be systematically evaluated by using the method, to guide a network operator to maintain and optimize the network based on a requirement of the XR data.</p><p id="p-0079" num="0079">In the part <b>710</b>, optionally, the delay information includes packet delay budget (PDB) information and/or delay variation information. The PDB information indicates a PDB, and the PDB indicates how long a data packet needs to be correctly transmitted. The delay variation information indicates a change of a delay. For example, if the PDB information indicates that the PDB is 10 milliseconds (ms), it indicates that the data packet needs to be correctly transmitted within 10 ms.</p><p id="p-0080" num="0080">In the part <b>710</b>, optionally, the delay information further includes packet average delay information and/or delay variance information. The average delay information indicates an average value of the delay or the PDB in a period of time. The delay variance information indicates a variance of the delay.</p><p id="p-0081" num="0081">In the part <b>710</b>, optionally, the transmission error information includes one or more of packet error rate (PER) information, block error rate (BLER) information, retransmission information, average packet loss rate information, burst packet loss rate information, or first packet response time information. The PER (which may also be referred to as a packet error rate) information indicates a ratio of a quantity of incorrectly received data packets to a total quantity of received data packets. The BLER information indicates a ratio of a quantity of incorrectly received data blocks to a total quantity of received data blocks. The retransmission information may indicate, for example, a quantity of hybrid automatic repeat request (HARQ) retransmission times, or acknowledgment response (ACK) or negative acknowledgment response (NACK) information reported by a terminal device to a base station. The average packet loss rate information may indicate a rate of packet loss in a period of time. The burst packet loss rate information may indicate a packet loss rate of a burst service from the beginning to the end. The first packet response time information may indicate time from starting to send the first packet to receiving an acknowledgment response (ACK) for the packet.</p><p id="p-0082" num="0082">In the part <b>710</b>, optionally, the target rate includes a source rate and/or a network transmission rate of the XR data.</p><p id="p-0083" num="0083">The source rate of the XR data may be understood as a data rate of an XR video source and/or audio source, or may be understood as a data output rate of the XR video source and/or audio source at a source end. For example, a source rate of 4K quality (4K resolution) XR data is 60 megabits per second (Mbps), and a source rate of 8K quality (8K resolution) XR data is 120 Mbps. The source rate of the XR data varies with a frame rate and an XR video compression rate. After receiving the XR data, an XR terminal decodes and performs corresponding processing on the received XR data, and then outputs the XR data to an output apparatus at a specific rate (which may also be understood as a data output rate of the XR data on the terminal) to present the XR data to a user in a form of video and/or audio. When the data output rate of the XR data on the terminal can match a data output rate of a source end (for example, the data output rate of the XR data on the terminal is greater than or equal to the data output rate of the source end), the output apparatus of the XR terminal can restore, on the terminal side, the resolution of the XR video source and/or audio source at the source end. For example, when the data output rate of the XR data on the terminal can reach 60 Mbps, 4K quality XR data can be restored on the terminal side. For another example, when the data output rate of the XR data on the terminal can reach 120 Mbps, 8K quality XR data can be restored on the terminal side.</p><p id="p-0084" num="0084">The network transmission rate may be understood as a transmission rate of data in an access network. The XQI information corresponding to the target rate in the part <b>710</b> may be understood as XQI information at a given target rate. When the XQI information corresponding to the target rate is obtained based on the delay information and the transmission error information, the XQI information may be obtained with reference to the target rate, or may not be obtained with reference to the target rate. This is not limited in this application. The network transmission rate affects an output effect of the XR data on the XR terminal. For example, when the network transmission rate is low, even if the XR terminal can restore the resolution of the XR video source and/or audio source at the source end, freezing and artifacts may occur in the XR data output by the XR terminal, and affect user experience.</p><p id="p-0085" num="0085">The XQI information corresponding to the target rate is reflected by using the foregoing delay information and transmission error information that represent objective impact on network transmission, so that a more flexible indicator can be provided for transmission quality of the XR data in the network, to provide a controllable and quantifiable evaluation basis for network maintenance and optimization based on an XR data requirement.</p><p id="p-0086" num="0086">In the method <b>700</b>, the obtaining, based on delay information and transmission error information, XQI information corresponding to a target rate may be: obtaining, based on the delay information and the transmission error information, an XQI corresponding to the target rate. In this case, the XQI may satisfy the following formula:</p><p id="p-0087" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>XQI=f1(delay information, transmission error information), where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0088" num="0087">&#x201c;f<b>1</b>(delay information, transmission error information)&#x201d; represents a function f<b>1</b> using the delay information and the transmission error information as independent variables. For example, the XQI may satisfy the following formula:</p><p id="p-0089" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>XQI=<i>f</i>1(delay information, transmission error information)=<i>K&#x2212;f</i>2(delay information, transmission error information), where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0090" num="0088">K represents a highest evaluation score (for example, 5) for evaluating XR data transmission quality, f<b>2</b>(delay information, transmission error information) represents a loss score (for example, a real number value greater than or equal to 0 and less than or equal to 5) of network transmission, and the loss score is represented by the function f<b>2</b> using the delay information and the transmission error information as independent variables.</p><p id="p-0091" num="0089">Optionally, the XQI information (or an XQI indicated by the XQI information) may alternatively be obtained based on the source rate, the network transmission rate, the delay information, and the transmission error information of the XR data. For example, when the network transmission rate is greater than or equal to the source rate of the XR data, the XQI is obtained according to the foregoing method. For example:</p><p id="p-0092" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>XQI=<i>f</i>1(delay information, transmission error information), or<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0093" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>XQI=<i>f</i>1(delay information, transmission error information)=<i>K&#x2212;f</i>2(delay information, transmission error information).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0094" num="0090">When the network transmission rate is less than the source rate of the XR data, the network transmission rate is also used as a factor affecting the XQI, to determine the XQI information with reference to the delay information and the transmission error information. For example, the XQI may satisfy the following formula:</p><p id="p-0095" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>XQI=<i>f</i>1(delay information, transmission error information, network transmission rate),<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0096" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>or<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0097" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>XQI=<i>f</i>1(delay information, transmission error information, network transmission rate)=<i>K&#x2212;f</i>2(delay information, transmission error information, network transmission rate), where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0098" num="0091">&#x201c;f<b>1</b>(delay information, transmission error information, network transmission rate)&#x201d; represents a function f<b>1</b> using the delay information, the transmission error information, and the network transmission rate as independent variables. K represents a highest evaluation score (for example, 5) for evaluating XR data transmission quality, f<b>2</b>(delay information, transmission error information, network transmission rate) represents a loss score (for example, a real number value greater than or equal to 0 and less than or equal to 5) of network transmission, and the loss score is represented by the function f<b>2</b> using the delay information, the transmission error information, and the network transmission rate as independent variables.</p><p id="p-0099" num="0092">Optionally, there is a correspondence between a value range of the XQI and transmission quality of the XR data and/or user experience of the XR service. User experience of the XR service may be evaluated, for example, by using one or more of the following indicators: image definition, image smoothness, image distortion, image stereoscopy, image black borders, image smearing, sound quality, sound effect, angle of view, freezing, artifacts, dizziness, audio and video synchronization, interaction freedom, interaction operation response speed, interaction operation precision, or content loading speed.</p><p id="p-0100" num="0093">For example, Table 2 shows a transmission quality level of the XR data and a level of user experience on the XR service that correspond to an XQI value range. A larger XQI value indicates better transmission quality of the XR data and better user experience on the XR service. It may be understood that the value range in Table 2 is merely an example, and the value range in Table 2 is not limited in this application.</p><p id="p-0101" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="offset" colwidth="14pt" align="left"/><colspec colname="1" colwidth="70pt" align="left"/><colspec colname="2" colwidth="63pt" align="left"/><colspec colname="3" colwidth="70pt" align="left"/><thead><row><entry/><entry namest="offset" nameend="3" rowsep="1">TABLE 2</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row><row><entry/><entry>Transmission quality </entry><entry/><entry>User experience on </entry></row><row><entry/><entry>of XR data</entry><entry>XQI value range</entry><entry>the XR service</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>Excellent</entry><entry>XQI &#x3e; 4.0</entry><entry>Very satisfied</entry></row><row><entry/><entry>Good</entry><entry>4.0 &#x2265; XQI &#x3e; 3.0</entry><entry>Satisfied</entry></row><row><entry/><entry>Accept</entry><entry>3.0 &#x2265; XQI &#x3e; 2.0</entry><entry>Average</entry></row><row><entry/><entry>Poor</entry><entry>2.0 &#x2265; XQI &#x3e; 1.0</entry><entry>Unsatisfied</entry></row><row><entry/><entry>Bad</entry><entry>1.0 &#x2265; XQI</entry><entry>Very unsatisfied</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0102" num="0094">For another example, Table 3 shows another transmission quality level of the XR data and another level of user experience on the XR service that correspond to an XQI value range. A smaller XQI value indicates better transmission quality of the XR data and better user experience on the XR service. It may be understood that the value range in Table 3 is merely an example, and the value range in Table 3 is not limited in this application.</p><p id="p-0103" num="0000"><tables id="TABLE-US-00003" num="00003"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="offset" colwidth="14pt" align="left"/><colspec colname="1" colwidth="70pt" align="left"/><colspec colname="2" colwidth="63pt" align="left"/><colspec colname="3" colwidth="70pt" align="left"/><thead><row><entry/><entry namest="offset" nameend="3" rowsep="1">TABLE 3</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row><row><entry/><entry>Transmission quality </entry><entry/><entry>User experience on </entry></row><row><entry/><entry>of XR data</entry><entry>XQI value range</entry><entry>the XR service</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>Excellent</entry><entry>1.0 &#x2265; XQI</entry><entry>Very satisfied</entry></row><row><entry/><entry>Good</entry><entry>2.0 &#x2265; XQI &#x3e; 1.0</entry><entry>Satisfied</entry></row><row><entry/><entry>Accept</entry><entry>3.0 &#x2265; XQI &#x3e; 2.0</entry><entry>Average</entry></row><row><entry/><entry>Poor</entry><entry>4.0 &#x2265; XQI &#x3e; 3.0</entry><entry>Unsatisfied</entry></row><row><entry/><entry>Bad</entry><entry>XQI &#x3e; 4.0</entry><entry>Very unsatisfied</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0104" num="0095">For another example, the XQI value range may also be real numbers ranging from 0 to 100. If the XQI is greater than 90, it indicates that user experience is very satisfied; if the XQI is greater than 70 and less than or equal to 90, it indicates that user experience is satisfied; and so on, as shown in the example in Table 4.</p><p id="p-0105" num="0000"><tables id="TABLE-US-00004" num="00004"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="offset" colwidth="14pt" align="left"/><colspec colname="1" colwidth="70pt" align="left"/><colspec colname="2" colwidth="63pt" align="left"/><colspec colname="3" colwidth="70pt" align="left"/><thead><row><entry/><entry namest="offset" nameend="3" rowsep="1">TABLE 4</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row><row><entry/><entry>Transmission quality </entry><entry/><entry>User experience on </entry></row><row><entry/><entry>of XR data</entry><entry>XQI value range</entry><entry>the XR service</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/><entry>Excellent</entry><entry>XQI &#x3e; 90</entry><entry>Very satisfied</entry></row><row><entry/><entry>Good</entry><entry>90 &#x2265; XQI &#x3e; 70</entry><entry>Satisfied</entry></row><row><entry/><entry>Accept</entry><entry>70 &#x2265; XQI &#x3e; 50</entry><entry>Average</entry></row><row><entry/><entry>Poor</entry><entry>50 &#x2265; XQI &#x3e; 30</entry><entry>Unsatisfied</entry></row><row><entry/><entry>Bad</entry><entry>30 &#x2265; XQI</entry><entry>Very unsatisfied</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0106" num="0096">In the part <b>710</b> of the method <b>700</b>, the obtaining, based on delay information and transmission error information, XQI information corresponding to a target rate may also be understood as that there is a correspondence between the XQI and a delay value indicated by the delay information and a transmission error rate indicated by the transmission error information.</p><p id="p-0107" num="0097">For example, Table 5 shows a possible correspondence between the XQI and the delay information and the transmission error information. 0 ms, 5 ms, 10 ms, 15 ms, and 20 ms in the first row of Table 5 represent five possible delay values (for example, a PDB) that may be indicated by the delay information, and 0%, 0.01%, 0.02%, 0.03%, 0.04%, 0.05%, 0.1%, and 0.2% in the first column of Table 5 represent eight possible transmission error rates (for example, PERs) that may be indicated by the transmission error information. Other values in Table 5 represent XQI values. It can be learned from Table 5 that one XQI corresponds to one delay value and one transmission error rate. For example, when a transmission error rate=0.02%, and a delay value=10 ms, a corresponding XQI=3.5118. For example, the XQI values in Table 5 may be obtained by using a method of MOS, POLQA, VQI, or VMAF, or may be obtained by using a combination of two or more methods in the MOS, POLQA, VQI, and VMAF, or may be obtained by using another method. This is not limited in this application. It may be understood that the values in Table 5 are merely examples, and the values in Table 5 are not limited in this application.</p><p id="p-0108" num="0000"><tables id="TABLE-US-00005" num="00005"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="1" colwidth="35pt" align="left"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="42pt" align="center"/><colspec colname="4" colwidth="35pt" align="center"/><colspec colname="5" colwidth="35pt" align="center"/><colspec colname="6" colwidth="35pt" align="center"/><thead><row><entry namest="1" nameend="6" rowsep="1">TABLE 5</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row><row><entry/><entry>0 ms</entry><entry>5 ms</entry><entry>10 ms</entry><entry>15 ms</entry><entry>20 ms</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="1" colwidth="35pt" align="left"/><colspec colname="2" colwidth="35pt" align="char" char="."/><colspec colname="3" colwidth="42pt" align="char" char="."/><colspec colname="4" colwidth="35pt" align="char" char="."/><colspec colname="5" colwidth="35pt" align="char" char="."/><colspec colname="6" colwidth="35pt" align="char" char="."/><tbody valign="top"><row><entry>&#x2003;&#x2009;0%</entry><entry>5</entry><entry>5</entry><entry>5</entry><entry>4.6976</entry><entry>4.364</entry></row><row><entry>0.01%</entry><entry>4.1846</entry><entry>4.1846</entry><entry>4.1846</entry><entry>3.9744</entry><entry>3.7426</entry></row><row><entry>0.02%</entry><entry>3.5118</entry><entry>3.5118</entry><entry>3.5118</entry><entry>3.3017</entry><entry>3.0698</entry></row><row><entry>0.03%</entry><entry>2.9567</entry><entry>2.9567</entry><entry>2.9567</entry><entry>2.7466</entry><entry>2.5147</entry></row><row><entry>0.04%</entry><entry>2.4988</entry><entry>2.4988</entry><entry>2.4988</entry><entry>2.2886</entry><entry>2.0568</entry></row><row><entry>0.05%</entry><entry>2.1209</entry><entry>2.1209</entry><entry>2.1209</entry><entry>1.9108</entry><entry>1.6789</entry></row><row><entry>0.10%</entry><entry>1.0202</entry><entry>1.0202</entry><entry>1.0202</entry><entry>1</entry><entry>1</entry></row><row><entry>0.20%</entry><entry>1</entry><entry>1</entry><entry>1</entry><entry>1</entry><entry>1</entry></row><row><entry namest="1" nameend="6" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0109" num="0098">Optionally, when the network transmission rate is greater than or equal to the source rate of the XR data, there is a correspondence between the XQI and the delay information and the transmission error information (for example, the correspondence shown in Table 5). When the network transmission rate is less than the source rate of the XR data, there is a correspondence between the XQI and the delay information, the transmission error information, and the network transmission rate.</p><p id="p-0110" num="0099">It may be understood that the correspondence between the XQI and the delay value and the transmission error rate may be alternatively represented by using a function. For example, the correspondence shown in Table 5 is used as an example, where x represents the delay value indicated by the delay information, y represents the transmission error rate indicated by the transmission error information, and the XQI satisfies the following formula:</p><p id="p-0111" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>XQI=(<i>p</i>1<i>+p</i>3<i>*x+p</i>5<i>*y+p</i>7<i>*x</i><sup>2</sup><i>+p</i>9<i>*y</i><sup>2</sup><i>+p</i>11<i>*x*y</i>)/(1<i>+p</i>2<i>*x+p</i>4<i>*y+p</i>6<i>*x</i><sup>2</sup><i>+p</i>8<i>*y</i><sup>2</sup><i>+p</i>10<i>*x*y</i>), where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0112" num="0100">p<b>1</b>=4.95812, p<b>2</b>=&#x2212;0.00728, p<b>3</b>=&#x2212;0.01195, p<b>4</b>=6.03596, p<b>5</b>=&#x2212;50.5809, p<b>6</b>=0.000212, p<b>7</b>=&#x2212;0.0014729, p<b>8</b>=59.1871, p<b>9</b>=238.6637, p<b>10</b>=0.01589, and p<b>11</b>=0.25696.</p><p id="p-0113" num="0101">Optionally, the XQI information in the method <b>700</b> corresponds to a first extended reality data stream and a second extended reality data stream, where the XQI information includes first XQI information and second XQI information, the first XQI information corresponds to the first extended reality data stream, and the second XQI information corresponds to the second extended reality data stream. It may also be understood as that XQIs included in the XQI information correspond to a first extended reality data stream and a second extended reality data stream, where the XQIs include a first XQI and a second XQI, the first XQI corresponds to the first extended reality data stream, and the second XQI corresponds to the second extended reality data stream. The first extended reality data stream and the second extended reality data stream may be one of the following cases.<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0102">The first extended reality data stream includes an extended reality base layer data stream, and the second extended reality data stream includes an extended reality enhancement layer data stream. The extended reality base layer data stream and the extended reality enhancement layer data stream may be extended reality data streams obtained by coding source data of the XR. The coding may be, for example, high efficiency video coding (HEVC) or scalability extension of HEVC (SHVC).</li>        <li id="ul0004-0002" num="0103">The first extended reality data stream includes an extended reality in-field of view (FOV) data stream, and the second extended reality data stream includes an extended reality out-of-FOV data stream. The extended reality in-FOV data stream and the extended reality out-of-FOV data stream may be extended reality data streams obtained by performing FOV source coding on the source data of the XR. The FOV source coding may divide the source data of the XR into an in-view part and an out-of-view part. Generally, a view angle of the FOV is about 60 degrees to 150 degrees. The in-view part corresponds to the extended reality in-FOV data stream, and the out-of-view part corresponds to the extended reality out-of-FOV data stream.</li>    </ul>    </li></ul></p><p id="p-0114" num="0104">XQIs are independently allocated to different extended reality data streams, so that extended reality data with different transmission requirements can be differentiated. Different transmission policies are separately used for an extended reality data stream with a higher priority and an extended reality data stream with a lower priority, so that XR data can be transmitted more efficiently by using limited network resources.</p><p id="p-0115" num="0105">It may be understood that the first extended reality data flow and the second extended reality data flow are merely two extended reality data flows used as examples to describe the implementation. A quantity of extended reality data flows is not limited in this application, and the quantity of the extended reality data flows may also be three or more. Correspondingly, the first XQI and the second XQI are merely two XQIs used as examples to describe the implementation. A quantity of XQIs corresponding to the extended reality data flow is not limited in this application, and the quantity of the XQIs corresponding to the extended reality data flow may also be three or more. For example, the XQI information in the method <b>700</b> may further include third XQI information corresponding to a third extended reality data flow, or it may be understood that the XQI information may further include a third XQI corresponding to a third extended reality data flow.</p><p id="p-0116" num="0106">The method <b>700</b> may further include an optional part <b>730</b>: obtaining capacity information based on the XQI information and the target rate. Optionally, the capacity information includes terminal capacity information and/or network capacity information.</p><p id="p-0117" num="0107">The terminal capacity information may be understood as an equivalent capacity of the terminal at a given target rate. For example, for a terminal i, an example in which the target rate is Ci and the XQI information indicates that an XQI of the terminal i is an XQI<sub>i </sub>is used. An equivalent capacity C<sub>eff,i </sub>of the terminal i may satisfy one of the following formulas:</p><p id="p-0118" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>C</i><sub>eff,i</sub><i>=k</i><sub>i</sub><i>*C</i><sub>i</sub>*XQI<sub>i</sub>, or<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0119" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>C</i><sub>eff,i</sub><i>=k</i><sub>i</sub><i>*C</i><sub>i</sub>*log(XQI<sub>i</sub>), where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0120" num="0108">k<sub>i </sub>is a coefficient greater than 0, and k<sub>i </sub>may be predefined, or may be configured by a network. log(XQI) represents a logarithm with base 10 or 2 of the XQI.</p><p id="p-0121" num="0109">The network capacity information may be understood as an equivalent capacity of the network when all terminals in the network are considered. For example, a network includes I terminals. An equivalent capacity of terminal i (1&#x2264;i&#x2264;I) is C<sub>eff,i</sub>, and an equivalent capacity C<sub>eff,N </sub>of the network may satisfy one of the following formulas:</p><p id="p-0122" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>C</i><sub>eff,N</sub><i>=C</i><sub>eff,1</sub><i>+C</i><sub>eff,2</sub><i>+ . . . +C</i><sub>eff,i</sub><i>+ . . . +C</i><sub>eff,I&#x2212;1</sub><i>+C</i><sub>eff,I</sub>, or<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0123" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>C</i><sub>eff,N</sub><i>=w</i><sub>1</sub><i>*C</i><sub>eff,1</sub><i>+w</i><sub>2</sub><i>*C</i><sub>eff,2</sub><i>+ . . . +w</i><sub>i</sub><i>*C</i><sub>eff,i</sub><i>+ . . . +w</i><sub>I&#x2212;1</sub><i>*C</i><sub>eff,I&#x2212;1</sub><i>+w</i><sub>I</sub><i>*C</i><sub>eff,I</sub>, where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0124" num="0110">w<sub>i </sub>represents a weighting coefficient corresponding to the terminal i, and w<sub>i </sub>may be a real number greater than or equal to 0 and less than or equal to 1.</p><p id="p-0125" num="0111">In another manner of evaluating the network capacity information, for a terminal or a user included in a network, statistics may be collected on distribution of an XQI of the terminal or the user, for example, a cumulative distribution function (CDF) of the XQI, to measure performance of supporting the XR service by the network. For example, in the CDF of the XQI, a proportion of terminals or users corresponding to the XQI may be obtained. For example, a larger XQI indicates better user experience. If a proportion of terminals or users corresponding to a large XQI is high, the network supports the XR service well. If a proportion of terminals or users corresponding to a small XQI is high, the network supports the XR service poorly.</p><p id="p-0126" num="0112">The capacity information is obtained based on the XQI information and the target rate, so that an overall network capacity can be quantitatively evaluated, and the network operator can be guided to adapt the network resource based on a capacity requirement of the XR data, to use the network resource more efficiently.</p><p id="p-0127" num="0113">The method <b>700</b> may further include an optional part <b>740</b> and an optional part <b>750</b>.</p><p id="p-0128" num="0114">Part <b>740</b>: Obtain first evaluation information and second evaluation information, where the first evaluation information indicates source quality of the XR data, and the second evaluation information indicates a capability of processing the XR data. The source quality of the XR data may be used to evaluate one or more of the following indicators of the XR video source and/or audio source: image quality definition, image smoothness, image stereoscopy, image distortion, frame rate, audio quality, or rendering effect. The capability of processing the XR data may be used to evaluate a capability of an XR terminal to process and/or display the XR data, for example, a supported FOV angle and/or refresh rate. The capability of processing the XR data may be further used to evaluate one or more of indicators such as a battery life, wearing comfort, wearing fatigue, portability, or visual impairment friendliness of the XR terminal. Optionally, the first evaluation information and the second evaluation information may be obtained by using a method of MOS, POLQA, VQI, or VMAF, or may be obtained by using a combination of two or more methods in the MOS, POLQA, VQI, and VMAF, or may be obtained by using another method. This is not limited in this application.</p><p id="p-0129" num="0115">Part <b>750</b>: Obtain third evaluation information based on the XQI information, the first evaluation information, and the second evaluation information, where the third evaluation information indicates user experience in an end-to-end process of an XR service, and the end-to-end process includes generation of the XR data, transmission of the XR data, and processing of the XR data. The first evaluation information indicates source quality of the XR data, and may be understood as evaluating quality (namely, source quality) when the XR data is generated. The second evaluation information indicates a capability of processing the XR data, and may be understood as evaluating an indicator (namely, end quality) of the XR terminal when processing the XR data. The XQI information represents transmission quality of the XR data, and may be understood as evaluating transmission quality (namely, pipe quality) of the XR data in the network. The three parts of information: the XQI information, the first evaluation information, and the second evaluation information may be independently obtained from a corresponding network element. The third evaluation information obtained based on the XQI information, the first evaluation information, and the second evaluation information can reflect user experience in an entire end-to-end process of the XR service.</p><p id="p-0130" num="0116">For example, the first evaluation information, the second evaluation information, and the third evaluation information respectively indicate the first MOS, the second MOS, and the third MOS, and the XQI information indicates the XQI. The third MOS may satisfy the following formula:</p><p id="p-0131" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Third MOS=<i>f</i>3(XQI, first MOS, second MOS), where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0132" num="0117">&#x201c;f<b>3</b>(XQI, first MOS, second MOS)&#x201d; represents a function f<b>3</b> using the XQI, the first MOS, and the second MOS as independent variables. For example, the third MOS may satisfy one of the following formulas:</p><p id="p-0133" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Third MOS=<i>f</i>3(XQI, first MOS, second MOS)=XQI+first MOS+second MOS, or<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0134" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Third MOS=<i>f</i>3(XQI, first MOS, second MOS)=<i>w</i><sub>X</sub>*XQI+<i>w</i><sub>M1</sub>*first MOS+<i>w</i><sub>M2</sub>*second MOS, where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0135" num="0118">w<sub>X</sub>, w<sub>M1</sub>, and w<sub>M2 </sub>respectively represent weighting coefficients corresponding to the XQI, the first MOS, and the second MOS, and w<sub>X</sub>, w<sub>M1</sub>, and w<sub>M2 </sub>may be real numbers greater than or equal to 0 and less than or equal to 1.</p><p id="p-0136" num="0119">Optionally, if the part <b>740</b> is executed by a centralized controller or a chip, a chip system, or a processor in a centralized controller, the centralized controller or the chip, the chip system, or the processor in the centralized controller may obtain the first evaluation information reported by the server and the second evaluation information reported by the XR terminal. In addition, the centralized controller or the chip, the chip system, or the processor in the centralized controller may further obtain the XQI information reported by the network device.</p><p id="p-0137" num="0120">User experience in the end-to-end process of the XR service can be obtained based on evaluation information about the data source, terminal, and transmission pipe of the XR service, so that an end-to-end comprehensive evaluation system can be established for the XR service, to guide the network operator to maintain and optimize the network based on the evaluation system to meet the requirement of the XR service.</p><p id="p-0138" num="0121">The method <b>700</b> may further include an optional part <b>705</b>: determining that a data type is extended reality data. Correspondingly, the part <b>705</b> may be implemented as follows: determining, based on the data type, to obtain, based on delay information and transmission error information, XQI information corresponding to a target rate, where the XQI information indicates transmission quality of the extended reality data. The determining that a data type is extended reality data may be understood as a trigger/request condition that can trigger/request obtaining the XQI information corresponding to the target rate based on the delay information and the transmission error information.</p><p id="p-0139" num="0122">In this implementation, after it is learned that the data type is the extended reality data, the XQI information indicating the transmission quality of the extended reality data is obtained based on a corresponding parameter, so that XQI-based transmission quality measurement and evaluation can be performed on the extended reality data more pertinently, to guide the network design for data of the XR type, and guide the network operator to maintain and optimize the network based on the requirement of the XR data.</p><p id="p-0140" num="0123">There may be a plurality of different implementations of determining that the data type is the extended reality data.</p><p id="p-0141" num="0124">In an implementation of determining that the data type is the extended reality data, data type information may be obtained, and it is determined, based on the data type information, that the data type is the extended reality data. For example, the data type information may indicate that the data type is the extended reality data.</p><p id="p-0142" num="0125">There may be a plurality of different implementations of obtaining the foregoing data type information.</p><p id="p-0143" num="0126">In an implementation of obtaining the data type information, when the method <b>700</b> is performed by a terminal or a component of a terminal, downlink control information (DCI) or higher layer signaling (for example, RRC signaling) from a network device may be received to obtain the data type information. The DCI may be carried on a physical downlink control channel (PDCCH) or a physical downlink shared channel (PDSCH), and the higher layer signaling may be carried on the PDCCH or the PDSCH.</p><p id="p-0144" num="0127">For example, the DCI may include an indication field indicating the data type, where the indication field includes the data type information. When the indication field indicates a predefined value, it may indicate that the data type is the extended reality data. The indication field may be a newly introduced indication field, or may be an original indication field reused in the DCI.</p><p id="p-0145" num="0128">For another example, the data type may be indicated in a DCI format, that is, the DCI format may be understood as the foregoing data type information. When the DCI is in a predefined format, it may indicate that the data type is the extended reality data.</p><p id="p-0146" num="0129">For another example, the RRC signaling may include an indication field/information element indicating the data type, where the indication field/information element includes the data type information. When the indication field/information element indicates a predefined value, it may indicate that the data type is the extended reality data. The indication field/information element may be a newly introduced indication field/information element, or may be an original indication field/information element reused in the RRC signaling.</p><p id="p-0147" num="0130">In another implementation of obtaining the data type information network, when the method <b>700</b> is performed by a network device or a component of a network device, or when the method <b>700</b> is performed by a centralized controller or a component of a centralized controller, uplink control information (UCI) or higher layer signaling (for example, RRC signaling) from a terminal may be received to obtain the data type information. The UCI may be carried on a physical uplink control channel (PUCCH) or a physical uplink shared channel (PUSCH), and the higher layer signaling may be carried on the PUCCH or the PUSCH.</p><p id="p-0148" num="0131">For example, the UCI may include an indication field indicating the data type, where the indication field includes the data type information. When the indication field indicates a predefined value, it may indicate that the data type is the extended reality data. The indication field may be a newly introduced indication field, or may be an original indication field reused in the UCI.</p><p id="p-0149" num="0132">For another example, the data type may be indicated in a UCI format, that is, the UCI format may be understood as the foregoing data type information. When the UCI is in a predefined format, it may indicate that the data type is the extended reality data.</p><p id="p-0150" num="0133">For another example, the RRC signaling may include an indication field/information element indicating the data type, where the indication field/information element includes the data type information. When the indication field/information element indicates a predefined value, it may indicate that the data type is the extended reality data. The indication field/information element may be a newly introduced indication field/information element, or may be an original indication field/information element reused in the RRC signaling.</p><p id="p-0151" num="0134">In another implementation of determining that the data type is extended real data, when the method <b>700</b> is performed by a terminal or a component of a terminal, or when the method <b>700</b> is performed by a network device or a component of a network device, or when the method <b>700</b> is performed by a centralized controller or a component of a centralized controller, the data type may be obtained based on a service characteristic of the data. For example, the data type corresponding to the data may be learned based on a data periodicity and/or a data packet size. For example, when the data periodicity is 16.7 ms or 8.3 ms, and/or when the data packet size is 0.6 megabits (Mb) to 0.65 Mb, it may be learned that the data type corresponding to the data is the extended reality data.</p><p id="p-0152" num="0135">In another implementation of determining that the data type is the extended reality data, the data type may be determined based on configuration information of a core network. For example, when sending data, the core network configures a data type of the data as extended reality data, and notifies a base station and/or a terminal of the configuration information, so that the base station and/or the terminal can determine the data type of the data.</p><p id="p-0153" num="0136"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a flowchart of another communication method <b>770</b> according to an embodiment of this application. The method may be executed by a terminal (for example, an XR terminal), or may be executed by a chip, a chip system, a processor, or the like that supports the terminal in implementing the method. The method may be executed by a network device (for example, a core network device, an access network device, a Wi-Fi router, or a Wi-Fi access point), or may be executed by a chip, a chip system, a processor, or the like that supports the network device in implementing the method. The method may be executed by a server (for example, a cloud server), or may be executed by a chip, a chip system, a processor, or the like that supports the server in implementing the method. The method may be executed by a centralized controller, or may be executed by a chip, a chip system, a processor, or the like that supports the centralized controller in implementing the method. Execution bodies of parts in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> may be the same or may be different. As shown in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, the method <b>770</b> in this embodiment may include a part <b>780</b> and a part <b>790</b>.</p><p id="p-0154" num="0137">Part <b>780</b>: Determine that a data type is extended reality data. Content of the part <b>780</b> is the same as that of the part <b>705</b> in the method <b>700</b>, and details are not described herein again.</p><p id="p-0155" num="0138">Part <b>790</b>: Report XQI information or information related to an XQI based on the foregoing data type. Optionally, the information related to the XQI includes one or more of PDB information, delay variation information, average delay information, delay variance information, PER information, BLER information, retransmission information, average packet loss rate information, burst packet loss rate information, or first packet response time information related to the extended reality data. That the data type is the extended reality data may be understood as a trigger/request condition that can trigger/request reporting of the XQI information, or trigger/request reporting of the information related to the XQI.</p><p id="p-0156" num="0139">In this implementation, after it is learned that the data type is the extended reality data, the XQI information related to the extended reality data is reported or parameter information required by the XQI is obtained, so that XQI-based transmission quality measurement and evaluation can be performed on the extended reality data more pertinently, to guide the network design for data of the XR type, and guide the network operator to maintain and optimize the network based on the requirement of the XR data.</p><p id="p-0157" num="0140">It may be understood that the method <b>770</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> may also be implemented in combination with the method <b>700</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>. For example, when the XQI information is reported in the part <b>790</b>, the part <b>710</b> in the method <b>700</b> may be performed between the part <b>780</b> and the part <b>790</b>, and to-be-reported XQI information is first obtained based on the delay information and the transmission error information before the XQI information is reported. Alternatively, the method <b>770</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> may be implemented in combination with another part (for example, one or more of the part <b>720</b>, the part <b>730</b>, the part <b>740</b>, or the part <b>750</b>) in the method <b>700</b> shown in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>. Details are not described herein again.</p><p id="p-0158" num="0141"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of another communication method <b>800</b> according to an embodiment of this application. The method may be executed by a terminal (for example, an XR terminal), or may be executed by a chip, a chip system, a processor, or the like that supports the terminal in implementing the method. The method may be executed by a network device (for example, a core network device, an access network device, a Wi-Fi router, or a Wi-Fi access point), or may be executed by a chip, a chip system, a processor, or the like that supports the network device in implementing the method. The method may be executed by a server (for example, a cloud server), or may be executed by a chip, a chip system, a processor, or the like that supports the server in implementing the method. The method may be executed by a centralized controller, or may be executed by a chip, a chip system, a processor, or the like that supports the centralized controller in implementing the method. Execution bodies of parts in <figref idref="DRAWINGS">FIG. <b>8</b></figref> may be the same or may be different. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the method <b>800</b> in this embodiment may include a part <b>840</b> and a part <b>850</b>. Content of the part <b>840</b> is the same as that of the part <b>740</b> in the method <b>700</b>, content of the part <b>850</b> is the same as that of the part <b>750</b> in the method <b>700</b>, and corresponding beneficial effects are the same as beneficial effects corresponding to the part <b>740</b> and the part <b>750</b> in the method <b>700</b>. Details are not described herein again.</p><p id="p-0159" num="0142">Optionally, the method <b>800</b> may further include a part <b>810</b> and a part <b>820</b>. Content of the part <b>810</b> is the same as that of the part <b>710</b> in the method <b>700</b>, content of the part <b>820</b> is the same as that of the part <b>720</b> in the method <b>700</b>, and corresponding beneficial effects are the same as beneficial effects corresponding to the part <b>710</b> and the part <b>720</b> in the method <b>700</b>. Details are not described herein again.</p><p id="p-0160" num="0143">Optionally, the method <b>800</b> may further include a part <b>830</b>. Content of the part <b>830</b> is the same as that of the part <b>730</b> in the method <b>700</b>, and corresponding beneficial effects are the same as beneficial effects corresponding to the part <b>730</b> in the method <b>700</b>. Details are not described herein again.</p><p id="p-0161" num="0144">Optionally, the method <b>800</b> may further include a part <b>805</b>. Content of the part <b>805</b> is the same as that of the part <b>705</b> in the method <b>700</b>, and corresponding beneficial effects are the same as beneficial effects corresponding to the part <b>705</b> in the method <b>700</b>. Details are not described herein again.</p><p id="p-0162" num="0145"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of another communication method <b>900</b> according to an embodiment of this application. The method may be executed by a terminal (for example, an XR terminal), or may be executed by a chip, a chip system, a processor, or the like that supports the terminal in implementing the method. The method may be executed by a network device (for example, a core network device, an access network device, a Wi-Fi router, or a Wi-Fi access point), or may be executed by a chip, a chip system, a processor, or the like that supports the network device in implementing the method. The method may be executed by a server (for example, a cloud server), or may be executed by a chip, a chip system, a processor, or the like that supports the server in implementing the method. The method may be executed by a centralized controller, or may be executed by a chip, a chip system, a processor, or the like that supports the centralized controller in implementing the method. Execution bodies of parts in <figref idref="DRAWINGS">FIG. <b>9</b></figref> may be the same or may be different. As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the method <b>900</b> in this embodiment may include a part <b>930</b>. Content of the part <b>930</b> is the same as that of the part <b>730</b> in the method <b>700</b>, and corresponding beneficial effects are the same as beneficial effects corresponding to the part <b>730</b> in the method <b>700</b>. Details are not described herein again.</p><p id="p-0163" num="0146">Optionally, the method <b>900</b> may further include a part <b>910</b> and a part <b>920</b>. Content of the part <b>910</b> is the same as that of the part <b>710</b> in the method <b>700</b>, content of the part <b>920</b> is the same as that of the part <b>720</b> in the method <b>700</b>, and corresponding beneficial effects are the same as beneficial effects corresponding to the part <b>710</b> and the part <b>720</b> in the method <b>700</b>. Details are not described herein again.</p><p id="p-0164" num="0147">Optionally, the method <b>900</b> may further include a part <b>940</b> and a part <b>950</b>. Content of the part <b>940</b> is the same as that of the part <b>740</b> in the method <b>700</b>, content of the part <b>950</b> is the same as that of the part <b>750</b> in the method <b>700</b>, and corresponding beneficial effects are the same as beneficial effects corresponding to the part <b>740</b> and the part <b>750</b> in the method <b>700</b>. Details are not described herein again.</p><p id="p-0165" num="0148">Optionally, the method <b>900</b> may further include a part <b>905</b>. Content of the part <b>905</b> is the same as that of the part <b>705</b> in the method <b>700</b>, and corresponding beneficial effects are the same as beneficial effects corresponding to the part <b>705</b> in the method <b>700</b>. Details are not described herein again.</p><p id="p-0166" num="0149">Corresponding to the method provided in the foregoing method embodiments, an embodiment of this application further provides a corresponding apparatus. The apparatus includes a corresponding module configured to perform the foregoing embodiments. The module may be software, hardware, or a combination of software and hardware.</p><p id="p-0167" num="0150"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram of a structure of an apparatus. The apparatus <b>1000</b> may be a network device, a terminal device, a server, or a centralized controller, or may be a chip, a chip system, or a processor that supports the network device, the terminal device, the server, or the centralized controller in implementing the foregoing method. The apparatus may be configured to implement the methods described in the foregoing method embodiments. For details, refer to the descriptions in the foregoing method embodiments.</p><p id="p-0168" num="0151">The apparatus <b>1000</b> may include one or more processors <b>1001</b>. The processor <b>1001</b> may also be referred to as a processing unit, and may implement a control function. The processor <b>1001</b> may be a general-purpose processor, a dedicated processor, or the like. For example, the processor <b>1001</b> may be a baseband processor or a central processing unit. The baseband processor may be configured to process a communication protocol and communication data. The central processing unit may be configured to control a communication apparatus (for example, a base station, a baseband chip, a terminal, a terminal chip, a DU, or a CU), execute a software program, and process data of the software program.</p><p id="p-0169" num="0152">In an optional design, the processor <b>1001</b> may alternatively store instructions and/or data <b>1003</b>, and the instructions and/or data <b>1003</b> may be run by the processor, so that the apparatus <b>1000</b> performs the methods described in the foregoing method embodiments.</p><p id="p-0170" num="0153">In another optional design, the processor <b>1001</b> may include a transceiver unit configured to implement receiving and sending functions. For example, the transceiver unit may be a transceiver circuit, an interface, an interface circuit, or a communication interface. The transceiver circuits, the interfaces, or the interface circuits configured to implement the receiving and sending functions may be separated, or may be integrated together. The transceiver circuit, the interface, or the interface circuit may be configured to read and write code/data. Alternatively, the transceiver circuit, the interface, or the interface circuit may be configured to transmit or transfer a signal.</p><p id="p-0171" num="0154">In still another embodiment, the apparatus <b>1000</b> may include a circuit, and the circuit may implement the sending, receiving, or communication function in the foregoing method embodiments.</p><p id="p-0172" num="0155">Optionally, the apparatus <b>1000</b> may include one or more memories <b>1002</b>. The memory <b>1002</b> may store instructions <b>1004</b>, and the instructions may be run on the processor, so that the apparatus <b>1000</b> performs the methods described in the foregoing method embodiments. Optionally, the memory may further store data. Optionally, the processor may also store instructions and/or data. The processor and the memory may be separately disposed, or may be integrated together. For example, the correspondence described in the foregoing method embodiments may be stored in the memory or stored in the processor.</p><p id="p-0173" num="0156">Optionally, the apparatus <b>1000</b> may further include a transceiver <b>1005</b> and/or an antenna <b>1006</b>. The processor <b>1001</b> may be referred to as a processing unit, and control the apparatus <b>1000</b>. The transceiver <b>1005</b> may be referred to as a transceiver unit, a transceiver machine, a transceiver circuit, a transceiver apparatus, a transceiver module, or the like, and is configured to implement sending and receiving functions.</p><p id="p-0174" num="0157">Optionally, the apparatus <b>1000</b> in this embodiment of this application may be configured to perform the method described in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, <figref idref="DRAWINGS">FIG. <b>8</b></figref>, or <figref idref="DRAWINGS">FIG. <b>9</b></figref> in embodiments of this application.</p><p id="p-0175" num="0158">The processor and the transceiver in this application may be implemented in an integrated circuit (IC), an analog IC, a radio frequency integrated circuit RFIC, a mixed signal IC, an application-specific integrated circuit (ASIC), a printed circuit board (PCB), an electronic device, or the like. The processor and the transceiver may also be fabricated by using various IC process technologies, for example, a complementary metal oxide semiconductor (CMOS), an n-type metal oxide semiconductor (NMOS), a p-type metal oxide semiconductor (PMOS), a bipolar junction transistor (BJT), a bipolar CMOS (BiCMOS), silicon germanium (SiGe), and gallium arsenide (GaAs).</p><p id="p-0176" num="0159">The apparatus described in the foregoing embodiments may be a network device or a terminal device. However, a range of the apparatus described in this application is not limited thereto, and a structure of the apparatus may not be limited to <figref idref="DRAWINGS">FIG. <b>10</b></figref>. The apparatus may be an independent device, or may be a part of a larger device. For example, the apparatus may be:</p><p id="p-0177" num="0160">(1) an independent integrated circuit IC, a chip, or a chip system or subsystem;</p><p id="p-0178" num="0161">(2) a set of one or more ICs, where optionally, the IC set may further include a storage component configured to store data and/or instructions;</p><p id="p-0179" num="0162">(3) an ASIC, for example, a modem (MSM);</p><p id="p-0180" num="0163">(4) a module that can be embedded in another device;</p><p id="p-0181" num="0164">(5) a receiver, a terminal, an intelligent terminal, a cellular phone, a wireless device, a handheld device, a mobile unit, a vehicle-mounted device, a network device, a cloud device, an artificial intelligence device, a machine device, a home device, a medical device, an industrial device, or the like; or</p><p id="p-0182" num="0165">(6) others, or the like.</p><p id="p-0183" num="0166"><figref idref="DRAWINGS">FIG. <b>11</b></figref> provides a diagram of a structure of a terminal device. The terminal device is applicable to the scenario shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, <figref idref="DRAWINGS">FIG. <b>4</b></figref>, <figref idref="DRAWINGS">FIG. <b>5</b></figref>, or <figref idref="DRAWINGS">FIG. <b>6</b></figref>. For ease of description, <figref idref="DRAWINGS">FIG. <b>11</b></figref> shows only main components of the terminal device. As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the terminal device <b>1100</b> includes a processor, a memory, a control circuit, an antenna, and an input/output apparatus. The processor is mainly configured to: process a communication protocol and communication data, control the entire terminal, execute a software program, and process data of the software program. The memory is mainly configured to store the software program and the data. The radio frequency circuit is mainly configured to: perform conversion between a baseband signal and a radio frequency signal, and process the radio frequency signal. The antenna is mainly configured to send and receive the radio frequency signal in a form of an electromagnetic wave. The input/output apparatus, such as a touchscreen, a display, or a keyboard, is mainly configured to: receive data input by a user and output data to the user.</p><p id="p-0184" num="0167">After the terminal device is powered on, the processor may read a software program in a storage unit, parse and execute instructions of the software program, and process data of the software program. When data needs to be sent in a wireless manner, the processor performs baseband processing on the to-be-sent data, and outputs a baseband signal to the radio frequency circuit. The radio frequency circuit processes the baseband signal to obtain a radio frequency signal, and sends the radio frequency signal to the outside in an electromagnetic wave form by using the antenna. When data is sent to the terminal device, the radio frequency circuit receives the radio frequency signal through the antenna, further converts the radio frequency signal into a baseband signal, and outputs the baseband signal to the processor. The processor converts the baseband signal into data, and processes the data.</p><p id="p-0185" num="0168">For ease of description, <figref idref="DRAWINGS">FIG. <b>11</b></figref> shows only one memory and one processor. In an actual terminal device, there may be a plurality of processors and a plurality of memories. The memory may also be referred to as a storage medium, a storage device, or the like. This is not limited in this embodiment of the present application.</p><p id="p-0186" num="0169">In an optional implementation, the processor may include a baseband processor and a central processing unit. The baseband processor is mainly configured to process the communication protocol and the communication data. The central processing unit is mainly configured to control the entire terminal device, execute the software program, and process the data of the software program. The processor in <figref idref="DRAWINGS">FIG. <b>11</b></figref> is integrated with functions of the baseband processor and the central processing unit. A person skilled in the art may understand that, the baseband processor and the central processing unit may be independent processors, and are interconnected by using a technology such as a bus. A person skilled in the art may understand that the terminal device may include a plurality of baseband processors to adapt to different network standards, and the terminal device may include a plurality of central processing units to enhance processing capabilities of the terminal device, and components of the terminal device may be connected by using various buses. The baseband processor may also be expressed as a baseband processing circuit or a baseband processing chip. The central processing unit may also be expressed as a central processing circuit or a central processing chip. A function of processing the communication protocol and the communication data may be built in the processor, or may be stored in the storage unit in a form of a software program, and the processor executes the software program to implement a baseband processing function.</p><p id="p-0187" num="0170">In an example, the antenna and the control circuit that have sending and receiving functions may be considered as a transceiver unit <b>1111</b> of the terminal device <b>1100</b>, and the processor having a processing function may be considered as a processing unit <b>1112</b> of the terminal device <b>1100</b>. As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the terminal device <b>1100</b> includes the transceiver unit <b>1111</b> and the processing unit <b>1112</b>. The transceiver unit may also be referred to as a transceiver, a transceiver machine, a transceiver apparatus, or the like. Optionally, a component that is in the transceiver unit <b>1111</b> and that is configured to implement a receiving function may be considered as a receiving unit, and a component that is in the transceiver unit <b>1111</b> and that is configured to implement a sending function may be considered as a sending unit. In other words, the transceiver unit <b>1111</b> includes the receiving unit and the sending unit. For example, the receiving unit may also be referred to as a receiver machine, a receiver, a receiver circuit, or the like. The sending unit may be referred to as a transmitter machine, a transmitter, a transmitter circuit, or the like. Optionally, the receiving unit and the sending unit may be one integrated unit, or may be a plurality of independent units. The receiving unit and the sending unit may be in one geographical position, or may be distributed in a plurality of geographical positions.</p><p id="p-0188" num="0171">As shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, another embodiment of this application provides an apparatus <b>1200</b>. The apparatus may be a terminal, a network device, a server, or a centralized controller, or may be a component (for example, an integrated circuit or a chip) of a terminal, a network device, a server, or a centralized controller. Alternatively, the apparatus may be another communication module configured to implement the methods in the method embodiments of this application. The apparatus <b>1200</b> may include a processing module <b>1202</b> (or referred to as a processing unit). Optionally, the apparatus <b>1200</b> may further include a transceiver module <b>1201</b> (or referred to as a transceiver unit or a communication interface) and a storage module <b>1203</b> (or referred to as a storage unit).</p><p id="p-0189" num="0172">In an embodiment, one or more modules in <figref idref="DRAWINGS">FIG. <b>12</b></figref> may be implemented by one or more processors, or may be implemented by one or more processors and memories, or may be implemented by one or more processors and transceivers, or may be implemented by one or more processors, memories, and transceivers. This is not limited in this embodiment of this application. The processor, the memory, and the transceiver may be disposed separately, or may be integrated.</p><p id="p-0190" num="0173">The apparatus has a function of implementing the terminal described in embodiments of this application. For example, the apparatus includes a corresponding module, unit, or means used for the terminal to perform the steps that are related to the terminal and that are described in embodiments of this application. The function, the unit, or the means may be implemented by software or hardware, may be implemented by hardware executing corresponding software, or may be implemented by a combination of software and hardware. For details, refer to the corresponding descriptions in the foregoing corresponding method embodiments. Alternatively, the apparatus has a function of implementing the network device described in embodiments of this application. For example, the apparatus includes a corresponding module, unit, or means used for the network device to perform the steps that are related to the network device and that are described in embodiments of this application. The function, the unit, or the means may be implemented by software or hardware, may be implemented by hardware executing corresponding software, or may be implemented by a combination of software and hardware. For details, refer to the corresponding descriptions in the foregoing corresponding method embodiments.</p><p id="p-0191" num="0174">Optionally, the modules in the apparatus <b>1200</b> in this embodiment of this application may be configured to perform the method described in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, <figref idref="DRAWINGS">FIG. <b>8</b></figref>, or <figref idref="DRAWINGS">FIG. <b>9</b></figref> in embodiments of this application.</p><p id="p-0192" num="0175">In an embodiment, the apparatus <b>1200</b> may include a processing module <b>1202</b> and a transceiver module <b>1201</b>. The processing module <b>1202</b> is configured to: obtain, based on delay information and transmission error information, XQI information corresponding to a target rate, where the XQI information indicates transmission quality of the extended reality data. The processing module <b>1202</b> is further configured to control the transceiver module <b>1201</b> to perform communication based on the XQI information. For example, the processing module <b>1202</b> may be configured to control the transceiver module <b>1201</b> to output the XQI information. For another example, the processing module <b>1202</b> may be configured to control, based on the XQI information, the transceiver module <b>1201</b> to send or receive XR data.</p><p id="p-0193" num="0176">Because the XQI information can represent transmission quality of the XR data in a network, objective impact on the XR data in network transmission can be systematically evaluated by using the apparatus, to guide a network operator to maintain and optimize the network based on a requirement of the XR data.</p><p id="p-0194" num="0177">Optionally, the delay information includes PDB information and/or delay variation information.</p><p id="p-0195" num="0178">Optionally, the transmission error information includes one or more of PER information, BLER information, or retransmission information.</p><p id="p-0196" num="0179">Optionally, the target rate includes a source rate and/or a network transmission rate of the extended reality data.</p><p id="p-0197" num="0180">Optionally, the XQI information corresponds to a first extended reality data stream and a second extended reality data stream. The first extended reality data stream includes an extended reality base layer data stream, and the second extended reality data stream includes an extended reality enhancement layer data stream. Alternatively, the first extended reality data stream includes an extended reality in-FOV data stream, and the second extended reality data stream includes an extended reality out-of-FOV data stream. Further optionally, the XQI information includes first XQI information and second XQI information, the first XQI information corresponds to the first extended reality data stream, and the second XQI information corresponds to the second extended reality data stream.</p><p id="p-0198" num="0181">In some implementations of the apparatus <b>1200</b>, the processing module <b>1202</b> is further configured to obtain capacity information based on the XQI information and the target rate, and the capacity information includes terminal capacity information and/or network capacity information.</p><p id="p-0199" num="0182">In some implementations of the apparatus <b>1200</b>, the processing module <b>1202</b> is further configured to: obtain first evaluation information and second evaluation information, and obtain third evaluation information based on the XQI information, the first evaluation information, and the second evaluation information. The first evaluation information indicates source quality of the extended reality data, the second evaluation information indicates a capability of processing the extended reality data, the third evaluation information indicates user experience in an end-to-end process of an extended reality service, and the end-to-end process includes generation of the extended reality data, transmission of the extended reality data, and processing of the extended reality data.</p><p id="p-0200" num="0183">In some implementations of the apparatus <b>1200</b>, the processing module <b>1202</b> is further configured to determine that a data type is extended reality data. That the processing module <b>1202</b> is configured to: obtain, based on delay information and transmission error information, XQI information corresponding to a target rate is specifically implemented as follows: The processing module <b>1202</b> is configured to: determine, based on the data type, to obtain, based on delay information and transmission error information, XQI information corresponding to a target rate.</p><p id="p-0201" num="0184">In an implementation of that the processing module <b>1202</b> is configured to determine that the data type is the extended reality data, the processing module <b>1202</b> is further configured to: obtain data type information, and determine, based on the data type information, that the data type is the extended reality data. For example, the transceiver module <b>1201</b> may be configured to receive DCI or higher layer signaling, and the processing module <b>1202</b> may be configured to obtain the data type information based on the DCI or the higher layer signaling. For another example, the transceiver module <b>1201</b> may be configured to receive UCI or higher layer signaling, and the processing module <b>1202</b> may be configured to obtain the data type information based on the UCI or the higher layer signaling.</p><p id="p-0202" num="0185">In another implementation of that the processing module <b>1202</b> is configured to determine that the data type is the extended reality data, the processing module <b>1202</b> is configured to: determine, based on a service characteristic of the data, that the data type is the extended reality data.</p><p id="p-0203" num="0186">In another implementation of that the processing module <b>1202</b> is configured to determine that the data type is the extended reality data, the processing module <b>1202</b> is configured to: determine, based on configuration information of a core network, that the data type is the extended reality data.</p><p id="p-0204" num="0187">In another implementation, the apparatus <b>1200</b> may include a processing module <b>1202</b> and a transceiver module <b>1201</b>. The processing module <b>1202</b> is configured to determine that a data type is extended reality data. The processing module <b>1202</b> is further configured to control, based on the data type, the transceiver module <b>1201</b> to report XQI information or report information related to an XQI. Optionally, the information related to the XQI includes one or more of PDB information, delay variation information, average delay information, delay variance information, PER information, BLER information, retransmission information, average packet loss rate information, burst packet loss rate information, or first packet response time information related to the extended reality data.</p><p id="p-0205" num="0188">In some implementations of the apparatus <b>1200</b>, when the XQI information is reported, the processing module <b>1202</b> may further obtain to-be-reported XQI information based on delay information and transmission error information before the transceiver module <b>1201</b> reports the XQI information.</p><p id="p-0206" num="0189">It may be understood that, in some scenarios, some optional features in embodiments of this application may be independently implemented without depending on another feature, for example, a solution on which the optional features are currently based, to resolve a corresponding technical problem and achieve a corresponding effect. Alternatively, in some scenarios, the optional features are combined with other features based on requirements. Correspondingly, an apparatus provided in embodiments of this application may also correspondingly implement these features or functions. Details are not described herein.</p><p id="p-0207" num="0190">A person skilled in the art may further understand that various illustrative logical blocks and steps that are listed in embodiments of this application may be implemented by using electronic hardware, computer software, or a combination thereof. Whether the functions are implemented by using hardware or software depends on particular applications and a design requirement of the entire system. A person skilled in the art may use various methods to implement the functions for corresponding application, but it should not be considered that the implementation goes beyond the scope of embodiments of this application.</p><p id="p-0208" num="0191">It may be understood that, the processor in embodiments of this application may be an integrated circuit chip, and has a signal processing capability. In an implementation process, the steps in the foregoing method embodiments may be completed by using a hardware integrated logic circuit or instructions in a form of software in the processor. The foregoing processor may be a general purpose processor, a digital signal processor (DSP), an application-specific integrated circuit (ASIC), a field programmable gate array (FPGA) or another programmable logic device, a discrete gate or transistor logic device, or a discrete hardware component.</p><p id="p-0209" num="0192">The solutions described in this application may be implemented in various manners. For example, these technologies may be implemented by using hardware, software, or a combination of hardware and software. For hardware implementation, a processing unit configured to perform these technologies at a communication apparatus (for example, a base station, a terminal, a network entity, or a chip) may be implemented in one or more general-purpose processors, a DSP, a digital signal processing device, an ASIC, a programmable logic device, an FPGA, or another programmable logic apparatus, a discrete gate or transistor logic device, a discrete hardware component, or any combination thereof. The general-purpose processor may be a microprocessor. Optionally, the general-purpose processor may also be any conventional processor, controller, microcontroller, or state machine. The processor may also be implemented by a combination of computing apparatuses, such as a digital signal processor and a microprocessor, a plurality of microprocessors, one or more microprocessors with a digital signal processor core, or any other similar configuration.</p><p id="p-0210" num="0193">It may be understood that the memory in embodiments of this application may be a transitory memory or a non-transitory memory, or may include both a transitory memory and a non-transitory memory. The non-transitory memory may be a read-only memory (ROM), a programmable read-only memory (PROM), an erasable programmable read-only memory (EPROM), an electrically erasable programmable read-only memory (EEPROM), or a flash memory. The transitory memory may be a random access memory (RAM) and is used as an external cache. By way of example but not limitative description, many forms of RAMs are available, for example, a static random access memory (SRAM), a dynamic random access memory (DRAM), a synchronous dynamic random access memory (SDRAM), a double data rate synchronous dynamic random access memory (DDR SDRAM), an enhanced synchronous dynamic random access memory (ESDRAM), a synchlink dynamic random access memory (SLDRAM), and a direct rambus random access memory (DR RAM). It should be noted that the memory in the system and the method described in this specification is intended to include, but not limited to, these memories and any memory of another proper type.</p><p id="p-0211" num="0194">This application further provides a computer-readable medium. The computer-readable medium stores a computer program. When the computer program is executed by a computer, functions of any one of the foregoing method embodiments are implemented.</p><p id="p-0212" num="0195">This application further provides a computer program product. When the computer program product is executed by a computer, a function of any one of the foregoing method embodiments is implemented.</p><p id="p-0213" num="0196">All or some of the foregoing embodiments may be implemented by using software, hardware, firmware, or any combination thereof. When the software is used to implement the embodiments, all or some of the embodiments may be implemented in a form of a computer program product. The computer program product includes one or more computer instructions. When the computer instructions are loaded and executed on a computer, all or some of the procedures or functions according to embodiments of this application are generated. The computer may be a general-purpose computer, a dedicated computer, a computer network, or another programmable apparatus. The computer instructions may be stored in a computer-readable storage medium or may be transmitted from a computer-readable storage medium to another computer-readable storage medium. For example, the computer instructions may be transmitted from a web site, computer, server, or data center to another web site, computer, server, or data center in a wired (for example, a coaxial cable, an optical fiber, or a digital subscriber line (DSL)) or wireless (for example, infrared, radio, or microwave) manner. The computer-readable storage medium may be any usable medium accessible by a computer, or a data storage device, such as a server or a data center, integrating one or more usable media. The usable medium may be a magnetic medium (for example, a floppy disk, a hard disk, or a magnetic tape), an optical medium (for example, a high density digital video disc (DVD)), a semiconductor medium (for example, a solid state drive (SSD)), or the like.</p><p id="p-0214" num="0197">It may be understood that &#x201c;an embodiment&#x201d; mentioned in the entire specification means that particular features, structures, or characteristics related to the embodiment are included in at least one embodiment of this application. Therefore, embodiments in the entire specification do not necessarily refer to a same embodiment. In addition, these particular features, structures, or characteristics may be combined in one or more embodiments in any appropriate manner. It may be understood that sequence numbers of the foregoing processes do not mean an execution sequence in various embodiments of this application. The execution sequence of the processes should be determined based on functions and internal logic of the processes, and should not be construed as any limitation on the implementation processes of embodiments of this application.</p><p id="p-0215" num="0198">It may be understood that, in this application, &#x201c;when&#x201d; and &#x201c;if&#x201d; mean that an apparatus performs corresponding processing in an objective situation, but do not constitute a limitation on time, do not require that the apparatus have a determining action during implementation, and do not mean any other limitation.</p><p id="p-0216" num="0199">&#x201c;Simultaneously&#x201d; in this application may be understood as being at a same time point, may be understood as being within a time period, or may be understood as being within a same periodicity.</p><p id="p-0217" num="0200">A person skilled in the art may understand that first, second, and various reference numerals in this application are for distinguishing only for ease of description, and are not used to limit the scope of embodiments of this application. A specific value of a numeral (which may also be referred to as an index), a specific value of a quantity, and a position in this application are only used as an example, but are not unique representation forms, and are not used to limit the scope of embodiments of this application. First, second, and various reference numerals in this application are also for distinguishing only for ease of description, and are not used to limit the scope of embodiments of this application.</p><p id="p-0218" num="0201">In this application, unless otherwise specified, an element represented in a singular form is intended to represent &#x201c;one or more&#x201d;, but is not intended to represent &#x201c;one and only one&#x201d;. In this application, unless otherwise specified, &#x201c;at least one&#x201d; is intended to represent &#x201c;one or more&#x201d;, and &#x201c;a plurality of&#x201d; is intended to represent &#x201c;two or more&#x201d;.</p><p id="p-0219" num="0202">In addition, the terms &#x201c;system&#x201d; and &#x201c;network&#x201d; are usually used interchangeably in this specification. The term &#x201c;and/or&#x201d; in this specification describes only an association relationship for describing associated objects and represents that three relationships may exist. For example, A and/or B may represent the following three cases: Only A exists, both A and B exist, and only B exists. A may be singular or plural, and B may be singular or plural. The character &#x201c;/&#x201d; usually indicates an &#x201c;or&#x201d; relationship between associated objects.</p><p id="p-0220" num="0203">The term &#x201c;at least one of&#x201d; in this specification indicates all or any combination of listed items. For example, &#x201c;at least one of A, B, and C&#x201d; may indicate the following six cases: Only A exists, only B exists, only C exists, both A and B exist, both B and C exist, and A, B and C all exist. A may be singular or plural, B may be singular or plural, and C may be singular or plural.</p><p id="p-0221" num="0204">It may be understood that, in embodiments of this application, &#x201c;B corresponding to A&#x201d; indicates that B is associated with A, and B may be determined based on A. However, it should be further understood that determining B based on A does not mean that B is determined based on only A. B may alternatively be determined based on A and/or other information.</p><p id="p-0222" num="0205">The correspondences shown in the tables in this application may be configured, or may be predefined. Values of the information in the tables are merely examples, and other values may be configured. This is not limited in this application. When a correspondence between information and each parameter is configured, not all correspondences shown in the tables need to be configured. For example, in the tables in this application, correspondences shown in some rows may alternatively not be configured. For another example, proper deformations and adjustments such as splitting and combination may be performed based on the foregoing tables. Names of the parameters shown in titles of the foregoing tables may alternatively be other names that can be understood by a communication apparatus, and values or representation manners of the parameters may alternatively be other values or representation manners that can be understood by the communication apparatus. During implementation of the foregoing tables, another data structure, such as an array, a queue, a container, a stack, a linear table, a pointer, a linked list, a tree, a graph, a structure, a class, a pile, or a hash table, may alternatively be used.</p><p id="p-0223" num="0206">&#x201c;Predefine&#x201d; in this application may be understood as &#x201c;define&#x201d;, &#x201c;predefine&#x201d;, &#x201c;store&#x201d;, &#x201c;pre-store&#x201d;, &#x201c;pre-negotiate&#x201d;, &#x201c;pre-configure&#x201d;, &#x201c;solidify&#x201d;, or &#x201c;pre-burn&#x201d;.</p><p id="p-0224" num="0207">A person of ordinary skill in the art may understand that units and algorithm steps in the examples described with reference to embodiments disclosed in this specification can be implemented by electronic hardware or a combination of computer software and electronic hardware. Whether the functions are executed by hardware or software depends on particular applications and design constraints of the technical solutions. A person skilled in the art may use different methods to implement the described functions for each particular application, but it should not be considered that the implementation goes beyond the scope of this application.</p><p id="p-0225" num="0208">A person of ordinary skill in the art may understand that, for a purpose of convenient and brief descriptions, for a detailed working process of the foregoing system, apparatus, and unit, refer to a corresponding process in the foregoing method embodiments. Details are not described herein again.</p><p id="p-0226" num="0209">It may be understood that the system, apparatus, and method described in this application may alternatively be implemented in another manner. For example, the described apparatus embodiment is merely an example. For example, division into the units is merely logical function division and may be other division during actual implementation. For example, a plurality of units or components may be combined or integrated into another system, or some features may be ignored or not performed. In addition, the displayed or discussed mutual couplings or direct couplings or communication connections may be implemented by using some interfaces. The indirect couplings or communication connections between the apparatuses or units may be implemented in electronic, mechanical, or other forms.</p><p id="p-0227" num="0210">The units described as separate parts may or may not be physically separate, and parts displayed as units may or may not be physical units, may be located in one position, or may be distributed on a plurality of network units. Some or all of the units may be selected based on actual requirements to achieve the objectives of the solutions of embodiments.</p><p id="p-0228" num="0211">In addition, functional units in embodiments of this application may be integrated into one processing unit, or each of the units may exist alone physically, or two or more units are integrated into one unit.</p><p id="p-0229" num="0212">When the functions are implemented in the form of a software functional unit and sold or used as an independent product, the functions may be stored in a computer-readable storage medium. Based on such an understanding, the technical solutions of this application essentially, or the part contributing to a current technology, or some of the technical solutions may be implemented in a form of a software product. The computer software product is stored in a storage medium, and includes instructions for instructing a computer device (which may be a personal computer, a server, a network device, or the like) to perform all or some of the steps of the methods described in the embodiments of this application. The foregoing storage medium includes any medium that can store program code, such as a USB flash drive, a removable hard disk, a read-only memory (ROM), a random access memory (RAM), a magnetic disk, or an optical disc.</p><p id="p-0230" num="0213">For same or similar parts in embodiments of this application, refer to each other. In embodiments of this application and the implementations/implementation methods in embodiments, unless otherwise specified or a logical conflict occurs, terms and/or descriptions are consistent and may be mutually referenced between different embodiments and between the implementations/implementation methods in embodiments. Technical features in the different embodiments and the implementations/implementation methods in embodiments may be combined to form a new embodiment, implementation, or implementation method according to an internal logical relationship thereof. The foregoing descriptions are implementations of this application, but are not intended to limit the protection scope of this application.</p><p id="p-0231" num="0214">The foregoing descriptions are merely implementations of this application, but are not intended to limit the protection scope of this application. Any variation or replacement readily figured out by a person skilled in the art within the technical scope disclosed in this application shall fall within the protection scope of this application.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A communication method, comprising:<claim-text>determining that a data type is extended reality data;</claim-text><claim-text>obtaining an extended reality quality indicator (XQI) information corresponding to a target rate, the obtaining being based on the data type, a delay information, and a transmission error information, the XQI information indicating a transmission quality of the extended reality data; and</claim-text><claim-text>performing communication based on the XQI information.</claim-text><claim-text>The issue I was concerned about is that the second paragraph is somewhat hard to read. Further, it contains two actions, the determining and the obtaining. As a result, the claim does not recite the actual obtaining of the XQI information, only that it &#x201c;intends&#x201d; to obtain the XQI information.</claim-text><claim-text>The revision I proposed would perform the obtaining based on the delay information and the transmission error information, but the obtaining is also based on the data type. The obtaining is performed in the original claim IF the determining condition is satisfied. Therefore, the obtaining is based on the data type, as well as based on the other two information items.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the delay information comprises at least one of a packet delay budget (PDB) information, a delay variation information, or a packet average delay information.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the transmission error information comprises one or more of packet error rate (PER) information, block error rate (BLER) information, or retransmission information.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the target rate comprises at least one of a source rate or a network transmission rate of the extended reality data.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the XQI information corresponds to a first extended reality data stream and a second extended reality data stream, wherein:<claim-text>the first extended reality data stream comprises an extended reality base layer data stream, and the second extended reality data stream comprises an extended reality enhancement layer data stream; or</claim-text><claim-text>the first extended reality data stream comprises an extended reality in-field of view (FOV) data stream, and the second extended reality data stream comprises an extended reality out-of-FOV data stream.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the XQI information comprises first XQI information and second XQI information, the first XQI information corresponds to the first extended reality data stream, and the second XQI information corresponds to the second extended reality data stream.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the method further comprises:<claim-text>obtaining capacity information based on the XQI information and the target rate, wherein the capacity information comprises at least one of a terminal capacity information or a network capacity information.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. An apparatus, comprising:<claim-text>a memory storing instructions; and</claim-text><claim-text>at least one processor in communication with the memory, the at least one processor configured, upon execution of the instructions, to perform the following steps:</claim-text><claim-text>determine that a data type is extended reality data;</claim-text><claim-text>obtain an extended reality quality indicator (XQI) information corresponding to a target rate, the obtaining being based on the data type, a delay information, and a transmission error information, the XQI information indicating a transmission quality of the extended reality data; and</claim-text><claim-text>perform communication based on the XQI information.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the delay information comprises at least one of a packet delay budget (PDB) information, a delay variation information, or a packet average delay information.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the transmission error information comprises one or more of a packet error rate (PER) information, a block error rate (BLER) information, or a retransmission information.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the target rate comprises at least one of a source rate or a network transmission rate of the extended reality data.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the XQI information corresponds to a first extended reality data stream and a second extended reality data stream, wherein:<claim-text>the first extended reality data stream comprises an extended reality base layer data stream, and the second extended reality data stream comprises an extended reality enhancement layer data stream; or</claim-text><claim-text>the first extended reality data stream comprises an extended reality in-field of view (FOV) data stream, and the second extended reality data stream comprises an extended reality out-of-FOV data stream.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the XQI information comprises first XQI information and second XQI information, the first XQI information corresponds to the first extended reality data stream, and the second XQI information corresponds to the second extended reality data stream.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The apparatus according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the apparatus is further caused to:<claim-text>obtain capacity information based on the XQI information and the target rate, wherein the capacity information comprises at least one of a terminal capacity information or a network capacity information.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory computer readable media storing computer instructions, that configure at least one processor, upon execution of the instructions, to perform the following steps:<claim-text>determining that a data type is extended reality data;</claim-text><claim-text>obtaining an extended reality quality indicator (XQI) information corresponding to a target rate, the obtaining being based on the data type, a delay information, and a transmission error information, the XQI information indicating a transmission quality of the extended reality data; and</claim-text><claim-text>performing communication based on the XQI information.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer readable medium according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the delay information comprises at least one of a packet delay budget (PDB) information, a delay variation information, or a packet average delay information.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer readable medium according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the transmission error information comprises one or more of a packet error rate (PER) information, a block error rate (BLER) information, or a retransmission information.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer readable medium according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the target rate comprises at least one of a source rate or a network transmission rate of the extended reality data.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer readable medium according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the XQI information corresponds to a first extended reality data stream and a second extended reality data stream, wherein:<claim-text>the first extended reality data stream comprises an extended reality base layer data stream, and the second extended reality data stream comprises an extended reality enhancement layer data stream; or</claim-text><claim-text>the first extended reality data stream comprises an extended reality in-field of view (FOV) data stream, and the second extended reality data stream comprises an extended reality out-of-FOV data stream.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer readable medium according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the XQI information comprises first XQI information and second XQI information, the first XQI information corresponds to the first extended reality data stream, and the second XQI information corresponds to the second extended reality data stream.</claim-text></claim></claims></us-patent-application>
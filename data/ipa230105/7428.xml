<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007429A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007429</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17940876</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>20163151.2</doc-number><date>20200313</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>S</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>7</main-group><subgroup>303</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>2400</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">APPARATUS AND METHOD FOR RENDERING A SOUND SCENE COMPRISING DISCRETIZED CURVED SURFACES</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/EP2021/056362</doc-number><date>20210312</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17940876</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Fraunhofer-Gesellschaft zur  Foerderung  der  angewandten  Forschung e. V.</orgname><address><city>Munich</city><country>DE</country></address></addressbook><residence><country>DE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>BORSS</last-name><first-name>Christian</first-name><address><city>Erlangen</city><country>DE</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>WEFERS</last-name><first-name>Frank</first-name><address><city>Erlangen</city><country>DE</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An apparatus for rendering a sound scene having reflection objects and a sound source at a sound source position, includes: a geometry data provider for providing an analysis of the reflection objects of the sound scene to determine a reflection object represented by a first polygon and a second adjacent polygon having associated a first image source position for the first polygon and a second image source position for the second polygon, wherein the first and second image source positions result in a sequence including a first visible zone related to the first image source position, an invisible zone and a second visible zone related to the second image source position; an image source position generator for generating an additional image source position such that the additional image source position is placed between the first image source position and the second image source position; and a sound renderer for rendering the sound source at the sound source position and, additionally for rendering the sound source at the first image source position, when a listener position is located within the first visible zone, for rendering the sound source at the additional image source position, when the listener position is located within the invisible zone, or for rendering the sound source at the second image source position, when the listener position is located within the second visible zone.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="151.55mm" wi="151.72mm" file="US20230007429A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="178.65mm" wi="158.75mm" file="US20230007429A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="176.61mm" wi="153.75mm" file="US20230007429A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="168.32mm" wi="99.91mm" file="US20230007429A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="231.14mm" wi="138.60mm" file="US20230007429A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="225.21mm" wi="158.24mm" orientation="landscape" file="US20230007429A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="175.60mm" wi="152.40mm" file="US20230007429A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="202.78mm" wi="161.46mm" file="US20230007429A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="224.20mm" wi="92.20mm" orientation="landscape" file="US20230007429A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="157.06mm" wi="160.10mm" file="US20230007429A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="127.25mm" wi="86.78mm" file="US20230007429A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="98.47mm" wi="131.66mm" file="US20230007429A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="105.33mm" wi="100.08mm" file="US20230007429A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCES TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of copending International Application No. PCT/EP2021/056362, filed Mar. 12, 2021, which is incorporated herein by reference in its entirety, and additionally claims priority from European Applications No. EP 20 163 151.2, filed Mar. 13, 2020, which is which incorporated herein by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0003" num="0002">The present invention relates to audio processing and, particularly, to audio signal processing for rendering sound scenes comprising reflections modeled by image sources in the field of Geometrical Acoustics.</p><p id="p-0004" num="0003">Geometrical Acoustics are applied in auralization, i.e., real-time and offline audio rendering of auditory scenes and environments [1, 2]. This includes Virtual Reality (VR) and Augmented Reality (AR) systems like the MPEG-I 6-DoF audio renderer. For rendering complex audio scenes with six degrees of freedom (DoF), the field of Geometrical Acoustics is applied, where the propagation of sound data is modeled with models known from optics such as ray-tracing. Particularly, the reflections at walls are modeled based on models derived from optics, in which the angle of incidence of a ray that is reflected at the wall results in a reflection angle being equal to the angle of incidence.</p><p id="p-0005" num="0004">Real-time auralization systems, like the audio renderer in a Virtual Reality (VR) or Augmented Reality (AR) system, usually render early specular reflections based on geometry data of the reflective environment [1,2]. A Geometrical Acoustics method like ray-tracing [3] or the image source method [4] is then used to find valid propagation paths of the reflected sound. These methods are valid, if the reflecting planar surfaces are large compared to the wave length of incident sound [<b>1</b>]. Furthermore, the distance of the reflection point on the surface to the boundaries of the reflecting surface also has to be large compared to the wave length of incident sound.</p><p id="p-0006" num="0005">If the geometry data approximates curved surfaces by triangles or rectangles, the classic Geometrical Acoustics methods are no longer valid and artifacts become audible. The resulting &#x201c;disco ball effect&#x201d; is illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. For a moving listener or a moving sound source the visibility of the image source will alternate between visible and invisible, resulting in a permanently switching localization, timbre, and loudness.</p><p id="p-0007" num="0006">If a classic image source model is used, there is usually no mitigation technique applied for the given problem [5]. If diffuse reflections are modeled in addition to specular reflections, this will further reduce the effect, but cannot solve it. Summarizing, no solution for this problem is described in the state-of-the-art.</p><p id="p-0008" num="0007">It is an object of the present invention to provide a concept for mitigating the disco ball effect in Geometrical Acoustics or to provide a concept of rendering a sound scene that provides an improved audio quality.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0009" num="0008">According to an embodiment, an apparatus for rendering a sound scene having reflection objects and a sound source at a sound source position may have: a geometry data provider for providing an analysis of the reflection objects of the sound scene to determine a reflection object represented by a first polygon and a second adjacent polygon having associated a first image source position for the first polygon and a second image source position for the second polygon, wherein the first and second image source positions result in a sequence having a first visible zone related to the first image source position, an invisible zone and a second visible zone related to the second image source position; an image source position generator for generating an additional image source position such that the additional image source position is placed between the first image source position and the second image source position; and a sound renderer for rendering the sound source at the sound source position and, additionally for rendering the sound source at the first image source position, when a listener position is located within the first visible zone, for rendering the sound source at the additional image source position, when the listener position is located within the invisible zone, or for rendering the sound source at the second image source position, when the listener position is located within the second visible zone.</p><p id="p-0010" num="0009">According to an embodiment, a method of rendering a sound scene having reflection objects and a sound source at a sound source position may have the steps of. providing an analysis of the reflection objects of the sound scene to determine a reflection object represented by a first polygon and a second adjacent polygon having associated a first image source position for the first polygon and a second image source position for the second polygon, wherein the first and second image source positions result in a sequence having a first visible zone related to the first image source position, an invisible zone and a second visible zone related to the second image source position; generating an additional image source position such that the additional image source position is placed between the first image source position and the second image source position; and rendering the sound source at the sound source position and, additionally rendering the sound source at the first image source position, when a listener position is located within the first visible zone, rendering the sound source at the additional image source position, when the listener position is located within the invisible zone, or rendering the sound source at the second image source position, when the listener position is located within the second visible zone.</p><p id="p-0011" num="0010">Another embodiment may have a non-transitory digital storage medium having a computer program stored thereon to perform the method of rendering a sound scene having reflection objects and a sound source at a sound source position, the method having the steps of: providing an analysis of the reflection objects of the sound scene to determine a reflection object represented by a first polygon and a second adjacent polygon having associated a first image source position for the first polygon and a second image source position for the second polygon, wherein the first and second image source positions result in a sequence having a first visible zone related to the first image source position, an invisible zone and a second visible zone related to the second image source position; generating an additional image source position such that the additional image source position is placed between the first image source position and the second image source position; and rendering the sound source at the sound source position and, additionally rendering the sound source at the first image source position, when a listener position is located within the first visible zone, rendering the sound source at the additional image source position, when the listener position is located within the invisible zone, or rendering the sound source at the second image source position, when the listener position is located within the second visible zone, when said computer program is run by a computer.</p><p id="p-0012" num="0011">The present invention is based on the finding that the problems associated with the so-called disco ball effect in Geometric Acoustics can be addressed by performing an analysis of reflecting geometric objects in a sound scene in order to determine whether a reflecting geometric object results in visible zones and invisible zones. For an invisible zone, an image source position generator generates an additional image source position so that the additional image source positon is placed between two image source positions being associated with the neighboring visible zones. Furthermore, a sound renderer is configured to render the sound source at the sound source position in order to obtain an audio impression of the direct path and to additionally rendering the sound source at an image source position or an additional image source position depending on whether the listener position is located within a visible zone or an invisible zone. By this procedure, the disco ball effect in Geometrical Acoustics is mitigated. This procedure can be applied in auralization such as real-time and offline audio rendering auditory scenes and environments.</p><p id="p-0013" num="0012">In embodiments, the present invention provides several components, where one component comprises a geometry data provider or a geometry pre-processor which detects curved surfaces such as &#x201c;round edges&#x201d; or &#x201c;round corners&#x201d;. Furthermore, the embodiments refer to the image source position generator that applies an extended image source model for the identified curved surfaces, i.e., the &#x201c;round edges&#x201d; or &#x201c;round corners&#x201d;.</p><p id="p-0014" num="0013">Particularly, an edge is a boundary line of a surface, and a corner is the point where two or more converging lines meet. A round edge is a boundary line between two flat surfaces that approximate a rounded continuous surfaces by means of triangles or polygons. A round corner or rounded corner is a point that is a common vertex of several flat surfaces that approximate a rounded continuous surfaces by means of triangles or polygons. Particularly, when a Virtual Reality scene, for example, comprises an advertising pillar or advertising column, this advertising pillar or advertising column can be approximated by polygon-shaped planes such as triangle or other polygon-shaped planes, and due to the fact that the polygon planes are not infinitesimally small, invisible zones between visible zones can occur.</p><p id="p-0015" num="0014">Typically, there will exist intentional edges or corners, i.e., objects in the audio scene that are to be acoustically represented as they are, and any effects that occur due to the acoustical processing are intended. However, rounded or round corners or edges are geometric objects in the audio scene that result in the disco ball artefact or, stated in other words, that result in invisible zones that degrade the audio quality when a listener moves with respect to a fixed source from a visible zone into an invisible zone or when a fixed listener listens to a moving source that results in bringing the user into an invisible zone and then a visible zone and then an invisible zone. Or, alternatively, when both, the listener and the source move, it can be that a listener is at one point in time within a visible zone and at another point in time in an invisible zone that is only due because of the applied Geometrical Acoustics model, but has nothing to do with the real-world acoustical scene that is to be approximated as far as possible by the apparatus for rendering the sound scene or the corresponding method.</p><p id="p-0016" num="0015">The present invention is advantageous since it generates high quality audio reflections on spheres and cylinders or other curved surfaces. The extended image source model is particularly useful for primitives such as polygons approximating cylinders, spheres or other curved surfaces. Above all, the present invention results in a quickly converging iterative algorithm for computing first order reflections particularly relying on the image source tools for modeling reflections. Advantageously, a particular frequency-selective equalizer is applied in addition to a material equalizer that accounts for the frequency-selective reflection characteristic that typically is a high-pass filter that depends on a reflector diameter, for example. Furthermore, the distance attenuation, the propagation time and the frequency-selective wall absorption or wall reflection is taken into account in embodiments. Advantageously, the inventive application of an additional image source position generation &#x201c;enlightens&#x201d; the dark or invisible zones. An additional reflection model for rounded edges and corners relies on this generation of additional image sources in addition to the classical image sources associated with the polygonal planes. Advantageously, a continuous extrapolation of image sources into the &#x201c;dark&#x201d; or invisible zones is performed advantageously using the technology of frustum tracing for the purpose of calculating first order reflections. In other embodiments, the technology can also be extended to second or higher order reflection processing. However, performing the present invention for applying the calculation of first order reflections already results in high audio quality and it has been found out that performing higher order reflection calculation, although being possible, will not always justify the additional processing requirements in view of the additionally gained audio quality. The present invention provides a robust, relatively easy to implement but nevertheless powerful tool for modeling reflections in complex sound scenes having problematic or specific reflection objects that would suffer from invisible zones without the application of the present invention.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0017" num="0016">Embodiments of the present invention will be detailed subsequently referring to the appended drawings, in which:</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram of an embodiment of the apparatus for rendering a sound scene;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates the flowchart for the implementation of the image source position generator in an embodiment;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a further implementation of the image source position generator;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates another implementation of the image source position generator;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates the construction of an image source in Geometrical Acoustics;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a specific object resulting in visible zones and invisible zones;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a specific reflection object where an additional image source is placed at an additional image source position in order to &#x201c;enlighten&#x201d; the invisible zones;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a procedure applied by the geometry data provider;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an implementation of the sound renderer for rendering the sound source at the sound source position and for additionally rendering the sound source at an image source position or an additional image source position depending on the position of the listener;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates the construction of the reflection point R on an edge;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates the quiet zone related to a rounded corner; and</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates the quiet zone or quiet frustum of related to a rounded edge of e.g. <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an apparatus for rendering a sound scene having reflection objects and a sound source at a sound source position. In particular, the sound source is represented by a sound source signal that can, for example, be a mono or a stereo signal and, in the sound scene, the sound source signal is emitted at the sound source position. Furthermore, the sound scene typically has an information on a listener position, where the listener position comprises, on the one hand, a listener location within a, for example, three-dimensional space or where the listener position incurs, on the other hand, a certain orientation of the head of the listener within a three-dimensional space. A listener can be positioned, with respect to her or his ears, at a certain location in the three-dimensional space resulting in three dimensions, and the listener can also turn his head around three different axes resulting in additional three dimensions so that a six degree of freedom's Virtual Reality or Augmented Reality situation can be processed. The apparatus for rendering a sound scene comprises a geometry data provider <b>10</b>, an image source position generator <b>20</b> and a sound renderer <b>30</b> in an embodiment. The geometry data provider can be implemented as a preprocessor for performing certain operations before the actual runtime or the geometry data provider can be implemented as a geometry processor doing its operation also at runtime. However, performing the calculations of the geometry data provider in advance, i.e., before the actual Virtual Reality or Augmented Reality rendering will free a processing platform from the corresponding geometry preprocessor tasks.</p><p id="p-0031" num="0030">The image source position generator relies on the source position and the listener position and, particularly due to the fact that the listener position will change in runtime, the image source position generator will operate in runtime. The same is true for the sound renderer <b>30</b> that additionally operates in runtime using the sound source data, the listener position and additionally using the image source positions and the additional image source positions if required, i.e., if the user is placed in an invisible zone that has to be &#x201c;enlightened&#x201d; by an additional image source determined by the image source position generator in accordance with the present invention.</p><p id="p-0032" num="0031">Advantageously, the geometry data provider <b>10</b> is configured for providing an analysis of the reflection object of the sound scene to determine a specific reflection object that is represented by a first polygon and a second adjacent polygon. The first polygon has associated a first image source position and the second polygon has associated a second image source position, where these image source positions are constructed, for example, as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. These image sources are the &#x201c;classical image sources&#x201d; that are mirrored at a certain wall. However, the first and second image source positions result in a sequence comprising a first visible zone related to the first image source position, a second visible zone related to the second image source position and an invisible zone placed between the first and the second visible zone as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b> or <b>7</b></figref>, for example. The image source position generator is configured for generating the additional image source position such that the additional image source located at the additional image source position is placed between the first image source position and the second image source position. Advantageously, the image source position generator additionally generates the first image source and the second image source in a classical way, i.e., by mirroring, for example, at a certain mirroring wall or, as is the case in <figref idref="DRAWINGS">FIG. <b>6</b></figref> or <figref idref="DRAWINGS">FIG. <b>7</b></figref>, when the reflecting wall is small and does not comprise a wall point where the rectangular projection of the source crosses the wall, the corresponding wall is extended only for the purpose of image source construction.</p><p id="p-0033" num="0032">The sound renderer <b>30</b> is configured for rendering the sound source at the sound source position in order to obtain the direct sound at the listener position. Additionally, in order to also render a reflection, the sound source is rendered at the first image source position, when the listener position is located within the first visible zone. In this situation, the image source position generator does not need to generate an additional image source position, since the listener position is such that any artefacts due to the disco ball effect do not occur at all. The same is true when the listener position is located within the second visible zone associated with the second image source. However, when the listener is located within the invisible zone, then the sound renderer uses the additional image source position and does not use the first image source position and the second image source position. Instead of the &#x201c;classical&#x201d; image sources modeling the reflections at the first and the second adjacent polygons, the sound renderer only renders, for the purpose of reflection rendering, the additional image source position generated in accordance with the present invention in order to fill up or enlighten the invisible zone with sound. Any artefacts that would otherwise result in a permanently switching localization, timbre and loudness are avoided by means of the inventive processing using the image source position generator generating the additional image source between the first and the second image source position.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates the so-called disco ball effect. Particularly, the reflecting surfaces are sketched in black and are denoted by 1, 2, 3, 4, 5, 6, 7, 8. Each reflecting surface or polygon <b>1</b>, <b>2</b>, <b>3</b>, <b>4</b>, <b>5</b>, <b>6</b>, <b>7</b>, <b>8</b> is also represented by a normal vector indicated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> in a normal direction to the corresponding surface. Furthermore, each reflecting surface has associated a visible zone. The visible zone associated with a source S at a source position <b>100</b> and reflecting surface or polygon <b>1</b> is indicated at <b>71</b>. Furthermore, the corresponding visible zones for the other polygons or surfaces <b>2</b>, <b>3</b>, <b>4</b>, <b>5</b>, <b>6</b>, <b>7</b>, <b>8</b> are illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> by reference numbers <b>72</b>, <b>73</b>, <b>74</b>, <b>75</b>, <b>76</b>, <b>77</b>, <b>78</b>, for example. The visible zones are generated in such a way that only within the visible zone associated with a certain polygon, the condition of the incidence angle being equal to the reflection angle of a sound emitted by the sound source S is fulfilled. For example, polygon <b>1</b> has a quite small visible zone <b>71</b>, since the extension of polygon <b>1</b> is quite small, and since the angle of incidence being equal to the angle of reflection can only be fulfilled for reflection angles within the small visible zone <b>71</b>.</p><p id="p-0035" num="0034">Furthermore, <figref idref="DRAWINGS">FIG. <b>6</b></figref> also has a listener L located at a listener position <b>130</b>. Due to the fact that the listener L is placed within the visible zone <b>74</b> associated with polygon number <b>4</b>, the sound for the listener L is rendered using the image source <b>64</b> illustrated at S/4. This image source S/4 indicated at <b>64</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is responsible for modeling the reflection at reflecting surface or polygon number <b>4</b>, and since the listener L is located within the visible zone <b>74</b> associated with the image source for the certain wall, no artefacts would occur. However, should there by a movement of the listener in the quite zone between visible zones <b>73</b> and <b>74</b> or into the invisible zone between visible zones <b>74</b> and <b>75</b>, i.e., when the listener moves upwards or downwards, then a classical renderer would stop rendering using image source S/4, and since the listener is not located in visible zone <b>73</b> or visible zone <b>75</b> associated with image source S/3 <b>63</b> or S/565, then the renderer would not render any reflections without the present invention.</p><p id="p-0036" num="0035">In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the disco ball effect is illustrated and the reflecting surfaces are sketched in black, gray areas mark the regions where the n-th image source &#x201c;Sn&#x201d; is visible, and S marks the source at the source position, and L marks the listener at the listener position <b>130</b>. The reflecting object in <figref idref="DRAWINGS">FIG. <b>6</b></figref> being a specific reflection object could, for example, be an advertising pillar or advertising column watched from the above, the sound source, could, for example, be a car located at a certain position fixed relative to the advertising color, and the listener would, for example, be a human walking around the advertising pillar in order to look what is on the advertising pillar. The listening human will typically hear the direct sound from the car, i.e., from position <b>100</b> to the human's position <b>130</b> and, additionally, will hear the reflection at the advertising pillar.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates the construction of an image source. Particularly, and with respect to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the situation of <figref idref="DRAWINGS">FIG. <b>5</b></figref> would illustrate the construction of image source S/4. However, the wall or polygon <b>4</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref> does not even reach until the direct connection between the source position <b>100</b> and the image source position <b>64</b>. The wall <b>140</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> as being a mirroring plane for the generation of the image source <b>120</b>, based on the source <b>100</b>, is not existent in <figref idref="DRAWINGS">FIG. <b>6</b></figref> at the direct connection between the source <b>100</b> and the image source <b>120</b>. However, for the purpose of constructing image sources, a certain wall, such as polygon <b>4</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, is extended in order to have a mirroring plane for mirroring the source at the wall. Furthermore, in classical image source processing, assumptions are made, in addition to an infinite wall, that the source emits a plane wave. However, this assumption is not material for the present invention, and the same is true for the infinity of the wall, since, for the purpose of mirroring the wall, an infinite wall actually is only required for explaining the underlying mathematical model.</p><p id="p-0038" num="0037">Furthermore, <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates the condition of having same angles of incidence on the wall and of the reflection from the wall. Furthermore, the path length for the propagation path from the source to the receiver is maintained. The path length from the source to the receiver is exactly the same as the path length from the image source to the receiver, i.e., r<sub>1</sub>+r<sub>2</sub>, and the propagation time is equal to the quotient between the total path length and the sound velocity c. Furthermore, a distance attenuation of the sound pressure p being proportional to 1/r or a distance attenuation of the sound energy being proportional to 1/r<sup>2 </sup>is typically modeled by the renderer rendering the image source.</p><p id="p-0039" num="0038">Furthermore, a wall absorption/reflection behavior is modeled by means of the wall absorption or reflection coefficient &#x221d;. Advantageously, the coefficient &#x221d; is dependent on the frequency, i.e., represents a frequency-selective absorption or reflection curve H<sub>w</sub>(k) and typically has a high-pass characteristic, i.e., high frequencies are better reflected than low frequencies. This behavior is accounted for in embodiments. The strength of the image source application is that subsequent to the construction of the image source and the description of the image source with respect to the propagation time, the distance attenuation and the wall absorption, the wall <b>140</b> will be completely removed from the sound scene and is only modeled by the image source <b>120</b>.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a problematic situation, where the first polygon <b>2</b> having associated the first image source position S/2 <b>62</b> and the second polygon <b>3</b> having associated therewith the second image source position <b>63</b> or S/3 are placed with a short angle in between, and the listener <b>130</b> is placed in the invisible zone between the first visible zone <b>72</b> associated with the first image source <b>62</b> and the second visible zone <b>73</b> associated with the second image source S/3 <b>63</b>. In order to &#x201c;enlighten&#x201d; the invisible zone <b>80</b> illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, an additional image source position <b>90</b> being placed between the first image source position <b>62</b> and the second image source position <b>63</b> is generated. Instead of modeling the reflection by means of the image source <b>63</b> or the image source <b>62</b> that is constructed as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> for the classical procedure, the reflection is now modeled using the additional image source position <b>90</b> that advantageously has the same distance to the reflection point at least in a certain tolerance.</p><p id="p-0041" num="0040">For the additional image source position <b>90</b>, the same path length, propagation time, distance attenuation and wall absorption is used for the purpose of rendering the first order reflection in the invisible zone <b>80</b>. In an embodiment, a reflection point <b>92</b> is determined. The reflection point <b>92</b> is at the junction between the first polygon and the second polygon when watched from above, and typically is in a vertical position, for example in the example of the advertising pillar that is determined by the height of the listener <b>130</b> and the height of the source <b>100</b>. Advantageously, the additional image source position <b>90</b> is placed on a line connecting the listener <b>130</b> and the reflection point <b>92</b>, where this line is indicated at <b>93</b>. Furthermore, the exact position of the additional sound source <b>90</b> in the embodiment is at the intersection point of the line <b>93</b> and the connecting line <b>91</b>, connecting the image source positions <b>62</b> and <b>63</b> that have visible zones adjacent to the invisible zone <b>80</b>.</p><p id="p-0042" num="0041">However, the <figref idref="DRAWINGS">FIG. <b>7</b></figref> embodiment only illustrates a most embodiment, where the path of the additional image source position is exactly calculated. Furthermore, the specific position of the additional sound source position on the connecting line <b>92</b>, depending on the listener position <b>130</b>, is also calculated exactly. When the listener L is closer to the visible zone <b>73</b>, then the sound source <b>90</b> is closer to the classical image source position <b>63</b> and vice versa. However, locating the additional sound source position in any place between the image sound sources <b>62</b> and <b>63</b> will already improve the entire audible impression very much compared to simply suffering from the invisible zones. Although <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates the embodiment with an exact position of the additional sound source position, another procedure would be to locate the additional sound source at any place between the adjacent sound source positions <b>62</b> and <b>63</b> so that a reflection is rendered in the invisible zone <b>80</b>.</p><p id="p-0043" num="0042">Furthermore, although it is advantageous to exactly calculate the propagation time depending on the exact path length, other embodiments rely on an estimation of the path length as depending on a modified path length of image source position <b>63</b>, or a modified path length of the other adjacent image source position <b>62</b>. Furthermore, with respect to the wall absorption or wall reflection modeling, for the purpose of rendering the additional sound source position <b>90</b>, either the wall absorption of one of the adjacent polygons can be used, or an average value of both absorption coefficients if they are different from each other can be used, and even a weighted average can be applied depending on whether the listener is closer to which visible zone, so that a certain wall absorption data of the wall having the visible zone to which the user is located closer receives a higher weighting value in a weighted addition compared to the absorption/reflection data of the other adjacent wall having the visible zone being further away from the listener position.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an implementation of the procedure of the image source position generator <b>20</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In a step <b>21</b>, it is determined, whether the listener is in an visible zone such as <b>72</b> and <b>73</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> or in an invisible zone <b>80</b>. In case it is determined that the user is in the visible zone, the image source position such as S/2 <b>62</b> when the user is in zone <b>72</b> or the image source position <b>63</b> or S/3 if the user is in the visible zone <b>73</b> is determined. Then, the information on the image source position is sent to the renderer <b>30</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> as is illustrated in step <b>23</b>.</p><p id="p-0045" num="0044">Alternatively, when step <b>21</b> determines that the user is placed within the invisible zone <b>80</b>, the additional image source position <b>90</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> is determined and as soon as same is determined as illustrated in step <b>24</b>, this information on the additional image source position and if applicable, other attributes such as a path length, a propagation time, a distance attenuation or a wall absorption/reflection information as also sent to the renderer as illustrated in step <b>25</b>.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an implementation of step <b>21</b>, i.e., how in a specific embodiment, it is determined whether the listener is in an visible zone or in an invisible zone. To this end, two basic procedures are envisioned. In one basic procedure, the two neighboring visible zones <b>72</b> and <b>73</b> are calculated as frustums based on the source position <b>100</b> and the corresponding polygon and, then it is determined, whether the listener is in one of those visible frustums. When it is determined that the listener is not located within one of the frustums, as it is indicated in step <b>26</b>, then a conclusion is made that the user is in the invisible zone. Alternatively, instead of calculating two frustums describing the visible zones <b>72</b> and <b>73</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, another procedure is to actually determine the invisible frustum describing the invisible zone <b>80</b>, and if the invisible frustum is determined, then it is decided that the listener is within the invisible zone <b>80</b>, when the listener is placed within the quit frustum. When it is determined that the listener is in the invisible zone as is the result of step <b>27</b> and step <b>26</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, then the additional image source position is calculated as illustrated in step <b>24</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> or step <b>24</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an implementation of the image source position generator for calculating the additional image source position <b>90</b> in an embodiment. In a step <b>41</b>, the image source positions for the first and the second polygons, i.e., image source position <b>62</b> and <b>63</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> are calculated in a classical or standard procedure. Furthermore, as illustrated in step <b>42</b>, a reflection point on the edge or corner as has been determined by the geometric data provider <b>10</b> as being a &#x201c;rounded&#x201d; edge or corner is determined. The determination of the reflection point <b>92</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, for example, is on the crossing line between the two polygons <b>2</b> and <b>3</b> and, in case of an exact rendering also in the vertical dimension, the vertical dimension of the reflection point is determined in step <b>42</b> depending on the height of the listener and the height of the source and other attributes such as the distance of the listener and the distance of the source from the reflection point or line <b>92</b>. Furthermore, as illustrated in block <b>43</b>, a sound line is determined by connecting the listener position <b>130</b> and the reflection point <b>92</b> and by extrapolating this line further into the region where the image source positions are located and have been determined in block <b>41</b>. This sound line is illustrated by reference number <b>93</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. In step <b>44</b>, a connection line between the standard image sources as determined by block <b>41</b> is calculated, and then, as illustrated in block <b>45</b>, the intersection of the sound line <b>93</b> and the connection line <b>91</b> is determined to be the additional sound source position. It is to be noted that the order of steps as indicated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is not compulsory. Since the result of a step <b>41</b> is only required before the step <b>44</b>, the steps <b>42</b> and <b>43</b> can already be calculated before calculating step <b>41</b> and so on. The only requirement is that, for example, the step <b>42</b> has to be performed before step <b>43</b> so that the sound line, for example, can be established.</p><p id="p-0048" num="0047">Subsequently, further procedures are given in order to illustrate a further procedure of calculating the additional image source position. The extended image source model needs to extrapolate the image source position in the &#x201c;dark zone&#x201d; of the reflectors, i.e. the areas between the &#x201c;bright zones&#x201d; in which the image source is visible (see <figref idref="DRAWINGS">FIG. <b>1</b></figref>). In a first embodiment of this method, a frustum is created for each round edge and it is checked, if the listener is located within this frustum. The frustum is created as follows: For the two adjacent planes of the edge, namely the left and the right plane, one computes the image sources S<sub>L </sub>and S<sub>R </sub>by mirroring the source on the left and the right plane. From these points together with the beginning and the end point of the edge one can define four planes k&#x2208;[1,4] in Hesse-Normal form where the normal vectors {right arrow over (N<sub>k</sub>)} are pointing inside of the frustum,</p><p id="p-0049" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>{right arrow over (<i>N</i><sub>k</sub>)}<i>{right arrow over (X)}&#x2212;d</i><sub>k</sub>=0.&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0050" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>If the distance<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0051" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>l</i><sub>k</sub>={right arrow over (<i>N</i><sub>k</sub>)}<i>{right arrow over (L)}&#x2212;d</i><sub>k</sub>&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0052" num="0000">is greater than or equal zero for all 4 planes, then the listener is located within the frustum that defines the coverage area of the model for the given round edge. The invisible zone frustum is illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref> additionally showing the source position <b>100</b> and the image sources <b>61</b> and <b>62</b> belonging to the respective polygons <b>1</b> and <b>2</b>. The frustum starts on the edge between polygons <b>1</b> and <b>2</b> and opens towards the source position out from the drawing plane and into the drawing plane.</p><p id="p-0053" num="0048">In this case, one can determine the reflection point on the round edge as follows:</p><p id="p-0054" num="0000">Let {right arrow over (P)}<sub>S </sub>be the orthogonal projection of the source position {right arrow over (S)} onto the edge and {right arrow over (P)}<sub>L </sub>be the orthogonal projection of the listener position {right arrow over (L)} onto the edge. This yields the reflection point {right arrow over (R)} as follows:</p><p id="p-0055" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>d</i><sub>S</sub>=|{right arrow over (<i>P</i><sub>S</sub>)}&#x2212;<i>{right arrow over (S)}|</i>&#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0056" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>d</i><sub>L</sub>=|{right arrow over (<i>P</i><sub>L</sub>)}&#x2212;<i>{right arrow over (L)}|</i>&#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0057" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mover>      <mi>R</mi>      <semantics definitionURL="">       <mo>&#x2192;</mo>       <annotation encoding="Mathematica">"\[Rule]"</annotation>      </semantics>     </mover>     <mo>=</mo>     <mrow>      <mrow>       <mfrac>        <msub>         <mi>d</mi>         <mi>S</mi>        </msub>        <mrow>         <msub>          <mi>d</mi>          <mi>S</mi>         </msub>         <mo>+</mo>         <msub>          <mi>d</mi>          <mi>L</mi>         </msub>        </mrow>       </mfrac>       <mo>&#x2062;</mo>       <mover>        <msub>         <mi>P</mi>         <mi>L</mi>        </msub>        <mo>&#x27f6;</mo>       </mover>      </mrow>      <mo>+</mo>      <mrow>       <mfrac>        <msub>         <mi>d</mi>         <mi>L</mi>        </msub>        <mrow>         <msub>          <mi>d</mi>          <mi>S</mi>         </msub>         <mo>+</mo>         <msub>          <mi>d</mi>          <mi>L</mi>         </msub>        </mrow>       </mfrac>       <mo>&#x2062;</mo>       <mover>        <msub>         <mi>P</mi>         <mi>S</mi>        </msub>        <mo>&#x27f6;</mo>       </mover>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>5</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0058" num="0049">The construction of the reflection point is illustrate in <figref idref="DRAWINGS">FIG. <b>10</b></figref> showing the listener position L, the source position S, the projections Ps and Pl and the resulting reflection point,</p><p id="p-0059" num="0050">The computation of the coverage area of the round corners is very similar. Here, the k adjacent planes yield k image sources which together with the corner position result in a frustum that is bounded by k planes. Again, if the distances of the listener to these planes are all greater than or equal zero, the listener is located within the coverage area of the round corner. The reflection point {right arrow over (R)} is given by the corner point itself.</p><p id="p-0060" num="0051">This situation, i.e., the invisible frustum or a round corner is illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrating four image sources <b>61</b>, <b>62</b>, <b>63</b>, <b>64</b> belonging to the four polygons or planes <b>1</b>, <b>2</b>, <b>3</b>, <b>4</b>. In <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the source is located in a visible zone and not in the invisible zone starting with its tip at the corner and opening away from the four polygons.</p><p id="p-0061" num="0052">For higher-order reflections, one can extend this method according to the frustum-tracing method where one splits up each frustum into sub-frustums whenever one hits a surface, round edge, or round corner.</p><p id="p-0062" num="0053"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a further implementation of the geometric data provider. Advantageously, the geometric data provider operates as a true data provider that generates, during runtime, pre-stored data on objects in order to indicate that an object is a specific reflection object having a sequence of visible zones and an invisible zone in between. The geometric data provider can be implemented as using a geometry pre-processor that is executed once during initialization, as it does not depend on the listener or source positions. Contrary thereto, the extended image source model as applied by the image source position generator is executed at run-time and determines edge and corner reflections depending on the listener and source positions.</p><p id="p-0063" num="0054">The geometric data provider may apply a curved surface detection. The geometry data provider also termed to be the geometry-processor calculates the specific reflection object determination in advance, in an initialization procedure or a runtime. If, for example, a CAD software is used to export the geometry data, as much information about curvatures as possible is advantageously used by the geometry data provider. For example, if surfaces are constructed from round geometry primitives like spheres or cylinders or from spline interpolations, the geometry pre-processor/geometry data provider is advantageously implemented within the export routine of the CAD software and detects and uses the information from the CAD software.</p><p id="p-0064" num="0055">If no a priori knowledge about the surface curvature is available, the geometry preprocessor or data provider needs to implement a round edge and round corner detector by using only the triangle or polygon mesh. For example, this can be done by computing the angle &#x3a6; between two adjacent triangles <b>1</b>, <b>2</b> or <b>1</b><i>a</i>, <b>2</b><i>a </i>as illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Particularly, the angle is determined to be a &#x201c;face angle&#x201d; in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, where the left portion of <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a positive face angle and the right portion in <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a negative face angle. Furthermore, the small arrows illustrate the face normal in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. If the face angle is below a certain threshold, the adjacent edge in both adjacent polygons forming the edge are considered to represent a curved surface section and is marked as such. If all edges that are in connection to a corner are marked as being round, the corner is also marked as being round, and as soon as this corner becomes pertinent for the sound rendering, the functionality of the image source position generator for generating the additional image source position is activated. When, however, it is determined that a certain reflection object is not a specific reflection object but a straight forward object, where any artifacts are not expected or are even intended by a sound scene creator, the image source position generator is only used for determining the classical image source positions, but any determination of an additional image source position in accordance with the present invention is deactivated for such a reflection object.</p><p id="p-0065" num="0056"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an embodiment of the sound renderer <b>30</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The sound renderer <b>30</b> advantageously comprises a direct sound filter stage <b>31</b>, the first order reflection filter stage <b>32</b> and, optionally, a second order reflection filter stage and probably one or more higher order reflection filter stages as well.</p><p id="p-0066" num="0057">Furthermore, depending on the output format required by the sound renderer <b>30</b>, i.e., depending on whether the sound renderer outputs via headphones, via loudspeakers or just for storage or transmission in a certain format, a certain number of output adders such as a left adder <b>34</b>, a right adder <b>35</b> and a center adder <b>36</b> and probably other adders for left surround output channels, or for right surround output channels, etc. are provided. While the left and the right adders <b>34</b> and <b>35</b> are advantageously used for the purpose of headphone reproduction for virtual reality applications, for example, any other adders for the purpose of loudspeaker output in a certain output format can also be used. When, for example, an output via headphones is required, then the direct sound filter stage <b>31</b> applies head related transfer functions depending on the sound source position <b>100</b> and the listener position <b>130</b>. For the purpose of the first order reflection filter stage, corresponding head related transfer functions are applied, but now for the listener position <b>130</b> on the one hand and the additional sound source position <b>90</b> on the other hand. Furthermore, any specific propagation delays, path attenuations or reflection effects are also included within the head related transfer functions in the first order reflection filter stage <b>32</b>. For the purpose of higher order reflection filter stages, other additional sound sources are applied as well.</p><p id="p-0067" num="0058">If the output is intended for a loudspeaker set up, then the direct sound filter stage will apply other filters different from head related transfer functions such as filters that perform vector based amplitude panning, for example. In any case, each of the direct sound filter stage <b>31</b>, the first order reflection filter stage <b>32</b> and the second order reflection filter stage <b>33</b> calculates a component for each of the adder stages <b>34</b>, <b>35</b>, <b>36</b> as illustrated, and the left adder <b>34</b> then calculates the output signal for the left headphone speaker and the right adder <b>35</b> calculates the headphone signal for the right headphone speaker, and so on. In case of an output format that is different from a headphone, the left adder <b>34</b> may deliver the output signal for the left speaker and the right adder <b>35</b> may deliver the output for the right speaker. If only two speakers in a two-speaker environment are there, then the center adder <b>32</b> is not required.</p><p id="p-0068" num="0059">The inventive method avoids the disco-ball effect, that occurs when a curved surface, approximated by a discrete triangle mesh, is auralized using the classical image sound source technique [3, 4]. The novel technique avoids invisible zones, making the reflection audible. For this procedure, approximations of curved surfaces have to be identified by threshold face angle. The novel technique is an extension to the original model, with special treatment faces identified as a representation of a curvature.</p><p id="p-0069" num="0060">Classical image sound source techniques [3, 4] do not consider that the given geometry can (partially) approximate a curved surface. This causes dark zones (silence) to be casted away from edge points of adjacent faces (see <figref idref="DRAWINGS">FIG. <b>1</b></figref>). A listener moving along such a surface observes reflections to be switched on/off depending where he/she is located (enlighted/invisible zone). This causes unpleasant audible artifacts, also diminishing the degree of realism and thus the immersion. In essence, classical image source techniques fail to realistically render such scenes.</p><p id="p-0070" num="0061">While this invention has been described in terms of several embodiments, there are alterations, permutations, and equivalents which fall within the scope of this invention. It should also be noted that there are many alternative ways of implementing the methods and compositions of the present invention. It is therefore intended that the following appended claims be interpreted as including all such alterations, permutations and equivalents as fall within the true spirit and scope of the present invention.</p><heading id="h-0006" level="1">REFERENCES</heading><p id="p-0071" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0062">[1] Vorl&#xe4;nder, M. &#x201c;Auralization: fundamentals of acoustics, modelling, simulation, algorithms and acoustic virtual reality.&#x201d; <i>Springer Science </i>&#x26; <i>Business Media, </i>2007.</li>    <li id="ul0001-0002" num="0063">[2] Savioja, L., and Svensson, U. P. &#x201c;Overview of geometrical room acoustic modeling techniques.&#x201d; <i>The Journal of the Acoustical Society of America </i>138.2 (2015): 708-730.</li>    <li id="ul0001-0003" num="0064">[3] Krokstad, A., Strom, S., and S&#xf8;rsdal, S. &#x201c;Calculating the acoustical room response by the use of a ray tracing technique.&#x201d; <i>Journal of Sound and Vibration </i>8.1 (1968): 118-125.</li>    <li id="ul0001-0004" num="0065">[4] Allen, J. B., and Berkley, D. A. &#x201c;Image method for efficiently simulating small room acoustics.&#x201d; <i>The Journal of the Acoustical Society of America </i>65.4 (1979): 943-950.</li>    <li id="ul0001-0005" num="0066">[5] Borish, J. &#x201c;Extension of the image model to arbitrary polyhedra.&#x201d; <i>The Journal of the Acoustical Society of America </i>75.6 (1984): 1827-1836.</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230007429A1-20230105-M00001.NB"><img id="EMI-M00001" he="6.01mm" wi="76.20mm" file="US20230007429A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. Apparatus for rendering a sound scene comprising reflection objects and a sound source at a sound source position, comprising.<claim-text>a geometry data provider for providing an analysis of the reflection objects of the sound scene to determine a reflection object represented by a first polygon and a second adjacent polygon having associated a first image source position for the first polygon and a second image source position for the second polygon, wherein the first and second image source positions result in a sequence comprising a first visible zone related to the first image source position, an invisible zone and a second visible zone related to the second image source position;</claim-text><claim-text>an image source position generator for generating an additional image source position such that the additional image source position is placed between the first image source position and the second image source position; and</claim-text><claim-text>a sound renderer for rendering the sound source at the sound source position and, additionally<claim-text>for rendering the sound source at the first image source position, when a listener position is located within the first visible zone,</claim-text><claim-text>for rendering the sound source at the additional image source position, when the listener position is located within the invisible zone, or</claim-text><claim-text>for rendering the sound source at the second image source position, when the listener position is located within the second visible zone.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the geometry data provider is configured to retrieve pre-stored information on the reflection objects stored during an initialization stage, and wherein the image source position generator is configured to generate the additional image source position in response to the pre-stored information indicating the reflection object.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the geometry data provider is configured to detect, during runtime or during an initialization stage and using geometry data on the sound scene delivered by a computer added design application, the reflection object.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the geometry data provider is configured to detect, during runtime or during an initialization stage, as the reflection object, an object comprising a round geometry, a curved geometry, or a geometry derived from a spline interpolation.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the geometry data provider is configured<claim-text>to compute an angle between two adjacent polygons of a reflection object and to mark the two adjacent polygons as a specific pair of polygons, when the angle is below a threshold,</claim-text><claim-text>to compute a further angle between two further adjacent polygons of the reflection object and to mark the two further adjacent polygons as a further specific pair of polygons, when the further angles below the threshold, and</claim-text><claim-text>to detect the reflection object, when the further adjacent polygons and the adjacent polygons have an edge in common, or belong to the same corner.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the image source position generator is configured to analyze, whether the listener position is in the invisible zone, and to generate the additional image source position only when the listener position is located in the invisible zone.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. Apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the image source position generator is configured to determine a first geometrical range associated with the first polygon or a second geometrical range associated with the second polygon, or a third geometrical range between the first geometrical range and the second geometrical range,<claim-text>wherein the first geometrical range determines the first visible zone or wherein the second geometrical range determines the second visible zone, or wherein the third geometrical range determines the invisible zone, and</claim-text><claim-text>wherein the first or the second geometrical range is determined such that a condition that an incidence angle from the source position to the first or the second polygon is equal to a reflection angle from the first or the second polygon is fulfilled for a position in the first or the second geometrical zone, or</claim-text><claim-text>wherein the third geometrical range is determined such that the condition of a reflection angle being equal to the incidence angle is not fulfilled for a position in the invisible zone.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. Apparatus of <claim-ref idref="CLM-00006">claim 6</claim-ref>,<claim-text>wherein the image source position generator is configured to calculate a first frustum for the first polygon and to determine, whether the listener position is located within the first frustum, or</claim-text><claim-text>wherein the image source position generator is configured to calculate a second frustum for the second polygon and to determine, whether the listener position is located within the second frustum, or</claim-text><claim-text>wherein the image source position generator is configured to calculate an invisible zone frustum and to determine, whether the listener is located within the invisible zone frustum.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. Apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the image source position generator is configured to define four planes having normal vectors pointing inside the first frustum, the second frustum or the invisible zone frustum, and<claim-text>wherein the image source position generator is configured to determine, whether a distance of the listener position to each plane is greater than or equal to 0, and to detect that the listener is located within a frustum of the first frustum, the second frustum or the invisible zone frustum, when the distance of the listener to each plane is greater than or equal to 0.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the image source position generator is configured to calculate the additional image source position as a position between the first image source position and the second image source position.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. Apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the image source position generator is configured to calculate the additional image source position on a connection line between the first image source position and the second image source position.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. Apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the image source position generator is configured to calculate the additional image source position as a position on a circular arc with radius r1 around reflection point, where r1 denotes the distance between the source position and the reflection point.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. Apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the image source position generator is configured to calculate the additional image source position, so that a distance between the additional image source position and the second image source position is proportional to a distance of the listener position to the second visible zone, or so that a distance between the additional image source position and the first image source position is proportional to a distance of the listener position to the first visible zone.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. Apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>,<claim-text>wherein the image source position generator is configured to determine a reflection point using an orthogonal projection of the vector for the sound source position and an orthogonal projection of the vector for the listener position with respect to the first polygon or the second polygon or the adjacent edge between the first polygon and the second polygon or to determine a point where the first polygon and the second polygon are connected to each other as the reflection point and,</claim-text><claim-text>wherein the image source position generator is configured to determine a section point of a line connecting the listener position and the reflection point and the connection line between the first image source position and the second image source position as the additional image source position.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the image source position generator is configured to calculate the first image source position by mirroring the sound source position at a plane defined by the first polygon, or</claim-text><claim-text>wherein the image source position generator is configured to calculate the second image source position by mirroring the sound source position at a plane defined by the second polygon.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the sound renderer is configured to render the sound source so that a sound source signal is filtered using a rendering filter defined by at least one of a distance between a corresponding image sound source position to the listener position and a delay time incurred by the distance, and an absorption coefficient or a reflection coefficient associated with the first polygon or the second polygon, or a frequency-selective absorption or reflection characteristic associated with the first polygon or the second polygon.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. Apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the sound renderer is configured to render the sound source using the sound source signal and the sound source position and the listener position using a direct sound filter stage, and to render the sound source using the sound source signal and a corresponding additional sound source position and the listener position as a first order reflection in a first order reflection filter stage, wherein the corresponding image sound source position comprises the first image sound source position, or the second image sound source position or the additional image sound source position.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. Method of rendering a sound scene comprising reflection objects and a sound source at a sound source position, comprising:<claim-text>providing an analysis of the reflection objects of the sound scene to determine a reflection object represented by a first polygon and a second adjacent polygon having associated a first image source position for the first polygon and a second image source position for the second polygon, wherein the first and second image source positions result in a sequence comprising a first visible zone related to the first image source position, an invisible zone and a second visible zone related to the second image source position;</claim-text><claim-text>generating an additional image source position such that the additional image source position is placed between the first image source position and the second image source position; and</claim-text><claim-text>rendering the sound source at the sound source position and, additionally<claim-text>rendering the sound source at the first image source position, when a listener position is located within the first visible zone,</claim-text><claim-text>rendering the sound source at the additional image source position, when the listener position is located within the invisible zone, or</claim-text><claim-text>rendering the sound source at the second image source position, when the listener position is located within the second visible zone.</claim-text></claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. Non-transitory digital storage medium having a computer program stored thereon to perform the method of rendering a sound scene comprising reflection objects and a sound source at a sound source position, comprising:<claim-text>providing an analysis of the reflection objects of the sound scene to determine a reflection object represented by a first polygon and a second adjacent polygon having associated a first image source position for the first polygon and a second image source position for the second polygon, wherein the first and second image source positions result in a sequence comprising a first visible zone related to the first image source position, an invisible zone and a second visible zone related to the second image source position;</claim-text><claim-text>generating an additional image source position such that the additional image source position is placed between the first image source position and the second image source position; and</claim-text><claim-text>rendering the sound source at the sound source position and, additionally<claim-text>rendering the sound source at the first image source position, when a listener position is located within the first visible zone,</claim-text><claim-text>rendering the sound source at the additional image source position, when the listener position is located within the invisible zone, or</claim-text><claim-text>rendering the sound source at the second image source position, when the listener position is located within the second visible zone,</claim-text></claim-text><claim-text>when said computer program is run by a computer.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005103A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005103</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17773411</doc-number><date>20201030</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>19206373.3</doc-number><date>20191030</date></priority-claim><priority-claim sequence="02" kind="regional"><country>EP</country><doc-number>19219481.9</doc-number><date>20191223</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>3</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>9</main-group><subgroup>64</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>3</main-group><subgroup>4015</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>9</main-group><subgroup>64</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e79">IMAGE PROCESSOR</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>INTOPIX SA</orgname><address><city>Mont-Saint-Guibert</city><country>BE</country></address></addressbook><residence><country>BE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>DESSY</last-name><first-name>Valentin</first-name><address><city>Mont-Saint-Guibert</city><country>BE</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>ROUVROY</last-name><first-name>Gael</first-name><address><city>Mont-Saint-Guibert</city><country>BE</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>PELLEGRIN</last-name><first-name>Pascal</first-name><address><city>Mont-Saint-Guibert</city><country>BE</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2020/080609</doc-number><date>20201030</date></document-id><us-371c12-date><date>20220429</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An image processor processes an image having color pixels (R, G, B) arranged in a Bayer pattern. The image processor provides a de-correlated image composed of three types of components (Y, Cr, Cb). The image processor provides a component of the first type (Y) as a substitute for a pixel of the first type (G), whereby the component of the first type (Y) is a weighted combination of a cluster of pixels that includes the pixel of the first type (G) and neighboring pixels, wherein neighboring pixels of the second and third type (R, B) have an overall positive weighting factor corresponding to an overall addition of neighboring pixels of the second and third type (R, B) to the pixel of the first type (G). The image processor also provides a component of the second type (Cr) and a component of the third type (Cb) in similar fashion.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="122.00mm" wi="127.34mm" file="US20230005103A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="215.90mm" wi="142.75mm" file="US20230005103A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="215.98mm" wi="133.43mm" file="US20230005103A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="220.73mm" wi="137.92mm" file="US20230005103A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="225.30mm" wi="141.14mm" file="US20230005103A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="220.64mm" wi="139.95mm" file="US20230005103A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="220.98mm" wi="136.91mm" file="US20230005103A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="220.98mm" wi="141.99mm" file="US20230005103A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This is a National Stage Entry into the United States Patent and Trademark Office from International Patent Application No. PCT/EP2020/080609, filed on Oct. 30, 2020, which claims priority to European Patent Application No. EP 19206373.3, filed on Oct. 30, 2019, and to European Patent Application No. EP 19219481.9, filed on Dec. 23, 2019, the entire contents of all of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE INVENTION</heading><p id="p-0003" num="0002">An aspect of the invention relates to an image processor adapted to process an image comprising three types of color pixels arranged in a Bayer pattern. The image processor may be used, for example, as a preprocessor in an encoding system, which enhances encoding efficiency. Further aspects of the invention relate to an encoding system, a method of processing an image, and a computer program for an image processor.</p><heading id="h-0003" level="1">DESCRIPTION OF THE RELATED ART</heading><p id="p-0004" num="0003">U.S. Pat. No. 6,154,493 describes a technique for splitting raw image data into a plurality of channels including color plane difference channels. Each of these channels are separately compressed using a two-dimensional discrete wavelet transform. The compression utilizes quantization, whereby the recovery of the compressed channel data may yield a perceptually lossless image. The technique operates on images directly in their Bayer pattern form. Quantization thresholds are defined for the quantizing which may vary depending upon the channel and discrete wavelet transform (DWT) sub-band being processed.</p><heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0005" num="0004">There is a need for an improved image processing that allows obtaining a relatively highly decorrelated image on the basis of an image wherein color pixels are arranged in a Bayer pattern, which, in turn, allows higher coding efficiency providing a better image quality at a given compression rate.</p><p id="p-0006" num="0005">In accordance with an aspect of the invention as defined in claim <b>1</b>, there is provided an image processor adapted to process an image comprising three types of color pixels arranged in a Bayer pattern so as to obtain a de-correlated image composed of three types of components arranged in a pattern corresponding to the Bayer pattern,<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0006">whereby, according to the Bayer pattern, the image is a rectangular array of blocks of 2 by 2 color pixels that comprise two diagonally disposed colors pixels of a first type, a color pixel of a second type, and a color pixel of a third type; and</li>        <li id="ul0002-0002" num="0007">whereby, according to the pattern corresponding to the Bayer pattern, the de-correlated image is a rectangular array of blocks of 2 by 2 components that comprise two diagonally disposed components of a first type, a component of a second type, and a component of a third type, wherein the processor is adapted to:</li>        <li id="ul0002-0003" num="0008">provide a component of the first type in the de-correlated image as a substitute for a pixel of the first type in the image, whereby the component of the first type is a weighted combination of a cluster of pixels in the image that includes the pixel of the first type and neighboring pixels, wherein neighboring pixels of the second and third type have an overall positive weighting factor corresponding to an overall addition of neighboring pixels of the second and third type to the pixel of the first type,</li>        <li id="ul0002-0004" num="0009">provide a component of the second type in the de-correlated image as a substitute for a pixel of the second type in the image, whereby the component of the second type is a weighted combination of a cluster of pixels that includes the pixel of the second type and neighboring pixels, wherein neighboring pixels of the first type have an overall negative weighting factor corresponding to an overall subtraction of neighboring pixels of the first type from the pixel of the second type; and</li>        <li id="ul0002-0005" num="0010">provide a component of the third type in the de-correlated image as a substitute for a pixel of the third type in the image, whereby the component of the third type is a weighted combination of a cluster of pixels that includes the pixel of the third type and neighboring pixels, wherein neighboring pixels of the first type have an overall negative weighting factor corresponding to an overall subtraction of neighboring pixels of the first type from the pixel of the third type.</li>    </ul>    </li></ul></p><p id="p-0007" num="0011">In accordance with further aspects of the invention as defined in claims <b>12</b>, <b>14</b>, and <b>15</b>, there are provided an encoding system, a method of processing an image, and a computer program product, respectively.</p><p id="p-0008" num="0012">An image processor as defined hereinbefore may effectively decorrelate an image comprising three types of color pixels arranged in a Bayer pattern, such as, for example, an image produced by an image sensor. The three types of color pixels may be, for example, red, green, and blue, whereby green pixels occur twice as much as red and blue pixels. As another example, the three types of color pixels may be, for example, yellow, cyan, and magenta, or may be in accordance with any other color scheme. Since the image processor efficiently decorrelates an image of the type concerned, a decorrelated image produced thereby can efficiently be encoded. This allows attaining a given image quality with an encoded image that comprises a relatively small amount of data. Stated otherwise, the encoded image has relatively good quality for a given amount of data that the encoded image may comprise. Nonetheless, the image processor need not introduce any loss of information. That is, the image in its original form may perfectly be reconstructed on the basis of the decorrelated image produced by the image processor.</p><p id="p-0009" num="0013">For the purpose of illustration, some embodiments of the invention are described in detail with reference to accompanying drawings. In this description, additional features will be presented, some of which are defined in the dependent claims, and advantages will be apparent.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of a camera.</p><p id="p-0011" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of a raw image provided by an image sensor in the camera.</p><p id="p-0012" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of an image processor in the camera.</p><p id="p-0013" num="0017"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram of a decorrelated image provided by a decorrelation module of the image processor on the basis of the raw image.</p><p id="p-0014" num="0018"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram of the decorrelation module that provides the decorrelated image.</p><p id="p-0015" num="0019"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a conceptual diagram illustrating a first decorrelation operation that the decorrelation module carries out.</p><p id="p-0016" num="0020"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a schematic diagram of an intermediate decorrelated image obtained by first decorrelation operation.</p><p id="p-0017" num="0021"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a conceptual diagram illustrating a second decorrelation operation that the decorrelation module carries out.</p><p id="p-0018" num="0022"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a schematic diagram of a partially wavelet filtered decorrelated image provided by a quincunx wavelet filtering module of the image processor on the basis of the decorrelated image.</p><p id="p-0019" num="0023"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a block diagram of the quincunx wavelet filtering module that provides the partially wavelet filtered decorrelated image.</p><p id="p-0020" num="0024"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a conceptual diagram illustrating a first wavelet filtering operation that the quincunx wavelet filtering module carries out.</p><p id="p-0021" num="0025"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a schematic diagram of an intermediate partially wavelet filtered decorrelated image obtained by the first wavelet filtering operation.</p><p id="p-0022" num="0026"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a conceptual diagram illustrating a second first wavelet filtering operation that the quincunx wavelet filtering module carries out.</p><p id="p-0023" num="0027"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a schematic diagram of a set of sub-bands provided by a two-dimensional wavelet filtering module of the image processor on the basis of components of the same type in the partially wavelet filtered decorrelated image.</p><p id="p-0024" num="0028"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a schematic diagram of a wavelet filtering of the Le Gall 5/3 type, which may be applied by the two-dimensional wavelet filtering module and which is conceptually related to the first and the second decorrelation operations that the decorrelation module carries out, as well as to the first and second wavelet filtering operations that the quincunx wavelet filtering module carries out.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF SOME EMBODIMENTS</heading><p id="p-0025" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b></figref> schematically illustrates a camera <b>100</b>. <figref idref="DRAWINGS">FIG. <b>1</b></figref> provides a block diagram of the camera <b>100</b>. The camera <b>100</b> may be, for example, a photo camera or a video camera, or a combination of both that can capture an image or a video, or both, respectively. The camera <b>100</b> may further store an image or a video that has been captured, or both, in an encoded form. The camera <b>100</b> may transmit an encoded version of an image or a video that has been captured, or both. The camera <b>100</b> may be part of, for example, a smart phone or another type of electronic apparatus.</p><p id="p-0026" num="0030">The camera <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> comprises an image sensor <b>101</b>, an image processor <b>102</b>, an encoder <b>103</b>, a storage device <b>104</b>, and a communication interface <b>105</b>. The image sensor <b>101</b> may comprise three types of color pixel sensors, such as, for example, green-sensitive pixel sensors, red-sensitive pixel sensors, and blue-sensitive pixel sensors. These color pixel sensors may be arranged in a so-called Bayer pattern, whereby there are twice as much green-sensitive pixel sensors as red-sensitive pixel sensors and blue-sensitive pixel sensors.</p><p id="p-0027" num="0031"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a raw image <b>200</b> that the image sensor <b>101</b> in the camera <b>100</b> may provide. <figref idref="DRAWINGS">FIG. <b>2</b></figref> provides a schematic diagram of the raw image <b>200</b>. The raw image <b>200</b> comprising three types of color pixels: color pixels of the first type, which are green pixels G, color pixels of the second type, which are red pixels R, and color pixels of a third type, which are blue pixels B. These color pixels are arranged in a Bayer pattern. The green pixels G occur twice as much as the red pixels R and the blue pixels B. These three types of color pixels are interleaved as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As can be seen, according to the Bayer pattern, the raw image <b>200</b> is a rectangular array of blocks of 2 by 2 color pixels that comprise two diagonally disposed green pixels G, a red pixel R, and a blue pixel B.</p><p id="p-0028" num="0032">The camera <b>100</b> basically operates as follows. The image processor <b>102</b> provides a decorrelated and wavelet filtered version of the raw image <b>200</b>, which may comprise low-frequency luminance components, a set of sub-bands for high-frequency luminance components, a set of sub-bands for red-based chrominance components, and a set of sub-bands for blue-based chrominance components. The decorrelated and wavelet filtered version of the raw image <b>200</b> may comprise the same amount of information as the raw image <b>200</b>. That is, the raw image <b>200</b> may be perfectly reconstructed on the basis of the decorrelated and wavelet filtered version of the raw image <b>200</b>. This implies that the image processor <b>102</b> need not introduce any loss of information and thus need not introduce any loss of image quality. The image processor <b>102</b> will be described in greater detail hereinafter.</p><p id="p-0029" num="0033">The encoder <b>103</b> encodes the decorrelated and wavelet filtered version of the raw image <b>200</b>. In doing so, the encoder <b>103</b> may apply data compression and may thereby cause some loss of information and thus cause some loss of quality. For example, the encoder <b>103</b> may operate in a manner that is described in U.S. Pat. No. 9,332,258.</p><p id="p-0030" num="0034">The image processor <b>102</b>, which will be described in greater detail hereinafter, allows the encoder <b>103</b> to achieve a relatively high data compression rate for a given image quality. Stated otherwise, the image processor <b>102</b> allows the encoder <b>103</b> to provide an encoded image of relatively high quality for given data compression rate. That is, the image processor <b>102</b> contributes to achieving relatively high encoding efficiency. The image processor <b>102</b> and the encoder <b>103</b> may jointly be regarded as an encoding system <b>106</b>, as indicated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, capable of achieving relatively high encoding efficiency. The encoding system <b>106</b> can be implemented in the form of, for example, an integrated circuit.</p><p id="p-0031" num="0035">The storage device <b>104</b> may store an encoded image that the encoding system <b>106</b> provides. The storage device <b>104</b> may comprise, for example, a solid-state storage device or a disk-based storage device, or a combination of these as well as other types of storage devices.</p><p id="p-0032" num="0036">The communication interface <b>105</b> may send the encoded image to an external apparatus, which may communicatively be coupled to the camera <b>100</b> via, for example, a direct communication link or a communication network. The communication interface <b>105</b> may comprise, for example, a USB port, a Bluetooth interface, or a Wi-Fi interface, or any combination of these as well as other types of communication interfaces.</p><p id="p-0033" num="0037">A decoding system may decode the encoded image so as to obtain a copy of the raw image <b>200</b>. The decoding system may be comprised in, for example, the camera <b>100</b> or an external device, or both. The decoding system is not illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> for the sake of convenience and simplicity. In general, the decoding system may carry out operations that are inverse to the operations that the encoding system <b>106</b> carries out as described hereinbefore and as described hereinafter in greater detail.</p><p id="p-0034" num="0038">The copy of the raw image <b>200</b> that is obtained by decoding the encoded image may undergo various image processing operations so as to obtain, for example, an image suitable for display. These image operations may include, for example, debayering, gamma correction, white balancing, and denoising. The term &#x201c;debayering&#x201d; designates an operation by which the Bayer pattern is effectively removed and replaced by a pattern that is suitable for a display device, such as, for example a conventional RGB pattern. An advantage of encoding the raw image <b>200</b> as described hereinbefore rather than encoding a debayered version of the raw image <b>200</b> is that less information is lost, which allows achieving higher image quality.</p><p id="p-0035" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> schematically illustrates the image processor <b>102</b> in the camera <b>100</b>. <figref idref="DRAWINGS">FIG. <b>3</b></figref> provides a block diagram of image processor <b>102</b>. The image processor <b>102</b> comprises a decorrelation module <b>301</b>, a quincunx wavelet filtering module <b>302</b>, and a two-dimensional wavelet filtering module <b>303</b>. These modules may be implemented in the form of, for example, dedicated circuits, programmable circuits, or a suitably programmed processor, or any combination of these.</p><p id="p-0036" num="0040">The image processor <b>102</b> basically operates as follows. The decorrelation module <b>301</b> carries out various pixel substitution operations so as to obtain a decorrelated image <b>304</b> on the basis of the raw image <b>200</b>. In more detail, the decorrelation module <b>301</b> substitutes green pixels G in the raw image <b>200</b> by luminance components Y. The decorrelation module <b>301</b> further substitutes red pixels R and blue pixels B in the raw image <b>200</b> by red-based chrominance components Cr and the blue-based chrominance components Cb, respectively.</p><p id="p-0037" num="0041"><figref idref="DRAWINGS">FIG. <b>4</b></figref> schematically illustrates the decorrelated image <b>304</b> that the decorrelation module <b>301</b> provides. <figref idref="DRAWINGS">FIG. <b>3</b></figref> provides a schematic diagram of the decorrelated image <b>304</b>. The luminance components Y, the red-based chrominance components Cr, and the blue-based chrominance components Cb are also arranged in a Bayer pattern. There are twice as much luminance components Y as there are red-based chrominance components Cr and blue-based chrominance components Cb. As can be seen, the de-correlated image <b>304</b> is a rectangular array of blocks of 2 by 2 components that comprise two diagonally disposed luminance components Y, a red-based chrominance component Cr, and a blue-based chrominance component Cb.</p><p id="p-0038" num="0042">In more detail, a luminance component Y in the decorrelated image <b>304</b>, which constitutes a substitution of a green pixel G in the raw image <b>200</b>, is a weighted combination of the green pixel G concerned and neighboring pixels in the raw image <b>200</b>. In the weighted combination, neighboring red and blue pixels R, B have an overall positive weighting factor. This corresponds to an overall addition of the neighboring red and blue pixels R, B to the green pixel G that is substituted. Conversely, neighboring green pixels G may have an overall negative weighting factor. This corresponds to an overall subtraction of the neighboring green pixels G from the green pixel G that is substituted.</p><p id="p-0039" num="0043">For example, the weighted combination that provides the luminance component Y may be as follows:</p><p id="p-0040" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i>(<i>i,j</i>)=+7/8*<i>G</i>(<i>i.j</i>)&#x2212;1/16*<i>G</i>(<i>i&#x2212;</i>1,<i>j&#x2212;</i>1)&#x2212;1/16*<i>G</i>(<i>i+</i>1,<i>j&#x2212;</i>1)&#x2212;1/16*<i>G</i>(<i>i&#x2212;</i>1,<i>j+</i>1)&#x2212;1/16*<i>G</i>(<i>i+</i>1,<i>j+</i>1)&#x2212;1/32*<i>G</i>(<i>i&#x2212;</i>2<i>j</i>)&#x2212;1/32*<i>G</i>(<i>i,j&#x2212;</i>2)&#x2212;1/32*<i>G</i>(<i>i+</i>2,<i>j</i>)&#x2212;1/32*<i>G</i>(<i>i,j+</i>2)+1/8*<i>B</i>(<i>i,j&#x2212;</i>1)+1/8*<i>B</i>(<i>i,j+</i>1)+1/8*<i>R</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/8*<i>R</i>(<i>i+</i>1,<i>j</i>).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0041" num="0000">In this equation, two variables between parentheses separated by a comma denote a position of the pixels concerned in the raw image <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, whereby i and j represent the position in a horizontal and a vertical direction, respectively, of the luminance component Y(i,j) that is formed and that of the green pixel G(i,j) that is replaced thereby.</p><p id="p-0042" num="0044">In this embodiment, four immediately neighboring blue and red pixels B(i,j&#x2212;1), B(i,j+1), R(i&#x2212;1,j) R(i+1, j) are all added to the green pixel G(i,j) that is substituted. Four nearest green pixels G(i&#x2212;1, j&#x2212;1), G(i+1, j&#x2212;1), G(i&#x2212;1, j+1), G(i+1, j+1) are all subtracted from the green pixel G(i,j) that is substituted. In addition, four further neighboring green pixels G(i&#x2212;2,j), G(i,j&#x2212;2), G(i+2,j), G(i,j+2) are also subtracted from the green pixel G(i,j) that is substituted. The four nearest neighboring green pixels G(i&#x2212;1, j&#x2212;1), G(i+1, j&#x2212;1), G(i&#x2212;1, j+1), G(i+1, j+1) are in an x-configuration with respect to the green pixel G(i.j) that is substituted. The four further neighboring green pixels G(i&#x2212;2,j), G(i,j&#x2212;2), G(i+2,j), G(i,j+2) are in an +-configuration with respect to the green pixel G(i.j) that is substituted. The four nearest neighboring green pixels G(i&#x2212;1, j&#x2212;1), G(i+1, j&#x2212;1), G(i&#x2212;1, j+1), G(i+1, j+1) have a heavier weighting factor, namely &#x2212;1/16, than that the four further neighboring green pixels G(i&#x2212;2,j), G(i,j&#x2212;2), G(i+2,j), G(i,j+2), which is &#x2212;1/32.</p><p id="p-0043" num="0045">A red-based chrominance component Cr in the decorrelated image <b>304</b>, which constitutes a substitution of a red pixel R in the raw image <b>200</b>, is a weighted combination of the pixel of the red pixel R concerned and neighboring pixels. In the weighted combination, neighboring green pixels G have an overall negative weighting factor. This corresponds to an overall subtraction of the neighboring green pixels G from the red pixel R that is substituted.</p><p id="p-0044" num="0046">The weighted combination that provides the red-based chrominance component Cr may be as follows:</p><p id="p-0045" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Cr</i>(<i>i,j</i>)=<i>R</i>(<i>i,j</i>)&#x2212;1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)&#x2212;1/4*<i>G</i>(<i>i,j&#x2212;</i>1)&#x2212;1/4*<i>G</i>(<i>i+</i>1,<i>j</i>)&#x2212;1/4*<i>G</i>(<i>i,j+</i>1).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0046" num="0000">In this equation too, the two variables between parentheses separated by a comma denote a position of the pixels concerned in the raw image <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, whereby i and j represent the position in a horizontal and a vertical direction, respectively, of the red-based chrominance component Cr(i,j) that is formed and that of the red pixel R(i,j) that is replaced thereby. In this embodiment, four immediately neighboring green pixels G(i&#x2212;1,j), G(i,j&#x2212;1), G(i+1,j), G(i,j+1) are all subtracted from the red pixel R(i,j) that is substituted.</p><p id="p-0047" num="0047">Likewise, a blue-based chrominance component Cb in the decorrelated image <b>304</b>, which constitutes a substitution of a blue pixel B in the raw image <b>200</b>, is a weighted combination of the blue pixel B concerned and neighboring pixels. In the weighted combination, neighboring green pixels G have an overall negative weighting factor. This corresponds to an overall subtraction of the neighboring green pixels G from the blue pixel B that is substituted.</p><p id="p-0048" num="0048">The weighted combination that provides the blue-based chrominance component Cb may be as follows:</p><p id="p-0049" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Cb</i>(<i>i,j</i>)=<i>B</i>(<i>i,j</i>)&#x2212;1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)&#x2212;1/4*<i>G</i>(<i>i,j&#x2212;</i>1)&#x2212;1/4*<i>G</i>(<i>i+</i>1,<i>j</i>)&#x2212;1/4*<i>G</i>(<i>i,j+</i>1).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0050" num="0000">In this equation too, two variables between parentheses separated by a comma denote a position of the pixels concerned in the raw image <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, whereby i and j represent the position in a horizontal and a vertical direction, respectively, of the blue-based chrominance component Cb(i,j) that is formed and that of the blue pixel B(i,j) that is replaced thereby. In this embodiment, four immediately neighboring green pixels G(i&#x2212;1,j), G(i,j&#x2212;1), G(i+1,j), G(i,j+1) are all subtracted from the blue pixel B(i,j) that is substituted, as in the weighted combination that provides the red-based chrominance component Cr(i,j) presented hereinbefore.</p><p id="p-0051" num="0049"><figref idref="DRAWINGS">FIG. <b>5</b></figref> schematically illustrates an embodiment of the decorrelation module <b>301</b>, which forms part of the image processor <b>102</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. <figref idref="DRAWINGS">FIG. <b>5</b></figref> provides a block diagram of this embodiment of the decorrelation module <b>301</b>, which will be simply referred to as the decorrelation module <b>301</b> hereinafter. The decorrelation module <b>301</b> comprises an input buffer memory <b>501</b>, a chrominance component formation module <b>502</b>, an intermediate buffer memory <b>503</b>, and a luminance component formation module <b>504</b>.</p><p id="p-0052" num="0050">The decorrelation module <b>301</b> basically operates as follows. The input buffer memory <b>501</b> temporarily stores at least a portion of the raw image <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The chrominance component formation module <b>502</b> retrieves from the input buffer memory <b>501</b> a red pixel R of the raw image <b>200</b>, as well as four immediately neighboring green pixels G. The chrominance component formation module <b>502</b> then forms a red-based chrominance component Cr by making the weighted combination between the red pixel R and the four immediately neighboring green pixels G as indicated hereinbefore. In this manner, the chrominance component formation module <b>502</b> forms respective red-based chrominance components Cr for the decorrelated image <b>304</b>, which constitute substitutions of red pixels R in the raw image <b>200</b>.</p><p id="p-0053" num="0051">The chrominance component formation module <b>502</b> forms blue-based chrominance components Cb in a similar manner. That is, the chrominance component formation module <b>502</b> retrieves from the input buffer memory <b>501</b> a blue pixel B of the raw image <b>200</b>, as well as four immediately neighboring green pixels G. The chrominance component formation module <b>502</b> then forms a blue-based chrominance component Cb by making the weighted combination between the blue pixel B and the four immediately neighboring green pixels G as indicated hereinbefore.</p><p id="p-0054" num="0052"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates a formation of a red-based chrominance component Cr and that of a blue-based chrominance component Cb as described hereinbefore. This may be regarded as a first decorrelation operation. <figref idref="DRAWINGS">FIG. <b>6</b></figref> provides a conceptual diagram of this first decorrelation operation by means of which chrominance components Cr, Cb for the decorrelated image <b>304</b> are formed. In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a portion of the raw image <b>200</b> is represented in a left half of this figure, whereas a portion of the decorrelated image <b>304</b> is represented in a right half of this same figure. A red pixel R and its four immediate neighboring green pixels G in the raw image <b>200</b> are indicated, as well as a blue pixel B and its four immediately neighboring green pixels G. In addition, a red-based chrominance component Cr in the decorrelated image <b>304</b> is indicated, which constitutes a substitution of the aforementioned red pixel R, as well as a blue-based chrominance component Cb in the decorrelated image <b>304</b> is indicated, which constitutes a substitution of the aforementioned blue pixel B. Further, weighing factors are indicated, which correspond to those indicated hereinbefore.</p><p id="p-0055" num="0053"><figref idref="DRAWINGS">FIG. <b>7</b></figref> schematically illustrates an intermediate decorrelated image <b>700</b> provided by the chrominance component formation module <b>502</b>, <figref idref="DRAWINGS">FIG. <b>7</b></figref> provides a schematic diagram of the intermediate decorrelated image <b>700</b>. The intermediate decorrelated image <b>700</b> corresponds with a modified version the raw image <b>200</b> in which respective red and blue pixels B have been substituted by respective red-based chrominance components Cr and respective blue-based chrominance components Cb. Green pixels G of the raw image <b>200</b> have not yet been substituted and thus remain present. At least a portion of the intermediate decorrelated image <b>700</b> is temporarily stored in the intermediate buffer memory <b>503</b> of the decorrelation module <b>301</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0056" num="0054">Referring again to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the luminance component formation module <b>504</b> retrieves from the intermediate buffer memory <b>503</b> a green pixel G in the intermediate decorrelated image <b>700</b>, as well as four immediately neighboring chrominance pixels Cr, Cb, namely two red-based chrominance pixels Cr and two blue-based chrominance pixels Cb. The luminance component formation module <b>504</b> then forms a luminance component Y by making a weighted combination of the green pixel G and the four immediately neighboring chrominance pixels Cr, Cb. In this manner, the luminance component formation module <b>504</b> forms respective luminance components Y for the decorrelated image <b>304</b>, which constitute substitutions of green pixels Gin the raw image <b>200</b>. The luminance component formation module <b>504</b> thus provides the decorrelated image <b>304</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> on the basis of the intermediate decorrelated image <b>700</b> illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, which is temporarily stored in the intermediate buffer memory <b>503</b> of the decorrelation module <b>301</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0057" num="0055"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a formation of a luminance component Y as described hereinbefore. This may be regarded as a second decorrelation operation. <figref idref="DRAWINGS">FIG. <b>8</b></figref> provides a conceptual diagram of this second decorrelation operation by means of which luminance components Y for the decorrelated image <b>304</b> are formed. In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, a portion of the intermediate decorrelated image <b>700</b> is represented in a left half of this figure, whereas a portion of the decorrelated image <b>304</b> is represented in a right half of this same figure. A green pixel G and its four immediate neighboring chrominance components Cb, Cr in the intermediate decorrelated image <b>700</b> are indicated. In addition, a luminance component Y in the decorrelated image <b>304</b> is indicated, which constitutes a substitution of the aforementioned green pixel G. Further, weighing factors are indicated. When these are combined with the weighing factors indicated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, weighing factors are obtained that correspond to those indicated hereinbefore for forming the luminance components Y.</p><p id="p-0058" num="0056">The decorrelation module <b>301</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> may work with integer numbers and round divisions that result from applying weighting factors to pixels. This allows relatively simple, low-cost implementations. There are various ways of rounding numbers. For example, the formation of a red-based chrominance component Cr and that of a blue-based chrominance component Cb could be adapted in the following manner:</p><p id="p-0059" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Cb</i>(<i>i,j</i>)=<i>B</i>(<i>i,j</i>)&#x2212;ROUNDDOWN(1/4*<i>G</i>(<i>i&#x2212;,</i>1<i>j</i>)+1/4*<i>G</i>(<i>i,j&#x2212;</i>1)+1/4*<i>G</i>(<i>i+</i>1,<i>j</i>)+1/4*<i>G</i>(<i>i,j+</i>1)); and<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0060" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Cr</i>(<i>i,j</i>)=<i>R</i>(<i>i,j</i>)&#x2212;ROUNDDOWN(1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/4*<i>G</i>(<i>i,j&#x2212;</i>1)+1/4*<i>G</i>(<i>i+</i>1,<i>j</i>)+<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0061" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>1/4*<i>G</i>(<i>i,j+</i>1)).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0062" num="0057">Similarly, the formation of a luminance component Y could be adapted in the following manner:</p><p id="p-0063" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i>(<i>i,j</i>)=<i>G</i>(<i>i,j</i>)+ROUNDDOWN(1/8*<i>Cr</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/8*<i>Cb</i>(<i>i,j&#x2212;</i>1)+1/8*<i>Cr</i>(<i>i+</i>1,<i>j</i>)+1/8*<i>Cb</i>(<i>i,j+</i>1)).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0064" num="0058">In a decoder, a module that is the counterpart of the decorrelation module <b>301</b> could be adapted to exactly reverse the aforementioned equations by carrying out the following ones:</p><p id="p-0065" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>G</i>(<i>i,j</i>)=<i>Y</i>(<i>i,j</i>)&#x2212;ROUNDDOWN(1/8*<i>Cr</i>(<i>i</i>-1,<i>j</i>)+1/8*<i>Cb</i>(<i>i,j&#x2212;</i>1)+1/8*<i>Cr</i>(<i>i+</i>1,<i>j</i>)+1/8*<i>Cb</i>(<i>i,j+</i>1));<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0066" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>R</i>(<i>i,j</i>)=<i>Cr</i>(<i>i,j</i>)+ROUNDDOWN(1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/4*<i>G</i>(<i>i,j&#x2212;</i>1)+1/4*<i>G</i>(<i>i+</i>1,<i>j</i>)+1/4*<i>G</i>(<i>i,j+</i>1)); and<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0067" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>B</i>(<i>i,j</i>)=<i>Cb</i>(<i>i,j</i>)+ROUNDDOWN(1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/4*<i>G</i>(<i>i,j&#x2212;</i>1)+1/4*<i>G</i>(<i>i+</i>1,<i>j</i>)+1/4*<i>G</i>(<i>i,j+</i>1)).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0068" num="0059">In these equation ROUNDDOWN represents an operator that rounds a number down to its nearest integer.</p><p id="p-0069" num="0060">Referring again to the image processor <b>102</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the quincunx wavelet filtering module <b>302</b> applies a wavelet filtering operation to the luminance components Y in the decorrelated image <b>304</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In effect, the quincunx wavelet filtering module <b>302</b> decomposes the luminance components Y into a first set of arrays of luminance components Y and into a second set of arrays of luminance components Y. The arrays of luminance components Y that belong to the first set are interleaved with the arrays of luminance components Y of the second set. For example, the first set of arrays of luminance components Y may correspond with even lines in the decorrelated image <b>304</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, whereas the second set of arrays of luminance components Y may correspond with uneven lines in the decorrelated image <b>304</b>, or vice versa.</p><p id="p-0070" num="0061">The quincunx wavelet filtering module <b>302</b> may provide high-frequency luminance components Y<sub>H </sub>for luminance components Y that belong to the first set of arrays. In that case, the quincunx wavelet filtering module <b>302</b> may provide low-frequency luminance components Y<sub>L </sub>for luminance components Y that belong to the second set of arrays. In fact, the high-frequency luminance components Y<sub>H </sub>then substitute the luminance components Y that belong to the first set of arrays. The low-luminance components Y<sub>L </sub>substitute the luminance components Y that belong to the second set of arrays.</p><p id="p-0071" num="0062"><figref idref="DRAWINGS">FIG. <b>9</b></figref> schematically illustrates a partially wavelet filtered decorrelated image <b>900</b> provided by the quincunx wavelet filtering module <b>302</b>. <figref idref="DRAWINGS">FIG. <b>9</b></figref> provides a schematic diagram of the partially wavelet filtered decorrelated image <b>900</b>. In this example, even lines of the partially wavelet filtered decorrelated image <b>900</b> comprise high-frequency luminance components Y<sub>H</sub>, whereas uneven lines comprise low-frequency luminance components Y<sub>L</sub>. Thus, in the partially wavelet filtered decorrelated image <b>900</b>, each different type of component is organized in dyadic arrays rather than in mosaic arrays. This feature may be relevant if, for example, the encoder <b>103</b> in the camera <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> has specifically been designed to handle components organized in dyadic arrays. This may be the case if, for example, the encoder <b>103</b> operates in a manner that is described in U.S. Pat. No. 9,332,258 mentioned hereinbefore.</p><p id="p-0072" num="0063"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an embodiment of the quincunx wavelet filtering module <b>302</b>, which forms part of the image processor <b>102</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. <figref idref="DRAWINGS">FIG. <b>10</b></figref> provides a block diagram of this embodiment of the quincunx wavelet filtering module <b>302</b>, which will be simply referred to as quincunx wavelet filtering module <b>302</b> hereinafter. The quincunx wavelet filtering module <b>302</b> comprises an input buffer memory <b>1001</b>, a high-frequency luminance component formation module <b>1002</b>, an intermediate buffer memory <b>1003</b>, and a low-frequency luminance component formation module <b>1004</b>.</p><p id="p-0073" num="0064">The quincunx wavelet filtering module <b>302</b> basically operates as follows. The input buffer memory <b>1001</b> temporarily stores at least a portion of the decorrelated image <b>304</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. The high-frequency luminance component formation module <b>1002</b> retrieves from the input buffer memory <b>1001</b> a luminance component Y from the decorrelated image <b>304</b> as well as four immediately neighboring luminance components Y that are in a quincunx configuration with respect to the first-mentioned luminance component, which will be referred to as central luminance component Y hereinafter for the sake of convenience. The central luminance component Y may belong to the first set of arrays, whereas the immediately neighboring luminance components Y may belong to the second set of arrays. For example, the central luminance component Y may be present in an even line in the decorrelated image <b>304</b>, whereas two of the four immediately neighboring luminance components Y may be present in an uneven line directly above the aforementioned even line, and the two other of the four immediately neighboring luminance components Y may be present in an uneven line directly below the aforementioned even line.</p><p id="p-0074" num="0065">The high-frequency luminance component formation module <b>1002</b> forms a high-frequency luminance component Y<sub>H </sub>by making a weighted combination between the central luminance component Y, on the one hand, and the four immediately neighboring luminance components Y, on the other hand. The weighted combination may be expressed as follows:</p><p id="p-0075" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i><sub>H</sub>(<i>i,j</i>)=<i>Y</i>(<i>i,j</i>)&#x2212;1/4*<i>Y</i>(<i>i&#x2212;</i>1,<i>j&#x2212;</i>1)&#x2212;1/4*<i>Y</i>(<i>i+</i>1,<i>j&#x2212;</i>1)&#x2212;1/4*<i>Y</i>(<i>i+</i>1,<i>j+</i>1)&#x2212;1/4*<i>Y</i>(<i>i&#x2212;</i>1,<i>j+</i>1),<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0076" num="0000">wherein, like hereinbefore, the two variables between parentheses separated by a comma denote a position of the luminance components concerned in decorrelated image <b>304</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. whereby i and j represent the position in a horizontal and a vertical direction, respectively, of the high-frequency luminance component Y<sub>H</sub>(i,j) that is formed and that of the luminance component Y(i,j) that is replaced thereby.</p><p id="p-0077" num="0066"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a formation of a high-frequency luminance component Y<sub>H</sub>, which may be regarded as a first partial wavelet filtering operation. <figref idref="DRAWINGS">FIG. <b>11</b></figref> provides a conceptual diagram of this first partial wavelet filtering operation by means of which high-frequency luminance components Y<sub>H </sub>for the partially wavelet filtered decorrelated image <b>900</b> are formed. In <figref idref="DRAWINGS">FIG. <b>11</b></figref>, a portion of the decorrelated image <b>304</b> is represented in a left half of this figure, whereas a portion of the partially wavelet filtered decorrelated image <b>900</b> is represented in a right half of this same figure. Luminance components Y that belong to the first set of arrays of luminance components Y and those that belong to the second set of arrays are indicated by different shadings in the decorrelated image <b>304</b>. In this example, arrays of luminance components Y correspond with lines in the decorrelated image <b>304</b>.</p><p id="p-0078" num="0067">A luminance component Y that belongs to the first set of arrays in the decorrelated image <b>304</b> and its four immediate neighboring luminance components Y that belong to the second set of arrays are indicated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. In addition, a high-frequency luminance components Y<sub>H </sub>in the partially wavelet filtered decorrelated image <b>900</b> is indicated, which constitutes a substitution of the first mentioned luminance component. Further, weighing factors are indicated, which correspond to those indicated hereinbefore.</p><p id="p-0079" num="0068"><figref idref="DRAWINGS">FIG. <b>12</b></figref> schematically illustrates an intermediate partially wavelet filtered decorrelated image <b>1200</b> provided by the high-frequency luminance component formation module <b>1002</b>, <figref idref="DRAWINGS">FIG. <b>12</b></figref> provides a schematic diagram of the intermediate partially wavelet filtered decorrelated image <b>1200</b>. This image <b>1200</b> corresponds with a modified version the decorrelated image <b>304</b> in which respective luminance components Y that belong to the first set of arrays have been substituted by respective high-frequency luminance components Y<sub>H</sub>. Luminance components Y in the decorrelated image <b>304</b> that belong to the second set of arrays have not yet been substituted and thus remain present. At least a portion of the intermediate partially wavelet filtered decorrelated image <b>1200</b> is temporarily stored in the intermediate buffer memory <b>1003</b> of the quincunx wavelet filtering module <b>302</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0080" num="0069">Referring again to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the low-frequency luminance component formation module <b>1004</b> retrieves from the intermediate buffer memory <b>1003</b> a luminance component Y in the intermediate partially wavelet filtered decorrelated image <b>1200</b>, as well as four immediately neighboring high-frequency luminance components Y<sub>H </sub>that are in a quincunx configuration with respect to the luminance component Y. In this example, the luminance component Y belongs to the second set of arrays, whereas the immediately neighboring high-frequency luminance components Y<sub>H </sub>have taken the place of luminance components Y belonging to the first set of arrays. For example, the luminance component Y may be present in an uneven line in the decorrelated image <b>304</b> and thus in the intermediate partially wavelet filtered version <b>1200</b> thereof, whereas two of the four immediately neighboring high-frequency luminance components Y<sub>H </sub>may be present in an even line directly above the aforementioned uneven line, and the two other of the four immediately neighboring luminance components Y may be present in an even line directly below the aforementioned uneven line.</p><p id="p-0081" num="0070">The low-frequency luminance component formation module <b>1004</b> forms a low-frequency luminance component Y<sub>L </sub>by making a weighted combination of the luminance component Y, on the one hand, and the four immediately neighboring high-frequency luminance components Y<sub>H</sub>, on the other hand. The weighted combination may be expressed as follows:</p><p id="p-0082" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i><sub>L</sub>(<i>i,j</i>)=<i>Y</i>(<i>i,j</i>)+1/8*<i>Y</i><sub>H</sub>(<i>i&#x2212;</i>1,<i>j&#x2212;</i>1)+1/8*<i>Y</i><sub>H</sub>(<i>i+</i>1,<i>j&#x2212;</i>1)+1/8*<i>Y</i><sub>H</sub>(<i>i+</i>1,<i>j+</i>1)+1/8*<i>Y</i><sub>H</sub>(<i>i</i>&#x2212;1,<i>j+</i>1),<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0083" num="0000">wherein, like hereinbefore, the two variables between parentheses separated by a comma denote a position of the luminance components concerned in the intermediate partially wavelet filtered decorrelated image <b>1200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. whereby i and j represent the position in a horizontal and a vertical direction, respectively, of the low-frequency luminance component Y<sub>L</sub>(i,j) that is formed and that of the luminance component Y(i,j) that is replaced thereby.</p><p id="p-0084" num="0071"><figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates a formation of a low-frequency luminance component, Y<sub>L </sub>which may be regarded as a second partial wavelet filtering operation. <figref idref="DRAWINGS">FIG. <b>13</b></figref> provides a conceptual diagram of this second partial wavelet filtering operation by means of which low-frequency luminance components Y<sub>L </sub>for the partially wavelet filtered decorrelated image <b>900</b> are formed. In <figref idref="DRAWINGS">FIG. <b>13</b></figref>, a portion of the intermediate partially wavelet filtered decorrelated image <b>1200</b> is represented in a left half of this figure, whereas a portion of the partially wavelet filtered decorrelated image <b>900</b> is represented in a right half of this same figure.</p><p id="p-0085" num="0072">A luminance component Y in the intermediate partially wavelet filtered decorrelated image <b>1200</b> is indicated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, as well as its four immediate neighboring high-frequency luminance components Y<sub>H</sub>. In addition, a low-frequency luminance components Y<sub>L </sub>in the partially wavelet filtered decorrelated image <b>900</b> is indicated, which constitutes a substitution of the aforementioned luminance component, Further, weighing factors are indicated, which correspond to those indicated hereinbefore.</p><p id="p-0086" num="0073">Like the decorrelation module <b>301</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the quincunx wavelet filtering module <b>302</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> may work with integer numbers and round divisions that result from applying weighting factors to components. This too allows relatively simple, low-cost implementations. There are various ways of rounding numbers, such as, for example, rounding down to the nearest integer as presented hereinbefore by way of example.</p><p id="p-0087" num="0074">Referring again to the image processor <b>102</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the two-dimensional wavelet filtering module <b>303</b> applies a two-dimensional wavelet filtering separately to the red-based chrominance components Cr, the blue-based chrominance components Cb, and the low-frequency luminance components Y<sub>L </sub>in the partially wavelet filtered decorrelated image <b>900</b> illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. That is, the red-based chrominance components Cr in this image constitute, in effect, a sub image that undergoes the two-dimensional wavelet filtering. Similarly, the blue-based chrominance components Cb constitute, in effect, another sub image that undergoes this filtering, and the low-frequency luminance components Y<sub>L </sub>constitute yet another sub image that undergoes the two-dimensional wavelet filtering.</p><p id="p-0088" num="0075">The two-dimensional wavelet filtering may involve two one-dimensional wavelet filtering operations that are successively carried out. One of the two one-dimensional wavelet filtering operations may be carried out in a horizontal direction, whereas the other one-dimensional wavelet filtering operation may be carried out in a vertical direction. For example, sub image components may first be applied line wise to a one-dimensional wavelet filter. This first wavelet filtering operation then produces a horizontal high-frequency sub-band and a horizontal low-frequency sub-band. Subsequently, components of the horizontal high-frequency sub-band may be applied column wise to the one-dimensional wavelet filter, which produces a horizontal high/vertical high-frequency sub-band and a horizontal high/vertical low frequency sub-band. Components of the horizontal low-frequency sub-band may be applied to the one-dimensional wavelet filter, which produces a horizontal low/vertical high-frequency sub-band and a horizontal low/vertical low frequency sub-band.</p><p id="p-0089" num="0076"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates a set of sub-bands provided by the two-dimensional wavelet filtering module <b>303</b>. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is a two-dimensional frequency diagram, which has a horizontal axis representing frequency in horizontal direction FH, and a vertical axis representing frequency in vertical direction F.v. In this example, there are four sub-bands, which have been mentioned he hereinbefore: the horizontal high vertical high frequency sub-band designated by reference <b>1401</b>, the horizontal high vertical low frequency sub-band designated by reference <b>1402</b>, the horizontal low vertical high frequency sub-band designated by reference <b>1403</b>, and the horizontal low vertical low frequency sub-band designated by reference <b>1404</b>. These four sub bands results from the two-dimensional wavelet filtering of a sub image as described hereinbefore, whereby the sub image is formed by components of the same type in the partially wavelet filtered decorrelated image <b>900</b>. The four of sub-bands illustrated in <figref idref="DRAWINGS">FIG. <b>14</b></figref> may thus result from the red-based chrominance components Cr, the blue-based chrominance components Cb, or the low-frequency luminance components Y<sub>L</sub>.</p><p id="p-0090" num="0077"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates a wavelet filtering of the Le Gall 5/3 type. <figref idref="DRAWINGS">FIG. <b>15</b></figref> provides a conceptual diagram of this wavelet filtering. The wavelet filtering of the Le Gall 5/3 type described hereinafter with reference to <figref idref="DRAWINGS">FIG. <b>15</b></figref> may correspond with the aforementioned one-dimensional wavelet filtering operations that the two-dimensional wavelet filtering module <b>303</b> carries out. Furthermore, the wavelet filtering of the Le Gall 5/3 type is conceptually related to the first and the second decorrelation operations that the decorrelation module <b>301</b> carries out, as well as to the first and second wavelet filtering operations that the quincunx wavelet filtering module <b>302</b> carries out. This will be explained in greater detail hereinafter.</p><p id="p-0091" num="0078">The wavelet filtering of the Le Gall 5/3 type is applied to a series of input samples, which are represented as a series of relatively small circles in an upper part of <figref idref="DRAWINGS">FIG. <b>15</b></figref>. A portion of these small circles have a white filling, whereas another portion of these small circles have a black filling. These will be referred to hereinafter as white input samples and black input samples, respectively. The white input samples are interleaved with the black input samples as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. The wavelet filtering of the Le Gall 5/3 type provides high-frequency output samples for the black input samples and low-frequency output samples for the white input samples. The high-frequency output samples are represented in the middle part of <figref idref="DRAWINGS">FIG. <b>15</b></figref>, whereas the low-frequency output samples are represented in the lower part of this figure.</p><p id="p-0092" num="0079">A high-frequency output sample is formed for a black input sample by making a weighted combination of the black input sample, on the one hand, and two immediately neighboring white input samples, on the other hand. In this weighted combination, the black input sample has a weighting factor of +1 and the two immediately neighboring white input samples have a weighting factor of &#x2212;0.5 as indicated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. Thus, the weighted combination expresses a difference between the black input sample and the two immediately neighboring white input samples. The high-frequency output sample that results from this weighted combination takes, in effect, the place of the black input sample for which it is formed.</p><p id="p-0093" num="0080">A low-frequency output sample is formed for a white input sample by making a weighted combination of the white input sample and two immediately neighboring high-frequency output samples. These two high-frequency output samples in the weighted combination take, in effect, the place of two black input samples that are immediately neighboring to the white input sample concerned, as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. In the weighted combination, the white input sample has a weighting factor of +1 and their immediately neighboring high-frequency output samples have a weighting factor of +0.25 as indicated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. Thus, the weighted combination is a weighted sum of the white input sample and the two immediately neighboring high-frequency output samples. The low-frequency output sample that results from the weighted combination takes, in effect, the place of the white input sample for which it is formed.</p><p id="p-0094" num="0081">As mentioned hereinbefore, the first and the second decorrelation operations that the decorrelation module <b>301</b> carries out in the image processor <b>102</b>, so as to form the decorrelated image <b>304</b>, are conceptually related to the wavelet filtering of the Le Gall 5/3 type discussed hereinbefore. In more detail, the formation of a red-based chrominance component Cr and that of a blue-based chrominance component Cb illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> may conceptually be regarded as a two-dimensional extension of the formation of a high-frequency output sample in the wavelet filtering of the Le Gall 5/3 type illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, which has a one-dimensional character. Instead of taking two immediately neighboring input samples in one dimension to form a high-frequency output sample as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the formation of a chrominance component involves taking four immediately neighboring pixels in two dimensions as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The sum of weighing factors in the weighted combination that provides the high-frequency output sample is equal to the sum of weighing factors in the weighted combination that provides the chrominance component. In the first-mentioned weighted combination, there are two neighbors that have a weighing factor of &#x2212;0.5 each; in the last-mentioned weighted combination there are four neighbors that have a weighting factor of &#x2212;0.25 each.</p><p id="p-0095" num="0082">Similarly, the formation of a luminance component Y illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> may conceptually be regarded as a two-dimensional extension of the formation of a low-frequency output sample in the wavelet filtering of the Le Gall 5/3 type illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, which has a one-dimensional character. Instead of taking two immediately neighboring high-frequency output samples in one dimension to form a low-frequency output sample as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the formation of a luminance component Y involves taking four immediately neighboring chrominance pixels in two dimensions as illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Again, the sum of weighing factors in the weighted combination that provides the low-frequency output sample is equal to the sum of weighing factors in the weighted combination that provides the luminance component. In the first-mentioned weighted combination, there are two neighbors that have a weighing factor of +0.25 each; in the last-mentioned weighted combination there are four neighbors that have a weighting factor of +0.125 each.</p><p id="p-0096" num="0083">As also mentioned hereinbefore, the first and second wavelet filtering operations that the quincunx wavelet filtering module <b>302</b> carries out in the image processor <b>102</b>, so as to form the partially wavelet filtered decorrelated image <b>900</b>, are conceptually related to the wavelet filtering of the Le Gall 5/3 type discussed hereinbefore. In more detail, the formation of a high-frequency luminance component Y<sub>H </sub>illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref> may conceptually be regarded as a two-dimensional extension of the formation of a high-frequency output sample in the wavelet filtering of the Le Gall 5/3 type illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, which has a one-dimensional character. Instead of taking two immediately neighboring input samples in one dimension to form a high-frequency output sample as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the formation of a high-frequency luminance component Y<sub>H </sub>involves taking four immediately neighboring luminance pixels in two dimensions as illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. The sum of weighing factors in the weighted combination that provides the high-frequency output sample is equal to the sum of weighing factors in the weighted combination that provides the high-frequency luminance component. In the first-mentioned weighted combination, there are two neighbors that have a weighing factor of &#x2212;0.5 each; in the last-mentioned weighted combination there are four neighbors that have a weighting factor of &#x2212;0.25 each.</p><p id="p-0097" num="0084">Similarly, the formation of a low-frequency luminance component Y<sub>L </sub>illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref> may conceptually be regarded as a two-dimensional extension of the formation of a low-frequency output sample in the wavelet filtering of the Le Gall 5/3 type illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, which has a one-dimensional character. Instead of taking two immediately neighboring high-frequency output samples in one dimension to form a low-frequency output sample as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the formation of a low-frequency luminance component Y<sub>L </sub>involves taking four immediately neighboring high-frequency luminance components Y<sub>H </sub>in two dimensions as illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Again, the sum of weighing factors in the weighted combination that provides the low-frequency output sample is equal to the sum of weighing factors in the weighted combination that provides the low-frequency luminance component. In the first-mentioned weighted combination, there are two neighbors that have a weighing factor of +0.25 each; in the last-mentioned weighted combination there are four neighbors that have a weighting factor of +0.125 each.</p><p id="p-0098" num="0085">In the camera <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the image processor <b>102</b> thus processes the raw image <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> to obtain the partially wavelet filtered decorrelated image <b>900</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, which may be regarded as a combination of four sub images: a sub image comprising high-frequency luminance components Y<sub>H</sub>, a sub image comprising low-frequency luminance components Y<sub>L</sub>, a sub image comprising red-based chrominance components Cr, and a sub image comprising blue-based chrominance components Cb. In addition, the image processor <b>102</b> provides a set of four sub-bands as illustrated in <figref idref="DRAWINGS">FIG. <b>14</b></figref> for each of the three last-mentioned sub images. The encoder <b>103</b> may then efficiently encode following data that may represent the raw image <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> without any loss of information: the high-frequency luminance components Y<sub>H</sub>, the four sub-bands that represent the low-frequency luminance components Y<sub>L</sub>, the four sub-bands that represent red-based chrominance components Cr, and the four sub-bands that represent the blue-based chrominance components Cb.</p><p id="p-0099" num="0086">The embodiments described hereinbefore with reference to the drawings are presented by way of illustration. The invention may be implemented in numerous different ways. In order to illustrate this, some alternatives are briefly indicated.</p><p id="p-0100" num="0087">The invention may be applied in numerous types of products or methods related to image processing, or video processing, or both. The presented embodiments provide an example of the invention being applied for image and video compression. However, the invention may be applied for other types of image and video processing, such as, for example, providing a multi-resolution view of an image for segmented storage and/or transport of the image, analysis of images to detect objects/properties in the image or achieve segmentation, and as an analysis filter for a debayering algorithm.</p><p id="p-0101" num="0088">There are numerous different ways of implementing an image processor in accordance with the invention. Any of the modules in the presented embodiments may be implemented by means of an electrical circuit, which may be dedicated or programmable, or by means of a suitably programmed processor, or a combination thereof. A computer program may define one or more operations carried out by the image processor, which have been described with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>15</b></figref>. In this respect, the block diagrams may each also be regarded, at least partially, as representing a flow chart diagram of such a computer program, as well as representing a method that a processor may carry out when executing the computer program. For example, the decorrelation module illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be regarded as representing a decorrelation step. Similarly, other modules may be regarded as representing steps of a method.</p><p id="p-0102" num="0089">There are numerous different ways of implementing decorrelating pixel-component transformation schemes in a product or method accordance with the invention. In the presented embodiments, a pixel-component transformation scheme is applied that is conceptually related to the wavelet filtering of the Le Gall 5/3 type as explained hereinbefore. More specifically, in this conceptual relationship, the pixels of the second and third type, which are the red and blue pixels in the presented embodiments, may be considered as samples for which high-frequency components are provided using a two-dimensional filter kernel that, in effect, is an extension of a one-dimensional kernel of the wavelet filtering concerned, whereby a correction of weighting factors is applied. The pixels of the first type, which are the green pixels in the presented embodiments, may be considered as samples for which low-frequency components are provided, again using a two-dimensional filter kernel that, in effect, is an extension of a one-dimensional kernel of the wavelet filtering concerned, whereby a correction of weighting factors is applied.</p><p id="p-0103" num="0090">In other embodiments, a pixel-component transformation scheme may be based on a wavelet filtering of a different type, such as, for example, a wavelet filtering of the Daubechies 9/7 type, or a 13/7 based wavelet filtering. A pixel-component transformation scheme based on one of the aforementioned types of wavelet filtering may be more complex to implement that the pixel-component transformation scheme in the presented embodiments. For example, a pixel-component transformation scheme that is based on the wavelet filtering of the Daubechies 9/7 type may involve more partial decorrelation operations than the first and second decorrelation operations described hereinbefore with reference to <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>8</b></figref>. That is, a decorrelation module based on the wavelet filtering of the Daubechies 9/7 type may require more functional blocks that the decorrelation module <b>301</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0104" num="0091">A pixel-component transformation scheme that is based on a wavelet filtering of a type that is more complex than the wavelet filtering of the Le Gall 5/3 type, will provide more complex weighted combinations that define components replacing pixels. This is because more neighboring pixels will be taken into account to form a component that replaces a pixel. A general rule regarding weighted combinations that has been indicated hereinbefore and that is defined in the appended claims will nonetheless still apply. Namely, in a weighted combination that provides a component of a first type, neighboring pixels of the second and third type have an overall positive weighting factor corresponding to an overall addition of the neighboring pixels of the second and third type to a pixel of the first type that is substituted. Conversely, in a weighted combination that provides a component of a second or third type, neighboring pixels of the first type have an overall negative weighting factor corresponding to an overall subtraction of the neighboring pixels of the first type from a pixel of the second or third type, respectively, that is substituted.</p><p id="p-0105" num="0092">It should further be noted that there are numerous different manners of implementing a decorrelating pixel-component transformation scheme that is conceptually related to a particular type of wavelet filtering, such as, for example, the Le Gall 5/3 type wavelet filtering. For example, the presented embodiments describe an implementation that may be simplified as follows. A weighted combination that provides a red-based chrominance component Cr is simplified by taking into account pixels on two consecutive lines only. In case the red pixel R(i,j) is on a lower of the two consecutive lines, the weighted combination may be expressed as follows:</p><p id="p-0106" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Cr</i>(<i>i,j</i>)=<i>R</i>(<i>i,j</i>)&#x2212;1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)&#x2212;1/2*<i>G</i>(<i>i,j&#x2212;</i>1)&#x2212;1/4*<i>G</i>(<i>i+</i>1,<i>j</i>).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0107" num="0093">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, in that case, the green pixel G that is immediately below the red pixel R that is substituted by the red-based chrominance component Cr is omitted. This omission is compensated for by doubling the weighting factor for the green pixel G that is immediately above the red pixel R, which thus becomes &#x2212;0.5 instead of &#x2212;0.25. This is equivalent to horizontally mirroring, as it were, the aforementioned green pixel G so that this same pixel is also immediately below the red pixel R, thereby taking the place of the green pixel G that is omitted.</p><p id="p-0108" num="0094">In case the red pixel R(i,j) is on an upper of the two consecutive lines, the weighted combination may be expressed as follows:</p><p id="p-0109" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Cr</i>(<i>i,j</i>)=<i>R</i>(<i>i,j</i>)&#x2212;1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)&#x2212;1/4*<i>G</i>(<i>i+</i>1,<i>j</i>)&#x2212;1/2*<i>G</i>(<i>i,j+</i>1).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0110" num="0095">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, in that case, the green pixel G that is immediately above the red pixel R that is substituted by the red-based chrominance component Cr is omitted. This omission is compensated for by doubling the weighting factor for the green pixel G that is immediately below the red pixel R, which thus becomes &#x2212;0.5 instead of &#x2212;0.25.</p><p id="p-0111" num="0096">In the same manner, a weighted combination that provides a blue-based chrominance component Cb is simplified by taking into account pixels on two consecutive lines only. In case the blue pixel B(i,j) is on a lower of the two consecutive lines, the weighted combination may be expressed as follows:</p><p id="p-0112" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Cb</i>(<i>i,j</i>)=<i>B</i>(<i>i,j</i>)&#x2212;1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)&#x2212;1/2*<i>G</i>(<i>i,j&#x2212;</i>1)&#x2212;1/4*<i>G</i>(<i>i+</i>1,<i>j</i>).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0113" num="0097">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, in that case, the green pixel G that is immediately below the blue pixel B that is substituted by the blue-based chrominance component Cb is omitted. This omission is compensated for by doubling the weighting factor for the green pixel G that is immediately above the blue pixel B, which thus becomes &#x2212;0.5 instead of &#x2212;0.25.</p><p id="p-0114" num="0098">In case the blue pixel B(i,j) is on an upper of the two consecutive lines, the weighted combination may be expressed as follows:</p><p id="p-0115" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Cb</i>(<i>i,j</i>)=<i>B</i>(<i>i,j</i>)&#x2212;1/4*<i>G</i>(<i>i&#x2212;</i>1,<i>j</i>)&#x2212;1/4*<i>G</i>(<i>i+</i>1,<i>j</i>)&#x2212;1/2*<i>G</i>(<i>i,j+</i>1).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0116" num="0099">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, in that case, the green pixel G that is immediately above the blue pixel B that is substituted by the blue-based chrominance component Cb is omitted. This omission is compensated for by doubling the weighting factor for the green pixel G that is immediately below the blue pixel B, which thus becomes &#x2212;0.5 instead of &#x2212;0.25.</p><p id="p-0117" num="0100">A weighted combination that provides a luminance component Y can similarly be simplified by taking into account pixels and chrominance components on two consecutive lines only in the intermediate decorrelated image <b>700</b> illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. In case the luminance pixel Y(i,j) and the green pixel G(i,j) that is replaced are on a lower of the two consecutive lines, with horizontally adjacent blue-based chrominance components Cb and vertically adjacent red-based chrominance components Cr, the weighted combination may be expressed as follows:</p><p id="p-0118" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i>(<i>i,j</i>)=<i>G</i>(<i>i,j</i>)+1/8*<i>Cb</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/4*<i>Cr</i>(<i>i,j&#x2212;</i>1)+1/8*<i>Cb</i>(<i>i+</i>1,<i>j</i>).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0119" num="0101">In a variant of the case hereinbefore with horizontally adjacent red-based chrominance components Cr and vertically adjacent blue-based chrominance components Cb the weighted combination may be expressed as follows:</p><p id="p-0120" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i>(<i>i,j</i>)=<i>G</i>(<i>i,j</i>)+1/8*<i>Cr</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/4*<i>Cb</i>(<i>i,j&#x2212;</i>1)+1/8*<i>Cr</i>(<i>i+</i>1,<i>j</i>).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0121" num="0102">Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in the latter case, the blue-based chrominance component Cb that is immediately below the green pixel G that is substituted by the luminance component Y is omitted. This omission is compensated for by doubling the weighting factor for the blue-based chrominance component Cb that is immediately above the green pixel G, which thus becomes +0.25 instead of +0.125. This is equivalent to horizontally mirroring, as it were, the aforementioned blue-based chrominance component Cb so that this same component is also immediately below the green pixel G, thereby taking the place of the blue-based chrominance component Cb that is omitted.</p><p id="p-0122" num="0103">In case the luminance pixel Y(i,j) and the green pixel G(i,j) that is replaced are on an upper of the two consecutive lines, with horizontally adjacent blue-based chrominance components Cb and vertically adjacent red-based chrominance components Cr, the weighted combination may be expressed as follows:</p><p id="p-0123" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i>(<i>i,j</i>)=<i>G</i>(<i>i,j</i>)+1/8*<i>Cb</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/8*<i>Cb</i>(<i>i+</i>1,<i>j</i>)+1/4*<i>Cr</i>(<i>i,j+</i>1).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0124" num="0104">In a variant of the case hereinbefore with horizontally adjacent red-based chrominance components Cr and vertically adjacent blue-based chrominance components Cb the weighted combination may be expressed as follows:</p><p id="p-0125" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Y</i>(<i>i,j</i>)=<i>G</i>(<i>i,j</i>)+1/8*<i>Cr</i>(<i>i&#x2212;</i>1,<i>j</i>)+1/8*<i>Cr</i>(<i>i+</i>1,<i>j</i>)+1/4*<i>Cb</i>(<i>i,j+</i>1).<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0126" num="0105">Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in the latter case, the blue-based chrominance component Cb that is immediately above the green pixel G that is substituted by the luminance component Y is omitted. This omission is compensated for by doubling the weighting factor for the blue-based chrominance component Cb that is immediately below the green pixel G, which thus becomes +0.25 instead of +0.125.</p><p id="p-0127" num="0106">The wavelet filtering operation that is applied to luminance components Y by the quincunx wavelet filtering module <b>302</b> illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, can be simplified in a similar manner. That is, a simplified wavelet filtering operation may take into account the luminance components on two consecutive lines only in the decorrelated image <b>304</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, this may imply ignoring the luminance components Y that are on a line immediately below the luminance component Y for which the high-frequency luminance component Y<sub>H </sub>is formed. In that case, the weighting factor for the remaining luminance components Y, which are on a line immediately above the luminance component Y for which the high-frequency luminance component Y<sub>H </sub>is formed, may be doubled to become &#x2212;0.5 instead of &#x2212;0.25. Conversely, simplification may imply ignoring the luminance components Y that are on a line immediately above the luminance component Y for which the high-frequency luminance component Y<sub>H </sub>is formed. In that case, the weighting factor for the remaining luminance components Y is doubled too.</p><p id="p-0128" num="0107">The wavelet filtering operation applied by the quincunx wavelet filtering module <b>302</b> can further be simplified by taking into account luminance components Y and high-frequency luminance component Y<sub>H </sub>on two consecutive lines only in the intermediate partially wavelet filtered decorrelated image <b>1200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. Referring to <figref idref="DRAWINGS">FIG. <b>13</b></figref>, such a simplification may imply ignoring the high-frequency luminance components Y<sub>H </sub>that are on a line immediately below the luminance component Y for which the low-frequency luminance component Y<sub>L </sub>is formed. In that case, the weighting factor for the remaining high-frequency luminance components Y<sub>H</sub>, which are on a line immediately above the luminance component Y for which the low-frequency luminance component Y<sub>L </sub>is formed, may be doubled to become +0.25 instead of +0.125. Conversely, the simplification may imply ignoring the high-frequency luminance components Y<sub>H </sub>that are on a line immediately above the luminance component Y for which the high-frequency luminance component Y<sub>H </sub>is formed. In that case, the weighting factor for the remaining luminance components Y is doubled too.</p><p id="p-0129" num="0108">The remarks presented hereinbefore illustrate that there are numerous different ways of implementing a decorrelating pixel-component transformation in accordance with the invention. The transformation can be applied in a perfectly reversible manner or in a non-perfectly reversible manner. For example, in video encoding with a relatively low compression ratio, a perfectly reversible transform may be preferred for high quality. Conversely, in video encoding with a relatively high compression ratio, a non-perfectly reversible transform may be acceptable and even preferred.</p><p id="p-0130" num="0109">In another aspect, there are numerous different ways of implementing a wavelet filtering operation that is applied to luminance components Y in a product or method in accordance with the invention. In the presented embodiments, there is a line-wise decomposition of luminance components Y into a first set of arrays and into a second set of arrays. In other embodiments, this decomposition may be column-wise. More generally, it is possible to implement a column-wise processing instead of a line-wise processing as indicated hereinbefore and in the presented embodiments.</p><p id="p-0131" num="0110">In general, there are numerous different ways of implementing the invention, whereby different implementations may have different topologies. In any given topology, a single entity may carry out several functions, or several entities may jointly carry out a single function. In this respect, the drawings are very diagrammatic.</p><p id="p-0132" num="0111">The remarks made hereinbefore demonstrate that the embodiments described with reference to the drawings illustrate the invention, rather than limit the invention. The invention can be implemented in numerous alternative ways that are within the scope of the appended claims. All changes that come within the meaning and range of equivalency of the claims are to be embraced within their scope. Any reference sign in a claim should not be construed as limiting the claim. The verb &#x201c;comprise&#x201d; in a claim does not exclude the presence of other elements or other steps than those listed in the claim. The same applies to similar verbs such as &#x201c;include&#x201d; and &#x201c;contain&#x201d;. The mention of an element in singular in a claim pertaining to a product, does not exclude that the product may comprise a plurality of such elements. Likewise, the mention of a step in singular in a claim pertaining to a method does not exclude that the method may comprise a plurality of such steps. The mere fact that respective dependent claims define respective additional features, does not exclude combinations of additional features other than those reflected in the claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image processor configured to process an image comprising pixels of three different colors (R, G, B) arranged in a Bayer pattern so as to obtain a de-correlated image composed of components of three different types (Y, Cr, Cb) arranged in a pattern corresponding to the Bayer pattern,<claim-text>whereby, according to the Bayer pattern, the image is a rectangular array of blocks of 2 by 2 pixels that comprise two diagonally disposed pixels of a first color (G), a pixel of a second color (R), and a pixel of a third color (B); and</claim-text><claim-text>whereby, according to the pattern corresponding to the Bayer pattern, the de-correlated image is a rectangular array of blocks of 2 by 2 components that comprise two diagonally disposed components of a first type (Y), a component of a second type (Cr), and a component of a third type (Cb),</claim-text><claim-text>wherein the processor is configured to:</claim-text><claim-text>provide a component of the first type (Y) in the de-correlated image as a substitute for a pixel of the first color (G) in the image, whereby the component of the first type (Y) is a weighted combination of a cluster of pixels in the image that includes the pixel of the first color (G) and neighboring pixels, wherein neighboring pixels of the second and third color (R, B) have an overall positive weighting factor corresponding to an overall addition of neighboring pixels of the second and third color (R, B) to the pixel of the first color (G),</claim-text><claim-text>provide a component of the second type (Cr) in the de-correlated image as a substitute for a pixel of the second color (R) in the image, whereby the component of the second type (Cr) is a weighted combination of a cluster of pixels in the image that includes the pixel of the second color (R) and neighboring pixels, wherein neighboring pixels of the first color (G) have an overall negative weighting factor corresponding to an overall subtraction of neighboring pixels of the first color (G) from the pixel of the second color (R); and</claim-text><claim-text>provide a component of the third type (Cb) in the de-correlated image as a substitute for a pixel of the third color (B) in the image, whereby the component of the third type (Cb) is a weighted combination of a cluster of pixels in the image that includes the pixel of the third color (B) and neighboring pixels, wherein neighboring pixels of the first color (G) have an overall negative weighting factor corresponding to an overall subtraction of neighboring pixels of the first color (G) from the pixel of the third color (B).</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. An image processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image processor is configured to:<claim-text>first provide respective components of the second type (Cr) as substitutes of respective pixels of the second color (R) and to provide respective components of the third type (Cb) as substitutes of respective pixels of the third color (B), and, subsequently, to</claim-text><claim-text>provide respective components of the first type (Y) as substitutes of respective pixels of the first color (G), whereby a component of the first type (Y) is provided on the basis of a weighed combination of, on the one hand, the pixel of the first color (G) for which the component of the first type is a substitute and, on the other hand, components of the second type (Cr) and components of the third type (Cb) that have been provided as substitutes for pixels of the second color and for pixels of the third color, respectively, that form a cluster with the pixel of the first color.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. An image processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weighted combination that forms the component of the first type (Y) comprises:<claim-text>nearest neighboring pixels of the first color (G) that are in an x-configuration with respect to the pixel of the first color that is substituted; and</claim-text><claim-text>further neighboring pixels of the first color that are in an +-configuration with respect to the pixel of the first color that is substituted.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. An image processor according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the nearest neighboring pixels of the first color (G) that are in an x-configuration have a heavier weighting factor in the weighted combination than the further neighboring pixels of the first color that are in an +-configuration.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. An image processor according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein, in the weighted combination that forms the component of the first type (Y):<claim-text>the pixel of the first color (G) that is substituted has a weighting factor of +7/8;</claim-text><claim-text>the nearest neighboring pixels of the first color that are in an x-configuration have a weighting factor of &#x2212;1/16;</claim-text><claim-text>the further neighboring pixels of the first color that are in an +-configuration have a weighting factor of &#x2212;1/32; and</claim-text><claim-text>the neighboring pixels of the second color (R) and the neighboring pixels of the third color (B) have a weighting factor of +1/8.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. An image processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, in the weighted combination that forms the component of the second type (Cr):<claim-text>the pixel of the second color (R) that is substituted has a weighting factor of +1; and</claim-text><claim-text>the neighboring pixels of the first color (G) are four immediately neighboring pixels of the first color that have a weighing factor of &#x2212;1/4.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. An image processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, in the weighted combination that forms the component of the third type (Cb):<claim-text>the pixel of the third color (B) that is substituted has a weighting factor of +1; and</claim-text><claim-text>the neighboring pixels of the first color (G) are four immediately neighboring pixels of the first color that have a weighing factor of &#x2212;1/4.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. An image processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the image processor is configured to apply a wavelet-based filtering to components of the first type (Y) in the de-correlated image so as to obtain high frequency components of the first type (Y<sub>H</sub>) and low frequency components of the first type (Y<sub>L</sub>), the wavelet-based filtering involving a decomposition of the components of the first type (Y) into a first set of arrays of components of the first type and a second set of arrays of components of the first type, the arrays of components of the first type that belong to the first set being interlaced with the arrays of components of the first type that belong to the second set, whereby the high frequency components of the first type (Y<sub>H</sub>) are provided for the components of the first type that belong to the first set of arrays and whereby the low frequency components of the first type (Y<sub>L</sub>) are provided for the components of the first type that belong to the second set of arrays.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. An image processor according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein a high frequency component of the first type (Y<sub>H</sub>) is a weighted combination between a component of the first type belonging to the first set of arrays and neighboring components of the first type belonging to the second set of arrays, and wherein a low frequency component of the first type (Y<sub>L</sub>) is a weighed sum of a component of the first type belonging to the second set of arrays and neighboring high-frequency components.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. An image processor according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein:<claim-text>in the weighted combination that forms the high frequency component of the first type (Y<sub>H</sub>), the component of the first type belonging to the first set of arrays has a weighting factor of +1 and the neighboring components of the first type belonging to the second set of arrays have a weighting factor of &#x2212;1/4: and</claim-text><claim-text>in the weighed sum that forms the low frequency component of the first type (Y<sub>L</sub>), the component of the first type belonging to the second set of arrays has a weighting factor of +1 and neighboring high-frequency components have a weighting factor of +1/8.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An image processor according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the processor is configured to apply a two-dimensional wavelet-based filtering to the low frequency components of the first type (Y<sub>L</sub>), to the components of the second type (Cr) in the decorrelated image, and to the components of the third type (Cb) in the decorrelated image.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An encoding system comprising an image processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref> and an encoder configured to encode at least one of the following: the de-correlated image and a wavelet-based filtered version of the de-correlated image.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. An encoding system according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the encoder is configured to encode:<claim-text>the high frequency components of the first type (Y<sub>H</sub>);</claim-text><claim-text>sub bands produced obtained by applying the two-dimensional wavelet-based filtering to the low frequency components of the first type (Y<sub>L</sub>);</claim-text><claim-text>sub bands produced obtained by applying the two-dimensional wavelet-based filtering to, the components of the second type (Cr) in the decorrelated image; and</claim-text><claim-text>sub bands produced obtained by applying the two-dimensional wavelet-based filtering to the components of the third type (Cb) in the decorrelated image,</claim-text><claim-text>wherein the processor is configured to apply a two-dimensional wavelet-based filtering to the low frequency components of the first type (Y<sub>L</sub>), to the components of the second type (Cr) in the decorrelated image, and to the components of the third type (Cb) in the decorrelated image.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. An inversely-operating image processor configured to process the de-correlated image produced by the image processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, the inversely-operating image processor being configured to reconstitute the image comprising the pixels of three different colors (R, G, B) that are arranged in the Bayer pattern.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A method of processing an image comprising pixels of three different colors (R, G, B) arranged in a Bayer pattern so as to obtain a de-correlated image composed of components of three different types (Y, Cr, Cb) arranged in a pattern corresponding to the Bayer pattern,<claim-text>whereby, according to the Bayer pattern, the image is a rectangular array of blocks of 2 by 2 pixels that comprise two diagonally disposed pixels of a first color (G), a pixel of a second color (R), and a pixel of a third color (B); and</claim-text><claim-text>whereby, according to the pattern corresponding to the Bayer pattern, the de-correlated image is a rectangular array of blocks of 2 by 2 components that comprise two diagonally disposed components of a first type (Y), a component of a second type (Cr), and a component of a third type (Cb),</claim-text></claim-text><claim-text>wherein the method comprises:<claim-text>providing a component of the first type (Y) in the de-correlated image as a substitute for a pixel of the first color (G) in the image, whereby the component of the first type (Y) is a weighted combination of a cluster of pixels in the image that includes the pixel of the first color (G) and neighboring pixels, wherein neighboring pixels of the second and third color (R, B) have an overall positive weighting factor corresponding to an overall addition of neighboring pixels of the second and third color (R, B) to the pixel of the first color (G),</claim-text><claim-text>providing a component of the second type (Cr) in the de-correlated image as a substitute for a pixel of the second color (R) in the image, whereby the component of the second type (Cr) is a weighted combination of a cluster of pixels in the image that includes the pixel of the second color (R) and neighboring pixels, wherein neighboring pixels of the first color (G) have an overall negative weighting factor corresponding to an overall subtraction of neighboring pixels of the first color (G) from the pixel of the second color (R); and</claim-text><claim-text>providing a component of the third type (Cb) in the de-correlated image as a substitute for a pixel of the third color (B) in the image, whereby the component of the third type (Cb) is a weighted combination of a cluster of pixels in the image that includes the pixel of the third color (B) and neighboring pixels, wherein neighboring pixels of the first color (G) have an overall negative weighting factor corresponding to an overall subtraction of neighboring pixels of the first color (G) from the pixel of the third color (B).</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A computer program product comprising a set of instructions that enables an image processor to carry out the method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>.</claim-text></claim></claims></us-patent-application>
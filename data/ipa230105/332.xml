<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000333A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221220" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000333</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17940328</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>06</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>0661</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>0638</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220201</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>1</main-group><subgroup>0655</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">ENDOSCOPE SYSTEM, PROCESSING APPARATUS, AND COLOR ENHANCEMENT METHOD</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2020/011284</doc-number><date>20200313</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17940328</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>OLYMPUS CORPORATION</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>YAMAZAKI</last-name><first-name>Kenji</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>OLYMPUS CORPORATION</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An endoscope system includes a light source apparatus configured to cause light of a plurality of colors to be emitted at a first/second light amount ratio to generate first/second illumination light, an endoscope configured to generate an image pickup signal, and a processing apparatus including a processor. The processor causes the light source apparatus to emit light while switching light between the first/second illumination light, generates a first image signal from an image pickup signal related to the first illumination light, generates a second image signal from an image pickup signal related to the second illumination light and generates a corrected image signal in which color is enhanced based on the first and the second image signals. The second illumination light is light obtained by adjusting the second light amount ratio so that the second image signal related to a reference portion substantially indicates achromatic color.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="117.86mm" wi="158.75mm" file="US20230000333A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="212.26mm" wi="166.37mm" orientation="landscape" file="US20230000333A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="135.38mm" wi="147.74mm" file="US20230000333A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="258.66mm" wi="102.79mm" file="US20230000333A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="175.77mm" wi="159.77mm" file="US20230000333A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="191.09mm" wi="154.52mm" file="US20230000333A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="190.58mm" wi="150.37mm" file="US20230000333A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="218.10mm" wi="156.04mm" orientation="landscape" file="US20230000333A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="218.10mm" wi="115.99mm" orientation="landscape" file="US20230000333A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="236.30mm" wi="117.18mm" file="US20230000333A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is a continuation application of PCT/JP2020/011284 filed on Mar. 13, 2020, the entire contents of which are incorporated herein by this reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><heading id="h-0003" level="1">1. Field of the Invention</heading><p id="p-0003" num="0002">The present invention relates to an endoscope system, a processing apparatus, and a color enhancement method for performing color enhancement on an image acquired by emitting a plurality of kinds of light having different center wavelengths.</p><heading id="h-0004" level="1">2. Description of the Related Art</heading><p id="p-0004" num="0003">In related art, an endoscope apparatus that displays an image in which superficial blood vessels and superficial microstructures are made clear has been proposed and has greatly contributed to diagnosis of an affected area.</p><p id="p-0005" num="0004">For example, Japanese Patent Application Laid-Open Publication No. 2013-176 discloses a technique of acquiring a normal light image by picking up a subject image in which light amount values of B light, G light and R light are equal, acquiring a special light image by picking up a subject image in which light amount values of B light, G light and R light are B light &#x3e;G light &#x3e;R light and synthesizing the special light image and the normal light image to obtain a synthesized image in which superficial microscopic blood vessels, and the like, are made clear.</p><p id="p-0006" num="0005">Further, for example, Japanese Patent No. 6050286 discloses a technique of, in a feature space formed with a plurality of pieces of color information, generating an image in which a difference in color between a normal portion and an abnormal portion is enhanced by moving coordinates of first to third ranges in which an observation target within a subject is distributed to cause a coordinate of one specific range among the first to the third ranges to fall within a reference range and moving the two ranges other than the specific range so as to be separate from each other.</p><p id="p-0007" num="0006">Further, for example, Japanese Patent No. 3228627 discloses an IHb color enhancement technique of calculating a hemoglobin concentration (IHb) and an average value &#x3c;IHb&#x3e; of IHb and enhancing a gap of IHb from the average value &#x3c;IHb&#x3e;.</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0008" num="0007">An endoscope system according to one aspect of the present invention includes an endoscope, a light source apparatus, and a processing apparatus, in which the light source apparatus includes a plurality of semiconductor light emitting devices configured to emit light with different center wavelengths and causes the plurality of semiconductor light emitting devices to emit light at a certain light amount ratio to generate illumination light, the endoscope includes an image pickup device configured to pick up an image of return light from a subject irradiated with the illumination light to generate an image pickup signal having a plurality of color components, the processing apparatus includes a processor, the processor is configured to execute: controlling the light source apparatus to switch light between first illumination light emitted at a first light amount ratio and second illumination light emitted at a second light amount ratio different from the first light amount ratio, generating a first image signal based on an image pickup signal obtained by picking up an image of a subject illuminated with the first illumination light, generating a second image signal based on an image pickup signal obtained by picking up an image of the subject illuminated with the second illumination light, and generating a corrected image signal in which color is enhanced based on the first image signal and the second image signal, and the second illumination light is light obtained by adjusting the second light amount ratio so that the second image signal related to a reference portion of the subject indicates achromatic color within a predetermined error range.</p><p id="p-0009" num="0008">A processing apparatus according to one aspect of the present invention includes a processor, in which the processor is configured to execute: controlling a light source apparatus to switch light between first illumination light in which a plurality of kinds of light with different center wavelengths are emitted at a first light amount ratio and second illumination light in which the plurality of kinds of light are emitted at a second light amount ratio different from the first light amount ratio, generating a first image signal based on an image pickup signal obtained by picking up an image of a subject illuminated with the first illumination light, generating a second image signal based on an image pickup signal obtained by picking up an image of the subject illuminated with the second illumination light, and generating a corrected image signal in which color is enhanced based on the first image signal and the second image signal, and the second illumination light is light obtained by adjusting the second light amount ratio so that the second image signal related to a reference portion of the subject indicates achromatic color within a predetermined error range.</p><p id="p-0010" num="0009">A color enhancement method according to one aspect of the present invention includes emitting light while switching light between first illumination light in which a light amount ratio of a plurality of kinds of light with different center wavelengths is set at a first light amount ratio and second illumination light in which the light amount ratio is set at a second light amount ratio different from the first light amount ratio, generating a first image signal based on an image pickup signal obtained by picking up an image of a subject illuminated with the first illumination light, generating a second image signal based on an image pickup signal obtained by picking up an image of the subject illuminated with the second illumination light, generating a corrected image signal in which color is enhanced based on the first image signal and the second image signal, and adjusting the second light amount ratio so that the second image signal related to a reference portion of the subject indicates achromatic color within a predetermined error range.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a view illustrating a configuration of an endoscope apparatus according to a first embodiment of the present invention:</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a configuration of a color enhancement unit according to the first embodiment;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating color enhancement display processing to be performed by the endoscope apparatus according to the first embodiment;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a timing chart indicating an aspect where white light WL and color enhancement light CE are alternately emitted when a color enhancement mode is ON according to the first embodiment:</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a timing chart indicating an example of an aspect where white light WL is emitted when the color enhancement mode is OFF according to the first embodiment;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a table indicating setting examples of light amounts of respective LEDs in first illumination light and second illumination light when the color enhancement mode is ON in a normal observation mode according to the first embodiment;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a table indicating an example of the normal observation mode in which a light amount ratio of the respective LEDs in the second illumination light is made different in accordance with a portion of a subject according to the first embodiment;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a table indicating an example of the normal observation mode in which the light amount ratio of the respective LEDs in the second illumination light is made different in accordance with the portion of the subject and a distance from a distal end portion of an endoscope to the portion of the subject according to the first embodiment;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a table indicating an example of an NBI observation mode in which a light amount ratio of a violet LED and a green LED in the second illumination light is made different in accordance with the portion of the subject according to the first embodiment:</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a table indicating an example of change of pixel signals of a pixel of a normal tissue and a pixel of a diseased tissue in a corrected image signal obtained by synthesizing a first image signal and a second image signal by a color enhancement unit according to the first embodiment;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a table for explaining another example of a synthesis method by a synthesis unit according to the first embodiment;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a graph indicating an example where a color enhancement amount is made to change in accordance with a distance of a component of the first image signal from an L* axis in an a*b* plane according to the first embodiment; and</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a graph indicating an example of a region in which color enhancement is to be performed in the a*b* plane according to the first embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0024" num="0023">An embodiment of the present invention will be described below with reference to the drawings. However, the present invention is not limited to the embodiment described below.</p><p id="p-0025" num="0024">Note that the same reference numerals will be assigned to the same or corresponding components as appropriate in the drawings. Further, the drawings are schematic drawings, and there is a case where a relationship of lengths of respective components, a ratio of lengths of respective components, and the like, in one drawing are different from an actual relationship, ratio, and the like. Further, there is a case where part of a relationship and a ratio of lengths are different among a plurality of drawings.</p><heading id="h-0008" level="1">First Embodiment</heading><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> to <figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrate a first embodiment of the present invention, and <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a view illustrating a configuration of an endoscope apparatus <b>1</b>.</p><p id="p-0027" num="0026">The endoscope apparatus <b>1</b> (endoscope system) includes an endoscope <b>2</b>, a light source apparatus <b>3</b>, a processor <b>4</b> (processing apparatus), a display <b>5</b> and an input device <b>6</b>.</p><p id="p-0028" num="0027">The endoscope <b>2</b> is configured as an electronic endoscope that can be inserted into a body cavity or the like of a subject, and picks up an image of body tissues or the like of the subject and outputs an image pickup signal.</p><p id="p-0029" num="0028">The light source apparatus <b>3</b> supplies illumination light to the endoscope <b>2</b> so as to enable observation of the subject in a dark portion.</p><p id="p-0030" num="0029">The processor <b>4</b>, which is connected to the light source apparatus <b>3</b> and the endoscope <b>2</b>, generates and outputs a video signal for observation and/or for recording based on the image pickup signal outputted from the endoscope <b>2</b>.</p><p id="p-0031" num="0030">The display <b>5</b>, which includes a display device such as an LCD (liquid-crystal display) and an organic EL (electro-luminescence) display, displays an observation image, and the like, in accordance with the video signal outputted from the processor <b>4</b>.</p><p id="p-0032" num="0031">The input device <b>6</b>, which includes an operation member such as a switch and a button, outputs to the processor <b>4</b>, an instruction signal in accordance with operation inputted by a user such as a surgeon.</p><p id="p-0033" num="0032">The endoscope <b>2</b> is, for example, detachably connected to the processor <b>4</b> by way of a universal cord (not illustrated) and detachably connected to the light source apparatus <b>3</b> by way of a light guide cable (not illustrated).</p><p id="p-0034" num="0033">The endoscope <b>2</b> includes an elongated insertion portion <b>2</b><i>a </i>that can be inserted into the subject, and an operation portion <b>2</b><i>b </i>provided on a proximal end side of the insertion portion <b>2</b><i>a. </i></p><p id="p-0035" num="0034">An image pickup unit <b>21</b> and an illumination optical system <b>22</b> are provided at a distal end portion <b>2</b><i>c </i>of the insertion portion <b>2</b><i>a. </i></p><p id="p-0036" num="0035">A light guide <b>7</b> for transmitting illumination light passes through and is disposed inside the light guide cable and the endoscope <b>2</b> described above. An emission end portion of the light guide <b>7</b> is disposed at a position facing the illumination optical system <b>22</b>. By this means, the illumination light transmitted by way of the light guide <b>7</b> is emitted toward the subject by the illumination optical system <b>22</b>.</p><p id="p-0037" num="0036">The image pickup unit <b>21</b> includes an objective optical system <b>21</b><i>a </i>and an image pickup device <b>21</b><i>b. </i></p><p id="p-0038" num="0037">The objective optical system <b>21</b><i>a </i>forms an image of return light from the subject illuminated with the illumination light emitted from the illumination optical system <b>22</b>, on the image pickup device <b>21</b><i>b. </i></p><p id="p-0039" num="0038">The image pickup device <b>21</b><i>b </i>picks up an optical image of the subject formed by the objective optical system <b>21</b><i>a </i>to generate an image pickup signal including a plurality of color components and outputs the generated image pickup signal.</p><p id="p-0040" num="0039">Specifically, the image pickup device <b>21</b><i>b </i>is configured as an image sensor such as a CCD and a CMOS in which a plurality of pixels are arranged in a matrix, and, which includes, for example, color filters of a Bayer array of primary colors (which may be, for example, color filters of complementary colors).</p><p id="p-0041" num="0040">The operation portion <b>2</b><i>b </i>is formed in a shape that can be grasped and operated by the user, and a scope switch <b>23</b> and a scope memory <b>24</b> are provided.</p><p id="p-0042" num="0041">The scope switch <b>23</b>, which includes an operation member such as a switch and a button, outputs to the processor <b>4</b>, an instruction signal in accordance with operation inputted by the user.</p><p id="p-0043" num="0042">The scope memory <b>24</b> stores endoscope information including information specific to the endoscope <b>2</b>, such as an ID number of the endoscope <b>2</b> and spectral sensitivity characteristic information of the image pickup unit <b>21</b>.</p><p id="p-0044" num="0043">A signal line to be connected to the image pickup device <b>21</b><i>b</i>, a signal line to be connected to the scope switch <b>23</b>, and a signal line to be connected to the scope memory <b>24</b> are disposed inside the endoscope <b>2</b> and inside the universal cable described above and are electrically connected to the processor <b>4</b> by way of the universal cable.</p><p id="p-0045" num="0044">This allows the endoscope information stored in the scope memory <b>24</b> to be read by a control unit <b>47</b> which will be described later, of the processor <b>4</b> when the endoscope <b>2</b> and the processor <b>4</b> are electrically connected and the processor <b>4</b> is powered on. Further, the instruction signal outputted from the scope switch <b>23</b> is transmitted to the control unit <b>47</b>. Still further, the image pickup signal outputted from the image pickup device <b>21</b><i>b </i>is transmitted to a preprocessing circuit <b>40</b> which will be described later, inside the processor <b>4</b>.</p><p id="p-0046" num="0045">The light source apparatus <b>3</b> includes a light source controller <b>31</b>, a light source unit <b>32</b>, an optical multiplexer <b>33</b>, and a condenser lens <b>34</b>.</p><p id="p-0047" num="0046">The light source controller <b>31</b>, which includes a control circuit and the like, controls light emission by the light source unit <b>32</b> in accordance with an illumination control signal outputted from the processor <b>4</b>.</p><p id="p-0048" num="0047">The light source unit <b>32</b>, which functions as a light source section and includes a plurality of semiconductor light emitting devices (specifically. LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>described below) that emit light with different center wavelengths, causes the plurality of semiconductor light emitting devices to emit light at a certain light amount ratio to generate illumination light.</p><p id="p-0049" num="0048">Specifically, the light source unit <b>32</b> includes, for example, a violet LED (light-emitting diode) <b>32</b><i>a</i>, a blue LED <b>32</b><i>b</i>, a green LED <b>32</b><i>c </i>and a red LED <b>32</b><i>d. </i></p><p id="p-0050" num="0049">The violet LED <b>32</b><i>a </i>emits violet light (hereinafter, also referred to as V light) having a center wavelength belonging to a violet region. Particularly, the present embodiment assumes an endoscope system capable of implementing an NBI observation mode, and thus, it is assumed that the violet LED <b>32</b><i>a </i>emits violet light in a narrow band of a wavelength from 390 to 445 (nm).</p><p id="p-0051" num="0050">The blue LED <b>32</b><i>b </i>emits blue light (hereinafter, also referred to as B light) having a center wavelength belonging to a blue region. As will be described later, the blue light is also preferably light in a narrow band.</p><p id="p-0052" num="0051">The green LED <b>32</b><i>c </i>emits green light (hereinafter, also referred to as G light) having a center wavelength belonging to a green region. As described above, the present embodiment assumes the NBI observation mode, and thus, it is assumed that the green LED <b>32</b><i>c </i>emits green light in a narrow band of a wavelength from 530 to 550 (nm).</p><p id="p-0053" num="0052">The red LED <b>32</b><i>d </i>emits red light (hereinafter, also referred to as R light) having a center wavelength belonging to a red region. As will be described later, the red light is also preferably light in a narrow band.</p><p id="p-0054" num="0053">The respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>of the light source unit <b>32</b> individually emit light or perform extinction at the respective light amounts based on control by the light source controller <b>31</b>. Note that the light amounts described here refer to light amounts of illumination light emitted during a period while an image is picked up (exposed) by the image pickup device <b>21</b><i>b. </i></p><p id="p-0055" num="0054">Note that there are various spectral sensitivity characteristics of the image pickup unit <b>21</b> indicated by the spectral sensitivity characteristic information stored in the scope memory <b>24</b> in accordance with models (further, individuals) of the endoscope <b>2</b>. For example, wavelength bands of light received by the image pickup device <b>21</b><i>b </i>by way of an R (red) filter, a G (green) filter and a B (blue) filter of a Bayer array of primary colors are not respectively limited to a red wavelength band, a green wavelength band and a blue wavelength band, and the image pickup device <b>21</b><i>b </i>may be actually sensitive to a broader bandwidth.</p><p id="p-0056" num="0055">Thus, as a light source to be employed as the light source unit <b>32</b> that accurately controls illumination light, it is preferable to use a light source, for which a band is made narrower, and for which optical spectra of respective kinds of color light are discrete.</p><p id="p-0057" num="0056">For example, also in a case where an LED is used as a light source of the light source unit <b>32</b>, it is preferable to use an LED of a type that generates light emission color with light emitted from the LED itself rather than use an LED of a type that generates light emission color with a fluorescence agent.</p><p id="p-0058" num="0057">Further, as well as an LED, for example, a laser light source such as a semiconductor laser (LD: laser diode) may be used as the light source of the light source unit <b>32</b>.</p><p id="p-0059" num="0058">This can reduce color mixture upon image pickup by way of primary color filters and can improve accuracy of color enhancement.</p><p id="p-0060" num="0059">The optical multiplexer <b>33</b> multiplexes light emitted from the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>of the light source unit <b>32</b> and emits the multiplexed light.</p><p id="p-0061" num="0060">The condenser lens <b>34</b> condenses light emitted from the optical multiplexer <b>33</b> to the emission end portion of the light guide <b>7</b>.</p><p id="p-0062" num="0061">The processor <b>4</b> includes the preprocessing circuit <b>40</b>, an A/D converter <b>41</b>, a WB (white balance) processing unit <b>42</b>, a synchronization processing unit <b>43</b>, a color enhancement unit <b>44</b>, a sharpness enhancement unit <b>45</b>, a display control unit <b>46</b> and a control unit <b>47</b>. The preprocessing circuit <b>40</b> that is disposed before the A/D converter <b>41</b> is an analog circuit. Further, the WB processing unit <b>42</b>, the synchronization processing unit <b>43</b>, the color enhancement unit <b>44</b>, the sharpness enhancement unit <b>45</b> and the display control unit <b>46</b> that are disposed subsequent to the A/D converter <b>41</b> are digital circuits, and, further, the control unit <b>47</b> is also a digital circuit.</p><p id="p-0063" num="0062">It is assumed here that digital circuit units of the processor <b>4</b> are configured to implement functions of the respective units by, for example, a processor such as an ASIC (application specific integrated circuit) and an FPGA (field programmable gate array) including a CPU (central processing unit), and the like, reading and executing a processing program stored in a storage apparatus (or a recording medium) such as a memory.</p><p id="p-0064" num="0063">However, the digital circuit units are not limited to this, and the respective units of the processor <b>4</b> may be configured as, for example, dedicated electronic circuits that implement the respective functions.</p><p id="p-0065" num="0064">The preprocessing circuit <b>40</b> amplifies the image pickup signal outputted from the image pickup unit <b>21</b> of the endoscope <b>2</b> and, further, for example, performs noise removal processing such as correlated double sampling.</p><p id="p-0066" num="0065">The A/D converter <b>41</b> performs A/D conversion on the analog image pickup signal outputted from the preprocessing circuit <b>40</b> to generate a digital image signal. The digital image signal generated by the A/D converter <b>41</b> is outputted to the WB processing unit <b>42</b> and the control unit <b>47</b>.</p><p id="p-0067" num="0066">The WB processing unit <b>42</b> performs white balance processing on the image signal having a plurality of color components, outputted from the A/D converter <b>41</b>.</p><p id="p-0068" num="0067">The synchronization processing unit <b>43</b> performs synchronization processing (also referred to as demosaicking processing) on the image signal having a plurality of color components, outputted from the A/D converter <b>41</b>. In other words, in a case where the image pickup device <b>21</b><i>b </i>is, for example, a single-chip image pickup device including color filters of a Bayer array of primary colors as described above, the image pickup signal becomes a signal having one color component in one pixel. Thus, for example, in a case of a G pixel in which a G filter is provided, the synchronization processing unit <b>43</b> performs synchronization processing of generating RGB components at a pixel position of the G pixel by supplementing a lacking R component and B component at the position of the G pixel in a pixel signal based on an R component in a surrounding R pixel and a B component in a surrounding B pixel. An image signal in which RGB components exist at the respective pixel positions is generated by also performing synchronization processing on pixels in which other color filters are provided in a similar manner.</p><p id="p-0069" num="0068">The color enhancement unit <b>44</b> performs color enhancement processing on the image signal outputted from the synchronization processing unit <b>43</b> based on control by the control unit <b>47</b>. The color enhancement processing to be performed by the color enhancement unit <b>44</b> will be described in detail later.</p><p id="p-0070" num="0069">The sharpness enhancement unit <b>45</b> performs sharpness enhancement processing on the image signal outputted from the color enhancement unit <b>44</b> based on control by the control unit <b>47</b>.</p><p id="p-0071" num="0070">The display control unit <b>46</b> generates a video signal in which the image signal outputted from the sharpness enhancement unit <b>45</b> is allocated to an R channel, a G channel and a B channel of the display <b>5</b> and outputs the generated video signal to the display <b>5</b>.</p><p id="p-0072" num="0071">The control unit <b>47</b> is a controller that comprehensively controls the whole of the endoscope apparatus <b>1</b> including the processor <b>4</b> by receiving instruction signals outputted from the input device <b>6</b> and the scope switch <b>23</b>.</p><p id="p-0073" num="0072">The control unit <b>47</b> includes a memory <b>47</b><i>a </i>that stores a processing program to be executed by the control unit <b>47</b>.</p><p id="p-0074" num="0073">Further, in the memory <b>47</b><i>a</i>, information such as a color adjustment coefficient for adjusting light amounts of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>in accordance with a type of the illumination light and an enhancement coefficient to be used in color enhancement processing to be performed by the color enhancement unit <b>44</b> is stored in advance.</p><p id="p-0075" num="0074">Note that while both the color adjustment coefficient and the enhancement coefficient are stored in the memory <b>47</b><i>a </i>here, at least one of the color adjustment coefficient or the enhancement coefficient may be stored in a memory (not illustrated) in the light source controller <b>31</b>.</p><p id="p-0076" num="0075">As described above, the control unit <b>47</b> reads the endoscope information stored in the scope memory <b>24</b> when the endoscope <b>2</b> and the processor <b>4</b> are electrically connected and the processor <b>4</b> is powered on.</p><p id="p-0077" num="0076">Then, the control unit <b>47</b> sets an observation mode of the endoscope apparatus <b>1</b> based on an instruction signal outputted from an observation mode switch (not illustrated) provided at the input device <b>6</b> and/or the scope switch <b>23</b>. It is assumed here that an observation mode that can be set at the endoscope apparatus <b>1</b> includes, for example, a normal observation mode and a special light observation mode. Note that while in the present embodiment, an NBI (narrow-band imaging) observation mode will be described as an example of the special light observation mode, the special light observation mode is not limited to the NBI observation mode.</p><p id="p-0078" num="0077">Further, the control unit <b>47</b> sets ON/OFF of a color enhancement mode of the endoscope apparatus <b>1</b> based on an instruction signal outputted from a color enhancement mode setting switch (not illustrated) provided at the input device <b>6</b> and/or the scope switch <b>23</b>.</p><p id="p-0079" num="0078">In other words, the endoscope apparatus <b>1</b> of the present embodiment can set ON/OFF of the color enhancement mode in each observation mode. It is therefore possible to select and set one of ON of the color enhancement mode in the normal observation mode, OFF of the color enhancement mode in the normal observation mode, ON of the color enhancement mode in the NBI observation mode or OFF of the color enhancement mode in the NBI observation mode.</p><p id="p-0080" num="0079">The control unit <b>47</b> generates an illumination control signal for causing the light source apparatus <b>3</b> to emit illumination light appropriate for the set observation mode and the set ON/OFF of the color enhancement mode in accordance with the spectral sensitivity characteristic information of the image pickup unit <b>21</b> indicated by the endoscope information read from the scope memory <b>24</b> and outputs the illumination control signal to the light source controller <b>31</b>.</p><p id="p-0081" num="0080">In a case where the color enhancement mode is ON, the control unit <b>47</b> controls the light source apparatus <b>3</b> to emit light while switching light between first illumination light in which a light amount ratio of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>is set at a first light amount ratio for observing the subject and second illumination light in which the light amount ratio is set at a second light amount ratio different from the first light amount ratio.</p><p id="p-0082" num="0081">On the other hand, in a case where the color enhancement mode is OFF, the control unit <b>47</b> controls the light source apparatus <b>3</b> to emit the first illumination light for observing the subject.</p><p id="p-0083" num="0082">If an image of return light from the subject irradiated with the illumination light emitted from the light source apparatus <b>3</b> is picked up by the image pickup unit <b>21</b>, the control unit <b>47</b> extracts brightness information of the subject from the image signal outputted from the A/D converter <b>41</b>, generates an illumination control signal so as to make the brightness of the subject appropriate based on current brightness information and outputs the illumination control signal to the light source controller <b>31</b>.</p><p id="p-0084" num="0083">Further, in a case where the color enhancement mode is ON, the control unit <b>47</b> reads the enhancement coefficient from the memory <b>47</b><i>a </i>and controls the color enhancement unit <b>44</b> to perform color enhancement processing using the read enhancement coefficient.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a configuration of the color enhancement unit <b>44</b>.</p><p id="p-0086" num="0085">The color enhancement unit <b>44</b> includes a first memory <b>44</b><i>a</i>, a second memory <b>44</b><i>b</i>, an L*a*b* conversion unit <b>44</b><i>c</i>, a synthesis unit <b>44</b><i>d </i>and an RGB conversion unit <b>44</b><i>e. </i></p><p id="p-0087" num="0086">The first memory <b>44</b><i>a </i>is a memory that stores a first image signal obtained by processing a first image pickup signal generated by picking up an image of return light from the subject irradiated with the first illumination light. Here, the first illumination light is illumination light in which a light amount ratio of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>is set at a first light amount ratio for observing the subject. Specific examples of the first illumination light include white light WL in the normal observation mode, NBI illumination light in the NBI observation mode, and the like.</p><p id="p-0088" num="0087">The second memory <b>44</b><i>b </i>is a memory that stores a second image signal obtained by processing a second image pickup signal generated by picking up an image of return light from the subject irradiated with the second illumination light. Here, the second illumination light is illumination light emitted at a second light amount ratio different from the first light amount ratio using the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>that are the same as the LEDs emitting the first illumination light.</p><p id="p-0089" num="0088">The second illumination light, which is also referred to as color enhancement light CE (color enhance), is light for which the second light amount ratio is adjusted so that a second image signal related to a reference portion of the subject indicates achromatic color within a predetermined error range (in examples in some color spaces, in a case of an RGB color space, R=G=B. CIE (International Commission on Illumination), (hereinafter, &#x201c;CIE&#x201d; will be omitted), in a case of an L*a*b* color space, a*=b*=0, and the like).</p><p id="p-0090" num="0089">Here, examples of the reference portion of the subject include a normal portion in the subject (for example, a normal tissue such as normal mucosa), which does not contain a blood vessel. Further, a biological model may be used as the reference portion of the subject. Thus, in the second image signal, the reference portion of the subject is indicated in achromatic color (gray scale such as white color) and color occurs at an abnormal portion, and the like, other than the reference portion.</p><p id="p-0091" num="0090">The L*a*b* conversion unit <b>44</b><i>c </i>reads the first image signal (it is assumed that the RGB component is (R1, G1, B1)) of an RGB color space stored in the first memory <b>44</b><i>a </i>and converts the first image signal into a first image signal (L1*, a1*, b1*) of an L*a*b* color space.</p><p id="p-0092" num="0091">Further, the L*a*b* conversion unit <b>44</b><i>c </i>reads the second image signal (it is assumed that the RGB component is (R2, G2, B2)) of the RGB color space stored in the second memory <b>44</b><i>b </i>and converts the second image signal into a second image signal (L2*, a2*, b2*) of the L*a*b* color space.</p><p id="p-0093" num="0092">The synthesis unit <b>44</b><i>d </i>generates a corrected image signal by performing color enhancement on the first image signal (L1*, a1*, b1*) based on the second image signal (L2*, a2*, b2*). When the synthesis unit <b>44</b><i>d </i>synthesizes the image signals, the enhancement coefficient transmitted from the control unit <b>47</b> is used as will be described later.</p><p id="p-0094" num="0093">Note that the first image pickup signal and the second image pickup signal are signals acquired through image pickup at different time points (see <figref idref="DRAWINGS">FIG. <b>4</b></figref>, and the like). Thus, the synthesis unit <b>44</b><i>d </i>preferably performs synthesis after processing of adjusting positions of the first image signal (L1*, a1*, b1*) and the second image signal (L2*, a2*, b2*). This can reduce image blurring and color shift due to misalignment.</p><p id="p-0095" num="0094">The RGB conversion unit <b>44</b><i>e </i>converts the signal of the L*a*b* color space subjected to synthesis by the synthesis unit <b>44</b><i>d </i>into a signal of the RGB color space and outputs the signal.</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating color enhancement display processing to be performed by the endoscope apparatus <b>1</b>, <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a timing chart indicating an aspect where white light WL and color enhancement light CE are alternately emitted when the color enhancement mode is ON, and <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a timing chart indicating an example of an aspect where white light WL is emitted when the color enhancement mode is OFF.</p><p id="p-0097" num="0096">Note that the color enhancement display processing illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> is performed by the endoscope apparatus <b>1</b> when the color enhancement mode is ON in either the normal observation mode or the special light observation mode (here, the NBI observation mode).</p><p id="p-0098" num="0097">As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, when the color enhancement mode is ON, the white light WL and the color enhancement light CE are alternately emitted for each one frame of image pickup. However, <figref idref="DRAWINGS">FIG. <b>4</b></figref> merely illustrates an example, and light emission is not limited to the example in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. For example, a modification may be made such that the color enhancement light CE corresponding to one frame is emitted after the white light WL corresponding to two frames is continuously emitted.</p><p id="p-0099" num="0098">Note that while here, a case is assumed where color enhancement is performed by each combination of (WL1, CE1), (WL2, CE2), . . . , among the images picked up through radiation of respective kinds of illumination light illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, color enhancement by each combination of (CE1, WL2), (CE2, WL3), . . . , may be further performed to improve an image pickup frame rate.</p><p id="p-0100" num="0099">Further, when the color enhancement mode is OFF, the image pickup frame rate is preferably improved by emitting the white light WL also at light emission timings of the color enhancement light CE as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> instead of simply preventing emission of the color enhancement light CE. By improving the image pickup frame rate, a movie that can be easily observed can be generated even in a case where there is motion.</p><p id="p-0101" num="0100">In main processing which is not illustrated, if the processing illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> is started, the control unit <b>47</b> and the light source controller <b>31</b> set light amounts of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>to emit the first illumination light (step S<b>1</b>). Here, in an example where the first illumination light is white light WL (in a case of the normal observation mode), the light amounts of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>are set as follows.</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a table indicating a setting example of the light amounts of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>in the first illumination light and the second illumination light when the color enhancement mode is ON in the normal observation mode.</p><p id="p-0103" num="0102">The control unit <b>47</b> sets a light amount Gw of the green LED <b>32</b><i>c </i>in the white light WL based on the brightness information extracted from the image signal outputted from the A/D converter <b>41</b>. Further, the control unit <b>47</b> reads color adjustment coefficients &#x3b1;wv, &#x3b1;wb and &#x3b1;wr for the white light WL from the memory <b>47</b><i>a </i>and multiplies the light amount Gw of the green LED <b>32</b><i>c </i>to respectively calculate a light amount Gv=&#x3b1;wv&#xd7;Gw, of the violet LED <b>32</b><i>a</i>, a light amount Gb=&#x3b1;wb&#xd7;Gw, of the blue LED <b>32</b><i>b</i>, and a light amount Gr=&#x3b1;wr&#xd7;Gw, of the red LED <b>32</b><i>d </i>(see a field of WL in <figref idref="DRAWINGS">FIG. <b>6</b></figref>).</p><p id="p-0104" num="0103">Note that in the present embodiment, by causing the violet LED <b>32</b><i>a </i>and the blue LED <b>32</b><i>b </i>to emit light at the same time, an image of return light from the subject, which is picked up by the B pixel of the image pickup device <b>21</b><i>b</i>, is obtained. The image of the return light is obtained in this manner to supplement the light amount of the blue LED <b>32</b><i>b </i>with the light amount of the violet LED <b>32</b><i>a</i>, and in the normal observation mode, the violet LED <b>32</b><i>a </i>is also substantially dealt with as an LED that emits blue light. However, if there is an enough light amount of the blue LED <b>32</b><i>b</i>, it is also possible to cause the blue LED <b>32</b><i>b </i>to emit light without causing the violet LED <b>32</b><i>a </i>to emit light and obtain return light from the subject by picking up an image with the B pixel.</p><p id="p-0105" num="0104">The control unit <b>47</b> generates an illumination control signal with which the light amounts of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>set in this manner can be obtained and outputs the illumination control signal to the light source controller <b>31</b>.</p><p id="p-0106" num="0105">The light source apparatus <b>3</b> emits the first illumination light, here, for example, the white light WL by the light source controller <b>31</b> supplying a drive current to each semiconductor light emitting device based on the illumination control signal (step S<b>2</b>).</p><p id="p-0107" num="0106">Then, the image pickup device <b>21</b><i>b </i>picks up an image of the return light from the subject to generate a first image pickup signal, and the processor <b>4</b> receives the first image pickup signal from the endoscope <b>2</b>. The processor <b>4</b> processes the first image pickup signal by the preprocessing circuit <b>40</b> to the synchronization processing unit <b>43</b> to generate, for example, a first image signal (R1, G1, B1) having RGB components (step S<b>3</b>). The first image signal (R1, G1, B1) generated here is stored in the first memory <b>44</b><i>a. </i></p><p id="p-0108" num="0107">The L*a*b* conversion unit <b>44</b><i>c </i>reads the first image signal (R1, G1, B1) stored in the first memory <b>44</b><i>a </i>and converts the first image signal into a first image signal (L1*, a1*, b1*) of the L*a*b* color space (step S<b>4</b>).</p><p id="p-0109" num="0108">Then, the control unit <b>47</b> and the light source controller <b>31</b> set light amounts of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>for emitting the second illumination light (step S<b>5</b>). Here, in a case where the first illumination light is the white light WL, the second illumination light is the color enhancement light CE related to the white light WL.</p><p id="p-0110" num="0109">The control unit <b>47</b> sets the light amount of the green LED <b>32</b><i>c </i>in the color enhancement light CE to a light amount basically the same as the light amount Gw of the green LED <b>32</b><i>c </i>in the white light WL to prevent fluctuation of brightness (or luminance) of the first illumination light and the second illumination light.</p><p id="p-0111" num="0110">However, when the light amount of the green LED <b>32</b><i>c </i>in the color enhancement light CE is set at Gw, in a case where at least one of the light amount of the violet LED <b>32</b><i>a</i>, the light amount of the blue LED <b>32</b><i>b </i>or the light amount of the red LED <b>32</b><i>d </i>to be calculated based on the second light amount ratio exceeds a maximum light amount of each kind of color light, the control unit <b>47</b> makes a setting so as to reduce the light amounts of the respective kinds of color light while maintaining the second light amount ratio so that all of the light amount of the violet LED <b>32</b><i>a</i>, the light amount of the blue LED <b>32</b><i>b </i>and the light amount of the red LED <b>32</b><i>d </i>become equal to or less than the maximum light amounts.</p><p id="p-0112" num="0111">Thus, a color adjustment coefficient Kg illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is basically set at 1, and in a case where the second light amount ratio cannot be achieved with Kg=1, for example, the color adjustment coefficient Kg is set at a value Kg&#x3c;1 as appropriate. Further, the light amount Gw of the green LED <b>32</b><i>c </i>in the white light WL is multiplied by the set Kg, and thereby a light amount Gw&#xd7;Kg of the green LED <b>32</b><i>c </i>in the color enhancement light CE is calculated.</p><p id="p-0113" num="0112">Further, the control unit <b>47</b> reads a color adjustment coefficient Kv related to the second light amount ratio from the memory <b>47</b><i>a </i>and multiplies the light amount &#x3b1;wv&#xd7;Gw of the violet LED <b>32</b><i>a </i>in the white light WL to calculate the light amount Gv=&#x3b1;wv&#xd7;Gw&#xd7;Kv, of the violet LED <b>32</b><i>a</i>. Note that it goes without saying that the color adjustment coefficient Kv (and color adjustment coefficients Kb and Kr which will be described below) becomes different values in accordance with whether the color adjustment coefficient Kg is 1 or a value other than 1 to maintain the second light amount ratio.</p><p id="p-0114" num="0113">In a similar manner, the control unit <b>47</b> reads the color adjustment coefficient Kb related to the second light amount ratio from the memory <b>47</b><i>a </i>and multiplies the light amount &#x3b1;wb&#xd7;Gw of the blue LED <b>32</b><i>b </i>in the white light WL to calculate the light amount Gb=&#x3b1;wb&#xd7;Gw&#xd7;Kb, of the blue LED <b>32</b><i>b. </i></p><p id="p-0115" num="0114">The control unit <b>47</b> reads the color adjustment coefficient Kr related to the second light amount ratio from the memory <b>47</b><i>a </i>and multiplies the light amount &#x3b1;wr&#xd7;Gw of the red LED <b>32</b><i>d </i>in the white light WL to calculate the light amount Gr=&#x3b1;wr&#xd7;Gw&#xd7;Kr, of the red LED <b>32</b><i>d </i>(see a field of CE in <figref idref="DRAWINGS">FIG. <b>6</b></figref>).</p><p id="p-0116" num="0115">Here, the respective color adjustment coefficients Kg. Kv, Kb and Kr described above are obtained in advance as such coefficients that cause the second image signal to indicate achromatic color within a predetermined error range based on a spectral reflection factor of the reference portion of the subject, spectral sensitivity characteristics of the image pickup unit <b>21</b> and spectral light emission intensity characteristics of the light source unit <b>32</b> (for example, coefficients that makes an average of respective values of the R component, the G component and the B component the same within a predetermined error range) and are stored in the memory <b>47</b><i>a. </i></p><p id="p-0117" num="0116">It is assumed here that as the spectral reflection factor of the reference portion of the subject, a factor measured from a predetermined distance using the technique as disclosed in, for example, Japanese Patent Application Laid-Open Publication No. 2000-14629 (however, it is of course possible to apply other techniques as appropriate) is used.</p><p id="p-0118" num="0117">Thus, values of the color adjustment coefficients Kg, Kv, Kb and Kr are typically different in accordance with combinations of the endoscope <b>2</b>, the light source apparatus <b>3</b> and the processor <b>4</b>, and thus, for example, the values may be stored in the memory <b>47</b><i>a </i>as a table in accordance with combinations of models.</p><p id="p-0119" num="0118">Note that in a case where Kg=1, a specific example of the second light amount ratio is as follows.</p><p id="p-0120" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>V </i>light:<i>B </i>light:<i>G </i>light:<i>R </i>light=(&#x3b1;<i>wv&#xd7;Kv</i>):(&#x3b1;<i>wb&#xd7;Kb</i>):1:(&#x3b1;<i>wr&#xd7;Kr</i>)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0121" num="0119">Such a second light amount ratio may be changed in real time. For example, the control unit <b>47</b> may adjust the color adjustment coefficients Kv. Kb and Kr related to the second light amount ratio in real time so that an average of the respective signal values of the reference portion (an average will be expressed with &#x3c; &#x3e;) becomes &#x3c;R2&#x3e;=&#x3c;G2&#x3e;=&#x3c;B2&#x3e; within the predetermined error range in the second image signal (R2, G2, B2) of the RGB color space.</p><p id="p-0122" num="0120">Alternatively, the control unit <b>47</b> may calculate an average &#x3c;a2*&#x3e; of a* components and an average &#x3c;b2*&#x3e; of b* components in the reference portion in the second image signal (L2*, a2*, b2*) of the L*a*b* color space and may adjust the color adjustment coefficients Kv, Kb and Kr in real time so that &#x3c;a2*&#x3e; and &#x3c;b2*&#x3e; become 0 within the predetermined error range.</p><p id="p-0123" num="0121">For example, when &#x3c;a*&#x3e; is a positive value, a value of the color adjustment coefficient Kr is lowered, when &#x3c;a*&#x3e; is a negative value, the value of the color adjustment coefficient Kr is increased, when &#x3c;b*&#x3e; is a positive value, values of the color adjustment coefficients Kv and Kb are increased, and when &#x3c;b*&#x3e; is a negative value, the values of the color adjustment coefficients Kv and Kb are lowered. The reference portion in the second image signal may always be indicated in achromatic color within the predetermined error range by, for example, recursively performing such processing.</p><p id="p-0124" num="0122">Alternatively, the following may be performed. First, a user such as a surgeon sets a normal portion which does not contain blood vessels, at a predetermined position where an average is to be calculated in the image by operating the endoscope <b>2</b>. Then, the user operates the input device <b>6</b> to give an instruction to calculate an average at the predetermined position. This allows the user to select a portion which the user desires to be shown in achromatic color.</p><p id="p-0125" num="0123">The control unit <b>47</b> generates the illumination control signal with which the set light amounts of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>can be obtained in this manner and outputs the illumination control signal to the light source controller <b>31</b>.</p><p id="p-0126" num="0124">The light source apparatus <b>3</b> emits second illumination light, here, the color enhancement light CE related to the white light WL based on the illumination control signal (step S<b>6</b>).</p><p id="p-0127" num="0125">Then, the image pickup device <b>21</b><i>b </i>picks up an image of return light from the subject to generate a second image pickup signal, and the processor <b>4</b> receives the second image pickup signal from the endoscope <b>2</b>. The processor <b>4</b> processes the second image pickup signal by the preprocessing circuit <b>40</b> to the synchronization processing unit <b>43</b> to generate, for example, a second image signal (R2, G2, B2) having RGB components (step S<b>7</b>). The second image signal (R2, G2, B2) generated here is stored in the second memory <b>44</b><i>b. </i></p><p id="p-0128" num="0126">The L*a*b* conversion unit <b>44</b><i>c </i>reads the second image signal (R2, G2, B2) stored in the second memory <b>44</b><i>b </i>and converts the second image signal into a second image signal (L2*, a2*, b2*) of the L*a*b* color space (step S<b>8</b>).</p><p id="p-0129" num="0127">Then, the synthesis unit <b>44</b><i>d </i>synthesizes the first image signal (L1*, a1*, b1*) and the second image signal (L2*, a2*, b2*) for each pixel in the L*a*b* color space to generate a color enhanced corrected image signal (step S<b>9</b>).</p><p id="p-0130" num="0128"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a table indicating an example of change of pixel signals of a pixel of a normal tissue and a pixel of a diseased tissue in the corrected image signal obtained by synthesizing the first image signal and the second image signal by the color enhancement unit.</p><p id="p-0131" num="0129">As described above, a normal tissue or the like which does not contain blood vessels is selected as the reference portion of the subject. In this case, as indicated in a field of the normal tissue in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the second illumination light is set so that the normal tissue in the second image is shown in achromatic color (gray scale such as white color), and thus, both values of the a* component and the b* component in the second image signal become 0 within the predetermined error range.</p><p id="p-0132" num="0130">Thus, (as*, bs*) that is an a* component and an b* component of the synthesized corrected image signal does not change from the a* component and the b* component in the first image signal and is as indicated in Equation 1.</p><p id="p-0133" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(<i>as*,bs</i>*)=(<i>a</i>1*,<i>b</i>1*)&#x2003;&#x2003;[Math. 1]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0134" num="0131">In contrast, it is known that reflectance of blue band light to green band light of a diseased tissue, such as a body tissue including inflammation, is lower than reflectance of blue band light to green band light of a normal tissue (absorption of blue band light to green band light is increased). A signal of a pixel obtained by picking up an image of such a diseased tissue has a signal value in which R=G=B does not hold and becomes a signal value in which G&#x3c;R and B&#x3c;R.</p><p id="p-0135" num="0132">In this manner, in a case of a diseased tissue, even if the portion is illuminated with the second illumination light, the portion is not shown in achromatic color (gray scale such as white color), and at least one of the a* component or the b* component of the second image signal has a value (a2*, b2*) other than 0.</p><p id="p-0136" num="0133">The synthesis unit <b>44</b><i>d </i>calculates a component (as*, bs*) of the color enhanced corrected image signal as indicated in Equation 2 below by multiplying the component (a2*, b2*) of the second image signal by the enhancement coefficient C received from the control unit <b>47</b> and adding the result to the component (a1*, b1*) of the first image signal.</p><p id="p-0137" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(<i>as*,bs</i>*)=(<i>a</i>1*+<i>C&#xd7;a</i>2*,<i>b</i>1*+<i>C&#xd7;b</i>2*)&#x2003;&#x2003;[Math. 2]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0138" num="0134">While Equation 2 is also applied to a normal tissue in a similar manner, (a2*, b2*)=(0, 0) in the normal tissue, and thus, a result as indicated in Equation 1 is obtained. Further, if the enhancement coefficient C=1, a simple addition result of the component (a1*, b1*) of the first image signal and the component (a2*, b2*) of the second image signal becomes the component (as*, bs*) of the corrected image signal.</p><p id="p-0139" num="0135">On the other hand, concerning an L* component (luminance component) of the corrected image signal, the synthesis unit <b>44</b><i>d </i>calculates Ls* that is the L* component of the synthesized corrected image signal by performing calculation, for example, as indicated in Equation 3 below using a second enhancement coefficient C2 received from the control unit <b>47</b>.</p><p id="p-0140" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Ls*=L</i>1*+<i>C</i>2&#xd7;(<i>L</i>2*&#x2212;<i>L</i>1*)&#x2003;&#x2003;[Math. 3]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0141" num="0136">The calculation in Equation 3 is correction by multiplying a difference value obtained by subtracting a luminance component L1* of the first image signal from a luminance component L2* of the second image signal by the second enhancement coefficient C2 and adding the result to the luminance component L1* of the first image signal.</p><p id="p-0142" num="0137">As described above, in a case where a light amount of the green LED <b>32</b><i>c </i>in the color enhancement light CE is made the same as a light amount Gw of the green LED <b>32</b><i>c </i>in the white light WL, it is assumed that L1* becomes equal to or close to L2* and Ls* changes little from L1*.</p><p id="p-0143" num="0138">Thus, in Equation 3, the luminance changes little, and mainly a color phase is enhanced by Equation 2.</p><p id="p-0144" num="0139">Note that the synthesis method by the synthesis unit <b>44</b><i>d </i>is not limited to the above-described method, and other various kinds of methods can be applied.</p><p id="p-0145" num="0140"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a table for explaining other examples of the synthesis method by the synthesis unit <b>44</b><i>d. </i></p><p id="p-0146" num="0141">In the calculation method by Equation 2 described above, as indicated in a field of the diseased tissue and the corrected image in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, while a color phase of the component (as*, bs*) of the corrected image signal is close to a color phase of the component (a1*, b1*) of the first image signal, some changes may occur in the color phase.</p><p id="p-0147" num="0142">Thus, a synthesis method indicated in <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a method that does not cause change in a color phase.</p><p id="p-0148" num="0143">A distance of the component (a1*, b1*) of the first image signal from an origin (0, 0) (that is, an L* axis) on an a*b* plane (L*=L1* plane) is set at r1 (see Equation 5 which will be described later), and an angle formed with an a* axis is set at &#x3b8;.</p><p id="p-0149" num="0144">In a similar manner, a distance of the component (a2*, b2*) of the second image signal from the origin (0, 0) on the a*b* plane (L*=L2* plane) is set at r2.</p><p id="p-0150" num="0145">In this event, as indicated in Equation 4 below, the synthesis unit <b>44</b><i>d </i>calculates the component (as*, bs*) of the color enhanced corrected image signal by extending the distance r1 based on the distance r2 using the enhancement coefficient C received from the control unit <b>47</b>.</p><p id="p-0151" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(<i>as*,bs</i>*)=([<i>r</i>1+<i>C&#xd7;r</i>2]cos &#x3b8;,[<i>r</i>1+<i>C&#xd7;r</i>2]sin &#x3b8;)&#x2003;&#x2003;[Math. 4]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0152" num="0146">According to the calculation method indicated in Equation 4, the a*b* plane component of the second image signal is enhanced by the enhancement coefficient C and added to the a*b* plane component of the first image signal. Moreover, an angle formed by the component (as*, bs*) of the corrected image signal and the a* axis is the same as the angle &#x3b8; formed by the component (a1*, b1*) of the first image signal and the a* axis, so that it is possible to perform color enhancement without changing a color phase.</p><p id="p-0153" num="0147">Note that it is only necessary to calculate the L* component (luminance component) of the corrected image signal, for example, through calculation indicated in Equation 3 described above.</p><p id="p-0154" num="0148">Still further, as the synthesis method by the synthesis unit <b>44</b><i>d</i>, a method of performing weighting addition on the component (a1*, b1*) of the first image signal and the component (a2*, b2*) of the second image signal may be used, in which case, weighting may be normalized. On the other hand, for the L* component, a value of the L1* component of the first image signal may be used as is as the L* component of the corrected image signal.</p><p id="p-0155" num="0149">If the corrected image signal is generated by the synthesis unit <b>44</b><i>d </i>in this manner, the RGB conversion unit <b>44</b><i>e </i>converts the corrected image signal of the L*a*b* color space into a signal of the RGB color space and outputs the signal (step S<b>10</b>).</p><p id="p-0156" num="0150">Then, the sharpness enhancement unit <b>45</b> performs sharpness enhancement processing, the display control unit <b>46</b> generates a video signal, and the color enhanced corrected image is displayed at the display <b>5</b> (step S<b>11</b>).</p><p id="p-0157" num="0151">Then, the control unit <b>47</b> determines whether or not a setting of finishing the color enhancement display processing is made by an instruction signal from the input device <b>6</b> or the scope switch <b>23</b> (step S<b>12</b>), and in a case where the setting is not made, the processing returns to step S<b>1</b>, and the processing as described above is repeatedly performed.</p><p id="p-0158" num="0152">On the other hand, in a case where it is determined in step S<b>12</b> that the setting of finishing the color enhancement display processing is made, the processing returns to main processing which is not illustrated.</p><p id="p-0159" num="0153">Note that while <figref idref="DRAWINGS">FIG. <b>6</b></figref> indicates setting examples of the light amounts of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>in the second illumination light, a light amount ratio of the LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>may be changed in accordance with a portion of the subject. <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a table indicating an example of the normal observation mode in which the light amount ratio of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>in the second illumination light is made different in accordance with the portion of the subject.</p><p id="p-0160" num="0154">In an example of a digestive tract, color of the reference portion of the subject differs in accordance with whether the portion of the subject is, for example, esophagus (first portion), stomach (second portion) or large intestine (third portion).</p><p id="p-0161" num="0155">Thus, <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a table in which a color adjustment coefficient (Kv1, Kb1, Kr1) for the first portion, a color adjustment coefficient (Kv2, Kb2, Kr2) for the second portion, and a color adjustment coefficient (Kv3, Kb3, Kr3) for the third portion are prepared in advance as the color adjustment coefficient (Kv, Kb, Kr) and stored in the memory <b>47</b><i>a </i>of the control unit <b>47</b>.</p><p id="p-0162" num="0156">Here, as described above, the color adjustment coefficients for the respective portions are determined in advance as such coefficients that cause the second image signal to indicate achromatic color within the predetermined error range based on a spectral reflection factor of the reference portion of each portion measured using the technique as disclosed in, for example, Japanese Patent Application Laid-Open Publication No. 2000-14629, spectral sensitivity characteristics of the image pickup unit <b>21</b>, and spectral light emission intensity characteristics of the light source unit <b>32</b>.</p><p id="p-0163" num="0157">Then, it is only necessary to select and use one of the color adjustment coefficients in accordance with the portion of the subject upon an examination. Here, the color adjustment coefficient may be selected by the user operating, for example, the input device <b>6</b> or the scope switch <b>23</b> to manually select the portion of the subject. Alternatively, it is also possible to determine the portion of the subject in the image through machine learning such as CNN (convolutional neural network) that has a successful record in image recognition and automatically select the color adjustment coefficient in accordance with the determination result.</p><p id="p-0164" num="0158">Note that while a case where Kg=1 is assumed in <figref idref="DRAWINGS">FIG. <b>7</b></figref>-, Kg #<b>1</b> may be set as necessary in a similar manner to described above. In this case, a color adjustment coefficient such as Kg1, Kg2 and Kg3 different in accordance with the portion of the subject may be used. Here, Kg1 is a color adjustment coefficient to be multiplied by the light amount Gw of the white light WL in first color enhancement light (first CE) with which the first portion is to be irradiated, Kg2 is a color adjustment coefficient to be multiplied by the light amount Gw of the white light WL in second color enhancement light (second CE) with which the second portion is to be irradiated, and Kg3 is a color adjustment coefficient to be multiplied by the light amount Gw of the white light WL in third color enhancement light (third CE) with which the third portion is to be irradiated.</p><p id="p-0165" num="0159">Further, <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a table indicating an example of the normal observation mode in which the light amount ratio of the respective LEDs <b>32</b><i>a </i>to <b>32</b><i>d </i>in the second illumination light is made different in accordance with the portion of the subject and in accordance with a distance from the distal end portion <b>2</b><i>c </i>of the endoscope <b>2</b> to the portion of the subject.</p><p id="p-0166" num="0160">In a case where the distal end portion <b>2</b><i>c </i>of the endoscope <b>2</b> is close to the portion to be examined, the image pickup unit <b>21</b> can acquire the return light, as it is, from the subject irradiated with the illumination light emitted from the illumination optical system <b>22</b>.</p><p id="p-0167" num="0161">In contrast, in a case where the distal end portion <b>2</b><i>c </i>of the endoscope <b>2</b> becomes farther from the portion to be examined, there is a case where other portions are irradiated with return light from a certain portion as secondary light, and light incident on the image pickup unit <b>21</b> from the other portions includes return light of the illumination light and return light of the secondary light that are superimposed.</p><p id="p-0168" num="0162">In this manner, there is a case where the light incident on the image pickup unit <b>21</b> from the subject is affected by reflected light and scattered light (hereinafter, multiple scattered light) including not only secondary light but also typically, higher-order light, in accordance with the distance to the subject.</p><p id="p-0169" num="0163">Spectral components in a red wavelength band increases in the multiple scattered light in a living body, and thus, even if the same illumination light is radiated, the spectral reflection factor of the subject changes in accordance with the distance from the distal end portion <b>2</b><i>c </i>to the subject.</p><p id="p-0170" num="0164">Thus, in the example, Kc1n for near distance, Kc1m for medium distance, and Kc1f for far distance are prepared in advance as the color adjustment coefficient Kc1 (where &#x201c;c&#x201d; indicates color, and c=v (violet), b (blue), r (red)) for the first portion in accordance with whether the distance from the distal end portion <b>2</b><i>c </i>of the endoscope <b>2</b> to the subject is a near distance, a medium distance or a far distance. In a similar manner, also for the color adjustment coefficients Kc2 and Kc3 for the second and the third portions, Kc2n for near distance, Kc2m for medium distance, Kc2f for far distance, Kc3n for near distance, Kc3m for medium distance, and Kc3f for far distance are prepared in advance.</p><p id="p-0171" num="0165">Note that <figref idref="DRAWINGS">FIG. <b>8</b></figref> is similar to described above in that Kg&#x2260;1 may be set, color &#x201c;c&#x201d; may include c=g (green), and Kg1n, Kg1m, Kg1f (the same also applies to cases of the second and the third portions) may be prepared in accordance with the distance to the subject.</p><p id="p-0172" num="0166">It is only necessary to determine the color adjustment coefficient in accordance with the distance based on the spectral reflection factor of each portion measured in each of the near distance, the medium distance and the far distance using, for example, the technique as disclosed in Japanese Patent Application Laid-Open Publication No. 2000-14629 described above.</p><p id="p-0173" num="0167">Specific examples of the determined color adjustment coefficient in a living body can include a color adjustment coefficient that lowers a light amount of the red LED <b>32</b><i>d </i>as the distance becomes farther, Kr1n&#x3e;Kr1m&#x3e;Kr1 f (the same applies to cases of the second and the third portions). Further, to prevent decrease in all the light amounts in association with decrease in the light amount of the red LED <b>32</b><i>d</i>, the respective light amounts of the green LED <b>32</b><i>c</i>, the violet LED <b>32</b><i>a </i>and the blue LED <b>32</b><i>b </i>may be slightly increased as the distance becomes farther.</p><p id="p-0174" num="0168">Note that while the example has been described where the distance is divided into three stages of the near distance, the medium distance and the far distance, the distance may be divided into two stages or may be divided into four or more stages. Alternatively, the color adjustment coefficient corresponding to any distance may be obtained through interpolation.</p><p id="p-0175" num="0169">The color adjustment coefficients prepared in this manner are stored in advance in the memory <b>47</b><i>a </i>of the control unit <b>47</b>, and it is only necessary to select and use one of the color adjustment coefficients in accordance with the portion of the subject and the distance to the subject upon an examination. The selection in this event may be manually set by the user operating the input device <b>6</b> or the scope switch <b>23</b> or may be automatically set by the control unit <b>47</b> based on the distance measured with various kinds of techniques such as distance measurement using laser and distance measurement through image recognition, for example, concerning the distance.</p><p id="p-0176" num="0170">Further, while in the above description, the color adjustment coefficient is made different in accordance with the distance as well as the portion of the subject, the color adjustment coefficient may be made different in accordance with an angle formed by a direction of the distal end portion <b>2</b><i>c </i>of the endoscope <b>2</b> and a direction formed by a plane of the portion of the subject in place of or in addition to the distance.</p><p id="p-0177" num="0171">Further, while an example has been described above where the color enhancement mode is ON in the normal observation mode, as described above, in the endoscope apparatus <b>1</b> of the present embodiment, the color enhancement mode can be put into ON in the NBI observation mode. Here, flow of the color enhancement display processing in the NBI observation mode is similar to the flow indicated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> as described above.</p><p id="p-0178" num="0172"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a table indicating an example of the NBI observation mode in which a light amount ratio of the violet LED <b>32</b><i>a </i>and the green LED <b>32</b><i>c </i>in the second illumination light is made different in accordance with the portion of the subject.</p><p id="p-0179" num="0173">The NBI observation mode is an observation mode in which light with two wavelengths, which is made a narrower band and which is easily absorbed by hemoglobin in the blood, specifically, as described above, violet light with a wavelength from 390 to 445 (nm) and green light with a wavelength from 530 to 550 (nm) is radiated, and capillary vessels in a superficial portion of the mucous membrane and a fine pattern of the mucous membrane are enhanced and displayed.</p><p id="p-0180" num="0174">Thus, in the NBI observation mode, the violet LED <b>32</b><i>a </i>and the green LED <b>32</b><i>c </i>are made to emit light at a first light amount ratio to generate NBI illumination light as first illumination light.</p><p id="p-0181" num="0175">Specifically, the control unit <b>47</b> calculates a light amount Gv=&#x3b1;Nv&#xd7;GN of the violet LED <b>32</b><i>a </i>by multiplying the light amount GN of the green LED <b>32</b><i>c </i>in the NBI illumination light by a color adjustment coefficient &#x3b1;Nv for the NBI illumination light read from the memory <b>47</b><i>a </i>(see a field of NBI in <figref idref="DRAWINGS">FIG. <b>9</b></figref>) (step S<b>1</b>).</p><p id="p-0182" num="0176">Then, the light source apparatus <b>3</b> emits the NBI illumination light of the set light amount (step S<b>2</b>), and the image pickup device <b>21</b><i>b </i>picks up an image of return light from the subject to generate a first image pickup signal. Upon the image pickup, a B pixel mainly picks up an image of return light of violet light, and a G pixel mainly picks up an image of return light of green light.</p><p id="p-0183" num="0177">The synchronization processing unit <b>43</b> allocates the image signal related to the image pickup signal obtained from the B pixel to an R channel and a B channel, allocates the image signal related to the image pickup signal obtained from the G pixel to a G channel and performs synchronization processing (demosaicking processing) to generate, for example, a first image signal (R1. G1, B1) having RGB components (step S<b>3</b>).</p><p id="p-0184" num="0178">The first image signal (R1, G1 B1) is stored in the first memory <b>44</b><i>a </i>and is converted into a first image signal (L1*, a1*, b1*) of the L*a*b* color space by the L*a*b* conversion unit <b>44</b><i>c </i>(step S<b>4</b>).</p><p id="p-0185" num="0179">Then, the control unit <b>47</b> and the light source controller <b>31</b> set light amounts of the violet LED <b>32</b><i>a </i>and the green LED <b>32</b><i>c </i>for emitting the second illumination light (the color enhancement light CE related to the NBI illumination light) in the NBI observation mode (step S<b>5</b>).</p><p id="p-0186" num="0180">First, the light amount of the green LED <b>32</b><i>c </i>in the color enhancement light CE is basically set to the same amount as the light amount GN of the green LED <b>32</b><i>c </i>in the NBI illumination light to prevent fluctuation of brightness (or luminance), in a similar manner to a case of the normal observation mode described above. Further, the light amount of the green LED <b>32</b><i>c </i>in the color enhancement light CE is changed as necessary to achieve the second light amount ratio, also in a similar manner to a case of the normal observation mode described above.</p><p id="p-0187" num="0181">Further, the control unit <b>47</b> reads the color adjustment coefficient Kvx (where &#x201c;x&#x201d; indicates a number of the portion, x=1 in a case of the first portion, x=2 in a case of the second portion, and x=3 in a case of the third portion) related to the second light amount ratio from the memory <b>47</b><i>a </i>and calculates the light amount Gv=&#x3b1;NV&#xd7;GN&#xd7;Kvx of the violet LED <b>32</b><i>a </i>by multiplying the light amount &#x3b1;Nv&#xd7;GN of the violet LED <b>32</b><i>a </i>in the NBI illumination light (see fields of the first to the third CE in <figref idref="DRAWINGS">FIG. <b>9</b></figref>).</p><p id="p-0188" num="0182">Here, the color adjustment coefficient Kvx is a coefficient such that color of the reference portion of the subject in the second image (R2, G2, B2) stored in the second memory <b>44</b><i>b </i>of the color enhancement unit <b>44</b> becomes achromatic color (gray scale such as white color), that is, (a2*, b2*)&#x2248;(0, 0).</p><p id="p-0189" num="0183">Then, the light source apparatus <b>3</b> emits green light and violet light at the set second light amount ratio to thereby generate color enhancement light CE as the second illumination light (step S<b>6</b>).</p><p id="p-0190" num="0184">The image pickup device <b>21</b><i>b </i>picks up an image of return light from the subject irradiated with the color enhancement light CE to generate the second image pickup signal. Upon the image pickup, the B pixel mainly picks up an image of return light of the violet light, and the G pixel mainly picks up an image of return light of the green light.</p><p id="p-0191" num="0185">The synchronization processing unit <b>43</b> allocates the image signal related to the image pickup signal obtained from the B pixel to the R channel and the B channel, allocates the image signal related to the image pickup signal obtained from the G pixel to the G channel and performs synchronization processing (demosaicking processing) to generate a second image signal (R2, G2, B2) (step S<b>7</b>).</p><p id="p-0192" num="0186">The second image signal (R2, G2, B2) is stored in the second memory <b>44</b><i>b </i>and converted into a second image signal (L2*, a2*, b2*) of the L*a*b* color space by the L*a*b* conversion unit <b>44</b><i>c </i>(step S<b>8</b>).</p><p id="p-0193" num="0187">Then, the synthesis unit <b>44</b><i>d </i>synthesizes the first image signal (L1*, a1*, b1*) and the second image signal (L2*, a2*, b2*) using one of the methods described above regarding the normal observation mode to generate a color enhanced corrected image signal (step S<b>9</b>).</p><p id="p-0194" num="0188">If the corrected image signal is generated by the synthesis unit <b>44</b><i>d </i>in this manner, the RGB conversion unit <b>44</b><i>e </i>converts the corrected image signal of the L*a*b* color space into a signal of the RGB color space and outputs the signal (step S<b>10</b>).</p><p id="p-0195" num="0189">Then, the sharpness enhancement unit <b>45</b> performs sharpness enhancement processing, and the display control unit <b>46</b> generates a video signal. When the display control unit <b>46</b> generates the video signal, the display control unit <b>46</b> performs pseudo color processing of allocating the image signal of the G channel to the R channel and allocating the image signal of the B channel to the G channel and the B channel. The corrected image in the NBI observation mode, for which color is enhanced with the video signal generated in this manner is displayed at the display <b>5</b> (step S<b>11</b>).</p><p id="p-0196" num="0190">Then, whether or not the processing is finished is determined (step S<b>12</b>), and in a case where the processing is not finished, the processing returns to step S<b>1</b>, and in a case where the processing is finished, the processing returns to main processing which is not illustrated, as described above.</p><p id="p-0197" num="0191">Note that while <figref idref="DRAWINGS">FIG. <b>9</b></figref> indicates an example where the color adjustment coefficient Kvx is made different in accordance with the portion of the subject, as described with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the color adjustment coefficient Kv may be made different in accordance with a distance and an angle.</p><p id="p-0198" num="0192">Further, while in the above description, NBI illumination is performed with a combination of the violet LED <b>32</b><i>a </i>and the green LED <b>32</b><i>c</i>, for example, an amber LED that emits amber light may be additionally provided (so-called a configuration of five LEDs) within the light source apparatus <b>3</b> to perform second NBI illumination.</p><p id="p-0199" num="0193">In this case, the control unit <b>47</b> only requires to control the light source apparatus <b>3</b> to emit red light, green light and amber light at a first light amount ratio to thereby generate the second NBI illumination light (first illumination light) and emit red light, green light and amber light at a second light amount ratio to thereby generate color enhancement light as the second illumination light.</p><p id="p-0200" num="0194">Further, color enhancement may be performed in a similar manner to that described above also in the special light observation mode such as an infrared observation mode and a fluorescent observation mode, as well as the NBI observation mode.</p><p id="p-0201" num="0195"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a graph indicating an example where a color enhancement amount is changed in accordance with a distance of the component (a1*, b1*) of the first image signal on the a*b* plane from the L* axis.</p><p id="p-0202" num="0196">For example, if color enhancement is performed on the component (a1*, b1*) of the first image signal at a constant color enhancement amount, there is a case where color enhancement becomes excessive in a region where intensity is high, and the calculated value may exceed a feasible color range.</p><p id="p-0203" num="0197">Thus, as indicated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the color enhancement amount is preferably changed in accordance with the distance of the component (a1*, b1*) of the first image signal from the L* axis.</p><p id="p-0204" num="0198">First, the distance of the component (a1*, b1*) of the first image signal from the L* axis is calculated as indicated in Equation 5 below as the distance r1 from the origin (0, 0) on the a*b* plane.</p><p id="p-0205" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>r</i>1=&#x221a;{square root over (&#x3b1;1*<sup>2</sup><i>+b</i>1*<sup>2</sup>)}&#x2003;&#x2003;[Math. 5]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0206" num="0199">In a similar manner, the distance of the component (as*, bs*) of the corrected image signal from the L* axis is calculated as indicated in Equation 6 below as the distance rs from the origin (0, 0) on the a*b* plane.</p><p id="p-0207" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>rs</i>=&#x221a;{square root over (&#x3b1;<i>s*</i><sup>z</sup><i>+bs*</i><sup>2</sup>)}&#x2003;&#x2003;[Math. 6]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0208" num="0200">A straight dotted line in <figref idref="DRAWINGS">FIG. <b>12</b></figref> indicates a case where the distance rs is equal to the distance r1, and color enhancement is not performed.</p><p id="p-0209" num="0201">On the other hand, functions f1 to f3 indicated in <figref idref="DRAWINGS">FIG. <b>12</b></figref> indicate some examples of a function f that performs color enhancement in accordance with the distance r1. The function f is expressed, for example, as indicated in Equation 7 below using a constant k (0&#x3c;k) and &#x3b3; (0&#x3c;&#x3b3;&#x3c;1) representing an exponent.</p><p id="p-0210" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>rs=f</i>(<i>r</i>1)=<i>k&#xb7;r</i>1<sup>&#x3b3;</sup>&#x2003;&#x2003;[Math. 7]<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0211" num="0202">Here, &#x3b3; representing an exponent mainly determines a curved shape of the function f, and if a value of &#x3b3; is close to 1, the color enhancement amount becomes small as indicated in the function f3 of a dashed-two dotted line, if the value of &#x3b3; is close to 0, the color enhancement amount becomes large as indicated in the function f1 of a solid line, and if the value of &#x3b3; is medium, the color enhancement amount becomes medium as indicated in the function f2 of a dashed-dotted line. In other words, if &#x3b3; of the function f1 is set at &#x3b3;1, &#x3b3; of the function f2 is set at &#x3b3;<sup>2</sup>, and &#x3b3; of the function f3 is set at &#x3b3;3, a relationship of 0&#x3c;&#x3b3;1&#x3c;&#x3b3;2&#x3c;&#x3b3;3&#x3c;1 holds.</p><p id="p-0212" num="0203">Then, in the examples of all of the functions f1 to f3, the processor <b>4</b> sets the enhancement coefficient C so that the enhancement coefficient C monotonously decreases to gradually come closer to 0 in accordance with increase in the distance r1 from the L* axis on the a*b* plane.</p><p id="p-0213" num="0204">Setting methods of the enhancement coefficient C as indicated in the functions f1 to f3 may be prepared in advance, and, for example, the user may select a setting method with which a desired color enhancement amount can be obtained.</p><p id="p-0214" num="0205">Further, as indicated in an upper right corner in the graph in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, a maximum value of the distance r1 is equal to a maximum value of the distance rs, and thus, even if color enhancement is performed using the method indicated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, a feasible color range is not exceeded.</p><p id="p-0215" num="0206">Thus, by changing the enhancement coefficient C with the setting method as indicated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, it is possible to effectively perform color enhancement in a region where intensity is low while preventing color enhancement from becoming excessive in a region where intensity is high in the color space.</p><p id="p-0216" num="0207">Next, <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a graph indicating an example of a region where color enhancement is to be performed on the a*b* plane.</p><p id="p-0217" num="0208">As indicated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the region where color enhancement is to be performed on the a*b* plane may be limited to a constant range.</p><p id="p-0218" num="0209">In other words, while color enhancement is performed on a pixel (pixel for which the component (a1*, b1*) falls within a hatched region indicated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>) for which the distance r1 of the component (a1*, b1*) of the first image signal from the origin (0, 0) on the a*b* plane is less than a predetermined distance rth, color enhancement is not performed on a pixel for which the distance r1 is equal to or greater than the predetermined distance rth, and the component (a1*, b1*) of the first image signal is used as is as the component (as*, bs*) of the corrected image signal. Note that in this event, smoothing processing is preferably performed to prevent the color enhancement amount from rapidly changing in the distance r1=rth.</p><p id="p-0219" num="0210">Note that while in the above description, the same enhancement coefficient C is used as the enhancement coefficient for the a* component and the enhancement coefficient for the b* component, the enhancement coefficients are not limited to these, and different enhancement coefficients may be set for the a* component and the b* component.</p><p id="p-0220" num="0211">According to such a first embodiment, the first image signal related to the first illumination light for observing the subject is generated, the second image signal related to the second illumination light with which the reference portion of the subject is shown in achromatic color is generated, and color enhancement is performed based on the first image signal and the second image signal, so that it is possible to perform display while enhancing a slight difference in color without degrading color reproducibility.</p><p id="p-0221" num="0212">In this event, in the second image signal, a portion with a spectral reflection factor different from a spectral reflection factor of the reference portion is not shown in achromatic color and has color, so that it is possible to perform color enhancement based on a difference in color through simple processing of adding the second image signal to the first image signal.</p><p id="p-0222" num="0213">Further, color enhancement is performed using the second image signal acquired through radiation of the second illumination light, so that it is possible to prevent occurrence of artifacts depending on an image processing condition unlike with a case where color enhancement is performed by image processing being performed only on the first image signal.</p><p id="p-0223" num="0214">Further, color enhancement is performed by converting the first image signal and the second image signal in such a way that signals of the RGB color space are converted into signals of the L*a*b* color space and respectively adding the a* component and the b* component of the second image signal to the a* component and the b* component of the first image signal, which separates the luminance component L*, so that it is possible to perform color enhancement while efficiently handling a color phase and intensity.</p><p id="p-0224" num="0215">In this event, it is possible to control the color enhancement amount by multiplying the a* component and the b* component of the second image signal by the enhancement coefficient C and respectively adding the results to the a* component and the b* component of the first image signal.</p><p id="p-0225" num="0216">Further, by setting the enhancement coefficient C so as to monotonously decrease to gradually come closer to 0 in accordance with increase of the distance r1 of the first image signal from the L* axis, it is possible to prevent color enhancement from becoming excessive in a region where intensity is high and effectively perform color enhancement in a region where intensity is low.</p><p id="p-0226" num="0217">Further, it is possible to prevent color enhancement in a region where intensity is high by avoiding color enhancement in a case where the distance r1 of the first image signal from the L* axis is equal to or greater than the predetermined distance rth.</p><p id="p-0227" num="0218">Then, by correcting the luminance component based on Equation 3, it is possible to obtain a luminance component of the corrected image signal having appropriate balance between luminance of the first image signal and luminance of the second image signal.</p><p id="p-0228" num="0219">On the other hand, in a case where the distance r1 of the first image signal from the L* axis is extended based on the distance r2 of the second image signal from the L* axis using Equation 4, it is possible to perform color enhancement without changing a color phase.</p><p id="p-0229" num="0220">Further, in a case where the color enhancement mode is ON using the white light WL as the first illumination light, an image of the normal observation mode, for which color is enhanced, can be observed.</p><p id="p-0230" num="0221">In this event, the light amount of the green light in the second illumination light is made as close as possible to the light amount of the green light in the first illumination light, so that fluctuation of brightness (or luminance) can be prevented.</p><p id="p-0231" num="0222">However, the light amount of each kind of color light is reduced within a range of a maximum light amount of each kind of color light as necessary while the second light amount ratio is maintained, and thus, even in a case where the light amount of the green light in the second illumination light cannot be made the same as the light amount of the green light in the first illumination light, the corrected image in which color is appropriately enhanced can be obtained.</p><p id="p-0232" num="0223">Further, in a case where the color enhancement mode is ON using the NBI illumination light as the first illumination light, an image in the NBI observation mode, for which color is enhanced, can be observed. In this event, observation can be performed while color is enhanced in any of the NBI observation mode in which green light and violet light are combined, and the second NBI observation mode in which red light, green light and amber light are combined.</p><p id="p-0233" num="0224">Then, by adjusting the second light amount ratio in real time, it is possible to always perform appropriate color enhancement on each frame of, for example, a movie.</p><p id="p-0234" num="0225">Note that while an example of the CIE L*a*b* color space has been described in the above description, the color space is not limited to this, and other color coordinate systems may be used. As an example, a lightness color difference space YCrCb may be used. In this case, in the above description, it is only necessary to respectively replace L*, a* and b* with Y, Cr and Cb.</p><p id="p-0235" num="0226">Note that while a case has been mainly described above where the present invention is an endoscope apparatus (endoscope system) including a processor, the present invention is not limited to this and may be a processing apparatus including a processor, a color enhancement method for performing color enhancement in a similar manner to the endoscope apparatus, a computer program for causing a computer to perform processing similar to the processing of the endoscope apparatus, a computer readable non-temporary recording medium that records the computer program, and the like.</p><p id="p-0236" num="0227">Further, the present invention is not limited to the exact embodiment described above and can be embodied while modifying components within a range not deviating from the gist in an implementation stage. Further, various aspects of the invention can be formed by appropriately combining a plurality of components disclosed in the above-described embodiment. For example, some components may be deleted from all the components described in the embodiment. Further, components across different embodiments may be combined as appropriate. In this manner, various modifications and application can be performed within a range not deviating from the gist of the invention.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An endoscope system comprising:<claim-text>an endoscope;</claim-text><claim-text>a light source apparatus; and</claim-text><claim-text>a processing apparatus, wherein</claim-text><claim-text>the light source apparatus includes a plurality of semiconductor light emitting devices configured to emit light with different center wavelengths and causes the plurality of semiconductor light emitting devices to emit light at a certain light amount ratio to generate illumination light,</claim-text><claim-text>the endoscope includes an image pickup device configured to pick up an image of return light from a subject irradiated with the illumination light to generate an image pickup signal having a plurality of color components,</claim-text><claim-text>the processing apparatus includes a processor,</claim-text><claim-text>the processor is configured to execute:</claim-text><claim-text>controlling the light source apparatus to switch light between first illumination light emitted at a first light amount ratio and second illumination light emitted at a second light amount ratio different from the first light amount ratio;</claim-text><claim-text>generating a first image signal based on an image pickup signal obtained by picking up an image of a subject illuminated with the first illumination light;</claim-text><claim-text>generating a second image signal based on an image pickup signal obtained by picking up an image of the subject illuminated with the second illumination light; and</claim-text><claim-text>generating a corrected image signal in which color is enhanced based on the first image signal and the second image signal, and</claim-text><claim-text>the second illumination light is light obtained by adjusting the second light amount ratio so that the second image signal related to a reference portion of the subject indicates achromatic color within a predetermined error range.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The endoscope system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor<claim-text>converts the first image signal and the second image signal in such a way that signals of an RGB color space are converted into signals of a CIE L*a*b* color space, and</claim-text><claim-text>enhances color of the first image signal by respectively adding an a* component and a b* component of the second image signal to an a* component and a b* component of the first image signal in the CIE L*a*b* color space.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The endoscope system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the processor enhances color of the first image signal by multiplying the a* component and the b* component of the second image signal by an enhancement coefficient and then respectively adding the a* component and the b* component multiplied by the enhancement coefficient to the a* component and the b* component of the first image signal.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The endoscope system according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein<claim-text>the processor sets the enhancement coefficient so that the enhancement coefficient monotonously decreases to gradually come closer to 0 in accordance with increase in a distance of the first image signal from an L* axis on an a*b* plane in the CIE L*a*b* color space.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The endoscope system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein<claim-text>the processor does not perform color enhancement in a case where the distance of the first image signal from the L* axis on the a*b* plane in the CIE L*a*b* color space is equal to or greater than a predetermined distance.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The endoscope system according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein<claim-text>the processor further multiplies a difference value obtained by subtracting an L* component of the first image signal from an L* component of the second image signal by a second enhancement coefficient and adds the difference value multiplied by the second enhancement coefficient to the L* component of the first image signal.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The endoscope system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the processor converts the first image signal and the second image signal in such a way that signals of an RGB color space are converted into signals of a CIE L*a*b* color space, and</claim-text><claim-text>enhances color of the first image signal by extending a distance of the first image signal from an L* axis on an a*b* plane based on a distance of the second image signal from the L* axis on the a*b* plane in the CIE L*a*b* color space.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The endoscope system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the light source apparatus includes a semiconductor light emitting device configured to emit red light, a semiconductor light emitting device configured to emit green light, and a semiconductor light emitting device configured to emit blue light,</claim-text><claim-text>the processor controls the light source apparatus to:</claim-text><claim-text>generate white light as the first illumination light by causing red light, green light and blue light to be emitted at the first light amount ratio; and</claim-text><claim-text>generate color enhancement light as the second illumination light by causing red light, green light and blue light to be emitted at the second light amount ratio.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The endoscope system according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein<claim-text>concerning a light amount of red light and a light amount of blue light calculated based on the second light amount ratio when a light amount of green light in the second illumination light is made same as a light amount of green light in the first illumination light,</claim-text><claim-text>the processor sets a light amount of green light in the second illumination light to a light amount that is the same as the light amount of the green light in the first illumination light in a case where both the light amount of the red light and the light amount of the blue light are equal to or less than a maximum light amount, and</claim-text><claim-text>makes a setting so as to reduce the light amounts of the green light, the red light and the blue light while maintaining the second light amount ratio so that both the light amount of the red light and the light amount of the blue light become equal to or less than the maximum light amount in a case where at least one of the light amount of the red light or the light amount of the blue light exceeds the maximum light amount.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The endoscope system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the light source apparatus includes a semiconductor light emitting device configured to emit green light and a semiconductor light emitting device configured to emit violet light, and</claim-text><claim-text>the processor controls the light source apparatus to:</claim-text><claim-text>cause NBI illumination light as the first illumination light to be generated by causing green light and violet light to be emitted at the first light amount ratio; and</claim-text><claim-text>cause color enhancement light as the second illumination light to be generated by causing green light and violet light to be emitted at the second light amount ratio.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The endoscope system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the light source apparatus includes a semiconductor light emitting device configured to emit red light, a semiconductor light emitting device configured to emit green light, and a semiconductor light emitting device configured to emit amber light, and</claim-text><claim-text>the processor controls the light source apparatus to:</claim-text><claim-text>cause NBI illumination light as the first illumination light to be generated by causing red light, green light and amber light to be emitted at the first light amount ratio; and</claim-text><claim-text>cause color enhancement light as the second illumination light to be generated by causing red light, green light and amber light to be emitted at the second light amount ratio.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The endoscope system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the processor adjusts the second light amount ratio in real time so that the second image signal indicates achromatic color within a predetermined error range.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The endoscope system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the second illumination light is set so that a normal tissue in the second image signal is shown in achromatic color.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The endoscope system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>both the a* component and the b* component in the second image signal are 0 within a predetermined error range.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A processing apparatus comprising:<claim-text>a processor, wherein</claim-text><claim-text>the processor is configured to execute:</claim-text><claim-text>controlling a light source apparatus to switch light between first illumination light in which a plurality of kinds of light with different center wavelengths are emitted at a first light amount ratio and second illumination light in which the plurality of kinds of light are emitted at a second light amount ratio different from the first light amount ratio;</claim-text><claim-text>generating a first image signal based on an image pickup signal obtained by picking up an image of a subject illuminated with the first illumination light;</claim-text><claim-text>generating a second image signal based on an image pickup signal obtained by picking up an image of the subject illuminated with the second illumination light; and</claim-text><claim-text>generating a corrected image signal in which color is enhanced based on the first image signal and the second image signal, and</claim-text><claim-text>the second illumination light is light obtained by adjusting the second light amount ratio so that the second image signal related to a reference portion of the subject indicates achromatic color within a predetermined error range.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A color enhancement method comprising:<claim-text>emitting light while switching light between first illumination light in which a light amount ratio of a plurality of kinds of light with different center wavelengths is set at a first light amount ratio and second illumination light in which the light amount ratio is set at a second light amount ratio different from the first light amount ratio;</claim-text><claim-text>generating a first image signal based on an image pickup signal obtained by picking up an image of a subject illuminated with the first illumination light;</claim-text><claim-text>generating a second image signal based on an image pickup signal obtained by picking up an image of the subject illuminated with the second illumination light;</claim-text><claim-text>generating a corrected image signal in which color is enhanced based on the first image signal and the second image signal; and</claim-text><claim-text>adjusting the second light amount ratio so that the second image signal related to a reference portion of the subject indicates achromatic color within a predetermined error range.</claim-text></claim-text></claim></claims></us-patent-application>
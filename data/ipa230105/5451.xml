<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005452A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005452</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17782854</doc-number><date>20191206</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>09</class><subclass>G</subclass><main-group>5</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>3</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>5</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>3</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2340</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2340</main-group><subgroup>0407</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SIGNAL PROCESSING DEVICE AND IMAGE DISPLAY APPARATUS INCLUDING THE SAME</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>LG ELECTRONICS INC.</orgname><address><city>Seoul</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Changhyun</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>YANG</last-name><first-name>Jeonghyu</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>LIM</last-name><first-name>Jungeun</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Junseong</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>LIM</last-name><first-name>Sunguk</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>LG ELECTRONICS INC.</orgname><role>03</role><address><city>Seoul</city><country>KR</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/KR2019/017179</doc-number><date>20191206</date></document-id><us-371c12-date><date>20220606</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Provided are a signal processing device and an image display apparatus including the same. The signal processing device and the image display apparatus including the same include: a signal processor <b>170</b><i>a </i>may include an OSC processor configured to upscale an OSC having a first resolution to a second resolution greater than the first resolution; and a synthesizer configured to synthesize at least a part of an image having the second resolution and the upscaled OSD having the second resolution, and the OSD processor outputs the OSD having the second resolution, in which luminance and transparency are adjusted.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="112.86mm" wi="158.58mm" file="US20230005452A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="133.18mm" wi="160.61mm" file="US20230005452A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="167.05mm" wi="166.96mm" file="US20230005452A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="107.87mm" wi="163.49mm" file="US20230005452A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="93.30mm" wi="132.33mm" file="US20230005452A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="221.06mm" wi="150.45mm" file="US20230005452A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="132.00mm" wi="237.74mm" file="US20230005452A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="121.67mm" wi="133.35mm" file="US20230005452A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="127.68mm" wi="128.44mm" file="US20230005452A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="131.23mm" wi="236.47mm" file="US20230005452A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="157.31mm" wi="87.46mm" file="US20230005452A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="216.41mm" wi="163.75mm" file="US20230005452A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="205.23mm" wi="146.98mm" file="US20230005452A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="161.80mm" wi="126.83mm" file="US20230005452A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="121.84mm" wi="142.16mm" file="US20230005452A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="160.19mm" wi="155.28mm" file="US20230005452A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><heading id="h-0002" level="1">1. Field</heading><p id="p-0002" num="0001">The present disclosure relates to a signal processing device and an image display apparatus including the same, and more particularly, a signal processing device capable of stably improving resolution even when input images of various resolutions are input, and an image display apparatus including the same.</p><heading id="h-0003" level="1">2. Related Art</heading><p id="p-0003" num="0002">The signal processing device is a device that performs signal processing on an input image so that an image may be displayed.</p><p id="p-0004" num="0003">For example, the signal processing device may receive images of various resolutions through an external device or an external server and may perform signal processing thereon.</p><p id="p-0005" num="0004">Meanwhile, in recent years, with the increase in resource of the input image, when an OSD and the input image are displayed jointly, a case where degradation of an image quality in an OSD area occurs has frequently happened.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">An object of the present disclosure is to provide a signal processing device and an image display apparatus including the same capable of increasing a clarity of an OSD when mixing with an image.</p><p id="p-0007" num="0006">Another object of the present disclosure is to provide a signal processing device and an image display apparatus including the same capable of increasing the clarity of the OSD and reducing noise when mixing with the image while increasing a resolution of the OSD.</p><p id="p-0008" num="0007">Yet another object of the present disclosure is to provide a signal processing device and an image display apparatus including the same capable of increasing the clarity of the OSD and reducing the noise when mixing with the image while increasing the resolution of the OSD by using a deep neural network.</p><p id="p-0009" num="0008">In an aspect of the present disclosure, a signal processing device and an image display apparatus including the same include: an OSC processor configured to upscale an OSC having a first resolution to a second resolution greater than the first resolution; and a synthesizer configured to synthesize at least a part of an image having the second resolution and the upscaled OSD having the second resolution, and the OSD processor outputs the OSD having the second resolution, in which luminance and transparency are adjusted.</p><p id="p-0010" num="0009">Meanwhile, in another aspect of the present disclosure, a signal processing device and an image display apparatus including the same include: an OSC processor configured to upscale an OSD having a first resolution to a second resolution greater than the first resolution; and a synthesizer configured to synthesize at least a part of an image having the second resolution and the upscaled OSD having the second resolution, and the OSD processor outputs the OSD having the second resolution, in which a blending ratio of the image and the OSD, and luminance are adjusted.</p><heading id="h-0005" level="1">Advantageous Effects</heading><p id="p-0011" num="0010">The signal processing device and the image display apparatus including the same include: an OSC processor configured to upscale an OSC having a first resolution to a second resolution greater than the first resolution; and a synthesizer configured to synthesize at least a part of an image having the second resolution and the upscaled OSD having the second resolution, and the OSD processor outputs the OSD having the second resolution, in which luminance and transparency are adjusted. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0012" num="0011">Meanwhile, the OSD processor may control the luminance and the transparency of the OSD having the second resolution to be greater than the luminance and the transparency of the</p><p id="p-0013" num="0012">OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0014" num="0013">Meanwhile, the OSD processor may control change amounts of the luminance and the transparency of the OSD having the second resolution to further increase as a difference between the first resolution and the second resolution increases. As such, the change amounts of the luminance and the transparency are changed according to the difference between the first resolution and the second resolution to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0015" num="0014">Meanwhile, the OSD processor may be configured to increase the transparency of the OSD having the second resolution as the luminance of the image increases and decrease the transparency of the OSD having the second resolution as the luminance of the image decreases. As such, the transparency is adjusted according to the luminance of the image to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0016" num="0015">Meanwhile, the OSD processor may be configured to increase sharpness of the transparency of the OSD having the second resolution. As such, the sharpness of the transparency is adjusted to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0017" num="0016">Meanwhile, the OSD processor may be configured to increase the luminance and the sharpness of the transparency of the OSD having the second resolution. As such, the sharpness of the transparency is adjusted to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0018" num="0017">Meanwhile, the OSD processor may be configured to increase change amounts of the luminance and the sharpness of the transparency of the OSD having the second resolution as the luminance of the image increases and decrease the change amounts of the luminance and the sharpness of the transparency of the OSD having the second resolution as the luminance of the image decreases. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0019" num="0018">Meanwhile, the OSD processor may output the OSD having the second resolution, in which a color is further adjusted. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0020" num="0019">Meanwhile, the OSD processor may control a level of the color of the OSD having the second resolution to be greater than the level of the color of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0021" num="0020">Meanwhile, the signal processor may include a first resolution processor configured to change the luminance of the OSD having the first resolution to the luminance of the OSD having the second resolution, a second resolution processor configured to change the transparency of the OSD having the first resolution to the luminance of the OSD having the second resolution, and a third resolution processor configured to change a color of the OSD having the first resolution to the color of the OSD having the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0022" num="0021">Meanwhile, the signal processor may include a learning processor configured to change the luminance of the OSD having the first resolution to the luminance of the OSD having the second resolution, and change the transparency of the OSD having the first resolution to the transparency of the OSD having the second resolution, based on learning a deep neural network, and a resolution processor configured to change the color of the OSD having the first resolution to the color of the OSD having the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0023" num="0022">Meanwhile, in another aspect of the present disclosure, a signal processing device and an image display apparatus including the same include: an OSC processor configured to upscale an OSD having a first resolution to a second resolution greater than the first resolution; and a synthesizer configured to synthesize at least a part of an image having the second resolution and the upscaled OSD having the second resolution, and the OSD processor outputs the OSD having the second resolution, in which a blending ratio of the image and the OSD, and luminance are adjusted. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0024" num="0023">Meanwhile, the OSD processor may control the luminance and the blending ratio of the OSD having the second resolution to be greater than the luminance and the blending ratio of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0025" num="0024">Meanwhile, the OSD processor may control change amounts of the luminance and the blending ratio of the OSD having the second resolution to further increase as a difference between the first resolution and the second resolution increases. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image. As such, the change amounts of the luminance and the blending ratio are changed according to the difference between the first resolution and the second resolution to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0026" num="0025">Meanwhile, the OSD processor may be configured to increase the blending ratio of the OSD having the second resolution as the luminance of the image increases and control the blending ratio of the OSD having the second resolution to decrease as the luminance of the image decreases. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image. As such, the blending ratio is adjusted according to the luminance of the image to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0027" num="0026">Meanwhile, the OSD processor may be configured to increase sharpness of the blending ratio of the OSD having the second resolution. As such, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image according to the blending ratio.</p><p id="p-0028" num="0027">Meanwhile, the OSD processor may be configured to increase change amounts of the luminance and the sharpness of the blending ratio of the OSD having the second resolution as the luminance of the image increases and decrease the change amounts of the luminance and the sharpness of the blending ratio of the OSD having the second resolution as the luminance of the image decreases. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0029" num="0028">Meanwhile, the OSD processor may output the OSD having the second resolution, in which a color is further adjusted. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0030" num="0029">Meanwhile, the OSD processor may control a level of the color of the OSD having the second resolution to be greater than the level of the color of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0031" num="0030">Meanwhile, the signal processor may include a first resolution processor configured to change the luminance of the OSD having the first resolution to the luminance of the OSD having the second resolution, a second resolution processor configured to change the blending ratio of the OSD having the first resolution to the blending ratio of the OSD having the second resolution, and a third resolution processor configured to change the color of the OSD having the first resolution to the color of the OSD having the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an image display system according to an embodiment of the present disclosure;</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is an example of an internal block diagram of an image display apparatus of <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is an example of an internal block diagram of a signal processor of <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> illustrates a control method of a remote control device of <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is an internal block diagram of the remote control device of <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an internal block diagram of a display of <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIGS. <b>6</b>A to <b>6</b>B</figref> are views referenced for illustrating an organic light emitting panel of <figref idref="DRAWINGS">FIG. <b>5</b></figref>;</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example of an internal block diagram of a signal processor of <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIGS. <b>8</b>A to <b>8</b>B</figref> are views referenced for illustrating an operation of the signal processor of <figref idref="DRAWINGS">FIG. <b>7</b></figref>;</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a view illustrating that an OSD and an image are mixed and displayed;</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a view illustrating an internal block diagram of a signal processor according to an embodiment of the present disclosure;</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a view illustrating an internal block diagram of a signal processor according to another embodiment of the present disclosure; and</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIGS. <b>12</b>A to <b>13</b></figref> are views referenced for the operation description of <figref idref="DRAWINGS">FIG. <b>10</b> or <b>11</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0045" num="0044">Hereinafter, the present disclosure will be described in more detail with reference to the drawings.</p><p id="p-0046" num="0045">The suffixes &#x201c;module&#x201d; and &#x201c;unit&#x201d; for the constituent elements used in the following description are given in consideration of only the ease of preparation of the present disclosure and do not impart a particularly important meaning or role by themselves. Accordingly, the &#x201c;module&#x201d; and &#x201c;unit&#x201d; may be used interchangeably with each other.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an image display system according to an embodiment of the present disclosure.</p><p id="p-0048" num="0047">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, an image display system <b>10</b> according to an embodiment of the present disclosure may include an image display apparatus <b>100</b> having a display <b>180</b>, a set-top box <b>300</b>, and a server <b>600</b>.</p><p id="p-0049" num="0048">The image display apparatus <b>100</b> according to an embodiment of the present disclosure may receive an image from the set-top box <b>300</b> or the server <b>600</b>.</p><p id="p-0050" num="0049">For example, the image display apparatus <b>100</b> may receive an image signal from the set-top box <b>300</b> through an HDMI terminal.</p><p id="p-0051" num="0050">As another example, the image display apparatus <b>100</b> may receive an image signal from the server <b>600</b> through a network terminal.</p><p id="p-0052" num="0051">Meanwhile, the image display apparatus <b>100</b> may receive input images of various resolutions through an external set-top box <b>300</b> or a network.</p><p id="p-0053" num="0052">Meanwhile, the image display apparatus <b>100</b> according to an embodiment of the present disclosure upscales the resolution of the OSD to the resolution of the input image and synthesizes at least a part of the input image and the upscaled OSD, however, synthesizes the upscaled OSD of which luminance and transparency are adjusted with the at least a part of the input image when the resolution of the input image and the resolution of the OSD are different from each other. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and noise may be reduced when mixing with the image.</p><p id="p-0054" num="0053">Meanwhile, the image display apparatus <b>100</b> according to another embodiment of the present disclosure upscales the resolution of the OSD to the resolution of the input image and synthesizes at least a part of the input image and the upscaled OSD, however, synthesizes the upscaled OSD in which a blending ratio of the image and the OSD is adjusted with the at least a part of the input image when the resolution of the input image and the resolution of the OSD are different from each other. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0055" num="0054">Meanwhile, the display <b>180</b> may be implemented with any one of various panels. For example, the display <b>180</b> may be any one of a liquid crystal display panel (LCD panel), an organic light emitting diode panel (OLED panel), an inorganic light emitting diode panel (LED panel).</p><p id="p-0056" num="0055">In the present invention, an example in which the display <b>180</b> includes the organic light emitting diode panel (OLED panel) is mainly described.</p><p id="p-0057" num="0056">Meanwhile, the OLED panel exhibits a faster response speed than the LED and is excellent in color reproduction.</p><p id="p-0058" num="0057">Accordingly, if the display <b>180</b> includes an OLED panel, it is preferable that the signal processor <b>170</b> (see <figref idref="DRAWINGS">FIG. <b>2</b></figref>) of the image display apparatus <b>100</b> performs image quality processing for the OLED panel. Meanwhile, the signal processor may be called a signal processing device. Hereinafter, the signal processing device and the signal processor are used to have the same meaning.</p><p id="p-0059" num="0058">Meanwhile, the image display apparatus <b>100</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may be a TV, a monitor, a tablet PC, a mobile terminal, a display for a vehicle, etc.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is an example of an internal block diagram of the image display apparatus of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0061" num="0060">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the image display apparatus <b>100</b> according to an embodiment of the present invention includes a broadcast receiver <b>105</b>, a memory <b>140</b>, a user input interface <b>150</b>, a sensor module (not shown), a signal processor <b>170</b>, a display <b>180</b>, and an audio output interface <b>185</b>.</p><p id="p-0062" num="0061">The signal processor <b>170</b> in the drawing may correspond to the signal processing device described above.</p><p id="p-0063" num="0062">The broadcast receiver <b>105</b> may include a tuner module <b>110</b>, a demodulator <b>120</b>, a network interface <b>135</b>, and an external apparatus interface <b>130</b>.</p><p id="p-0064" num="0063">Meanwhile, unlike the drawing, the broadcast receiver <b>105</b> may include only the tuner module <b>110</b>, the demodulator <b>120</b>, and the external apparatus interface <b>130</b>. That is, the network interface <b>135</b> may not be included.</p><p id="p-0065" num="0064">The tuner module <b>110</b> selects an RF broadcast signal corresponding to a channel selected by a user or all pre-stored channels among radio frequency (RF) broadcast signals received through an antenna (not shown). In addition, the selected RF broadcast signal is converted into an intermediate frequency signal, a baseband image, or a audio signal.</p><p id="p-0066" num="0065">For example, if the selected RF broadcast signal is a digital broadcast signal, it is converted into a digital IF signal (DIF). If the selected RF broadcast signal is an analog broadcast signal, it is converted into an analog baseband image or audio signal (CVBS/SIF). That is, the tuner module <b>110</b> can process a digital broadcast signal or an analog broadcast signal. The analog baseband image or audio signal (CVBS/SIF) output from the tuner module <b>110</b> may be directly input to the signal processor <b>170</b>.</p><p id="p-0067" num="0066">Meanwhile, the tuner module <b>110</b> can include a plurality of tuners for receiving broadcast signals of a plurality of channels. Alternatively, a single tuner that simultaneously receives broadcast signals of a plurality of channels is also available.</p><p id="p-0068" num="0067">The demodulator <b>120</b> receives the converted digital IF signal DIF from the tuner module <b>110</b> and performs a demodulation operation.</p><p id="p-0069" num="0068">The demodulator <b>120</b> may perform demodulation and channel decoding and then output a stream signal TS. Here, the stream signal may be a multiplexed signal of an image signal, an audio signal, or a data signal.</p><p id="p-0070" num="0069">The stream signal output from the demodulator <b>120</b> may be input to the signal processor <b>170</b>. The signal processor <b>170</b> performs demultiplexing, image/audio signal processing, and the like, and then outputs an image to the display <b>180</b> and outputs audio to the audio output interface <b>185</b>.</p><p id="p-0071" num="0070">The external apparatus interface <b>130</b> may transmit or receive data with a connected external apparatus (not shown), e.g., a set-top box <b>50</b>. To this end, the external apparatus interface <b>130</b> may include an A/V input and output interface (not shown).</p><p id="p-0072" num="0071">The external apparatus interface <b>130</b> may be connected in wired or wirelessly to an external apparatus such as a digital versatile disk (DVD), a Blu ray, a game equipment, a camera, a camcorder, a computer(note book), and a set-top box, and may perform an input/output operation with an external apparatus.</p><p id="p-0073" num="0072">The A/V input and output interface may receive image and audio signals from an external apparatus. Meanwhile, a wireless transceiver (not shown) may perform short-range wireless communication with other electronic apparatus.</p><p id="p-0074" num="0073">Through the wireless transceiver (not shown), the external apparatus interface <b>130</b> may exchange data with an adjacent mobile terminal <b>600</b>. In particular, in a mirroring mode, the external apparatus interface <b>130</b> may receive device information, executed application information, application image, and the like from the mobile terminal <b>600</b>.</p><p id="p-0075" num="0074">The network interface <b>135</b> provides an interface for connecting the image display apparatus <b>100</b> to a wired/wireless network including the Internet network. For example, the network interface <b>135</b> may receive, via the network, content or data provided by the Internet, a content provider, or a network operator.</p><p id="p-0076" num="0075">Meanwhile, the network interface <b>135</b> may include a wireless transceiver (not shown).</p><p id="p-0077" num="0076">The memory <b>140</b> may store a program for each signal processing and control in the signal processor <b>170</b>, and may store signal-processed image, audio, or data signal.</p><p id="p-0078" num="0077">In addition, the memory <b>140</b> may serve to temporarily store image, audio, or data signal input to the external apparatus interface <b>130</b>. In addition, the memory <b>140</b> may store information on a certain broadcast channel through a channel memory function such as a channel map.</p><p id="p-0079" num="0078">Although <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates that the memory is provided separately from the signal processor <b>170</b>, the scope of the present invention is not limited thereto. The memory <b>140</b> may be included in the signal processor <b>170</b>.</p><p id="p-0080" num="0079">The user input interface <b>150</b> transmits a signal input by the user to the signal processor <b>170</b> or transmits a signal from the signal processor <b>170</b> to the user.</p><p id="p-0081" num="0080">For example, it may transmit/receive a user input signal such as power on/off, channel selection, screen setting, etc., from a remote controller <b>200</b>, may transfer a user input signal input from a local key (not shown) such as a power key, a channel key, a volume key, a set value, etc., to the signal processor <b>170</b>, may transfer a user input signal input from a sensor module (not shown) that senses a user's gesture to the signal processor <b>170</b>, or may transmit a signal from the signal processor <b>170</b> to the sensor module (not shown).</p><p id="p-0082" num="0081">The signal processor <b>170</b> may demultiplex the input stream through the tuner module <b>110</b>, the demodulator <b>120</b>, the network interface <b>135</b>, or the external apparatus interface <b>130</b>, or process the demultiplexed signals to generate and output a signal for image or audio output.</p><p id="p-0083" num="0082">For example, the signal processor <b>170</b> may receive a broadcast signal or HDMI signal received by the broadcast receiver <b>105</b>, and perform signal processing based on the received broadcast signal or HDMI signal to thereby output a processed image signal.</p><p id="p-0084" num="0083">The image signal processed by the signal processor <b>170</b> is input to the display <b>180</b>, and may be displayed as an image corresponding to the image signal. In addition, the image signal processed by the signal processor <b>170</b> may be input to the external output apparatus through the external apparatus interface <b>130</b>.</p><p id="p-0085" num="0084">The audio signal processed by the signal processor <b>170</b> may be output to the audio output interface <b>185</b> as an audio signal. In addition, audio signal processed by the signal processor <b>170</b> may be input to the external output apparatus through the external apparatus interface <b>130</b>.</p><p id="p-0086" num="0085">Although not shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the signal processor <b>170</b> may include a demultiplexer, an image processor, and the like. That is, the signal processor <b>170</b> is capable of performing a variety of signal processing, and, for this reason, the signal processor <b>170</b> may be implemented in the form of System On Chip (SOC). This will be described later with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0087" num="0086">In addition, the signal processor <b>170</b> can control the overall operation of the image display apparatus <b>100</b>. For example, the signal processor <b>170</b> may control the tuner module <b>110</b> to control the tuning of the RF broadcast corresponding to the channel selected by the user or the previously stored channel.</p><p id="p-0088" num="0087">In addition, the signal processor <b>170</b> may control the image display apparatus <b>100</b> according to a user command input through the user input interface <b>150</b> or an internal program.</p><p id="p-0089" num="0088">Meanwhile, the signal processor <b>170</b> may control the display <b>180</b> to display an image. Here, the image displayed on the display <b>180</b> may be a still image or a moving image, and may be a 2D image or a 3D image.</p><p id="p-0090" num="0089">Meanwhile, the signal processor <b>170</b> may display a certain object in an image displayed on the display <b>180</b>. For example, the object may be at least one of a connected web screen (newspaper, magazine, etc.), an electronic program guide (EPG), various menus, a widget, an icon, a still image, a moving image, or a text.</p><p id="p-0091" num="0090">Meanwhile, the signal processor <b>170</b> may recognize the position of the user based on the image photographed by a photographing device (not shown). For example, the distance (z-axis coordinate) between a user and the image display apparatus <b>100</b> can be determined. In addition, the x-axis coordinate and the y-axis coordinate in the display <b>180</b> corresponding to a user position can be determined.</p><p id="p-0092" num="0091">The display <b>180</b> generates a driving signal by converting an image signal, a data signal, an OSD signal, a control signal processed by the signal processor <b>170</b> or an input image, a data signal, a control signal, and the like in the external device interface <b>130</b>.</p><p id="p-0093" num="0092">Meanwhile, the display <b>180</b> may be configured as a touch screen and used as an input device in addition to an output device.</p><p id="p-0094" num="0093">The audio output interface <b>185</b> receives a signal processed by the signal processor <b>170</b> and outputs it as an audio.</p><p id="p-0095" num="0094">The photographing device (not shown) photographs a user. The photographing device (not shown) may be implemented by a single camera, but the present invention is not limited thereto and may be implemented by a plurality of cameras. Image information photographed by the photographing device (not shown) may be input to the signal processor <b>170</b>.</p><p id="p-0096" num="0095">The signal processor <b>170</b> may sense a gesture of the user based on each of the images photographed by the photographing device (not shown), the signals detected from the sensor module (not shown), or a combination thereof.</p><p id="p-0097" num="0096">The power supply <b>190</b> supplies corresponding power to the image display apparatus <b>100</b>. Particularly, the power supply <b>190</b> may supply the power to the signal processor <b>170</b> which can be implemented in the form of SOC, the display <b>180</b> for displaying an image, and an audio output interface <b>185</b> for outputting an audio.</p><p id="p-0098" num="0097">Specifically, the power supply <b>190</b> may include a converter for converting an AC power into a DC power, and a DC/DC converter for converting the level of the DC power.</p><p id="p-0099" num="0098">The remote controller <b>200</b> transmits the user input to the user input interface <b>150</b>. To this end, the remote controller <b>200</b> may use Bluetooth, a radio frequency (RF) communication, an infrared (IR) communication, an Ultra Wideband (UWB), ZigBee, or the like. In addition, the remote controller <b>200</b> may receive the image, audio, or data signal output from the user input interface <b>150</b>, and display it on the remote controller <b>200</b> or output it as an audio.</p><p id="p-0100" num="0099">Meanwhile, the image display apparatus <b>100</b> may be a fixed or mobile digital broadcasting receiver capable of receiving digital broadcasting.</p><p id="p-0101" num="0100">Meanwhile, a block diagram of the image display apparatus <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram for an embodiment of the present invention. Each component of the block diagram may be integrated, added, or omitted according to a specification of the image display apparatus <b>100</b> actually implemented. That is, two or more components may be combined into a single component as needed, or a single component may be divided into two or more components. The function performed in each block is described for the purpose of illustrating embodiments of the present invention, and specific operation and apparatus do not limit the scope of the present invention.</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is an example of an internal block diagram of a signal processor shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0103" num="0102">Referring to the drawing, the signal processor <b>170</b> according to an embodiment of the present invention may include a demultiplexer <b>310</b>, an image processor <b>320</b>, a processor <b>330</b>, and an audio processor <b>370</b>. In addition, it may further include a data processor (not shown).</p><p id="p-0104" num="0103">The demultiplexer <b>310</b> demultiplexes the input stream. For example, when an MPEG-2 TS is input, it can be demultiplexed into image, audio, and data signal, respectively. Here, the stream signal input to the demultiplexer <b>310</b> may be a stream signal output from the tuner module <b>110</b>, the demodulator <b>120</b>, or the external apparatus interface <b>130</b>.</p><p id="p-0105" num="0104">The image processor <b>320</b> may perform signal processing on an input image. For example, the image processor <b>320</b> may perform image processing on an image signal demultiplexed by the demultiplexer <b>310</b>.</p><p id="p-0106" num="0105">To this end, the image processor <b>320</b> may include an image decoder <b>325</b>, a scaler <b>335</b>, an image quality processor <b>635</b>, an image encoder (not shown), an OSD processor <b>340</b>, a frame rate converter <b>350</b>, a formatter <b>360</b>, etc.</p><p id="p-0107" num="0106">The image decoder <b>325</b> decodes a demultiplexed image signal, and the scaler <b>335</b> performs scaling so that the resolution of the decoded image signal can be output from the display <b>180</b>.</p><p id="p-0108" num="0107">The image decoder <b>325</b> can include a decoder of various standards. For example, a 3D image decoder for MPEG-2, H.264 decoder, a color image, and a depth image, and a decoder for a multiple view image may be provided.</p><p id="p-0109" num="0108">The scaler <b>335</b> may scale an input image signal decoded by the image decoder <b>325</b> or the like.</p><p id="p-0110" num="0109">For example, if the size or resolution of an input image signal is small, the scaler <b>335</b> may upscale the input image signal, and, if the size or resolution of the input image signal is great, the scaler <b>335</b> may downscale the input image signal.</p><p id="p-0111" num="0110">The image quality processor <b>635</b> may perform image quality processing on an input image signal decoded by the image decoder <b>325</b> or the like.</p><p id="p-0112" num="0111">For example, the image quality processor <b>625</b> may perform noise reduction processing on an input image signal, extend a resolution of gray level of the input image signal, perform image resolution enhancement, perform high dynamic range (HDR)-based signal processing, change a frame rate, perform image quality processing appropriate for properties of a panel, especially an OLED panel, etc.</p><p id="p-0113" num="0112">The OSD processor <b>340</b> generates an OSD signal according to a user input or by itself. For example, based on a user input signal, the OSD processor <b>340</b> may generate a signal for displaying various information as a graphic or a text on the screen of the display <b>180</b>. The generated OSD signal may include various data such as a user interface screen of the image display apparatus <b>100</b>, various menu screens, a widget, and an icon. In addition, the generated OSD signal may include a 2D object or a 3D object.</p><p id="p-0114" num="0113">In addition, the OSD processor <b>340</b> may generate a pointer that can be displayed on the display, based on a pointing signal input from the remote controller <b>200</b>. In particular, such a pointer may be generated by a pointing signal processor, and the OSD processor <b>340</b> may include such a pointing signal processor (not shown). Obviously, the pointing signal processor (not shown) may be provided separately from the OSD processor <b>340</b>.</p><p id="p-0115" num="0114">The frame rate converter (FRC) <b>350</b> may convert the frame rate of an input image. Meanwhile, the frame rate converter <b>350</b> can also directly output the frame rate without any additional frame rate conversion.</p><p id="p-0116" num="0115">Meanwhile, the formatter <b>360</b> may change a format of an input image signal into a format suitable for displaying the image signal on a display and output the image signal in the changed format.</p><p id="p-0117" num="0116">In particular, the formatter <b>360</b> may change a format of an image signal to correspond to a display panel.</p><p id="p-0118" num="0117">The processor <b>330</b> may control overall operations of the image display apparatus <b>100</b> or the signal processor <b>170</b>.</p><p id="p-0119" num="0118">For example, the processor <b>330</b> may control the tuner module <b>110</b> to control the tuning of an RF broadcast corresponding to a channel selected by a user or a previously stored channel.</p><p id="p-0120" num="0119">In addition, the processor <b>330</b> may control the image display apparatus <b>100</b> according to a user command input through the user input interface <b>150</b> or an internal program.</p><p id="p-0121" num="0120">In addition, the processor <b>330</b> may transmit data to the network interface <b>135</b> or to the external apparatus interface <b>130</b></p><p id="p-0122" num="0121">In addition, the processor <b>330</b> may control the demultiplexer <b>310</b>, the image processor <b>320</b>, and the like in the signal processor <b>170</b>.</p><p id="p-0123" num="0122">Meanwhile, the audio processor <b>370</b> in the signal processor <b>170</b> may perform the audio processing of the demultiplexed audio signal. To this end, the audio processor <b>370</b> may include various decoders.</p><p id="p-0124" num="0123">In addition, the audio processor <b>370</b> in the signal processor <b>170</b> may process a base, a treble, a volume control, and the like.</p><p id="p-0125" num="0124">The data processor (not shown) in the signal processor <b>170</b> may perform data processing of the demultiplexed data signal. For example, when the demultiplexed data signal is a coded data signal, it can be decoded. The encoded data signal may be electronic program guide information including broadcast information such as a start time and an end time of a broadcast program broadcasted on each channel.</p><p id="p-0126" num="0125">Meanwhile, a block diagram of the signal processor <b>170</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram for an embodiment of the present invention. Each component of the block diagram may be integrated, added, or omitted according to a specification of the signal processor <b>170</b> actually implemented.</p><p id="p-0127" num="0126">In particular, the frame rate converter <b>350</b> and the formatter <b>360</b> may be provided separately from the image processor <b>320</b>.</p><p id="p-0128" num="0127"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a diagram illustrating a control method of a remote controller of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0129" num="0128">As shown in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>(a), it is illustrated that a pointer <b>205</b> corresponding to the remote controller <b>200</b> is displayed on the display <b>180</b>.</p><p id="p-0130" num="0129">The user may move or rotate the remote controller <b>200</b> up and down, left and right (<figref idref="DRAWINGS">FIG. <b>4</b>A</figref>(b)), and back and forth (<figref idref="DRAWINGS">FIG. <b>4</b>A</figref>(c)). The pointer <b>205</b> displayed on the display <b>180</b> of the image display apparatus corresponds to the motion of the remote controller <b>200</b>. Such a remote controller <b>200</b> may be referred to as a space remote controller or a 3D pointing apparatus, because the pointer <b>205</b> is moved and displayed according to the movement in a 3D space, as shown in the drawing.</p><p id="p-0131" num="0130"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref>(b) illustrates that when the user moves the remote controller <b>200</b> to the left, the pointer <b>205</b> displayed on the display <b>180</b> of the image display apparatus also moves to the left correspondingly.</p><p id="p-0132" num="0131">Information on the motion of the remote controller <b>200</b> detected through a sensor of the remote controller <b>200</b> is transmitted to the image display apparatus. The image display apparatus may calculate the coordinate of the pointer <b>205</b> from the information on the motion of the remote controller <b>200</b>. The image display apparatus may display the pointer <b>205</b> to correspond to the calculated coordinate.</p><p id="p-0133" num="0132"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref>(c) illustrates a case where the user moves the remote controller <b>200</b> away from the display <b>180</b> while pressing a specific button of the remote controller <b>200</b>. Thus, a selection area within the display <b>180</b> corresponding to the pointer <b>205</b> may be zoomed in so that it can be displayed to be enlarged. On the other hand, when the user moves the remote controller <b>200</b> close to the display <b>180</b>, the selection area within the display <b>180</b> corresponding to the pointer <b>205</b> may be zoomed out so that it can be displayed to be reduced. Meanwhile, when the remote controller <b>200</b> moves away from the display <b>180</b>, the selection area may be zoomed out, and when the remote controller <b>200</b> approaches the display <b>180</b>, the selection area may be zoomed in.</p><p id="p-0134" num="0133">Meanwhile, when the specific button of the remote controller <b>200</b> is pressed, it is possible to exclude the recognition of vertical and lateral movement. That is, when the remote controller <b>200</b> moves away from or approaches the display <b>180</b>, the up, down, left, and right movements are not recognized, and only the forward and backward movements are recognized. Only the pointer <b>205</b> is moved according to the up, down, left, and right movements of the remote controller <b>200</b> in a state where the specific button of the remote controller <b>200</b> is not pressed.</p><p id="p-0135" num="0134">Meanwhile, the moving speed or the moving direction of the pointer <b>205</b> may correspond to the moving speed or the moving direction of the remote controller <b>200</b>.</p><p id="p-0136" num="0135"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is an internal block diagram of the remote controller of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0137" num="0136">Referring to the drawing, the remote controller <b>200</b> includes a wireless transceiver <b>425</b>, a user input interface <b>430</b>, a sensor module <b>440</b>, an output interface <b>450</b>, a power supply <b>460</b>, a memory <b>470</b>, and a signal processor <b>480</b>.</p><p id="p-0138" num="0137">The wireless transceiver <b>425</b> transmits/receives a signal to/from any one of the image display apparatuses according to the embodiments of the present invention described above. Among the image display apparatuses according to the embodiments of the present invention, one image display apparatus <b>100</b> will be described as an example.</p><p id="p-0139" num="0138">In the present embodiment, the remote controller <b>200</b> may include an RF module <b>421</b> for transmitting and receiving signals to and from the image display apparatus <b>100</b> according to a RF communication standard. In addition, the remote controller <b>200</b> may include an IR module <b>423</b> for transmitting and receiving signals to and from the image display apparatus <b>100</b> according to an IR communication standard.</p><p id="p-0140" num="0139">In the present embodiment, the remote controller <b>200</b> transmits a signal containing information on the motion of the remote controller <b>200</b> to the image display apparatus <b>100</b> through the RF module <b>421</b>.</p><p id="p-0141" num="0140">In addition, the remote controller <b>200</b> may receive the signal transmitted by the image display apparatus <b>100</b> through the RF module <b>421</b>. In addition, if necessary, the remote controller <b>200</b> may transmit a command related to power on/off, channel change, volume change, and the like to the image display apparatus <b>100</b> through the IR module <b>423</b>.</p><p id="p-0142" num="0141">The user input interface <b>435</b> may be implemented by a keypad, a button, a touch pad, a touch screen, or the like. The user may operate the user input interface <b>435</b> to input a command related to the image display apparatus <b>100</b> to the remote controller <b>200</b>. When the user input interface <b>435</b> includes a hard key button, the user can input a command related to the image display apparatus <b>100</b> to the remote controller <b>200</b> through a push operation of the hard key button. When the user input interface <b>435</b> includes a touch screen, the user may touch a soft key of the touch screen to input the command related to the image display apparatus <b>100</b> to the remote controller <b>200</b>. In addition, the user input interface <b>435</b> may include various types of input means such as a scroll key, a jog key, etc., which can be operated by the user, and the present invention does not limit the scope of the present invention.</p><p id="p-0143" num="0142">The sensor module <b>440</b> may include a gyro sensor <b>441</b> or an acceleration sensor <b>443</b>. The gyro sensor <b>441</b> may sense information about the motion of the remote controller <b>200</b>.</p><p id="p-0144" num="0143">For example, the gyro sensor <b>441</b> may sense information on the operation of the remote controller <b>200</b> based on the x, y, and z axes. The acceleration sensor <b>443</b> may sense information on the moving speed of the remote controller <b>200</b>. Meanwhile, a distance measuring sensor may be further provided, and thus, the distance to the display <b>180</b> may be sensed.</p><p id="p-0145" num="0144">The output interface <b>450</b> may output an image or an audio signal corresponding to the operation of the user input interface <b>435</b> or a signal transmitted from the image display apparatus <b>100</b>. Through the output interface <b>450</b>, the user may recognize whether the user input interface <b>435</b> is operated or whether the image display apparatus <b>100</b> is controlled.</p><p id="p-0146" num="0145">For example, the output interface <b>450</b> may include an LED module <b>451</b> that is turned on when the user input interface <b>430</b> is operated or a signal is transmitted/received to/from the image display apparatus <b>100</b> through the wireless transceiver <b>425</b>, a vibration module <b>453</b> for generating a vibration, an audio output module <b>455</b> for outputting an audio, or a display module <b>457</b> for outputting an image.</p><p id="p-0147" num="0146">The power supply <b>460</b> supplies power to the remote controller <b>200</b>. When the remote controller <b>200</b> is not moved for a certain time, the power supply <b>460</b> may stop the supply of power to reduce a power waste. The power supply <b>460</b> may resume power supply when a certain key provided in the remote controller <b>200</b> is operated.</p><p id="p-0148" num="0147">The memory <b>470</b> may store various types of programs, application data, and the like necessary for the control or operation of the remote controller <b>200</b>. If the remote controller <b>200</b> wirelessly transmits and receives a signal to/from the image display apparatus <b>100</b> through the RF module <b>421</b>, the remote controller <b>200</b> and the image display apparatus <b>100</b> transmit and receive a signal through a certain frequency band. The signal processor <b>480</b> of the remote controller <b>200</b> may store information about a frequency band or the like for wirelessly transmitting and receiving a signal to/from the image display apparatus <b>100</b> paired with the remote controller <b>200</b> in the memory <b>470</b> and may refer to the stored information.</p><p id="p-0149" num="0148">The signal processor <b>480</b> controls various matters related to the control of the remote controller <b>200</b>. The signal processor <b>480</b> may transmit a signal corresponding to a certain key operation of the user input interface <b>430</b> or a signal corresponding to the motion of the remote controller <b>200</b> sensed by the sensor module <b>440</b> to the image display apparatus <b>100</b> through the wireless transceiver <b>425</b>.</p><p id="p-0150" num="0149">The user input interface <b>150</b> of the image display apparatus <b>100</b> includes a wireless transceiver <b>151</b> that can wirelessly transmit and receive a signal to and from the remote controller <b>200</b> and a coordinate value calculator <b>415</b> that can calculate the coordinate value of a pointer corresponding to the operation of the remote controller <b>200</b>.</p><p id="p-0151" num="0150">The user input interface <b>150</b> may wirelessly transmit and receive a signal to and from the remote controller <b>200</b> through the RF module <b>412</b>. In addition, the user input interface <b>150</b> may receive a signal transmitted by the remote controller <b>200</b> through the IR module <b>413</b> according to an IR communication standard.</p><p id="p-0152" num="0151">The coordinate value calculator <b>415</b> may correct a hand shake or an error from a signal corresponding to the operation of the remote controller <b>200</b> received through the wireless transceiver <b>151</b> and calculate the coordinate value (x, y) of the pointer <b>205</b> to be displayed on the display <b>180</b>.</p><p id="p-0153" num="0152">The transmission signal of the remote controller <b>200</b> inputted to the image display apparatus <b>100</b> through the user input interface <b>150</b> is transmitted to the signal processor <b>170</b> of the image display apparatus <b>100</b>. The signal processor <b>170</b> may determine the information on the operation of the remote controller <b>200</b> and the key operation from the signal transmitted from the remote controller <b>200</b>, and, correspondingly, control the image display apparatus <b>100</b>.</p><p id="p-0154" num="0153">For another example, the remote controller <b>200</b> may calculate the pointer coordinate value corresponding to the operation and output it to the user input interface <b>150</b> of the image display apparatus <b>100</b>. In this case, the user input interface <b>150</b> of the image display apparatus <b>100</b> may transmit information on the received pointer coordinate value to the signal processor <b>170</b> without a separate correction process of hand shake or error.</p><p id="p-0155" num="0154">For another example, unlike the drawing, the coordinate value calculator <b>415</b> may be provided in the signal processor <b>170</b>, not in the user input interface <b>150</b>.</p><p id="p-0156" num="0155"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an internal block diagram of a display of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0157" num="0156">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the organic light emitting diode panel-based display <b>180</b> may include an organic light emitting diode panel <b>210</b>, a first interface <b>230</b>, a second interface <b>231</b>, a timing controller <b>232</b>, a gate driver <b>234</b>, a data driver <b>236</b>, a memory <b>240</b>, a processor <b>270</b>, a power supply <b>290</b>, a current detector <b>510</b>, and the like.</p><p id="p-0158" num="0157">The display <b>180</b> receives an image signal Vd, a first DC power V<b>1</b>, and a second DC power V<b>2</b>, and may display a certain image based on the image signal Vd.</p><p id="p-0159" num="0158">Meanwhile, the first interface <b>230</b> in the display <b>180</b> may receive the image signal Vd and the first DC power V<b>1</b> from the signal processor <b>170</b>.</p><p id="p-0160" num="0159">Here, the first DC power V<b>1</b> may be used for the operation of the power supply <b>290</b> and the timing controller <b>232</b> in the display <b>180</b>.</p><p id="p-0161" num="0160">Next, the second interface <b>231</b> may receive a second DC power V<b>2</b> from an external power supply <b>190</b>. Meanwhile, the second DC power V<b>2</b> may be input to the data driver <b>236</b> in the display <b>180</b>.</p><p id="p-0162" num="0161">The timing controller <b>232</b> may output a data driving signal Sda and a gate driving signal Sga, based on the image signal Vd.</p><p id="p-0163" num="0162">For example, when the first interface <b>230</b> converts the input image signal Vd and outputs the converted image signal va<b>1</b>, the timing controller <b>232</b> may output the data driving signal Sda and the gate driving signal Sga based on the converted image signal va<b>1</b>.</p><p id="p-0164" num="0163">The timing controller <b>232</b> may further receive a control signal, a vertical synchronization signal Vsync, and the like, in addition to the image signal Vd from the signal processor <b>170</b>.</p><p id="p-0165" num="0164">In addition to the image signal Vd, based on a control signal, a vertical synchronization signal Vsync, and the like, the timing controller <b>232</b> generates a gate driving signal Sga for the operation of the gate driver <b>234</b>, and a data driving signal Sda for the operation of the data driver <b>236</b>.</p><p id="p-0166" num="0165">Here, when the panel <b>210</b> includes a RGBW subpixel, the data driving signal Sda may be a data driving signal for driving of RGBW subpixel.</p><p id="p-0167" num="0166">Meanwhile, the timing controller <b>232</b> may further output a control signal Cs to the gate driver <b>234</b>.</p><p id="p-0168" num="0167">The gate driver <b>234</b> and the data driver <b>236</b> supply a scan signal and an image signal to the organic light emitting diode panel <b>210</b> through a gate line GL and a data line DL respectively, according to the gate driving signal Sga and the data driving signal Sda from the timing controller <b>232</b>. Accordingly, the organic light emitting diode panel <b>210</b> displays a certain image.</p><p id="p-0169" num="0168">Meanwhile, the organic light emitting diode panel <b>210</b> may include an organic light emitting layer. In order to display an image, a plurality of gate lines GL and data lines DL may be disposed in a matrix form in each pixel corresponding to the organic light emitting layer.</p><p id="p-0170" num="0169">Meanwhile, the data driver <b>236</b> may output a data signal to the organic light emitting diode panel <b>210</b> based on a second DC power V<b>2</b> from the second interface <b>231</b>.</p><p id="p-0171" num="0170">The power supply <b>290</b> may supply various power supplies to the gate driver <b>234</b>, the data driver <b>236</b>, the timing controller <b>232</b>, and the like.</p><p id="p-0172" num="0171">The current detector <b>510</b> may detect the current flowing in a sub-pixel of the organic light emitting diode panel <b>210</b>. The detected current may be input to the processor <b>270</b> or the like, for a cumulative current calculation.</p><p id="p-0173" num="0172">The processor <b>270</b> may perform each type of control of the display <b>180</b>. For example, the processor <b>270</b> may control the gate driver <b>234</b>, the data driver <b>236</b>, the timing controller <b>232</b>, and the like.</p><p id="p-0174" num="0173">Meanwhile, the processor <b>270</b> may receive current information flowing in a sub-pixel of the organic light emitting diode panel <b>210</b> from the current detector <b>510</b>.</p><p id="p-0175" num="0174">In addition, the processor <b>270</b> may calculate the accumulated current of each subpixel of the organic light emitting diode panel <b>210</b>, based on information of current flowing through the subpixel of the organic light emitting diode panel <b>210</b>. The calculated accumulated current may be stored in the memory <b>240</b>.</p><p id="p-0176" num="0175">Meanwhile, the processor <b>270</b> may determine as burn-in, if the accumulated current of each sub-pixel of the organic light emitting diode panel <b>210</b> is equal to or greater than an allowable value.</p><p id="p-0177" num="0176">For example, if the accumulated current of each subpixel of the OLED panel <b>210</b> is equal to or greater than 300000 A, the processor <b>270</b> may determine that a corresponding subpixel is a burn-in subpixel.</p><p id="p-0178" num="0177">Meanwhile, if the accumulated current of each subpixel of the OLED panel <b>210</b> is close to an allowable value, the processor <b>270</b> may determine that a corresponding subpixel is a subpixel expected to be burn in.</p><p id="p-0179" num="0178">Meanwhile, based on a current detected by the current detector <b>510</b>, the processor <b>270</b> may determine that a subpixel having the greatest accumulated current is an expected burn-in subpixel.</p><p id="p-0180" num="0179"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>6</b>B</figref> are diagrams referred to in the description of an organic light emitting diode panel of <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0181" num="0180">Firstly, <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a diagram illustrating a pixel in the organic light emitting diode panel <b>210</b>.</p><p id="p-0182" num="0181">Referring to drawing, the organic light emitting diode panel <b>210</b> may include a plurality of scan lines Scan<b>1</b> to Scann and a plurality of data lines R<b>1</b>, G<b>1</b>, B<b>1</b>, W<b>1</b> to Rm, Gm, Bm, Wm intersecting the scan lines.</p><p id="p-0183" num="0182">Meanwhile, a pixel (subpixel) is defined in an intersecting area of the scan line and the data line in the organic light emitting diode panel <b>210</b>. In the drawing, a pixel including sub-pixels SR<b>1</b>, SG<b>1</b>, SB<b>1</b> and SW<b>1</b> of RGBW is shown.</p><p id="p-0184" num="0183"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> illustrates a circuit of any one sub-pixel in the pixel of the organic light emitting diode panel of <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>.</p><p id="p-0185" num="0184">Referring to drawing, an organic light emitting sub pixel circuit (CRTm) may include, as an active type, a scan switching element SW<b>1</b>, a storage capacitor Cst, a drive switching element SW<b>2</b>, and an organic light emitting layer (OLED).</p><p id="p-0186" num="0185">The scan switching element SW<b>1</b> is turned on according to the input scan signal Vdscan, as a scan line is connected to a gate terminal. When it is turned on, the input data signal Vdata is transferred to the gate terminal of a drive switching element SW<b>2</b> or one end of the storage capacitor Cst.</p><p id="p-0187" num="0186">The storage capacitor Cst is formed between the gate terminal and the source terminal of the drive switching element SW<b>2</b>, and stores a certain difference between a data signal level transmitted to one end of the storage capacitor Cst and a DC power (VDD) level transmitted to the other terminal of the storage capacitor Cst.</p><p id="p-0188" num="0187">For example, when the data signal has a different level according to a Plume Amplitude Modulation (PAM) method, the power level stored in the storage capacitor Cst varies according to the level difference of the data signal Vdata.</p><p id="p-0189" num="0188">For another example, when the data signal has a different pulse width according to a Pulse Width Modulation (PWM) method, the power level stored in the storage capacitor Cst varies according to the pulse width difference of the data signal Vdata.</p><p id="p-0190" num="0189">The drive switching element SW<b>2</b> is turned on according to the power level stored in the storage capacitor Cst. When the drive switching element SW<b>2</b> is turned on, the driving current (IOLED), which is proportional to the stored power level, flows in the organic light emitting layer (OLED). Accordingly, the organic light emitting layer OLED performs a light emitting operation.</p><p id="p-0191" num="0190">The organic light emitting layer OLED may include a light emitting layer (EML) of RGBW corresponding to a subpixel, and may include at least one of a hole injecting layer (HIL), a hole transporting layer (HTL), an electron transporting layer (ETL), or an electron injecting layer (EIL). In addition, it may include a hole blocking layer, and the like.</p><p id="p-0192" num="0191">Meanwhile, all the subpixels emit a white light in the organic light emitting layer OLED. However, in the case of green, red, and blue subpixels, a subpixel is provided with a separate color filter for color implementation. That is, in the case of green, red, and blue subpixels, each of the subpixels further includes green, red, and blue color filters. Meanwhile, since a white subpixel outputs a white light, a separate color filter is not required.</p><p id="p-0193" num="0192">Meanwhile, in the drawing, it is illustrated that a p-type MOSFET is used for a scan switching element SW<b>1</b> and a drive switching element SW<b>2</b>, but an n-type MOSFET or other switching element such as a JFET, IGBT, SIC, or the like are also available.</p><p id="p-0194" num="0193">Meanwhile, the pixel is a hold-type element that continuously emits light in the organic light emitting layer (OLED), after a scan signal is applied, during a unit display period, specifically, during a unit frame.</p><p id="p-0195" num="0194"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example of an internal block diagram of the signal processor of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and <figref idref="DRAWINGS">FIGS. <b>8</b>A to <b>8</b>B</figref> are views referenced for explanation of the operation of the signal processor of <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0196" num="0195">Referring to the drawings, the signal processor <b>170</b> according to an embodiment of the present invention may include an image analyzer <b>610</b> and an image quality processor <b>635</b>.</p><p id="p-0197" num="0196">The image analyzer <b>610</b> may analyze an input image signal, and output information related to the analyzed input image signal.</p><p id="p-0198" num="0197">Meanwhile, the image analyzer <b>610</b> may differentiate an object region and a background region of a first input image signal. Alternatively, the image analyzer <b>610</b> may calculate a probability or percentage of the object region and the background region of the first input image signal.</p><p id="p-0199" num="0198">The input image signal may be an input image signal from an image receiver <b>105</b> or an image decoded by the image decoder <b>320</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0200" num="0199">In particular, the image analyzer <b>610</b> may analyze an input image signal using artificial intelligence (AI), and output information on the analyzed input image signal.</p><p id="p-0201" num="0200">Specifically, the image analyzer <b>610</b> may output a resolution, gray level, a noise level, and a pattern of an input image signal, and output information on the analyzed input image signal, especially image setting information, to the image quality processor <b>635</b>.</p><p id="p-0202" num="0201">The image quality processor <b>635</b> may include an HDR processor <b>705</b>, a first reduction processor <b>710</b>, an enhancement processor <b>750</b>, and a second reduction processor <b>790</b>.</p><p id="p-0203" num="0202">The HDR processor <b>705</b> may receive an image signal and perform high dynamic range (HDR) processing on the input image signal.</p><p id="p-0204" num="0203">For example, the HDR processor <b>705</b> may convert a standard dynamic range (SDR) image signal into an HDR image signal.</p><p id="p-0205" num="0204">For another example, the HDR processor <b>705</b> may receive an image signal, and perform gray level processing on the input image signal for an HDR.</p><p id="p-0206" num="0205">Meanwhile, if an input image signal is an SDR image signal, the HDR processor <b>705</b> may bypass gray level conversion, and, if an input image signal is an HDR image signal, the HDR processor <b>705</b> performs gray level conversion. Accordingly, it is possible to improve high gray level expression for an input image.</p><p id="p-0207" num="0206">Meanwhile, the HDR processor <b>705</b> may convert gray level according to a first gray level conversion mode, in which low gray level is to be enhanced and high gray level is to be saturated, and a second gray level conversion mode, in which low gray level and high gray level are somewhat uniformly converted.</p><p id="p-0208" num="0207">Specifically, if the first gray level conversion mode is implemented, the HDR processor <b>705</b> may convert gray level based on data corresponding to the first gray level conversion mode in a lookup table.</p><p id="p-0209" num="0208">More specifically, if the first gray level conversion mode is implemented, the HDR processor <b>705</b> may convert gray level based on an equation of input data and the first gray level conversion mode in a lookup table determined by the equation. Here, the input data may include video data and metadata.</p><p id="p-0210" num="0209">Meanwhile, if the second gray level conversion mode is implemented, the HDR processor <b>705</b> may convert gray level based on data corresponding to the second gray level conversion mode in a lookup table.</p><p id="p-0211" num="0210">More specifically, if the second gray level conversion mode is implemented, the HDR processor <b>705</b> may convert gray level based on an equation of input data and data corresponding to the second gray level conversion mode in a lookup table determined by the equation. Here, the input data may include video data and metadata.</p><p id="p-0212" num="0211">Meanwhile, the HDR processor <b>705</b> may select the first gray level conversion mode or the second gray level conversion mode according to a third gray level conversion mode or a fourth gray level conversion mode in a high gray level amplifier <b>851</b> in the second reduction processor <b>790</b>.</p><p id="p-0213" num="0212">For example, if the third gray level conversion mode is implemented, the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b> may convert gray level based on data corresponding to the third gray level conversion mode in a lookup table.</p><p id="p-0214" num="0213">Specifically, if the third gray level conversion mode is implemented, the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b> may perform convert gray level based on an equation of input data and data corresponding to the third gray level conversion mode in a lookup table determined by the equation. Here, the input data may include video data and metadata.</p><p id="p-0215" num="0214">Meanwhile, if the fourth gray level conversion mode is implemented, the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b> may convert gray level based on data corresponding to the fourth gray level conversion mode in a lookup table.</p><p id="p-0216" num="0215">Specifically, if the fourth gray level conversion mode is implemented, the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b> may perform convert gray level based on an equation of input data and data corresponding to the fourth gray level conversion mode in a lookup table determined by the equation. Here, the input data may include video data and metadata.</p><p id="p-0217" num="0216">For example, if the fourth gray level conversion mode is implemented in the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b>, the HDR processor <b>705</b> may implement the second gray level conversion mode.</p><p id="p-0218" num="0217">For another example, if the third gray level conversion mode is implemented in the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b>, the HDR processor <b>705</b> may implement the first gray level conversion mode.</p><p id="p-0219" num="0218">Alternatively, the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b> may change a gray level conversion mode according to a gray level conversion mode in the HDR processor <b>705</b>.</p><p id="p-0220" num="0219">For example, if the second gray level conversion mode is implemented in the HDR processor <b>705</b>, the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b> may perform the fourth gray level conversion mode.</p><p id="p-0221" num="0220">For another example, if the first gray level conversion mode is implemented in the HDR processor <b>705</b>, the high gray level amplifier <b>851</b> in the second reduction processor <b>790</b> may implement the third gray level conversion mode.</p><p id="p-0222" num="0221">Meanwhile, the HDR processor <b>705</b> according to an embodiment of the present invention may implement a gray level conversion mode so that low gray level and high gray level are converted uniformly.</p><p id="p-0223" num="0222">Meanwhile, according to the second gray level conversion mode in the HDR processor <b>705</b>, the second reduction processor <b>790</b> may implement the fourth gray level conversion mode and thereby amplify an upper limit on gray level of a received input signal. Accordingly, it is possible to improve high gray level expression for the input image.</p><p id="p-0224" num="0223">Next, the first reduction processor <b>710</b> may perform noise reduction on an input image signal or an image signal processed by the HDR processor <b>705</b>.</p><p id="p-0225" num="0224">Specifically, the first reduction processor <b>710</b> may perform multiple stages of noise reduction processing and a first stage of gray level extension processing on an input image signal or an HDR image from the HDR processor <b>705</b>.</p><p id="p-0226" num="0225">To this end, the first reduction processor <b>710</b> may include a plurality of noise reduction processors <b>715</b> and <b>720</b> for reducing noise in multiple stages, and a first gray level extension processor <b>725</b> for extending gray level.</p><p id="p-0227" num="0226">Next, the enhancement processor <b>750</b> may perform multiple stages of image resolution enhancement processing on an image from the first reduction processor <b>710</b>.</p><p id="p-0228" num="0227">In addition, the enhancement processor <b>750</b> may perform object three-dimensional effect enhancement processing. In addition, the enhancement processor <b>750</b> may perform color or contrast enhancement processing.</p><p id="p-0229" num="0228">To this end, the enhancement processor <b>750</b> may include: a plurality of resolution enhancement processors <b>735</b>, <b>738</b>, <b>742</b> for enhancing a resolution of an image in multiple stages; an object three-dimensional effect enhancement processor <b>745</b> for enhancing a three-dimensional effect of an object; and a color contrast enhancement processor <b>749</b> for enhancing color or contrast.</p><p id="p-0230" num="0229">Next, the second reduction processor <b>790</b> may perform a second stage of gray level extension processing based on a noise-reduced image signal received from the first reduction processor <b>710</b>.</p><p id="p-0231" num="0230">Meanwhile, the second reduction processor <b>790</b> may amplify an upper limit on gray level of an input signal, and extend a resolution of high gray level of the input signal. Accordingly, it is possible to improve high gray level expression for an input image.</p><p id="p-0232" num="0231">For example, gray level extension may be performed uniformly on the entire gray level range of an input signal. Accordingly, gray level extension is performed uniformly on the entire area of an input image, thereby improving high gray level expression.</p><p id="p-0233" num="0232">Meanwhile, the second reduction processor <b>790</b> may perform gray level amplification and extension based on a signal received from the first gray level extension processor <b>725</b>. Accordingly, it is possible to improve high gray level expression for an input image.</p><p id="p-0234" num="0233">Meanwhile, if an input image signal input is an SDR image signal, the second reduction processor <b>790</b> may change the degree of amplification based on a user input signal. Accordingly, it is possible to improve high gray level expression in response to a user setting.</p><p id="p-0235" num="0234">Meanwhile, if an input image signal is an HDR image signal, the second reduction processor <b>790</b> may perform amplification according to a set value. Accordingly, it is possible to improve high gray level expression for an input image.</p><p id="p-0236" num="0235">Meanwhile, if an input image signal is an HDR image signal, the second reduction processor <b>790</b> may change the degree of amplification based on a user input signal. Accordingly, it is possible to improve high gray level expression according to a user setting.</p><p id="p-0237" num="0236">Meanwhile, in the case of extending gray level based on a user input signal, the second reduction processor <b>790</b> may change the degree of extension of gray level. Accordingly, it is possible to improve high gray level expression according to a user's setting.</p><p id="p-0238" num="0237">Meanwhile, the second reduction processor <b>790</b> may amplify an upper limit on gray level according to a gray level conversion mode in the HDR processor <b>705</b>. Accordingly, it is possible to improve high gray level expression for an input image.</p><p id="p-0239" num="0238">The signal processor <b>170</b> includes the HDR processor <b>705</b> configured to receive an image signal and adjust luminance of the input image signal, and the reduction processor <b>790</b> configured to amplify brightness of the image signal received from the HDR processor <b>705</b> and increase gray level resolution of the image signal to thereby generate an enhanced image signal. The enhanced image signal provides increased luminance and increased gray level resolution of the image signal while a high dynamic range in a displayed HDR image is maintained.</p><p id="p-0240" num="0239">Meanwhile, the range of brightness of the image signal is adjusted by a control signal received by the signal processor <b>170</b>.</p><p id="p-0241" num="0240">Meanwhile, the signal processor <b>170</b> further includes an image analyzer configured to determine whether an input image signal is an HDR signal or an SDR signal, and generate a control signal to be provided to the HDR processor <b>705</b>. The range of brightness of an input image signal is adjusted by a control signal only when the input image signal is an HDR signal.</p><p id="p-0242" num="0241">Meanwhile, the control signal is received from a controller of an image display apparatus, which relates to signal processing, and the control signal corresponds to a setting of the image display apparatus.</p><p id="p-0243" num="0242">Meanwhile, a resolution of gray level is increased based on amplification of adjusted brightness of an image signal.</p><p id="p-0244" num="0243">Meanwhile, a resolution of gray level is increased based on a control signal received by the signal processor <b>170</b>.</p><p id="p-0245" num="0244">Meanwhile, a control signal is received from a controller of an image display apparatus, which relates to signal processing, and the control signal corresponds to a setting of the image display apparatus.</p><p id="p-0246" num="0245">Meanwhile, the reduction processor <b>790</b> may include the high gray level amplifier <b>851</b> configured to amplify an upper limit on gray level of an input signal, and a decontouring processor <b>842</b> and <b>844</b> configured to extend the resolution of gray level amplified by the high gray level amplifier <b>851</b>.</p><p id="p-0247" num="0246">The second reduction processor <b>790</b> may include a second gray level extension processor <b>729</b> for a second stage of gray level extension.</p><p id="p-0248" num="0247">Meanwhile, the image quality processor <b>635</b> in the signal processor <b>170</b> according to the present invention is characterized in performing four stages of reduction processing and four stages of image enhancement processing, as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0249" num="0248">Here, the four stages of reduction processing may include two stages of noise reduction processing and two stages of gray level extension processing.</p><p id="p-0250" num="0249">Herein, the two stages of noise reduction processing may be performed by the first and second noise reduction processors <b>715</b> and <b>720</b> in the first reduction processor <b>710</b>, and the two stages of gray level extension processing may be performed by the first gray level extension processor <b>725</b> in the first reduction processor <b>710</b> and the second gray level extension processor <b>729</b> in the second reduction processor <b>790</b>.</p><p id="p-0251" num="0250">Meanwhile, the four stages of image enhancement processing may include three stages of image resolution enhancement (bit resolution enhancement) and object three-dimensional effect enhancement.</p><p id="p-0252" num="0251">Here, the three stages of image enhancement processing may be performed by the first to third resolution enhancement processors <b>735</b>, <b>738</b>, and <b>742</b>, and the object three-dimensional effect enhancement may be performed by the object three-dimensional enhancement processor <b>745</b>.</p><p id="p-0253" num="0252">Meanwhile, the signal processor <b>170</b> of the present invention may apply the same algorithm or similar algorithms to image quality processing multiple times, thereby enabled to gradually enhance an image quality.</p><p id="p-0254" num="0253">To this end, the image quality processor <b>635</b> of the signal processor <b>170</b> of the present invention may perform image quality processing by applying the same algorithm or similar algorithms two or more times.</p><p id="p-0255" num="0254">Meanwhile, the same algorithm or the similar algorithms implemented by the image quality processor <b>635</b> have a different purpose to achieve in each stage. In addition, since image quality processing is performed gradually in multiple stages, there is an advantageous effect to cause a less number of artifacts to appear in an image, resulting in a more natural and more vivid image processing result.</p><p id="p-0256" num="0255">Meanwhile, the same algorithm or the similar algorithms are applied multiple times alternately with a different image quality algorithm, thereby bringing an effect more than simple continuous processing.</p><p id="p-0257" num="0256">Meanwhile, the signal processor <b>170</b> of the present invention may perform noise reduction processing in multiple stages. Each stage of noise reduction processing may include temporal processing and spatial processing.</p><p id="p-0258" num="0257">Meanwhile, in order to calculate original quality of an image signal, the present invention uses the state-of-the-art technology such as artificial intelligence (AI). To this end, a Deep Neural Network (DNN) may be used.</p><p id="p-0259" num="0258">The quality calculator <b>632</b> may calculate a resolution and a noise level of an input image signal using the DNN.</p><p id="p-0260" num="0259">The quality calculator <b>632</b> may obtain an original resolution and a training image for each compression rate, and train the network so as to increase accuracy of the calculation.</p><p id="p-0261" num="0260">A variety of images which can be commonly seen in ordinary broadcasting programs are provided as images used for the training, and thus, it is possible to cover any input environment.</p><p id="p-0262" num="0261">Meanwhile, in order to reduce detection time or cost, the quality calculator <b>632</b> may perform learning using Convolutional Neural Network, Mobile-Net, and the like which has few number of layers.</p><p id="p-0263" num="0262">For example, the quality calculator <b>632</b> may analyze only a region (e.g., 224&#xd7;224, 128&#xd7;128, 64&#xd7;64, etc.) of an entire image.</p><p id="p-0264" num="0263">Meanwhile, the quality calculator <b>632</b> may select a detection region appropriate for a purpose of detection.</p><p id="p-0265" num="0264">For example, the quality calculator <b>632</b> may select a first region having the greatest number of edge components when detecting an original resolution, and select a second region having the least number of edge components when detecting noise.</p><p id="p-0266" num="0265">In particular, the quality calculator <b>632</b> may apply an algorithm that selects a detection region in a short time in order to increase a processing speed.</p><p id="p-0267" num="0266">For example, the quality calculator <b>632</b> may perform pre-processing such as Fast Fourier Transform (FFT) on a detection region.</p><p id="p-0268" num="0267"><figref idref="DRAWINGS">FIG. <b>8</b>A</figref> is a diagram showing calculation based on a Convolutional Neural Network (CNN).</p><p id="p-0269" num="0268">Referring to the drawing, a convolutional neural network is used for a particular region <b>1015</b> in an acquired image <b>1010</b>.</p><p id="p-0270" num="0269">As the convolution neural network, a convolution network and a deconvolution network may be implemented.</p><p id="p-0271" num="0270">According to the convolution neural network, convolution and pooling are performed repeatedly.</p><p id="p-0272" num="0271">Meanwhile, according to the CNN scheme shown in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>, information on the region <b>1015</b> may be used to determine types of pixels in the region <b>1015</b>.</p><p id="p-0273" num="0272"><figref idref="DRAWINGS">FIG. <b>8</b>B</figref> is a diagram showing calculation based on Mobile-Net.</p><p id="p-0274" num="0273">According to the scheme shown in the drawing, quality calculation is performed.</p><p id="p-0275" num="0274">Meanwhile, as original quality changes, the signal processor <b>170</b> of the present invention may apply an image quality setting corresponding to the changed quality in real time.</p><p id="p-0276" num="0275">In particular, the signal processor <b>170</b> may perform control apply, when the image quality setting is changed, the change of the image quality setting without any condition such as a channel change or an input change while an image is reproduced.</p><p id="p-0277" num="0276">In this case, &#x201c;real time&#x201d; refers to employing a temporal processing technique including imaging infrared (IIR) and step movement.</p><p id="p-0278" num="0277">Meanwhile, an input image input to the image display apparatus <b>100</b> may be input as a fixed image size set in the external device <b>400</b> or may be input as a compressed image size through an internal image decoder.</p><p id="p-0279" num="0278">Accordingly, the signal processor <b>170</b> in the image display apparatus <b>100</b> may expand an image size with at least one scaler for image size expansion, image quality processing, etc., and performs image quality processing to improve sharpness.</p><p id="p-0280" num="0279">Here, only an input image having a specific size was subjected to image size expansion and image quality processing.</p><p id="p-0281" num="0280">In addition, image quality processing is based on low-level feature such as variance indicating a distribution of a difference between a median value of an edge or a pixel and a peripheral value, having a limitation that is not adaptive to the image resolution.</p><p id="p-0282" num="0281">In addition, image quality processing was performed with only the input image resolution regardless of a source resolution of the input image, and there is a limitation in that an improvement filter and a size adjustment filter cannot be applied correspondingly to the original resolution of the input image.</p><p id="p-0283" num="0282">Meanwhile, research into a super resolution (SR) algorithm has been conducted regarding the number of frames in use, in which of data region of a spatial region feature matching with a frequency is to be performed, whether high-resolution images are to be inferred from input low-resolution or whether to use a data set having a previously created codebook concept.</p><p id="p-0284" num="0283">The SR algorithm includes two key steps in common. The first is how to create or from which candidate data to be used as an image patch that represents high resolution and the second is extracting features to be used to compare and determine interrelationship between the input low-resolution image and the data defined in the first step.</p><p id="p-0285" num="0284">The features used here are diverse such as edge and periphery values, brightness of corresponding pixels, color difference or histogram, and pattern direction, but low- or mid-level features are generally used in image processing fields.</p><p id="p-0286" num="0285">However, real images are very diverse in many ways for human analysis, and there is a limit for human to directly develop improved filters for generating features and high-resolution candidate patches, and thus improvement of performance of the SR has stagnated after reaching a certain level.</p><p id="p-0287" num="0286">Meanwhile, deep learning, which is mainly used in the image field, has a form in which several layers are sequentially connected, and an output of each layer is used as an input of the next layer. Also, all layers calculate the entirety or part of input data as a weighted sum and obtain a resultant output by applying a non-linear function to the calculated value. Also, in the learning process, a weight of the synapse connecting inputs and outputs of all layers is obtained.</p><p id="p-0288" num="0287">Such a deep learning structure has several similarities when compared to the SR algorithm.</p><p id="p-0289" num="0288">First, a feature extraction filter and an image quality improvement filter used in the SR algorithm will play a similar role to the synapse weight in the deep learning structure, and secondly, whether to reflect multiple filter results of the SR in the deep learning layer or strength may be considered by matching output determination through non-linearity. In addition, compared to the existing case where images of at most 100 units are referenced in the algorithm development process, deep learning-based algorithms use more than 10,000 units of learning data, so the deep learning-based algorithm is considered to more elaborately analyze more images than human to generate an improvement filter fitting thereto.</p><p id="p-0290" num="0289">Therefore, in the present disclosure, a super resolution SR may be performed by using an artificial intelligence technology based algorithm.</p><p id="p-0291" num="0290"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a view illustrating that an OSD and an image are mixed and displayed.</p><p id="p-0292" num="0291">Referring to the figure, the display <b>180</b> of the image display apparatus <b>100</b> may display an OSD <b>920</b> and an image <b>910</b> jointly.</p><p id="p-0293" num="0292">For example, the OSD <b>920</b> may be displayed in a part (left side) of the image <b>910</b> jointly.</p><p id="p-0294" num="0293">In this case, when the resolutions of the OSD <b>920</b> and the image <b>910</b> displayed at a left area of the display <b>180</b> are different, it is desirable upscale the resolution of the OSD <b>920</b> according to the resolution of the image <b>910</b>.</p><p id="p-0295" num="0294">However, when only the resolution of the OSD <b>920</b> is upscaled, an edge area or a boundary area of the OSD <b>920</b> is not smoothly processed, and as a result, the clarity of the OSD <b>920</b> is degraded.</p><p id="p-0296" num="0295">Therefore, the present disclosure proposes a method which may enhance the clarity of the OSD <b>920</b> while upscaling the resolution of the OSD <b>920</b> according to the resolution of the image <b>910</b> when the resolutions of the OSD <b>920</b> and the image <b>910</b> are different. This will be described with reference to <figref idref="DRAWINGS">FIG. <b>10</b></figref> and below.</p><p id="p-0297" num="0296"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a view illustrating an internal block diagram of a signal processor according to an embodiment of the present disclosure.</p><p id="p-0298" num="0297">Referring to the figure, a signal processor <b>170</b><i>a </i>may include an OSD processor <b>1010</b> upscaling an OSD having a first resolution to a second resolution greater than the first resolution and a synthesizer <b>1020</b> synthesizing at least a part of an image having the second resolution and the upscaled OSD having the second resolution.</p><p id="p-0299" num="0298">In this case, the OSD processor <b>1010</b> outputs the OSD having the second resolution, in which luminance and transparency are adjusted. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and noise may be reduced when mixing with the image.</p><p id="p-0300" num="0299">For example, when it is assumed that the first resolution 2K and the second resolution is 4K, the signal processor <b>170</b><i>a </i>may first upscale a 2K OSD and convert the 2K OSD into a 4K resolution at the time of synthesizing the 2K OSD and the 4K image. In this case, the super resolution algorithm may also be used.</p><p id="p-0301" num="0300">Meanwhile, it is desirable that the OSD processor <b>1010</b> increases luminance Y and transparency &#x3b1; of the 2K OSD for enhancement of the clarity of the OSD.</p><p id="p-0302" num="0301">That is, the OSD processor <b>1010</b> may control luminance HOSDy and transparency of the OSD having the second resolution to be greater than the luminance and the transparency of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution.</p><p id="p-0303" num="0302">As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0304" num="0303">Meanwhile, the OSD processor <b>1010</b> may control change amounts of the luminance HOSDy and the transparency of the OSD having the second resolution to be larger as a difference between the first resolution and the second resolution increases.</p><p id="p-0305" num="0304">For example, when it is assumed that the first resolution 2K and the second resolution is 8K, the signal processor <b>170</b><i>a </i>may first upscale a 2K OSD and convert the 2K OSD into a 8K resolution at the time of synthesizing the 2K OSD and the 8K image. In this case, the super resolution algorithm may also be used.</p><p id="p-0306" num="0305">Meanwhile, it is desirable that the OSD processor <b>1010</b> increases luminance Y and transparency &#x3b1; of the 2K OSD for enhancement of the clarity of the OSD.</p><p id="p-0307" num="0306">In this case, it is desirable that the OSD processor <b>1010</b> further increases the luminance Y and the transparency a of the OSD in a case where 2K is upscaled to 8K as compared with a case where 2K is upscaled to 4K.</p><p id="p-0308" num="0307">As such, the change amounts of the luminance and the transparency are changed according to the difference between the first resolution and the second resolution to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0309" num="0308">Meanwhile, it is desirable that the OSD processor <b>1010</b> performs signal processing so that the clarities of the luminance Y and the transparency &#x3b1; of the OSD are equal to each other when the luminance Y and the transparency &#x3b1; of the OSC increase. As a result, the clarity of the OSD may be increased and the noise may be reduced.</p><p id="p-0310" num="0309">Meanwhile, the OSD processor <b>1010</b> may be configured to increase transparency HOSDa of the OSD having the second resolution as the luminance of the image increases and control the transparency HOSDa of the OSD having the second resolution to decrease as the luminance of the image decreases. As such, the transparency is adjusted according to the luminance of the image to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0311" num="0310">Meanwhile, the OSD processor <b>1010</b> may be configured to increase sharpness of the transparency HOSDa of the OSD having the second resolution. As such, the sharpness of the transparency is adjusted to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0312" num="0311">Meanwhile, the OSD processor <b>1010</b> may be configured to jointly increase the luminance HOSDy and the sharpness of the transparency of the OSD having the second resolution. As such, the sharpness of the transparency is adjusted to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0313" num="0312">Meanwhile, the OSD processor <b>1010</b> may be configured to increase the change amounts of the luminance HOSDy and the sharpness of the transparency of the OSD having the second resolution as the luminance of the image increases and control the change amounts of the luminance HOSDy and the sharpness of the transparency of the OSD having the second resolution to decrease as the luminance of the image decreases.</p><p id="p-0314" num="0313">As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0315" num="0314">Meanwhile, the OSD processor <b>1010</b> may output the OSD having the second resolution, in which colors Cb and Cr are further adjusted. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0316" num="0315">Meanwhile, the OSD processor <b>1010</b> may control a level of a color HOSDbr of the OSD having the second resolution to be greater than the level of a color LOSDbr of the OSD having the first resolution after luminance after upscaling the OSD having the first resolution to the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0317" num="0316">Meanwhile, the OSD processor <b>1010</b> may include a first resolution processor <b>1012</b> changing the luminance LOSDy of the OSD having the first resolution to the luminance HOSDy of the OSD having the second resolution, a second resolution processor <b>1014</b> changing the transparency LOSDa of the OSD having the first resolution to the transparency HOSDa of the OSD having the second resolution, and a third resolution processor <b>1016</b> changing the color LOSDbr of the OSD having the first resolution to the color HOSDbr of the OSD having the second resolution.</p><p id="p-0318" num="0317">The first resolution processor <b>1012</b> may perform image quality processing with the resolution of a luminance component Y of the OSD.</p><p id="p-0319" num="0318">For example, the first resolution processor <b>1012</b> increases the resolution of the luminance of the OSD having the first resolution to convert and output the luminance of the OSD having the second resolution which is the same as the image.</p><p id="p-0320" num="0319">The second resolution processor <b>1014</b> may perform image quality processing with the resolution of the transparency of the OSD.</p><p id="p-0321" num="0320">For example, the second resolution processor <b>1014</b> increases the resolution of the transparency of the OSD having the first resolution to convert and output the transparency of the OSD having the first resolution into the transparency of the OSD having the second resolution which is the same as the image.</p><p id="p-0322" num="0321">Meanwhile, the second resolution processor <b>1014</b> may perform image quality processing with alpha (&#x3b1;) which is a blending ratio of the image and the OSD.</p><p id="p-0323" num="0322">For example, the second resolution processor <b>1014</b> increases the resolution of the alpha (&#x3b1;) of the OSD having the first resolution to convert and output the alpha (&#x3b1;) of the OSD having the first resolution into the alpha (&#x3b1;) of the OSD having the second resolution which is the same as the image.</p><p id="p-0324" num="0323">Meanwhile, the third resolution processor <b>1016</b> may perform image quality processing with the resolutions of the color components Cb and Cr of the OSD.</p><p id="p-0325" num="0324">For example, the third resolution processor <b>1016</b> increases the resolutions of the colors Cb and Cr of the OSD having the first resolution to convert and output the colors Cb and Cr of the OSD having the first resolution into the colors Cb and Cr of the OSD having the second resolution which is the same as the image.</p><p id="p-0326" num="0325">As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0327" num="0326"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a view illustrating an internal block diagram of a signal processor according to another embodiment of the present disclosure.</p><p id="p-0328" num="0327">Referring to the figure, a signal processor <b>170</b><i>b </i>may include a learning processor DRL that upscales an OSD having a first resolution to a second resolution greater than the first resolution and a synthesizer <b>1020</b> that synthesizes at least a part of an image having the second resolution and the upscaled OSD having the second resolution.</p><p id="p-0329" num="0328">Referring to the figure, a signal processor <b>170</b><i>b </i>according to another embodiment of the present disclosure is similar to the signal processor <b>170</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>, but different from the signal processor <b>170</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref> in that the OSD processor <b>1010</b><i>b </i>includes the learning processor DRL and the resolution processor <b>1018</b>.</p><p id="p-0330" num="0329">Meanwhile, the resolution processor <b>1018</b> may correspond to the third resolution processor <b>1016</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0331" num="0330">The learning processor DRL may change the luminance of LOSDy of the OSD having the first resolution to the luminance HOSDy of the OSD having the second resolution, and change the transparency LOSDa of the OSD having the first resolution to the transparency HOSDa of the OSD having the second resolution, based on the learning using the deep neural network.</p><p id="p-0332" num="0331">In this case, the learning processor DRL outputs the OSD having the second resolution, in which the luminance and the transparency are adjusted, based on the learning using the deep neural network. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0333" num="0332">For example, when it is assumed that the first resolution 2K and the second resolution is 4K, the signal processor <b>170</b><i>a </i>may first upscale a 2K OSD and convert the 2K OSD into a 4K resolution at the time of synthesizing the 2K OSD and the 4K image. In this case, the super resolution algorithm may also be used.</p><p id="p-0334" num="0333">Meanwhile, it is desirable that the learning processor DRL increases the luminance Y and the transparency &#x3b1; of the 2K OSD for enhancement of the clarity of the OSD, based on the learning using the deep neural network.</p><p id="p-0335" num="0334">That is, the learning processor DRL may control the luminance HOSDy and the transparency of the OSD having the second resolution to be greater than the luminance and the transparency of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution, based on the learning using the deep neural network.</p><p id="p-0336" num="0335">As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0337" num="0336">Meanwhile, the learning processor DRL may control the change amounts of the luminance HOSDy and the transparency of the OSD having the second resolution to be larger as the difference between the first resolution and the second resolution increases, based on the learning using the deep neural network.</p><p id="p-0338" num="0337">For example, when it is assumed that the first resolution 2K and the second resolution is 8K, the signal processor <b>170</b><i>a </i>may first upscale a 2K OSD and convert the 2K OSD into a 8K resolution at the time of synthesizing the 2K OSD and the 8K image. In this case, the super resolution algorithm may also be used.</p><p id="p-0339" num="0338">Meanwhile, it is desirable that the learning processor DRL increases the luminance Y and the transparency &#x3b1; of the 2K OSD for enhancement of the clarity of the OSD, based on the learning using the deep neural network.</p><p id="p-0340" num="0339">In this case, it is desirable that the learning processor DRL further increases the luminance Y and the transparency &#x3b1; of the OSD in a case where 2K is upscaled to 8K as compared with a case where 2K is upscaled to 4K.</p><p id="p-0341" num="0340">As such, the change amounts of the luminance and the transparency are changed according to the difference between the first resolution and the second resolution to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0342" num="0341">Meanwhile, it is desirable that the learning processor DRL performs signal processing so that the clarities of the luminance Y and the transparency &#x3b1; of the OSD are equal to each other when the luminance Y and the transparency &#x3b1; of the OSC increase, based on the learning using the deep neural network. As a result, the clarity of the OSD may be increased and the noise may be reduced.</p><p id="p-0343" num="0342">Meanwhile, the learning processor DRL may be configured to increase transparency HOSDa of the OSD having the second resolution as the luminance of the image increases and control the transparency HOSDa of the OSD having the second resolution to decrease as the luminance of the image decreases, based on the learning using the deep neural network. As such, the transparency is adjusted according to the luminance of the image to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0344" num="0343">Meanwhile, the learning processor DRL may be configured to increase sharpness of the transparency HOSDa of the OSD having the second resolution, based on the learning using the deep neural network. As such, the sharpness of the transparency is adjusted to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0345" num="0344">Meanwhile, the learning processor DRL may be configured to jointly increase the luminance HOSDy and the sharpness of the transparency of the OSD having the second resolution, based on the learning using the deep neural network. As such, the sharpness of the transparency is adjusted to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0346" num="0345">Meanwhile, the learning processor DRL may be configured to increase the change amounts of the luminance HOSDy and the sharpness of the transparency of the OSD having the second resolution as the luminance of the image increases and control the change amounts of the luminance HOSDy and the sharpness of the transparency of the OSD having the second resolution to decrease as the luminance of the image decreases.</p><p id="p-0347" num="0346">As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0348" num="0347"><figref idref="DRAWINGS">FIGS. <b>12</b>A to <b>13</b></figref> are views referenced for the operation description of <figref idref="DRAWINGS">FIG. <b>10</b> or <b>11</b></figref>.</p><p id="p-0349" num="0348">First, <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> illustrates an OSD <b>1210</b>, a transparency or alpha <b>1220</b> of the OSD, and an input image <b>1230</b>.</p><p id="p-0350" num="0349">The signal processor <b>170</b> according to the embodiment of the present disclosure may blend the OSD <b>1210</b> and the input image <b>1230</b> by using the transparency or the alpha <b>1220</b> of the OSD when synthesizing the OSD <b>1210</b> and the input image <b>1230</b>.</p><p id="p-0351" num="0350">In this case, as described above, the signal processor <b>170</b> allows the OSD of which luminance and transparency are adjusted, and the input image to be synthesized while upscaling the OSD.</p><p id="p-0352" num="0351"><figref idref="DRAWINGS">FIG. <b>12</b>B</figref> illustrates that the OSD <b>1250</b> of which luminance and transparency are adjusted, and the input image <b>1240</b> are synthesized according to the embodiment of the present disclosure.</p><p id="p-0353" num="0352">As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image. In particular, the clarity in an edge area or a border area of the OSD is enhanced.</p><p id="p-0354" num="0353"><figref idref="DRAWINGS">FIG. <b>13</b>A</figref> illustrates an OSD <b>1320</b> having a first resolution and an input image <b>1310</b> having a second resolution.</p><p id="p-0355" num="0354">When image quality improvement is not performed for the OSD <b>1320</b> having the first resolution, i.e., when the resolution is not increased or only the resolution is increased, and the luminance and the transparency are not adjusted, the clarity is low in the edge area or the border area of an OSD <b>1320</b><i>a </i>as illustrated in <figref idref="DRAWINGS">FIG. <b>13</b>A</figref>.</p><p id="p-0356" num="0355">Meanwhile, when image quality improvement is performed for the OSD <b>1320</b> having the first resolution, i.e., when the resolution of the OSD is increased and the luminance is increased, the clarity is enhanced in the edge area or the border area of an OSD <b>1320</b><i>b </i>as illustrated in <figref idref="DRAWINGS">FIG. <b>13</b>B</figref>.</p><p id="p-0357" num="0356">Meanwhile, when image quality improvement is performed for the OSD <b>1320</b> having the first resolution, i.e., when the resolution of the OSD is increased and the luminance and the transparency are increased, the clarity is further enhanced in the edge area or the border area of an OSD <b>1320</b><i>c </i>as illustrated in <figref idref="DRAWINGS">FIG. <b>13</b>C</figref>.</p><p id="p-0358" num="0357">Meanwhile, the signal processor <b>170</b><i>a </i>and the image display apparatus including the same according to another embodiment of the present disclosure includes an OSD processor <b>1010</b> that upscales an OSD having a first resolution to a second resolution greater than the first resolution and a synthesizer <b>1020</b> that synthesizes at least a part of an image having the second resolution and the upscaled OSD having the second resolution, and the OSD processor <b>1010</b> outputs the OSD having the second resolution, in which the blending ratio of the image and the OSD, and the luminance are adjusted. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0359" num="0358">Meanwhile, the OSD processor <b>1010</b> may control the luminance HOSDy and the blending ratio of the OSD having the second resolution to be greater than the luminance and the blending ratio of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0360" num="0359">Meanwhile, the OSD processor <b>1010</b> may control change amounts of the luminance HOSDy and the blending ratio of the OSD having the second resolution to be larger as the difference between the first resolution and the second resolution increases. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image. As such, the change amounts of the luminance and the blending ratio are changed according to the difference between the first resolution and the second resolution to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0361" num="0360">Meanwhile, the OSD processor <b>1010</b> may be configured to increase the blending ratio of the OSD having the second resolution as the luminance of the image increases and control the blending ratio of the OSD having the second resolution to decrease as the luminance of the image decreases. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image. As such, the blending ratio is adjusted according to the luminance of the image to increase the clarity of the OSD and reduce the noise when mixing with the image.</p><p id="p-0362" num="0361">Meanwhile, the OSD processor <b>1010</b> may be configured to increase the sharpness of the blending ratio of the OSD having the second resolution. As such, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image according to the blending ratio.</p><p id="p-0363" num="0362">Meanwhile, the OSD processor <b>1010</b> may be configured to increase the change amounts of the luminance HOSDy and the sharpness of the blending ratio of the OSD having the second resolution as the luminance of the image increases and decrease the change amounts of the luminance HOSDy and the sharpness of the blending ratio of the OSD having the second resolution as the luminance of the image decreases. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0364" num="0363">Meanwhile, the OSD processor <b>1010</b> may output the OSD having the second resolution, in which a color is further adjusted. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0365" num="0364">Meanwhile, the OSD processor <b>1010</b> may control a level of a color HOSDbr of the OSD having the second resolution to be greater than the level of a color LOSDbr of the OSD having the first resolution after luminance after upscaling the OSD having the first resolution to the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0366" num="0365">Meanwhile, the OSD processor <b>1010</b> may include a first resolution processor that changes the luminance LOSDy of the OSD having the first resolution to the luminance HOSDy of the OSD having the second resolution, a second resolution processor that changes the blending ratio of the OSD having the first resolution to the blending ratio of the OSD having the second resolution, and a third resolution processor that changes the color LOSDbr of the OSD having the first resolution to the color HOSDbr of the OSD having the second resolution. As a result, while the resolution of the OSD is increased, the clarity of the OSD may be increased and the noise may be reduced when mixing with the image.</p><p id="p-0367" num="0366">The signal processing device <b>170</b> and the image display apparatus <b>100</b> including the same according to the embodiment of the present disclosure may be extensively applied to 4K TV, 8K TV, signage including a plurality of displays, etc.</p><p id="p-0368" num="0367">While the preferred embodiments of the present disclosure have been illustrated and described above, the present disclosure is not limited to the aforementioned specific embodiments, various modifications may be made by a person with ordinary skill in the technical field to which the present disclosure pertains without departing from the subject matters of the present disclosure that are claimed in the claims, and these modifications should not be appreciated individually from the technical spirit or prospect of the present disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A signal processing device comprising:<claim-text>an OSC processor configured to upscale an OSC having a first resolution to a second resolution greater than the first resolution; and</claim-text><claim-text>a synthesizer configured to synthesize at least a part of an image having the second resolution and the upscaled OSD having the second resolution,</claim-text><claim-text>wherein the OSD processor outputs the OSD having the second resolution, in which luminance and transparency are adjusted.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The signal processing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the OSD processor controls the luminance and the transparency of the OSD having the second resolution to be greater than the luminance and the transparency of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The signal processing device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the OSD processor controls change amounts of the luminance and the transparency of the OSD having the second resolution to further increase as a difference between the first resolution and the second resolution increases.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The signal processing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the OSD processor is configured to increase the transparency of the OSD having the second resolution as the luminance of the image increases and decrease the transparency of the OSD having the second resolution as the luminance of the image decreases.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The signal processing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the OSD processor is configured to increase sharpness of the transparency of the OSD having the second resolution.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The signal processing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the OSD processor is configured to increase the luminance and the sharpness of the transparency of the OSD having the second resolution.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The signal processing device of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the OSD processor is configured to increase change amounts of the luminance and the sharpness of the transparency of the OSD having the second resolution as the luminance of the image increases and decrease the change amounts of the luminance and the sharpness of the transparency of the OSD having the second resolution as the luminance of the image decreases.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The signal processing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the OSD processor outputs the OSD having the second resolution, in which a color is further adjusted.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The signal processing device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the OSD processor controls a level of the color of the OSD having the second resolution to be greater than the level of the color of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The signal processing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signal processor includes<claim-text>a first resolution processor configured to change the luminance of the OSD having the first resolution to the luminance of the OSD having the second resolution,</claim-text><claim-text>a second resolution processor configured to change the transparency of the OSD having the first resolution to the luminance of the OSD having the second resolution, and</claim-text><claim-text>a third resolution processor configured to change a color of the OSD having the first resolution to the color of the OSD having the second resolution.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The signal processing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signal processor includes<claim-text>a learning processor configured to change the luminance of the OSD having the first resolution to the luminance of the OSD having the second resolution, and change the transparency of the OSD having the first resolution to the transparency of the OSD having the second resolution, based on learning a deep neural network, and</claim-text><claim-text>a resolution processor configured to change the color of the OSD having the first resolution to the color of the OSD having the second resolution.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A signal processing device comprising:<claim-text>an OSC processor configured to upscale an OSD having a first resolution to a second resolution greater than the first resolution; and</claim-text><claim-text>a synthesizer configured to synthesize at least a part of an image having the second resolution and the upscaled OSD having the second resolution,</claim-text><claim-text>wherein the OSD processor outputs the OSD having the second resolution, in which a blending ratio of the image and the OSD, and luminance are adjusted.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The signal processing device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the OSD processor controls the luminance and the blending ratio of the OSD having the second resolution to be greater than the luminance and the blending ratio of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The signal processing device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the OSD processor is configured to increase change amounts of the luminance and the blending ratio of the OSD having the second resolution as a difference between the first resolution and the second resolution increases.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The signal processing device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the OSD processor is configured to increase the blending ratio of the OSD having the second resolution as the luminance of the image increases and decrease the blending ratio of the OSD having the second resolution as the luminance of the image decreases.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The signal processing device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the OSD processor is configured to increase sharpness of the blending ratio of the OSD having the second resolution.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The signal processing device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the OSD processor is configured to increase change amounts of the luminance and the sharpness of the blending ratio of the OSD having the second resolution as the luminance of the image increases and decrease the change amounts of the luminance and the sharpness of the blending ratio of the OSD having the second resolution as the luminance of the image decreases.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The signal processing device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the OSD processor outputs the OSD having the second resolution, in which a color is further adjusted.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The signal processing device of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the OSD processor controls a level of the color of the OSD having the second resolution to be greater than the level of the color of the OSD having the first resolution after upscaling the OSD having the first resolution to the second resolution.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. An image display apparatus comprising:<claim-text>a display; and</claim-text><claim-text>a signal processor configured to output an image signal of which image quality is processed to the display,</claim-text><claim-text>wherein the signal processor comprises:</claim-text><claim-text>an OSC processor configured to upscale an OSC having a first resolution to a second resolution greater than the first resolution; and</claim-text><claim-text>a synthesizer configured to synthesize at least a part of an image having the second resolution and the upscaled OSD having the second resolution,</claim-text><claim-text>wherein the OSD processor outputs the OSD having the second resolution, in which luminance and transparency are adjusted.</claim-text></claim-text></claim></claims></us-patent-application>
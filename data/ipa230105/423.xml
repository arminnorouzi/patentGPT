<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000424A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221220" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000424</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17704287</doc-number><date>20220325</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>055</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>4088</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>7275</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>055</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>0012</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10092</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30016</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHOD OF EVALUATING CONCOMITANT CLINICAL DEMENTIA RATING AND ITS FUTURE OUTCOME USING PREDICTED AGE DIFFERENCE AND PROGRAM THEREOF</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63216028</doc-number><date>20210629</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>AcroViz USA Inc.</orgname><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Tseng</last-name><first-name>Wen-Yih</first-name><address><city>Taipei</city><country>TW</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Hsu</last-name><first-name>Yung-Chin</first-name><address><city>New Taipei</city><country>TW</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain, the method comprising scanning the individual's brain with a scanning device so as to acquire at least one medical brain image; processing the medical brain image to obtain at least one feature of the image; using a pre-established prediction model to determine a condition of the cognitive impairment and predict its future change based on the at least one feature obtained.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="85.51mm" wi="133.27mm" file="US20230000424A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="179.92mm" wi="101.35mm" orientation="landscape" file="US20230000424A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="102.79mm" wi="90.59mm" file="US20230000424A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="112.52mm" wi="127.59mm" file="US20230000424A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="77.22mm" wi="134.54mm" file="US20230000424A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="106.85mm" wi="135.30mm" file="US20230000424A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="107.95mm" wi="121.92mm" file="US20230000424A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="105.24mm" wi="150.37mm" file="US20230000424A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="126.83mm" wi="106.09mm" file="US20230000424A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="92.46mm" wi="151.38mm" file="US20230000424A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="187.11mm" wi="135.89mm" orientation="landscape" file="US20230000424A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="208.03mm" wi="148.34mm" orientation="landscape" file="US20230000424A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="204.55mm" wi="144.27mm" orientation="landscape" file="US20230000424A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="203.71mm" wi="145.88mm" orientation="landscape" file="US20230000424A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="138.43mm" wi="133.69mm" file="US20230000424A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="165.02mm" wi="143.85mm" file="US20230000424A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="81.28mm" wi="119.63mm" file="US20230000424A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="95.84mm" wi="168.23mm" file="US20230000424A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="203.45mm" wi="148.51mm" orientation="landscape" file="US20230000424A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="100.67mm" wi="150.20mm" file="US20230000424A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="76.12mm" wi="146.30mm" file="US20230000424A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="99.74mm" wi="163.66mm" file="US20230000424A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="123.61mm" wi="155.28mm" file="US20230000424A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED PATENT APPLICATION</heading><p id="p-0002" num="0001">This application claims priority to and the benefit of U.S. Provisional Patent Application Ser. No. 63/216,028, filed Jun. 29, 2021, which is incorporated herein in its entirety by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE INVENTION</heading><p id="p-0003" num="0002">The present disclosure relates to the technical field of evaluating predicted age difference (PAD) based on the corrected diffusion MRI data and using the PAD to predict current and future concomitant clinical dementia rating and related program, as well as distortion/artefact correction for diffusion magnetic resonance imaging (MRI) data in an integrated framework and program thereof.</p><heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0004" num="0003">The background description provided herein is for the purpose of generally presenting the context of the present invention. The subject matter discussed in the background of the invention section should not be assumed to be prior art merely as a result of its mention in the background of the invention section. Similarly, a problem mentioned in the background of the invention section or associated with the subject matter of the background of the invention section should not be assumed to have been previously recognized in the prior art. The subject matter in the background of the invention section merely represents different approaches, which in and of themselves may also be inventions.</p><p id="p-0005" num="0004">In clinical practice, physicians use various cognitive tests to assess cognitive decline and/or impairment due to dementia. The cognitive tests include dementia assessment tests and neuropsychological tests. Dementia assessment tests are developed based on clinically-relevant cognitive symptoms, while neuropsychological tests are developed based on the performance in different psychological domains. Dementia assessment tests that are widely used include the Clinical Dementia Rating (CDR), Mini-Mental State Examination (MMSE), Montreal Cognitive Assessment (MoCA), AD8, Alzheimer's Disease Assessment Scale-Cognitive Subscale (ADAS-cog), Alzheimer's Disease Co-operative Study ADL Scale for Mild Cognitive Impairment (ADCS-ADL-MCI), and Neuropsychiatric Inventory (NPI). A typical neuropsychological evaluation will assess a person's general intelligence, attention and concentration, learning and memory, reasoning and problem solving, language, visual-spatial skills (perception), motor and sensory skills, mood and behavior. An example of such evaluation is Repeatable Battery for the Assessment of Neuropsychological Status (RBANS).</p><p id="p-0006" num="0005">The clinical dementia rating (CDR) is a score estimated during a semi-structure interview used for staging the severity of dementia in Alzheimer's disease (AD) (Hughes et al., 1982) or non-AD dementia (Kazui et al., 2016). Compared with neuropsychological tests, the interview for the CDR focuses on patients' daily functioning and, therefore, is more congruent with standard diagnostic criteria of dementia (Lim et al., 2007).</p><p id="p-0007" num="0006">The CDR interview is conducted by certified physicians or nurses, and administered to patients and appropriate informants. The interview consists of 6 different domains, i.e. memory, orientation, judgment and problem solving, community affairs, home and hobbies, and personal care. The functional impairment of each domain is graded by a five-point scale system: none=0, questionable=0.5, mild=1, moderate=2, severe=3. The scores over the 6 domains are then converted to a global score of the CDR. The CDR score has been validated to be reliable to diagnose dementia and to grade the dementia severity (Morris, 1993). To date, the CDR has been included by professional societies worldwide in the guideline of dementia care and diagnosis (Petersen et al., 2018).</p><p id="p-0008" num="0007">However, current CDR has two significant limitations. The first imitation of the CDR is its inability to predict future outcome of the CDR in the upcoming 2 to 3 years. Although the CDR is reliable to grade the dementia severity, it cannot predict the progression of dementia. CDR future outcome is clinically important because medical professionals not only assess the severity of dementia of a patient, but also want to know whether and how fast dementia will be worsened in a few years to come. This limitation is clinically relevant especially in patients with very mild or questionable dementia, i.e. CDR=0.5. The outcome of these patients is heterogeneous, some may progress to dementia (CDR=1 or higher), some may turn to normal cognition (CDR=0), and some may stay in the same CDR (Daly et al., 2000). To address this limitation, some studies demonstrated that the sum scores of the six domains, i.e. sum of boxes (SOB) (O'Bryant et al., 2008), or the subscale score in the orientation domain (Kim et al., 2017), or combination of SOB with additional memory test (Lee et al., 2006) could be useful to predict dementia progression. However, all of the above measures rely heavily on the interview, and so they are affected by clinician's judgement, informant's reliability and cultural difference (Lim et al., 2007), which is the second limitation of the CDR.</p><p id="p-0009" num="0008">Regarding this second limitation, the CDR has stringent conditions for a successful interview. It requires well trained medical professionals and availability of reliable informants to ensure the accuracy of the CDR. Trained professionals or reliable informants may be lacking in less developed or supported areas, undermining the availability of accurate CDR.</p><p id="p-0010" num="0009">To address these limitations, Maillard et al. addressed the two limitations altogether by using the free water (FW) content, a metric derived from post-processing of the brain diffusion MRI. They reported that higher baseline FW was significantly associated with higher baseline CDR, and higher probability to change to a higher CDR score in later interviews (Maillard et al., 2019). In addition, to address the second limitation, Beheshti et al. estimated PAD on the basis of individual's morphometric features of gray matter of the brain extracted from T1-weighted (T1w) MRI, and found that PAD was associated with the scores of several clinical assessments of dementia including the CDR (Beheshti et al., 2018).</p><p id="p-0011" num="0010">However, all existing methods/discoveries for addressing CDR limitations has their own limitations and disadvantages. For example, Beheshti et al. demonstrated that PAD was associated with the CDR, but it fails to report how PAD could predict the future outcome of the CDR. O'Bryant et al., Kim et al. and Lee et al. used the information obtained from interview to predict CDR outcome, however, all of the scores they measure rely on interview, and so they are affected by clinician's judgement, informant's reliability and cultural difference. Maillard's FW metric has been shown to be associated with the CDR at the baseline and it can also predict the CDR change in later visits. However, FW may be confounded by cerebral atrophy in pixels neighboring the ventricles and cerebral sulci due to the partial volume effect of the cerebrospinal fluid (CSF).</p><p id="p-0012" num="0011">Therefore, a method based on MRI scanning data of an individual patient that can predict the dementia progression of a given CDR and is free of these limitations is imperatively needed.</p><p id="p-0013" num="0012">In another aspect of the field, diffusion MRI is widely used as a tool in understanding the morphometric features of an individual's brain. However, the diffusion-weighted images (DWI) comprised in a diffusion MRI (dMRI) data suffer from various artefacts, which impairs the medical professionals in estimating the PAD. Among them, the artefact of susceptibility-induced distortions is the most notorious since it greatly degrades the performance of dMRI analysis. This artefact is usually corrected retrospectively by measuring or estimating the &#x201c;field map&#x201d;, which represents how a point in the undistorted space displaces (or distorts in the distortion correction context) to the distorted space. The field map is a 3D scalar field since DWI is usually assumed to distort along the phase-encoding (PE) direction due to low acquisition bandwidth.</p><p id="p-0014" num="0013">The correction method could be roughly divided into three categories. The first is field map-based, this method explicitly measures the field map by acquiring two gradient echo images with exact scanning parameters except for the echo time (TE), then the field map is the phase differences between the two images divided by the differences of the TE values (Jezzard et al., 1998) The second is reverse gradient-based (Andersson et al., 2003; Irfanoglu et al., 2015; Hedouin et al., 2017), where two b<sub>0 </sub>images (or two complete dMRI datasets) with reverse PE gradients are acquired. The b<sub>0 </sub>images here refer to the DWI whose b-value=0 s/mm<sup>2</sup>, i.e., without applying the diffusion-sensitive gradients. The basic idea behind this category is that the two b<sub>0 </sub>images (or the two dMRI datasets) would have reverse distortions, hence the field map could be estimated by registering them to their &#x201c;midpoint&#x201d; image, which is theoretically the undistorted image. The last is anatomical image-based (Huang et al., 2008), in this category, the real b<sub>0 </sub>image is registered to a pseudo b<sub>0 </sub>image, which is constructed from the anatomical images, such as T1-weighted (T1w) image or T2-weighted (T2w) image. Since the anatomical images are free of distortions, the estimated displacement map of the registration could be considered as a surrogate of the field map. Technically, both the reverse gradient-based and the anatomical image-based methods greatly involve registration calculations, therefore, some efforts have been made to combine them by regarding the pseudo b<sub>0 </sub>images as the midpoint images in the reverse gradient-based methods; this approach has been shown to improve the performance of distortion correction (Irfanoglu et al., 2015).</p><p id="p-0015" num="0014">However, the above identified methods suffer from disadvantages that significantly limit the accuracy of the dMRI data.</p><p id="p-0016" num="0015">In particular, the anatomical image-based methods use the anatomical image (T1w or T2w) to construct the pseudo b<sub>0 </sub>image, which is used as the reference image to drive the correction. Correction methods in this category estimate the field map by non-linearly registering the real b<sub>0 </sub>image (distorted) to align with the pseudo b<sub>0 </sub>image (distortion-free). When the images are aligned well, the image discrepancy shall be low. Therefore, the goodness of the alignment is usually measured by similarity metrics such as sum of squared differences (SSD) (Huang et al., 2008), normalized mutual information (NMI) (Bhushan et al., 2015), correlation ratio (CR) (Bhushan et al., 2015), or cross-correlation (CC) (Irfanoglu et al., 2015).</p><p id="p-0017" num="0016">Non-linear registration is an ill-posed problem, so it is easy to fail in nature, particularly when the images have large discrepancy. Two primary sources contribute to the image discrepancy, one is the spatial discrepancy, which is due to the susceptibility-induced distortions, and the other is the contrast discrepancy, which is the intensity biases between the real b<sub>0 </sub>image and the pseudo b<sub>0 </sub>image. The conventional correction methods assume that the image discrepancy is entirely caused by the susceptibility-induced distortions and disregard the contribution of the intensity biases. In this manner, the overfitting problem may become significant for regions with large intensity biases, leading to wrong point-by-point correspondence and wrong field map.</p><p id="p-0018" num="0017">One of the solutions is to use the cost functions which are less sensitive to the contrast discrepancy, such as NMI, CR, or CC. However, estimations using these cost functions are easy to be trapped in local minima (or maxima, depends on the cost functions), rendering the spatial discrepancy originated from the susceptibility-induced distortions not corrected very well (Bhushan C et al., 2015). Another solution is to adjust the hyperparameters of the correction method to make the field map smoother, consequently lowering the sensitivity of image discrepancy. Similar to the previous approach, the lower sensitivity would lead the real distortions not corrected very well.</p><p id="p-0019" num="0018">In addition, some of the previous studies use general-purpose 3D registration correction method, such as Large Deformation Diffeomorphic Metric Mapping (LDDMM) (Beg et al., 2005; Miller et al., 2006) and Advanced Normalization Tools (ANTs) (Avants et al., 2008), to conduct the registration. Employing the 3D registration correction method to solve the 1D distortion correction problem has at least two drawbacks. First, the calculated free-form deformations have to be further constrained to along the PE direction (Irfanoglu et al., 2015), leading to unnecessary calculations. The second, which is more serious, is that the convergence of the registration may not always correspond to the convergence of distortion correction because the registration correction method have higher degrees of freedom than the distortion problem per se.</p><p id="p-0020" num="0019">Therefore, a method for correcting and/or reducing artefacts in dMRI data of an individual's brain is necessary for effectively calculating and predicting the dementia progression of a given CDR.</p><heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0021" num="0020">With respect to the technical limitations in the prior art, the present disclosure provides a brain age score used to predict the severity of dementia of a person and to predict his/her dementia outcome in the following years, and the program thereof. Specifically, the brain age score is PAD, and it evaluates the current CDR of a patient as well as predicting the patient's CDR change in the next few years.</p><p id="p-0022" num="0021">Brain age is a type of brain predicted age derived from a brain image-based machine learning method (Cole and Franke, 2017). It entails training of a brain age model using a large amount of brain images from a group of healthy people together with each individual's chronological age. Typically, features of brain structure or function are extracted from the brain MRI data and the features are trained by the machine learning algorithm. The algorithm produces a prediction model to predict an individual's chronological age based on his/her brain images, hence called brain predicted age. Once the model is trained and validated, it can then be used to estimate brain age of an individual, and the PAD, defined as the difference between brain age and chronological age of an individual, is then calculated to indicate the aging status of the brain.</p><p id="p-0023" num="0022">PAD has been shown to be a potential cognitive aging marker. It is associated with cognitive impairment (Liem et al., 2017), fluid intelligence (Cole, 2020; Cole et al., 2018), and various cognitive abilities (Boyle et al., 2020; Richard et al., 2018). Beheshti et al. estimated PAD using individual's morphometric features extracted from T1w MRI (Beheshti et al., 2018). They found that PAD was associated with the scores of several clinical assessments of dementia including the CDR. Beheshti's work demonstrated the capability of PAD in predicting the CDR at the moment of MRI scanning, however, they did not have longitudinal data to investigate the prediction of PAD in the CDR change in the following years.</p><p id="p-0024" num="0023">The Open Access Series of Imaging Studies (OASIS) is a databank which collects MRI and PET data, neuropsychological testing, and clinical data (https://www.oasis-brains.org/). It is publicly available to the scientific community with the aim of studying the effects of healthy aging and AD. The OASIS-3 is a dataset released in 2019 which comprises longitudinal data of 1098 participants, aged from 42 to 95 years (LaMontagne et al., 2019). The participants include (1) generally healthy and cognitively normal, i.e. the Clinical Dementia Rating (CDR)=0, individuals with or without a family history of Alzheimer's disease (AD), and (2) otherwise healthy individuals with questionable, mild, moderate or severe dementia, i.e. CDR=0.5, 1, 2, or 3, respectively. All participants gave informed consent following procedures approved by the Institutional Review Board of Washington University School of Medicine.</p><p id="p-0025" num="0024">Being able to predict a person's CDR in the following years is of great interest for healthcare professionals and patients because appropriate intervention and follow-up visits can be prescribed individually. Therefore, the present method is based on a system of 258 cognitively normal adults in the OASIS data to build a pre-established prediction model, which is a brain age model, and applied the model to participants with different CDRs encompassing 0, 0.5 and 1 at the baseline, i.e., the time of MRI scanning, and investigated the association of PAD with the CDR change in several years of follow-up.</p><p id="p-0026" num="0025">Specifically, the present invention establishes three conclusions. First, PADs were different among participants with different CDR scores of 0, 0.5 and 1 at the baseline. Second, PAD in participants with stable CDR of 0.5 was different from PAD in participants with the CDR of 0.5 at the baseline but turned to 0 or 1 in the follow-up. Third, PAD in participants with stable CDR of 0 was different from PAD in participants whose baseline CDR was 0 but converted to 0.5 in the follow-up years.</p><p id="p-0027" num="0026">Moreover, instead of using morphometric features of gray matter from T1w MRI (Beheshti et al., 2018) or FW content from diffusion MRI (Maillard et al., 2019), the present invention uses microstructural features of white matter (WM) of the brain extracted from diffusion tensor imaging (DTI) to calculate PAD, dubbed WM PAD, and establishes a method which associates the WM PAD and the CDR. Specifically, an individual's WM PAD is associated with this person's concomitant CDR. In addition, given the CDR of a person, WM PAD is also associated with the CDR change in the following two to three years. This method for associating the WM PAD and the CDR allows the medical professionals to use WM PAD as a surrogate marker to predict the CDR and its future outcome in the coming years.</p><p id="p-0028" num="0027">In one embodiment of the invention, a method and related computer based program have been designed to read the specified brain image data of an individual as inputs and estimates the person's predicted age difference (PAD), and according to the predefined cutoff value of PAD, it is determined whether the person is likely/or unlikely to be cognitively normal if he/she were assessed by the clinical dementia rating (CDR). The method and the program are used for a retrospective study on a cohort of a databank OASIS-3, and evaluated the performance of PAD in identifying patients who were likely/or unlikely to be cognitively normal (CDR =0) by comparing the results with patient's CDR scores.</p><p id="p-0029" num="0028">In one embodiment, the current invention is directed to a method of quantitatively evaluating likelihood of a disease condition and/or condition change from a medical image of an individual's brain, the method comprising (1) processing the original medical image to obtain a first medical image and a second medical image; (2) processing the first medical image to obtain segments of at least one brain tissue of the first medical image; (3) obtaining a deformation map of the individual's brain based on the segments of at least one brain tissue obtained in the step (2); (4) correcting artifacts of the second medical image; (5) obtaining at least one diffusion-related values of the brain tissue using the artifact-corrected second medical image obtained in the step (4) and the deformation map obtained from the first medical image in the step (3); (6) calculating predicted age difference (PAD) by inputting the extracted diffusion-related values obtained in the step (5) to an established brain age prediction model; (7) predicting likelihood of a disease condition or condition change from the PAD using a disease condition or a condition change prediction model.</p><p id="p-0030" num="0029">In one embodiment of the invention, the disease condition refers to concomitant CDR. In one embodiment, the disease condition change refers to CDR change in 2-3 years. In one embodiment, the diffusion-related values includes the fractional anisotropy (FA) and mean diffusivity (MD) values.</p><p id="p-0031" num="0030">In another aspect of the invention, the method of quantitatively evaluating likelihood of a disease condition or condition change from a medical image of an individual's brain, wherein the first image is a T1-weighted (T1w) image.</p><p id="p-0032" num="0031">In another aspect of the invention, the method of quantitatively evaluating likelihood of a disease condition or condition change from a medical image of an individual's brain, wherein the second image is obtained from a diffusion tensor imaging (DTI) sequence.</p><p id="p-0033" num="0032">In another aspect of the invention, the method of quantitatively evaluating likelihood of a disease condition or condition change from a medical image of an individual's brain, wherein the at least one brain tissue includes white matter (WM), gray matter (GM), or both.</p><p id="p-0034" num="0033">In another aspect of the invention, the method of quantitatively evaluating likelihood of a disease condition or condition change from a medical image of an individual's brain, wherein the step (3) includes registering the segments of at least one brain tissue obtained in the step (2) to MNI space.</p><p id="p-0035" num="0034">In another aspect of the invention, the method of quantitatively evaluating likelihood of a disease condition or condition change from a medical image of an individual's brain, wherein the step (4) includes inverting T1w contrast to synthesize a pseudo b0 image and registering the DTI to pseudo b0 image to correct the artifacts of DTI data.</p><p id="p-0036" num="0035">In another aspect of the invention, the method of quantitatively evaluating likelihood of a disease condition or condition change from a medical image of an individual's brain, wherein the brain tissue of step (5) is WM.</p><p id="p-0037" num="0036">In another aspect of the invention, the method of quantitatively evaluating likelihood of a disease condition or condition change from a medical image of an individual's brain, wherein the diffusion-related values of step (5) include fractional anisotropy (FA) and mean diffusivity (MD).</p><p id="p-0038" num="0037">In another aspect of the invention, the method of quantitatively evaluating likelihood of a disease condition or condition change from a medical image of an individual's brain according to any preceding claims, wherein the disease condition is the clinical dementia rating (CDR).</p><p id="p-0039" num="0038">In another aspect of the invention, the invention is directed to a method for evaluating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, comprising: (1) acquiring MRI data of the individual's brain using T1-weighted (T1w) imaging and diffusion tensor imaging (DTI) sequences; (2) processing the acquired T1w data so as to obtain white matter (WM) and grey matter (GM) segments; (3) registering the WM and GM segments obtained in the step (2) to the MNI space to obtain the deformation map of the individual's brain; (4) correcting artifacts of the DTI data; (5) obtaining fractional anisotropy (FA) and mean diffusivity (MD) maps for the individual in native space based on the artifact corrected DTI data; (6) extracting FA and MD values of WM region of the individual's brain using the FA and MD maps obtained in the step (5) and the deformation map obtained in the step (3); (7) calculating the WM PAD by inputting the extracted FA and MD of WM to an established brain predicted age model; (8) predicting the CDR and CDR change of the individual from the WM PAD using a CDR prediction model and a CDR change prediction model.</p><p id="p-0040" num="0039">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein the step (2) comprising: (i) correcting SI inhomogeneity of T1w data; (ii) segmenting tissue probability maps (TPM); (iii) obtaining WM and GM segments.</p><p id="p-0041" num="0040">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein the step (2) further comprising: inverting T1w contrast to synthesize a pseudo b0 image.</p><p id="p-0042" num="0041">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein the step (4) comprising: registering the DTI data to pseudo b0 image to correct the artifacts of DTI data.</p><p id="p-0043" num="0042">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein the step (5) comprising: (i) estimating diffusion tensor at each image pixel of the artifact corrected DTI data; (ii) calculating FA and MD at each pixel using a diffusion tensor indexes derived from the estimated diffusion tensor at each pixel; (iii) generating the FA and MD maps in the native space using the FA and MD at each pixel.</p><p id="p-0044" num="0043">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein MD=(&#x3bb;<b>1</b>+&#x3bb;<b>2</b>+&#x3bb;<b>3</b>)/3; FA=[3(&#x394;&#x3bb;<b>1</b><sup>2</sup>+&#x394;&#x3bb;<b>2</b><sup>2</sup>+&#x394;&#x3bb;<b>3</b><sup>2</sup>)/2(&#x3bb;<b>1</b><sup>2</sup>+&#x3bb;<b>2</b><sup>2</sup>+&#x3bb;<b>3</b><sup>2</sup>)]<sup>1/2</sup>. &#x3bb;<b>1</b>, &#x3bb;<b>2</b>, &#x3bb;<b>3</b> represent the 1st, 2nd, 3rd eigenvalues of the diffusion tensor, respectively.</p><p id="p-0045" num="0044">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein the step (6) comprising: (i) registering the FA and MD maps to the MNI space using the deformation maps in the step (3); and (ii) masking the registered FA and MD maps with WM segments.</p><p id="p-0046" num="0045">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein: the brain predicted age model is built by regressing the chronological age of more than one individual against FA and MD values inside the WM region using a Gaussian process regression method.</p><p id="p-0047" num="0046">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein: the individual's brain consists of the white matter region.</p><p id="p-0048" num="0047">In another aspect of the invention, the method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, wherein: the CDR change is the CDR of the individual in the next 2-3 years since the date of the MRI scanning.</p><p id="p-0049" num="0048">In another aspect of the invention, the invention is directed to a non-transitory computer readable medium storing a program causing a computer to execute a process for predicting the clinical dementia rating (CDR) of an individual and CDR's future change, the process comprising: (1) processing an original medical image to obtain a first medical image and a second medical image; (2) processing the first medical image to obtain segments of at least one brain tissue of the first medical image; (3) obtaining a deformation map of the individual's brain based on the segments of at least one brain tissue obtained in the step (2); (4) correcting artifacts of the second medical image; (5) obtaining fractional anisotropy (FA) and mean diffusivity (MD) values of the brain tissue using the artifacts-corrected second medical image obtained in the step (4) and the deformation map obtained from the first medical image in the step (3); (6) calculating predicted age difference (PAD) by inputting the extracted FA and MD obtained in the step (5) to an established dMRI-brain age model; (7) predicting likelihood of a disease condition or condition change from the PAD using a disease condition or a condition change prediction model.</p><p id="p-0050" num="0049">In another aspect of the invention, the non-transitory computer readable medium storing a program causing a computer to execute a process for predicting the clinical dementia rating (CDR) of an individual and CDR's future change, wherein the first image is a T1-weighted (T1w) image; and the second image is a diffusion tensor imaging (DTI) sequence.</p><p id="p-0051" num="0050">In another aspect of the invention, the non-transitory computer readable medium storing a program causing a computer to execute a process for predicting the clinical dementia rating (CDR) of an individual and CDR's future change, wherein the at least one brain tissue includes white matter (WM), gray matter (GM), or both.</p><p id="p-0052" num="0051">In another aspect of the current invention, DWI are corrected with a novel method and/or a computer based program so as to remove and/or reduce the artefacts in the dMRI data more efficiently.</p><p id="p-0053" num="0052">First, for spatial discrepancy, a registration method which is dedicated for the susceptibility-induced distortions is developed. The first derivative (analytic) and the second derivative (approximated) are derived. Therefore, this method could estimate the field map using a Gauss-Newton optimization scheme, which is very efficient. Second, a term called &#x201c;bias field&#x201d; is introduced to model the contrast discrepancy between the real b<sub>0 </sub>image and the pseudo b<sub>0 </sub>image. In this way, the image discrepancy would be explained by two factors: the susceptibility-induced distortions by the field map and the intensity biases by the bias field. During the registration process, the field map and the bias field are estimated simultaneously. Their values are automatically adjusted by the estimation method according to the magnitude of susceptibility-induced distortions and the level of intensity biases.</p><p id="p-0054" num="0053">These and other aspects of the present invention will become apparent from the following description of the preferred embodiment taken in conjunction with the following drawings, although variations and modifications therein may be effected without departing from the spirit and scope of the novel concepts of the disclosure.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0055" num="0054">The accompanying drawings illustrate one or more embodiments of the invention and together with the written description, serve to explain the principles of the invention. Wherever possible, the same reference numbers are used throughout the drawings to refer to the same or like elements of an embodiment.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a flow chart of a process for estimating the CDR from WM PAD;</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a flow chart of a process for acquisition of T1w and DTI data;</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a flow chart of a process for image processing of T1w;</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a flow chart of a process for registration of GM and WM to MNI space;</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a flow chart of a process for artifact correction of DTI data;</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a flow chart of a process for reconstruction of MD and FA;</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows a flow chart of a process for extraction of FA and MD;</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a flow chart of a process for estimation of WM brain age and PAD;</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows a flow chart of a process for prediction of the CDR and CDR change;</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows comparisons between CN1-to-[CN2], [nD1], and [nD2] of Example 2;</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows comparisons between [D1]-to-CN, [nD1], and [D1]-to-D2 of Example 2;</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows comparisons between CN1-to-[CN2], D1-to-[CN], and [CN]-to-D1 of Example 2;</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows spectrum of PAD.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows the process for participant's brain being scanned by an MRI scanner.</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>15</b></figref> shows the process for the anatomical image being converted to the pseudo b<sub>0 </sub>image.</p><p id="p-0071" num="0070"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows the process for extracting the real b<sub>0 </sub>image from the dMRI data.</p><p id="p-0072" num="0071"><figref idref="DRAWINGS">FIG. <b>17</b></figref> shows the process the pseudo b<sub>0 </sub>image is rigidly registered to the real b<sub>0 </sub>image.</p><p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>18</b></figref> shows the image discrepancy modeling.</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. <b>19</b></figref> shows the algorithm for estimating &#x3b2; and &#x3bd;.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>20</b></figref> shows the results of correcting the artefacts of a participant's dMRI data.</p><p id="p-0076" num="0075"><figref idref="DRAWINGS">FIG. <b>21</b></figref> shows the PAD comparisons between CN1-to-[CN2], [nD1], and [nD2] of Example 3.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>22</b></figref> shows the ROC curve analysis to evaluate the performance of differentiating between CDR=0 and CDR&#x3e;0.</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. <b>23</b></figref> shows the confusion matrix of the results using the cutoff PAD of 6, and the distribution of the two populations (i.e. CDR=0 and CDR&#x3e;0) with respect to PAD.</p><p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>24</b></figref> shows a conceptual data flow diagram illustrating the data flow between different components/means in an exemplary apparatus.</p><p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. <b>25</b></figref> shows a diagram illustrating an example of a hardware implementation for an apparatus employing a processing system.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading><p id="p-0081" num="0080">The invention will now be described more fully hereinafter with reference to the accompanying drawings, in which exemplary embodiments of the invention are shown. This invention may, however, be embodied in many different forms and should not be construed as limited to the embodiments set forth herein. Rather, these embodiments are provided so that this disclosure will be thorough and complete, and will fully convey the scope of the invention to those skilled in the art. Like reference numerals refer to like elements throughout.</p><p id="p-0082" num="0081">The terms used in this specification generally have their ordinary meanings in the art, within the context of the invention, and in the specific context where each term is used. Certain terms that are used to describe the invention are discussed below, or elsewhere in the specification, to provide additional guidance to the practitioner regarding the description of the invention. For convenience, certain terms may be highlighted, for example using italics and/or quotation marks. The use of highlighting has no influence on the scope and meaning of a term; the scope and meaning of a term is the same, in the same context, whether or not it is highlighted. It will be appreciated that same thing can be said in more than one way. Consequently, alternative language and synonyms may be used for any one or more of the terms discussed herein, nor is any special significance to be placed upon whether or not a term is elaborated or discussed herein. Synonyms for certain terms are provided. A recital of one or more synonyms does not exclude the use of other synonyms. The use of examples anywhere in this specification including examples of any terms discussed herein is illustrative only, and in no way limits the scope and meaning of the invention or of any exemplified term. Likewise, the invention is not limited to various embodiments given in this specification.</p><p id="p-0083" num="0082">It will be understood that, as used in the description herein and throughout the claims that follow, the meaning of &#x201c;a&#x201d;, &#x201c;an&#x201d;, and &#x201c;the&#x201d; includes plural reference unless the context clearly dictates otherwise. Also, it will be understood that when an element is referred to as being &#x201c;on&#x201d; another element, it can be directly on the other element or intervening elements may be present therebetween. In contrast, when an element is referred to as being &#x201c;directly on&#x201d; another element, there are no intervening elements present. As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items.</p><p id="p-0084" num="0083">It will be understood that, although the terms first, second, third etc. may be used herein to describe various elements, components, regions, layers and/or sections, these elements, components, regions, layers and/or sections should not be limited by these terms. These terms are only used to distinguish one element, component, region, layer or section from another element, component, region, layer or section. Thus, a first element, component, region, layer or section discussed below could be termed a second element, component, region, layer or section without departing from the teachings of the invention.</p><p id="p-0085" num="0084">Furthermore, relative terms, such as &#x201c;lower&#x201d; or &#x201c;bottom&#x201d; and &#x201c;upper&#x201d; or &#x201c;top,&#x201d; may be used herein to describe one element's relationship to another element as illustrated in the Figures. It will be understood that relative terms are intended to encompass different orientations of the device in addition to the orientation depicted in the Figures. For example, if the device in one of the figures is turned over, elements described as being on the &#x201c;lower&#x201d; side of other elements would then be oriented on &#x201c;upper&#x201d; sides of the other elements. The exemplary term &#x201c;lower&#x201d;, can therefore, encompasses both an orientation of &#x201c;lower&#x201d; and &#x201c;upper,&#x201d; depending of the particular orientation of the figure. Similarly, if the device in one of the figures is turned over, elements described as &#x201c;below&#x201d; or &#x201c;beneath&#x201d; other elements would then be oriented &#x201c;above&#x201d; the other elements. The exemplary terms &#x201c;below&#x201d; or &#x201c;beneath&#x201d; can, therefore, encompass both an orientation of above and below.</p><p id="p-0086" num="0085">It will be further understood that the terms &#x201c;comprises&#x201d; and/or &#x201c;comprising,&#x201d; or &#x201c;includes&#x201d; and/or &#x201c;including&#x201d; or &#x201c;has&#x201d; and/or &#x201c;having&#x201d;, or &#x201c;carry&#x201d; and/or &#x201c;carrying,&#x201d; or &#x201c;contain&#x201d; and/or &#x201c;containing,&#x201d; or &#x201c;involve&#x201d; and/or &#x201c;involving, and the like are to be open-ended, i.e., to mean including but not limited to. When used in this disclosure, they specify the presence of stated features, regions, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, regions, integers, steps, operations, elements, components, and/or groups thereof.</p><p id="p-0087" num="0086">Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this invention belongs. It will be further understood that terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and the present disclosure, and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein.</p><p id="p-0088" num="0087">As used in this disclosure, &#x201c;around&#x201d;, &#x201c;about&#x201d;, &#x201c;approximately&#x201d; or &#x201c;substantially&#x201d; shall generally mean within 20 percent, preferably within 10 percent, and more preferably within 5 percent of a given value or range. Numerical quantities given herein are approximate, meaning that the term &#x201c;around&#x201d;, &#x201c;about&#x201d;, &#x201c;approximately&#x201d; or &#x201c;substantially&#x201d; can be inferred if not expressly stated.</p><p id="p-0089" num="0088">As used in this disclosure, the phrase &#x201c;at least one of A, B, and C&#x201d; should be construed to mean a logical (A or B or C), using a non-exclusive logical OR. As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items.</p><p id="p-0090" num="0089">Embodiments of the invention are illustrated in detail hereinafter with reference to accompanying drawings. The description below is merely illustrative in nature and is in no way intended to limit the invention, its application, or uses. The broad teachings of the invention can be implemented in a variety of forms. Therefore, while this invention includes particular examples, the true scope of the invention should not be so limited since other modifications will become apparent upon a study of the drawings, the specification, and the following claims. For purposes of clarity, the same reference numbers will be used in the drawings to identify similar elements. It should be understood that one or more steps within a method may be executed in different order (or concurrently) without altering the principles of the invention.</p><p id="p-0091" num="0090">The description will be made as to the embodiments of the present invention in conjunction with the accompanying drawings in <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>20</b></figref>. In accordance with the purposes of this invention, as embodied and broadly described herein, this invention, in one aspect, relates to a method and related apparatus for calculating and predicting the CDR based on the MRI data of an individual's WM PAD.</p><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows the overall flowchart of the invention: process of using WM PAD to evaluate the CDR and predict CDR change by a program. The invention starts with the acquisition of MRI data using T1w imaging and diffusion-weighted imaging sequences (step 1). To ensure the same WM component is selected from different brains, spatial registration of each individual's MRI image to a standard template in the MNI space is mandated (step 2 &#x26; 3). In one embodiment, steps 2 and/or 3 are spatial normalization process during which the MRI image such as the T1w image is segmented and the segments of certain brain tissues are registered to MNI space. Therefore, a deformation map(s) of the certain brain tissues are obtained during the spatial normalization process. To ensure accurate quantification of diffusion-weighted indexes, i.e. fractional anisotropy (FA) and mean diffusivity (MD), artefacts in the diffusion-weighted MRI data should be corrected, followed by accurate estimation of the FA and MD indexes (step 4 &#x26; 5). Having obtained the FA and MD maps in the native space and the deformation matrix between the native space and MNI space, we can transform the FA and MD maps to the MNI space and extract the FA and MD indexes within the WM component (step 6). In one embodiment, steps 5 and/or 6 are feature quantification process, during which FA and MD maps based on the artifact corrected diffusion-weighted MRI data are obtained, and FA and MD indexes of certain brain tissues are extracted. The resulting FA and MD values serve as input to an established dMRI-brain age model to estimate brain age and WM PAD (step 7). In the final step, WM PAD is used to determine the CDR and predict CDR future change using pre-established models in programs (step 8). Detailed description of each step is described as follows.</p><p id="p-0093" num="0092"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows the process of acquisition of T1w and DTI data by the program.</p><p id="p-0094" num="0093">Step 1.1 is MRI scanning of a person's brain. A person is scanned by a MRI system at 1.5 Tesla or 3 Tesla with a phase-arrayed multi-channel head coil. MRI scanning is contraindicated for participants who are pregnant within 1st trimester, having pacemaker or defibrillator implantation, or vascular clipping or stenting within 6 months.</p><p id="p-0095" num="0094">Step 1.2 is acquisition of T1w. T1w data are acquired using a 3-dimensional magnetization prepared rapid gradient echo sequence. The imaging parameters are detailed as follow: repetition time (TR)=2400 ms, echo time (TE)=3.16 ms, inversion time (TI)=1000 ms, field-of-view (FOV)=256&#xd7;256&#xd7;176 mm3, and matrix size=256&#xd7;256&#xd7;176.</p><p id="p-0096" num="0095">Step 1.3 is acquisition of DTI data. DTI data are acquired using diffusion-weighted 2-dimensional single shot spin-echo echo planar imaging using 24 different magnitudes of diffusion sensitivity (b-values) corresponding to 24 different directions (b-vectors) evenly distributed in the q space.</p><p id="p-0097" num="0096">Step 1.4 is obtaining T1w and DTI data. In this way, one T1w data and one DTI data were obtained for each participant for the processing in step 2 and 4.</p><p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows the step of image processing of T1w by the program during the spatial normalization process.</p><p id="p-0099" num="0098">Step 2.1 is a person's T1w image. The T1w image is processed using the Segment toolbox in the SPM12 software (Wellcome Trust Centre for Neuroimaging, University College London, London, UK).</p><p id="p-0100" num="0099">Step 2.2 is correction of SI inhomogeneity on T1w. The toolbox corrects signal intensity inhomogeneity.</p><p id="p-0101" num="0100">Step 2.3 is segment tissue probability maps (TPM) using Segment toolbox in SPM12. Having corrected SI inhomogeneity, the toolbox segments the T1w image into various tissue segments, including gray matter (GM), white matter (WM), cerebrospinal fluid (CSF), bone, scalp, and others.</p><p id="p-0102" num="0101">Step 2.4 is obtaining GM and WM segments. In this way, six TPMs were obtained and from which GM and WM segments are selected for the processing in step 3.</p><p id="p-0103" num="0102">Step 2.5 is inverting T1w contrast. In parallel to step 2.3 and 2.4, the contrast of the T1w image, which has been corrected for the signal intensity inhomogeneity, is inverted to synthesize a pseudo b<sub>0 </sub>image.</p><p id="p-0104" num="0103">Step 2.6 is obtaining pseudo b<sub>0 </sub>image: In this way, we obtain a pseudo b<sub>0 </sub>image for each person for the processing in step 4.</p><p id="p-0105" num="0104"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows the process of registration of GM and WM to MNI space during the spatial normalization process.</p><p id="p-0106" num="0105">Step 3.1 is a person's GM and WM segments. The GM and WM segments are registered to the ICBM152 template which is defined in the MNI space.</p><p id="p-0107" num="0106">Step 3.2 is to register GM and WM segments to ICBM152 template: The registration invokes a process which is a variant of the Large Deformation Diffeomorphic Metric Mapping (LDDMM) (Beg et al., 2005; Miller et al., 2006). Specifically, the initial velocity situated in the ICBM152 space is iteratively estimated by shooting this velocity along the time dimension toward the individual's native space. In the registration, the course is divided into 10 uniform intervals, and an isotropic Gaussian filter with 10 mm full width at half maximum (FWHM) is used to ensure the smoothness of the initial velocity.</p><p id="p-0108" num="0107">Step 3.3 is obtaining a person's deformation maps: In the final stage of convergence, a deformation map which transforms the individual's TPM to match the TPM in the ICBM152 template in obtained. The deformation map is used for the processing in step 6.</p><p id="p-0109" num="0108"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows the process of artifact correction of DTI data.</p><p id="p-0110" num="0109">Step 4.1 is a person's DTI image. The raw DTI data suffers from various artefacts, including susceptibility-induced distortion, eddy current-induced distortion, head motion, and intensity inhomogeneity, which vary from person to person and should be corrected to ensure accurate registration to the MNI space.</p><p id="p-0111" num="0110">Step 4.2 is to register DTI to pseudo b<sub>0 </sub>image. The DTI data are processed using a novel registration-based method which correct these artefacts in an integrated framework. The registration-based method registers a person's raw DTI data to the same person's pseudo b<sub>0 </sub>image which serves as the reference image without distortion and intensity inhomogeneity.</p><p id="p-0112" num="0111">Step 4.3 is to reduce artifacts using a series of artefact models. By invoking the artefact models in the integrated framework, the process is able to reduce the artefacts of the DTI data.</p><p id="p-0113" num="0112">Step 4.4 is to obtain artefact-corrected DTI image. In this way, the artefact-corrected DTI image is obtained. When the estimation achieved convergence, the corrected DTI data is also aligned with the T1w image.</p><p id="p-0114" num="0113"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the process of reconstruction of MD and FA during the feature quantification process.</p><p id="p-0115" num="0114">Step 5.1 is the artefact-corrected DTI data. The artefact-corrected DTI data is processed to estimate the diffusion tensor and the diffusion tensor indexes derived therein.</p><p id="p-0116" num="0115">Step 5.2 is to estimate diffusion tensor at each image pixel. The diffusion tensor estimation is performed using an approach proposed by (Koay et al., 2007). Briefly, weighted linear least squares method is first conducted, the results are then employed as the initial estimation for the constrained nonlinear least squares method to obtain the diffusion tensors, which are ensured to be positive-definite (i.e., the eigenvalues of the diffusion tensors are all positive).</p><p id="p-0117" num="0116">Step 5.3 is to calculate FA and MD at each pixel. The diffusion tensor indexes, i.e. fractional anisotropy (FA) and mean diffusivity (MD), are derived from the estimated diffusion tensor at each pixel. The MD and FA values are determined using the standard formula: MD=(&#x3bb;<b>1</b>+&#x3bb;<b>2</b>+&#x3bb;<b>3</b>)/3, and FA=[3(&#x394;&#x3bb;<b>1</b><sup>2</sup>+&#x394;&#x3bb;<b>2</b><sup>2</sup>+&#x394;&#x3bb;<b>3</b><sup>2</sup>)/2(&#x3bb;<b>1</b><sup>2</sup>+&#x3bb;<b>2</b><sup>2</sup>+&#x3bb;<b>3</b><sup>2</sup>)]<sup>1/2</sup>, where &#x3bb;<b>1</b>, &#x3bb;<b>2</b> and &#x3bb;<b>3</b> denoted the first, second and third eigenvalues of the diffusion tensor, respectively, and &#x394;&#x3bb;<b>1</b>, &#x394;&#x3bb;<b>2</b> and &#x394;&#x3bb;<b>3</b> represented &#x3bb;<b>1</b>&#x2212;MD, &#x3bb;<b>2</b>&#x2212;MD, and &#x3bb;<b>3</b>&#x2212;MD, respectively.</p><p id="p-0118" num="0117">Step 5.4 is to obtain FA and MD maps in the native space: In this way, FA and MD maps for each person in native space were obtained.</p><p id="p-0119" num="0118"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows the process of extraction of FA and MD during the feature quantification process.</p><p id="p-0120" num="0119">Step 6.1 is a person's FA and MD maps in native space. Having obtained the FA and MD maps in step 5, it is necessary to extract FA and MD values from the standardized WM segment.</p><p id="p-0121" num="0120">Step 6.2 is to register FA and MD maps to MNI space. To do this, the FA and MD maps in the native space are normalized to the MNI space through the deformation map obtained in step 3.</p><p id="p-0122" num="0121">Step 6.3 is to mask the registered FA and MD maps with WM segment. Having normalized to the MNI space, the FA and MD values in WM are masked by the standardized WM segment in the ICBM152 template.</p><p id="p-0123" num="0122">Step 6.4 is to obtain FA and MD values of WM. In the final step, the values of FA and MD of WM for each person were obtained. The results are used for the processing in step 7.</p><p id="p-0124" num="0123"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows the process for estimation of WM brain age and PAD.</p><p id="p-0125" num="0124">Step 7.1 is a person's FA and MD in WM: A persons' FA and MD are used as the input to an established dMRI-brain age model which was trained and validated in advance using the DTI data acquired from the same MRI scanner.</p><p id="p-0126" num="0125">Step 7.2 is inputting the FA and MD values to an established dMRI-brain age model to estimate brain age. To build the dMRI-brain age model, a Gaussian process regression (GPR) method was used to regress the chronological age of the participants against the FA and MD values inside the WM region. The output of the model is a predicted age, called dMRI-brain age, estimated on the basis of the person's FA and MD values and the GRP model. The performance of the model has been tested and quantified in terms of the mean absolute error (MAE) and the Pearson's correlation coefficient (r) between the dMRI-brain age and chronological age.</p><p id="p-0127" num="0126">Step 7.3 is calculating the WM PAD from the estimated brain age and chronological age of the person. Having obtained the dMRI-brain age, predicted age difference of white matter (WM PAD) is calculated by the formula: dMRI-brain age&#x2212;chronological age.</p><p id="p-0128" num="0127">Step 7.4 is obtaining WM PAD. In this way, WM PAD was obtained for estimating the CDR and CDR change.</p><p id="p-0129" num="0128"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the process for determining of the CDR and prediction of CDR future change.</p><p id="p-0130" num="0129">Step 8.1 is a person's WM PAD. A person's WM PAD is used as input of an established prediction model to determine his/her CDR and/or predict CDR future change.</p><p id="p-0131" num="0130">Step 8.2 is to determine the CDR from the established model relating WM PAD to the CDR. To build the prediction model of the CDR from WM PAD, a linear regression model is applied to a dataset from a group of people whose WM PAD and concomitant CDR are known in advance. In one embodiment, the dataset from the group of people whose WM PAD and concomitant CDR are known in advance is used to establish a brain age model.</p><p id="p-0132" num="0131">Step 8.3 is to obtain determined CDR. Using the established regression model of the CDR and/or brain age model, the CDR of a person is determined from the same person's WM PAD.</p><p id="p-0133" num="0132">Step 8.4 is to predict the CDR future change from the established model relating WM PAD to CDR future change. To build the prediction model of the CDR future change from WM PAD, a linear regression model is applied to a dataset of a group of people whose WM PAD and the records of the CDR 2 to 3 years after WM PAD measurement are known. In one embodiment, such a model is a brain age model. The CDR change is defined as the difference between the CDR which is taken at the same time as WM PAD measurement and the CDR taken 2 to 3 years later.</p><p id="p-0134" num="0133">Step 8.5 is to obtain predicted CDR change. Using the established regression model of the CDR change, the CDR change of a person is predicted from the same person's WM PAD.</p><p id="p-0135" num="0134">In one embodiment, a pre-established prediction model includes both the dMRI-brain age model being used in calculating the WM PAD from the extracted FA and MD value in step 7, as well as the models relating WM PAD to the CDR and CDR change in step 8.</p><p id="p-0136" num="0135">In one embodiment, the medical brain images of a number of patients are processed to extract at least one feature of each patient. Given a set of training data, this pre-established prediction model is constructed by associating the features with the conditions of cognitive impairment using machine-learning methods. For independent data, the model can be used to predict the conditions of cognitive impairment by inputting the brain image features.</p><p id="p-0137" num="0136"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a conceptual data flow diagram illustrating the data flow between different components/means in an exemplary apparatus <b>2400</b>. In one embodiment, one or more image acquiring device (e.g. MRI scanner(s)) collect patient's brain image data and transmits the data to a reception component <b>2402</b> for being further processing. The reception component <b>2402</b> then transmits the image data to an image process component <b>2403</b>. It should be noted that in other embodiment, the image acquiring device(s), may directly transmit the image data to the image process component <b>2403</b>, without using the reception component <b>2402</b>.</p><p id="p-0138" num="0137">The image process component <b>2403</b> processes the steps 2.1-2.6 to obtain pseudo b<sub>0 </sub>image and GM and WM segments information. It then transmits the GM and WM segments information to a registration component <b>2406</b> for step 3.1-3.3 to obtain the deformation map. In parallel, the pseudo b<sub>0 </sub>image information and DTI data were transmitted to an artefact correction component <b>2405</b> for step 4.1-4.4, during which the artefact-corrected DTI image is obtained.</p><p id="p-0139" num="0138">In one embodiment, a prediction component <b>2407</b> then receives the deformation map from the registration component <b>2406</b>, and artefact-corrected DTI data from the artefact correction component <b>2405</b>. The prediction component <b>2407</b> may then proceed steps 5-8. In another embodiment, the steps 6.1-6.4 may take place at the registration component <b>2406</b> for obtaining FA and MD values of WM.</p><p id="p-0140" num="0139"><figref idref="DRAWINGS">FIG. <b>25</b></figref> is a diagram <b>2500</b> illustrating an example of a hardware implementation for a processing system <b>2400</b>. The processing system <b>2500</b> may be implemented with a bus architecture, represented generally by a bus <b>2503</b>. The bus <b>2503</b> may include any number of interconnecting buses and bridges depending on the specific application of the processing system <b>2500</b> and the overall design constraints. The bus <b>2503</b> links together various circuits including one or more processors and/or hardware components, represented by one or more processors <b>2501</b>, the image process component <b>2403</b>, the artefact correction component <b>2405</b>, the registration component <b>2406</b>, the prediction component <b>2407</b>, and a computer-readable medium/memory <b>2502</b>. The bus <b>2503</b> may also link various other circuits such as timing sources, peripherals, voltage regulators, and power management circuits, etc.</p><p id="p-0141" num="0140">The processing system <b>2500</b> may be coupled to an image acquiring device <b>2401</b>, which may be a MRI scanner or other clinical image acquiring device.</p><p id="p-0142" num="0141">The processing system <b>2500</b> includes one or more processors <b>2501</b> coupled to a computer-readable medium/memory <b>2502</b>. The one or more processors <b>2501</b> are responsible for general processing, including the execution of software stored on the computer-readable medium/memory <b>2502</b>. The software, when executed by the one or more processors <b>2501</b>, causes the processing system <b>2500</b> to perform the various functions described supra for any particular apparatus. The computer-readable medium/memory <b>2502</b> may also be used for storing data that is manipulated by the one or more processors <b>2501</b> when executing software. The processing system <b>2500</b> further includes at least one of the image process component <b>2403</b>, the artefact correction component <b>2405</b>, the registration component <b>2406</b>, the prediction component <b>2407</b>. The components may be software components running in the one or more processors <b>2501</b>, resident/stored in the computer readable medium/memory <b>2502</b>, one or more hardware components coupled to the one or more processors <b>2501</b>, or some combination thereof.</p><p id="p-0143" num="0142">It is understood that the specific order or hierarchy of blocks in the processes/flowcharts disclosed is an illustration of exemplary approaches. Based upon design preferences, it is understood that the specific order or hierarchy of blocks in the processes/flowcharts may be rearranged. Further, some blocks may be combined or omitted. The accompanying method claims present elements of the various blocks in a sample order, and are not meant to be limited to the specific order or hierarchy presented.</p><heading id="h-0007" level="1">EXAMPLE 1</heading><p id="p-0144" num="0143">This artifact correction steps 4.1-4.3 and <figref idref="DRAWINGS">FIG. <b>5</b></figref> is presented in a more detailed manner in <figref idref="DRAWINGS">FIG. <b>14</b>-<b>20</b></figref>.</p><p id="p-0145" num="0144">In particular, the participant's brain is scanned by a MRI scanner. The dMRI data and the anatomical image (T1w or T2w) are acquired. (<figref idref="DRAWINGS">FIG. <b>14</b></figref>.) The anatomical image is converted to the pseudo b<sub>0 </sub>image, which has similar image contrast to the real b<sub>0 </sub>image. (<figref idref="DRAWINGS">FIG. <b>15</b></figref>) The real b<sub>0 </sub>image is extracted from the dMRI data. (<figref idref="DRAWINGS">FIG. <b>16</b></figref>) The pseudo b<sub>0 </sub>image is rigidly registered to the real b<sub>0 </sub>image. This registered image is denoted as f<sub>0</sub>: &#x3a9;&#x2192;<img id="CUSTOM-CHARACTER-00001" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>+</sup>f<sub>0</sub>: &#x3a9;&#x2192;<img id="CUSTOM-CHARACTER-00002" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>+</sup> and the real b<sub>0</sub>b<sub>0 </sub>image is f<sub>1</sub>: &#x3a9;&#x2192;<img id="CUSTOM-CHARACTER-00003" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>+</sup>f<sub>1</sub>: &#x3a9;&#x2192;<img id="CUSTOM-CHARACTER-00004" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>+</sup>. Here &#x3a9; &#x2282; <img id="CUSTOM-CHARACTER-00005" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>3</sup>&#x3a9; &#x2282; <img id="CUSTOM-CHARACTER-00006" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>3 </sup>denotes the image domain. The coordinate of f<sub>0</sub>f<sub>0 </sub>is r &#x2208; &#x3a9;r &#x2208; &#x3a9;. The PE direction of f<sub>1</sub>f<sub>1 </sub>is p &#x2208;<img id="CUSTOM-CHARACTER-00007" he="2.79mm" wi="1.78mm" file="US20230000424A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>2</sup>p &#x2208;<img id="CUSTOM-CHARACTER-00008" he="2.79mm" wi="1.78mm" file="US20230000424A1-20230105-P00003.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>2</sup>. (<figref idref="DRAWINGS">FIG. <b>17</b></figref>)</p><p id="p-0146" num="0145">It is assumed that the bias field is multiplicative and model it with e<sup>&#x3b2;</sup>, where &#x3b2;: &#x3a9;&#x2192;<img id="CUSTOM-CHARACTER-00009" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>. In this way, <o ostyle="single">f</o><sub>0</sub>=e<sup>&#x3b2;</sup>&#xb7;f<sub>0 </sub>would be similar to f<sub>1</sub>. The smoothness of the &#x3b2; field is achieved via differential operator L<sub>&#x3b2;</sub>, with the norm of &#x3b2; defined as &#x2225;&#x3b2;&#x2225;<sup>2</sup>=<img id="CUSTOM-CHARACTER-00010" he="2.79mm" wi="1.44mm" file="US20230000424A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/>L<sub>&#x3b2;</sub>&#x3b2;|&#x3b2;<img id="CUSTOM-CHARACTER-00011" he="2.79mm" wi="1.44mm" file="US20230000424A1-20230105-P00005.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>2|</sub> According to <figref idref="DRAWINGS">FIG. <b>18</b></figref>, &#x3c8;: &#x3a9;&#x2192;<img id="CUSTOM-CHARACTER-00012" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/> is used to denote the field map (in unit of Hz). The relation between the distortion map and the field map is</p><p id="p-0147" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3c6;(<i>r</i>)=<i>r+k&#xb7;&#x3c8;</i>(<i>r</i>)&#xb7;<i>p, &#x2200;r &#x2208; &#x3a9;, </i>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0148" num="0000">where k=&#x3c4;V, &#x3c4; is the effective echo-spacing time and V is the filed of view if the DW image in the PE direction. Let &#x3bd;=k&#x3c8; be the initial velocity. The smoothness of &#x3bd; is achieved via differential operator L<sub>&#x3bd;</sub>, with the norm of &#x3bd; defined as &#x2225;&#x3bd;&#x2225;<sup>2</sup>=<img id="CUSTOM-CHARACTER-00013" he="2.79mm" wi="1.44mm" file="US20230000424A1-20230105-P00006.TIF" alt="custom-character" img-content="character" img-format="tif"/>L<sub>&#x3bd;</sub>&#x3bd;|&#x3bd;<img id="CUSTOM-CHARACTER-00014" he="2.79mm" wi="1.44mm" file="US20230000424A1-20230105-P00007.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>2</sub>.</p><p id="p-0149" num="0146">The distortion corrected image is |D&#x3c6;|f<sub>1 </sub>&#xb0; &#x3c6;, where &#xb0; denotes function composition. (<figref idref="DRAWINGS">FIG. <b>18</b></figref>)</p><p id="p-0150" num="0147"><figref idref="DRAWINGS">FIG. <b>19</b></figref> shows the process to estimate &#x3b2; and &#x3bd;. The cost function to be minimized is E<sub>1</sub>=E<sub>d</sub>+E<sub>&#x3b2;</sub>+E<sub>&#x3bd;</sub>, where</p><p id="p-0151" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <msub>      <mi>E</mi>      <mi>d</mi>     </msub>     <mo>=</mo>     <mrow>      <mfrac>       <mn>1</mn>       <mn>2</mn>      </mfrac>      <mo>&#x2062;</mo>      <msub>       <mi>&#x3c3;</mi>       <mi>d</mi>      </msub>      <mo>&#x2062;</mo>      <mrow>       <msub>        <mo>&#x222b;</mo>        <mrow>         <mi>v</mi>         <mtext> </mtext>         <mo>&#x2208;</mo>         <mi>&#x3a9;</mi>        </mrow>       </msub>       <mrow>        <msup>         <mrow>          <semantics definitionURL="">           <mo>&#x2758;</mo>           <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>          </semantics>          <mrow>           <mi>D</mi>           <mo>&#x2062;</mo>           <mi>&#x3c6;</mi>          </mrow>          <semantics definitionURL="">           <mo>&#x2758;</mo>           <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>          </semantics>         </mrow>         <mrow>          <mo>-</mo>          <mn>1</mn>         </mrow>        </msup>        <mo>&#x2062;</mo>        <msup>         <mrow>          <mo>(</mo>          <mrow>           <mrow>            <msup>             <mi>e</mi>             <mi>&#x3b2;</mi>            </msup>            <mo>&#x2062;</mo>            <msub>             <mi>f</mi>             <mn>0</mn>            </msub>           </mrow>           <mo>-</mo>           <mrow>            <mrow>             <semantics definitionURL="">              <mo>&#x2758;</mo>              <annotation encoding="Mathematica">"\[LeftBracketingBar]"</annotation>             </semantics>             <mrow>              <mi>D</mi>              <mo>&#x2062;</mo>              <mi>&#x3c6;</mi>             </mrow>             <semantics definitionURL="">              <mo>&#x2758;</mo>              <annotation encoding="Mathematica">"\[RightBracketingBar]"</annotation>             </semantics>            </mrow>            <mo>&#x2062;</mo>            <mrow>             <msub>              <mi>f</mi>              <mn>1</mn>             </msub>             <mo>&#x2218;</mo>             <mi>&#x3c6;</mi>            </mrow>           </mrow>          </mrow>          <mo>)</mo>         </mrow>         <mn>2</mn>        </msup>        <mo>&#x2062;</mo>        <mi>dr</mi>       </mrow>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00001-2" num="00001.2"><math overflow="scroll"> <mrow>  <msub>   <mi>E</mi>   <mi>&#x3b2;</mi>  </msub>  <mo>=</mo>  <mrow>   <mfrac>    <mn>1</mn>    <mn>2</mn>   </mfrac>   <mo>&#x2062;</mo>   <msub>    <mi>&#x3c3;</mi>    <mi>&#x3b2;</mi>   </msub>   <mo>&#x2062;</mo>   <msup>    <mrow>     <mo>&#xf605;</mo>     <mrow>      <msub>       <mi>L</mi>       <mi>&#x3b2;</mi>      </msub>      <mo>&#x2062;</mo>      <mi>&#x3b2;</mi>     </mrow>     <mo>&#xf606;</mo>    </mrow>    <mn>2</mn>   </msup>  </mrow> </mrow></math></maths><maths id="MATH-US-00001-3" num="00001.3"><math overflow="scroll"> <mrow>  <msub>   <mi>E</mi>   <mi>v</mi>  </msub>  <mo>=</mo>  <mrow>   <mfrac>    <mn>1</mn>    <mn>2</mn>   </mfrac>   <mo>&#x2062;</mo>   <msub>    <mi>&#x3c3;</mi>    <mi>v</mi>   </msub>   <mo>&#x2062;</mo>   <mrow>    <msup>     <mrow>      <mo>&#xf605;</mo>      <mrow>       <msub>        <mi>L</mi>        <mi>v</mi>       </msub>       <mo>&#x2062;</mo>       <mi>v</mi>      </mrow>      <mo>&#xf606;</mo>     </mrow>     <mn>2</mn>    </msup>    <mo>.</mo>   </mrow>  </mrow> </mrow></math></maths></p><p id="p-0152" num="0148">We use the sum of squared differences (SSD) to quantify the data-matching between the real and pseudo b<sub>0 </sub>images (E<sub>d</sub>), with the regularizations penalizing non-smooth bias field (E<sub>&#x3b2;</sub>) and non-smooth initial velocity (E<sub>&#x3bd;</sub>). Parameters &#x3c3;<sub>d</sub>, &#x3c3;<sub>&#x3b2;</sub>, and &#x3c3;<sub>&#x3bd;</sub> are the weightings for the data-matching and the regularization terms, respectively.</p><p id="p-0153" num="0149">For notational convenience, we define some assistant functions. The function b=vec(A) converts the 3D field A: &#x3a9;&#x2192;<img id="CUSTOM-CHARACTER-00015" he="2.79mm" wi="2.12mm" file="US20230000424A1-20230105-P00008.TIF" alt="custom-character" img-content="character" img-format="tif"/> to the vector b &#x2208;<img id="CUSTOM-CHARACTER-00016" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>n</sup><sup><sub2>xyz</sub2></sup><sup>&#xd7;1 </sup>by concatenating the field column by column, where n<sub>xyz </sub>is the total number of voxels. The reverse operation is achieved by A=ivec(b). In addition, the function B=diag(b) converts the b vector to the diagonal matrix B.</p><p id="p-0154" num="0150">The Gauss-Newton approach is used to update the values of &#x3b2;. Let</p><p id="p-0155" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>g</i><sub>&#x3b2;</sub><i>=|D&#x3c6;|</i><sup>&#x2212;1</sup><i>e</i><sup>&#x3b2;</sup><i>f</i><sub>0</sub>(<i>e</i><sup>&#x3b2;</sup><i>f</i><sub>0</sub><i>&#x2212;|D&#x3c6;|f</i><sub>1 </sub>&#xb0; &#x3c6;)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0156" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>H</i><sub>&#x3b2;</sub>=2|<i>D&#x3c6;|</i><sup>&#x2212;1</sup>(<i>e</i><sup>&#x3b2;</sup><i>f</i><sub>0</sub>)<sup>2</sup>, &#x2003;&#x2003;(3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0157" num="0000">and b<sub>&#x3b2;</sub>=vec(&#x3b2;), g<sub>&#x3b2;</sub>=vec(g<sub>&#x3b2;</sub>), and H<sub>&#x3b2;</sub>=diag(vec(H<sub>&#x3b2;</sub>)). The descent deviation is computed via</p><p id="p-0158" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3b4;<i>b</i><sub>&#x3b2;</sub>=(&#x3c3;<sub>d</sub><i>H</i><sub>&#x3b2;</sub><i>+L</i><sub>&#x3b2;</sub>)<sup>&#x2212;1</sup>(&#x3c3;<sub>d</sub><i>g</i><sub>&#x3b2;</sub>+&#x3c3;<sub>&#x3b2;</sub><i>L</i><sub>&#x3b2;</sub><i>b</i><sub>&#x3b2;</sub>), &#x2003;&#x2003;(4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0159" num="0000">or in the 3D field form &#x3b4;&#x3b2;=ivec(&#x3b4;b<sub>&#x3b2;</sub>), then the &#x3b2; field is updated by</p><p id="p-0160" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3b2;<sup>(iter+1)</sup>=&#x3b2;<sup>(iter)</sup>&#x2212;&#x3b3;<sub>&#x3b2;</sub>&#xb7;&#x3b4;&#x3b2;<sup>(iter)</sup>, &#x2003;&#x2003;(5)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0161" num="0151">Where 0&#x3c;&#x3b3;<sub>&#x3b2;</sub>&#x2264;1 is a scaling factor controlling the descent size. The differential operator L<sub>&#x3b2;</sub> is implemented through</p><p id="p-0162" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><img id="CUSTOM-CHARACTER-00017" he="2.79mm" wi="1.44mm" file="US20230000424A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/><i>L</i><sub>&#x3b2;</sub>&#x3b2;|&#x3b2;<img id="CUSTOM-CHARACTER-00018" he="2.79mm" wi="1.44mm" file="US20230000424A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>2</sub>=<sub>r&#x2208;&#x3a9;</sub>&#x3bb;<sub>&#x3b2;, 1</sub>&#x2225;&#x2207;&#x3b2;(<i>r</i>)&#x2225;<sup>2</sup>+&#x3bb;<sub>&#x3b2;, 2</sub>&#x2225;&#x2207;<sup>2</sup>&#x3b2;(<i>r</i>)&#x2225;<sup>2</sup><i>dr. </i>&#x2003;&#x2003;(6)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0163" num="0000">where the first term in the integral is the membrane energy and the second is the bending energy, &#x3bb;<sub>&#x3b2;, 1 </sub>and &#x3bb;<sub>&#x3b2;, 2 </sub>control their strength of regularization, respectively. Practically, this differential operator is expressed in the matrix form L<sub>&#x3b2;</sub> &#x2208;<img id="CUSTOM-CHARACTER-00019" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00012.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>n</sup><sup><sub2>xyz</sub2></sup><sup>&#xd7;n</sup><sup><sub2>xyz</sub2></sup>.</p><p id="p-0164" num="0152">Same as the bias field, Gauss-Newton approach is used to update the initial velocity field &#x3bd;. Let</p><p id="p-0165" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>g</i><sub>&#x3bd;</sub><i>=e</i><sup>&#x3b2;</sup><i>f</i><sub>0</sub>&#x2207;<sub>p</sub>(|<i>D&#x3c6;|</i><sup>&#x2212;1</sup>(<i>e</i><sup>&#x3b2;</sup><i>f</i><sub>0</sub><i>&#x2212;|D&#x3c6;|f</i><sub>1 </sub>&#xb0; &#x3c6;))<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0166" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>H</i><sub>&#x3bd;</sub><i>=|D&#x3c6;|</i><sup>2</sup>&#x2207;<sub>p</sub>(|<i>D&#x3c6;|</i><sup>&#x2212;1</sup><i>e</i><sup>&#x3b2;</sup><i>f</i><sub>0</sub>)&#xb7;&#x2207;<sub>p</sub><sup>T</sup>(|<i>D&#x3c6;|</i><sup>&#x2212;1</sup><i>e</i><sup>&#x3b2;</sup><i>f</i><sub>0</sub>). &#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0167" num="0153">Here &#x2207;<sub>p </sub>is the gradient along the p direction. Also let b<sub>&#x3bd;</sub>=vec(&#x3bd;), g<sub>&#x3bd;</sub>=vec(g<sub>&#x3bd;</sub>), H<sub>&#x3bd;</sub>=diag(vec(H<sub>&#x3bd;</sub>)), the descent deviation is computed via</p><p id="p-0168" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3b4;<i>b</i><sub>&#x3bd;</sub>=(&#x3c3;<sub>d</sub><i>H</i><sub>&#x3bd;</sub><i>+L</i><sub>&#x3bd;</sub>)<sup>&#x2212;1</sup>(&#x3c3;<sub>d</sub><i>g</i><sub>&#x3bd;</sub>+&#x3c3;<sub>&#x3bd;</sub><i>L</i><sub>&#x3bd;</sub><i>b</i><sub>&#x3bd;</sub>), &#x2003;&#x2003;(8)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0169" num="0000">or in the 3D field form &#x3b4;&#x3bd;=ivec(&#x3b4;b<sub>&#x3bd;</sub>), then the &#x3bd; field is updated by</p><p id="p-0170" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x3bd;<sup>(iter+1)</sup>=&#x3bd;<sup>(iter)</sup>&#x2212;&#x3b3;<sub>&#x3bd;</sub>&#xb7;&#x3b4;&#x3bd;<sup>(iter)</sup>, &#x2003;&#x2003;(9)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0171" num="0000">where 0&#x3c;&#x3b3;<sub>&#x3bd;</sub>&#x2264;1 controls the descent size. The differential operator L<sub>&#x3bd;</sub> is defined with the same form as L<sub>&#x3b2;</sub>, where the strength of membrane energy and that of bending energy are controlled by &#x3bb;<sub>&#x3bd;, 1 </sub>and &#x3bb;<sub>&#x3bd;, 2</sub>, respectively. This differential operator is encoded in the matrix L<sub>&#x3bd;</sub> &#x2208;<img id="CUSTOM-CHARACTER-00020" he="2.79mm" wi="2.46mm" file="US20230000424A1-20230105-P00013.TIF" alt="custom-character" img-content="character" img-format="tif"/><sup>n</sup><sup><sub2>xyz</sub2></sup><sup>&#xd7;n</sup><sup><sub2>xyz</sub2></sup>.</p><p id="p-0172" num="0154">Compare to existing method, the current registration method is dedicated for the susceptibility-induced distortions, which is a 1D deformation along the PE direction. While the first derivative (g<sub>&#x3bd;</sub>) has been shown previously, the Hessian (H<sub>&#x3bd;</sub>) which is an approximation to the second derivative is our invention. Therefore, this method estimates the field map using a Gauss-Newton optimization scheme, which is more efficient as compared to existing methods.</p><p id="p-0173" num="0155">Moreover, a term called &#x201c;bias field&#x201d; is introduced to model the contrast discrepancy between the real b<sub>0 </sub>image and the pseudo b<sub>0 </sub>image. Existing anatomical image-base methods do not explicitly consider the contrast discrepancy in the estimation procedures.</p><p id="p-0174" num="0156"><figref idref="DRAWINGS">FIG. <b>20</b></figref> shows an example of using the proposed method. As it can be observed, the raw b<sub>0 </sub>image (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>a</i>)</figref>) suffers from large distortions around the frontal regions, with reference to the pseudo b<sub>0 </sub>image (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>e</i>)</figref>). If the artefact models do not take the intensity biases into consideration, the method falls into local minima, rendering the distortions not adequately corrected, such as those regions indicated by the green arrows in the b<sub>0 </sub>image (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>b</i>)</figref>) and the fractional anisotropy (FA) map (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>c</i>)</figref>). On the other hand, using the bias field (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>i</i>)</figref>) to model the intensity biases can result in a proper registration, hence the b<sub>0 </sub>image (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>f</i>)</figref>) and the FA map (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>g</i>)</figref>) aligned to the pseudo b<sub>0 </sub>image very well. The field map estimated using the model with intensity biases (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>h</i>)</figref>) is much smoother than that without (<figref idref="DRAWINGS">FIG. <b>20</b>(<i>d</i>)</figref>). An explanation to the results is the locally large image discrepancy between the real and pseudo b<sub>0 </sub>images. Recall that two primary sources contribute to the image discrepancy: spatial discrepancy (by susceptibility-induced distortions) and the contrast discrepancy (by intensity biases). If the algorithm disregards the contribution of the intensity biases, the algorithm would attempt to reduce the cost function (i.e., SSD) by spatially aligning the registered images. It is well known that registration, particularly non-linear, is an ill-posed problem. In this manner, registering regions with large intensity biases is easy to result in wrong point-by-point correspondence and wrong field map.</p><p id="p-0175" num="0157">The results reveal that (1) the estimated field map could adequately correct the susceptibility-induced distortions, and (2) modeling the intensity biases could facilitate the correction for the susceptibility-induced distortions.</p><heading id="h-0008" level="1">EXAMPLE 2</heading><p id="p-0176" num="0158">Method</p><p id="p-0177" num="0159">1. Subjects</p><p id="p-0178" num="0160">The participants in OASIS-3 were enrolled by different projects related to Knight ADRC. The participants were (1) generally healthy and cognitively normal (CDR=0) individuals with or without a family history of AD, and (2) generally healthy individuals with CDR=0.5, 1 or 2. The exclusion criteria included medical conditions that precluded longitudinal participation, e.g. end-stage renal disease requiring dialysis or contraindications for the MRI study, e.g. pacemaker implantation. All participants gave informed consent following procedures approved by the Institutional Review Board of Washington University School of Medicine.</p><p id="p-0179" num="0161">2. Data Selection</p><p id="p-0180" num="0162">Participants in OASIS-3 undertook one to multiple sessions of brain MRI scanning on three 3T MRI scanners (Siemens, Erlangen, Germany) including two scanner models, i.e., Biograph and TIM Trio. To reduce scanner-wise variability, MRI data acquired from the same scanner model (TIM Trio) using the same acquisition scheme for T1w imaging and diffusion tensor imaging (DTI) were selected for the analysis. Since the analysis required acceptable image quality of T1w and DTI data, participants whose images presented severe image artefact such as motion blurring on T1w or failed artefact correction on DTI were excluded. Consequently, a total of 529 participants in 575 MRI scanning sessions were enrolled for subsequent analysis.</p><p id="p-0181" num="0163">3. MRI Data Acquisition</p><p id="p-0182" num="0164">As presented above in <figref idref="DRAWINGS">FIG. <b>2</b></figref> and related description, T1w data were acquired using the 3-dimensional magnetization prepared rapid gradient echo sequence. The imaging parameters were detailed as follow: repetition time (TR)=2400 ms, echo time (TE)=3.16 ms, inversion time (TI)=1000 ms, field-of-view (FOV)=256&#xd7;256&#xd7;176 mm3, and matrix size=256&#xd7;256&#xd7;176. DTI data were acquired using diffusion-weighted 2-dimensional single shot spin-echo echo planar imaging using 24 different magnitudes of diffusion sensitivity (b-values) corresponding to 24 different directions (b-vectors), repeated twice. The b-values and b-vectors are listed in the Supplementary File 1. The imaging parameters were described as follow: TR=14500 ms, TE=112 ms, FOV=224&#xd7;224 mm<sup>2</sup>, matrix size=112&#xd7;112, slice thickness=2 mm. The two DTI acquisitions were concatenated to form a single DTI dataset, and so there were one T1w data and one DTI data in each MR session for each participant.</p><p id="p-0183" num="0165">4. Image Processing</p><p id="p-0184" num="0166">All MRI data were processed following the procedures described below. It entailed tissue segmentation, artefact correction, diffusion tensor estimation, image registration and diffusion index extraction.</p><p id="p-0185" num="0167">4.1 As presented in <figref idref="DRAWINGS">FIG. <b>3</b></figref> and related description, for brain segmentation on T1w image, the T1w image was processed using the Segment toolbox in the SPM12 software (Wellcome Trust Centre for Neuroimaging, University College London, London, UK). The toolbox corrected signal intensity inhomogeneity and segmented the T1w image into various tissue components, including gray matter (GM), white matter (WM), cerebrospinal fluid (CSF), bone, scalp, and others. The outputs of the Segment toolbox were six TPMs, each represented a brain tissue component, and the T1w image with intensity inhomogeneity being corrected. The corrected T1w image were used in the subsequent artefact correction on DTI data, and the TPMs of GM and WM were used for spatial normalization of the images to the MNI space.</p><p id="p-0186" num="0168">4.2 Artefact correction on DTI data: As presented in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and related description, the raw DTI data suffered from various artefacts, including susceptibility-induced distortion, eddy current-induced distortion, head motion, and intensity inhomogeneity. The DTI data was processed using a novel registration-based process which corrected these artefacts in an integrated framework. Briefly, this process registered the raw DTI data to a pseudo b<sub>0 </sub>image which was synthesized by inverting the contrast of the T1w image, intensity inhomogeneity of which had been corrected in the step 4.1. In this manner, the pseudo b<sub>0 </sub>image served as the reference image without distortion and intensity inhomogeneity. By incorporating the artefact models in an integrated framework, the process was able to reduce the artefacts of the DTI data. Meanwhile, the corrected DTI data was readily aligned with the space of T1w image when the estimation achieved convergence.</p><p id="p-0187" num="0169">4.3 Diffusion tensor estimation: According to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the artefact-corrected DTI data was processed to estimate the diffusion tensor using the approach proposed by (Koay et al., 2007). Briefly, the weighted linear least squares method was first conducted, the results were then employed as the initial estimation for the constrained nonlinear least squares method to obtain the diffusion tensors, which were ensured to be positive-definite (i.e., the eigenvalues of the diffusion tensors were all positive). The associated fractional anisotropy (FA) and mean diffusivity (MD) were derived from the estimated diffusion tensor at each pixel. The MD and FA values were determined using the standard formula: MD=(&#x3bb;<b>1</b>+&#x3bb;<b>2</b>+&#x3bb;<b>3</b>)/3, and FA=[3(&#x394;&#x3bb;<b>1</b><sup>2</sup>+&#x394;&#x3bb;<b>2</b><sup>2</sup>+&#x394;&#x3bb;<b>3</b><sup>2</sup>)/2(&#x3bb;<b>1</b><sup>2</sup>+&#x3bb;<b>2</b><sup>2</sup>+&#x3bb;<b>3</b><sup>2</sup>)]<sup>1/2</sup>, where &#x3bb;<b>1</b>, &#x3bb;<b>2</b> and &#x3bb;<b>3</b> denoted the first, second and third eigenvalues of the diffusion tensor, respectively, and &#x394;&#x3bb;<b>1</b>, &#x394;&#x3bb;<b>2</b> and &#x394;&#x3bb;<b>3</b> represented &#x3bb;<b>1</b>&#x2212;MD, &#x3bb;<b>2</b>&#x2212;MD, and &#x3bb;<b>3</b>&#x2212;MD, respectively.</p><p id="p-0188" num="0170">4.4 Spatial normalization to the MNI space: The TPMs of GM and WM, segmented from the T1w image, were registered to the ICBM152 template (defined in the MNI space) using a variant of the Large Deformation Diffeomorphic Metric Mapping (LDDMM) algorithm (Hsu et al., 2012, Hsu et al., 2015, Beg et al., 2005; Miller et al., 2006). Specifically, the initial velocity situated in the ICBM152 space was iteratively estimated by shooting this velocity along the time dimension toward the individual's native space. On convergence, the associated deformation map could transform the individual's TPMs to match the ICBM152 TPM template. In the registration, the course was divided into 10 uniform intervals, and an isotropic Gaussian filter with 10 mm full width at half maximum (FWHM) was used to ensure the smoothness of the initial velocity.</p><p id="p-0189" num="0171">4.5 Diffusion index extraction: The FA and MD maps in the native space were normalized to the MNI space through the deformation map derived from the LDDMM registration. The FA and MD values in the WM pixels were extracted using the mask created from the WM TPM of the ICBM152 template. Since FA and MD were DTI indices representing white matter microstructural property, these values were used as the features in modeling the dMRI-brain age.</p><p id="p-0190" num="0172">All the image processing procedures were conducted using in-house programs in MATLAB (The MathWorks, Inc., Natick, Mass., USA) except the brain segmentation on T1w image for which SPM12 was used.</p><p id="p-0191" num="0173">5. Grouping According to CDR Track Records</p><p id="p-0192" num="0174">The participants enrolled in the study were grouped into 9 groups according to the track records of their CDR values. The 9 groups were named as follow: [CN]-Modeling, [CN1]-to-CN2, CN1-to-[CN2], [CN]-to-D1, D1-to-[CN], [D1]-to-CN, [nD1], [D1]-to-D2, and [nD2]. All groups were mutually exclusive except [CN1]-to-CN2 and CN1-to-[CN2] which recruited the same participants, undertaking the first and second MRI scanning, respectively. The characteristics of the 9 groups were described below. There were 475 people included in the analysis after grouping, 258 participants in the CN-Modeling group and 217 participants in the rest of the groups.</p><p id="p-0193" num="0175">5.1 [CN]-Modeling</p><p id="p-0194" num="0176">This group comprised participants who were cognitively normal (CDR=0, CN for short) and stable. The CDR was 0 in all clinical records and had at least one such record within 1 year before or after the MRI scanning. The data in this group served as the training data to build the dMRI-brain age model. [CN] denoted the cognitive status of CN around the time of MR scanning.</p><p id="p-0195" num="0177">5.2 [CN1]-to-CN2</p><p id="p-0196" num="0178">This group comprised 46 participants who were cognitively normal and stable. The screening criteria were the same as the [CN]-Modeling group. The data in this group served as the testing data of the dMRI-brain age modeling. [CN1] denoted that the participants were CN around the time of the first MR scanning.</p><p id="p-0197" num="0179">5.3 CN1-to-[CN2]</p><p id="p-0198" num="0180">Participants in this group (N=46) were the same participants as those in [CN1]-to-CN2. As described above, the MRI scanning date in this group was later than that in [CN1]-to-CN2 with the inter-scan interval of 2.91&#xb1;0.67 years. [CN2] denoted that the participants were CN around the time of the second MR scanning.</p><p id="p-0199" num="0181">5.4 [CN]-to-D1</p><p id="p-0200" num="0182">Participants in this group (N=34) were cognitively normal within the interval of &#xb1;180 days from the date of MRI scanning but converted to very mild symptomatic AD (CDR=0.5, D1 for short) after the interval.</p><p id="p-0201" num="0183">5.5 D1-to-[CN]</p><p id="p-0202" num="0184">Participants in this group (N=25) were cognitively normal within the interval of &#xb1;180 days from the MRI scanning date but were in D1 before the interval.</p><p id="p-0203" num="0185">5.6 [D1]-to-CN</p><p id="p-0204" num="0186">Participants in this group (N=26) were in D1 within the interval of &#xb1;180 days from the MRI scanning date but turned to CN after the interval. [D1] denoted the cognitive status of D1 around the time of MRI scanning.</p><p id="p-0205" num="0187">5.7 [nD1]</p><p id="p-0206" num="0188">Participants in this group (N=34) were in D1 within the interval of &#xb1;180 days from the MRI scanning date. After the interval, 19 participants had at least one clinical record showing that they stayed in the D1 stage, while rest of the participants (N=15) did not have any record of the CDR available. Therefore, nominal D1 (nD1 for short) was named for this group. [nD1] denoted that the participants were in nominal D1 around the time of MRI scanning.</p><p id="p-0207" num="0189">5.8 [D1]-to-D2</p><p id="p-0208" num="0190">Participants in this group (N=28) were in D1 within the interval of &#xb1;180 days from the MRI scanning date but converted to mild symptomatic AD (CDR=1, D2 for short) after the interval.</p><p id="p-0209" num="0191">5.9 [nD2]</p><p id="p-0210" num="0192">Participants in this group (N=24) were in D2 within the interval of &#xb1;180 days from the MRI scanning date. After the interval, 13 participants converted to moderate symptomatic AD (CDR=2, D3 for short), 6 participants had at least one clinical record showing that they stayed unchanged, and 5 participants did not have any CDR record. Therefore, nominal D2 (nD2 for short) was named for this group. [nD2] denoted that the participants were in nominal D2 around the time of MRI scanning.</p><p id="p-0211" num="0193">Table 1 lists the demographics of the people in the analysis and Table 2 summarizes the statistical results of the pairwise comparison among the seven groups.</p><p id="p-0212" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="315pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Demographics</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="offset" colwidth="84pt" align="left"/><colspec colname="1" colwidth="49pt" align="center"/><colspec colname="2" colwidth="182pt" align="center"/><tbody valign="top"><row><entry/><entry>Elapsed</entry><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="offset" colwidth="84pt" align="left"/><colspec colname="1" colwidth="49pt" align="center"/><colspec colname="2" colwidth="28pt" align="center"/><colspec colname="3" colwidth="56pt" align="center"/><colspec colname="4" colwidth="49pt" align="center"/><colspec colname="5" colwidth="49pt" align="center"/><tbody valign="top"><row><entry/><entry>Time</entry><entry>Sample</entry><entry>Gender</entry><entry>Age</entry><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="8"><colspec colname="1" colwidth="49pt" align="left"/><colspec colname="2" colwidth="35pt" align="left"/><colspec colname="3" colwidth="49pt" align="center"/><colspec colname="4" colwidth="28pt" align="center"/><colspec colname="5" colwidth="28pt" align="center"/><colspec colname="6" colwidth="28pt" align="center"/><colspec colname="7" colwidth="49pt" align="center"/><colspec colname="8" colwidth="49pt" align="center"/><tbody valign="top"><row><entry>Group</entry><entry>Category</entry><entry>(years)</entry><entry>Size</entry><entry>Female</entry><entry>Male</entry><entry>(years)</entry><entry>MMSE</entry></row><row><entry namest="1" nameend="8" align="center" rowsep="1"/></row><row><entry>[CN]-Modeling</entry><entry>Training</entry><entry/><entry>258</entry><entry>57.8%</entry><entry>42.2%</entry><entry>68.54 &#xb1; 8.75</entry><entry>29.24 &#xb1; 1.17</entry></row><row><entry/><entry>Data</entry></row><row><entry>[CN1]-to-CN2</entry><entry>Testing</entry><entry>&#x2002;2.91 &#xb1; 0.67&#x2020;</entry><entry>46</entry><entry>65.2%</entry><entry>34.8%</entry><entry>66.19 &#xb1; 8.13</entry><entry>29.17 &#xb1; 0.93</entry></row><row><entry/><entry>Data</entry></row><row><entry>CN1-to-[CN2]</entry><entry>Statistical</entry><entry>&#x2002;2.91 &#xb1; 0.67&#x2020;</entry><entry>46</entry><entry>65.2%</entry><entry>34.8%</entry><entry>69.10 &#xb1; 7.86</entry><entry>29.09 &#xb1; 1.15</entry></row><row><entry/><entry>Analysis</entry></row><row><entry>[CN]-to-D1</entry><entry>Statistical</entry><entry>2.49 &#xb1; 1.17</entry><entry>34</entry><entry>50.0%</entry><entry>50.0%</entry><entry>75.51 &#xb1; 6.45</entry><entry>28.85 &#xb1; 1.42</entry></row><row><entry/><entry>Analysis</entry></row><row><entry>D1-to-[CN]</entry><entry>Statistical</entry><entry>3.06 &#xb1; 1.87</entry><entry>25</entry><entry>60.0%</entry><entry>40.0%</entry><entry>75.75 &#xb1; 8.27</entry><entry>29.08 &#xb1; 1 04</entry></row><row><entry/><entry>Analysis</entry></row><row><entry>[D1]-to-CN</entry><entry>Statistical</entry><entry>1.44 &#xb1; 0.58</entry><entry>26</entry><entry>38.5%</entry><entry>61.5%</entry><entry>74.87 &#xb1; 7.29</entry><entry>28.35 &#xb1; 1.57</entry></row><row><entry/><entry>Analysis</entry></row><row><entry>[nD1]</entry><entry>Statistical</entry><entry/><entry>34</entry><entry>50.0%</entry><entry>50.0%</entry><entry>76.23 &#xb1; 7.21</entry><entry>26.65 &#xb1; 2.91</entry></row><row><entry/><entry>Analysis</entry></row><row><entry>[D1]-to-D2</entry><entry>Statistical</entry><entry>2.18 &#xb1; 1.06</entry><entry>28</entry><entry>32.1%</entry><entry>67.9%</entry><entry>75.45 &#xb1; 6.20</entry><entry>25.71 &#xb1; 2.45</entry></row><row><entry/><entry>Analysis</entry></row><row><entry>[nD2]</entry><entry>Statistical</entry><entry/><entry>24</entry><entry>33.3%</entry><entry>66.7%</entry><entry>&#x2002;76.40 &#xb1; 10.31</entry><entry>21.13 &#xb1; 3.89</entry></row><row><entry/><entry>Analysis</entry></row><row><entry namest="1" nameend="8" align="center" rowsep="1"/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="offset" colwidth="98pt" align="left"/><colspec colname="1" colwidth="49pt" align="left"/><colspec colname="2" colwidth="42pt" align="center"/><colspec colname="3" colwidth="42pt" align="center"/><colspec colname="4" colwidth="28pt" align="center"/><colspec colname="5" colwidth="56pt" align="center"/><tbody valign="top"><row><entry/><entry/><entry>CDR</entry><entry>Education</entry><entry>APOE</entry><entry>PAD</entry></row><row><entry/><entry>Group</entry><entry>(sum of box)</entry><entry>(years)</entry><entry>e4&#x2021;</entry><entry>(years)</entry></row><row><entry/><entry namest="offset" nameend="5" align="center" rowsep="1"/></row><row><entry/><entry>[CN]-Modeling</entry><entry>0.01 &#xb1; 0.06</entry><entry>16.22 &#xb1; 2.47</entry><entry>31.9%</entry></row><row><entry/><entry>[CN1]-to-CN2</entry><entry>0.00 &#xb1; 0.00</entry><entry>16.13 &#xb1; 2.60</entry><entry>34.8%</entry><entry>&#x2212;0.86 &#xb1; 5.48&#x2002;</entry></row><row><entry/><entry>CN1-to-[CN2]</entry><entry>0.00 &#xb1; 0.00</entry><entry>16.13 &#xb1; 2.60</entry><entry>34.8%</entry><entry>&#x2212;0.75 &#xb1; 5.53&#x2002;</entry></row><row><entry/><entry>[CN]-to-D1</entry><entry>0.04 &#xb1; 0.14</entry><entry>15.41 &#xb1; 2.70</entry><entry>38.2%</entry><entry>3.10 &#xb1; 7.72</entry></row><row><entry/><entry>D1-to-[CN]</entry><entry>0.00 &#xb1; 0.00</entry><entry>16.08 &#xb1; 2.80</entry><entry>36.0%</entry><entry>2.90 &#xb1; 7.19</entry></row><row><entry/><entry>[D1]-to-CN</entry><entry>0.94 &#xb1; 0.59</entry><entry>15.27 &#xb1; 2.44</entry><entry>42.3%</entry><entry>2.99 &#xb1; 7.16</entry></row><row><entry/><entry>[nD1]</entry><entry>1.91 &#xb1; 0.97</entry><entry>14.91 &#xb1; 3.39</entry><entry>52.9%</entry><entry>5.48 &#xb1; 6.68</entry></row><row><entry/><entry>[D1]-to-D2</entry><entry>2.45 &#xb1; 1.07</entry><entry>15.29 &#xb1; 3.09</entry><entry>57.1%</entry><entry>9.21 &#xb1; 6.14</entry></row><row><entry/><entry>[nD2]</entry><entry>5.46 &#xb1; 1.11</entry><entry>13.71 &#xb1; 2.93</entry><entry>54.2%</entry><entry>12.33 &#xb1; 10.89</entry></row><row><entry/><entry namest="offset" nameend="5" align="center" rowsep="1"/></row><row><entry/><entry namest="offset" nameend="5" align="left" id="FOO-00001">MMSE: Mini-Mental State Examination; CDR: Clinical Dementia Rating; CN: CDR = 0 (Cognitively Normal); D1: CDR = 0.5; D2: CDR = 1; PAD: Predicted Age Difference.</entry></row><row><entry/><entry namest="offset" nameend="5" align="left" id="FOO-00002">&#x2020;The elapsed time here represents the inter-scan interval between [CN1]-to-CN2 and CN1-to-[CN2].</entry></row><row><entry/><entry namest="offset" nameend="5" align="left" id="FOO-00003">&#x2021;APOE e4 means the percentage in the group population that poses either one or two e4 alleles.</entry></row></tbody></tgroup></table></tables></p><p id="p-0213" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="364pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 2</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Adjusted p-value of pairwise comparison (two sample t-test; adjusted</entry></row><row><entry>for multiple comparisons using the Benjamini-Hochberg method)</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="8"><colspec colname="1" colwidth="42pt" align="center"/><colspec colname="2" colwidth="56pt" align="left"/><colspec colname="3" colwidth="56pt" align="center"/><colspec colname="4" colwidth="56pt" align="left"/><colspec colname="5" colwidth="56pt" align="center"/><colspec colname="6" colwidth="28pt" align="center"/><colspec colname="7" colwidth="35pt" align="center"/><colspec colname="8" colwidth="35pt" align="left"/><tbody valign="top"><row><entry/><entry/><entry/><entry/><entry/><entry/><entry/><entry>Significant</entry></row><row><entry>Comparison</entry><entry/><entry>PAD of Group 1</entry><entry/><entry>PAD of Group 2</entry><entry>Original</entry><entry>Adjusted</entry><entry>(FDR of</entry></row><row><entry>#</entry><entry>Name of Group 1</entry><entry>(years)</entry><entry>Name of Group 2</entry><entry>(years)</entry><entry>p-value</entry><entry>p-value</entry><entry>0.05)</entry></row><row><entry namest="1" nameend="8" align="center" rowsep="1"/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="8"><colspec colname="1" colwidth="42pt" align="char" char="."/><colspec colname="2" colwidth="56pt" align="left"/><colspec colname="3" colwidth="56pt" align="center"/><colspec colname="4" colwidth="56pt" align="left"/><colspec colname="5" colwidth="56pt" align="center"/><colspec colname="6" colwidth="28pt" align="char" char="."/><colspec colname="7" colwidth="35pt" align="char" char="."/><colspec colname="8" colwidth="35pt" align="left"/><tbody valign="top"><row><entry>1</entry><entry>CN1-to-[CN2]</entry><entry>&#x2212;0.75 &#xb1; 5.53&#x2002;</entry><entry>[CN]-to-D1</entry><entry>3.10 &#xb1; 7.72</entry><entry>0.0112</entry><entry>0.0213</entry><entry>Yes</entry></row><row><entry>2</entry><entry>CN1-to-[CN2]</entry><entry>&#x2212;0.75 &#xb1; 5.53&#x2002;</entry><entry>D1-to-[CN]</entry><entry>2.90 &#xb1; 7.19</entry><entry>0.0197</entry><entry>0.0318</entry><entry>Yes</entry></row><row><entry>3</entry><entry>CN1-to-[CN2]</entry><entry>&#x2212;0.75 &#xb1; 5.53&#x2002;</entry><entry>[D1]-to-CN</entry><entry>2.99 &#xb1; 7.16</entry><entry>0.0158</entry><entry>0.0276</entry><entry>Yes</entry></row><row><entry>4</entry><entry>CN1-to-[CN2]</entry><entry>&#x2212;0.75 &#xb1; 5.53&#x2002;</entry><entry>[nD1]</entry><entry>5.48 &#xb1; 6.68</entry><entry>0.0000</entry><entry>0.0001</entry><entry>Yes</entry></row><row><entry>5</entry><entry>CN1-to-[CN2]</entry><entry>&#x2212;0.75 &#xb1; 5.53&#x2002;</entry><entry>[D1]-to-D2</entry><entry>9.21 &#xb1; 6.14</entry><entry>0.0000</entry><entry>0.0000</entry><entry>Yes</entry></row><row><entry>6</entry><entry>CN1-to-[CN2]</entry><entry>&#x2212;0.75 &#xb1; 5.53&#x2002;</entry><entry>[nD2]</entry><entry>12.33 &#xb1; 10.89</entry><entry>0.0000</entry><entry>0.0000</entry><entry>Yes</entry></row><row><entry>7</entry><entry>[CN]-to-D1</entry><entry>3.10 &#xb1; 7.72</entry><entry>D1-to-[CN]</entry><entry>2.90 &#xb1; 7.19</entry><entry>0.9219</entry><entry>1.0000</entry><entry>No</entry></row><row><entry>8</entry><entry>[CN]-to-D1</entry><entry>3.10 &#xb1; 7.72</entry><entry>[D1]-to-CN</entry><entry>2.99 &#xb1; 7.16</entry><entry>0.9555</entry><entry>1.0000</entry><entry>No</entry></row><row><entry>9</entry><entry>[CN]-to-D1</entry><entry>3.10 &#xb1; 7.72</entry><entry>[nD1]</entry><entry>5.48 &#xb1; 6.68</entry><entry>0.1774</entry><entry>0.2192</entry><entry>No</entry></row><row><entry>10</entry><entry>[CN]-to-D1</entry><entry>3.10 &#xb1; 7.72</entry><entry>[D1]-to-D2</entry><entry>9.21 &#xb1; 6.14</entry><entry>0.0012</entry><entry>0.0028</entry><entry>Yes</entry></row><row><entry>11</entry><entry>[CN]-to-D1</entry><entry>3.10 &#xb1; 7.72</entry><entry>[nD2]</entry><entry>12.33 &#xb1; 10.89</entry><entry>0.0004</entry><entry>0.0020</entry><entry>Yes</entry></row><row><entry>12</entry><entry>D1-to-[CN]</entry><entry>2.90 &#xb1; 7.19</entry><entry>[D1]-to-CN</entry><entry>2.99 &#xb1; 7.16</entry><entry>0.9663</entry><entry>0.9663</entry><entry>No</entry></row><row><entry>13</entry><entry>D1-to-[CN]</entry><entry>2.90 &#xb1; 7.19</entry><entry>[nD1]</entry><entry>5.48 &#xb1; 6.68</entry><entry>0.1610</entry><entry>0.2255</entry><entry>No</entry></row><row><entry>14</entry><entry>D1-to-[CN]</entry><entry>2.90 &#xb1; 7.19</entry><entry>[D1]-to-D2</entry><entry>9.21 &#xb1; 6.14</entry><entry>0.0012</entry><entry>0.0035</entry><entry>Yes</entry></row><row><entry>15</entry><entry>D1-to-[CN]</entry><entry>2.90 &#xb1; 7.19</entry><entry>[nD2]</entry><entry>12.33 &#xb1; 10.89</entry><entry>0.0008</entry><entry>0.0028</entry><entry>Yes</entry></row><row><entry>16</entry><entry>[D1]-to-CN</entry><entry>2.99 &#xb1; 7.16</entry><entry>[nD1]</entry><entry>5.48 &#xb1; 6.68</entry><entry>0.1696</entry><entry>0.2227</entry><entry>No</entry></row><row><entry>17</entry><entry>[D1]-to-CN</entry><entry>2.99 &#xb1; 7.16</entry><entry>[D1]-to-D2</entry><entry>9.21 &#xb1; 6.14</entry><entry>0.0012</entry><entry>0.0031</entry><entry>Yes</entry></row><row><entry>18</entry><entry>[D1]-to-CN</entry><entry>2.99 &#xb1; 7.16</entry><entry>[nD2]</entry><entry>12.33 &#xb1; 10.89</entry><entry>0.0007</entry><entry>0.0030</entry><entry>Yes</entry></row><row><entry>19</entry><entry>[nD1]</entry><entry>5.48 &#xb1; 6.68</entry><entry>[D1]-to-D2</entry><entry>9.21 &#xb1; 6.14</entry><entry>0.0271</entry><entry>0.0406</entry><entry>Yes</entry></row><row><entry>20</entry><entry>[nD1]</entry><entry>5.48 &#xb1; 6.68</entry><entry>[nD2]</entry><entry>12.33 &#xb1; 10.89</entry><entry>0.0044</entry><entry>0.0093</entry><entry>Yes</entry></row><row><entry>21</entry><entry>[D1]-to-D2</entry><entry>9.21 &#xb1; 6.14</entry><entry>[nD2]</entry><entry>12.33 &#xb1; 10.89</entry><entry>0.2006</entry><entry>0.2340</entry><entry>No</entry></row><row><entry namest="1" nameend="8" align="center" rowsep="1"/></row><row><entry namest="1" nameend="8" align="left" id="FOO-00004">CDR: Clinical Dementia Rating: CN: CDR = 0 (Cognitively Normal): D1: CDR = 0.5; D2: CDR = 1; PAD: Predicted Age Difference: FDR: False Discovery Rate.</entry></row></tbody></tgroup></table></tables></p><p id="p-0214" num="0194">6. dMRI-Brain Age</p><p id="p-0215" num="0195">Data in the CN-Modeling group were used to train the dMRI-brain age model. The Gaussian process regression method was used to regress the chronological age of the participants against the FA and MD values inside the WM region. After the training process, this model was applied to each MRI data in other groups to estimate the dMRI-brain age. The predicted age difference (PAD) was calculated by subtracting the chronological age from the dMRI-brain age. The performance of the model was tested in the CN1 group and quantified by the mean absolute error (MAE) and the Pearson's correlation coefficient (r) between the dMRI-brain age and chronological age.</p><p id="p-0216" num="0196">7. Statistical Inference</p><p id="p-0217" num="0197">PAD values were compared between any two of the seven groups, namely CN1-to-[CN2], [CN]-to-D1, D1-to-[CN], [D1]-to-CN, [nD1], [D1]-to-D2, and [nD2]; amounting to 21 pairwise comparisons. For each pair of groups, two sample t-test was conducted. The Benjamini-Hochberg procedure with a false discovery rate (FDR) of 0.05 was used to determine if a test was considered statistically significant.</p><p id="p-0218" num="0198">Results</p><p id="p-0219" num="0000">i. Comparison Between Different CDR Levels</p><p id="p-0220" num="0199"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows the groups with different CDR levels, i.e., CN1-to-[CN2], [nD1], and [nD2]. The mean and standard deviation of PAD values of CN1-to-[CN2], [nD1], and [nD2] were &#x2212;0.75&#xb1;5.53, 5.48&#xb1;6.68, and 12.33&#xb1;10.89 years, respectively. All comparisons on the three pairs of groups showed statistically significant differences (Table 2, #4, #6, #20). The results indicated that the higher the CDR level, the higher the PAD values.</p><p id="p-0221" num="0000">ii. Comparison within Participants with Baseline CDR of 0.5</p><p id="p-0222" num="0200"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows the participants who had the CDR of 0.5 at the time of MRI scanning who reverted to CN ([D1]-to-CN), stayed relatively stable ([nD1]), or converted to D2 ([D1]-to-D2) in 2 to 3 years (<figref idref="DRAWINGS">FIG. <b>11</b></figref>). The mean and standard deviation of PAD values of [D1]-to-CN, [nD1], and [D1]-to-D2 were 2.99&#xb1;7.16, 5.48&#xb1;6.68, 9.21&#xb1;6.14 years, respectively. The PAD value in [D1]-to-D2 was significantly higher than that in [D1]-to-CN (adjusted p=0.0031) and that in [nD1] (adjusted p=0.0406) (Table 2, #17, #19). The PAD value in [D1]-to-CN was lower than that in [nD1], but the comparison between the two groups did not reach statistical significance (adjusted p=0.2227) (Table 2, #16).</p><p id="p-0223" num="0000">iii. Comparison within Participants with Baseline CDR of 0</p><p id="p-0224" num="0201"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows the participants who were in CN at the time of MRI scanning but presented relatively stable (CN1-to-[CN2]) or unstable states ([CN]-to-D1 and D1-to-[CN]) in 1 to 2 years. The mean and standard deviation of PAD values of CN1-to-[CN2], [CN]-to-D1, and D1-to-[CN] were &#x2212;0.75&#xb1;5.53, 3.10&#xb1;7.72, and 2.90&#xb1;7.19 years, respectively. Both groups of [CN]-to-D1 (adjusted p=0.0213) and D1-to-[CN] (adjusted p=0.0318) had PAD values significantly higher than the CN1-to-[CN2] group (Table 2, #1, #2). There was no significant difference between the [CN]-to-D1 and D1-to-[CN] groups (adjusted p=1.0000) (Table 2, #7).</p><p id="p-0225" num="0000">iv. Spectrum of PAD</p><p id="p-0226" num="0202"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows the seven groups sorted by their mean PAD values, and we can observe five sub-groups as follow. The first sub-group comprised the participants with relatively stable normal cognition (CN1-to-[CN2]), and the mean PAD of which was approximately 0 years. The second sub-group included those exhibiting transitions between CN and D1 (i.e. [CN]-to-D1, D1-to-[CN], and [D1]-to-CN), and the mean PADs were approximately 3 years. The third, fourth and fifth sub-groups were the participants with [nD1], [D1]-to-D2, and [nD2], with the mean PAD of 5.48, 9.21 and 12.33 years, respectively.</p><p id="p-0227" num="0203">In conclusion, for older people with the CDR of 0, 0.5 and 1, DTI-derived PAD corresponds to the CDR scores, and PAD differs between people with relatively stable CDR and those with the CDR changed to higher scores in a couple of years. The results produced by the present invention suggest that PAD is essential in grading the dementia severity and predicting the change of severity in a few years. The capability of PAD can solve the current limitations of the CDR which is subjected to inaccurate information obtained from unreliable informants and inability to predict CDR change in the coming years. Therefore, the solution in the present invention can be a surrogate marker of the concomitant CDR and, furthermore, a prediction marker of the CDR change 2 to 3 years from the baseline.</p><p id="p-0228" num="0000">Association of PAD with Low to Moderate Severity of Dementia</p><p id="p-0229" num="0204">In the present invention, it is demonstrated that PAD derived from white matter microstructural property, as indicated by FA and MD of DTI, was associated with the CDR of 0, 0.5 and 1 (<figref idref="DRAWINGS">FIG. <b>10</b></figref>).</p><p id="p-0230" num="0000">PAD in Patients with the Baseline CDR of 0.5 is Associated with the CDR Change in 1 to 2 Years</p><p id="p-0231" num="0205">In patients with the CDR of 0.5, they presented different outcomes in approximately 1 to 2 years (<figref idref="DRAWINGS">FIG. <b>11</b></figref>). The present invention demonstrated that PADs among these patients were significantly different. Patients whose CDR changed from 0.5 to 1 in approximately 2 years had mean PAD of 9.21 years, significantly higher than patients with constant CDR of 0.5 (mean PAD=5.48 years, adjusted p=0.0406) or those with the baseline CDR of 0.5 but turned to 0 in approximately 1.5years (mean PAD=2.99 years, adjusted p=0.0031). The results have clinical implications. Currently exercise and cognitive training are the interventions recommended for patients with MCI (Petersen et al., 2018), whose CDR is mostly 0.5. However, no information is available to predict each patient's cognitive decline, and therefore, the intervention cannot be further tailored to each individual patient according to the decline risk. Findings in the present invention imply that PAD may be useful to stratify patients with MCI into high risk group (CDR changed from 0.5 to 1) and low risk group (constant CDR of 0.5 or CDR changed from 0.5 to 0). Appropriate intervention can then be designed for different risk groups.</p><p id="p-0232" num="0000">PAD in Patients with Baseline CDR of 0 is Associated with the CDR Change in 2 to 3 Years</p><p id="p-0233" num="0206">The present invention also showed that participants with constant CDR of 0 had significantly different PAD from those with baseline CDR of 0 but turned to 0.5 in approximately 2.5 year (mean PAD: &#x2212;0.75 years vs. 3.10 years, adjusted p=0.0213; <figref idref="DRAWINGS">FIG. <b>12</b></figref>). The results indicate that there is a variation of PAD even in cognitively normal people. Multiple brain age studies on cognitively normal people have demonstrated that PAD is associated with lifestyle factors, such as physical exercise, alcohol and tobacco consumption and interpersonal relationship, and cardiovascular risks, such as blood pressure, diabetes and body mass index (Cole, 2020; Hatton et al., 2018; Kolbeinsson et al., 2020; Ning et al., 2020; Ronan et al., 2016; Steffener et al., 2016). These studies suggest that, to some extent, the variation of PAD arises from health-related risk factors of each individual, the more the risk factors, the higher the PAD. Moreover, many epidemiological studies have shown that poor health-related risk factors have higher risks of afflicting dementia later in life (Akbaraly et al., 2019; Cations et al., 2016; Fayosse et al., 2020; Kivipelto et al., 2006; Mukadam et al., 2019; WHO, 2019). To sum, previous studies reported the association between PAD and lifestyle risk factors, and the associations between lifestyle factors and dementia. The present study further suggests that for the cognitively healthy people above 60 years old (approximately mean&#x2212;SD=69.10&#x2212;7.86 years in Table 1, CN1-to-[CN2]), those with PAD higher than 10 years (approximately mean+SD=3.10+7.72 years in Table 2, [CN]-to-D1) might be more likely to become cognitively impaired (CDR=0.5) in 3 years than those with PAD lower than &#x2212;6 years (approximately mean&#x2212;SD=&#x2212;0.75&#x2212;5.53 years in Table 2, CN1-to-[CN2]).</p><p id="p-0234" num="0000">Correspondence of PAD with Stable and Meta-Stable CDR States</p><p id="p-0235" num="0207">The present invention found that some of the groups in the study population exhibited relatively stable CDR scores in 2 to 3 years, i.e., CN1-to-[CN2], [nD1] and [nD2], while some groups presented relatively rapid transitions of the CDR, i.e., [CN]-to-D1, D1-to-[CN], [D1]-to-CN, and [D1]-to-D2 (Table 2). Notably, when labeling each group with PAD, a continuum of PAD revealed across the relatively stable and meta-stable groups (<figref idref="DRAWINGS">FIG. <b>13</b></figref>). PAD was smallest in the cognitively normal group (CN, &#x2212;0.75 years), followed by 3 meta-stable groups ([CN]-to-D1, D1-to-[CN], and [D1]-to-CN, presenting 3.10, 2.90, and 2.99 years, respectively), the relatively stable group of CDR=0.5 ([nD1], 5.48 years), another meta-stable group ([D1]-to-D2, 9.21 years), and the largest in the relatively stable group of CDR=1 or beyond ([nD2], 12.33 years). The spectrum of PAD corresponding to the stable and meta-stable states of the CDR provides a new perspective to the CDR in elderly people. Given a CDR score of 0, 0.5, or 1 of an individual, we could use PAD to predict the probability of staying cognitively normal (CDR=0) or transitioning to a different CDR stage (CDR=0.5 or 1) in a couple of years.</p><heading id="h-0009" level="1">EXAMPLE 3</heading><p id="p-0236" num="0208">Another example of the current invention provides proof of concept to support the proposed intended use of the device. The computer based program reads the specified brain image data of an individual as inputs and estimates the person's PAD, and according to the predefined cutoff value of PAD, the program determines whether the person is likely/or unlikely to be cognitively normal if he/she were assessed by the CDR.</p><p id="p-0237" num="0209">A retrospective study on a cohort of a databank OASIS-3 was performed with the current invention, which evaluated the performance of PAD in identifying patients who were likely/or unlikely to be cognitively normal (CDR=0) by comparing the results with patient's CDR scores.</p><p id="p-0238" num="0210">To obtain positive predictive value (PPV), negative predictive value (NPV), sensitivity, specificity, odds ratio (OR), and accuracy of distinguishing between CDR&#x3e;0 and CDR=0 at different cutoff values of PAD.</p><p id="p-0239" num="0211">Data Selection</p><p id="p-0240" num="0212">Same to Example 3, participants in OASIS-3 of Example 3 undertook one to multiple sessions of brain MRI scanning on three 3T MRI scanners (Siemens, Erlangen, Germany) including two scanner models, i.e., Biograph and TIM Trio. To reduce scanner-wise variability, MRI data acquired from the same scanner model (TIM Trio) using the same acquisition scheme for T1-weighted (T1w) imaging and diffusion tensor imaging (DTI) were selected for the analysis. Since the analysis required acceptable image quality of T1w and DTI data, participants whose images presented severe image artefact such as motion blurring on T1w or failed artefact correction on DTI were excluded. A total of 529 participants in 575 MRI scanning sessions were enrolled for subsequent analysis met the selection criteria.</p><p id="p-0241" num="0213">Grouping According to the CDR</p><p id="p-0242" num="0214">The participants enrolled in the study were grouped into 5 groups according to the track records of their CDR values. The 5 groups were named as follow: [CN]-Modeling, [CN1]-to-CN2, CN1-to-[CN2], [nD1], and [nD2]. All groups were mutually exclusive except [CN1]-to-CN2 and CN1-to-[CN2] which recruited the same participants, undertaking the first and second MRI scanning, respectively. The characteristics of the 5 groups were described below.</p><p id="p-0243" num="0215">i) [CN]-Modeling: This group comprised 258 participants who were cognitively normal (CDR=0, CN for short) and stable. The CDR was 0 in all clinical records and had at least one such record within 1 year before or after the MRI scanning. The data in this group served as the training data to build the dMRI-brain age model. [CN] denotes the cognitive status of CN around the time of MR scanning.</p><p id="p-0244" num="0216">ii) [CN1]-to-CN2: This group comprised 46 participants who were cognitively normal and stable. The screening criteria were the same as the [CN]-Modeling group. The data in this group served as the testing data of the dMRI-brain age modeling. [CN1] denotes that the participants were CN around the time of the first MR scanning.</p><p id="p-0245" num="0217">iii) CN1-to-[CN2]: Participants in this group (N=46) were the same participants as those in [CN1]-to-CN2. As described above, the MRI scanning date in this group was later than that in [CN1]-to-CN2 with the inter-scan interval of 2.91&#xb1;0.67 years. [CN2] denotes that the participants were CN around the time of the second MR scanning.</p><p id="p-0246" num="0218">iv) [nD1]: Participants in this group (N=34) were in D1 within the interval of &#xb1;180 days from the MRI scanning date. After the interval, 19 participants had at least one clinical record showing that they stayed in the D1 stage, while rest of the participants (N=15) did not have any record of the CDR available. Therefore, nominal D1 (nD1 for short) was named for this group. [nD1] denotes that the participants were in nominal D1 around the time of MRI scanning.</p><p id="p-0247" num="0219">v) [nD2]: Participants in this group (N=24) were in D2 within the interval of &#xb1;180 days from the MRI scanning date. After the interval, 13 participants converted to moderate symptomatic AD (CDR=2, D3 for short), 6 participants had at least one clinical record showing that they stayed unchanged, and 5 participants did not have any CDR record. Therefore, nominal D2 (nD2 for short) was named for this group. [nD2] denotes that the participants were in nominal D2 around the time of MRI scanning.</p><p id="p-0248" num="0220">Analysis and Statistics</p><p id="p-0249" num="0221">Brain age modeling: Data in the [CN]-Modeling group were used to train the dMRI-brain age model. The Gaussian Process Regression method was used to regress the chronological age of the participants against the DTI indices of the brain. After the training process, the model was applied to each MRI data in other groups to estimate the dMRI-brain age. The predicted age difference (PAD) was calculated by subtracting the chronological age from the dMRI-brain age. The performance of the model was tested in the [CN1]-to-CN2 group and quantified by the mean absolute error (MAE) and the Pearson's correlation coefficient (r) between the dMRI-brain age and chronological age.</p><p id="p-0250" num="0222">Group comparison: PAD values were compared between any two of the three groups, namely CN1-to-[CN2], [nD1], and [nD2], amounting to 3 pairwise comparisons. For each pair of groups, two sample t-test was conducted. The Benjamin-Hochberg procedure with a false discovery rate (FDR) of 0.05 was used to determine if a test was considered statistically significant.</p><p id="p-0251" num="0223">Performance of the intended use: To evaluate the performance of PAD in ruling out cognitively normal condition, we pooled the [nD1] and [nD2] groups to form a new group (named [nD1]+[nD2]) to represent the group with CDR&#x3e;0 which is to be ruled out by our intended use. The receiver operating characteristic (ROC) curve analysis was performed to evaluate the accuracy of PAD in differentiating between CDR=0 and CDR&#x3e;0. Positive predictive value (PPV), negative predictive value (NPV), sensitivity, specificity, and odds ratio (OR) of differentiating between CDR&#x3e;0 and CDR=0 was evaluated at different cutoff values of PAD.</p><p id="p-0252" num="0224">Results</p><p id="p-0253" num="0225">Demographics: Table 3 summarizes the demographics of the 5 groups including [CN]-Modeling (training data), [CN1]-to-CN2 (testing data) and 3 comparison groups, namely CN1-to-[CN2], [nD1], and [nD2]. Qualitatively, we can see a tendency of the increase in the CDR and PAD and the decrease in the MMSE from CN1-to-[CN2], [nD1] to [nD2].</p><p id="p-0254" num="0000"><tables id="TABLE-US-00003" num="00003"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="308pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 3</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Demographics</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="8"><colspec colname="1" colwidth="49pt" align="left"/><colspec colname="2" colwidth="35pt" align="left"/><colspec colname="3" colwidth="42pt" align="center"/><colspec colname="4" colwidth="28pt" align="center"/><colspec colname="5" colwidth="28pt" align="center"/><colspec colname="6" colwidth="28pt" align="center"/><colspec colname="7" colwidth="49pt" align="center"/><colspec colname="8" colwidth="49pt" align="center"/><tbody valign="top"><row><entry/><entry/><entry>Elapsed</entry><entry/><entry/><entry/><entry/><entry/></row><row><entry/><entry/><entry>Time</entry><entry>Sample</entry><entry>Gender</entry><entry>Age</entry><entry>MMSE</entry></row><row><entry>Group</entry><entry>Category</entry><entry>(years)</entry><entry>Size</entry><entry>Female</entry><entry>Male</entry><entry>(years)</entry><entry>CDR</entry></row><row><entry namest="1" nameend="8" align="center" rowsep="1"/></row><row><entry>[CN]-Modeling</entry><entry>Training</entry><entry/><entry>258</entry><entry>57.80%</entry><entry>42.20%</entry><entry>68.54 &#xb1; 8.75</entry><entry>29.24 &#xb1; 1.17</entry></row><row><entry/><entry>Data</entry></row><row><entry>[CN1]-to-CN2</entry><entry>Testing</entry><entry>2.91 &#xb1; 0.67&#x2020;</entry><entry>46</entry><entry>65.20%</entry><entry>34.80%</entry><entry>66.19 &#xb1; 8.13</entry><entry>29.17 &#xb1; 0.93</entry></row><row><entry/><entry>Data</entry></row><row><entry>CN1-to-[CN2]</entry><entry>Statistical</entry><entry>2.91 &#xb1; 0.67&#x2020;</entry><entry>46</entry><entry>65.20%</entry><entry>34.80%</entry><entry>69.10 &#xb1; 7.86</entry><entry>29.09 &#xb1; 1.15</entry></row><row><entry/><entry>Analysis</entry></row><row><entry>[nD1]</entry><entry>Statistical</entry><entry/><entry>34</entry><entry>50.00%</entry><entry>50.00%</entry><entry>76.23 &#xb1; 7.21</entry><entry>26.65 &#xb1; 2.91</entry></row><row><entry/><entry>Analysis</entry></row><row><entry>[nD2]</entry><entry>Statistical</entry><entry/><entry>24</entry><entry>33.30%</entry><entry>66.70%</entry><entry>&#x2002;76.40 &#xb1; 10.31</entry><entry>21.13 &#xb1; 3.89</entry></row><row><entry/><entry>Analysis</entry></row><row><entry namest="1" nameend="8" align="center" rowsep="1"/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="6"><colspec colname="offset" colwidth="91pt" align="left"/><colspec colname="1" colwidth="49pt" align="left"/><colspec colname="2" colwidth="42pt" align="center"/><colspec colname="3" colwidth="42pt" align="center"/><colspec colname="4" colwidth="28pt" align="center"/><colspec colname="5" colwidth="56pt" align="center"/><tbody valign="top"><row><entry/><entry/><entry/><entry>APOE</entry><entry/><entry/></row><row><entry/><entry/><entry>Education</entry><entry>e4&#x2021;</entry></row><row><entry/><entry>Group</entry><entry>(sum of box)</entry><entry>(years)</entry><entry>PAD</entry><entry>(years)</entry></row><row><entry/><entry namest="offset" nameend="5" align="center" rowsep="1"/></row><row><entry/><entry>[CN]-Modeling</entry><entry>0.01 &#xb1; 0.06</entry><entry>16.22 &#xb1; 2.47</entry><entry>31.90%</entry></row><row><entry/><entry>[CN1]-to-CN2</entry><entry>0.00 &#xb1; 0.00</entry><entry>16.13 &#xb1; 2.60</entry><entry>34.80%</entry><entry>&#x2212;0.86 &#xb1; 5.48&#x2002;</entry></row><row><entry/><entry>CN1-to-[CN2]</entry><entry>0.00 &#xb1; 0.00</entry><entry>16.13 &#xb1; 2.60</entry><entry>34.80%</entry><entry>&#x2212;0.75 &#xb1; 5.53&#x2002;</entry></row><row><entry/><entry>[nD1]</entry><entry>1.91 &#xb1; 0.97</entry><entry>14.91 &#xb1; 3.39</entry><entry>52.90%</entry><entry>5.48 &#xb1; 6.68</entry></row><row><entry/><entry>[nD2]</entry><entry>5.46 &#xb1; 1.11</entry><entry>13.71 &#xb1; 2.93</entry><entry>54.20%</entry><entry>12.33 &#xb1; 10.89</entry></row><row><entry/><entry namest="offset" nameend="5" align="center" rowsep="1"/></row><row><entry/><entry namest="offset" nameend="5" align="left" id="FOO-00005">MMSE: Mini-Mental State Examination; CDR: Clinical Dementia Rating; CN: CDR = 0 (Cognitively Normal); D1: CDR = 0.5; D2: CDR = 1; PAD: Predicted Age Difference,</entry></row><row><entry/><entry namest="offset" nameend="5" align="left" id="FOO-00006">&#x2020;The elapsed time here represents the inter-scan interval between [CN1]-to-CN2 and CN1-to-[CN2].</entry></row><row><entry/><entry namest="offset" nameend="5" align="left" id="FOO-00007">&#x2021;APOE e4 means the percentage in the group population that poses either one or two e4 alleles.</entry></row></tbody></tgroup></table></tables></p><p id="p-0255" num="0226">Performance of brain age prediction: The model performance tested in the [CN1]-to-CN2 group (testing data) gave MAE=4.35&#xb1;3.39 years and r=0.77 (p-value=3.64&#xd7;10<sup>&#x2212;10</sup>).</p><p id="p-0256" num="0227">Group comparison: <figref idref="DRAWINGS">FIG. <b>21</b></figref> shows the groups with different CDR levels, i.e., CN1-to-[CN2], [nD1], and [nD2]. The mean and standard deviation of PAD values of CN1-to-[CN2], [nD1], and [nD2] were &#x2212;0.75&#xb1;5.53, 5.48&#xb1;6.68, and 12.33&#xb1;10.89 years, respectively. All comparisons on the three pairs of groups showed statistically significant differences. The results indicated that the higher the CDR level, the higher the PAD values.</p><p id="p-0257" num="0228">ROC curve analysis: <figref idref="DRAWINGS">FIG. <b>22</b></figref> shows the results of the ROC curve analysis. Area under the curve (AUC) was 0.82. Table 4 lists the performance of differentiating between CDR=0 and CDR&#x3e;0 at different cutoff values of PAD. The best cutoff value of PAD was found to be 3 years. Using PAD=3 as the cutoff value, the performance of differentiating between CDR=0 and CDR&#x3e;0 showed sensitivity=0.79, specificity=0.74, PPV=0.79, NPV=0.74, OR=10.86, and accuracy=0.77.</p><p id="p-0258" num="0000"><tables id="TABLE-US-00004" num="00004"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 4</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>The performance of differentiating between CDR = 0 and</entry></row><row><entry>CDR &#x3e; 0 at different cutoff values of PAD.</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="12"><colspec colname="1" colwidth="28pt" align="center"/><colspec colname="2" colwidth="14pt" align="center"/><colspec colname="3" colwidth="21pt" align="center"/><colspec colname="4" colwidth="14pt" align="center"/><colspec colname="5" colwidth="21pt" align="center"/><colspec colname="6" colwidth="21pt" align="center"/><colspec colname="7" colwidth="28pt" align="center"/><colspec colname="8" colwidth="21pt" align="center"/><colspec colname="9" colwidth="28pt" align="center"/><colspec colname="10" colwidth="21pt" align="center"/><colspec colname="11" colwidth="21pt" align="center"/><colspec colname="12" colwidth="21pt" align="center"/><tbody valign="top"><row><entry>PAD</entry><entry>TP</entry><entry>FP</entry><entry>FN</entry><entry>TN</entry><entry>OR</entry><entry>ACC</entry><entry>PPV</entry><entry>NPV</entry><entry>Sens.</entry><entry>Spec.</entry><entry>AUC</entry></row><row><entry namest="1" nameend="12" align="center" rowsep="1"/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="12"><colspec colname="1" colwidth="28pt" align="char" char="."/><colspec colname="2" colwidth="14pt" align="char" char="."/><colspec colname="3" colwidth="21pt" align="char" char="."/><colspec colname="4" colwidth="14pt" align="char" char="."/><colspec colname="5" colwidth="21pt" align="char" char="."/><colspec colname="6" colwidth="21pt" align="char" char="."/><colspec colname="7" colwidth="28pt" align="char" char="."/><colspec colname="8" colwidth="21pt" align="char" char="."/><colspec colname="9" colwidth="28pt" align="char" char="."/><colspec colname="10" colwidth="21pt" align="char" char="."/><colspec colname="11" colwidth="21pt" align="char" char="."/><colspec colname="12" colwidth="21pt" align="char" char="."/><tbody valign="top"><row><entry>0</entry><entry>49</entry><entry>20</entry><entry>9</entry><entry>26</entry><entry>7.08</entry><entry>0.72</entry><entry>0.71</entry><entry>0.74</entry><entry>0.84</entry><entry>0.57</entry><entry>0.82</entry></row><row><entry>10</entry><entry>48</entry><entry>18</entry><entry>10</entry><entry>28</entry><entry>7.47</entry><entry>0.73</entry><entry>0.73</entry><entry>0.74</entry><entry>0.83</entry><entry>0.61</entry></row><row><entry>2</entry><entry>47</entry><entry>14</entry><entry>11</entry><entry>32</entry><entry>9.77</entry><entry>0.76</entry><entry>0.77</entry><entry>0.74</entry><entry>0.81</entry><entry>0.70</entry></row><row><entry>3</entry><entry>46</entry><entry>12</entry><entry>12</entry><entry>34</entry><entry>10.86</entry><entry>0.77</entry><entry>0.79</entry><entry>0.74</entry><entry>0.79</entry><entry>0.74</entry></row><row><entry>4</entry><entry>39</entry><entry>7</entry><entry>19</entry><entry>39</entry><entry>11.44</entry><entry>0.75</entry><entry>0.85</entry><entry>0.67</entry><entry>0.67</entry><entry>0.85</entry></row><row><entry>5</entry><entry>35</entry><entry>6</entry><entry>23</entry><entry>40</entry><entry>10.14</entry><entry>0.72</entry><entry>0.85</entry><entry>0.63</entry><entry>0.60</entry><entry>0.87</entry></row><row><entry>6</entry><entry>33</entry><entry>4</entry><entry>25</entry><entry>42</entry><entry>13.86</entry><entry>0.72</entry><entry>0.89</entry><entry>0.63</entry><entry>0.57</entry><entry>0.91</entry></row><row><entry>7</entry><entry>30</entry><entry>4</entry><entry>28</entry><entry>42</entry><entry>11.25</entry><entry>0.69</entry><entry>0.88</entry><entry>0.60</entry><entry>0.52</entry><entry>0.91</entry></row><row><entry>8</entry><entry>27</entry><entry>3</entry><entry>31</entry><entry>43</entry><entry>12.48</entry><entry>0.67</entry><entry>0.90</entry><entry>0.58</entry><entry>0.47</entry><entry>0.93</entry></row><row><entry>9</entry><entry>26</entry><entry>3</entry><entry>32</entry><entry>43</entry><entry>11.65</entry><entry>0.66</entry><entry>0.90</entry><entry>0.57</entry><entry>0.45</entry><entry>0.93</entry></row><row><entry>10</entry><entry>25</entry><entry>3</entry><entry>33</entry><entry>43</entry><entry>10.86</entry><entry>0.65</entry><entry>0.89</entry><entry>0.57</entry><entry>0.43</entry><entry>0.93</entry></row><row><entry namest="1" nameend="12" align="center" rowsep="1"/></row><row><entry namest="1" nameend="12" align="left" id="FOO-00008">Abbreviation: PAD = predicted age difference, TP = true positive, FP = false positive, FN = false negative, TN = true negative, OR = odds ratio, ACC = accuracy, PPV = positive predictive value, NPV = negative predictive value, Sens. = sensitivity, Spec. = specificity, AUC = area under the curve.</entry></row></tbody></tgroup></table></tables></p><heading id="h-0010" level="1">CONCLUSION</heading><p id="p-0259" num="0229">The current invention shows that the best cutoff value of PAD for differentiating between CDR=0 and CDR&#x3e;0 is 3 years, resulting in sensitivity=0.79, specificity=0.74, PPV=0.79, NPV=0.74, OR=10.86, and accuracy=0.77. However, the intended use is to rule out CDR=0 in patients who are suspected to have dementia. With this intended use, the performance of PPV, specificity and OR, rather than sensitivity and accuracy, become the end points of primary interest. In this case, PAD=6 years appears to be the best cutoff value, giving PPV=0.89, specificity=0.91, and OR=13.86. <figref idref="DRAWINGS">FIG. <b>23</b></figref> shows the confusion matrix of the results using the cutoff PAD of 6, and the distribution of the two populations (i.e. CDR=0 and CDR&#x3e;0) with respect to PAD. The results mean that for those whose PAD&#x3e;=6 years, 89% of them are not cognitively normal (i.e. CDR&#x3e;0), and for those who are cognitively normal (i.e. CDR=0), 91% of them have PAD&#x3c;6 years. The OR of 13.86, defined as (TP&#xd7;TN)/(FP&#xd7;FN), means the ratio of the true outcome (TP and TN) with respect to the false outcome (FP and FN) is more than 10 folds. On the other hand, using PAD=6 years as the cutoff value, sensitivity=0.57 and NPV=0.63. The results mean that for those who are not cognitively normal (i.e. CDR&#x3e;0), 57% of them have PAD&#x3e;=6 years, and for those who have PAD&#x3c;6 years, 63% are cognitively normal (i.e. CDR=0). In sum, using PAD=6 years as the cutoff value has satisfactory performance to identify patients who are very unlikely to be cognitively normal, but it performs poorly in identifying those who are cognitively normal. Therefore, we conclude that the satisfactory performance of PPV and OR supports the intended use of our proposed device.</p><p id="p-0260" num="0230">Importantly, it should be noted that the present invention is pioneering in the field of CDR estimation and prediction with respect to at least three aspects. First, the brain age model being built by the present invention is based on the white matter microstructural metrics, named dMRI-brain age and the resulting WM PAD. Second, what WM PAD does is to predict a person's concomitant measures of the CDR. Third, in addition, WM PAD also predicts the same person's CDR change 2 to 3 years from the time when dMRI-brain age is measured.</p><p id="p-0261" num="0231">In contrast to the present invention, the existing method for estimating the CDR either built the brain age model on the basis of morphometric features of gray matter obtained from T1M MRI, named GM brain age and the resulting GM PAD, and found associations between GM PAD and concomitant measures of the CDR (Beheshti et al., 2018); or calculated FW content from diffusion MRI and found that FW was associated with concomitant measures of the CDR and future status of the CDR (Maillard et al., 2019).</p><p id="p-0262" num="0232">Other researches and inventions in the field scrutinize the associations between MRI metrics and the whole array of cognitive performance measured by validated tools. In those results, it is reported that a particular MRI metric which is associated with a particular cognitive measure. However, the present invention establishes the unique correspondence between WM PAD and concomitant CDR, and the correspondence between WM PAD and CDR change 2 to 3 years later from the baseline. Such specific correspondence between dMRI-brain age and the CDR is not reported before and so it is not obvious to contemporary inventors.</p><p id="p-0263" num="0233">WM PAD has the advantages over prior solutions due to (1) better sensitivity to the CDR than GM brain age, and (2) less susceptibility to the cerebrospinal fluid (CSF) partial volume effect than the FW metric.</p><p id="p-0264" num="0234">First, WM PAD is more sensitive than GM brain age in distinguishing CDR scores. In the paper of Beheshti et al., they only showed the correlation between GM brain age and the CDR scores (from 0, 0.5 to 1). They did not show the results of comparison between brain age and the CDR, probably due to null results owing to marked overlaps between CDR scores (<figref idref="DRAWINGS">FIG. <b>7</b><i>b </i></figref>in Beheshti's paper).</p><p id="p-0265" num="0235">On the other hand, dMRI-brain age maybe less susceptible to the CSF partial volume effect induced by brain atrophy than is FW metric. Hypothetically, FW content is mainly attributed by the CSF partial volume effect in white matter neighboring the ventricles or cerebral sulci. The FW content would be likely to increase as the brain becomes atrophic with age. In other words, FW content is confounded by brain atrophy. By contrast, WM PAD is derived from FA and MD in the whole brain white matter. Although FA and MD values are likely to be altered in the white matter pixels adjacent to the ventricles and cerebral sulci, the effect is negligible because the number of pixels with the partial volume effect is substantially small as compared with the whole brain white matter pixels.</p><p id="p-0266" num="0236">The foregoing description of the exemplary embodiments of the invention has been presented only for the purposes of illustration and description and is not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations are possible in light of the above teaching.</p><p id="p-0267" num="0237">While there has been shown several and alternate embodiments of the present invention, it is to be understood that certain changes can be made as would be known to one skilled in the art without departing from the underlying scope of the invention as is discussed and set forth above and below including claims and drawings. Furthermore, the embodiments described above and claims set forth below are only intended to illustrate the principles of the present invention and are not intended to limit the scope of the invention to the disclosed elements.</p><p id="p-0268" num="0238">References cited in the instant application, which may include patents, patent applications and various publications, are cited and discussed in the description of this invention. The citation and/or discussion of such references is provided merely to clarify the description of the present invention and is not an admission that any such reference is &#x201c;prior art&#x201d; to the invention described herein. All references cited and discussed in the description of this invention, are incorporated herein by reference in their entireties and to the same extent as if each reference was individually incorporated by reference.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001 MATH-US-00001-2 MATH-US-00001-3" nb-file="US20230000424A1-20230105-M00001.NB"><img id="EMI-M00001" he="19.39mm" wi="76.20mm" file="US20230000424A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain, the method comprising:<claim-text>(1) scanning the individual's brain with a scanning device so as to acquire at least one medical brain image;</claim-text><claim-text>(2) processing the medical brain image to obtain at least one feature of the image;</claim-text><claim-text>(3) using a pre-established prediction model to determine a condition of the cognitive impairment and predict its future change based on the at least one feature obtained; and</claim-text><claim-text>(4) outputting the condition of cognitive impairment and its future change in an output terminal;</claim-text><claim-text>wherein the pre-established prediction model comprises at least a brain age model.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the at least one image is a brain MRI image.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. (canceled)</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the condition of the cognitive impairment is clinically assessed using the clinical dementia rating (CDR).</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein:<claim-text>the brain MRI image comprises at least a brain diffusion weighted MRI.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the step of processing of the medical brain image comprises at least one step of correcting the artifacts of the medical brain image.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the step of processing of the medical brain image further comprises at least one step of spatial normalization process.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein:<claim-text>the step of processing of the medical image further comprises at least one step of feature quantification process.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of quantitatively evaluating a cognitive impairment and its future change from a medical image of an individual's brain according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the pre-established prediction model comprises a first determination model for determining the condition of the cognitive impairment; and,</claim-text><claim-text>a second prediction model for predicting the future change of the condition of the cognitive impairment.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A method for evaluating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain, comprising:<claim-text>(1) scanning the individual's brain with a MRI scanning device so as to acquire MRI data of the individual's brain using T1-weighted (T1w) imaging and diffusion tensor imaging (DTI) sequences;</claim-text><claim-text>(2) processing the acquired T1w data so as to obtain white matter (WM) and grey matter (GM) image segments;</claim-text><claim-text>(3) registering the WM and GM image segments obtained in the step (2) to the MNI space to obtain the deformation map of the individual's brain;</claim-text><claim-text>(4) correcting artifacts of the DTI data;</claim-text><claim-text>(5) obtaining fractional anisotropy (FA) and mean diffusivity (MD) maps for the individual in native space based on the artifact corrected DTI data;</claim-text><claim-text>(6) extracting FA and MD values of WM region of the individual's brain using the FA and MD maps obtained in the step (5) and the deformation map obtained in the step (3);</claim-text><claim-text>(7) calculating the WM PAD by inputting the extracted FA and MD of WM to an established dMRI-brain age model;</claim-text><claim-text>(8) predicting the CDR and CDR change of the individual from the WM PAD using a CDR prediction model and a CDR change prediction model; and</claim-text><claim-text>(9) outputting the CDR and CDR change in an output terminal.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the step (2) comprises: (i) correction of SI inhomogeneity of T1w data;<claim-text>(ii) segment of tissue probability maps (TPM);</claim-text><claim-text>(iii) obtaining WM and GM segments;</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the step (2) further comprises:<claim-text>inverting T1w contrast to synthesize a pseudo b0 image.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the step (4) comprises:<claim-text>registering the DTI data to pseudo b0 image to correct the artifacts of DTI data.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the step (5) comprises:<claim-text>(i) estimating diffusion tensor at each image pixel of the artifact corrected DTI data;</claim-text><claim-text>(ii) calculating FA and MD at each pixel using a diffusion tensor indexes derived from the estimated diffusion tensor at each pixel;</claim-text><claim-text>(iii) generating the FA and MD maps in the native space using the FA and MD at each pixel.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein<claim-text><br/><?in-line-formulae description="In-line Formulae" end="lead"?>MD=(&#x3bb;1+&#x3bb;2+&#x3bb;3)/3;<?in-line-formulae description="In-line Formulae" end="tail"?></claim-text><claim-text><br/><?in-line-formulae description="In-line Formulae" end="lead"?>FA=[3(&#x394;&#x3bb;1<sup>2</sup>+&#x394;&#x3bb;2<sup>2</sup>+&#x394;&#x3bb;3<sup>2</sup>)/2(&#x3bb;1<sup>2</sup>+&#x3bb;2<sup>2</sup>+&#x3bb;3<sup>2</sup>)]<sup>1/2</sup>;<?in-line-formulae description="In-line Formulae" end="tail"?></claim-text><claim-text>wherein &#x3bb;<b>1</b>, &#x3bb;<b>2</b>, and &#x3bb;<b>3</b> are 1st, 2nd, and 3rd eigenvalues of the diffusion tensor, respectively.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the step (6) comprises:<claim-text>(i) registering the FA and MD maps to the MNI space using the deformation maps in the step (3); and</claim-text><claim-text>(ii) masking the registered FA and MD maps with WM segments</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:<claim-text>the dMRI-brain age model is built by regressing the chronological age of more than one individual against FA and MD values inside the WM region using a Gaussian process regression method.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:<claim-text>the individual's brain region consists of the white matter region.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method for estimating the clinical dementia rating (CDR) of an individual and CDR's future change from predicted age difference (PAD) based on MRI data of the individual's brain according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein:<claim-text>the CDR change is the CDR change of the individual in the next 2-3 years since the date of the MRI scanning.</claim-text></claim-text></claim><claim id="CLM-20-22" num="20-22"><claim-text><b>20</b>-<b>22</b>. (canceled)</claim-text></claim></claims></us-patent-application>
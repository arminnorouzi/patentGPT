<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005402A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005402</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17758940</doc-number><date>20200124</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>3208</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>72</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200801</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>035</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>3208</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>013</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>012</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>72</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2320</main-group><subgroup>0693</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2320</main-group><subgroup>0233</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2320</main-group><subgroup>0242</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2354</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2320</main-group><subgroup>0666</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">IMAGE COMPENSATION FOR FOLDABLE DEVICES</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>GOOGLE LLC</orgname><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Peng</last-name><first-name>Yenyu</first-name><address><city>New Taipei City</city><country>TW</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Chung</last-name><first-name>Yu-Ting</first-name><address><city>New Taipei City</city><country>TW</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/US2020/015012</doc-number><date>20200124</date></document-id><us-371c12-date><date>20220715</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Foldable displays may have portions folded into a folded configuration. Each folded portion may be observed by a user at a different viewing angle. As such, folding-artifacts may appear in the displayed image as a result of the different viewing angles. For example, a perceptible color difference and/or a perceptible brightness difference may appear between folded portions. Disclosed here are systems and methods to create compensated images that when displayed reduced the folding artifacts. The creation may include sensing a viewing angle for each portion and determining adjustments for pixels in each portion using a display model. The display model may be created by measuring color and brightness of pixels for various folded configurations, view-points and/or viewing angles.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="231.65mm" wi="158.75mm" file="US20230005402A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="85.94mm" wi="141.56mm" orientation="landscape" file="US20230005402A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="163.66mm" wi="134.37mm" orientation="landscape" file="US20230005402A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="122.17mm" wi="159.00mm" orientation="landscape" file="US20230005402A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="163.66mm" wi="119.55mm" orientation="landscape" file="US20230005402A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="127.76mm" wi="104.73mm" orientation="landscape" file="US20230005402A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="114.64mm" wi="154.35mm" orientation="landscape" file="US20230005402A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="106.68mm" wi="136.23mm" orientation="landscape" file="US20230005402A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="109.30mm" wi="144.27mm" orientation="landscape" file="US20230005402A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="100.92mm" wi="154.77mm" orientation="landscape" file="US20230005402A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="155.19mm" wi="133.77mm" orientation="landscape" file="US20230005402A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="174.84mm" wi="128.27mm" orientation="landscape" file="US20230005402A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="140.80mm" wi="116.16mm" orientation="landscape" file="US20230005402A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="168.06mm" wi="53.85mm" orientation="landscape" file="US20230005402A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="158.16mm" wi="146.73mm" orientation="landscape" file="US20230005402A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="129.20mm" wi="145.63mm" orientation="landscape" file="US20230005402A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD OF THE DISCLOSURE</heading><p id="p-0002" num="0001">The present disclosure relates to visual displays and, more specifically, to a mobile computing device having a flexible display that is configured to adjust signals sent to the flexible display when it is in a folded configuration in order to reduce visual artifacts caused by the folding.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">A visual display can be fabricated using flexible films (e.g., a flexible plastic substrate). The flexibility of the display may be used to allow electronic devices to be folded. For example, a mobile computing device, such as a mobile phone or a tablet computer utilizing a flexible display can be folded over a range of folding angles and into a variety of folded configurations. In a folded configuration, a user may view portions of the flexible display at different viewing angles. Because a visual performance of a display may depend on viewing angle, a user may perceive variations in a display image when the device is in a folded configuration.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">In at least one aspect, the present disclosure generally describes a computing device. The computing device includes a display that is capable of being configured into a folded configuration, in which portions of the display are at different viewing angles with a user. The computing device further includes a memory that is configured to store a display model that relates adjustments in brightness and color of pixels (i.e., pixel adjustments) to viewing angles. The computing device further includes at least one sensor that is configured to sense the user and the display. The computing device further includes a processor. The processor can be configured by software instructions to perform a method. The method includes receiving data from the at least one sensor. Based on the (received) data, the method includes determining the folded configuration of the display and determining viewing angles of the user relative to the portions of the display. The method also includes accessing the display model stored in the memory with the viewing angles for the portion of the display to adjust pixels of the display. The adjustment causes folding artifacts (i.e., as perceived by a user) in an image displayed in the folded configuration to be reduced for the user.</p><p id="p-0005" num="0004">The computing device may be a mobile computing device such as a mobile phone or a tablet computer. The display may be an organic light emitting diode (OLED) display. The folded configuration in which portions of the display are at different viewing angles with the user may include: a spine portion, a first-folded portion and a second-folded portion, the first-folded portion folded at a first-bending angle with the spine portion and the second-folded portion folded at a second-bending angle with the spine portion. The display model may be stored in a look-up table. The look-up table may include fold-compensation factors that relate adjustments in brightness and/or color of a pixel to viewing angles. Accessing the display model stored in the memory with the viewing angles for the portions of the display may include determining a fold-compensation factor for a pixel from the look-up table based on the viewing angle of the portion of the display including the pixel. The at least one sensor may include a camera configured to capture an image of the user. Data from the camera may include eye-tracking data corresponding to a sight-line of the user. The at least one sensor may include a first inertial measurement unit affixed to a first-folded portion of the display and a second inertial measurement unit affixed to a second-folded portion of the display. The determining, based on the data, that the display is in the folded configuration may include comparing data from the first inertial measurement unit and the second inertial measurement unit. The at least one sensor may include a Hall-effect sensor proximate with a magnet affixed to a spine portion of the display. The at least one sensor may include a radar having three receivers. Data from the radar may include head-tracking data corresponding a sight-line of the user. The accessing the display model stored in the memory with the viewing angles for the portions of the display to adjust pixels of the display so that folding-artifacts in an image displayed in the folded configuration are reduced may include adjusting digital levels of pixels in an image or a video. The display model may be created for the mobile computing device at a time before the mobile computing device is used by the user. The folding-artifacts may include a color difference or a brightness difference between the portions of the display that are at different viewing angles with the user.</p><p id="p-0006" num="0005">In another aspect, the present disclosure generally describes a method for reducing folding-artifacts in an image displayed on a display of a mobile computing device in a folded configuration. The method includes receiving data from at least one sensor (e.g., that senses a user and the display). Based on the (received) data, the method includes determining the folded configuration of the display and determining viewing angles of a user relative to portions of the display. The method also includes accessing a display model stored in a memory of the mobile computing device with the viewing angles for the portions of the display to adjust pixels (e.g., pixel brightness and/or pixel color) of the display so that folding artifacts in an image displayed in the folded configuration are reduced for the user.</p><p id="p-0007" num="0006">The method may further comprise creating a display model, wherein the creating includes: folding a portion of the display; capturing an image of the display from a view-point at a viewing angle with the portion of the display; determining, from the image, a brightness and a color of pixels in the portion of the display; updating the display model to relate the brightness and the color of the pixels in the portion of the display to the viewing angle; and repeating the folding, the capturing, the determining, and the updating for other folded configurations, from other view-points, and at other viewing angles to create the display model.</p><p id="p-0008" num="0007">In another aspect, the present disclosure generally describes a non-transitory computer readable medium containing computer-readable instructions that when executed by a processor of a mobile computing device cause the mobile computing device to perform a method for reducing folding-artifacts in an image displayed on a display of the mobile computing device in a folded configuration. The method includes receiving data from at least one sensor (e.g., that senses a user and the display). Based on the (received) data, the method includes determining a folded configuration of the display and determining viewing angles of a user relative to portions of the display. The method also includes accessing a display model stored in a memory of the mobile computing device with the viewing angles for the portions of the display to adjust pixels of the display (e.g., adjust each pixel's color and/or brightness) so that folding-artifacts in an image displayed in the folded configuration are reduced for the user.</p><p id="p-0009" num="0008">In another aspect, the present disclosure generally describes a system. The system includes a display device. The display device includes a display that is capable of being configured into a folded configuration, in which portions of the display are positioned at different viewing angles with respect to a user and at least one sensor that is configured to sense the user and the display. The system also includes a computing device. The computing device includes a memory that is configured to store a display model that relates adjustments in brightness and/or color of pixels to viewing angles and a processor that can be configured by software instructions to perform a method. The method includes receiving data from the at least one sensor and determining, based on the data, viewing angles of the user relative to the portions of the display. The method further includes accessing the display model stored in the memory with the viewing angles for the portions of the display to adjust pixels of the display so that folding-artifacts in an image displayed in the folded configuration are reduced for the user.</p><p id="p-0010" num="0009">In a possible implementation of the system, the display device and the computing device are physically separate. In other implementations the system may be a mobile device and the display and computing device may be parts of the mobile computing device.</p><p id="p-0011" num="0010">It will be appreciated that implementations can be combined. For example, features described in the context of a computing device above can also be implemented by way of a method and/or non-transitory computer readable medium.</p><p id="p-0012" num="0011">The foregoing illustrative summary, as well as other exemplary objectives and/or advantages of the disclosure, and the manner in which the same are accomplished, are further explained within the following detailed description and its accompanying drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> graphically illustrates a display in an unfolded configuration observed by a user according to an implementation of the present disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> is a display of a mobile computing device according to an implementation of the present disclosure configured according to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> showing no folding-artifacts.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> graphically illustrates a display in a possible folded configuration observed by a user according to an implementation of the present disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> is a display of a mobile computing device according to an implementation of the present disclosure configured according to <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> showing a folding-artifact.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> graphically illustrates a display in a possible folded configuration observed by a user according to an implementation of the present disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> is a display of a mobile computing device according to an implementation of the present disclosure configured according to <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> showing a folding-artifact.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>4</b></figref> graphically illustrates a display in a folded configuration observed by a user at a viewing angle according to an implementation of the present disclosure.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>5</b></figref> graphically illustrates test setup for creating a display model according to an implementation of the present disclosure</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow chart of a method for creating/updating a display model according to a possible implementation of the present disclosure.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a block diagram of a mobile computing device according to a possible implementation of the present disclosure.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a block diagram of a system including a mobile computing device that is physically separate from a display device according to a possible implementation of the present disclosure.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a side-view of a mobile computing device with a possible implementation of a folded-configuration sensor shown.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a side-view of a mobile computing device with a possible implementation of a folded-configuration sensor shown.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a possible implementation of a user sensor according to a possible implementation of the present disclosure.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flow chart of a method for reducing folding-artifacts in an image displayed on a display of a mobile computing device in a folded configuration according to a possible implementation of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0028" num="0027">The components in the drawings are not necessarily to scale relative to each other. Like reference symbols in the various drawings indicate like elements.</p><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0029" num="0028">A mobile computing device (e.g., a mobile phone, tablet computer, etc.) having flexible display (i.e., display) may be positioned in a folded configuration in which a user may view portions of the display at different viewing angles. The viewing-angle variation may lead to folding-artifacts in an image displayed on the folded display. The folding-artifacts may include a variation in a perceived color between portions of the display. For example, white pixels in a portion of the display directly facing a user (i.e., normal to the user) may appear as a different shade of white than white pixels in a portion of the display folded at an angle with the user. The folding-artifacts may also include a variation in a perceived brightness between portions of the display. For example, pixels in a portion of the display normal to the user may appear brighter than pixels in a portion of the display folded at an angle with the user even though the pixels are intended to be at the same brightness level. The uneven (i.e., inhomogeneous) color and/or brightness may be annoying or unacceptable to a user, especially when the user is expecting the visual performance of a flat display. The present disclosure describes systems and methods to minimize folding-artifacts (e.g., inhomogeneous color or brightness) associated with a foldable device (e.g., tablet, mobile phone or other display) having a flexible display (e.g., an organic light emitting diode (OLED) display).</p><p id="p-0030" num="0029">To minimize folding-artifacts for a mobile computing device having a flexible display (i.e., foldable display), a display model can be generated from measurements at a time prior to use by a user (e.g., factory set) and stored in the memory of the mobile computing device. The display model may be based on tests (i.e., measurements) of folding-artifacts at various viewing angles with respect to portions of the display folded at various folding angles. The results of the tests may be expressed in the model as fold-compensation factors. In use, the stored model can be accessed using a folding angle of the device and/or a viewing angle of a user, to obtain fold-compensation factors. The fold-compensation factors may be used to adjust signals sent to the display (e.g., pixel-level signal) so that portions (e.g., all portions) of the display appear, to a user viewing the portions at various viewing angels, as the same brightness and/or as the same color (e.g., shade of a color). In what follows, these general aspects of the disclosure are described in greater detail.</p><p id="p-0031" num="0030">As mentioned, the flexible display may be an OLED display. Pixels of the OLED display include individually driven (i.e., switched and biased) light emitting diodes. In a color display, a pixel may include a combination of red, blue, and green LEDs. The LEDs may be designed and arranged to have an optimal viewing angle (i.e., optimal viewing direction) that is normal to the surface of the display. The brightness (i.e., luminous intensity) of the LEDs may be maximum when viewed at the optimal viewing angle and may decrease as the viewing angle deviates from the optimal viewing angle. Because pixel color is related to a carefully calibrated intensity combination of red, green, and blue light, and because perceived brightness as a function of viewing angle may be different for different color LEDs, the color of a pixel may appear to shift as the viewing angle alters the perceived relative intensity of the red, blue, and green light.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> graphically illustrates a top-view of a display <b>101</b> (e.g., OLED display) in an unfolded (i.e., flat) configuration observed by a user <b>110</b> from a position located along a sight-line <b>111</b> that is orthogonal (i.e., normal) to a front surface of the display <b>101</b>. For this example, the normal direction is considered the optimal viewing angle; however, a display could be optimized for a different optimal viewing angle. In this configuration, the user <b>110</b> primarily receives light <b>115</b> from the display in a direction aligned with the sight-line <b>111</b> (i.e., line-of-sight, viewing angle, viewing direction) of the user. In other words, while the display may emit light in a variety of directions, the user will receive most light in a direction aligned with the sight-line <b>111</b> of the user. For this reason, the light <b>115</b> shown in the <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is aligned with the sight-line <b>111</b> of the user <b>110</b>.</p><p id="p-0033" num="0032">In the configuration shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, the light <b>115</b> primarily received by the user is aligned with the optimal viewing angle (i.e., optimal viewing direction) of the display. In other words, the light primarily received by the user will be light in a direction aligned with the optimal-viewing direction <b>120</b> of the display, which as described previously may (for some implementations) be normal to the display's front surface. Additionally, in the flat configuration, the light <b>115</b> primarily received by the user has the same directional relationship with the optimal-viewing direction <b>120</b> for all portions of the display.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> is a front-view of a display of a mobile computing device <b>200</b> in the unfolded (i.e., flat) configuration of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>. As shown <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, an image presented on the display of a mobile computing device in a flat configuration can appear to a user (i.e., can be perceived by a user) as substantially homogeneous in color and brightness (i.e., no folding-artifacts). For example, as shown in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, the user's perception of background pixels of a displayed image in a first area <b>125</b>A of the display, which are programmed to be &#x201c;white,&#x201d; can have a perceived brightness and color that is substantially similar (e.g., within 1%) as the perceived brightness and color of background pixels in a second area <b>125</b>B of the display, which are programmed to be displayed as &#x201c;white.&#x201d;</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> graphically illustrates a top-view of the display <b>101</b> in a folded (i.e., bent) configuration observed by a user <b>110</b>. In this configuration, the display <b>101</b> may be described as having three portions. A first-folded portion <b>101</b>A is folded by a first bending angle <b>102</b>A towards the user, and a second-folded portion <b>101</b>B is folded by a second bending angle <b>102</b>B towards the user <b>110</b>. As shown, the first-folded portion <b>101</b>A and the second-folded portion <b>101</b>B are at equal bending angles with a third-folded portion (i.e., the spine portion <b>101</b>C). The third portion may be referred to as a spine portion <b>101</b>C of the display. The spine portion <b>101</b>C does not fold as the folded portions <b>101</b>A and <b>101</b>B. It is not necessary for the first-folded portion <b>101</b>A and the second-folded portion <b>101</b>B to be at equal angles with the spine portion <b>101</b>C, and in possible fold configurations these angles are different.</p><p id="p-0036" num="0035">The optimal viewing directions of the display <b>101</b> are different in the first-folded portion <b>101</b>A, the second-folded portion <b>101</b>B, and the spine portion <b>101</b>C. The sight-line <b>111</b> of the user is aligned with the optimal viewing direction for the spine portion <b>101</b>C of the display <b>101</b> but is not aligned with the optimal viewing direction for the first-folded portion <b>101</b>A or the second-folded portion <b>101</b>B. For example, the optimal-viewing direction <b>120</b> for the second-folded portion <b>101</b>B of the display is at an angle with the sight-line <b>111</b> of the user <b>110</b>. The light <b>115</b> primarily received by the user <b>110</b> from the second-folded portion <b>101</b>B of the display is at an angle with the optimal-viewing direction <b>120</b> of the second-folded portion <b>101</b>B of the display <b>101</b>. This angle is referred to as the viewing angle and is a function of both the user's sight-line and the bending angle of the portion of the display.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> is a front-view of a display of a mobile computing device <b>200</b> in the folded configuration of <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>. The image presented on the display has noticeable folding-artifacts because light from pixels in different areas of the display is not viewed as homogeneous in color and brightness. For example, as shown in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, white background pixels in the first area <b>125</b>A of the display (i.e., the first-folded portion <b>101</b>A of the display) appear to have a brightness and color that are different from white background pixels in a in a third area <b>125</b>C of the display (i.e., the spine portion <b>101</b>C of the display). For example, the white background pixels in the third area <b>125</b>C of the display appear brighter and whiter than pixels in either the first area <b>125</b>A or the second area <b>125</b>B because the viewing angle of the spine portion of the display is aligned with the optimal viewing angle of the pixels.</p><p id="p-0038" num="0037">White background pixels in the first area <b>125</b>A of the display (i.e., the first-folded portion <b>101</b>A of the display) may appear to have a brightness and color that are substantially similar to white background pixels in the second area <b>125</b>B of the display (i.e., the second-folded portion <b>101</b>B). This apparent similarity is due, at least in part, to substantially equal (but opposite) viewing angles for the first-folded portion <b>101</b>A and the second-folded portion <b>101</b>B.</p><p id="p-0039" num="0038">As mentioned, in possible folding configurations, the bending angles <b>102</b>A, <b>102</b>B can be different. For example, a bending angle of the first-folded portion <b>101</b>A may be approximately zero (e.g., equal to zero) so that it and the spine portion <b>101</b>C define a flat surface. The flat surface defined by the first-folded portion <b>101</b>A and the spine portion <b>101</b>C may be used as a keyboard, while the second-folded portion <b>101</b>B may be used as a display, such as in the folding configuration shown in <figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref>.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> graphically illustrates a side-view of a display <b>101</b> in another possible folded configuration in which the mobile computing device is arranged in a configuration similar to a laptop configuration. As such, a screen portion <b>310</b> of the display may be adjusted so that light <b>115</b> from this portion can be received by the user primarily along a direction aligned with the sight-line <b>111</b> of the user, which is also aligned with the optimal-viewing direction <b>120</b>B of this portion of the display. A keyboard portion <b>320</b> of the display may be aligned with a resting surface. Light <b>115</b> from the portion of the display operating as the keyboard can received by the user primarily along a direction aligned with the sight-line <b>111</b> of the user, which is not aligned with the optimal-viewing direction <b>120</b>A of this portion of the display.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>3</b>B</figref> is a front-view of a display of a mobile computing device <b>200</b> in the laptop-like configuration of <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>. The image presented on the display of a mobile computing device <b>200</b> in this configuration is inhomogeneous in color and brightness (i.e., has folding-artifacts). The screen portion <b>310</b> of the folded display may appear much brighter than the keyboard portion <b>320</b> of the display because the sight-line <b>111</b> of the user is aligned with the optimal viewing direction of the screen portion <b>310</b> but is not aligned with the optimal viewing direction of the keyboard portion <b>320</b>. This inhomogeneity may not be acceptable to some users.</p><p id="p-0042" num="0041">To make the color and/or brightness of the display appear more uniform (i.e., to minimize folding-artifacts), pixels in a first portion (i.e., a first area) of the folded display may be driven with signals that are adjusted so that, where appropriate, the color and/or brightness of the pixels in the first portion approximately match (e.g., within 1%) the color and/or brightness of pixels in a second portion of the display. For example, in the folded configuration of <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> pixels in the screen portion <b>310</b> of the display may be reduced in brightness to match pixels is the keyboard portion <b>320</b> of the display. Alternatively, pixels in the keyboard portion <b>320</b> of the display may be increased in brightness to match pixels is the screen portion <b>310</b> of the display. Further, intensities of any combination of red, green, and blue (i.e., RGB) subpixels of pixels in the screen portion <b>310</b> may be adjusted to match a perceived color of pixels of the keyboard portion <b>320</b> of the display (or vice versa).</p><p id="p-0043" num="0042">The adjustment to the signals provided to pixels in portions of a display in a folded configuration may be implemented as fold-compensation factors that when applied (e.g., multiplied, divided, added, subtracted, etc.) to an amplitude of a driving signal for a pixel can adjust an intensity of the pixel (or any combination of the pixel's RGB subpixels). Alternatively, the fold-compensation factors can be applied to digital pixel levels of an image or video to adjust an intensity of the pixel (or any combination of the pixel's RGB subpixels). In other words, a fold-compensation factor can correspond an adjustment in a color and/or a brightness of a pixel necessary to minimize a fold-artifact, and this adjustment may be applied in (at least) an image domain or a driving-signal domain.</p><p id="p-0044" num="0043">The amount of adjustment necessary to minimize (e.g., eliminate) folding-artifacts may be related to a folded configuration of the device and a sight-line of a user, which together can define a viewing angle for portions of the display. This relationship can be characterized as a display model. For example, a display model may be implemented as a look-up table. The look-up table may relate fold-compensation factors to possible viewing angles. In this case, accessing the display model may include relating (e.g., matching, interpolating) a viewing angle for a pixel in a folded portion of the display to a viewing angle of the folded portion. Alternatively, the display model may be implemented as a neural network. In this case, accessing the model may include inputting a pixel level and a viewing angle into the neural network to compute an adjusted pixel level.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a top-view of a user and a mobile computing device in a folded configuration. The mobile computing device may have a plurality of portions than can be folded relative to one another. A user may observe the display from a view-point that is not aligned with any particular portion. Accordingly, determining a viewing angle for a particular portion may include determining a bending angle for each portion. Alternatively, when the first-folded portion <b>101</b>A and the second-folded portion <b>101</b>B have the same bending angle, a folding angle <b>420</b> for the mobile computing device may be determined. The folding angle <b>420</b> and a dimension <b>410</b> of the spine portion <b>101</b>C may be sufficient to determine the arrangement and orientations of the portions of the display. Due to fabrication tolerances the dimension <b>410</b> of the spine portion <b>101</b>C may vary (e.g., within 10%).</p><p id="p-0046" num="0045">Determining a viewing angle for a particular portion may also include determining a view-point <b>440</b> and/or a sight-line <b>111</b> of the user <b>110</b>. The view-point <b>440</b> may be a position relative to a coordinate system centered on the display, while a sight-line may be a direction or angle from the view-point to the display (or vice versa). For example, a viewing angle <b>430</b> for the spine portion <b>101</b>C of the display is shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Based on the folding angle <b>420</b> and the view-point <b>440</b>, the viewing angle for the first-folded portion <b>101</b>A is smaller than the viewing angle <b>430</b> for the spine portion <b>101</b>C (i.e., is zero as shown), while the viewing angle for the second-folded portion <b>101</b>B is larger than the viewing angle <b>430</b> for the spine portion <b>101</b>C. For a folded configuration portions of the display are at different viewing angles with a view-point (e.g., a view-point of a user).</p><p id="p-0047" num="0046">As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, for a display having a first-folded portion <b>101</b>A, a second-folded portion <b>101</b>B, and a spine portion <b>101</b>C, the dimension <b>410</b> of the spine portion <b>101</b>C, can be used in assigning the pixels of the display to a particular portion. The pixels within each portion of the display can be assumed to have the same viewing angle. Accordingly, an adjustment to compensate for folding-artifacts may be applied to each pixel in the portion. The adjustment can require a determination of the viewing angle of the portion.</p><p id="p-0048" num="0047">Adjusting pixels in portions of a folded display so that all pixels appear to have the same color and/or brightness may require a model of a relationship between a pixel's color/brightness and viewing angle. Accordingly, a display model maybe created to specify this relationship. Using the display model adjustments for pixels in each portion may be derived. For example, the display model may return a color/brightness of a pixel viewed at a viewing angle. From the returned color/brightness, an adjustment may be determined. Alternatively, the display model may return color/brightness adjustments necessary for pixels in a portion to appear as pixels in another portion (e.g., a portion viewed along an optimal viewing direction).</p><p id="p-0049" num="0048">A display model may be created at a time before use by a user. For example, creating the display model may be part of a calibration or factory-setting that occurs as part of a fabrication/test process. Once created, the display model may be stored in a memory that is accessible to the mobile computing device. For example, the display model may be stored locally in memory of the mobile computing device. The display model can be accessed whenever the display is folded so that adjusted-images (i.e., compensated-images), in which the folding-artifacts are reduced (i.e., from a viewer's perspective), can be displayed (e.g., in real-time). The reduction of folding-artifacts in compensated-images may be a reduction as compared to unadjusted images, and in some cases, the folding-artifacts in compensated-images displayed may be eliminated.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a top-view of a possible test-setup (i.e., calibration setup) for creating a display model. In the test-setup <b>500</b>, a foldable display is positioned within a field-of-view <b>560</b> of a camera <b>510</b> (e.g., a CCD camera) so that a measurement-image of the portions of the display can be captured from a particular viewpoint and at a particular viewing angle. The measurement-image can be analyzed to determine the dimensions (i.e., the pixels within) the first-folded portion <b>101</b>A, the second-folded portion <b>101</b>B, and the spine portion <b>101</b>C of the display. The measurement-image can also be analyzed to determine (i.e., measure) a brightness and a color of the imaged pixels. The measurement-image may have a resolution that is higher than the pixel resolution of the display so the measurement of the color/brightness of the pixels may be averaged over pixels in the measurement-image. Additionally, one or more test-images may be displayed on the display to help in the determination of the brightness and color of pixels. The viewing angle of each portion of the display may be determined by the arrangement of the test-setup. For example, sensors may determine the position and orientation of the camera as well as the folded configuration of the display. The relationships between viewing angle, portions, brightness, and color may be recorded as part of a display model. This process may be repeated to update the display mode for other folded configuration, from other view-points and at other viewing angles.</p><p id="p-0051" num="0050">In the test setup, the display is configured into a folded configuration. For the implementation shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the folded configuration is characterized by the first-folded portion <b>101</b>A arranged at a first-bending angle <b>540</b> (with the spine portion <b>101</b>C) and the second-folded portion <b>101</b>B arranged at a second-bending angle <b>550</b>. The camera <b>510</b> has field-of-view <b>560</b> to capture at least all portions of the display. Between iterations of the display-model creation process, the camera <b>510</b> may be moved in any direction to adjust the camera's view-point, such as along a direction <b>530</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. The camera may also be rotated, such as along a rotation <b>520</b>, to adjust the viewing angle of the camera relative to the portions of the display. Alternatively, the display may be moved/rotated relative to the camera.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow chart of a method for creating/updating a display model according to a possible implementation of the present disclosure. In the method <b>600</b>, the display is adjusted <b>610</b> into a folded configuration in which at least one portion of the display is folded at an angle with another portion or other portions of the display. Next, an image (i.e., measurement-image) of the display, displaying a test-image, is captured <b>620</b> using a camera located at a view-point and aligned at a viewing angle or viewing angles with the portions of the display. The measurement-image is then analyzed <b>630</b> to determine pixel brightness and/or pixel color for pixels in the portions of the display. The analysis may include analyzing a gamma curve corresponding to the measurement image to determine a pixel's brightness. Additionally, the analysis may include mapping a pixel to a CIE map to determine the pixel's color. Based on the determine of the color and the brightness, a portion of the display model may be created. The method may then be repeated <b>645</b> (i.e. iterated) to update <b>640</b> the display model to include and/or accommodate other folded configurations (i.e., additional folded configurations), view-points, and/or viewing angles. The display model <b>650</b> that results may be stored in a memory, such as the memory of a mobile computing device having the foldable display.</p><p id="p-0053" num="0052">After the display model is created and stored, it may be accessed (e.g., automatically), when the device is in a folded configuration, to adjust a displayed image (or images) to compensate for perceived artifacts (e.g., variation in brightness and/or color) in portions of the display based on their viewing angle between a user and the portions of the display. As part of this process, the folded configuration of the mobile computing device and a sight-line of a user can be characterized by at least one sensor of the mobile computing device.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a block diagram of a mobile computing device according to a possible implementation of the present disclosure. The mobile computing device <b>700</b> includes a display capable of being configured into a folded configuration (i.e., a foldable display <b>770</b>), in which portions of the display are at different viewing angles with a user (or other viewer of the display). The mobile computing device includes a memory <b>720</b>. The memory <b>720</b> can be a non-transitory computer readable medium. The non-transitory computer readable medium can contain computer-readable instructions that can be executed by a processor <b>710</b> (e.g., a central processing unit (CPU)) of the mobile computing device to carry out the processes necessary for reducing folding-artifacts in an image (or images) display on the foldable display <b>770</b>. Additionally, the memory <b>720</b> may store the display model <b>650</b>, as described previously. The mobile computing device <b>700</b> further includes at least one sensor for collecting data that can be used to determine a viewing angle between, which can be used to access the display model <b>650</b> to determine the adjustment necessary for images displayed on the foldable display <b>770</b>.</p><p id="p-0055" num="0054">The at least one sensor can include a folded-configuration sensor <b>730</b>. The folded-configuration sensor <b>730</b> may be configured to collect data related to the folded configuration of the mobile computing device, such as a bending angle (e.g., the first-bending angle <b>540</b>) of a portion of the device or a folding angle <b>420</b> of the mobile computing device.</p><p id="p-0056" num="0055">While <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> illustrates a possible implementation in which the processor and the foldable display are integrated together (e.g., physically combined as parts of a single device), various other possible implementations are within the scope of the present disclosure. For example, <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a block diagram of a system that includes a mobile computing device <b>701</b> and a display device <b>702</b>. The processor <b>710</b> of the mobile computing device <b>701</b> may be communicatively coupled to the sensor(s) (e.g., the folded-configuration sensor <b>730</b>, the user sensor <b>750</b>) of the display device <b>702</b> and may also be communicatively coupled to the foldable display <b>770</b> of the display device <b>702</b>. The mobile computing device <b>701</b> and the display device <b>702</b> may be implemented as physically separate devices. In other words, the mobile computing device <b>701</b> and the display device <b>702</b> may be communicatively coupled (e.g., wired or wirelessly) over a physical spacing between the devices. Aside from this physical spacing, the implementations shown in <figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> may operate similarly.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a side-view of a possible implementation of a folded-configuration sensor <b>730</b>. As shown, the folded-configuration sensor <b>730</b> includes a first inertial measurement unit (IMU) <b>801</b>A and a second IMU <b>801</b>B. The IMUs may be affixed to, or otherwise integrated with, the first-folded portion and the second-folded portion of the mobile computing device <b>800</b>. The first IMU <b>801</b>A can be configured to output a first tilt angle <b>830</b>A between a first sensitivity axis <b>810</b>A a direction of gravity <b>820</b>. The second IMU <b>801</b>B can be configured to output a second tilt angle <b>830</b>B between a second sensitivity axis <b>810</b>B the direction of gravity <b>820</b>. The outputs of each IMU may provide information regarding a folded position of each portion of the mobile computing device. Further, the outputs of the two IMUs may be compared to obtain a folding angle <b>840</b> of the mobile computing device <b>800</b>.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates another possible implementation of a folded-configuration sensor <b>730</b>. As shown, the folded-configuration sensor <b>730</b> includes a Hall-effect sensor <b>910</b> and a magnet <b>920</b>. For example, the Hall-effect sensor may be proximate with a magnet affixed to a spine portion of the display. The Hall-effect sensor <b>910</b> is configured to output a signal (e.g., voltage) as based on a magnetic field strength. The magnet <b>920</b> can be configured to rotate according as a folded configuration of the mobile computing device <b>900</b> changes. Accordingly, the output of the Hall-effect sensor can be used to determine a folding angle of the mobile computing device <b>900</b>.</p><p id="p-0059" num="0058">Returning to <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, the at least one sensor may also include a user sensor <b>750</b> configured to collect data that can facilitate a determination a view-point <b>440</b> and/or a sight-line <b>111</b> of a user <b>110</b>. For example, the user sensor <b>750</b> may include one or more cameras to image a user. The processor <b>710</b> may be configured to perform image processing on the captured images of the user in order to determine a position/orientation of the user's head and/or body. Additionally, face-tracking data, eye-tracking data, and/or head-tracking data may be obtained from image processing the captured images of the user in order to determine a position on the display that the user is focused on (i.e., viewing).</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates another possible implementation of a user sensor <b>750</b>. As shown the user sensor <b>750</b> includes a radar having a transmitter and three receivers. The three receivers a positioned differently so that an amplitude received by each receiver can be used to determine a three-dimensional position of an object (e.g., a user's head, a user's eye). More specifically a first receiver is positioned at a first relative location (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>), a second receiver is position at a second relative location (x<sub>2</sub>, y<sub>2</sub>, z<sub>2</sub>) and the third receiver is positioned at a third relative location (x<sub>3</sub>, y<sub>3</sub>, z<sub>3</sub>). The amplitude of the received radar signal at the first receiver corresponds to a first range (R<sub>1</sub>), the amplitude of the received radar signal at the second receiver corresponds to a second range (R<sub>2</sub>), and the amplitude of the received radar signal at the third receiver corresponds to a third range (R<sub>3</sub>). Based on the relative locations and the ranges it is possible to calculate a relative position (x<sub>0</sub>, y<sub>0</sub>, z<sub>0</sub>) of the object (e.g., the user's eye) reflecting the radar signal back to the receivers. It is further possible that a user sensor includes data from a plurality of sensors (e.g., camera, radar, etc.) to determine a position/configuration of the user/device.</p><p id="p-0061" num="0060">While some sensors, operating individually, have been presented, it is anticipated that a variety of sensor types and combinations thereof may be used as the at least one sensor configuration for the purpose of determining the viewing angle with portions of a folded display.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flow chart of a method for reducing folding-artifacts in an image displayed on a display of a mobile computing device in a folded configuration according to a possible implementation of the present disclosure. The method includes receiving <b>1110</b> data from at least one sensor. In a possible implementation of the method, data from the at least one sensor can be used to determine <b>1120</b> that the display is in a folded configuration. This may have an advantage of computational efficiency because in a flat (i.e., unfolded) configuration, compensated images may not be necessary. The method <b>1100</b> further includes determining <b>1130</b>, based on the data from the sensor(s), viewing angles for portions of the display. In some implementations, this operation may further include determining the portions (e.g., boundaries of the portions) of the display so a pixel's adjustment may be applied based on the portion that it is within. The method further includes accessing a display model <b>650</b> with the determined viewing angles for each portion of the display to adjust a displayed image. For example, the method may include obtaining <b>1140</b> an adjustment (e.g., a fold-compensation factor) from the display model <b>650</b> for each portion of the display and adjusting 1150 pixels in each portion of an image according to the portion's adjustment. The adjustment to the image may result a compensated image <b>1160</b> in which digital levels of pixels are adjusted by pixel adjustments corresponding to their viewing angle. In other words, pixel adjustments are changes in digital levels pixels to allow the pixels to be perceived as having a similar (e.g., same) color/brightness. When the compensated image is displayed on the folded display, a user may perceive a displayed image in which a color difference or a brightness difference between portions of the display are reduced. A compensated video may be created as a collection of images.</p><p id="p-0063" num="0062">In the specification and/or figures, typical embodiments have been disclosed. The present disclosure is not limited to such exemplary embodiments. The use of the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items. The figures are schematic representations and so are not necessarily drawn to scale. Unless otherwise noted, specific terms have been used in a generic and descriptive sense and not for purposes of limitation.</p><p id="p-0064" num="0063">Unless defined otherwise, all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art. Methods and materials similar or equivalent to those described herein can be used in the practice or testing of the present disclosure. As used in the specification, and in the appended claims, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; &#x201c;the&#x201d; include plural referents unless the context clearly dictates otherwise. The term &#x201c;comprising&#x201d; and variations thereof as used herein is used synonymously with the term &#x201c;including&#x201d; and variations thereof and are open, non-limiting terms. The terms &#x201c;optional&#x201d; or &#x201c;optionally&#x201d; used herein mean that the subsequently described feature, event or circumstance may or may not occur, and that the description includes instances where said feature, event or circumstance occurs and instances where it does not. Ranges may be expressed herein as from &#x201c;about&#x201d; one particular value, and/or to &#x201c;about&#x201d; another particular value. When such a range is expressed, an aspect includes from the one particular value and/or to the other particular value. Similarly, when values are expressed as approximations, by use of the antecedent &#x201c;about,&#x201d; it will be understood that the particular value forms another aspect. It will be further understood that the endpoints of each of the ranges are significant both in relation to the other endpoint, and independently of the other endpoint.</p><p id="p-0065" num="0064">While certain features of the described implementations have been illustrated as described herein, many modifications, substitutions, changes and equivalents will now occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the scope of the implementations. It should be understood that they have been presented by way of example only, not limitation, and various changes in form and details may be made. Any portion of the apparatus and/or methods described herein may be combined in any combination, except mutually exclusive combinations. The implementations described herein can include various combinations and/or sub-combinations of the functions, components and/or features of the different implementations described.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for reducing folding-artifacts in an image displayed on a display of a computing device in a folded configuration, the method comprising:<claim-text>receiving data from at least one sensor;</claim-text><claim-text>determining, based on the data, that the display is in a folded configuration;</claim-text><claim-text>determining, based on the data, viewing angles of a user relative to portions of the display; and</claim-text><claim-text>accessing a display model that relates adjustments in a brightness and/or a color of pixels to viewing angles to adjust pixels of the display for the folded configuration using the viewing angles for the portions of the display, wherein the display model is generated from measurements that include:<claim-text>folding a portion of the display;</claim-text><claim-text>capturing an image of the display from a view-point at a viewing angle with the portion of the display;</claim-text><claim-text>determining, from the image, a brightness and/or a color of pixels in the portion of the display;</claim-text><claim-text>creating a portion of the display model to relate the brightness and/or the color of the pixels in the portion of the display to the viewing angle; and</claim-text><claim-text>repeating the folding, the capturing, the determining, and the creating for other folded configurations, from other view-points, and at other viewing angles to create the display model.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. (canceled)</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the portions include a spine portion, a first-folded portion and a second-folded portion, wherein the folded configuration in which portions of the display are at different viewing angles with the user includes:<claim-text>the first-folded portion folded at a first-bending angle with the spine portion and the second-folded portion folded at a second-bending angle with the spine portion.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the display model is stored in a look-up table.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the look-up table includes fold-compensation factors that relate adjustments in the brightness and/or the color of a pixel to viewing angles.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein accessing the display model includes:<claim-text>determining a fold-compensation factor for a pixel from the look-up table based on the viewing angle of the portion of the display including the pixel.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sensor includes a camera configured to capture an image of the user.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein data from the camera includes eye-tracking data corresponding to a sight-line of the user.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sensor includes a first inertial measurement unit affixed to a first-folded portion of the display and a second inertial measurement unit affixed to a second-folded portion of the display.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the determining, based on the data, the folded configuration of the display includes:<claim-text>comparing data from the first inertial measurement unit and the second inertial measurement unit.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sensor includes a Hall-effect sensor proximate with a magnet affixed to a spine portion of the display.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sensor includes a radar having three receivers.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein data from the radar includes head-tracking data corresponding a sight-line of the user.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein accessing the display model that relates adjustments in the brightness and/or the color of pixels to viewing angles to adjust pixels of the display form the determined folded configuration includes:<claim-text>adjusting digital levels of pixels in an image or a video.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the display model is created for at a time before the computing device is used by the user.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the folding-artifacts include a color difference or a brightness difference between the portions of the display that are at different viewing angles with the user.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the computing device is a mobile phone or a tablet computer.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the display is an organic light emitting diode (OLED) display.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A non-transitory computer readable medium containing computer-readable instructions that when executed by a processor of a mobile computing device cause the mobile computing device to perform a method that includes:<claim-text>receiving data from at least one sensor;</claim-text><claim-text>determining, based on the data, that a display is in a folded configuration;</claim-text><claim-text>determining, based on the data, viewing angles of a user relative to portions of the display; and</claim-text><claim-text>accessing a display model that relates adjustments in brightness and/or color of pixels to viewing angles to adjust pixels of the display for the folded configuration using the viewing angles for the portions of the display, wherein the display model is generated from measurements that include:<claim-text>folding a portion of the display;</claim-text><claim-text>capturing an image of the display from a view-point at a viewing angle with the portion of the display;</claim-text><claim-text>determining, from the image, a brightness and/or a color of pixels in the portion of the display;</claim-text><claim-text>creating a portion of the display model to relate the brightness and/or the color of the pixels in the portion of the display to the viewing angle; and</claim-text><claim-text>repeating the folding, the capturing, the determining, and the creating for other folded configurations, from other view-points, and at other viewing angles to create the display model.</claim-text></claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A system comprising:<claim-text>a display device including:<claim-text>a display capable of being configured into a folded configuration, in which portions of the display are positioned at different viewing angles with respect to a user; and</claim-text><claim-text>at least one sensor configured to sense the user and the display; and</claim-text></claim-text><claim-text>a computing device including:<claim-text>a memory; and</claim-text><claim-text>a processor configured by software instructions to perform a method including:<claim-text>receiving data from at least one sensor;</claim-text><claim-text>determining, based on the data, that the display is in the folded configuration;</claim-text><claim-text>determining, based on the data, viewing angles of a user relative to portions of the display; and</claim-text><claim-text>accessing a display model that relates adjustments in brightness and/or color of pixels to viewing angles to adjust pixels of the display for the folded configuration using the viewing angles for the portions of the display, wherein the display model is generated from measurements that include:</claim-text><claim-text>folding a portion of the display;</claim-text><claim-text>capturing an image of the display from a view-point at a viewing angle with the portion of the display;</claim-text><claim-text>determining, from the image, a brightness and/or a color of pixels in the portion of the display;</claim-text><claim-text>creating a portion of the display model to relate the brightness and/or the color of the pixels in the portion of the display to the viewing angle; and</claim-text><claim-text>repeating the folding, the capturing, the determining, and the creating for other folded configurations, from other view-points, and at other viewing angles to create the display model.</claim-text></claim-text></claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the display device and the computing device are physically separate.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The system according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the system comprises a mobile computing device, the mobile computing device comprising the display device and the computing device.</claim-text></claim></claims></us-patent-application>
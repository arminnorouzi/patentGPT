<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007117A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007117</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17944560</doc-number><date>20220914</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20210101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>M</subclass><main-group>1</main-group><subgroup>72412</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>7</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20210101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>12</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>7</main-group><subgroup>15</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>M</subclass><main-group>3</main-group><subgroup>56</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20090101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>M</subclass><main-group>1</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>N</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>M</subclass><main-group>1</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>N</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20210101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>M</subclass><main-group>1</main-group><subgroup>72412</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>7</main-group><subgroup>142</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>12</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>7</main-group><subgroup>15</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>M</subclass><main-group>3</main-group><subgroup>567</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>4</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20210101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>12</main-group><subgroup>068</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>7</main-group><subgroup>147</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>M</subclass><main-group>2201</main-group><subgroup>50</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>2007</main-group><subgroup>145</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>M</subclass><main-group>1</main-group><subgroup>0272</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>7</main-group><subgroup>152</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>M</subclass><main-group>3</main-group><subgroup>563</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>M</subclass><main-group>1</main-group><subgroup>6041</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">INFORMATION PROCESSING SYSTEM, WIRELESS TERMINAL, AND INFORMATION PROCESSING METHOD</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17109643</doc-number><date>20201202</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11477316</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17944560</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16799903</doc-number><date>20200225</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10887441</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17109643</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15775414</doc-number><date>20180511</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10616529</doc-number></document-id></parent-grant-document><parent-pct-document><document-id><country>WO</country><doc-number>PCT/JP2015/082821</doc-number><date>20151124</date></document-id></parent-pct-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16799903</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Maxell, Ltd.</orgname><address><city>Kyoto</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MATSUBARA</last-name><first-name>Takashi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An information processing system including a video device for displaying a video and a wireless terminal for communicating with the video device and communicating with other apparatuses via a network, wherein the video device transmits video information captured by a camera and sound information collected by a microphone when reception from the wireless terminal of information pertaining to a video to be displayed is detected, and outputs the received sound information using a speaker. The wireless terminal transmits information pertaining to the video to be displayed to the video device, the other apparatuses receive the captured video information and collected sound information via the network, and transmit information pertaining to the video to be displayed and information pertaining to the sound to be outputted.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="101.94mm" wi="158.75mm" file="US20230007117A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="114.38mm" wi="138.51mm" file="US20230007117A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="124.38mm" wi="161.88mm" file="US20230007117A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="202.52mm" wi="154.01mm" orientation="landscape" file="US20230007117A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="176.02mm" wi="127.85mm" file="US20230007117A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="244.26mm" wi="166.29mm" file="US20230007117A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="157.48mm" wi="106.76mm" file="US20230007117A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="157.48mm" wi="107.53mm" file="US20230007117A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="157.48mm" wi="107.53mm" file="US20230007117A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="243.84mm" wi="166.29mm" file="US20230007117A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="114.38mm" wi="138.43mm" file="US20230007117A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="243.84mm" wi="166.54mm" file="US20230007117A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="243.76mm" wi="166.29mm" file="US20230007117A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present invention relates to an information processing system, a wireless terminal, and an information processing method.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">As a background technology in the present technical field, in order to provide &#x201c;a projector capable of enabling a user to appropriately participate in or appropriately view a video conference or a remote presentation performed on a network&#x201d;, &#x201c;a projector which is connected with one or more projectors via a network and includes an input means for receiving an input of a video signal, a determining means for determining the presence or absence of the input of the video signal in the input means, a projecting means for projecting an image on the basis of the video signal, and a mode selecting means for selecting a server mode or a client mode on the basis of a determination result of the determining means, wherein, when the client mode is selected, video data to be projected by the projector is received from the projector in the server mode on the network, and the received video data is output to the projecting means, and when the server mode is selected, the video data to be projected by the projecting means is transmitted to the projector in the client mode on the network&#x201d; is disclosed in Patent Document 1.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Document</heading><p id="p-0004" num="0003">Patent Document 1: JP 2004-239968 A</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><heading id="h-0006" level="1">Technical Problem</heading><p id="p-0005" num="0004">By using the technique disclosed in Patent Document 1, it is possible to participate in the video conference as appropriate. However, in order to participate in the video conference, it is necessary for a device such as a projector to establish a connection with the video conference server and transmit authentication information, and thus usability is bad. There is a video call or a video conference by a smartphone, and there is already authentication for this, but cooperation between the smartphone and the projector is not taken into consideration.</p><p id="p-0006" num="0005">In this regard, it is an object of the present invention to improve the usability of the user.</p><heading id="h-0007" level="1">Solution to Problem</heading><p id="p-0007" num="0006">In order to solve the above problem, for example, configurations described in claims set forth below are employed.</p><p id="p-0008" num="0007">The present application provides a plurality of configurations for solving the above-mentioned problems, and as an example, provided is an information processing system, including a video device that displays a video and a wireless terminal that performs communication with the video device and performs communication with another apparatus via a network, wherein the video device transmits, if reception of information of the video to be displayed from the wireless terminal is detected, the video information captured by a camera and sound information collected by a microphone, and output received sound information through a speaker, the wireless terminal transmits information of the video to be displayed to the video device, and the other apparatus receives the captured video information and the collected sound information via a network and transmit video information to be displayed and sound information to be output via the network.</p><heading id="h-0008" level="1">Advantageous Effects of the Invention</heading><p id="p-0009" num="0008">According to the present invention, it is possible to improve the usability of the user.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of a system configuration according to a first embodiment.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of a video conference.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of a configuration of a projector.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an example of a configuration of a smartphone.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a sequence diagram illustrating an example of a first video conference start operation according to the first embodiment.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a diagram illustrating an example of a first screen display of a smartphone.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is a diagram illustrating an example of a second screen display of a smartphone.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b>C</figref> is a diagram illustrating an example of a third screen display of a smartphone.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a sequence diagram illustrating an example of a second video conference start operation according to the first embodiment.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of a system configuration according to a second embodiment.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a sequence diagram illustrating an example of a first video conference start operation according to the second embodiment.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a sequence diagram illustrating an example of a second video conference start operation according to the second embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0022" num="0021">Hereinafter, exemplary embodiments of the present invention will be described with reference to the appended drawings. Each of the following embodiments is applied to a system in which transmission and reception of a video captured by a camera and a sound collected by a microphone are performed between terminals at remote sites via a network (hereinafter referred to as a &#x201c;video conference system&#x201d;) as an example, but the video conference system is not limited to the following embodiments. Further, a system is not limited to the video conference system.</p><heading id="h-0011" level="1">First Embodiment</heading><p id="p-0023" num="0022">A first embodiment will be described in connection with a configuration in which, when a video conference with a remote site is performed using a video conference application of a smartphone (a wireless terminal), the smartphone performs the video conference using a video and a sound obtained by a video conference camera, a microphone, and a speaker which are installed in a projector and suitable for the use by a plurality of persons.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of a configuration of a video conference system according to the present embodiment. The video conference system of the present embodiment includes, for example, a projector <b>100</b>, a smartphone <b>110</b>, a network <b>120</b>, and a video conference server <b>130</b>. The projector <b>100</b> is a device for projecting a video so that the video can be seen by a plurality of persons, and a video conference camera <b>101</b>, a microphone <b>102</b>, and a speaker <b>112</b> are installed in the projector <b>100</b>.</p><p id="p-0025" num="0024">In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> are installed in the projector <b>100</b>, but the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> may be externally attached to the projector <b>100</b> if necessary, and a plurality of cameras <b>101</b>, a plurality of microphones <b>102</b>, or a plurality of speakers <b>112</b> may be installed.</p><p id="p-0026" num="0025">The projector <b>100</b> and the smartphone <b>110</b> communicate with each other through a predetermined inter-apparatus communication unit built in each of the projector <b>100</b> and the smartphone <b>110</b>. The inter-apparatus communication unit may perform communication via a wireless local area network (LAN) such as Wi-Fi (a registered trademark) or may perform communication via a wired LAN. Further, other wired or wireless communication such as USB, Bluetooth (a registered trademark), IrDA (a registered trademark), near field communication (NFC) or the like may be used.</p><p id="p-0027" num="0026">Here, Wi-Fi is a wireless LAN standard established by an Institute of Electrical and Electronic Engineers (IEEE) standard. USB is a standard established by USB Implementers Forum (USB-IF). Bluetooth is a standard established by a Bluetooth Special Interest Group (Bluetooth SIG).</p><p id="p-0028" num="0027">The network <b>120</b> is a network in which communication can be performed between apparatuses at remote sites or in a company such as the Internet, an in-house network, or the like. A wireless LAN such as Wi-Fi, or a wired LAN may be included as all or part of the network <b>120</b>. Further, the network <b>120</b> may include a mobile communication network used for mobile phones or the like.</p><p id="p-0029" num="0028">The video conference server <b>130</b> performs management of a connection between terminals and transfer of data such as a video and a sound transmitted from each terminal in order to make it possible to perform transmission and reception of a video and a sound among a plurality of terminals participating in the same video conference upon receiving a video conference start request from a terminal connected to the network <b>120</b> such as the smartphone <b>110</b>. Further, the video conference server <b>130</b> may accumulate video information of a material distributed at the video conference and distribute the video information to a plurality of terminals participating in the same video conference. A sound may be included in the information of the materials to be distributed.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an example of a form in which the user uses the video conference system. In the example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a form in which the projector <b>100</b> is placed on a conference table surrounded by a plurality of persons, and the video conference is performed using the video conference application of the smartphone <b>110</b> is illustrated. The smartphone <b>110</b> transmits a video and a sound to the projector <b>100</b>, and a camera video of the other party of the video conference is shown in a projection video <b>201</b> of the projector <b>100</b> as the video transmitted to the projector <b>100</b>. Further, a sound collected by a microphone of the other party of the video conference is output from the speaker <b>112</b> of the projector <b>100</b> as the sound transmitted to the projector <b>100</b>.</p><p id="p-0031" num="0030">In the example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the camera video of the other party is projected on the projection video <b>201</b>, but the present invention is not limited thereto, and the video of the material accumulated in the video conference server <b>130</b> may be projected or may be switchable by a switch (not illustrated). Further, the projection video <b>201</b> may be divided into two, and the camera video of the other party and the video o the material may be simultaneously projected.</p><p id="p-0032" num="0031">The video captured by the camera <b>101</b> installed in the projector <b>100</b> and the sound collected by the microphone <b>102</b> are transmitted to the smartphone <b>110</b> and input to the video conference application of the smartphone <b>110</b>. The camera <b>101</b> may image an imaging range <b>202</b> for participants in the video conference, or a plurality of imaging ranges <b>202</b> may be set so that some of a plurality of participants are imaged.</p><p id="p-0033" num="0032">Further, the camera <b>101</b> may image an imaging range <b>203</b> including the projection video <b>201</b>. The video of the material is projected on the projection video <b>201</b>, and for example, the participant points to a specific part of the material and explains it or overwrites a part of the material, and thus content to be explained to the other party of the video conference is easily conveyed. The imaging range <b>202</b> and the imaging range <b>203</b> of the camera <b>101</b> may be switchable by a switch (not illustrated), the camera <b>101</b> may be physically movable, or both the imaging range <b>202</b> and the imaging range <b>203</b> may be imaged at the same time.</p><p id="p-0034" num="0033">Further, the camera <b>101</b> may image a paper material, a sample item, or the like placed on the conference table as the imaging range.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an example of a configuration of a projector <b>100</b>. The projector <b>100</b> includes, for example, a camera <b>101</b>, a microphone <b>102</b>, a video/sound input unit <b>103</b>, a control unit <b>104</b>, a memory <b>105</b>, a video decoding/output unit <b>107</b>, a display unit <b>109</b>, an sound decoding/output unit <b>111</b>, a speaker <b>112</b>, a communication unit <b>113</b>, an antenna unit <b>114</b>, a manipulation input unit <b>115</b>, a video input/encoding unit <b>116</b>, an sound input/encoding unit <b>117</b>, an input terminal <b>118</b>, and the like, and the respective units are connected via a bus as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0036" num="0035">The control unit <b>104</b> includes, for example, a processor, and receives information of an input manipulation of the user via the manipulation input unit <b>115</b> and controls the respective units connected to the bus of the projector <b>100</b> by executing various kinds of programs <b>106</b> stored in the memory <b>105</b>. For example, the control unit <b>104</b> reads a programs among various kinds of programs <b>106</b> from the memory <b>105</b>, and controls the video input/encoding unit <b>116</b> and the communication unit <b>113</b> in accordance with the read program such that the video input/encoding unit <b>116</b> receives and encodes the video captured by the camera <b>101</b>, and the encoded video is transmitted from the communication unit <b>113</b>.</p><p id="p-0037" num="0036">The control unit <b>104</b> is a system-on-a-chip (SoC) and may include a circuit that separates video/sound information input from the video/sound input unit <b>103</b> into sound information and video information and outputs the sound information and the video information to the sound decoding/output unit <b>111</b> and the video decoding/output unit <b>107</b> in addition to the processor. Detailed description of the control of each part of the projector <b>100</b> by the control unit <b>104</b> executing various kinds of programs <b>106</b> is omitted, and an operation of the projector <b>100</b> will be described with reference to <figref idref="DRAWINGS">FIGS. <b>5</b></figref> and <b>7</b>.</p><p id="p-0038" num="0037">The memory <b>105</b> stores various kinds of programs <b>106</b> executed by the control unit <b>104</b>, data which is written and read out by the control unit <b>104</b>, and the like. Setting information of the projector <b>100</b>, video data, and sound data may be stored in the memory <b>105</b>. Various kinds of programs <b>106</b> stored in the memory <b>105</b> may be stored in the memory <b>105</b> in advance at a time point at which the projector <b>100</b> is shipped, may be stored in a recording medium such as a semiconductor memory, or may be stored in the memory <b>105</b> via a medium connecting unit (not illustrated) and installed.</p><p id="p-0039" num="0038">Further, various kinds of programs <b>106</b> may be downloaded from an external network via the communication unit <b>113</b>, stored in the memory <b>105</b>, and installed. The operation performed by the control unit <b>104</b> executing various kinds of programs <b>106</b> may be implemented by hardware as a circuit for performing the same operation.</p><p id="p-0040" num="0039">The communication unit <b>113</b> performs communication with the smartphone <b>110</b> via the antenna unit <b>114</b> in accordance with a predetermined standard or protocol. The standard used by the communication unit <b>113</b> may be a wireless LAN such as Wi-Fi or a wired LAN. Further, other wired or wireless communication such as USB, Bluetooth, IrDA, NFC, or the like may be used, and direct communication may be performed without going through the network <b>120</b>. Further, the communication unit <b>113</b> may include a plurality of chips supporting communications of different standards mounted therein or a single chip supporting communications of a plurality of standards mounted therein.</p><p id="p-0041" num="0040">The communication unit <b>113</b> outputs the video/sound information received by the antenna unit <b>114</b> to the video/sound input unit <b>103</b>, and transmits the video/sound information input from the video input/encoding unit <b>116</b> and the sound input/encoding unit <b>117</b> through the antenna unit <b>114</b>. The video/sound information received by the antenna unit <b>114</b> may be output to the bus.</p><p id="p-0042" num="0041">The video/sound input unit <b>103</b> receives the video/sound information to be projected by the projector <b>100</b> from the input terminal <b>118</b>. This may be for an original use of projecting the input video of the projector <b>100</b> other than the use for the video conference or may be used for receiving a material referred to in the video conference from a personal computer or the like. To this end, the video/sound input unit <b>103</b> may output the video/sound information to the bus as well as the control unit <b>104</b>.</p><p id="p-0043" num="0042">The input terminal <b>118</b> is, for example, a composite terminal, an S terminal, a D terminal, a component terminal, a VGA terminal, a DVI terminal, an HDMI terminal, or the like. In a case in which an input from the input terminal <b>118</b> is an analog signal, the video/sound input unit <b>103</b> may convert an analog signal into a digital signal. Further, the video/sound input unit <b>103</b> may select the input from the input terminal <b>118</b> and an input from the communication unit <b>113</b> or may synthesize both inputs.</p><p id="p-0044" num="0043">In a case in which the video/sound input unit <b>103</b> outputs the video/sound information to the bus, the communication unit <b>113</b> may receive the video/sound information via the bus and transmit the video/sound information through the antenna unit <b>114</b>. At this time, the video information or the sound information may be selected, and for example, the video information of the material may be transferred from the video/sound input unit <b>103</b> to the communication unit <b>113</b>, and the sound information of the person participating in the conference may be transferred from the microphone <b>102</b> to the communication unit <b>113</b> via the sound input/encoding unit <b>117</b>.</p><p id="p-0045" num="0044">The video decoding/output unit <b>107</b> decodes the video information input from the control unit <b>104</b> if necessary and outputs the decoded video information to the display unit <b>109</b>. For example, since the video information received by the communication unit <b>113</b> is compressed/encoded, the video information received by the communication unit <b>113</b> is decoded and output, and the video information input from the input terminal <b>118</b> may be output without change since the video information input from the input terminal <b>118</b> is not compressed/encoded. The control unit <b>104</b> may control whether or not to the decoding is performed. Part of the video information output from the video decoding/output unit <b>107</b> may be video information generated by the control unit <b>104</b> executing various kinds of programs <b>106</b>.</p><p id="p-0046" num="0045">The display unit <b>109</b> is constituted by, for example, a liquid crystal panel, an optical lens, or the like and projects a video onto a screen or the like. A video projection structure may be a digital light processing (DLP: a registered trademark), a laser light source, or the like or may be another video projection structure. Further, the display unit <b>109</b> may include a liquid crystal panel or the like that does not project a video.</p><p id="p-0047" num="0046">The sound decoding/output unit <b>111</b> decodes the sound information input from the control unit <b>104</b> if necessary and outputs the decoded sound information to the speaker <b>112</b>. For example, since the sound information received by the communication unit <b>113</b> is compressed/encoded, the sound information received by the communication unit <b>113</b> may be decoded and output, and since the sound information input from the input terminal <b>118</b> is not compressed/encoded, the sound information input from the input terminal <b>118</b> may be output without change. The control unit <b>104</b> may control whether or not the decoding is performed. The sound information output by the sound decoding/output unit <b>111</b> may be output to an external apparatus (not illustrated) in place of the speaker <b>112</b>.</p><p id="p-0048" num="0047">The speaker <b>112</b> is preferably a speaker which is omnidirectional and generates a sound with a sufficient volume for the conference. The microphone <b>102</b> is preferably a microphone which is omnidirectional and has sensitivity capable of collecting the sound of the participant on the conference table. The speaker <b>112</b> and the microphone <b>102</b> may be ones in which emphasis is placed on a sound frequency band. Further, a plurality of speaker <b>112</b> and a plurality of microphones <b>102</b> may be installed for an omnidirectional property or the like. The sound input/encoding unit <b>117</b> receives the sound information converted into an electric signal by the microphone <b>102</b>, encodes the sound information to compress an information amount, and outputs the encoded sound information to the communication unit <b>113</b> via the bus.</p><p id="p-0049" num="0048">The camera <b>101</b> images the imaging ranges <b>202</b> and <b>203</b>, converts the captured video into an electric signal, and inputs the electric signal to the video input/encoding unit <b>116</b>. A plurality of cameras <b>101</b> may be installed in accordance with the imaging ranges <b>202</b> and <b>203</b>, or the like, and a plurality of cameras <b>101</b> may be connected to the video input/encoding unit <b>116</b>. Further, the camera <b>101</b> may be mounted on the projector <b>100</b> with a physically movable structure.</p><p id="p-0050" num="0049">The video input/encoding unit <b>116</b> receives the video information converted into an electric signal by the camera <b>101</b>, encodes the video information to compress an information amount, and outputs the encoded video information to the communication unit <b>113</b> via the bus. The video input/encoding unit <b>116</b> may be connected to a plurality of cameras <b>101</b>, and in a case in which the video information is input from each of a plurality of cameras <b>101</b>, video input/encoding unit <b>116</b> may select one of the inputs form a plurality of cameras <b>101</b> or may synthesize the inputs from a plurality of cameras <b>101</b>.</p><p id="p-0051" num="0050">The manipulation input unit <b>115</b> is an input device that receives an input manipulation to the projector <b>100</b> from the user, and is, for example, a remote controller, a keyboard, a pointing device such as a mouse or a touch panel, or the like.</p><p id="p-0052" num="0051">In the example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the structure of the projector <b>100</b> has been described, but a display that displays a video instead of projecting the video may be used as the display unit <b>109</b>, and each structure described above with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be installed in a television receiver or a display device. In other words, the projection video <b>201</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may be a television receiver, and the projector <b>100</b> may be included in the television receiver. In the configuration of this television receiver, the camera <b>101</b> for imaging the imaging range <b>202</b> may be installed, and the camera <b>101</b> for imaging the imaging range <b>203</b> may not be installed, or a touch panel or the like may be installed in the television receiver instead of the camera <b>101</b> for imaging the imaging range <b>203</b>.</p><p id="p-0053" num="0052">Further, a configuration in which the display unit <b>109</b> and the speaker <b>112</b> are removed from the configuration illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and output terminals are installed instead of the display unit <b>109</b> and the speaker <b>112</b>, and it is configured with a set-top box (STB) or a recorder which does not directly display the video or output the sound may be provided. Further, instead of the projector <b>100</b>, a personal computer, a monitor device, a tablet terminal, or the like including the respective components illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may be used.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an example of the configuration of the smartphone <b>110</b>. The smartphone <b>110</b> includes, for example, a camera <b>405</b>, a microphone <b>406</b>, a control unit <b>400</b>, a memory <b>403</b>, a display unit <b>401</b>, a manipulation input unit <b>402</b>, a communication unit <b>407</b>, a communication antenna unit <b>408</b>, a mobile communication unit <b>409</b>, a mobile communication antenna unit <b>410</b>, and the like.</p><p id="p-0055" num="0054">The control unit <b>400</b> includes a processor, reads out and executes various kinds of programs <b>412</b> stored in the memory <b>403</b>, and controls the respective units of the smartphone <b>110</b> via a bus. The control unit <b>400</b> is an SoC and may include a circuit related to processing of videos and sounds. The display unit <b>401</b> may be a liquid crystal panel, an organic EL (Electroluminescence) display, or the like or may be integrated with a touch panel of the manipulation input unit <b>402</b>. The camera <b>405</b> images a specific direction of the smartphone <b>110</b>, the microphone <b>406</b> collects the sound around the smartphone <b>110</b>, and a speaker <b>411</b> outputs the sound.</p><p id="p-0056" num="0055">The communication unit <b>407</b> performs communication with the projector <b>100</b> via the communication antenna unit <b>408</b> in accordance with a predetermined standard or protocol. The communication standard is a standard in which communication with the projector <b>100</b> can be performed. In order to perform communication with the network <b>120</b> via the mobile communication antenna unit <b>410</b>, a mobile communication base station (not illustrated), or the like, the mobile communication unit <b>409</b> may perform communication conforming to a mobile communication standard such as 3G, 4G, or LTE.</p><p id="p-0057" num="0056">Further, in order to perform communication with the network <b>120</b> via the mobile communication antenna unit <b>410</b>, an access point (not illustrated), or the like, the mobile communication unit <b>409</b> may perform communication conforming to a wireless LAN standard such as Wi-Fi. Further, the mobile communication unit <b>409</b> may perform communication with the network <b>120</b> via a wired LAN through a terminal (not illustrated) in place of the mobile communication antenna unit <b>410</b> and may include a plurality of chips supporting communications of different standards mounted therein or a single chip supporting communications of a plurality of standards mounted therein.</p><p id="p-0058" num="0057">As various kinds of programs <b>412</b> stored in the memory <b>403</b>, a video conference application is included. The video conference application may be a program such as a video call or the like, and may be an application program of a telephone call using the display unit <b>401</b>, the camera <b>405</b>, the microphone <b>406</b>, and the like. Further, as various kinds programs <b>412</b>, an operating system (OS) or a presentation application may be included.</p><p id="p-0059" num="0058">Hereinafter, an operation example in which the video conference is started using the smartphone <b>110</b>, and the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> of the projector <b>100</b> are used in the video conference will be described with reference to <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref>.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a sequence diagram illustrating an example of a video conference start operation according to the first embodiment. The video conference start operation is a sequence in which the video conference via the video conference server <b>130</b> is started using the video conference application of the smartphone <b>110</b>, the display unit <b>109</b> and the speaker <b>112</b> of the projector <b>100</b> are used for the video and the sound received from the video conference server <b>130</b>, and the camera <b>101</b> and the microphone <b>102</b> of the projector <b>100</b> are used for the video and the sound to be transmitted to the video conference server <b>130</b>.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIGS. <b>6</b>A, <b>6</b>B, and <b>6</b>C</figref> are diagrams illustrating an example of a screen display of the smartphone <b>110</b>. In the sequence described with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the smartphone <b>110</b> displays the screen to be described with reference to <figref idref="DRAWINGS">FIGS. <b>6</b>A, <b>6</b>B, and <b>6</b>C</figref>. The camera <b>405</b>, the microphone <b>406</b>, and the display unit <b>401</b> in <figref idref="DRAWINGS">FIGS. <b>6</b>A, <b>6</b>B, and <b>6</b>C</figref> are similar to those described above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the manipulation input unit <b>402</b> is integrated with the display unit <b>401</b>, and a manipulation is input when the display of the display unit <b>401</b> is touched.</p><p id="p-0062" num="0061">Step <b>500</b>: The smartphone <b>110</b> displays a plurality of icons on the display unit <b>401</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, detects that an icon <b>601</b> of the video conference application is selected (touched) by the user, and activates the video conference application.</p><p id="p-0063" num="0062">Step <b>501</b>: The smartphone <b>110</b> displays a screen for prompting an input of a conference ID, an account/password (authentication information), and the like for a video conference to participate in on the display unit <b>401</b>, receives the conference ID, the account/password, and the like input by user, transmits the input conference ID, the account/password, and the like to the video conference server <b>130</b>, and requests a connection to the video conference.</p><p id="p-0064" num="0063">Step <b>502</b>: The video conference server <b>130</b> receives the request from the smartphone <b>110</b>, and starts a connection process with a terminal participating in the same video conference on the basis of the received conference ID, the account/password, and the like.</p><p id="p-0065" num="0064">Step <b>503</b>: The video conference server <b>130</b> establishes a connection with the terminal participating in the same video conference as the video conference requested by the smartphone <b>110</b>, and gives a notification indicating that the connection has been established to the smartphone <b>110</b>.</p><p id="p-0066" num="0065">Step <b>504</b>: The smartphone <b>110</b> starts a video conference process using the camera <b>405</b>, the microphone <b>406</b>, and the speaker <b>411</b> of the smartphone <b>110</b>. Step <b>505</b>: The smartphone <b>110</b> transmits the video captured by the camera <b>405</b> and the sound collected by the microphone <b>406</b> to the video conference server <b>130</b>. Further, the smartphone <b>110</b> receives the video and the sound of another terminal transmitted from the video conference server <b>130</b>, displays the video on the display unit <b>401</b>, and outputs the sound through the speaker <b>411</b>.</p><p id="p-0067" num="0066">Step <b>506</b>: The video conference server <b>130</b> transfers the video and the sound received from the smartphone <b>110</b> to the terminal participating in the same conference. Further, the video conference server <b>130</b> transfers the video and the sound received from the terminal participating in the same meeting to the smartphone <b>110</b>.</p><p id="p-0068" num="0067">Step <b>507</b>: The smartphone <b>110</b> displays a video output destination setting menu <b>602</b> on the display unit <b>401</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, detects that the &#x201c;projector&#x201d; is selected (touched) by the user, and transmits the display screen to the projector <b>100</b> through the communication unit <b>407</b>. The video output destination setting menu <b>602</b> may be displayed if the video conference application is activated or may be displayed if a specific menu of the video conference application is selected.</p><p id="p-0069" num="0068">Step <b>508</b>: Upon detecting the reception of the display screen from the smartphone <b>110</b> through the communication unit <b>113</b>, the projector <b>100</b> starts displaying the received display screen and proceeds to step <b>509</b>.</p><p id="p-0070" num="0069">Step <b>509</b>: The projector <b>100</b> gives a notification indicating that the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> of the projector <b>100</b> are usable to the smartphone <b>110</b> through the communication unit <b>113</b>.</p><p id="p-0071" num="0070">Step <b>510</b>: Upon receiving the notification from the projector <b>100</b>, the smartphone <b>110</b> displays a camera/microphone/speaker use confirmation menu <b>603</b> on the display unit <b>401</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref>, the process proceeds to step <b>511</b> if &#x201c;Yes&#x201d; is selected (touched) by the user, and the video conference start operation ends if it is detected that &#x201c;No&#x201d; is selected (touched).</p><p id="p-0072" num="0071">Step <b>511</b>: Since &#x201c;Yes&#x201d; is selected in the camera/microphone/speaker use confirmation menu <b>603</b>, the smartphone <b>110</b> gives a notification indicating the use of the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> to the projector <b>100</b> through the communication unit <b>407</b>.</p><p id="p-0073" num="0072">Step <b>512</b>: Upon receiving the notification of step <b>511</b> from the smartphone <b>110</b> through the communication unit <b>113</b>, the projector <b>100</b> starts imaging and sound collection using the camera <b>101</b> and the microphone <b>102</b> of the projector <b>100</b>.</p><p id="p-0074" num="0073">Step <b>513</b>: The projector <b>100</b> starts transmitting the video captured by the camera <b>101</b> of the projector <b>100</b> and the sound collected by the microphone <b>102</b> to the smartphone <b>110</b> through the communication unit <b>113</b>, and starts receiving the sound from the smartphone <b>110</b> so that the sound can be output through the speaker <b>112</b>.</p><p id="p-0075" num="0074">Step <b>514</b>: The smartphone <b>110</b> starts receiving the video and the sound from the projector <b>100</b> through the communication unit <b>407</b>, and starts transmitting the sound to the projector <b>100</b>.</p><p id="p-0076" num="0075">Step <b>515</b>: The smartphone <b>110</b> switches the video and the sound to be transmitted to the video conference server <b>130</b> from the video and the sound obtained by the camera <b>405</b> and the microphone <b>406</b> of the smartphone <b>110</b> to the video and the sound received from the projector <b>100</b>, and switches the sound received from the video conference server <b>130</b> from the output of the speaker <b>411</b> to the transmission of the sound to the projector <b>100</b>.</p><p id="p-0077" num="0076">As described above, when the video conference is started using the application used in the smartphone <b>110</b>, and the smartphone <b>110</b> outputs the video to the projector <b>100</b>, the projector <b>100</b> gives a notification indicating that the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> of the projector are usable to the smartphone <b>110</b>, and thus a cooperation can be easily achieved.</p><p id="p-0078" num="0077">Further, since the smartphone <b>110</b> uses the video and the sound obtained by the camera <b>101</b> and the microphone <b>102</b> of the projector <b>100</b> in the video conference and uses the speaker <b>112</b> for the sound of the video conference, it is possible to use the camera, the microphone, and the speaker suitable for the conference using the smartphone <b>110</b> which is daily used by the user and the application thereof, and thus it is possible to improve the convenience of the user.</p><p id="p-0079" num="0078">Further, since the information of the smartphone <b>110</b> can be used as the information for participating in the video conference (the authentication information, the password, or the like), it is easy to input information, special dedicated information is unnecessary, and it is easy to use a popular participation procedure.</p><p id="p-0080" num="0079">In the example of the sequence illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, after the video conference is started in the smartphone <b>110</b> (step <b>504</b>), the video output to the projector <b>100</b> and the use of the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> of the projector <b>100</b> are started, but this sequence is not limited.</p><p id="p-0081" num="0080">For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, before the video conference is started by the smartphone <b>110</b> (step <b>714</b>), the video may be output from the smartphone <b>110</b> to the projector <b>100</b> (step <b>701</b>), and at a time point at which the video conference application is activated (step <b>705</b>), the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> of the projector <b>100</b> may become usable.</p><p id="p-0082" num="0081">Step <b>701</b> to step <b>703</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> correspond to step <b>507</b> to step <b>509</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, and the smartphone <b>110</b> receives the notification in step <b>704</b>. Thereafter, if the video conference application of the smartphone <b>110</b> is activated in step <b>705</b>, the smartphone <b>110</b> executes step <b>706</b> on the basis of the notification received in step <b>704</b> in advance. Step <b>707</b> to step <b>710</b> correspond to step <b>511</b> to step <b>514</b>, and step <b>711</b> to step <b>714</b> correspond to step <b>501</b> to step <b>504</b>.</p><p id="p-0083" num="0082">Step <b>715</b> to step <b>716</b> correspond to step <b>505</b> to step <b>506</b>, but in step <b>505</b>, the camera <b>405</b> or the like of the smartphone <b>110</b> is used, whereas in step <b>710</b>, if step <b>710</b> is already executed, the camera <b>101</b> or the like of the projector <b>100</b> is used.</p><p id="p-0084" num="0083">Further, when the smartphone <b>110</b> is outputting a screen of an application in which it is unnecessary to use the camera, the microphone, and the speaker such as a presentation application to the projector <b>100</b>, the camera/microphone/speaker use confirmation menu <b>603</b> illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref> is not displayed, and the camera/microphone/speaker use confirmation menu <b>603</b> is displayed only when an application in which it is necessary to use the camera, the microphone, and the speaker such as the video conference application is activated, the menu display is not complicated, and the convenience of the user can be improved.</p><p id="p-0085" num="0084">The communication unit <b>113</b> of the projector <b>100</b> and the communication unit <b>407</b> of the smartphone <b>110</b> may enter a communicable state in advance, for example, by pairing of Bluetooth or an operation equivalent thereto. Further, the video output from the smartphone <b>110</b> to the projector <b>100</b> may be a video output by execution of the OS of the smartphone <b>110</b>.</p><p id="p-0086" num="0085">In step <b>701</b>, if the video can be output by the execution of the OS, a type of video is not limited, and it may be the output of the same video as the video displayed on the display unit <b>401</b> of the smartphone <b>110</b>. Therefore, a mirror image of the display unit <b>401</b> of the smartphone <b>110</b> may be projected by the projector <b>100</b>.</p><p id="p-0087" num="0086">As the video conference system, the configuration in which participation in the video conference is performed through communication with the video conference server <b>130</b> has been described, but the present invention is not limited to this configuration. For example, the video conference server <b>130</b> may not be provided, and the smartphone <b>110</b> may perform point-to-point (P2P) communication of directly communicating with the terminal participating in the video conference via the network <b>120</b>.</p><heading id="h-0012" level="1">Second Embodiment</heading><p id="p-0088" num="0087">A second embodiment of the present invention will be described below with reference to <figref idref="DRAWINGS">FIGS. <b>8</b> to <b>10</b></figref>. In the first embodiment, the projector <b>100</b> transmits the video and the sound via the smartphone <b>110</b>, but in the second embodiment, the smartphone <b>110</b> is used to participate in the video conference, and the projector <b>100</b> transmits the video and the sound without going through smartphone <b>110</b>. Detailed description of the same configuration as in the first embodiment will be omitted, and different configurations will be described in particular.</p><p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram illustrating an example of a video conference system according to the second embodiment. A difference from the first embodiment lies in that the projector <b>100</b> can communicate directly with the network <b>120</b>. Accordingly, the projector <b>100</b> transmits the video collected by the camera <b>101</b> and the sound collected by the microphone <b>102</b> to the video conference server <b>130</b> via the network <b>120</b>.</p><p id="p-0090" num="0089">The configuration of the projector <b>100</b> is similar to that described above with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, but the communication unit <b>113</b> of the projector <b>100</b> may perform communication with the network <b>120</b> via an access point or the like in addition to communication with the communication unit <b>407</b> of the smartphone <b>110</b>. Further, the projector <b>100</b> may include a mobile communication unit or a wired communication unit (not illustrated) and performs communication with the network <b>120</b>. The configuration of the smartphone <b>110</b> is similar to that described above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a sequence diagram illustrating an example of the video conference start operation according to the second embodiment. Step <b>900</b> to step <b>910</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref> correspond to step <b>500</b> to step <b>510</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref>. A difference from the sequence diagram of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, that is, step <b>911</b> and subsequent steps will be described below.</p><p id="p-0092" num="0091">Step <b>911</b>: Since &#x201c;Yes&#x201d; is selected in the camera/microphone use confirmation menu, the smartphone <b>110</b> stops transmitting the video and the sound using the camera <b>405</b> and the microphone <b>406</b> of the smartphone <b>110</b> which are being transmitted to the video conference server <b>130</b>. Further, with the stop, transferring the video and the sound which received from the smartphone <b>110</b> to other terminals in the video conference server <b>130</b> is stopped.</p><p id="p-0093" num="0092">Step <b>912</b>: The smartphone <b>110</b> transmits the connection destination of the video conference server <b>130</b> and information necessary to a connection to the video conference such as the conference ID and the account/password (the authentication information) to the projector <b>100</b>, and instructs the video conference server <b>130</b> to transmit the video and the sound. Further, the connection destination of the video conference server <b>130</b> may be information indicated by an IP address, a URL, or the like.</p><p id="p-0094" num="0093">Step <b>913</b>: The projector <b>100</b> receives the connection destination of the video conference server <b>130</b> and the information necessary for a connection to the video conference such as the conference ID and the account/password, and starts imaging and sound collection using the camera <b>101</b> and the microphone <b>102</b> of the projector <b>100</b>.</p><p id="p-0095" num="0094">Step <b>914</b>: The projector <b>100</b> establishes a connection with the video conference server <b>130</b> using the connection destination of the video conference server <b>130</b> and the information necessary for a connection to the video conference such as the conference ID and the account/password received from the smartphone <b>110</b>, and starts transmitting the video captured by the camera <b>101</b> of the projector <b>100</b> and the sound collected by the microphone <b>102</b>.</p><p id="p-0096" num="0095">Step <b>915</b>: The video conference server <b>130</b> resumes the transfer of the video and the sound to other terminals participating in the same meeting using the video and the sound received from the projector <b>100</b>.</p><p id="p-0097" num="0096">As described above, when the video conference is started using the application used in the smartphone <b>110</b>, and the smartphone <b>110</b> outputs the video to the projector <b>100</b>, the projector <b>100</b> gives a notification indicating that the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> of the projector <b>100</b> are usable to the smartphone <b>110</b>, and thus a cooperation can be easily achieved.</p><p id="p-0098" num="0097">The smartphone <b>110</b> instructs the projector <b>100</b> to transmit the video and the sound obtained by the camera <b>101</b> and the microphone <b>102</b> of the projector <b>100</b> to the video conference server <b>130</b>, and thus it is possible to use the camera <b>101</b> and the microphone <b>102</b> suitable for the conference using the smartphone <b>110</b> which is daily used by the user and the application thereof, and thus it is possible to improve the convenience of the user.</p><p id="p-0099" num="0098">Further, since the video and the sound in the video conference are transmitted directly from the projector <b>100</b> to the video conference server <b>130</b>, for example, it is possible to reduce the amount of communication data of the smartphone <b>110</b> via the mobile communication network and improve the convenience of the user.</p><p id="p-0100" num="0099">In the example of the sequence illustrated in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, after the video conference is started in the smartphone <b>110</b> (step <b>904</b>), the video output to the projector <b>100</b> and the use of the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> of the projector <b>100</b> are started, but this sequence is not limited.</p><p id="p-0101" num="0100">For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, before the video conference is started by the smartphone <b>110</b> (step <b>1009</b>), the video may be output from the smartphone <b>110</b> to the projector <b>100</b> (step <b>1001</b>), and at a time point at which the video conference application is activated (step <b>1005</b>), the camera <b>101</b>, the microphone <b>102</b>, and the speaker <b>112</b> of the projector <b>100</b> may become usable.</p><p id="p-0102" num="0101">Step <b>1001</b> to step <b>1003</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref> correspond to step <b>909</b> to step <b>909</b> of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, and the smartphone <b>110</b> receives the notification in step <b>1004</b>. Thereafter, in step <b>1005</b>, the video conference application of the smartphone <b>110</b> is activated. Step <b>1006</b> to step <b>1009</b> correspond to step <b>901</b> to step <b>904</b>, and the smartphone <b>110</b> executes step <b>1010</b> on the basis of the notification received in step <b>1004</b> in advance.</p><p id="p-0103" num="0102">Step <b>1011</b> to step <b>1014</b> correspond to step <b>912</b> to step <b>915</b>. Step <b>1015</b> corresponds to step <b>905</b>, and the smartphone <b>110</b> uses the camera <b>405</b> and the microphone <b>406</b> of the smartphone <b>110</b>.</p><p id="p-0104" num="0103">Further, when the smartphone <b>110</b> is outputting a screen of an application in which it is unnecessary to use the camera and the microphone such as a presentation application to the projector <b>100</b>, the camera/microphone use confirmation menu illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref> is not displayed, and the camera/microphone use confirmation menu is displayed only when an application in which it is necessary to use the camera and the microphone such as the video conference application is activated, the menu display is not complicated, and the convenience of the user can be improved.</p><p id="p-0105" num="0104">A part of the configuration of each embodiment described above may be deleted or replaced with a part of the configuration of another embodiment, and a part of the configuration of another embodiment is added to the configuration of each embodiment.</p><heading id="h-0013" level="1">REFERENCE SIGNS LIST</heading><p id="p-0106" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0105"><b>100</b> projector</li>    <li id="ul0001-0002" num="0106"><b>101</b> camera</li>    <li id="ul0001-0003" num="0107"><b>102</b> microphone</li>    <li id="ul0001-0004" num="0108"><b>110</b> smartphone</li>    <li id="ul0001-0005" num="0109"><b>112</b> speaker</li>    <li id="ul0001-0006" num="0110"><b>120</b> network</li>    <li id="ul0001-0007" num="0111"><b>130</b> video conference server</li>    <li id="ul0001-0008" num="0112"><b>405</b> camera</li>    <li id="ul0001-0009" num="0113"><b>406</b> microphone</li>    <li id="ul0001-0010" num="0114"><b>411</b> speaker</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An information processing system, comprising:<claim-text>a video apparatus configured to display a video; and</claim-text><claim-text>a wireless terminal configured to perform communication with the video apparatus and performs communication with another apparatus via a network,</claim-text><claim-text>wherein the wireless terminal is further configured to: i) receive information of a video to be displayed by the video apparatus from the other apparatus via the network; and ii) transmit the information of the video to be displayed by the video apparatus to the video apparatus,</claim-text><claim-text>wherein, after reception of information of the video to be displayed from the wireless terminal is detected, the video apparatus is further configured to: i) transmit information of a video captured by a camera of the video apparatus to the wireless terminal; ii) receive information of a sound from the wireless terminal; and iii) output the received information of the sound by a speaker of the video apparatus,</claim-text><claim-text>wherein the wireless terminal is further configured to: i) receive information of a video to be displayed by the video apparatus from the other apparatus; and ii) transmit the information of the video to be displayed by the video apparatus to the video apparatus,</claim-text><claim-text>wherein the wireless terminal is further configured to: i) receive the information of the video captured by the camera of the video apparatus from the video apparatus; and ii) transmit the received information of the video to the other apparatus via the network, and</claim-text><claim-text>wherein the other apparatus transmits the information of the video to be displayed by the video apparatus and the information of the sound to be output by the speaker of the video apparatus via the network to the video apparatus.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004169A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004169</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17779847</doc-number><date>20201104</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-213480</doc-number><date>20191126</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>02</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>86</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0251</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>1</main-group><subgroup>0274</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>867</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>2013</main-group><subgroup>93271</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>05</class><subclass>D</subclass><main-group>2201</main-group><subgroup>0213</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">Apparatus and Method for Controlling Mobile Body</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Hitachi Astemo, Ltd.</orgname><address><city>Hitachinaka-shi, Ibaraki</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KIDO</last-name><first-name>Hideaki</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>MONJI</last-name><first-name>Tatsuhiko</first-name><address><city>Hitachinaka</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>HAYASE</last-name><first-name>Shigenori</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/041140</doc-number><date>20201104</date></document-id><us-371c12-date><date>20220525</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An apparatus and the like for controlling a mobile body that are capable of adjusting a detection result by a radar device in accordance with a three-dimensional shape for each region of a three-dimensional map generated from an image captured by an image-capturing device are provided. A mobile body control unit <b>105</b> is an apparatus for controlling the vehicle (mobile body) including an image-capturing device <b>101</b> and a millimeter wave radar device <b>102</b> (radar device). A three-dimensional map generation unit <b>203</b> generates a three-dimensional map around the vehicle from an image captured by the image-capturing device <b>101</b>. A radar weight map estimation unit <b>204</b> (weight estimation unit) estimates the weight of the detection result by the millimeter wave radar device <b>102</b> for each region of the three-dimensional map from the three-dimensional shape for each region of the three-dimensional map. A weight adjustment unit <b>205</b> (adjustment unit) adjusts a detection result by the millimeter wave radar device <b>102</b> on the basis of a weight.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="77.89mm" wi="136.40mm" file="US20230004169A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="209.13mm" wi="150.37mm" file="US20230004169A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="228.43mm" wi="143.59mm" file="US20230004169A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="225.04mm" wi="156.29mm" file="US20230004169A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="226.74mm" wi="154.09mm" file="US20230004169A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="94.49mm" wi="62.82mm" file="US20230004169A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present invention relates to an apparatus and a method for controlling a mobile body.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">In achievement of automatic driving and an advanced safety driving support system, importance of a sensor that monitors the outside world and detects an object necessary for own vehicle travel such as an obstacle and lane information is increasing. Outside world monitoring sensors come in types such as a camera, a millimeter wave radar, and LIDAR, each of which has characteristics of a sensor, and there are advantages and disadvantages in a traveling scene.</p><p id="p-0004" num="0003">For example, a camera becomes difficult to detect in a case of backlight. When there is a large reflective object beside a detection target object, a millimeter wave radar has a multipath, in which a radar wave is reflected once on the reflective object, is reflected again on another object, and returns, occurs, thereby becoming likely to cause erroneous measurement of a distance and an arrival angle and erroneous detection due to clutter.</p><p id="p-0005" num="0004">In order to solve this problem, for example, PTL 1 discloses a technology of determining, using map information for navigation, the presence or absence of a sidewall that causes erroneous detection when detecting an object by a millimeter wave radar, and reducing or stopping the monitoring frequency of the millimeter wave radar, thereby suppressing output of sensor information in a state of low reliability. For example, PTL 2 proposes a technology of performing object detection with a millimeter wave radar by combining map information created by a stereo camera and detection of a polarization region, thereby suppressing a reflected wave from a metal object on a road surface.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0006" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0005">PTL 1: JP 2900737 A</li>    <li id="ul0001-0002" num="0006">PTL 2: WO 2017/057058</li></ul></p><heading id="h-0005" level="1">SUMMARY OF INVENTION</heading><heading id="h-0006" level="1">Technical Problem</heading><p id="p-0007" num="0007">PTL 1 makes it possible to predict an object registered in a navigation map, but not possible to cope with a case where an object not registered in the navigation map induces a detection error of a millimeter wave radar. For example, it cannot solve a case where a large trailer is traveling beside a detection target object or there is a guardrail not registered on the map.</p><p id="p-0008" num="0008">PTL 2 discloses a method for detecting a metal object on a road surface, but does not describe a response to a situation where a multipath can occur.</p><p id="p-0009" num="0009">An objective of the present invention is to provide an apparatus and a method for controlling a mobile body that are capable of adjusting a detection result by a radar device in accordance with a three-dimensional shape for each region of a three-dimensional map generated from an image captured by an image-capturing device.</p><heading id="h-0007" level="1">Solution to Problem</heading><p id="p-0010" num="0010">In order to achieve the above objective, an example of the present invention is an apparatus for controlling a mobile body that has an image-capturing device and a radar device, the apparatus including: a three-dimensional map generation unit that generates a three-dimensional map around the mobile body from an image captured by the image-capturing device; a weight estimation unit that estimates, from a three-dimensional shape of each region of the three-dimensional map, a weight of a detection result by the radar device for each region of the three-dimensional map; and an adjustment unit that adjusts a detection result by the radar device based on the weight.</p><heading id="h-0008" level="1">Advantageous Effects of Invention</heading><p id="p-0011" num="0011">According to the present invention, it is possible to adjust a detection result by the radar device in accordance with the three-dimensional shape of each region of a three-dimensional map generated from an image captured by the image-capturing device. Problems, configurations, and effects other than those described above will be made clear by the description of the following embodiment.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0012" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a view explaining a configuration of an in-vehicle mobile body control apparatus according to a first embodiment.</p><p id="p-0013" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a view explaining a configuration of a mobile body control unit illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0014" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a view explaining a configuration of a three-dimensional map generation unit illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0015" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a view explaining a configuration of a radar weight map estimation unit.</p><p id="p-0016" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a view explaining an example of a specific shape registered in a specific shape database.</p><p id="p-0017" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a view illustrating a behavior of the radar weight map estimation unit in a state where a plurality of vehicles are in front.</p><p id="p-0018" num="0018"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is an overhead view of a three-dimensional map.</p><p id="p-0019" num="0019"><figref idref="DRAWINGS">FIG. <b>6</b>C</figref> is a view for explaining an operation of the radar weight map estimation unit.</p><p id="p-0020" num="0020"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a view utilizing past map information.</p><p id="p-0021" num="0021"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a view utilizing past composite map information.</p><p id="p-0022" num="0022"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart showing processing executed by the mobile body control apparatus.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0023" num="0023">An embodiment of the invention will be described below. The present embodiment relates to a system that highly understands a surrounding environment in automatic driving and an advanced safety driving system.</p><p id="p-0024" num="0024"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a vehicle control system using an image-capturing device and a millimeter wave radar.</p><p id="p-0025" num="0025">An image-capturing device <b>101</b> and a millimeter wave radar device <b>102</b> are mounted on a vehicle <b>103</b>, and measure and transmit, to a mobile body control unit <b>105</b>, a distance to an object <b>104</b> in front and a relative speed, for example. The mobile body control unit <b>105</b> determines control of the brake and the accelerator from the distance to the object <b>104</b> and the relative speed, and controls the vehicle <b>103</b>.</p><p id="p-0026" num="0026">That is, the mobile body control unit <b>105</b> is an apparatus for controlling the vehicle <b>103</b> (mobile body) including the image-capturing device <b>101</b> and the millimeter wave radar device <b>102</b> (radar device).</p><p id="p-0027" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a first mode of the mobile body control unit <b>105</b> that implements the present invention. Note that the mobile body control unit <b>105</b> is, for example, an electronic control unit (ECU), and includes a memory (storage device), a CPU (processor), and an input/output circuit (communication device).</p><p id="p-0028" num="0028">Object detection units <b>201</b> and <b>202</b> are provided in the mobile body control unit <b>105</b> for the image-capturing device <b>101</b> and the millimeter wave radar device <b>102</b>, respectively, and detect various objects that exist in the field of view seen from the own vehicle (vehicle <b>103</b>). The image-capturing device <b>101</b> causes a three-dimensional map generation unit <b>203</b> to generate a three-dimensional map in real time from acquired sensor information. Here, the three-dimensional map has information (e.g., distance information) in a depth direction, a height direction, and a lateral direction of an object existing in the field of view of a sensor.</p><p id="p-0029" num="0029">As the three-dimensional map, a distance image by a stereo camera may be used, a sensor that acquires a point group having distance information as LIDAR may be used, or generation of distance information by time series analysis using a monocular camera or generation of a distance image by learning may be used, and the means does not matter.</p><p id="p-0030" num="0030">After the three-dimensional map is generated, radar weight map estimation is performed. A radar weight map estimation unit <b>204</b> generates a weight value indicating how reliable a radar signal arriving from each point on the three-dimensional map is at the point. Using a result of the radar weight map estimation unit <b>204</b>, a weight adjustment unit <b>205</b> performs adjustment of values related to detection, such as the reliability, existence probability, and distance accuracy of an object detected by the object detection unit <b>202</b> on the millimeter wave radar device <b>102</b> (radar device) side. The result is input to a sensor fusion unit <b>206</b>.</p><p id="p-0031" num="0031">The sensor fusion unit <b>206</b> matches with a result of the object detection unit <b>201</b> on the image-capturing device side to make one signal, and transmits the signal to a control unit <b>109</b>. That is, the sensor fusion unit <b>206</b> synthesizes a detection result by the image-capturing device <b>101</b> and a detection result by the millimeter wave radar device <b>102</b> (radar device) adjusted based on the weight, and outputs a detection result that is synthesized. This makes it possible to secure the reliability of the composite detection result. The control unit <b>109</b> generates a signal for controlling the vehicle in accordance with the result.</p><p id="p-0032" num="0032"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a configuration example of the three-dimensional map generation unit <b>203</b>.</p><p id="p-0033" num="0033">Here, an example of a case of use of a stereo camera as an example of the image-capturing device <b>101</b> will be described. The stereo camera can measure a distance on the basis of the principle of triangulation from parallaxes of two or more cameras that are installed, and can output the distance as a distance image generation unit <b>301</b> and handle it as a three-dimensional map having distance information in the horizontal direction and the vertical direction. The three-dimensional map generation unit <b>203</b> includes at least such a function.</p><p id="p-0034" num="0034">In other words, the three-dimensional map generation unit <b>203</b> generates a three-dimensional map around the vehicle <b>103</b> (mobile body) from an image captured by the image-capturing device <b>101</b>. Note that the result of the three-dimensional map generation unit <b>203</b> created here can also be used for the object detection unit <b>201</b> of the image-capturing device <b>101</b>.</p><p id="p-0035" num="0035">In addition, the three-dimensional map generation unit <b>203</b> includes an object attribute estimation unit <b>302</b> that estimates the attribute and the material of the object for each distance by image analysis after image capturing. As a generally known method for estimating the attribute of an object, use of a discriminator, semantic segmentation, instance segmentation, and the like for an image are known as well-known technologies, and the method does not matter here.</p><p id="p-0036" num="0036">In other words, the three-dimensional map generation unit <b>203</b> includes the object attribute estimation unit <b>302</b> (attribute estimation unit) that estimates the attribute of the object detected from an image captured by the image-capturing device <b>101</b>. The attribute of an object to be estimated is, for example, a pedestrian, a vehicle, a wall, a tree, a curbstone, a guardrail, or a pole.</p><p id="p-0037" num="0037">Note that the radar weight map estimation unit <b>204</b> (weight estimation unit) may estimate (set) the weight of the detection result by the millimeter wave radar device <b>102</b> (radar device) for each region of the three-dimensional map from a combination of the three-dimensional shape (e.g., corner shape) for each region of the three-dimensional map and the attribute (e.g., guardrail) of the object. For example, a small weight is associated with a combination of a &#x201c;corner shape&#x201d; as a three-dimensional shape and a &#x201c;guardrail&#x201d; as an attribute of an object, and stored in the memory.</p><p id="p-0038" num="0038">This makes it possible to adjust the detection result by the radar device in accordance with the combination of the three-dimensional shape (e.g., corner shape) for each region of the three-dimensional map generated from the image captured by the image-capturing device and the attribute (e.g., guardrail) of the object estimated by the attribute estimation unit.</p><p id="p-0039" num="0039"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a configuration example of the radar weight map estimation unit <b>204</b>.</p><p id="p-0040" num="0040">In the radar weight map estimation unit <b>204</b>, information created by the three-dimensional map generation unit <b>203</b> is input. By detecting a specific shape with reference to a registered specific shape database <b>401</b>, a specific shape detection unit <b>402</b> estimates a place where a multipath possibly occurs, and causes a weight setting unit <b>404</b> to assign a low weight to the detected place.</p><p id="p-0041" num="0041">In other words, the radar weight map estimation unit <b>204</b> (weight estimation unit) estimates the weight of the detection result by the millimeter wave radar device <b>102</b> (radar device) for each region of the three-dimensional map from the three-dimensional shape for each region of the three-dimensional map.</p><p id="p-0042" num="0042">The specific shape database <b>401</b> retains a feature of a shape that is likely to cause a multipath. In the specific shape database <b>401</b>, there is a case where it is necessary to change the weight setting depending on the material of the shape as described later, and it is therefore conceivable to also transmit the material information of the shape to the weight setting unit.</p><p id="p-0043" num="0043">As a different implementation method, an object size measurement unit <b>403</b> detects a large object that is likely to cause a multipath, and the weight setting unit <b>404</b> assigns low reliability to the surroundings of it.</p><p id="p-0044" num="0044">In other words, in a case where there is an object (first object) having a predetermined size or larger in the three-dimensional map, the radar weight map estimation unit <b>204</b> (weight estimation unit) lowers the weight of the detection result by the millimeter wave radar device <b>102</b> (radar device) for each region of the three-dimensional map around the object (first object). This makes it possible to lower the reliability of the detection result by the radar device around a large trailer, for example, in a case where the large trailer that is likely to induce a multipath exists around the mobile body (own vehicle).</p><p id="p-0045" num="0045">In a case where there is another object (second object) close to the object (first object) in the three-dimensional map, the radar weight map estimation unit <b>204</b> (weight estimation unit) may lower the weight of the detection result by the millimeter wave radar device <b>102</b> (radar device) for each region of the three-dimensional map around the object (first object) and the other object (second object). This makes it possible to lower the reliability of the detection result by the radar device around a trailer and a passenger car traveling side by side, for example, in a case where the large trailer and the passenger car travel side by side.</p><p id="p-0046" num="0046"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example of the specific shapes registered in the specific shape database <b>401</b>.</p><p id="p-0047" num="0047">This specific shape varies depending on the arrival angle from the sensor, but a shape in the direction illustrated at <b>501</b> is illustrated here. This figure illustrates a specific shape in a bird eye view. A multipath is likely to occur at a corner (concave) part as indicated by <b>502</b>. There is an example in which the shape continuously changes or a possibility that a similar phenomenon occurs in a shape <b>503</b>. Reversely, in a shape <b>504</b> in which a circular (convex) pattern is oriented in a vehicle direction, a strong reflection is incident on the vehicle, and thus a signal from there becomes dominant, which affects a signal group from another, and there is a possibility of erroneous measurement.</p><p id="p-0048" num="0048">As described above, this specific shape varies depending on the arrival angle of the sensor. As a storage method into the specific shape database <b>401</b>, it is conceivable to store the specific shape in a point sequence, and adjust and output, from the specific shape database <b>401</b>, the shape using the absolute value of the arrival angle and the reference distance as parameters.</p><p id="p-0049" num="0049">In the present embodiment, when the three-dimensional shape is a corner shape or a circle shape, the radar weight map estimation unit <b>204</b> (weight estimation unit) lowers the weight of the detection result by the millimeter wave radar device <b>102</b> (radar device) in a region of the three-dimensional map corresponding to the three-dimensional shape. As a result, in the case where the three-dimensional shape is a corner shape or a circular shape and is a shape that is likely to induce erroneous detection by the radar device, it is possible to lower the weight of the detection result by the radar device.</p><p id="p-0050" num="0050">An example of the weight setting unit <b>404</b> will be explained with reference to <figref idref="DRAWINGS">FIGS. <b>6</b>A to <b>6</b>C</figref>.</p><p id="p-0051" num="0051">Consider a case where there is an own vehicle <b>601</b> as in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, there are two preceding vehicles <b>602</b> and <b>603</b> in front, and there is one large trailer <b>604</b>. It is assumed that an overhead view of the three-dimensional map obtained from the image-capturing device <b>101</b> is obtained as in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>. The broken line drawn in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref> indicates the reference of the spread angle from the sensor center, and indicates 20&#xb0;, 10&#xb0;, 0&#xb0;, &#x2212;10&#xb0;, and &#x2212;20&#xb0; from the left.</p><p id="p-0052" num="0052">By analyzing <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, the weight setting unit <b>404</b> lowers the weight of the region, if there is a specific shape. An example of it is illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref>. The horizontal axis represents the spread angle from the sensor center, and the vertical axis represents the distance. Now, in a case where a specific shape is given from the specific shape database <b>401</b> (dictionary), on an assumption that a place corresponding to the specific shape (special shape) is at a distance of &#x2212;15&#xb0; and 20 m ahead, the millimeter wave radar reliability of the region is lowered compared to the others.</p><p id="p-0053" num="0053">In this table (<figref idref="DRAWINGS">FIG. <b>6</b>C</figref>), the reliability is higher in the order of A, B, and C (A&#x3e;B&#x3e;C). C is set at +20&#xb0; and 30 m ahead because this is a blocked region where an object (preceding vehicle <b>602</b>) is present on the near side. Since <figref idref="DRAWINGS">FIG. <b>6</b>C</figref> is based on an overhead representation, it is represented two-dimensionally, but can actually have three-dimensional information. In that case, the weight can be changed in accordance with the height.</p><p id="p-0054" num="0054">With such a weight map, the importance level of the detection result of the millimeter wave radar is controlled by the weight adjustment unit <b>205</b> in the subsequent stage.</p><p id="p-0055" num="0055">Note that in particular, in a region where the shape is determined to be a guardrail or a metal object, the reflectance is generally high, and the range affected by the specific shape becomes large. Therefore, in a case where the object attribute estimation unit <b>302</b> estimates that the object is a metal body, it is necessary to apply larger weight adjustment by the weight setting unit <b>404</b>.</p><p id="p-0056" num="0056">Conversely, there is a possibility that the influence of reflection is low for an object having a low reflectance such as plastic or wood, and therefore, in a case where such estimation is performed by the object attribute estimation unit <b>302</b>, it is necessary to perform adjustment so as not to affect with the weight setting unit <b>404</b>. For example, in this case, the weight of the table given in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref> is changed to A at &#x2212;15&#xb0; and 20 m.</p><p id="p-0057" num="0057">In other words, the three-dimensional map generation unit <b>203</b> includes the object attribute estimation unit <b>302</b> (attribute estimation unit) that estimates the material of the object detected from an image captured by the image-capturing device <b>101</b>. The material of the object to be estimated is, for example, metal, stone, tree, or plastic. The radar weight map estimation unit <b>204</b> (weight estimation unit) estimates (sets) the weight of the detection result by the millimeter wave radar device <b>102</b> (radar device) for each region of the three-dimensional map from a combination of the three-dimensional shape for each region of the three-dimensional map and the material of the object. For example, a small weight is associated with a combination of a &#x201c;corner shape&#x201d; as a three-dimensional shape and a &#x201c;metal&#x201d; as a material of an object, and stored in the memory.</p><p id="p-0058" num="0058">This makes it possible to adjust the detection result by the radar device in accordance with the combination of the three-dimensional shape (e.g., corner shape) for each region of the three-dimensional map generated from the image captured by the image-capturing device and the material (e.g., metal) of the object estimated by the attribute estimation unit.</p><p id="p-0059" num="0059">The weight adjustment unit <b>205</b> adjusts the result detected by the millimeter wave radar device <b>102</b> from the weight set as described above. In a case where the existence probability and the distance/relative speed accuracy of the object are given at the time point of the object detection unit <b>202</b> of the millimeter wave radar device <b>102</b>, it is conceivable to adjust the accuracy and probability. In a case where they are not given, the weight is processed by the sensor fusion unit <b>206</b>, and may be simply added to the output of the object detection unit <b>202</b>, and the method of handling the weight does not matter.</p><p id="p-0060" num="0060">In the present embodiment, the weight adjustment unit <b>205</b> (adjustment unit) adjusts the detection result by the millimeter wave radar device <b>102</b> (radar device) on the basis of the weight. Specifically, for example, the smaller the weight becomes, the lower the reliability of the detection result by the millimeter wave radar device <b>102</b> (radar device) is evaluated. This makes it possible to adjust a detection result by the radar device in accordance with the three-dimensional shape of each region of a three-dimensional map generated from an image captured by the image-capturing device. Furthermore, it is also possible to cope with a case where the radar device detects an object that is not registered on the navigation map.</p><p id="p-0061" num="0061">Note that, as shown in at least <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the mobile body control unit <b>105</b> generates a three-dimensional map around the vehicle <b>103</b> (mobile body) from an image captured by the image-capturing device <b>101</b> (S<b>10</b>), estimates the weight of the detection result by the millimeter wave radar device <b>102</b> (radar device) for each region of the three-dimensional map from the three-dimensional shape for each region of the three-dimensional map (S<b>15</b>), and adjusts the detection result by the millimeter wave radar device <b>102</b> (radar device) on the basis of the weight (S<b>20</b>).</p><p id="p-0062" num="0062">The sensor fusion unit <b>206</b> synthesizes and outputs, to the control unit <b>207</b>, the detection results using the result detected by the millimeter wave radar device <b>102</b> and the result detected by the image-capturing device <b>101</b>. As a fusion method, a method of simply adopting one with a higher weight or probability as a detection result or a method of probabilistically performing fusion as a detection result can be considered, and the method does not matter.</p><p id="p-0063" num="0063"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example in which past history information is input to the three-dimensional map generation unit <b>203</b>.</p><p id="p-0064" num="0064">In the mode of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a map prediction unit <b>701</b> appropriately predicts, from the own vehicle behavior, the speed at each position, and the like, a three-dimensional map at a next time t+1 from a three-dimensional map at a certain time t, and the three-dimensional map generation unit <b>203</b> synthesizes the map predicted at the time t when the three-dimensional map is generated next and the map at the time t+1. The composite map is used in subsequent processing. By adopting such a mechanism, extrapolation is performed from past information (three-dimensional map) even when there is an error or lack of information in the three-dimensional map acquired from the current frame, and statistical accuracy can be expected to be improved.</p><p id="p-0065" num="0065">In other words, the mobile body control unit <b>105</b> includes the map prediction unit <b>701</b> that predicts a three-dimensional map in the next frame from a three-dimensional map. The three-dimensional map generation unit <b>203</b> generates a three-dimensional map around the vehicle <b>103</b> (mobile body) from the three-dimensional map of the next frame predicted by the map prediction unit <b>701</b> and the image captured by the image-capturing device <b>101</b>. This makes it possible to improve the accuracy of the three-dimensional map generated by the three-dimensional map generation unit using the three-dimensional map before fusion.</p><p id="p-0066" num="0066"><figref idref="DRAWINGS">FIG. <b>8</b></figref> explains an example in which past history information uses map information synthesized from information of each sensor after sensor fusion.</p><p id="p-0067" num="0067">The vehicle control system has a configuration that includes a map prediction unit <b>802</b> that predicts current map information from the fused past map information, and reflects it in the three-dimensional map generation unit <b>203</b>.</p><p id="p-0068" num="0068">In other words, the mobile body control unit <b>105</b> includes a composite map creation unit <b>801</b> that creates a three-dimensional map from the detection result synthesized by the sensor fusion unit <b>206</b>, and the map prediction unit <b>802</b> that predicts a three-dimensional map in the next frame from the three-dimensional map created by the composite map creation unit <b>801</b>. The three-dimensional map generation unit <b>203</b> generates a three-dimensional map around the vehicle <b>103</b> (mobile body) from the predicted three-dimensional map of the next frame and the image captured by the image-capturing device <b>101</b>. This makes it possible to improve the accuracy of the three-dimensional map generated by the three-dimensional map generation unit using the three-dimensional map after fusion.</p><p id="p-0069" num="0069">The present invention is not limited to the above-described embodiment, and includes various modifications. For example, the embodiment described above has been described in detail for an easy-to-understand explanation of the present invention, and is not necessarily limited to those having all the described configurations. It is also possible to replace part of the configuration of one embodiment with the configuration of another embodiment, and it is also possible to add the configuration of another embodiment to the configuration of one embodiment. It is further possible to add, delete, or replace other configurations for part of the configuration of each embodiment.</p><p id="p-0070" num="0070">In the above embodiment, the image-capturing device <b>101</b> measures the distance with a stereo camera, but may measure the distance with a monocular camera. In the above embodiment, the millimeter wave radar device <b>102</b> is used as a radar device, but a radar device using a radio wave having a wavelength other than the millimeter wave may be used.</p><p id="p-0071" num="0071">In the above embodiment, the object detection units <b>201</b> and <b>202</b> are provided in the mobile body control unit <b>105</b>, but may be provided in the image-capturing device <b>101</b> and the millimeter wave radar device <b>102</b>, respectively. In the above embodiment, the object detection units <b>201</b> and <b>202</b> are provided in the mobile body control unit <b>105</b>, but may be provided in another ECU.</p><p id="p-0072" num="0072">Some or all of the above-described configurations, functions, and the like may be implemented in hardware by designing them in an integrated circuit, for example. The above configurations, functions, and the like may be implemented by software by a processor interpreting and executing a program that implements each function. Information such as a program, a table, and a file that implement each function can be stored in a recording device such as a memory, a hard disk, and a solid state drive (SSD), or a recording medium such as an IC card, an SD card, and a DVD.</p><p id="p-0073" num="0073">The embodiment of the present invention may have the following aspects.</p><p id="p-0074" num="0074">(1). A mobile body control apparatus including an image-capturing device that detects an object in an outside world, and a millimeter wave radar device, the apparatus including: a three-dimensional map generation unit that generates a three-dimensional map around a mobile body from information of the image-capturing device; a radar weight estimation unit that estimates, from a three-dimensional shape, a weight of a detection result by the millimeter wave radar device for each region based on a distance and an azimuth using the three-dimensional map; and a weight adjustment unit that adjusts reliability of the object detected by the radar device based on a weight estimated by the radar weight estimation unit.</p><p id="p-0075" num="0075">(2). A mobile body control apparatus, in which, based on the three-dimensional map according to (1), a radar reliability estimation unit according to (1) lowers a reliability of the radar device for each azimuth and distance in a case where there is an object having a predetermined size or larger or in a case where an object has a plurality of adjacent shapes.</p><p id="p-0076" num="0076">(3). A mobile body control apparatus, in which a three-dimensional map creation unit according to (1) has a distance information generation unit and an attribute information generation unit, and the attribute information generation unit estimates, for an image-capturing target, one or more attributes of a pedestrian, a vehicle, a wall, a tree, a curbstone, a guardrail, and a pole.</p><p id="p-0077" num="0077">(4). A mobile body control apparatus, in which a three-dimensional map creation unit according to (1) has a distance information generation unit and a material information generation and the attribute information generation unit estimates, for an image-capturing target, one or more attributes of metal, stone, tree, and plastic.</p><p id="p-0078" num="0078">(5). A mobile body control apparatus including an image-capturing device that detects an object in an outside world, and a millimeter wave radar device, the apparatus including: a three-dimensional map generation unit that generates a three-dimensional map around a mobile body from information of the image-capturing device; a radar weight estimation unit that estimates, from a three-dimensional shape, a weight of a detection result by the millimeter wave radar device for each region based on a distance and an azimuth using the three-dimensional map; a weight adjustment unit that adjusts reliability of the object detected by the radar device based on a weight estimated by the radar weight estimation unit; and a sensor fusion unit that synthesizes a detection results of an image-capturing device and a millimeter wave radar based on a result of the weight adjustment unit, and outputs a detection result that is synthesized.</p><p id="p-0079" num="0079">(6). A mobile body control apparatus including an image-capturing device that detects an object in an outside world, and a millimeter wave radar device, the apparatus including: a three-dimensional map generation unit that generates a three-dimensional map around a mobile body from information of the image-capturing device; a radar weight estimation unit that estimates, from a three-dimensional shape, a weight of a detection result by the millimeter wave radar device for each region based on a distance and an azimuth using the three-dimensional map; a weight adjustment unit that adjusts reliability of the object detected by the radar device based on a weight estimated by the radar weight estimation unit; and a map prediction unit that predicts and reflects, in a three-dimensional map generation unit of a next frame, a three-dimensional map in a next frame from information of the three-dimensional map.</p><p id="p-0080" num="0080">(7). A mobile body control apparatus including an image-capturing device that detects an object in an outside world, and a millimeter wave radar device, the apparatus including: a three-dimensional map generation unit that generates a three-dimensional map around a mobile body from information of the image-capturing device; a radar weight estimation unit that estimates, from a three-dimensional shape, a weight of a detection result by the millimeter wave radar device for each region based on a distance and an azimuth using the three-dimensional map; a weight adjustment unit that adjusts reliability of the object detected by the radar device based on a weight estimated by the radar weight estimation unit; a sensor fusion unit that synthesizes detection results of an image-capturing device and a millimeter wave radar based on a result of the weight adjustment unit, and outputs a detection result that is synthesized; a composite map creation unit that creates a map from a composite result; and a map prediction unit that predicts and reflects, in a three-dimensional map generation unit of a next frame, a three-dimensional map in a next frame from information of the composite map creation unit.</p><p id="p-0081" num="0081">According to (1) to (7), even when an object not registered on a navigation map induces a detection error of a millimeter wave radar, it is possible to reduce the error and provide a highly reliable sensor system.</p><heading id="h-0011" level="1">REFERENCE SIGNS LIST</heading><p id="p-0082" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0082"><b>101</b> image-capturing device</li>    <li id="ul0002-0002" num="0083"><b>102</b> millimeter wave radar device</li>    <li id="ul0002-0003" num="0084"><b>103</b> vehicle</li>    <li id="ul0002-0004" num="0085"><b>104</b> object</li>    <li id="ul0002-0005" num="0086"><b>105</b> mobile body control unit</li>    <li id="ul0002-0006" num="0087"><b>109</b> control unit</li>    <li id="ul0002-0007" num="0088"><b>201</b> object detection unit</li>    <li id="ul0002-0008" num="0089"><b>202</b> object detection unit</li>    <li id="ul0002-0009" num="0090"><b>203</b> three-dimensional map generation unit</li>    <li id="ul0002-0010" num="0091"><b>204</b> radar weight map estimation unit</li>    <li id="ul0002-0011" num="0092"><b>205</b> weight adjustment unit</li>    <li id="ul0002-0012" num="0093"><b>206</b> sensor fusion unit</li>    <li id="ul0002-0013" num="0094"><b>207</b> control unit</li>    <li id="ul0002-0014" num="0095"><b>301</b> distance image generation unit</li>    <li id="ul0002-0015" num="0096"><b>302</b> object attribute estimation unit</li>    <li id="ul0002-0016" num="0097"><b>401</b> specific shape database</li>    <li id="ul0002-0017" num="0098"><b>402</b> specific shape detection unit</li>    <li id="ul0002-0018" num="0099"><b>403</b> object size measurement unit</li>    <li id="ul0002-0019" num="0100"><b>404</b> weight setting unit</li>    <li id="ul0002-0020" num="0101"><b>601</b> own vehicle</li>    <li id="ul0002-0021" num="0102"><b>602</b>, <b>603</b> preceding vehicle</li>    <li id="ul0002-0022" num="0103"><b>604</b> large trailer</li>    <li id="ul0002-0023" num="0104"><b>701</b> map prediction unit</li>    <li id="ul0002-0024" num="0105"><b>801</b> composite map creation unit</li>    <li id="ul0002-0025" num="0106"><b>802</b> map prediction unit</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An apparatus for controlling a mobile body that has an image-capturing device and a radar device, the apparatus comprising:<claim-text>a three-dimensional map generation unit that generates a three-dimensional map around the mobile body from an image captured by the image-capturing device;</claim-text><claim-text>a weight estimation unit that estimates, from a three-dimensional shape of each region of the three-dimensional map, a weight of a detection result by the radar device for each region of the three-dimensional map; and</claim-text><claim-text>an adjustment unit that adjusts a detection result by the radar device based on the weight.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The apparatus for controlling a mobile body according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>in a case where there is a first object having a predetermined size or larger in the three-dimensional map,</claim-text><claim-text>the weight estimation unit lowers a weight of a detection result by the radar device for each region of the three-dimensional map around the first object.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The apparatus for controlling a mobile body according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>in a case where there is a second object close to the first object in the three-dimensional map,</claim-text><claim-text>the weight estimation unit lowers a weight of a detection result by the radar device for each region of the three-dimensional map around the first object and the second object.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The apparatus for controlling a mobile body according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the three-dimensional map generation unit includes</claim-text><claim-text>an attribute estimation unit that estimates an attribute of an object detected from an image captured by the image-capturing device,</claim-text><claim-text>an attribute of the object to be estimated is</claim-text><claim-text>a pedestrian, a vehicle, a wall, a tree, a curbstone, a guardrail, or a pole, and</claim-text><claim-text>the weight estimation unit estimates</claim-text><claim-text>a weight of a detection result by the radar device for each region of the three-dimensional map from a combination of a three-dimensional shape for each region of the three-dimensional map and an attribute of the object.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The apparatus for controlling a mobile body according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the three-dimensional map generation unit includes</claim-text><claim-text>an attribute estimation unit that estimates a material of an object detected from an image captured by the image-capturing device,</claim-text><claim-text>a material of the object to be estimated is</claim-text><claim-text>metal, stone, tree, or plastic, and</claim-text><claim-text>the weight estimation unit estimates</claim-text><claim-text>a weight of a detection result by the radar device for each region of the three-dimensional map from a combination of a three-dimensional shape for each region of the three-dimensional map and a material of the object.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The apparatus for controlling a mobile body according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a sensor fusion unit that synthesizes a detection result by an image-capturing device and a detection result by the radar device adjusted based on the weight, and outputs a detection result that is synthesized.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The apparatus for controlling a mobile body according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a map prediction unit that predicts a three-dimensional map in a next frame from the three-dimensional map, wherein<claim-text>the three-dimensional map generation unit generates</claim-text><claim-text>a three-dimensional map around the mobile body from a three-dimensional map of a next frame predicted by the map prediction unit and an image captured by the image-capturing device.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The apparatus for controlling a mobile body according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:<claim-text>a composite map creation unit that creates a three-dimensional map from the detection result synthesized by the sensor fusion unit; and</claim-text><claim-text>a map prediction unit that predicts a three-dimensional map in a next frame from a three-dimensional map created by the composite map creation unit, wherein</claim-text><claim-text>the three-dimensional map generation unit generates</claim-text><claim-text>a three-dimensional map around the mobile body from a three-dimensional map of a next frame having been predicted and an image captured by the image-capturing device.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The apparatus for controlling a mobile body according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>when the three-dimensional shape is a corner shape or a circle shape,</claim-text><claim-text>the weight estimation unit lowers a weight of a detection result by the radar device in a region of the three-dimensional map corresponding to the three-dimensional shape.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A method for causing a control apparatus to execute<claim-text>a three-dimensional map generation process of generating a three-dimensional map around a mobile body from an image captured by an image-capturing device,</claim-text><claim-text>a weight estimation process of estimating a weight of a detection result by a radar device for each region of the three-dimensional map from a three-dimensional shape for each region of the three-dimensional map, and</claim-text><claim-text>an adjustment process of adjusting a detection result by the radar device based on the weight.</claim-text></claim-text></claim></claims></us-patent-application>
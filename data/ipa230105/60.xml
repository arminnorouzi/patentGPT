<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000061A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221220" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000061</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17939144</doc-number><date>20220907</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>01</class><subclass>K</subclass><main-group>61</main-group><subgroup>95</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>28</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>A</section><class>01</class><subclass>K</subclass><main-group>61</main-group><subgroup>95</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>285</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>17</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">ESCAPE DETECTION AND MITIGATION FOR AQUACULTURE</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17102947</doc-number><date>20201124</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17939144</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>X Development LLC</orgname><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>James</last-name><first-name>Barnaby John</first-name><address><city>Campbell</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Methods, systems, and apparatus, including computer programs encoded on computer-storage media, for escape detection and mitigation for aquaculture. In some implementations, a method includes obtaining one or more images that depict one or more fish within a population of fish that are located within an enclosure; providing, to one or more detection models configured to classify fish that are depicted within the images as likely being member or as likely not being member of a type of fish, the one or images; generating, as a result of providing the one or more images to the one or more detection models, a value that reflects a quantity of fish that are depicted in the images that are likely a member of the type of fish; and detecting a condition based at least on the value.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="117.43mm" wi="158.75mm" file="US20230000061A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="197.44mm" wi="146.64mm" orientation="landscape" file="US20230000061A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="190.08mm" wi="134.20mm" file="US20230000061A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="225.89mm" wi="161.88mm" orientation="landscape" file="US20230000061A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This patent application is a continuation (and claims the benefit of priority under 35 USC 120) of U.S. patent application Ser. No. 17/102,947, filed Nov. 24, 2020. The disclosure of the prior application is considered part of (and is incorporated by reference in) the disclosure of this application.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">This specification generally relates to camera controllers, particularly those that are used for underwater cameras in aquaculture.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Researchers and fish farm operators face several challenges in managing pens or other enclosures used for aquaculture. While nets or other materials may be used to enclose fish within an aquaculture environment, these materials may tear or break while in use. In an open water environment, an undetected tear may result in the escape of fish, which may have negative consequences, e.g. on a nearby population of other fish.</p><p id="p-0005" num="0004">When fish escape through a torn net of a pen, remediation efforts typically involve attempting to catch and return the escaped fish, such as by hiring sport fisherman or the use of Fjord nets. However, these methods tend to be both expensive and ineffective.</p><p id="p-0006" num="0005">Manual, direct monitoring of an enclosure to determine if fish have escaped or are escaping can be difficult, as enclosures can be large (e.g., 170 meters to 200 meters in circumferences and 35 meters deep). Further, manual processes are often time-consuming, expensive, inaccurate, and can be delayed, such as when work schedules or adverse weather conditions decrease the availability of human monitors.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0007" num="0006">In general, innovative aspects of the subject matter described in this specification relate to the escape detection and mitigation of fish.</p><p id="p-0008" num="0007">According to one implementation of the subject matter described in this specification, tears in a meshed net enclosure that contains fish native to the enclosure may be detected to prevent the escape of the native fish or the introduction of foreign fish from outside of the enclosure. A surveillance device, e.g., a camera, is used to obtain images of fish that are present within the enclosure. The obtained images of present fish may include one or more native fish as well as one or more foreign fish that have entered the enclosure through a break in the meshed net. The obtained images are used to identify the species or type of fish corresponding to the present fish, and to calculate a metric, such as a ratio, which indicates an amount of native versus foreign fish within the enclosure, or a change in the amount of native versus foreign fish in the enclosure over time. The metric is utilized as an escape risk score, which can be used by other hardware control systems to initiate automated opening detection or mitigation procedures or techniques to locate, isolate, and/or remediate possible openings in the enclosure.</p><p id="p-0009" num="0008">In some implementations, a method for escape detection and mitigation for aquaculture includes obtaining one or more images that depict one or more fish within a population of fish that are located within an enclosure; providing, to each of multiple detection models that are each configured to classify fish that are depicted within the images as likely being a member or as likely not being member of a different type of fish, the one or images; generating, as a result of providing the one or more images to the multiple detection models, a value that reflects a quantity of fish that are depicted in the images that are likely a member of each different type of fish; detecting an error condition relating to a possible opening of the enclosure based at least on the value; and in response to detecting the error condition relating to the possible opening of the enclosure, initiating one or more mitigation actions relating to the possible opening.</p><p id="p-0010" num="0009">In some implementations, initiating the one or more mitigation actions includes sending a signal to a controllable device configured to move towards a location specified in the signal relative to the enclosure.</p><p id="p-0011" num="0010">In some implementations, initiating the one or more mitigation actions includes sending signals to one or more devices configured to prevent fish entering and exiting the enclosure.</p><p id="p-0012" num="0011">In some implementations, the multiple detection models include one or more classifiers configured to aid in classifying each of the one or more fish as likely being a member or as likely not being member of a different type of fish.</p><p id="p-0013" num="0012">In some implementations, the method further includes storing locations corresponding to locations of the one or more fish enclosed within the enclosure.</p><p id="p-0014" num="0013">In some implementations, initiating the one or more mitigation actions includes determining, based in part on the locations of the one or more fish, the possible opening of the enclosure that allows fish to exit or enter.</p><p id="p-0015" num="0014">In some implementations, the method further includes sending an alert to a user based on user preferences, where the alert includes information used in initiating the one or more mitigation actions.</p><p id="p-0016" num="0015">In some implementations, the multiple detection models include a machine learning model trained using images of the different type of fish.</p><p id="p-0017" num="0016">Advantageous implementations can include one or more of the following features. For example, the indirect nature of population tracking allows effective detection of escapes and unintended enclosure openings without the effort of directly monitoring an enclosure for visual signs of tears or escapes. Given the typical size of enclosures, the direct method of monitoring the enclosure may require additional resources compared to the indirect method of population detection and tracking outlined in this specification. In addition, obtaining locations of one or more fish within the enclosure can be used to directly identify potential openings that allow foreign fish to enter the enclosure and native fish to exit the enclosure. Using these techniques, automated escape detection techniques can be initiated when the risk of an escape or unintended fish entry through an opening is high, and are avoided or eliminated when the risk of an escape is low, reducing unnecessary demand and wear-and-tear on surveillance devices, and preserving surveillance resources for other, higher priority surveillance tasks.</p><p id="p-0018" num="0017">The details of one or more embodiments of the invention are set forth in the accompanying drawings and the description below. Other features and advantages of the invention will become apparent from the description, the drawings, and the claims.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing an example of an escape detection and mitigation system.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is flow diagram illustrating an example of a process for escape detection and mitigation.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram of computer system components that can be used in an escape detection and mitigation system.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0022" num="0021">Like reference numbers and designations in the various drawings indicate like elements.</p><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram showing an example of an escape detection and mitigation system <b>100</b>. The system <b>100</b> is configured to detect different types of fish within a fish net enclosure <b>101</b> and to track the populations of those different types of fish, e.g., different species such as salmon, mackerel, cleaner fish such as wrasse and lumpfish, among others. The system <b>100</b> is then configured to detect relative increases or other changes in the populations of the different types of fish, e.g., over time, as a proxy for escape detection. The system <b>100</b> is then configured to perform detection or mitigation actions that are designed to prevent native fish escaping from the enclosure <b>101</b> and to prevent foreign fish from entering the enclosure <b>101</b>.</p><p id="p-0024" num="0023">The system <b>100</b> includes the fish net enclosure <b>101</b> for the native fish shown in school <b>102</b><i>a</i>, school <b>102</b><i>b</i>, and fish <b>102</b><i>c</i>. Within this specification, native fish refer to fish that are initially enclosed within the enclosure <b>101</b> but may move out of the enclosure <b>101</b> through an opening such as opening <b>111</b> while foreign fish refer to fish that are initially not enclosed within the enclosure <b>101</b> but may move into the enclosure <b>101</b> through an opening such as the opening <b>111</b>. The system also includes a control unit <b>103</b> that is communicably connected to a surveillance device <b>107</b>. The control unit <b>103</b> is configured to send control signals to the surveillance device <b>107</b> as well as receive information from the surveillance device <b>107</b>. The surveillance device <b>107</b> is configured to move and to record images of fish.</p><p id="p-0025" num="0024">Stages A through C of <figref idref="DRAWINGS">FIG. <b>1</b></figref> depict an example of the operation of the system <b>100</b>. Specifically, in stage A, the surveillance device <b>107</b> patrols the enclosure <b>101</b>. The surveillance device <b>107</b> receives one or more signals from the movement controller <b>104</b>. The one or more signals can be used by the surveillance device <b>107</b> to inform movement around the enclosure <b>101</b>.</p><p id="p-0026" num="0025">In some implementations, the surveillance device <b>107</b> prioritizes escape detection in relation to one or more other tasks. For example, the surveillance device <b>107</b> can be used for multiple purposes such as fish identification, feeding tracking, behavior tracking, population identification, escape detection, general surveillance, among others. In some cases, the surveillance device <b>107</b> prioritizes actions related to escape detection when the risk of an escape caused by a tear, crack or other opening in the enclosure <b>101</b>, is above a predetermined threshold. By prioritizing actions, the surveillance device <b>107</b> may perform escape mitigation or detection actions less frequently. By prioritizing actions, the surveillance device <b>107</b> may also conserve resources, such as energy, data storage or other limited resources. These resources may be saved for actions with greater priority. Similarly, by prioritizing actions, the surveillance device <b>107</b> can perform only high priority actions thereby potentially reducing wear and tear on physical mechanisms.</p><p id="p-0027" num="0026">During patrol, the surveillance device <b>107</b> captures images of fish including one or more images of a foreign fish <b>109</b><i>a</i>. The foreign fish <b>109</b><i>a </i>is a fish with characteristics different from the native fish shown in schools <b>102</b><i>a </i>and <b>102</b><i>b</i>. The foreign fish or fishes <b>109</b><i>a</i>, <b>109</b><i>b</i>, and <b>109</b><i>c </i>enter the enclosure <b>101</b> through the opening <b>111</b> made in the enclosure <b>101</b>. Similarly, the native fish <b>102</b><i>c </i>escapes through the opening <b>111</b>. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the opening <b>111</b> is a tear in the fish net of the enclosure <b>101</b>.</p><p id="p-0028" num="0027">Although the detection and identification of the foreign fish <b>109</b><i>a </i>is considered in detail, the system <b>100</b> is similarly configured to detect and identify the native fish of schools <b>102</b><i>a </i>and <b>102</b><i>b </i>as well as other foreign fish <b>109</b><i>b </i>and <b>109</b><i>c</i>. The techniques used to detect and identify the foreign fish <b>109</b><i>a</i>, for example, can be used to detect and identify each of the fish of the native fish of schools <b>102</b><i>a </i>and <b>102</b><i>b</i>. In some implementations, a trained model uses alternative classifiers to detect or identify the foreign fish <b>109</b><i>a </i>and the native fish of schools <b>102</b><i>a </i>and <b>102</b><i>b</i>. For example, the trained model can use a classifier corresponding to native fish to detect or identify the native fish of schools <b>102</b><i>a </i>and <b>102</b><i>b </i>and can use a classifier corresponding to foreign fish to detect or identify the foreign fish <b>109</b><i>a </i>among other potential foreign fish such as foreign fish <b>109</b><i>b </i>and <b>109</b><i>c. </i></p><p id="p-0029" num="0028">The surveillance device <b>107</b> sends the captured one or more images of the foreign fish <b>109</b><i>a </i>to the control unit <b>103</b>. In some cases, the surveillance device <b>107</b> also sends a location, e.g., depth, net grid, direction, position coordinates, radial position, enclosure identifier, quadrant or other sectional identifier, among others, corresponding to a present location of the foreign fish <b>109</b><i>a</i>. The captured one or more images of the foreign fish <b>109</b><i>a </i>may include visual portions that do not include the foreign fish <b>109</b><i>a </i>and visual portions that do include the foreign fish <b>109</b><i>a</i>. The control unit <b>109</b><i>a </i>can use any appropriate processing technique, such as a technique that uses image recognition to identify borders of the foreign fish <b>109</b><i>a </i>relative to a background or to detect predetermined markers on the body of the foreign fish <b>109</b><i>a</i>, e.g., nose of fish, tail of fish, or the like, in order to detect the foreign fish <b>109</b><i>a </i>within the captured one or more images. Any appropriate data processing technique known in the art may be used.</p><p id="p-0030" num="0029">In stage B, the control unit <b>103</b> uses a fish detection module <b>113</b> to analyze the one or more images of the foreign fish <b>109</b><i>a </i>as shown in item <b>114</b>. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the fish detection module <b>113</b> includes a truss network generator that generates a truss network <b>115</b> for the foreign fish <b>109</b><i>a </i>based on the captured one or more images of the foreign fish <b>109</b><i>a</i>. The truss network <b>115</b> can be used, in part, to determine the type of the foreign fish <b>109</b><i>a</i>. Depending on implementation, the type of the foreign fish <b>109</b><i>a </i>includes either a species identifier, a sub-species identifier, a distinctive element identifier, a health condition identifier, among others. The truss network <b>115</b> includes multiple values representing distances between various points on the body of the foreign fish <b>109</b><i>a. </i></p><p id="p-0031" num="0030">Based, at least, on the multiple values, the fish detection module <b>113</b> can determine a type of fish corresponding to the foreign fish <b>109</b><i>a</i>. For example, in situations where the native fish shown in schools <b>102</b><i>a </i>and <b>102</b><i>b </i>are salmon fish, the foreign fish <b>109</b><i>a </i>may be detected as a type of cleaner fish, Mackerel, or any other type of marine animal that is distinct from the native fish. The types of fishes that compose either the native fish shown in schools <b>102</b><i>a </i>and <b>102</b><i>b </i>or the foreign fish or fishes <b>109</b><i>a</i>, <b>109</b><i>b</i>, <b>109</b><i>c</i>, and <b>109</b><i>d</i>, is not limited in the present specification.</p><p id="p-0032" num="0031">In some implementations, the fish detection module <b>113</b> uses one or more classifiers. For example, the fish detection module <b>113</b> can use a salmon model classifier to detect salmon, a mackerel model classifier to detect mackerel, a cleaner fish model classifier to detect cleaner fish, and so forth. In some cases, one or more classifiers are applied to one or more images in order to detect a given fish within the one or more images. In some cases, specific classifiers are updated based on one or more detections. In some cases, subcategories of salmon, mackerel, cleaner fish (e.g., wrasse, lumpfish), or other types of fish can be detected and classified using classifiers configured to detect the given subcategories.</p><p id="p-0033" num="0032">In some implementations, detections of a first category or species of fish are not used to compute a value, such as a ratio, that reflects a quantity of fish that are depicted in one or more captured images. For example, the fish detection module <b>113</b> can use a salmon model classifier to detect salmon, a mackerel model classifier to detect mackerel, a cleaner fish model classifier to detect cleaner fish, and so forth. The system <b>100</b> may use only the detections of salmon and mackerel to trigger subsequent actions. The detections of one category of fish, e.g., cleaner fish, can be filtered from the data such that one or more other categories, e.g., salmon and mackerel, are used to generate a calculated value, e.g., a ratio.</p><p id="p-0034" num="0033">In some implementations, the cleaner fish are included in a sum total of native fish. For example, in an example where salmon fish are native, the number of cleaner fish detections can be added to the number of salmon detections to create a sum of native fish detections. The sum of native fish detections can then be used to generate a ratio that includes the sum of native fish detections and the sum of foreign fish detections.</p><p id="p-0035" num="0034">In some implementations, the fish detection module <b>113</b> uses classifiers that have been trained to identify different types of fish. For example, classifiers can be configured to detect subcategories of species or distinct species within a group of fish. The classifiers can be trained to detect different features, e.g., patterns, colors, truss lengths, distinctive elements, or the like, that are associated with a specific subcategory of a species or a specific species depending on implementation. After being trained to detect various features, the classifiers can be used to detect the various features in new obtained images. The detection of one or more features by a classifier that has been trained can then be used to identify a given fish as a member of a specific subcategory of species or a specific species.</p><p id="p-0036" num="0035">Based on the detection of the fish detection module <b>113</b>, a tracker module <b>117</b> generates a metric that records the current amount of the foreign fish <b>109</b><i>a</i>, e.g., as an isolated value or as a ratio of wild fish to farmed fish, and optionally any previous metrics associated with prior or subsequently determined metrics. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the tracker module <b>117</b> records a location of the foreign fish <b>109</b><i>a </i>based on the location, or other information, sent by the surveillance device <b>107</b> to the control unit <b>103</b>.</p><p id="p-0037" num="0036">The tracker module <b>117</b> adds the location of the foreign fish <b>109</b><i>a </i>to a stored map that includes one or more other stored locations of other fish. A visual representation of the stored map is shown in item <b>118</b> in which visual distinct elements denote fish of different categories. For example, native fish are illustrated as black dots in the visual representation of the stored map shown in item <b>118</b> and foreign fish are illustrated as grey dots in the visual representation of the stored map shown in item <b>118</b>. In general, any visual representation may be presented to a user to show locations of one or more fish based on detections performed by the fish detection module <b>113</b>. In some cases, the location of the foreign fish <b>109</b><i>a </i>includes a radial position or depth value.</p><p id="p-0038" num="0037">The tracker module <b>117</b> increments a value of the metric corresponding to the cumulative number of foreign fish detected by the fish detection module <b>117</b> based on the detection of the foreign fish <b>109</b><i>a </i>as a foreign fish. This value is used to generate an escape risk score. A visualization of the running totals of foreign fish and native fish in the enclosure <b>101</b> is shown in item <b>119</b> in which the number of Fish Type B corresponds to the number of foreign fish (e.g., foreign fish <b>109</b><i>a</i>, <b>109</b><i>b</i>, and <b>109</b><i>c</i>) and the number of Fish Type A corresponds to the number of native fish (e.g., schools <b>102</b><i>a </i>and <b>102</b><i>b</i>).</p><p id="p-0039" num="0038">At a point shown visually in item <b>121</b>, the number of foreign fish increases relative to the number of native fish. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a trigger detection module <b>123</b> detects that the ratio of foreign fish to native fish has exceeded a threshold <b>122</b>, i.e., the risk of an escape is detected to be high where an escape can include not only native fish escaping from the enclosure <b>101</b> but foreign fish entering the enclosure <b>101</b> through an opening such as the opening <b>111</b>. The trigger detection module <b>123</b> generates detection output <b>124</b> based on corresponding information of the detection of the foreign fish <b>109</b><i>a </i>or any preceding or subsequent detections. For example, the detection output <b>124</b> can include a likely location of an opening such as a tear corresponding to the location of the opening <b>111</b>. The location of the opening <b>111</b> can be informed by the location of one or more detected fish as shown in item <b>118</b>.</p><p id="p-0040" num="0039">In some implementations, the trigger detection module <b>123</b> detects an increase of the number of foreign fish within a predetermined amount of time. For example, the trigger detection module <b>123</b> can record an increase of foreign fish within an hour. If the trigger detection module <b>123</b> detects a sufficient number of foreign fish within the hour, the trigger detection module <b>123</b> can determine that there is likely a tear, hole, or other opening in the enclosure <b>101</b>. If the trigger detection module <b>123</b> detects a sufficient number of foreign fish but it takes longer than an hour, the trigger detection module <b>123</b> can make an alternate determination. For example, in some cases, a slow rate of foreign fish detections can be caused by small fish swimming into the enclosure <b>101</b> and then growing over time.</p><p id="p-0041" num="0040">In some implementations, a rate of foreign fish detections is used. For example, the tracker module <b>117</b> can record the number of foreign fish detections per a predetermined time period, e.g., second, minute, or the like. The number of foreign fish detections per the predetermined time period can be a rate of foreign fish detections. Based on the rate of foreign fish detections, the trigger detection module <b>123</b> can detect a sufficient increase in foreign fish that satisfies a threshold. For example, if the rate of foreign fish detections is above a certain threshold, the trigger detection module <b>123</b> can generate output that indicates a high likelihood that there is an opening and that subsequent actions, such as mitigation actions, should be performed. In some cases, satisfying a threshold includes determining a rate is above a threshold for a predetermined amount of time in order to prevent brief increases in detection rates that may be spurious from triggering subsequent actions.</p><p id="p-0042" num="0041">The control unit <b>103</b>, based on the detection output <b>124</b>, sends information to the surveillance device <b>107</b>. In some cases, the information is configured to instruct the surveillance device <b>107</b> to move to another location <b>125</b> that is near a likely tear or opening. The surveillance device <b>107</b> depicted at location <b>125</b> can then proceed in carrying out mitigation techniques or obtaining additional information concerning the opening <b>111</b>. In some cases, mitigation techniques include repairs to the enclosure <b>101</b> or movements programmed to help prevent foreign fish from making their way into the enclosure <b>101</b> and to keep native fish from escaping.</p><p id="p-0043" num="0042">In some implementations, automated escape detection techniques of the system <b>100</b> are initiated when the risk of an escape is high, and are avoided or eliminated when the risk of an escape is low. In this way, the system <b>100</b> can reduce unnecessary demand and wear-and-tear on surveillance devices such as the surveillance device <b>107</b>, and preserve surveillance resources for other, higher priority surveillance tasks, such as tasks that have been prioritized above automated escape detection techniques based on a given risk score of a potential escape. The risk of an escape may represent a risk that native fish may be able to escape the enclosure <b>101</b> and foreign fish may be able to enter the enclosure <b>101</b>.</p><p id="p-0044" num="0043">In some implementations, the surveillance device <b>107</b> is outfitted with repair tools that enable the surveillance device <b>107</b> to repair the tear in the net of the enclosure <b>101</b> corresponding to the opening <b>111</b>. For example, the surveillance device <b>107</b> can use fasteners to connect opposing sides of the opening <b>111</b> to prevent native fish escaping or foreign fish entering.</p><p id="p-0045" num="0044">In some implementations, the enclosure <b>101</b> is a self-healing enclosure. For example, actuators can be embedded in the enclosure <b>101</b> and can then be controlled to close or open portions of the enclosure <b>101</b>. When the location of an opening is detected based on the determinations of the control unit <b>103</b>, signals can be sent to one or more actuators of the enclosure <b>101</b> within the vicinity of the suspected opening location with instructions to actuate or in other ways close any unintended opening. In some cases, subsequent data tracking by the control unit <b>103</b> can be used to determine if the actuators of the enclosure <b>101</b> were successful in closing the suspected opening location. If not, a search method that includes actuating other actuators in the vicinity of the initially activated actuators may be used until corresponding data tracking establishes that, based on determined values, the suspected opening location is closed.</p><p id="p-0046" num="0045">In some implementations, the surveillance device <b>107</b> uses programed movements to help prevent foreign fish from making their way into the enclosure <b>101</b> and to keep native fish from escaping. For example, the surveillance device <b>107</b> can use sensors onboard, or information sent by the control unit <b>103</b>, to locate the opening <b>111</b> and position itself such that the surveillance device <b>107</b> physically blocks the opening <b>111</b>. In some cases, extendable fans or other tools available to the surveillance device <b>107</b> may be used to block the opening <b>111</b>.</p><p id="p-0047" num="0046">In some implementations, sounds or other deterrents are used to deter entering or exiting through the opening <b>111</b>. For example, the surveillance device <b>107</b> may navigate within a vicinity of the opening <b>111</b> and use speaker devices to play audio designed to scare away one or more types of fish. The audio may resemble sounds of predators or may be loud or otherwise disturbing to a given fish. The audio may also be appealing and lure fish into a given location away from the opening <b>111</b>.</p><p id="p-0048" num="0047">In some implementations, attractors are used in response to an opening detection of the detection output <b>124</b> in order to control the locations of the fish in the enclosure <b>111</b>. For example, food may be distributed within a predetermined location away from the opening <b>111</b> such that fish are attracted away from the opening <b>111</b>. Any other attractive device known in the art may similarly be used.</p><p id="p-0049" num="0048">In some implementations, dynamic blocking elements are used to prevent entering and exiting through the opening <b>111</b>. For example, the surveillance device <b>107</b> can move to the location <b>125</b> and place a blocking element over the opening <b>111</b> in order to prevent or mitigate entering and exiting through the opening <b>111</b>. In some cases, any device known in the art may be used, either onboard the surveillance device <b>107</b> or within the vicinity of the enclosure <b>101</b>, to prevent entering and exiting through the opening <b>111</b>. For example, the surveillance device <b>107</b> can use onboard water vents to create water currents in the vicinity of the opening <b>111</b>. The water currents can be created to make entering and exiting through the opening <b>111</b> more difficult for fish. For example, water currents can be generated across the opening <b>111</b> such that a given fish attempting to enter or exit through the opening is impeded.</p><p id="p-0050" num="0049">In some implementations, other robots or devices are used to carry out one or more actions attributed to one or more of the entities in the system <b>100</b>. For example, instead of the surveillance device <b>107</b> navigating to the vicinity of the opening <b>111</b>, a second or third robot can be alerted and can move towards the opening <b>111</b> to perform subsequent tasks. In some cases, the control unit <b>103</b>, or another device communicably connected to the control unit <b>103</b>, is used to send one or more signals to the second or third robot such that the second or third robot performs one or more actions relevant to the enclosure <b>101</b> or one or more fish in the vicinity of the enclosure <b>101</b>.</p><p id="p-0051" num="0050">In some implementations, the control unit <b>103</b> alerts one or more users based on alert preferences and the detection output <b>124</b>. For example, the control unit <b>103</b> can send a message to a communicable connected device of a user with a notification detailing a likely tear in the net of the enclosure <b>101</b> as well as other information collected by the system <b>100</b>. In general, any party may be informed of any given process performed or event detected by the system <b>100</b>. The information sent to any given party may be presented according to one or more predetermined notification preferences that may be specific to the given party.</p><p id="p-0052" num="0051">In some implementations, the surveillance device <b>107</b> can continue to send images to the control unit <b>103</b>. The control unit <b>103</b> can monitor the ratio of foreign fish to native fish. Other thresholds may be used within mitigation techniques. For example, if the ratio of foreign fish to native fish has remained constant for a predetermined amount of time, the control unit <b>103</b> can alert the user that a given mitigation technique has been successful. In this case, both a predetermined amount of time and a predetermined rate of change can be used to determine if the ratio of foreign fish to native fish has remained constant for the predetermined amount of time.</p><p id="p-0053" num="0052">In some implementations, the surveillance device <b>107</b> sends other information to the control unit <b>103</b>. For example, the surveillance device <b>107</b> can send a current orientation to the control unit <b>103</b>. The current orientation can include a current direction in which a camera affixed to the surveillance device <b>107</b> is pointing. The current orientation can incorporate an attitude of the surveillance device <b>107</b>. The current orientation can also incorporate pitch, roll, yaw, or the like. In general, any method to locate and orient a device in three dimensional space can be used. Corresponding information for a given method to orient or locate the surveillance device <b>107</b> can be sent by the surveillance device <b>107</b> to the control unit <b>103</b>.</p><p id="p-0054" num="0053">In some implementations, the location is inferred based on other information sent by the surveillance device <b>107</b> to the control unit <b>103</b>. For example, the fish detection module <b>113</b> can obtain a location of the surveillance device <b>107</b> at a current time corresponding to when the one or more images of the foreign fish <b>109</b><i>a </i>are captured by the surveillance device <b>107</b>. Based on the location of the surveillance device <b>107</b> and the one or more images of the foreign fish <b>109</b><i>a</i>, a location of the foreign fish <b>109</b><i>a </i>may be inferred. In some cases, the truss network <b>115</b> is used to determine a likely distance between the foreign fish <b>109</b><i>a </i>and the surveillance device <b>107</b> at the time the one or more images of the foreign fish <b>109</b><i>a </i>are captured.</p><p id="p-0055" num="0054">In some implementations, sequences of images are used to determine a direction of travel of the foreign fish <b>109</b><i>a</i>. For example, the control unit <b>103</b> can obtain a plurality of images of the foreign fish <b>109</b><i>a</i>. The control unit <b>103</b>, using the fish detection module <b>113</b> can determine that the foreign fish <b>109</b><i>a </i>is heading in a current direction at a current rate of speed. Based on the determined current direction and current rate of speed, the fish detection module <b>113</b> can determine a subsequent location of the foreign fish <b>109</b><i>a </i>at some point after capturing the images.</p><p id="p-0056" num="0055">In some implementations, the location is inferred based on orientation information sent by the surveillance device <b>107</b>. For example, the surveillance device <b>107</b> can send a current orientation and location of the surveillance device <b>107</b> along with the one or more images of the foreign fish <b>109</b><i>a </i>to the fish detection module <b>113</b>. The fish detection module <b>113</b> can use one or more of the orientation, location, and the one or more images of the foreign fish <b>109</b><i>a </i>to determine a location of the foreign fish <b>109</b><i>a. </i></p><p id="p-0057" num="0056">In some implementations, the native fish and foreign fish are the same species but do not share one or more characteristics. For example, the native fish may be a particular sub-species. The fish detection module <b>113</b> can detect a fish as belonging to the particular sub-species as a native fish and a fish not belonging to the particular sub-species as a foreign fish. The fish detection module <b>113</b> can make the classifications of foreign and native fish based on pre-stored data that describes one or more features that define a foreign fish and one or more features that define a native fish.</p><p id="p-0058" num="0057">In some implementations, the non-shared characteristics between the native fish and foreign fish are generated externally by another process. For example, native fish can be tagged with distinctive elements such as visual elements (e.g., plastic markers, clipped fins, or the like) or non-visual elements (e.g., electronic chips, beacons, or the like). The surveillance device <b>107</b> can then patrol and obtain relevant data of distinctive elements (e.g., a image of a visual distinctive element or non-visual data of non-visual distinctive element) for a given fish such that the fish detection module <b>113</b> obtains data corresponding to the distinctive elements of the given fish and detects a type of the given fish based on the detected distinctive elements.</p><p id="p-0059" num="0058">In some implementations, fish detected by the fish detection module <b>113</b> that do not correspond to any known fish type may be classified in a separate category such as unknown. For example, the fish detection module <b>113</b> can analyze data obtained by the surveillance device <b>107</b> and compare it with predetermined data for a given number of fish types. If the fish detection module <b>113</b> is unable to match the given obtained data to any predetermined fish type, the fish detection module <b>113</b> can mark the fish as unknown and tally the result accordingly to system settings. For example, an unknown fish may be included into an existing category such as a native fish or be included in a third category that is neither foreign fish nor native fish. In some cases, the third category can be used to generate a processing value used to determine whether or not a triggering event, such as an event shown in item <b>121</b> is detected by the trigger detection module <b>123</b>.</p><p id="p-0060" num="0059">In some implementations, instead of the threshold <b>122</b>, another trigger is used by the system <b>100</b> to generate the detection output <b>124</b>. For example, the tracker module <b>117</b> can track a level of change in a given fish category's population over a given amount of time. The trigger detection module <b>123</b>, based on detecting a predetermined level of change can then generate the detection output <b>124</b> that includes information relevant to the level of change detected as well as potential areas of interest around the enclosure <b>101</b>.</p><p id="p-0061" num="0060">In some implementations, other processing values can be used as thresholds for the trigger detection module <b>123</b>. For example, instead of a threshold <b>122</b> of Fish Type A to Fish Type B as shown in item <b>119</b>, the trigger detection module <b>123</b> can compute one or more processing values based on one or more values representing a current or past number of native fish, a current or past number of foreign fish, a current or past number of a third category of sightings, or other relevant parameters. The resulting one or more processing values can then be used by the trigger detection module <b>123</b> to determine if a given event is taking place.</p><p id="p-0062" num="0061">In some implementations, a type of machine learning model is used to detect whether or not an event occurred or whether or not to generate the detection output <b>124</b>. For example, a given machine learning model used in the system <b>100</b> may be trained on historical data of fish escapes. The machine learning model can be trained to classify one or more given situations as corresponding to a given event. For example, a machine learning model can determine a potential fish escape based on historical data of fish escapes used as training data.</p><p id="p-0063" num="0062">In some implementations, a type of machine learning model is used to detect where an event took place based on one or more recorded location items. For example, as shown in the visual representation of the stored map shown in item <b>118</b>, the system <b>100</b> records a number of locations corresponding to given fish detections. Based on the positioning of one or more of the locations, a machine learning model, trained with historical positioning data, can be used to determine a likely opening, such as the opening <b>111</b> based on information corresponding to the stored map shown in item <b>118</b>.</p><p id="p-0064" num="0063">In some implementations, other processing techniques can be used by the fish detection module <b>113</b> in order to detect a fish. For example, instead of generating a truss network, the fish detection module <b>113</b> can obtain an electronic signal captured by the surveillance device <b>107</b> from a chip embedded in a fish such as a native fish of the school <b>102</b><i>a</i>. The fish detection module <b>113</b> can compare the electronic signal to known electronic signals of native fish and determine the type of fish based on the comparison.</p><p id="p-0065" num="0064">In some implementations, other processing techniques can be used by the fish detection module <b>113</b> in order to detect or identify a fish within the captured one or more images. For example, instead of generating a truss network, the fish detection module <b>113</b> can use object detection or another form of image processing to detect a first visual portion of the obtained one or more images. The first visual portion may contain a distinctive visual element such as a tag, unique fin clipping, or other distinct element. The fish detection module <b>113</b> can identify, based at least in part on the first visual portion, the corresponding type of fish captured in the first visual portions of the obtained one or more images.</p><p id="p-0066" num="0065">In some implementations, the control unit <b>103</b> is a device onboard the surveillance device <b>107</b>. For example, the surveillance device <b>107</b> can be a submersible with one or more compartments or attachments devoted to the processing described with respect to the control unit <b>103</b>. In some cases, one or more other surveillance devices can connect with the control unit <b>103</b> fixed onto the body of the surveillance device <b>107</b> such that the control unit <b>103</b> can process multiple signals for multiple surveillance devices.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart illustrating an example of a process <b>200</b> for escape detection and mitigation. The process <b>200</b> may be performed by one or more electronic systems, for example, the system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0068" num="0067">The process <b>200</b> includes capturing images of fish within an enclosure (<b>202</b>). For example, as shown <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the surveillance device <b>107</b> patrols the enclosure <b>101</b>. During patrol, the surveillance device <b>107</b> captures images of fish including one or more images of native fish in schools <b>102</b><i>a </i>or <b>102</b><i>b</i>. The surveillance device <b>107</b> similarly captures images of the foreign fish <b>109</b><i>a</i>. The foreign fish <b>109</b><i>a </i>is a fish with characteristics different from the native fish shown in schools <b>102</b><i>a </i>and <b>102</b><i>b</i>. The foreign fish or fishes <b>109</b><i>a</i>, <b>109</b><i>b</i>, and <b>109</b><i>c </i>enter the enclosure <b>101</b> through an opening <b>111</b> made in the enclosure <b>101</b>. Similarly, the native fish <b>102</b><i>c </i>escapes through the opening <b>111</b>.</p><p id="p-0069" num="0068">The process <b>200</b> includes categorizing one or more fish of the enclosure using a detection model (<b>204</b>). For example, the surveillance device <b>107</b> sends information corresponding to the foreign fish <b>109</b><i>a </i>to the control unit <b>103</b>. Based on the information, the control unit <b>103</b> and the fish detection module <b>113</b> categorize the foreign fish <b>109</b><i>a </i>as a foreign fish. The surveillance device <b>107</b> may also send information corresponding to one or more native fish of the schools <b>102</b><i>a </i>or <b>102</b><i>b </i>to the control unit <b>103</b>. The information corresponding to the one or more native fish of the schools <b>102</b><i>a </i>or <b>102</b><i>b </i>can be used by the control unit <b>103</b> to detect and identify the one or more native fish of the schools <b>102</b><i>a </i>or <b>102</b><i>b </i>as native fish.</p><p id="p-0070" num="0069">The process <b>200</b> includes recording the detections of one or more fish over time (<b>206</b>). For example, as shown in item <b>114</b>, and items <b>118</b> and <b>119</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the locations as well as a number of different types of fish are recorded. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the ratio of Fish Type A, native fish, to Fish Type B, foreign fish, is tracked by the tracker module <b>117</b> as shown in item <b>119</b>. In addition, the locations of the various fish in the enclosure <b>101</b> is shown in item <b>118</b>. Depending on implementation, other parameters or factors may be recorded.</p><p id="p-0071" num="0070">The process <b>200</b> includes detecting a change in the ratio of native fish to foreign fish (<b>208</b>). For example, in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the trigger detection module <b>123</b> detects that the ratio of foreign fish to native fish has exceeded the threshold <b>122</b> as shown in item <b>114</b>. As discussed above, in other implementations, other parameters corresponding to one or more fish detections in the enclosure <b>101</b> can be monitored.</p><p id="p-0072" num="0071">The process <b>200</b> includes triggering detection and mitigation protocol (<b>210</b>). For example, the trigger detection module <b>123</b> can generate detection output <b>124</b> based on corresponding information of the detection of the foreign fish <b>109</b><i>a </i>or any preceding or subsequent detections. For example, the detection output <b>124</b> can include a likely location of a tear corresponding to the location of the opening <b>111</b>. The location of the tear can be informed by the location of one or more detected fish as shown in item <b>118</b>.</p><p id="p-0073" num="0072">In some implementations, the control unit <b>103</b>, based on the detection output <b>124</b>, sends information to the surveillance device <b>107</b>. In some cases, the information is configured to instruct the surveillance device <b>107</b> to move to the location <b>125</b> that is near a likely tear or opening. The surveillance device <b>107</b> depicted at location <b>125</b> can then proceed in carrying out mitigation techniques. In some cases, mitigation techniques include repairs to the enclosure <b>101</b> or movements programmed to help prevent foreign fish from making their way into the enclosure <b>101</b> and to keep native fish from escaping as discussed above.</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram of computer system <b>300</b> components that can be used to implement a system for escape detection and mitigation such as the system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0075" num="0074">Computing device <b>300</b> is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers. Computing device <b>350</b> is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices. Additionally, computing device <b>300</b> or <b>350</b> can include Universal Serial Bus (USB) flash drives. The USB flash drives can store operating systems and other applications. The USB flash drives can include input/output components, such as a wireless transmitter or USB connector that can be inserted into a USB port of another computing device. The components shown here, their connections and relationships, and their functions, are meant to be examples only, and are not meant to limit implementations of the inventions described and/or claimed in this document.</p><p id="p-0076" num="0075">Computing device <b>300</b> includes a processor <b>302</b>, memory <b>304</b>, a storage device <b>308</b>, a high-speed interface <b>308</b> connecting to memory <b>304</b> and high-speed expansion ports <b>310</b>, and a low speed interface <b>312</b> connecting to low speed bus <b>314</b> and storage device <b>308</b>. Each of the components <b>302</b>, <b>304</b>, <b>308</b>, <b>308</b>, <b>310</b>, and <b>312</b>, are interconnected using various busses, and can be mounted on a common motherboard or in other manners as appropriate. The processor <b>302</b> can process instructions for execution within the computing device <b>300</b>, including instructions stored in the memory <b>304</b> or on the storage device <b>308</b> to display graphical information for a GUI on an external input/output device, such as display <b>316</b> coupled to high speed interface <b>308</b>. In other implementations, multiple processors and/or multiple buses can be used, as appropriate, along with multiple memories and types of memory. Also, multiple computing devices <b>300</b> can be connected, with each device providing portions of the necessary operations, e.g., as a server bank, a group of blade servers, or a multi-processor system.</p><p id="p-0077" num="0076">The memory <b>304</b> stores information within the computing device <b>300</b>. In one implementation, the memory <b>304</b> is a volatile memory unit or units. In another implementation, the memory <b>304</b> is a non-volatile memory unit or units. The memory <b>304</b> can also be another form of computer-readable medium, such as a magnetic or optical disk.</p><p id="p-0078" num="0077">The storage device <b>308</b> is capable of providing mass storage for the computing device <b>300</b>. In one implementation, the storage device <b>308</b> can be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid-state memory device, or an array of devices, including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product can also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the memory <b>304</b>, the storage device <b>308</b>, or memory on processor <b>302</b>.</p><p id="p-0079" num="0078">The high-speed controller <b>308</b> manages bandwidth-intensive operations for the computing device <b>300</b>, while the low speed controller <b>312</b> manages lower bandwidth intensive operations. Such allocation of functions is only an example. In one implementation, the high-speed controller <b>308</b> is coupled to memory <b>304</b>, display <b>316</b>, e.g., through a graphics processor or accelerator, and to high-speed expansion ports <b>310</b>, which can accept various expansion cards (not shown). In the implementation, low-speed controller <b>312</b> is coupled to storage device <b>308</b> and low-speed expansion port <b>314</b>. The low-speed expansion port, which can include various communication ports, e.g., USB, Bluetooth, Ethernet, wireless Ethernet can be coupled to one or more input/output devices, such as a keyboard, a pointing device, microphone/speaker pair, a scanner, or a networking device such as a switch or router, e.g., through a network adapter. The computing device <b>300</b> can be implemented in a number of different forms, as shown in the figure. For example, it can be implemented as a standard server <b>320</b>, or multiple times in a group of such servers. It can also be implemented as part of a rack server system <b>324</b>. In addition, it can be implemented in a personal computer such as a laptop computer <b>322</b>. Alternatively, components from computing device <b>300</b> can be combined with other components in a mobile device (not shown), such as device <b>350</b>. Each of such devices can contain one or more of computing device <b>300</b>, <b>350</b>, and an entire system can be made up of multiple computing devices <b>300</b>, <b>350</b> communicating with each other.</p><p id="p-0080" num="0079">The computing device <b>300</b> can be implemented in a number of different forms, as shown in the figure. For example, it can be implemented as a standard server <b>320</b>, or multiple times in a group of such servers. It can also be implemented as part of a rack server system <b>324</b>. In addition, it can be implemented in a personal computer such as a laptop computer <b>322</b>. Alternatively, components from computing device <b>300</b> can be combined with other components in a mobile device (not shown), such as device <b>350</b>. Each of such devices can contain one or more of computing device <b>300</b>, <b>350</b>, and an entire system can be made up of multiple computing devices <b>300</b>, <b>350</b> communicating with each other.</p><p id="p-0081" num="0080">Computing device <b>350</b> includes a processor <b>352</b>, memory <b>364</b>, and an input/output device such as a display <b>354</b>, a communication interface <b>366</b>, and a transceiver <b>368</b>, among other components. The device <b>350</b> can also be provided with a storage device, such as a micro-drive or other device, to provide additional storage. Each of the components <b>350</b>, <b>352</b>, <b>364</b>, <b>354</b>, <b>366</b>, and <b>368</b>, are interconnected using various buses, and several of the components can be mounted on a common motherboard or in other manners as appropriate.</p><p id="p-0082" num="0081">The processor <b>352</b> can execute instructions within the computing device <b>350</b>, including instructions stored in the memory <b>364</b>. The processor can be implemented as a chipset of chips that include separate and multiple analog and digital processors. Additionally, the processor can be implemented using any of a number of architectures. For example, the processor <b>310</b> can be a CISC (Complex Instruction Set Computers) processor, a RISC (Reduced Instruction Set Computer) processor, or a MISC (Minimal Instruction Set Computer) processor. The processor can provide, for example, for coordination of the other components of the device <b>350</b>, such as control of user interfaces, applications run by device <b>350</b>, and wireless communication by device <b>350</b>.</p><p id="p-0083" num="0082">Processor <b>352</b> can communicate with a user through control interface <b>358</b> and display interface <b>356</b> coupled to a display <b>354</b>. The display <b>354</b> can be, for example, a TFT (Thin-Film-Transistor Liquid Crystal Display) display or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology. The display interface <b>356</b> can comprise appropriate circuitry for driving the display <b>354</b> to present graphical and other information to a user. The control interface <b>358</b> can receive commands from a user and convert them for submission to the processor <b>352</b>. In addition, an external interface <b>362</b> can be provided in communication with processor <b>352</b>, so as to enable near area communication of device <b>350</b> with other devices. External interface <b>362</b> can provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces can also be used.</p><p id="p-0084" num="0083">The memory <b>364</b> stores information within the computing device <b>350</b>. The memory <b>364</b> can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units. Expansion memory <b>374</b> can also be provided and connected to device <b>350</b> through expansion interface <b>372</b>, which can include, for example, a SIMM (Single In Line Memory Module) card interface. Such expansion memory <b>374</b> can provide extra storage space for device <b>350</b>, or can also store applications or other information for device <b>350</b>. Specifically, expansion memory <b>374</b> can include instructions to carry out or supplement the processes described above, and can also include secure information. Thus, for example, expansion memory <b>374</b> can be provided as a security module for device <b>350</b>, and can be programmed with instructions that permit secure use of device <b>350</b>. In addition, secure applications can be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.</p><p id="p-0085" num="0084">The memory can include, for example, flash memory and/or NVRAM memory, as discussed below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the memory <b>364</b>, expansion memory <b>374</b>, or memory on processor <b>352</b> that can be received, for example, over transceiver <b>368</b> or external interface <b>362</b>.</p><p id="p-0086" num="0085">Device <b>350</b> can communicate wirelessly through communication interface <b>366</b>, which can include digital signal processing circuitry where necessary. Communication interface <b>366</b> can provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication can occur, for example, through radio-frequency transceiver <b>368</b>. In addition, short-range communication can occur, such as using a Bluetooth, Wi-Fi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module <b>370</b> can provide additional navigation- and location-related wireless data to device <b>350</b>, which can be used as appropriate by applications running on device <b>350</b>.</p><p id="p-0087" num="0086">Device <b>350</b> can also communicate audibly using audio codec <b>360</b>, which can receive spoken information from a user and convert it to usable digital information. Audio codec <b>360</b> can likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device <b>350</b>. Such sound can include sound from voice telephone calls, can include recorded sound, e.g., voice messages, music files, etc. and can also include sound generated by applications operating on device <b>350</b>.</p><p id="p-0088" num="0087">The computing device <b>350</b> can be implemented in a number of different forms, as shown in the figure. For example, it can be implemented as a cellular telephone <b>380</b>. It can also be implemented as part of a smartphone <b>382</b>, personal digital assistant, or other similar mobile device.</p><p id="p-0089" num="0088">A number of implementations have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. For example, various forms of the flows shown above may be used, with steps re-ordered, added, or removed.</p><p id="p-0090" num="0089">Embodiments of the invention and all of the functional operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the invention can be implemented as one or more computer program products, e.g., one or more modules of computer program instructions encoded on a computer readable medium for execution by, or to control the operation of, data processing apparatus. The computer readable medium can be a machine-readable storage device, a machine-readable storage substrate, a memory device, a composition of matter effecting a machine-readable propagated signal, or a combination of one or more of them. The term &#x201c;data processing apparatus&#x201d; encompasses all apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them. A propagated signal is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.</p><p id="p-0091" num="0090">A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.</p><p id="p-0092" num="0091">The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit).</p><p id="p-0093" num="0092">Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a tablet computer, a mobile telephone, a personal digital assistant (PDA), a mobile audio player, a Global Positioning System (GPS) receiver, to name just a few. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto optical disks; and CD ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.</p><p id="p-0094" num="0093">To provide for interaction with a user, embodiments of the invention can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.</p><p id="p-0095" num="0094">Embodiments of the invention can be implemented in a computing system that includes a back end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the invention, or any combination of one or more such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (&#x201c;LAN&#x201d;) and a wide area network (&#x201c;WAN&#x201d;), e.g., the Internet.</p><p id="p-0096" num="0095">The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.</p><p id="p-0097" num="0096">While this specification contains many specifics, these should not be construed as limitations on the scope of the invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of the invention. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.</p><p id="p-0098" num="0097">Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.</p><p id="p-0099" num="0098">In each instance where an HTML file is mentioned, other file types or formats may be substituted. For instance, an HTML file may be replaced by an XML, JSON, plain text, or other types of files. Moreover, where a table or hash table is mentioned, other data structures (such as spreadsheets, relational databases, or structured files) may be used.</p><p id="p-0100" num="0099">Particular embodiments of the invention have been described. Other embodiments are within the scope of the following claims. For example, the steps recited in the claims can be performed in a different order and still achieve desirable results.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method comprising:<claim-text>obtaining one or more images that depict one or more fish within a population of fish that are located within an enclosure;</claim-text><claim-text>providing, to one or more detection models configured to classify fish that are depicted within the images as likely being member or as likely not being member of a type of fish, the one or images;</claim-text><claim-text>generating, as a result of providing the one or more images to the one or more detection models, a value that reflects a quantity of fish that are depicted in the images that are likely a member of the type of fish; and</claim-text><claim-text>detecting a condition based at least on the value.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>determining a location of the quantity of fish within the enclosure.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, comprising:<claim-text>obtaining location data from a device that captures the one or more images; and</claim-text><claim-text>determining the location of the quantity of fish within the enclosure using the location data.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein detecting the condition comprises:<claim-text>detecting a possible opening of the enclosure based at least on the value.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the value represents a ratio indicating a number of fish of the type of fish.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the type of fish is a population raised for aquaculture in the enclosure.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>sending a signal to a controllable device configured to move towards a location specified in the signal relative to the enclosure.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising:<claim-text>storing locations corresponding to locations of the one or more fish enclosed within the enclosure.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more detection models comprise a machine learning model trained using images of the type of fish.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A non-transitory, computer-readable medium storing one or more instructions executable by a computer system to perform operations comprising:<claim-text>obtaining one or more images that depict one or more fish within a population of fish that are located within an enclosure;</claim-text><claim-text>providing, to one or more detection models configured to classify fish that are depicted within the images as likely being member or as likely not being member of a type of fish, the one or images;</claim-text><claim-text>generating, as a result of providing the one or more images to the one or more detection models, a value that reflects a quantity of fish that are depicted in the images that are likely a member of the type of fish; and</claim-text><claim-text>detecting a condition based at least on the value.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the operations comprise:<claim-text>determining a location of the quantity of fish within the enclosure.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The medium of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the operations comprise:<claim-text>obtaining location data from a device that captures the one or more images; and</claim-text><claim-text>determining the location of the quantity of fish within the enclosure using the location data.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein detecting the condition comprises:<claim-text>detecting a possible opening of the enclosure based at least on the value.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the value represents a ratio indicating a number of fish of the type of fish.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the type of fish is a population raised for aquaculture in the enclosure.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the operations comprise:<claim-text>sending a signal to a controllable device configured to move towards a location specified in the signal relative to the enclosure.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the operations comprise:<claim-text>storing locations corresponding to locations of the one or more fish enclosed within the enclosure.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The medium of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the one or more detection models comprise a machine learning model trained using images of the type of fish.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A computer-implemented system, comprising:<claim-text>one or more computers; and</claim-text><claim-text>one or more computer memory devices interoperably coupled with the one or more computers and having tangible, non-transitory, machine-readable media storing one or more instructions that, when executed by the one or more computers, perform one or more operations comprising:</claim-text><claim-text>obtaining one or more images that depict one or more fish within a population of fish that are located within an enclosure;</claim-text><claim-text>providing, to one or more detection models configured to classify fish that are depicted within the images as likely being member or as likely not being member of a type of fish, the one or images;</claim-text><claim-text>generating, as a result of providing the one or more images to the one or more detection models, a value that reflects a quantity of fish that are depicted in the images that are likely a member of the type of fish; and</claim-text><claim-text>detecting a condition based at least on the value.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the operations comprise:<claim-text>determining a location of the quantity of fish within the enclosure.</claim-text></claim-text></claim></claims></us-patent-application>
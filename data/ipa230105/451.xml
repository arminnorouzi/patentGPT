<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000452A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000452</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17305056</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>62</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>469</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>6256</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>5241</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS FOR SIMULTANEOUS MULTI-SLICE IMAGING</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SHANGHAI UNITED IMAGING HEALTHCARE CO., LTD.</orgname><address><city>Shanghai</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>ZHENG</last-name><first-name>Yuan</first-name><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>XU</last-name><first-name>Jian</first-name><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>LIU</last-name><first-name>Qi</first-name><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>SHANGHAI UNITED IMAGING HEALTHCARE CO., LTD.</orgname><role>03</role><address><city>Shanghai</city><country>CN</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for SMS imaging may include obtaining target k-space data related to a region of interest (ROI) of an object. The method may also include generate, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI at one of a plurality of target acquisition periods.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="180.68mm" wi="155.36mm" file="US20230000452A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="198.54mm" wi="157.40mm" file="US20230000452A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="158.24mm" wi="165.35mm" file="US20230000452A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="91.78mm" wi="110.41mm" file="US20230000452A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="194.73mm" wi="103.21mm" file="US20230000452A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="131.15mm" wi="63.84mm" file="US20230000452A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="211.41mm" wi="165.52mm" file="US20230000452A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="229.87mm" wi="138.60mm" file="US20230000452A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="229.87mm" wi="138.94mm" file="US20230000452A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="161.80mm" wi="159.51mm" file="US20230000452A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="86.78mm" wi="136.74mm" file="US20230000452A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="197.44mm" wi="153.25mm" file="US20230000452A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="246.97mm" wi="162.39mm" file="US20230000452A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="114.30mm" wi="166.79mm" file="US20230000452A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present disclosure generally relates to magnetic resonance imaging (MRI), and in particular, to systems and methods for simultaneous multi-slice (SMS) imaging.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Simultaneous multi-slice (SMS) imaging has rapidly advanced to become a major imaging technique for acceleration of magnetic resonance imaging (MRI). Compared with the imaging that only excites a single slice one time, SMS excites multiple slices at the same time and simultaneously acquires magnetic resonance (MR) signals generated from the multiple excited slices. The MR signals are filled into the k-space to generate k-space data. Because the received MR signals include the contributions of the multiple excited slices, reconstruction of the k-space data directly using inverse Fourier transform may lead to an aliased image of the multiple slices. Therefore, it is desirable to provide systems and/or methods for SMS reconstruction to generate an unaliased image for each slice.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">Additional features will be set forth in part in the description which follows, and in part will become apparent to those skilled in the art upon examination of the following and the accompanying drawings or may be learned by production or operation of the examples. The features of the present disclosure may be realized and attained by practice or use of various aspects of the methodologies, instrumentalities, and combinations set forth in the detailed examples discussed below.</p><p id="p-0005" num="0004">According to a first aspect of the present disclosure, a system for simultaneous multi-slice (SMS) imaging may include a magnetic resonance imaging (MRI) device configured to scan a region of interest (ROI) of an object, one or more storage devices, and one or more processors configured to communicate with the one or more storage devices. The one or more storage devices may include a set of instructions. When the one or more processors executing the set of instructions, the one or more processors may be directed to perform one or more of the following operations. The one or more processors may obtain target k-space data related to the ROI of the object. The one or more processors may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI at one of a plurality of target acquisition periods.</p><p id="p-0006" num="0005">In some embodiments, the target k-space data may include a plurality of first k-space data sets each of which is acquired from the plurality of target slices in one of the plurality of target acquisition periods.</p><p id="p-0007" num="0006">In some embodiments, the target k-space data may be undersampled.</p><p id="p-0008" num="0007">In some embodiments, to generate, based on the target k-space data using the trained reconstruction model, the plurality of target images, the one or more processors may input the target k-space data into the trained reconstruction model. The one or more processors may output, by the trained reconstruction model, the plurality of target images based on the target k-space data.</p><p id="p-0009" num="0008">In some embodiments, to obtain the target k-space data related to the ROI of the object, the one or more processors may cause the MRI device to apply one or more multiband excitation radio frequency (RF) pulses to the ROI to simultaneously excite, for one or more times, the plurality of target slices of the ROI. The one or more processors may cause the MRI device to apply phase modulation to at least one of the excited target slices by applying, to each of the at least one of the excited target slices, a transmit phase that varies with a plurality of target acquisition periods and/or a phase encoding direction. The one or more processors may acquire the target k-space data from the plurality of excited target slices of the ROI at the plurality of target acquisition periods.</p><p id="p-0010" num="0009">In some embodiments, the transmit phases applied to two or more of the plurality of target slices may be different.</p><p id="p-0011" num="0010">In some embodiments, to generate, based on the target k-space data using the trained reconstruction model, the plurality of target images, the one or more processors may generate a plurality of target aliased images by performing inverse Fourier transform on the target k-space data, each of the plurality of target aliased images corresponding to the plurality of target slices and one of the plurality of target acquisition periods. The one or more processors may input the plurality of aliased images into the trained reconstruction model. The one or more processors may output, by the trained reconstruction model, the plurality of target images based on the plurality of target aliased images.</p><p id="p-0012" num="0011">In some embodiments, to generate, based on the target k-space data using the trained reconstruction model, the plurality of target images, the one or more processors may determine a plurality of reference data sets based on the target k-space data. Each of the plurality of reference data sets may correspond to one of the plurality of target slices and one of the plurality of target acquisition periods. The plurality of reference data sets may provide unaliased information for unaliasing of the plurality of target slices in the target k-space data. The one or more processors may generate, based on the target k-space data and the plurality of reference data sets, the plurality of target images using the trained reconstruction model.</p><p id="p-0013" num="0012">In some embodiments, the trained reconstruction model may include a machine learning model.</p><p id="p-0014" num="0013">In some embodiments, the trained reconstruction model may be provided by: obtaining a plurality of training data sets; and obtaining the trained reconstruction model by training a preliminary model based on the plurality of training data sets. Each of the plurality of training data sets may include sample k-space data and a plurality of sample unaliased images. Each of the plurality of sample unaliased images may correspond to one of a plurality of sample slices of a sample and one of a plurality of sample acquisition periods. For each of at least one of the plurality of sample slices, phases of the corresponding sample k-space data may vary based on the plurality of sample acquisition periods and/or the phase encoding direction.</p><p id="p-0015" num="0014">In some embodiments, the sample k-space data may include real k-space data that is acquired by simultaneously exciting the plurality of sample slices. The plurality of sample unaliased images may be generated based on the sample k-space data.</p><p id="p-0016" num="0015">In some embodiments, the sample k-space data may be undersampled.</p><p id="p-0017" num="0016">In some embodiments, the sample k-space data may include synthesized k-space data. The synthesized k-space data may be obtained by obtaining a plurality of sample k-space data sets by performing Fourier transform on the plurality of sample unaliased images. Each of the plurality of sample k-space data sets may correspond to one of the plurality of sample unaliased images. The synthesized k-space data may be obtained further by applying phase modulation to the sample k-space data sets so that for each of at least one of the plurality of sample slices, the sample phases of the corresponding sample k-space data sets vary based on the plurality of sample acquisition periods and/or the phase encoding direction. The synthesized k-space data may be obtained further by obtaining a plurality of second k-space data sets by combining the sample k-space data sets corresponding to the sample acquisition period. Each of the plurality of second k-space data sets may correspond to the plurality of sample slices and one of the plurality of sample acquisition periods. The sample k-space data sets may include the plurality of second k-space data sets.</p><p id="p-0018" num="0017">In some embodiments, the synthesized k-space data may be obtained further by applying an undersampling strategy to the plurality of second k-space data sets or the plurality of sample k-space data sets by replacing a portion of data in the plurality of second k-space data sets or the plurality of sample k-space data sets with zero.</p><p id="p-0019" num="0018">In some embodiments, obtaining the trained reconstruction model by training the preliminary model based on the plurality of training data sets may include: for each of at least one of the plurality of training data sets, generating a plurality of sample aliased images by performing inverse Fourier transform on the sample k-space data of the training data set, each of the plurality of sample aliased images corresponding to the plurality of sample slices and one of the plurality of sample acquisition periods; and obtaining the trained reconstruction model by training the preliminary model based on the plurality of sample aliased images of the each of the at least one of the plurality of training data sets.</p><p id="p-0020" num="0019">In some embodiments, obtaining the trained reconstruction model by training the preliminary model based on the plurality of training data sets may include obtaining the trained reconstruction model by performing an iteration process including one or more iterations. At least one of the one or more iterations may include outputting, by an intermediate model, a plurality of output images based on the sample k-space data of one of the plurality of training data sets. The intermediate model may include the preliminary model in a first iteration of the one or more iterations of the iteration process or an updated model generated in a previous iteration of the at least one of the one or more iterations. Each of the plurality of output images may correspond to one of the plurality of sample unaliased images of the one of the plurality of training data sets. The at least one of the one or more iterations may further include updating the intermediate model based on a difference between the plurality of output images and the plurality of sample unaliased images of the one of the plurality of training data sets.</p><p id="p-0021" num="0020">In some embodiments, each of the plurality of target acquisition periods may correspond to a physiological motion phase of the ROI. The plurality of target images may form a physiological motion cine of the ROI.</p><p id="p-0022" num="0021">In some embodiments, the ROI of the object may include at least a portion of a heart or a lung.</p><p id="p-0023" num="0022">In some embodiments, the plurality of target images may be used for perfusion analysis and indicate a change of a density of a contrast agent in the plurality of target slices over time.</p><p id="p-0024" num="0023">According to another aspect of the present disclosure, a method for SMS imaging may include one or more of the following operations. One or more processors may obtain target k-space data related to an ROI of an object. The one or more processors may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI at one of a plurality of target acquisition periods.</p><p id="p-0025" num="0024">According to yet another aspect of the present disclosure, a system for SMS imaging may include an acquisition module configured to obtain target k-space data related to a region of interest (ROI) of an object. The system may also include a reconstruction module configured to generate, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI at one of a plurality of target acquisition periods.</p><p id="p-0026" num="0025">According to yet another aspect of the present disclosure, a non-transitory computer readable medium may comprise at least one set of instructions. The at least one set of instructions may be executed by one or more processors of a computing device. The one or more processors may obtain target k-space data related to an ROI of an object. The one or more processors may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI at one of a plurality of target acquisition periods.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0027" num="0026">The present disclosure is further described in terms of exemplary embodiments. These exemplary embodiments are described in detail with reference to the drawings. These embodiments are non-limiting exemplary embodiments, in which like reference numerals represent similar structures throughout the several views of the drawings, and wherein:</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram illustrating an exemplary MRI system according to some embodiments of the present disclosure;</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram illustrating an exemplary MRI scanner according to some embodiments of the present disclosure;</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram illustrating exemplary hardware and/or software components of a computing device according to some embodiments of the present disclosure;</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram illustrating exemplary hardware and/or software components of a mobile device according to some embodiments of the present disclosure;</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic block diagram illustrating an exemplary processing device according to some embodiments of the present disclosure;</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a flowchart illustrating an exemplary process for SMS imaging according to some embodiments of the present disclosure;</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. <b>6</b>B and <b>6</b>C</figref> are schematic diagrams illustrating exemplary acquisition of target k-space data according to some embodiments of the present disclosure;</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>6</b>D</figref> is a schematic diagram illustrating an exemplary trained reconstruction model according to some embodiments of the present disclosure;</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an exemplary process for obtaining a trained reconstruction model according to some embodiments of the present disclosure;</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an exemplary training process for obtaining a trained reconstruction model according to some embodiments of the present disclosure;</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an exemplary model training phase and an exemplary model application phase according to some embodiments of the present disclosure; and</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart illustrating an exemplary process for MR imaging according to some embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0040" num="0039">In the following detailed description, numerous specific details are set forth by way of examples in order to provide a thorough understanding of the relevant disclosure. However, it should be apparent to those skilled in the art that the present disclosure may be practiced without such details. In other instances, well-known methods, procedures, systems, components, and/or circuitry have been described at a relatively high-level, without detail, in order to avoid unnecessarily obscuring aspects of the present disclosure. Various modifications to the disclosed embodiments will be readily apparent to those skilled in the art, and the general principles defined herein may be applied to other embodiments and applications without departing from the spirit and scope of the present disclosure. Thus, the present disclosure is not limited to the embodiments shown, but to be accorded the widest scope consistent with the claims.</p><p id="p-0041" num="0040">The terminology used herein is for the purpose of describing particular example embodiments only and is not intended to be limiting. As used herein, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; may be intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms &#x201c;comprise,&#x201d; &#x201c;comprises,&#x201d; and/or &#x201c;comprising,&#x201d; &#x201c;include,&#x201d; &#x201c;includes,&#x201d; and/or &#x201c;including,&#x201d; when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and/or groups thereof.</p><p id="p-0042" num="0041">It will be understood that the term &#x201c;system,&#x201d; &#x201c;unit,&#x201d; &#x201c;module,&#x201d; and/or &#x201c;block&#x201d; used herein are one method to distinguish different components, elements, parts, section or assembly of different levels in ascending order. However, the terms may be displaced by another expression if they achieve the same purpose.</p><p id="p-0043" num="0042">Generally, the word &#x201c;module,&#x201d; &#x201c;unit,&#x201d; or &#x201c;block,&#x201d; as used herein, refers to logic embodied in hardware or firmware, or to a collection of software instructions. A module, a unit, or a block described herein may be implemented as software and/or hardware and may be stored in any type of non-transitory computer-readable medium or another storage device. In some embodiments, a software module/unit/block may be compiled and linked into an executable program. It will be appreciated that software modules can be callable from other modules/units/blocks or from themselves, and/or may be invoked in response to detected events or interrupts. Software modules/units/blocks configured for execution on computing devices (e.g., processor <b>310</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) may be provided on a computer readable medium, such as a compact disc, a digital video disc, a flash drive, a magnetic disc, or any other tangible medium, or as a digital download (and can be originally stored in a compressed or installable format that needs installation, decompression, or decryption prior to execution). Such software code may be stored, partially or fully, on a storage device of the executing computing device, for execution by the computing device. Software instructions may be embedded in firmware, such as an EPROM. It will be further appreciated that hardware modules/units/blocks may be included of connected logic components, such as gates and flip-flops, and/or can be included of programmable units, such as programmable gate arrays or processors. The modules/units/blocks or computing device functionality described herein may be implemented as software modules/units/blocks, but may be represented in hardware or firmware. In general, the modules/units/blocks described herein refer to logical modules/units/blocks that may be combined with other modules/units/blocks or divided into sub-modules/sub-units/sub-blocks despite their physical organization or storage.</p><p id="p-0044" num="0043">It will be understood that when a unit, engine, module or block is referred to as being &#x201c;on,&#x201d; &#x201c;connected to,&#x201d; or &#x201c;coupled to,&#x201d; another unit, engine, module, or block, it may be directly on, connected or coupled to, or communicate with the other unit, engine, module, or block, or an intervening unit, engine, module, or block may be present, unless the context clearly indicates otherwise. As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items.</p><p id="p-0045" num="0044">These and other features, and characteristics of the present disclosure, as well as the methods of operation and functions of the related elements of structure and the combination of parts and economies of manufacture, may become more apparent upon consideration of the following description with reference to the accompanying drawings, all of which form a part of this disclosure. It is to be expressly understood, however, that the drawings are for the purpose of illustration and description only and are not intended to limit the scope of the present disclosure. It is understood that the drawings are not to scale.</p><p id="p-0046" num="0045">Provided herein are systems and components for medical imaging and/or medical treatment. In some embodiments, the medical system may include an imaging system. The imaging system may include a single modality imaging system and/or a multi-modality imaging system. The single modality imaging system may include, for example, a magnetic resonance imaging (MRI) system. Exemplary MRI systems may include a superconducting magnetic resonance imaging system, a non-superconducting magnetic resonance imaging system, etc. The multi-modality imaging system may include, for example, a computed tomography-magnetic resonance imaging (MRI-CT) system, a positron emission tomography-magnetic resonance imaging (PET-MRI) system, a single photon emission computed tomography-magnetic resonance imaging (SPECT-MRI) system, a digital subtraction angiography-magnetic resonance imaging (DSA-MRI) system, etc. In some embodiments, the medical system may include a treatment system. The treatment system may include a treatment plan system (TPS), image-guided radiotherapy (IGRT) system, etc. The image-guided radiotherapy (IGRT) system may include a treatment device and an imaging device. The treatment device may include a linear accelerator, a cyclotron, a synchrotron, etc., configured to perform a radiotherapy on a subject. The treatment device may include an accelerator of species of particles including, for example, photons, electrons, protons, or heavy ions. The imaging device may include an MRI scanner, a CT scanner (e.g., cone beam computed tomography (CBCT) scanner), a digital radiology (DR) scanner, an electronic portal imaging device (EPID), etc.</p><p id="p-0047" num="0046">An aspect of the present disclosure relates to systems and methods for SMS imaging, and in particular, related to systems and methods for reconstruction of autocalibration acquisition data using a machine learning model. The autocalibration acquisition data may include the following features. The autocalibration acquisition data may be acquired from a plurality of slices of a region of interest (ROI) of an object that are simultaneously excited. The autocalibration acquisition data may be acquired in a plurality of acquisition periods so that a series of unaliased images each of which corresponds to one of the plurality of slices and one of the plurality of acquisition periods are reconstructed from the autocalibration acquisition data. The autocalibration acquisition data may be phase-modulated by applying a transmit phase that varies along the phase encoding direction and/or the temporal dimension (e.g., the plurality of acquisition periods). The reconstruction for the autocalibration acquisition data using a machine learning model is a non-linear approach, which may improve image quality and reconstruction speed.</p><p id="p-0048" num="0047">A plurality of reference data sets that provide unaliased information for unaliasing of the plurality of slices may be determined based on the autocalibration acquisition data (k-space data), which indicates that the autocalibration acquisition data includes the unaliased information. Therefore, after the autocalibration acquisition data is input into the machine learning model, the machine learning model may automatically extract the unaliased information implied in the autocalibration acquisition data and output unaliased images. In this way, additional operations for obtaining the reference data sets (e.g., additional determination or scan for the reference data sets) are not required in SMS reconstruction, which improves the efficiency for SMS reconstruction.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram illustrating an exemplary MRI system <b>100</b> according to some embodiments of the present disclosure. As illustrated, the MRI system <b>100</b> may include a scanner <b>110</b>, a network <b>120</b>, a user device <b>130</b>, a processing device <b>140</b>, and a storage device <b>150</b>. The components of the MRI system <b>100</b> may be connected in one or more of various ways. Mere by way of example, as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the scanner <b>110</b> may be connected to the processing device <b>140</b> through the network <b>120</b>. As another example, the scanner <b>110</b> may be connected to the processing device <b>140</b> directly (as indicated by the bi-directional arrow in dotted lines linking the scanner <b>110</b> and the processing device <b>140</b>). As a further example, the storage device <b>150</b> may be connected to the processing device <b>140</b> directly or through the network <b>120</b>. As still a further example, the user device <b>130</b> (e.g., <b>131</b>, <b>132</b>, <b>133</b>, etc.) may be connected to the processing device <b>140</b> directly (as indicated by the bi-directional arrow in dotted lines linking the user device <b>130</b> and the processing device <b>140</b>) or through the network <b>120</b>.</p><p id="p-0050" num="0049">The scanner <b>110</b> may scan an object located within its detection region and generate a plurality of imaging data relating to the object. In the present disclosure, &#x201c;subject&#x201d; and &#x201c;object&#x201d; are used interchangeably. Mere by way of example, the object may include a patient, a man-made object, etc. As another example, the object may include a specific portion, organ, and/or tissue of a patient. For example, the object may include head, brain, neck, body, shoulder, arm, thorax, cardiac, stomach, blood vessel, soft tissue, knee, feet, or the like, or any combination thereof.</p><p id="p-0051" num="0050">In some embodiments, the scanner <b>110</b> may include an MRI scanner, a multi-modality device, etc. Exemplary multi-modality device may include an MRI-CT device, a PET-MRI device, etc. In some embodiments, the MRI scanner may be a close-bore scanner or an open-bore scanner. In the present disclosure, the X axis, the Y axis, and the Z axis shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may form an orthogonal coordinate system. The X axis and the Z axis shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may be horizontal, and the Y axis may be vertical. As illustrated, the positive X direction along the X axis may be from the right side to the left side of the scanner <b>110</b> seen from the direction facing the front of the scanner <b>110</b>; the positive Y direction along the Y axis shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may be from the lower part to the upper part of the scanner <b>110</b>; the positive Z direction along the Z axis shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may refer to a direction in which the object is moved out of the scanning channel (or referred to as the bore) of the scanner <b>110</b>. More description of the scanner <b>110</b> may be found elsewhere in the present disclosure. See, e.g., <figref idref="DRAWINGS">FIG. <b>2</b></figref> and the description thereof.</p><p id="p-0052" num="0051">The network <b>120</b> may include any suitable network that can facilitate the exchange of information and/or data for the MRI system <b>100</b>. In some embodiments, one or more components of the MRI system <b>100</b> (e.g., the scanner <b>110</b>, the user device <b>130</b>, the processing device <b>140</b>, or the storage device <b>150</b>) may communicate information and/or data with one or more other components of the MRI system <b>100</b> via the network <b>120</b>. For example, the processing device <b>140</b> may obtain magnetic resonance (MR) data (also referred to as MR signals, echo signals, or echo data) from the scanner <b>110</b> via the network <b>120</b>. As another example, the user device <b>130</b> and/or the storage device <b>150</b> may obtain one or more images from the processing device <b>140</b>. In some embodiments, the network <b>120</b> may be any type of wired or wireless network, or a combination thereof. The network <b>120</b> may be and/or include a public network (e.g., the Internet), a private network (e.g., a local area network (LAN), a wide area network (WAN)), etc.), a wired network (e.g., an Ethernet network), a wireless network (e.g., an 802.11 network, a Wi-Fi network, etc.), a cellular network (e.g., a Long Term Evolution (LTE) network), a frame relay network, a virtual private network (&#x201c;VPN&#x201d;), a satellite network, a telephone network, routers, hubs, switches, server computers, and/or any combination thereof. Merely by way of example, the network <b>120</b> may include a cable network, a wireline network, a fiber-optic network, a telecommunications network, an intranet, a wireless local area network (WLAN), a metropolitan area network (MAN), a public telephone switched network (PSTN), a Bluetooth&#x2122; network, a ZigBee&#x2122; network, a near field communication (NFC) network, or the like, or any combination thereof. In some embodiments, the network <b>120</b> may include one or more network access points. For example, the network <b>120</b> may include wired and/or wireless network access points such as base stations and/or internet exchange points through which one or more components of the MRI system <b>100</b> may be connected to the network <b>120</b> to exchange data and/or information.</p><p id="p-0053" num="0052">The user device <b>130</b> may include a mobile device <b>131</b>, a tablet computer <b>132</b>, a laptop computer <b>133</b>, a desktop computer (not shown), a workstation (not shown), or the like, or any combination thereof. In some embodiments, the mobile device <b>131</b> may include a smart home device, a wearable device, a smart mobile device, a virtual reality device, an augmented reality device, or the like, or any combination thereof. In some embodiments, the smart home device may include a smart lighting device, a control device of an intelligent electrical apparatus, a smart monitoring device, a smart television, a smart video camera, an interphone, or the like, or any combination thereof. In some embodiments, the wearable device may include a smart bracelet, smart footgear, a pair of smart glasses, a smart helmet, a smart watch, smart clothing, a smart backpack, a smart accessory, or the like, or any combination thereof. In some embodiments, the smart mobile device may include a smartphone, a personal digital assistant (PDA), a gaming device, a navigation device, a point of sale (POS) device, or the like, or any combination thereof. In some embodiments, the virtual reality device and/or the augmented reality device may include a virtual reality helmet, a virtual reality glass, a virtual reality patch, an augmented reality helmet, an augmented reality glass, an augmented reality patch, or the like, or any combination thereof. For example, the virtual reality device and/or the augmented reality device may include a Google&#x2122; Glass, an Oculus Rift, a Hololens, a Gear VR, etc. In some embodiments, the user device <b>130</b> may remotely operate the scanner <b>110</b> and/or the processing device <b>140</b>. In some embodiments, the user device <b>130</b> may operate the scanner <b>110</b> and/or the processing device <b>140</b> via a wireless connection. In some embodiments, the user device <b>130</b> may receive information and/or instructions inputted by a user, and send the received information and/or instructions to the scanner <b>110</b> or to the processing device <b>140</b> via the network <b>120</b>. For example, a user (e.g., a doctor, a technician, or an engineer, etc.) of the MRI system <b>100</b> may set a scan protocol though the user device <b>130</b>. The user device <b>130</b> may send the scan protocol to the processing device <b>140</b> to direct the processing device <b>140</b> to cause the scanner <b>110</b> (e.g., the MRI scanner) to operate according to the scan protocol. In some embodiments, the user device <b>130</b> may receive data and/or information from the processing device <b>140</b> and/or the storage device <b>150</b>. For example, the user device <b>130</b> may obtain one or more images from the processing device <b>140</b> and/or the storage device <b>150</b>.</p><p id="p-0054" num="0053">The processing device <b>140</b> may process data and/or information obtained from the scanner <b>110</b>, the user device <b>130</b>, and/or the storage device <b>150</b>. For example, the processing device <b>140</b> may obtain MR data from the scanner <b>110</b> and determine one or more images based on the MR data. As another example, the processing device <b>140</b> may receive one or more instructions from the user device <b>130</b> and cause the scanner <b>110</b> to operate according to the one or more instructions. In some embodiments, the processing device <b>140</b> may be a single server, or a server group. The server group may be centralized or distributed. In some embodiments, the processing device <b>140</b> may be local or remote. For example, the processing device <b>140</b> may access information and/or data stored in or acquired by the scanner <b>110</b>, the user device <b>130</b>, and/or the storage device <b>150</b> via the network <b>120</b>. As another example, the processing device <b>140</b> may be directly connected to the scanner <b>110</b> (as illustrated by the bidirectional arrow in dashed lines connecting the processing device <b>140</b> and the scanner <b>110</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>), the user device <b>130</b> (as illustrated by the bidirectional arrow in dashed lines connecting the processing device <b>140</b> and the user device <b>130</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>), and/or the storage device <b>150</b> to access stored or acquired information and/or data. In some embodiments, the processing device <b>140</b> may be implemented on a cloud platform. Merely by way of example, the cloud platform may include a private cloud, a public cloud, a hybrid cloud, a community cloud, a distributed cloud, an inter-cloud, a multi-cloud, or the like, or any combination thereof. In some embodiments, the processing device <b>140</b> may be implemented on a computing device <b>300</b> having one or more components illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> in the present disclosure.</p><p id="p-0055" num="0054">The storage device <b>150</b> may store data and/or instructions. In some embodiments, the storage device <b>150</b> may include a database, a picture archiving and communication system, a file system, or the like, or any combination thereof. In some embodiments, the storage device <b>150</b> may store data obtained from the scanner <b>110</b>, the user device <b>130</b> and/or the processing device <b>140</b>. For example, the storage device <b>150</b> may store MR data acquired by the scanner <b>110</b>. As another example, the storage device <b>150</b> may store medical images (e.g., MRI images) generated by the processing device <b>140</b> and/or the user device <b>130</b>. As a further example, the storage device <b>150</b> may store preset scan parameters (e.g., preset scan protocols) of the MRI system <b>100</b>. In some embodiments, the storage device <b>150</b> may store data and/or instructions that the processing device <b>140</b> may execute or use to perform exemplary methods described in the present disclosure. For example, the storage device <b>150</b> may store instructions that the processing device <b>140</b> may execute to cause the scanner <b>110</b> to acquire MR data based on a pulse sequence including a steady-state sequence and an acquisition sequence. As another example, the storage device <b>150</b> may store instructions that the processing device <b>140</b> and/or the user device <b>130</b> may execute to generate one or more images based on the MR data. In some embodiments, the storage device <b>150</b> may include a mass storage device, a removable storage device, a volatile read-and-write memory, a read-only memory (ROM), or the like, or any combination thereof. Exemplary mass storage may include a magnetic disk, an optical disk, a solid-state drive, etc. Exemplary removable storage may include a flash drive, a floppy disk, an optical disk, a memory card, a zip disk, a magnetic tape, etc. Exemplary volatile read-and-write memory may include a random access memory (RAM). Exemplary RAM may include a dynamic RAM (DRAM), a double date rate synchronous dynamic RAM (DDR SDRAM), a static RAM (SRAM), a thyristor RAM (T-RAM), and a zero-capacitor RAM (Z-RAM), etc. Exemplary ROM may include a mask ROM (MROM), a programmable ROM (PROM), an erasable programmable ROM (PEROM), an electrically erasable programmable ROM (EEPROM), a compact disk ROM (CD-ROM), and a digital versatile disk ROM, etc. In some embodiments, the storage device <b>150</b> may be implemented on a cloud platform. Merely by way of example, the cloud platform may include a private cloud, a public cloud, a hybrid cloud, a community cloud, a distributed cloud, an inter-cloud, a multi-cloud, or the like, or any combination thereof.</p><p id="p-0056" num="0055">In some embodiments, the storage device <b>150</b> may be connected to the network <b>120</b> to communicate with one or more components of the MRI system <b>100</b> (e.g., the scanner <b>110</b>, the processing device <b>140</b>, the user device <b>130</b>, etc.). One or more components of the MRI system <b>100</b> may access the data or instructions stored in the storage device <b>150</b> via the network <b>120</b>. In some embodiments, the storage device <b>150</b> may be directly connected to or communicate with one or more components of the MRI system <b>100</b> (e.g., the scanner <b>110</b>, the processing device <b>140</b>, the user device <b>130</b>, etc.). In some embodiments, the storage device <b>150</b> may be part of the processing device <b>140</b>.</p><p id="p-0057" num="0056">In some embodiments, the MRI system <b>100</b> may further include one or more power supplies (not shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) connected to one or more components of the MRI system <b>100</b> (e.g., the scanner <b>110</b>, the processing device <b>140</b>, the user device <b>130</b>, the storage device <b>150</b>, etc.).</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram illustrating an exemplary MRI scanner according to some embodiments of the present disclosure. As illustrated, the main magnet <b>201</b> may generate a first magnetic field (or referred to as a main magnetic field) that may be applied to an object (also referred to as a subject) exposed inside the field. The main magnet <b>201</b> may include a resistive magnet or a superconductive magnet that both need a power supply (not shown) for operation. Alternatively, the main magnet <b>201</b> may include a permanent magnet. The main magnet <b>201</b> may include a bore that the object is placed within. The main magnet <b>201</b> may also control the homogeneity of the generated main magnetic field. Some shim coils may be in the main magnet <b>201</b>. The shim coils placed in the gap of the main magnet <b>201</b> may compensate for the inhomogeneity of the magnetic field of the main magnet <b>201</b>. The shim coils may be energized by a shim power supply.</p><p id="p-0059" num="0058">Gradient coils <b>202</b> may be located inside the main magnet <b>201</b>. The gradient coils <b>202</b> may generate a second magnetic field (or referred to as a gradient field, including gradient fields Gx, Gy, and Gz). The second magnetic field may be superimposed on the main field generated by the main magnet <b>201</b> and distort the main field so that the magnetic orientations of the protons of an object may vary as a function of their positions inside the gradient field, thereby encoding spatial information into MR signals generated by the object being imaged. The gradient coils <b>202</b> may include X coils (e.g., configured to generate the gradient field Gx corresponding to the X direction), Y coils (e.g., configured to generate the gradient field Gy corresponding to the Y direction), and/or Z coils (e.g., configured to generate the gradient field Gz corresponding to the Z direction) (not shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). In some embodiments, the Z coils may be designed based on circular (Maxwell) coils, while the X coils and the Y coils may be designed on the basis of the saddle (Golay) coil configuration. The three sets of coils may generate three different magnetic fields that are used for position encoding. The gradient coils <b>202</b> may allow spatial encoding of MR signals for image reconstruction. The gradient coils <b>202</b> may be connected with one or more of an X gradient amplifier <b>204</b>, a Y gradient amplifier <b>205</b>, or a Z gradient amplifier <b>206</b>. One or more of the three amplifiers may be connected to a waveform generator <b>216</b>. The waveform generator <b>216</b> may generate gradient waveforms that are applied to the X gradient amplifier <b>204</b>, the Y gradient amplifier <b>205</b>, and/or the Z gradient amplifier <b>206</b>. An amplifier may amplify a waveform. An amplified waveform may be applied to one of the coils in the gradient coils <b>202</b> to generate a magnetic field in the X axis, the Y axis, or the Z axis, respectively. The gradient coils <b>202</b> may be designed for either a close-bore MRI scanner or an open-bore MRI scanner. In some instances, all three sets of coils of the gradient coils <b>202</b> may be energized and three gradient fields may be generated thereby. In some embodiments of the present disclosure, the X coils and Y coils may be energized to generate the gradient fields in the X direction and the Y direction. As used herein, the X axis, the Y axis, the Z axis, the X direction, the Y direction, and the Z direction in the description of <figref idref="DRAWINGS">FIG. <b>2</b></figref> are the same as or similar to those described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0060" num="0059">In some embodiments, radio frequency (RF) coils <b>203</b> may be located inside the main magnet <b>201</b> and serve as transmitters, receivers, or both. The RF coils <b>203</b> may be in connection with RF electronics <b>209</b> that may be configured or used as one or more integrated circuits (ICs) functioning as a waveform transmitter and/or a waveform receiver. The RF electronics <b>209</b> may be connected to a radiofrequency power amplifier (RFPA) <b>207</b> and an analog-to-digital converter (ADC) <b>208</b>.</p><p id="p-0061" num="0060">When used as transmitters, the RF coils <b>203</b> may generate RF signals that provide a third magnetic field that is utilized to generate MR signals related to the object being imaged. The third magnetic field may be perpendicular to the main magnetic field. The waveform generator <b>216</b> may generate an RF pulse. The RF pulse may be amplified by the RFPA <b>207</b>, processed by the RF electronics <b>209</b>, and applied to the RF coils <b>203</b> to generate the RF signals in response to a powerful current generated by the RF electronics <b>209</b> based on the amplified RF pulse.</p><p id="p-0062" num="0061">When used as receivers, the RF coils may be responsible for detecting MR signals (e.g., echoes). After excitation, the MR signals generated by the object may be sensed by the RF coils <b>203</b>. The receive amplifier then may receive the sensed MR signals from the RF coils <b>203</b>, amplify the sensed MR signals, and provide the amplified MR signals to the ADC <b>208</b>. The ADC <b>208</b> may transform the MR signals from analog signals to digital signals. The digital MR signals then may be filled into k-space.</p><p id="p-0063" num="0062">In some embodiments, the gradient coils <b>202</b> and the RF coils <b>203</b> may be circumferentially positioned with respect to the object. It is understood by those skilled in the art that the main magnet <b>201</b>, the gradient coils <b>202</b>, and the RF coils <b>203</b> may be situated in a variety of configurations around the object.</p><p id="p-0064" num="0063">In some embodiments, the RFPA <b>207</b> may amplify an RF pulse (e.g., the power of the RF pulse, the voltage of the RF pulse) such that an amplified RF pulse is generated to drive the RF coils <b>203</b>. In some embodiments, the RFPA <b>207</b> may include one or more RFPAs.</p><p id="p-0065" num="0064">In some embodiments, the scanner <b>110</b> may further include an object positioning system (not shown). The object positioning system may include an object cradle and a transport device. The object may be placed on the object cradle and be positioned by the transport device within the bore of the main magnet <b>201</b>.</p><p id="p-0066" num="0065">MRI systems (e.g., the MRI system <b>100</b> in the present disclosure) may be commonly used to obtain an interior image from an object (e.g., a patient) for a particular region of interest that can be used for the purposes of, e.g., diagnosis, treatment, or the like, or a combination thereof. MRI systems include a main magnet (e.g., the main magnet <b>201</b>) assembly for providing a main magnetic field to align the individual magnetic moments of the H atoms within the patient's body. During this process, the H atoms oscillate around their magnetic poles at their characteristic Larmor frequency. If the object is subjected to an additional magnetic field, which is tuned to the Larmor frequency, the H atoms absorb additional energy, which rotates the net aligned moment of the H atoms. The additional magnetic field may be provided by an RF excitation signal (e.g., the RF signal generated by the RF coils <b>203</b>). When the additional magnetic field is removed, the magnetic moments of the H atoms rotate back into alignment with the main magnetic field, thereby emitting an MR signal. The acquired MR signals may be digitized and filled into the k-space. One or more images may be generated based on the k-space data. In the present disclosure, terms &#x201c;MR data,&#x201d; &#x201c;MR signal,&#x201d; &#x201c;echo,&#x201d; &#x201c;echo data,&#x201d; and &#x201c;echo signal&#x201d; may be used interchangeably.</p><p id="p-0067" num="0066">If the main magnetic field is uniform across the entire body of the patient, then the RF excitation signal may excite all of the H atoms in the sample non-selectively. Accordingly, in order to image a particular portion of the patient's body, magnetic field gradients Gx, Gy, and Gz (e.g., generated by the gradient coils <b>202</b>) in the X, Y, and Z directions (e.g., same as or similar to the X axis, the Y axis, and the Z axis in <figref idref="DRAWINGS">FIG. <b>1</b></figref>), having a particular timing, frequency, and phase, may be superimposed on the magnetic field such that the RF excitation signal excites the H atoms in one or more target slices of the patient's body, and unique phase and frequency information is encoded in the MR signal depending on the location of the H atoms in the &#x201c;image slice.&#x201d;</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram illustrating exemplary hardware and/or software components of a computing device on which the processing device <b>140</b> may be implemented according to some embodiments of the present disclosure. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the computing device <b>300</b> may include a processor <b>310</b>, a storage <b>320</b>, an input/output (I/O) <b>330</b>, and a communication port <b>340</b>.</p><p id="p-0069" num="0068">The processor <b>310</b> may execute computer instructions (program code) and perform functions of the processing device <b>140</b> in accordance with techniques described herein. The computer instructions may include routines, programs, objects, components, signals, data structures, procedures, modules, and functions, which perform particular functions described herein. For example, the processor <b>310</b> may generate one or more images based on MR data. In some embodiments, the processor <b>310</b> may include a microcontroller, a microprocessor, a reduced instruction set computer (RISC), an application specific integrated circuits (ASICs), an application-specific instruction-set processor (ASIP), a central processing unit (CPU), a graphics processing unit (GPU), a physics processing unit (PPU), a microcontroller unit, a digital signal processor (DSP), a field programmable gate array (FPGA), an advanced RISC machine (ARM), a programmable logic device (PLD), any circuit or processor capable of executing one or more functions, or the like, or any combinations thereof.</p><p id="p-0070" num="0069">Merely for illustration purposes, only one processor is described in the computing device <b>300</b>. However, it should be noted that the computing device <b>300</b> in the present disclosure may also include multiple processors, and thus operations of a method that are performed by one processor as described in the present disclosure may also be jointly or separately performed by the multiple processors. For example, if in the present disclosure the processor of the computing device <b>300</b> executes both operations A and B, it should be understood that operations A and B may also be performed by two different processors jointly or separately in the computing device <b>300</b> (e.g., a first processor executes operation A and a second processor executes operation B, or the first and second processors jointly execute operations A and B).</p><p id="p-0071" num="0070">Merely by way example, the processor <b>310</b> may receive instructions to follow an MRI scan protocol for imaging/scanning the object. For example, the processor <b>310</b> may instruct the object positioning system of the scanner <b>110</b> to move the object to a proper position within the bore of the main magnet <b>201</b>. As another example, the processor <b>310</b> may also provide certain control signals to control the main magnet <b>201</b> to generate a main magnet field with a specific strength.</p><p id="p-0072" num="0071">The processor <b>310</b> may receive control signals to set the shape, amplitude, and/or timing of the gradient waveforms and/or the RF waveforms, and send the set parameters to the waveform generator <b>216</b> to instruct the waveform generator <b>216</b> to generate a particular gradient waveform sequence and pulse sequence that are to be applied to the gradient coils <b>202</b> and the RF coils <b>203</b> through the amplifiers <b>204</b>-<b>207</b>, respectively.</p><p id="p-0073" num="0072">The processor <b>310</b> may also sample data (e.g., echoes) from the RF coils <b>203</b> based on one or more sampling parameters including, e.g., timing information (e.g., the length of data acquisition), the type of k-space data acquisition (e.g., undersampling, oversampling, etc.), sampling trajectory (e.g., a Cartesian trajectory, a non-Cartesian trajectory such as spiral trajectory, radial trajectory, etc.), or the like, or a combination thereof. In some embodiments, the timing information may be input by a user (e.g., an operator) or autonomously determined by the MRI system <b>100</b> based on one or more other parameters (e.g., clinical needs) of an imaging process. The timing information may correspond to the type of the gradient and RF waveforms that are sent to the gradient coils <b>202</b> and the RF coils <b>203</b>, respectively, so that the MR signals are correctly sampled. The processor <b>310</b> may also generate one or more MR images by reconstructing the sampled MR data.</p><p id="p-0074" num="0073">The storage <b>320</b> may store data/information obtained from the scanner <b>110</b>, the user device <b>130</b>, the storage device <b>150</b>, or any other component of the MRI system <b>100</b>. In some embodiments, the storage <b>320</b> may include a mass storage device, a removable storage device, a volatile read-and-write memory, a read-only memory (ROM), or the like, or any combination thereof. For example, the mass storage device may include a magnetic disk, an optical disk, a solid-state drive, etc. The removable storage device may include a flash drive, a floppy disk, an optical disk, a memory card, a zip disk, a magnetic tape, etc. The volatile read-and-write memory may include a random access memory (RAM). The RAM may include a dynamic RAM (DRAM), a double date rate synchronous dynamic RAM (DDR SDRAM), a static RAM (SRAM), a thyristor RAM (T-RAM), and a zero-capacitor RAM (Z-RAM), etc. The ROM may include a mask ROM (MROM), a programmable ROM (PROM), an erasable programmable ROM (PEROM), an electrically erasable programmable ROM (EEPROM), a compact disk ROM (CD-ROM), and a digital versatile disk ROM, etc. In some embodiments, the storage <b>320</b> may store one or more programs and/or instructions to perform exemplary methods described in the present disclosure. For example, the storage <b>320</b> may store a program for the processing device <b>140</b> for generating one or more images based on MR data. In some embodiments, the storage <b>320</b> may store one or more reconstructed MRI images.</p><p id="p-0075" num="0074">The I/O <b>330</b> may input or output signals, data, or information. In some embodiments, the I/O <b>330</b> may enable user interaction with the processing device <b>140</b>. In some embodiments, the I/O <b>330</b> may include an input device and an output device. Exemplary input devices may include a keyboard, a mouse, a touch screen, a microphone, a trackball, or the like, or a combination thereof. Exemplary output devices may include a display device, a loudspeaker, a printer, a projector, or the like, or a combination thereof. Exemplary display devices may include a liquid crystal display (LCD), a light-emitting diode (LED)-based display, a flat panel display, a curved screen, a television device, a cathode ray tube (CRT), or the like, or a combination thereof.</p><p id="p-0076" num="0075">The communication port <b>340</b> may be connected to a network (e.g., the network <b>120</b>) to facilitate data communications. The communication port <b>340</b> may establish connections between the processing device <b>140</b> and the scanner <b>110</b>, the user device <b>130</b>, or the storage device <b>150</b>. The connection may be a wired connection, a wireless connection, or a combination of both that enables data transmission and reception. The wired connection may include an electrical cable, an optical cable, a telephone wire, or the like, or any combination thereof. The wireless connection may include Bluetooth, Wi-Fi, WiMax, WLAN, ZigBee, mobile network (e.g., 3G, 4G, 5G, etc.), or the like, or a combination thereof. In some embodiments, the communication port <b>340</b> may be a standardized communication port, such as RS232, RS485, etc. In some embodiments, the communication port <b>340</b> may be a specially designed communication port. For example, the communication port <b>340</b> may be designed in accordance with the digital imaging and communications in medicine (DICOM) protocol.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram illustrating exemplary hardware and/or software components of a mobile device on which the user device <b>130</b> may be implemented according to some embodiments of the present disclosure. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the mobile device <b>400</b> may include a communication platform <b>410</b>, a display <b>420</b>, a graphics processing unit (GPU) <b>430</b>, a central processing unit (CPU) <b>440</b>, an I/O <b>450</b>, a memory <b>460</b>, and a storage <b>490</b>. In some embodiments, any other suitable component, including but not limited to a system bus or a controller (not shown), may also be included in the mobile device <b>400</b>. In some embodiments, a mobile operating system <b>470</b> (e.g., iOS, Android, Windows Phone, etc.) and one or more applications <b>480</b> may be loaded into the memory <b>460</b> from the storage <b>490</b> in order to be executed by the CPU <b>440</b>. The applications <b>480</b> may include a browser or any other suitable mobile apps for receiving and rendering information relating to image processing or other information from the processing device <b>140</b>. User interactions with the information stream may be achieved via the I/O <b>450</b> and provided to the processing device <b>140</b> and/or other components of the MRI system <b>100</b> via the network <b>120</b>. Merely by way of example, a user (e.g., a doctor, a technician, an engineer, an operator, etc.) of the MRI system <b>100</b> may input data related to an object (e.g., a patient) that is being/to be imaged/scanned through the I/O <b>450</b>. The data related to the object may include identification information (e.g., the name, age, gender, medical history, contact information, physical examination result, etc.) and/or the test information including the nature of the MRI scan that needs to be performed. The user may also input parameters needed for the operation of the scanner <b>110</b>, such as image contrast and/or ratio, a region of interest (ROI), slice thickness, an imaging type (e.g., T1 weighted imaging, T2 weighted imaging, proton density weighted imaging, etc.), T1, T2, an echo type (spin echo, fast spin echo (FSE), fast recovery FSE, single shot FSE, gradient recalled echo, fast imaging with steady-state procession, and so on), a flip angle value, acquisition time (TA), echo time (TE), repetition time (TR), inversion time (TI), saturation time (TS), echo train length (ETL), the number of phases, the number of excitations (NEX), bandwidth (e.g., RF receiver bandwidth, RF transmitter bandwidth, etc.), a scan type, a type of sampling, time points when the MR data is acquired (e.g., cardiac phases, respiratory phases, etc.), time points when an acquisition phase of the scan is triggered, a duration of a period of the acquisition phase, or the like, or any combination thereof. The I/O may also display MR images generated based on the sampled data.</p><p id="p-0078" num="0077">In some embodiments, the I/O <b>450</b> may include an input device and an output device. Exemplary input devices may include a keyboard, a mouse, a touch screen, a microphone, a trackball, or the like, or a combination thereof. Exemplary output devices may include a display device, a loudspeaker, a printer, a projector, or the like, or a combination thereof. Exemplary display devices may include a liquid crystal display (LCD), a light-emitting diode (LED)-based display, a flat panel display, a curved screen, a television device, a cathode ray tube (CRT), or the like, or a combination thereof.</p><p id="p-0079" num="0078">To implement various modules, units, and their functionalities described in the present disclosure, computer hardware platforms may be used as the hardware platform(s) for one or more of the elements described herein. The hardware elements, operating systems and programming languages of such computers are conventional in nature, and it is presumed that those skilled in the art are adequately familiar therewith to adapt those technologies to the blood pressure monitoring as described herein. A computer with user interface elements may be used to implement a personal computer (PC) or another type of work station or terminal device, although a computer may also act as a server if appropriately programmed. It is believed that those skilled in the art are familiar with the structure, programming and general operation of such computer equipment and as a result the drawings should be self-explanatory.</p><p id="p-0080" num="0079"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic block diagram illustrating an exemplary processing device according to some embodiments of the present disclosure. In some embodiments, the processing device <b>140</b> may include an acquisition module <b>520</b> and a reconstruction module <b>530</b>. In some embodiments, the processing device <b>140</b> may further include a control module <b>510</b>.</p><p id="p-0081" num="0080">The acquisition module <b>520</b> may obtain target k-space data related to an ROI of an object.</p><p id="p-0082" num="0081">The reconstruction module <b>530</b> may generate, based on the target k-space data using a trained reconstruction model, one or more target images. The trained reconstruction model may be a machine learning model.</p><p id="p-0083" num="0082">In some embodiments, the reconstruction module <b>530</b> may generate, based on the target k-space data using the trained reconstruction model, a target images corresponding to a target slice of the ROI. In some embodiments, the reconstruction module <b>530</b> may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images (temporal frames) each of which corresponds to a same target slice of the ROI and one of a plurality of target acquisition periods. In some embodiments, the reconstruction module <b>530</b> may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI. In some embodiments, the reconstruction module <b>530</b> may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images (temporal frames) each of which corresponds to one of a plurality of target slices of the ROI and one of a plurality of target acquisition periods.</p><p id="p-0084" num="0083">The control module <b>510</b> may cause the scanner <b>110</b> to scan the ROI of the object. In some embodiment, the control module <b>510</b> may cause the scanner <b>110</b> to apply one or more multiband excitation radio frequency (RF) pulses to the ROI to simultaneously excite, for one or more times, the plurality of target slices of the ROI. In some embodiment, the control module <b>510</b> may cause the MRI device to apply phase modulation to at least one of the excited target slices by applying, to each of the at least one of the excited target slices, a transmit phase that varies with a plurality of target acquisition periods and/or a phase encoding direction.</p><p id="p-0085" num="0084">The acquisition module <b>520</b> may acquire the target k-space data from the plurality of excited target slices of the ROI at the plurality of target acquisition periods.</p><p id="p-0086" num="0085">The modules in the processing device <b>140</b> may be connected to or communicate with each other via a wired connection or a wireless connection. The wired connection may include a metal cable, an optical cable, a hybrid cable, or the like, or any combination thereof. The wireless connection may include a Local Area Network (LAN), a Wide Area Network (WAN), a Bluetooth, a ZigBee, a Near Field Communication (NFC), or the like, or any combination thereof. Two or more of the modules may be combined as a single module, and any one of the modules may be divided into two or more units. For example, the reconstruction module <b>530</b> may be divided into a first unit configured to obtain a trained reconstruction model and a first unit configured to perform image reconstruction using the trained reconstruction model.</p><p id="p-0087" num="0086">It should be noted that the above description is merely provided for the purposes of illustration, and not intended to limit the scope of the present disclosure. For persons having ordinary skills in the art, multiple variations and modifications may be made under the teachings of the present disclosure. However, those variations and modifications do not depart from the scope of the present disclosure. For example, the processing device <b>140</b> may further include a storage module (not shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). The storage module may be configured to store data generated during any process performed by any component of the processing device <b>140</b>. As another example, each of the components of the processing device <b>140</b> may include a storage device. Additionally or alternatively, the components of the processing device <b>140</b> may share a common storage device.</p><p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is a flowchart illustrating an exemplary process for SMS imaging according to some embodiments of the present disclosure. In some embodiments, the process <b>600</b> may be implemented in the MRI system <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, the process <b>600</b> may be stored in a storage device (e.g., the storage device <b>150</b>, or the storage <b>320</b> of the processing device <b>140</b>) as a form of instructions, and can be invoked and/or executed by the processing device <b>140</b> (e.g., the processor <b>310</b> of the processing device <b>140</b>, or one or more modules in the processing device <b>140</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). The operations of the illustrated process <b>600</b> presented below are intended to be illustrative. In some embodiments, the process <b>600</b> may be accomplished with one or more additional operations not described, and/or without one or more of the operations discussed. Additionally, the order in which the operations of the process <b>600</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> and described below is not intended to be limiting.</p><p id="p-0089" num="0088">In <b>610</b>, the processing device <b>140</b> (e.g., the control module <b>510</b>) may cause an MRI device (e.g., the scanner <b>110</b>) to apply one or more excitation radio frequency (RF) pulses to a region of interest (ROI) of an object (e.g., a patient) to simultaneously excite, for one or more times, a plurality of target slices of the ROI.</p><p id="p-0090" num="0089">In some embodiments, the RF coils <b>203</b> may generate the one or more excitation RF pulses each of which is applied to the ROI to simultaneously excite a plurality of target slices of the ROI for one time. An excitation RF pulse may be applied in the presence of a slice-selective gradient in order to produce transverse magnetization in the plurality of target slice of the ROI.</p><p id="p-0091" num="0090">In some embodiments, the excitation RF pulse may be a composite RF pulse including a plurality of excited bands each of which is used to excite one of the plurality of target slices. For example, each of the plurality of excited bands may be of a different frequency value and bandwidth corresponding to the slice location and/or thickness of one of the plurality of target slices so as to excite the corresponding target slice.</p><p id="p-0092" num="0091">In <b>620</b>, the processing device <b>140</b> (e.g., the control module <b>510</b>) may cause the MRI device (e.g., the scanner <b>110</b>) to apply phase modulation to at least one of the plurality of excited target slices by applying, to each of the at least one of the plurality of excited target slices, a transmit phase that varies with a plurality of target acquisition periods and/or a phase encoding direction.</p><p id="p-0093" num="0092">In some embodiments, a target acquisition period may refer to a period in which target k-space data corresponding to an aliased image of the plurality of target slices is acquired. In some embodiments, in SMS imaging, k-space data corresponding to the plurality of target slices may be acquired simultaneously. Therefore, a target acquisition period may also refer to a period in which target k-space data corresponding to a target unaliased image (details regarding &#x201c;target unaliased image&#x201d; can be found in description in connection with operation <b>640</b>) of one of the plurality of target slices. For example, the process <b>600</b> for SMS imaging may be used to generate a physiological motion cine of the ROI (e.g., a cine of the cardiac motion of a heart or the respiration motion of a lung). In this case, a series of unaliased image (e.g., temporal frames) each of which depicts one of the plurality of target slices corresponding to a motion phase (e.g., a cardiac phase such as cardiac diastole or cardiac systole, or a respiration phase such as end-expiration or end-inspiration) may be generated. A target acquisition period may correspond to a motion phase. As another example, the process <b>600</b> for SMS imaging may be used for perfusion analysis and indicating a change of a density of a contrast agent in the plurality of target slices over time. In this case, a series of unaliased image (e.g., temporal frames) each of which indicates a density of a contrast agent in one of the plurality of target slices at a time point may be generated. A target acquisition period may correspond to a time point of a time-density curve of the contrast agent.</p><p id="p-0094" num="0093">In some embodiments, a transmit phase applied to a target slice may vary with the plurality of target acquisition periods. For example, transmit phases applied to k-space data corresponding to different target unaliased images (e.g., temporal frames) of a same target slice may be different. In some embodiments, the transmit phase applied to the target slice may further vary along a phase encoding direction. In some embodiments, one of the plurality of target slices may not be phase-modulated, e.g., not be applied to a transmit phase. In some embodiments, the transmit phases applied to two or more of the plurality of target slices may be different.</p><p id="p-0095" num="0094">In some embodiments, a transmit phase applied to a target slice may include a plurality of phase profiles that are applied to the target slice corresponding to the plurality of target acquisition periods. For example, one of the plurality of phase profiles &#x3b8;<sub>p,s</sub><sup>l </sup>(0&#x2264;&#x3b8;&#x2264;2&#x3c0;) may be applied to a target slice s so that MR data (e.g., an echo) that is generated from the target slice s and filled into a phase encoding line/in a target acquisition period p is of a phase value corresponding to the phase profile &#x3b8;<sub>p,s</sub><sup>l</sup>. In some embodiments, the phase profiles corresponding to the same target slice, the same target acquisition period, and two consecutive phase encoding lines may be different. For example, &#x3b8;<sub>p,s</sub><sup>l </sup>may be different from &#x3b8;<sub>p,s</sub><sup>l+1</sup>. In some embodiments, the phase profiles corresponding to the same target slice and the same target acquisition period may be dynamically cycled as a function of phase encoding lines, e.g., &#x3b8;<sub>p,s</sub><sup>l</sup>=&#x3b8;<sub>p,s</sub><sup>l+&#x394;l</sup>, wherein &#x394;l may be an arbitrary integer, and particularly, equal to the number (or count) of the plurality of target slices. In some embodiments, the phase profiles corresponding to the same target slice, the same phase encoding line, and two consecutive target acquisition periods may be different. For example, &#x3b8;<sub>p,s</sub><sup>l </sup>may be different from &#x3b8;<sub>p+1,s</sub><sup>l</sup>. In some embodiments, the phase profiles corresponding to the same target slice and the same phase encoding line may be dynamically cycled as a function of the plurality of target acquisition periods, e.g., &#x3b8;<sub>p+&#x394;p,s</sub><sup>l</sup>=&#x3b8;<sub>p,s</sub><sup>l</sup>, wherein &#x394;p may be an arbitrary integer, and particularly, equal to the number (or count) of the plurality of target slices. In some embodiments, &#x3b8;<sub>p+&#x394;,s</sub><sup>l</sup>=&#x3b8;<sub>p,s</sub><sup>l+&#x394;</sup>, wherein &#x394; may be an arbitrary integer.</p><p id="p-0096" num="0095">In some embodiments, the transmit phases applied to two or more of the plurality of target slices may be with different variations over the phase encoding direction and/or the plurality of target acquisition periods.</p><p id="p-0097" num="0096">In some embodiments, the application, to a target slice, of a transmit phase varying over the phase encoding direction and a plurality of target acquisition periods may achieve a field of view (FOV) shift of the target slice in image domain corresponding to each of the plurality of target acquisition periods, and the FOV shifts of the target slice corresponding to the plurality of target acquisition periods may be different. In some embodiments, the FOV shifts of the target slice corresponding to two consecutive target acquisition periods may be different. In some embodiments, the FOV shifts of the target slice corresponding to the plurality of target acquisition periods may be dynamically cycled as a function of the plurality of target acquisition periods. For example, the FOV shift of the target slice corresponding to the target acquisition period P<sub>1 </sub>is FOV/3, the FOV shift of the target slice corresponding to the target acquisition period P<sub>2 </sub>is 2FOV/3, the FOV shift of the target slice corresponding to the target acquisition period P<sub>3 </sub>is FOV/3, and so on. In some embodiments, the FOV shifts of different phase-modulated target slices corresponding to the same target acquisition period may be different. For example, the FOV shift of the target slice s<sub>1 </sub>corresponding to the target acquisition period P<sub>1 </sub>is FOV/3, and the FOV shift of the target slice s<sub>2 </sub>corresponding to the target acquisition period P<sub>1 </sub>is 2FOV/3.</p><p id="p-0098" num="0097">In some embodiments, the phase modulation of the at least one of the plurality of target slices may be realized by equipping the one or more excitation RF pulses with the phase profiles of the transmit phase applied to the at least one of the plurality of target slices. For example, for a phase profile corresponding to a phase encoding line, a target slice, and a target acquisition period, if the phase encoding line is acquired corresponding to the excitation of an excited band of an excitation RF pulse, the phase profile may be equipped in the excited band.</p><p id="p-0099" num="0098">Details regarding the transmit phase may be found in, for example, the reference &#x201c;Ferrazzi G, et al., Autocalibrated multiband CAIPIRINHA with through-time encoding: Proof of principle and application to cardiac tissue phase mapping, Magn Reson Med. 2019 February; 81(2):1016-1030,&#x201d; which is incorporated herein by reference.</p><p id="p-0100" num="0099">In <b>630</b>, the processing device <b>140</b> (e.g., the acquisition module <b>520</b>) may acquire target k-space data (also referred to as autocalibration acquisition data) from the plurality of excited target slices of the ROI at the plurality of target acquisition periods.</p><p id="p-0101" num="0100">In some embodiments, following excitation of the nuclear spins in the plurality of target slices, target k-space data may be acquired by sampling a series of echo signals generated from the plurality of excited target slices in the presence of a plurality of readout gradients (also referred to as frequency encoding gradients) and a plurality of phase encoding gradients. A readout gradient may act to fill an echo signal into the k-space along the frequency-encoding direction. The spatial encoding of an echo signal along the phase-encoding direction may be performed by a phase encoding gradient. The phase-encoding gradient may act to determine a filling position (e.g., a phase encoding line) of an echo signal in the k-space along the phase encoding direction.</p><p id="p-0102" num="0101">In some embodiments, the k-space may be undersapmed, fully sampled, or oversampled to obtain the target k-space data. In some embodiments, the trajectory of the target k-space data may include a Cartesian trajectory or a non-Cartesian trajectory such as radial lines and spirals.</p><p id="p-0103" num="0102">In some embodiments, a pulse sequence may include an excitation pulse RF, a slice-selective gradient, one or more readout gradients, and one or more phase encoding gradients illustrated above. The pulse sequence may be repeated one or more times such that the target k-space data are acquired. In some embodiments, the pulse sequence may include gradient-recalled echo (GRE), balanced steady-state free precession (bSSFP), fast spin-echo (FSE), echo-planer imaging (EPI), etc.</p><p id="p-0104" num="0103">In some embodiments, the target k-space data may include a plurality of first k-space data sets each of which corresponds to the plurality of target slices and one of the plurality of target acquisition periods. A first k-space data set may be an aliased k-space data set that including k-space data from the plurality of target slices corresponding to one of the plurality of target acquisition periods. An aliased image of the plurality of target slices corresponding to one of the plurality of target acquisition periods may be obtained by performing inverse Fourier transform on the corresponding first k-space data set.</p><p id="p-0105" num="0104">In some embodiments, after the plurality of target slices are simultaneously excited, a plurality of sets of echo signals may be generated from the plurality of excited target slices in sequence. Each of the plurality of sets of echo signals may include a plurality echo signals that are simultaneously generated from the plurality of excited target slices, respectively. Under the effect of the readout gradients and the phase encoding gradients, the echo signals simultaneously generated from the plurality of target slices may be filled into the same position (e.g., a phase encoding line) in the k-space. In this way, when the filing of the k-space is finished, the acquired k-space data may be referred to as a first k-space data set of the target k-space data. The period in which the first k-space data set is acquired may be referred to as a target acquisition period.</p><p id="p-0106" num="0105">In some embodiments, the plurality of first k-space data sets may be acquired in sequence. For example, after the acquisition of a first k-space data set is finished, the acquisition of anther first k-space data set may start. In some embodiments, the plurality of first k-space data sets may be acquired in parallel. For example, for cardiac cine imaging, in a first cardiac cycle, echo signals generated corresponding to a first cardiac phase may be filled into a first k-space, and echo signals generated corresponding to a second cardiac phase subsequent to the first cardiac phase in the first cardiac cycle may be filled into a second k-space. In a second cardiac cycle subsequent to the first cardiac cycle, echo signals generated corresponding to the first cardiac phase may be filled into the first k-space, and echo signals generated corresponding to the second cardiac phase may be filled into the second k-space. In this way, a first k-space data set 1 may be obtained by filling the first k-space, and a first k-space data set 2 may be obtained by filling the second k-space. The first k-space data set 1 and the first k-space data set 2 may be acquired in parallel. The first k-space data set 1 may correspond to the first cardiac phase, and the first k-space data set 2 may correspond to the second cardiac phase.</p><p id="p-0107" num="0106">In some embodiments, a period between two consecutive excitation RF pulses may be referred to as a repetition time (TR). There may be any correspondence between a TR and a target acquisition period. For example, a TR may include one or more target acquisition periods, indicating that one or more first k-space data sets may be acquired within a TR. As another example, different portions of a target acquisition period may be distributed in more than one TRs, indicating that a first k-space data set corresponding to the target acquisition period may be acquired within more than one TR.</p><p id="p-0108" num="0107"><figref idref="DRAWINGS">FIGS. <b>6</b>B and <b>6</b>C</figref> are schematic diagrams illustrating exemplary acquisition of target k-space data according to some embodiments of the present disclosure.</p><p id="p-0109" num="0108">As shown in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, three target slices, s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, are simultaneously excited. Target k-space data may be acquired from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3 </sub>in a first target acquisition period P<sub>1 </sub>and a second target acquisition period P<sub>2</sub>. The target k-space data may include a first k-space data set D<sub>1 </sub>that is acquired from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3 </sub>by filling a first k-space K<sub>1 </sub>in P<sub>1 </sub>and a first k-space data set D<sub>2 </sub>that is acquired from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3 </sub>by filling a second k-space K<sub>2 </sub>in P<sub>2</sub>. Slice s<sub>1 </sub>may not be phase-modulated, e.g., not be applied to any transmit phase, in P<sub>1 </sub>and P<sub>2</sub>. Slice s<sub>2 </sub>may be phase-modulated by being applied to a first transmit phase that varies over spatial dimension, e.g., the phase encoding direction, and the temporal dimension, e.g., P<sub>1 </sub>and P<sub>2</sub>. Slice s<sub>3 </sub>may be phase-modulated by being applied to a second transmit phase that varies over spatial dimension, e.g., the phase encoding direction, and the temporal dimension, e.g., P<sub>1 </sub>and P<sub>2</sub>. The first transmit phase may be different from the second transmit phase.</p><p id="p-0110" num="0109">In some embodiments, the first k-space data set D<sub>1 </sub>and the first k-space data set D<sub>2 </sub>may be acquired in sequence. For example, as shown in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, after s<sub>1</sub>, s<sub>2</sub>, and s<sub>3 </sub>are simultaneously excited, three echo signals echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>1</sup>, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>1</sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>1 </sup>may be simultaneously generated from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, respectively. Echo signal echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>1 </sup>may not be applied to any phase profile, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>1 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>1 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, Under the effect of a readout gradient and a phase encoding gradient, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>1 </sup>with no phase modulation, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>1 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>1 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>, s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>may be filled into the same position (e.g., the phase encoding line l<sub>1</sub>) of the first k-space K<sub>1</sub>. Subsequently, another three echo signals echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>2</sup>, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>2</sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>2 </sup>may be simultaneously generated from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, respectively. Echo signal echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>2 </sup>may not be applied to any phase profile, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>2 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>1 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>. Under the effect of a readout gradient and a phase encoding gradient, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>2 </sup>with no phase modulation, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>2 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>2 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2 </sub2></sup>may be filled into the same position (e.g., the phase encoding line l<sub>2</sub>) of the first k-space K<sub>1</sub>. The first k-space may be sampled in the above way to acquire the first k-space data set D<sub>1 </sub>in P<sub>1</sub>.</p><p id="p-0111" num="0110">After the acquisition of the first k-space data set D<sub>1 </sub>is finished, the acquisition of the first k-space data set D<sub>2 </sub>is started. For three echo signals echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>3</sup>, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>3</sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>3 </sup>simultaneously generated from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, respectively, echo may not be applied to any phase profile, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>3 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>3 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, Under the effect of a readout gradient and a phase encoding gradient, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>3 </sup>with no phase modulation, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>3 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>3 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>may be filled into the same position (e.g., the phase encoding line l<sub>1</sub>) of the second k-space K<sub>2</sub>. Subsequently, another three echo signals echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>4</sup>, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>4</sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>4 </sup>may be simultaneously generated from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, respectively. Echo signal echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>4 </sup>may not be applied to any phase profile, echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>4 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>4 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>. Under the effect of a readout gradient and a phase encoding gradient, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>4 </sup>with no phase modulation, echo<sub>s</sub><sup>4</sup><sub>2 </sub>with the phase &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>4 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2 </sub2></sup>may be filled into the same position (e.g., the phase encoding line l<sub>2</sub>) of the second k-space K<sub>2</sub>. The second k-space may be sampled in the above way to acquire the first k-space data set D<sub>2 </sub>in P<sub>2</sub>.</p><p id="p-0112" num="0111">Alternatively, the first k-space data set D<sub>1 </sub>and the first k-space data set D<sub>2 </sub>may be acquired in parallel. For example, for cardiac cine imaging, as shown in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, after s<sub>1</sub>, s<sub>2</sub>, and s<sub>3 </sub>are simultaneously excited, three echo signals echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>1</sup>, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>1</sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>1 </sup>may be simultaneously generated corresponding to a first cardiac phase in a first cardiac cycle from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, respectively. Echo signal echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>1 </sup>may not be applied to any phase profile, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>1 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>1 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>. Under the effect of a readout gradient and a phase encoding gradient, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>1 </sup>with no phase modulation, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>1 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>1 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>may be filled into the same position (e.g., the phase encoding line l<sub>1</sub>) of the first k-space Subsequently, another three echo signals echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>2</sup>, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>2</sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>2 </sup>may be simultaneously generated corresponding to a first cardiac phase in the first cardiac cycle from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, respectively. Echo signal echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>2 </sup>may not be applied to any phase profile, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>2 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>2 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>. Under the effect of a readout gradient and a phase encoding gradient, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>2 </sup>with no phase modulation, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>2 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>2 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>may be filled into the same position (e.g., the phase encoding line l<sub>1</sub>) of the second k-space K<sub>2</sub>.</p><p id="p-0113" num="0112">For three echo signals echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>3</sup>, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>3</sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>3 </sup>simultaneously generated corresponding to the first cardiac phase in a second cardiac cycle from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, respectively, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>3 </sup>may not be applied to any phase profile, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>3 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>3 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>. Under the effect of a readout gradient and a phase encoding gradient, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>3 </sup>with no phase modulation, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>3 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>3 </sup>with the phase &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2 </sub2></sup>may be filled into the same position (e.g., the phase encoding line l<sub>2</sub>) of the first k-space Kt. Subsequently, another three echo signals echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>4</sup>, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>4</sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>4 </sup>may be simultaneously generated corresponding to the second cardiac phase in the second cardiac cycle from s<sub>1</sub>, s<sub>2</sub>, and s<sub>3</sub>, respectively. Echo signal echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>4 </sup>may not be applied to any phase profile, echo<sub>s</sub><sub><sub2>2</sub2></sub><sup>4 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, and echo<sub>s</sub><sub><sub2>3</sub2></sub><sup>4 </sup>may be applied to a phase profile &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>. Under the effect of a readout gradient and a phase encoding gradient, echo<sub>s</sub><sub><sub2>1</sub2></sub><sup>4 </sup>with no phase modulation, echo<sub>s</sub><sup>4</sup><sub>2 </sub>with the phase &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, and echo<sub>s</sub><sup>4</sup><sub>3 </sub>with the phase &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2 </sub2></sup>may be filled into the same position (e.g., the phase encoding line l<sub>2</sub>) of the second k-space K<sub>2</sub>. The first k-space K<sub>1 </sub>and the second k-space K<sub>2 </sub>may be sampled in parallel in the above way to acquire the first k-space data set D<sub>1 </sub>in P<sub>1 </sub>(corresponding to the first cardiac phase) and the first k-space data set D<sub>2 </sub>in P<sub>2 </sub>(corresponding to the second cardiac phase).</p><p id="p-0114" num="0113">In some embodiments, s<sub>2 </sub>may be phase-modulated by being applied to a first transmit phase that varies over spatial dimension, e.g., the phase encoding direction, and the temporal dimension, e.g., P<sub>1 </sub>and P<sub>2</sub>. For example, the first transmit phase may include phase profiles &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, &#x3b8;&#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>1</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>may be different from &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2 </sub2></sup>and &#x3b8;&#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>may be different from &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>. In some embodiments, s<sub>3 </sub>may be phase-modulated by being applied to a second transmit phase that varies over spatial dimension, e.g., the phase encoding direction, and the temporal dimension, e.g., P<sub>1 </sub>and P<sub>2</sub>. For example, the second transmit phase may include phase profiles &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>. &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>may be different from &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2 </sub2></sup>and &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1 </sub2></sup>may be different from &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>. In some embodiments, the first transmit phase may be different from the second transmit phase. For example, the variation of &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>2</sub2></sub><sup>l</sup><sup><sub2>2 </sub2></sup>may be different from the variation of &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, &#x3b8;<sub>p</sub><sub><sub2>1</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>, &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>1</sub2></sup>, and &#x3b8;<sub>p</sub><sub><sub2>2</sub2></sub><sub>,s</sub><sub><sub2>3</sub2></sub><sup>l</sup><sup><sub2>2</sub2></sup>.</p><p id="p-0115" num="0114">In some embodiments, the acquisition of the target k-space data may be implemented on a single or multiple channel receiver coil.</p><p id="p-0116" num="0115">In <b>640</b>, the processing device <b>140</b> (e.g., the reconstruction module <b>530</b>) may generate, based on the target k-space data using a trained reconstruction model, a plurality of target unaliased images each of which corresponds to one of the plurality of target slices and one of the plurality of target acquisition periods. For example, the process <b>600</b> for SMS imaging may be used to generate a physiological motion cine of the ROI (e.g., a cine of the cardiac motion of a heart or the respiration motion of a lung). In this case, a series of target unaliased image (e.g., temporal frames) each of which depicts one of the plurality of target slices corresponding to a motion phase (e.g., a cardiac phase such as cardiac diastole or cardiac systole, or a respiration phase such as end-expiration or end-inspiration) may be generated. A target acquisition period may correspond to a temporal frame and the corresponding motion phase. As another example, the process <b>600</b> for SMS imaging may be used for perfusion analysis and indicating a change of a density of a contrast agent in the plurality of target slices over time. In this case, a series of unaliased image (e.g., temporal frames) each of which indicates a density of a contrast agent in one of the plurality of target slices at a time point may be generated. A target acquisition period may correspond to the temporal frame and the corresponding time point.</p><p id="p-0117" num="0116">In some embodiments, compared with the imaging that only excites a single slice one time, SMS excites multiple slices at the same time and simultaneously acquires magnetic resonance (MR) signals generated from the multiple excited slices. The MR signals are filled into the k-space to generate k-space data. Because the received MR signals include the contributions of the multiple excited slices, reconstruction of the k-space data directly using inverse Fourier transform may lead to an aliased image of the multiple slices. As used in the present disclosure, the term &#x201c;target unaliased image,&#x201d; also referred to as &#x201c;target image,&#x201d; refers to an image corresponding to a single slice of the multiple simultaneously excited slices, which is less aliased or unaliased relative to the aliased image of the multiple slices.</p><p id="p-0118" num="0117">In some embodiments, the trained reconstruction model may include a machine learning model or other forms of computer intelligence. In some embodiments, the trained reconstruction model may include a deep learning model. In some embodiments, the trained reconstruction model may include a neural network model. In some embodiments, the trained reconstruction model may include a convolutional neural network (CNN), a U-net, a V-net, and a recurrent neural network (RNN), or the like, or any combination thereof.</p><p id="p-0119" num="0118">In some embodiments, the target k-space data may be input into the trained reconstruction model, and the trained reconstruction model may output the plurality of target unaliased images based on the target k-space data.</p><p id="p-0120" num="0119">In some embodiments, the processing device <b>140</b> may generate a plurality of target aliased images by performing inverse Fourier transform on the target k-space data. Each of the plurality of target aliased images may correspond to the plurality of target slices and one of the plurality of target acquisition periods. For example, the target k-space data may include a plurality of first k-space data sets each of which corresponds to the plurality of target slices and one of the plurality of target acquisition periods. The processing device <b>140</b> may generate the plurality of target aliased images by performing inverse Fourier transform on the plurality of first k-space data sets, respectively. The processing device <b>140</b> may input the plurality of aliased images into the trained reconstruction model. The trained reconstruction model may output the plurality of target unaliased images based on the plurality of target aliased images.</p><p id="p-0121" num="0120">In some embodiments, the processing device <b>140</b> may determine a plurality of reference data sets based on the target k-space data. Each of the plurality of reference data sets may correspond to one of the plurality of target slices and one of the plurality of target acquisition periods. The plurality of reference data sets may provide unaliased information for unaliasing of the plurality of target slices in the target k-space data.</p><p id="p-0122" num="0121">In some embodiments, for a target acquisition period A, the processing device <b>140</b> may combine two or more first k-space data sets corresponding to two or more consecutive target acquisition periods including the target acquisition period A to generate separated data sets each of which corresponds to one of the plurality of target slices and the target acquisition period A. Subsequently, the processing device <b>140</b> may generate the reference data sets by applying phase modulation similar to what is illustrated in operation <b>620</b> by multiplying the corresponding separated data sets with the at least one transmit phase to match the phase modulation of the target k-space data.</p><p id="p-0123" num="0122">In some embodiments, the processing device <b>140</b> may generate the reference data sets using another method. For example, the processing device <b>140</b> may generate an averaged data set by averaging the separated data sets corresponding to the plurality of target acquisition periods. The processing device <b>140</b> may generate the reference data sets from the averaged data set.</p><p id="p-0124" num="0123">Details regarding determining the reference data sets based on the target k-space data may be found in, for example, the reference &#x201c;Ferrazzi G, et al., Autocalibrated multiband CAIPIRINHA with through-time encoding: Proof of principle and application to cardiac tissue phase mapping, Magn Reson Med. 2019 February; 81(2):1016-1030,&#x201d; which is incorporated herein by reference.</p><p id="p-0125" num="0124">In some embodiments, the processing device <b>140</b> may generate, based on the target k-space data and the plurality of reference data sets, the plurality of target unaliased images using the trained reconstruction model. For example, the processing device <b>140</b> may generate a plurality of aliasing images each of which corresponds to the plurality of target slices and one of the plurality of target acquisition periods by performing inverse Fourier transform on the target k-space data. The processing device <b>140</b> may generate a plurality of reference images with low image resolution by performing inverse Fourier transform on the reference data sets. The processing device <b>140</b> may input the plurality of aliasing images and the plurality of reference images into the trained reconstruction model. The trained reconstruction model may output the plurality of unaliased images based on the plurality of aliasing images and the plurality of reference images.</p><p id="p-0126" num="0125">As another example, the processing device <b>140</b> may input the target k-space data and the plurality of reference data sets into the trained reconstruction model. The trained reconstruction model may output the plurality of unaliased images based on the target k-space data and the plurality of reference data sets.</p><p id="p-0127" num="0126"><figref idref="DRAWINGS">FIG. <b>6</b>D</figref> is a schematic diagram illustrating an exemplary trained reconstruction model <b>650</b> according to some embodiments of the present disclosure.</p><p id="p-0128" num="0127">As shown in <figref idref="DRAWINGS">FIG. <b>6</b>D</figref>, the trained reconstruction model <b>650</b> may include an input layer <b>651</b>, an output layer <b>652</b>, and a plurality of hidden layers <b>653</b>. The layers of the trained reconstruction model <b>650</b> may be connected in a feed-forward fashion, and an output of an i<sup>th </sup>layer may be provided as an input to an (1&#xb1;1)<sup>th </sup>layer. In some embodiments, in the trained reconstruction model <b>650</b>, the input layer <b>651</b> may be configured to receive input data (e.g., the target k-space data, the plurality of aliased images, the plurality of reference data sets, or the plurality of reference images) of the trained reconstruction model <b>650</b>. Each hidden layer (e.g., <b>653</b>-<b>1</b>, <b>653</b>-<b>2</b>, . . . , <b>653</b>-N, etc.) may perform a specific function, e.g., convolution, pooling, normalization, matrix multiplication, non-linear activation, or the like. The output layer <b>652</b> may receive an input from the preceding layer and apply one or more transformations to the received input to generate output data (e.g., the plurality of target unaliased images) of the trained reconstruction model <b>650</b>. In some embodiments, the trained reconstruction model <b>650</b> may operate by managing coefficients of a weighting function that converts the input data into the output data. The weighting function may be represented as the plurality of hidden layers <b>653</b> between the input layer <b>651</b> and the output layer <b>652</b> of the trained reconstruction model <b>650</b>. In some embodiments, each node (e.g., A-N in <figref idref="DRAWINGS">FIG. <b>6</b>D</figref>) of the plurality of hidden layers <b>653</b> may read the input data, multiplies by various weights or coefficients, and produces the output data.</p><p id="p-0129" num="0128">For illustration purposes, a convolutional neural network (CNN) model may be taken as an example. Exemplary hidden layers may include a convolutional layer, a pooling layer, and a fully connected layer. In some embodiments, input data such as k-space data (e.g., the target k-space data and/or the plurality of reference data sets) or one or more images (e.g., the plurality of aliased images and/or the plurality of reference images) may be inputted into the trained reconstruction model. The k-space data or the one or more images may be represented as a 2D matrix or a 3D matrix including a plurality of elements (e.g., pixels or voxels). Each of the plurality of elements in the matrix may have a value representing a feature or characteristic of the element.</p><p id="p-0130" num="0129">The convolutional layer may include one or more kernels, which may be used to extract a feature of the input data. In some embodiments, each of the one or more convolutional kernel may have a specific size and stride. In some embodiments, each of the one or more kernels may filter a portion of the input data to generate a specific feature corresponding to the portion. The specific feature may be determined based on the one or more kernels. Exemplary features may include a low-level feature (e.g., an edge feature, a textural feature, a pixel value feature), a high-level feature, or a complicated feature.</p><p id="p-0131" num="0130">The pooling layer may take an output of the convolutional layer as an input. The pooling layer may include a plurality of pooling nodes, which may be used to sample the output of the convolutional layer, so as to reduce the computational load of data processing and accelerate the speed of data processing speed. In some embodiments, a size of the matrix representing the input data may be reduced in the pooling layer.</p><p id="p-0132" num="0131">The fully connected layer may include a plurality of neurons. The neurons may be connected to the pooling nodes in the pooling layer. In the fully connected layer, a plurality of vectors corresponding to the plurality of pooling nodes may be determined based on one or more features of the input data, and a plurality of weighting coefficients may be assigned to the plurality of vectors.</p><p id="p-0133" num="0132">The output layer may determine an output based on the vectors and the weighting coefficients obtained from the fully connected layer. In some embodiments, an output of the output layer may include the plurality of target unaliased images.</p><p id="p-0134" num="0133">In some embodiments, the trained reconstruction model may be implemented on one or more processing devices (e.g., the processing device <b>140</b>, the processor <b>210</b>, the terminal <b>130</b>, the CPU <b>340</b>, the GPU <b>330</b>, etc.). For example, one or more layers may be respectively implemented on a processing device. As another example, one or more components of a layer may be implemented on a same processing device. In some embodiments, a plurality of processing devices may execute a parallel processing operation in some layers of the trained reconstruction model by, for example, assigning two or more processing devices for an operation of different nodes (e.g., a kernel, a pooling node, a neuron) in the trained reconstruction model. For example, a first GPU may execute the operation corresponding to kernel A and kernel B, and a second kernel may execute the operation corresponding to kernel C and kernel D. Similarly, a plurality of GPUs may also execute the operation of other nodes (e.g., a kernel, a pooling node, a neuron) in the trained reconstruction model.</p><p id="p-0135" num="0134">In addition, in some embodiments, a storage device (e.g., the storage device <b>150</b>, the storage <b>320</b>, the storage <b>490</b>, the memory <b>460</b>, etc.) may be provided for storing data related to the trained reconstruction model, such as an activation functions, a learned weight for each node, and/or a network topology (e.g., a number (or count) of the hidden layers, a type of each hidden layer, etc.). Optionally, the storage device may further store a training data set.</p><p id="p-0136" num="0135">Traditional reconstruction methods for SMS imaging may be performed either in image domain using a least-squares approach (e.g., sensitivity encoding algorithm (SENSE)) or in k-space using a linear approach (e.g., generalized autocalibrating partially parallel acquisitions (GRAPPA)). In comparison, the reconstruction for SMS imaging using a machine learning model is a non-linear approach, which may improve image quality and reconstruction speed.</p><p id="p-0137" num="0136">In some embodiments, the reconstruction method using a machine learning model in the present disclosure may be applied in phase-modulated (as illustrated in operation <b>620</b>) SMS imaging of a series dynamic images.</p><p id="p-0138" num="0137">For example, the reconstruction method using a machine learning model in the present disclosure may be applied in reconstruction of a physiological motion (e.g., a cardiac motion or a respiration motion) cine of an ROI (e.g., at least a portion of a heart or a lung). In this case, each of the plurality of target acquisition periods may correspond to a physiological motion phase (e.g., a cardiac phase or a respiration phase) of the ROI, and the plurality of target unaliased images may form a physiological motion cine of the ROI.</p><p id="p-0139" num="0138">As another example, the reconstruction method using a machine learning model in the present disclosure may be applied in perfusion imaging. In this case, the plurality of target unaliased images may be used for perfusion analysis and indicate a change of a density of a contrast agent in the plurality of target slices over time, and a target acquisition period may correspond to a time point in the time-density curve of the contrast agent in the plurality of target slices.</p><p id="p-0140" num="0139">It should be noted that the above description is merely provided for the purposes of illustration, and not intended to limit the scope of the present disclosure. For persons having ordinary skills in the art, multiple variations and modifications may be made under the teachings of the present disclosure. However, those variations and modifications do not depart from the scope of the present disclosure.</p><p id="p-0141" num="0140"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart illustrating an exemplary process for obtaining a trained reconstruction model according to some embodiments of the present disclosure. In some embodiments, the process <b>700</b> may be implemented in the MRI system <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, the process <b>700</b> may be stored in a storage device (e.g., the storage device <b>150</b>, or the storage <b>320</b> of the processing device <b>140</b>) as a form of instructions, and can be invoked and/or executed by the processing device <b>140</b> (e.g., the processor <b>310</b> of the processing device <b>140</b>, or one or more modules in the processing device <b>140</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). The operations of the illustrated process <b>700</b> presented below are intended to be illustrative. In some embodiments, the process <b>700</b> may be accomplished with one or more additional operations not described, and/or without one or more of the operations discussed. Additionally, the order in which the operations of the process <b>700</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref> and described below is not intended to be limiting.</p><p id="p-0142" num="0141">In <b>710</b>, the reconstruction module <b>530</b> may obtain a plurality of training data sets. Each of the plurality of training data sets may include sample k-space data and a plurality of sample images.</p><p id="p-0143" num="0142">In some embodiments, each of the plurality of sample images may correspond to one of a plurality of sample slices of a sample and one of a plurality of sample acquisition periods. As used in the present disclosure, the term &#x201c;sample image,&#x201d; also referred to as &#x201c;sample unaliased image,&#x201d; refers to an image corresponding to a single slice of the plurality of sample slices of the sample, which is less aliased or unaliased relative to an aliased image of the plurality of sample slices.</p><p id="p-0144" num="0143">In some embodiments, the corresponding sample k-space data for each of at least one of the plurality of sample slices may be phase-modulated. In some embodiments, for each of at least one of the plurality of sample slices, phases of the corresponding sample k-space data may vary based on the plurality of sample acquisition periods. In some embodiments, for each of at least one of the plurality of sample slices, phases of the corresponding sample k-space data may further vary along the phase encoding direction. In some embodiments, modulated phases of the sample k-space data corresponding to two or more slices may be different.</p><p id="p-0145" num="0144">In some embodiments, the sample k-space data may include a plurality of second k-space data sets each of which corresponds to the plurality of sample slices and one of the plurality of sample acquisition periods. A second k-space data set may be an aliased k-space data set that includes k-space data from the plurality of sample slices corresponding to one of the plurality of sample acquisition periods.</p><p id="p-0146" num="0145">In some embodiments, the sample k-space data may include real k-space data that is acquired by simultaneously exciting the plurality of sample slices. The at least one of the excited sample slices may be applied to phase modulation by applying, to each of the at least one of the excited sample slices, a sample phase that varies with the plurality of target acquisition periods. In some embodiments, the sample phase may further vary along a phase encoding direction. In some embodiments, the sample phases applied to two or more of the plurality of sample slices may be different. In some embodiments, the sample k-space data may be acquired from the plurality of sample slices at the plurality of sample acquisition periods. The plurality of sample images may be generated from the sample k-space data using any reconstruction algorithm (e.g., SENSE, GRAPPA, etc.). In some embodiments, the sample k-space data may be undersampled, oversampled, or fully sampled.</p><p id="p-0147" num="0146">In some embodiments, the sample k-space data may include synthesized k-space data. In this case, the plurality of sample images may be generated based on SMS imaging or single slice excitation imaging. A plurality of sample k-space data sets may be obtained by performing Fourier transform on the plurality of sample images. Each of the plurality of sample k-space data sets may correspond to one of the plurality of sample images. Phase modulation may be applied to the sample k-space data sets corresponding to at least one of the plurality of sample slices and the plurality of sample acquisition periods. For example, for each of the at least one of the plurality of sample slices, a sample phase varying based on the plurality of sample acquisition periods may be applied to the corresponding sample k-space data sets. In some embodiments, the sample phase may further vary along a phase encoding direction. In some embodiments, the sample phases applied to the sample k-space data sets corresponding to two or more of the plurality of sample slices may be different. In some embodiments, after phase modulation, the sample k-space data sets corresponding to the same sample acquisition period may be combined to obtain a second k-space data set. The second k-space data sets each of which corresponds to the plurality of sample slices and one of the plurality of sample acquisition periods may form the sample k-space data.</p><p id="p-0148" num="0147">In some embodiments, the synthesized k-space data may be obtained further by applying an undersampling strategy to the plurality of second k-space data sets by replacing a portion of data in the plurality of second k-space data sets with zero. In some embodiments, the synthesized k-space data may be obtained further by applying an undersampling strategy to the plurality of sample k-space data sets by replacing a portion of data in the plurality of sample k-space data sets with zero. For example, for the sample k-space data sets corresponding to the plurality of sample slices and a sample acquisition period, a same undersampling strategy may be applied to the plurality of sample k-space data sets by replacing a portion of data in the same k-space position with zero.</p><p id="p-0149" num="0148">In <b>720</b>, the reconstruction module <b>530</b> may obtain the trained reconstruction model by training a preliminary model based on the plurality of training data sets.</p><p id="p-0150" num="0149">In some embodiments, the reconstruction module <b>530</b> may obtain the trained reconstruction model by training a preliminary model using the sample k-space data and the sample images in the plurality of training data sets.</p><p id="p-0151" num="0150">In some embodiments, for each of at least one of the plurality of training data sets, the reconstruction module <b>530</b> may generate a plurality of sample aliased images by performing inverse Fourier transform on the plurality of second k-space data sets of the sample k-space data in the training data set. Each of the plurality of sample aliased images may correspond to the plurality of sample slices and one of the plurality of sample acquisition periods.</p><p id="p-0152" num="0151">In some embodiments, the reconstruction module <b>530</b> may obtain the trained reconstruction model by training the preliminary model based on the plurality of sample aliased images of the each of the at least one of the plurality of training data sets. For example, if the sample k-space data in all of the plurality of training data sets is transformed into the sample aliased images, the reconstruction module <b>530</b> may obtain the trained reconstruction model by training the preliminary model using the sample aliased images and the sample images in the plurality of training data sets. As another example, if the sample k-space data in a portion of the plurality of training data sets is transformed into the sample aliased images, the reconstruction module <b>530</b> may obtain the trained reconstruction model by training the preliminary model using the sample aliased images, the remain sample k-space data, and the sample images in the plurality of training data sets.</p><p id="p-0153" num="0152">In some embodiments, during a training process of the trained reconstruction model, a preliminary model may be obtained. The preliminary model may be trained based on training input data (e.g., the sample k-space data and/or the sample aliased images) and the sample images (e.g., a known output (ground truth) of the training input data) of the plurality of training data sets to obtain the trained reconstruction model. In some embodiments, the preliminary model may include a plurality of weight parameters that are to be determined during learning, which may be referred to as a training process. In the training process, a training input may be processed by the preliminary model so that the preliminary model may learn how to provide an output for new input data by generalizing the information it learns in the training process from the training data. The purpose of learning may be to adapt the weight parameters on the incoming connections to predict the correct output when given an input.</p><p id="p-0154" num="0153">Details regarding the training process of the trained reconstruction model may be found elsewhere in the present disclosure (e.g., the description in connection with <figref idref="DRAWINGS">FIG. <b>8</b></figref>).</p><p id="p-0155" num="0154">In some embodiments, after additional sample images are collected, the training process may be repeated to update the trained reconstruction model using the additional sample images with or without previous sample images used for earlier rounds of the training.</p><p id="p-0156" num="0155">In some embodiments, the trained reconstruction model may be determined by the MRI system <b>100</b> (e.g., the processing device <b>140</b>, the terminal <b>130</b>, a storage device (the storage device <b>150</b>, the storage <b>320</b>, the storage <b>490</b>)) or a third party (e.g., an external device). In some embodiments, the MRI system <b>100</b> may determine and/or update the trained reconstruction model offline and store the trained reconstruction model in the storage device. In some embodiments, the trained reconstruction model may be determined and/or updated (or maintained) by, e.g., the manufacturer of the scanner <b>110</b> or a vendor. For instance, the manufacturer or the vendor may load either one of the trained reconstruction model into the MRI system <b>100</b> or a portion thereof (e.g., the processing device <b>140</b> and/or the terminal <b>130</b>) before or during the installation of the scanner <b>110</b>, the processing device <b>140</b>, and/or the terminal <b>130</b>, and maintain or update the trained reconstruction model from time to time (periodically or not). The maintenance or update may be achieved by installing a program stored on a storage device (e.g., a compact disc, a USB drive, etc.) or retrieved from an external source (e.g., a server maintained by the manufacturer or vendor) via the network <b>120</b>. The program may include a new model (e.g., a new trained reconstruction model) or a portion of a model that substitute or supplement a corresponding portion of the model.</p><p id="p-0157" num="0156">It should be noted that the above description is merely provided for the purposes of illustration, and not intended to limit the scope of the present disclosure. For persons having ordinary skills in the art, multiple variations and modifications may be made under the teachings of the present disclosure. However, those variations and modifications do not depart from the scope of the present disclosure.</p><p id="p-0158" num="0157"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an exemplary training process for obtaining a trained reconstruction model according to some embodiments of the present disclosure. In some embodiments, the process <b>800</b> may be implemented in the imaging system <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, the process <b>800</b> may be stored in a storage medium (e.g., the storage device <b>150</b>, or the storage <b>320</b> of the processing device <b>140</b>, the storage <b>490</b> of the terminal <b>130</b>, the memory <b>460</b> of the terminal <b>130</b>) as a form of instructions, and can be invoked and/or executed by the processing device <b>140</b> or the terminal <b>130</b> (e.g., the processor <b>310</b> of the processing device <b>140</b>, the CPU <b>440</b> and/or the GPU <b>430</b> of the terminal <b>130</b>, or one or more modules in the processing device <b>140</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). The operations of the illustrated process <b>800</b> presented below are intended to be illustrative. In some embodiments, the process <b>800</b> may be accomplished with one or more additional operations not described, and/or without one or more of the operations discussed. Additionally, the order in which the operations of the process <b>800</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> and described below is not intended to be limiting. In some embodiments, operation <b>720</b> of the process <b>700</b> may be performed based on the process <b>800</b>.</p><p id="p-0159" num="0158">In some embodiments, the reconstruction module <b>530</b> may obtain the trained reconstruction model by performing an iteration process including one or more iterations. In some embodiments, the reconstruction module <b>530</b> may update weight parameters of a preliminary model by performing an iteration process of a backpropagation neural network training procedure, e.g., a stochastic gradient descent backpropagation training technique, to determine the updated values of the weight parameters of the trained reconstruction model. For example, the reconstruction module <b>530</b> may backpropagate the error determined for the output of the neural network in order to adjust the parameters of the neural network layers.</p><p id="p-0160" num="0159">In <b>810</b>, the reconstruction module <b>530</b> may output, by an intermediate model, a plurality of output images based on the sample k-space data of one of the plurality of training data sets. For example, the reconstruction module <b>530</b> may input the sample k-space data of the one of the plurality of training data sets into the intermediate model. The intermediate model may output the output images based on the sample k-space data. As another example, the reconstruction module <b>530</b> may input the sample aliased images corresponding to the sample k-space data of the one of the plurality of training data sets into the intermediate model. The intermediate model may output the output images based on the sample aliased images. In some embodiments, each of the plurality of output images may correspond to one of the plurality of sample images of the one of the plurality of training data sets.</p><p id="p-0161" num="0160">In some embodiments, the intermediate model may include a preliminary model in a first iteration of the one or more iterations of the iteration process or an updated model generated in a previous iteration of the current iteration.</p><p id="p-0162" num="0161">In <b>820</b>, the reconstruction module <b>530</b> may determine a difference between the plurality of output images and the plurality of sample images of the one of the plurality of training data sets. In some embodiments, the reconstruction module <b>530</b> may determine a value of a loss function based on the difference.</p><p id="p-0163" num="0162">In <b>830</b>, the reconstruction module <b>530</b> may determine whether a termination condition is satisfied. An exemplary termination condition may be that the value of the loss function in the current iteration is less than a threshold value. Other exemplary termination conditions may include that a maximum number (or count) of iterations has been performed, and/or that a difference between the values of the loss function obtained in a previous iteration and the current iteration (or among the values of the loss function within a certain number or count of successive iterations) is less than a certain threshold. In response to a determination that the termination condition is not satisfied in <b>830</b>, the process <b>800</b> may proceed to <b>850</b>, and initiate a new iteration by further repeating <b>810</b>-<b>830</b> until the termination condition is satisfied. In response to a determination that the termination condition is satisfied in <b>830</b>, the process <b>800</b> may proceed to operation <b>840</b>, e.g., the iterative process may be terminated and the intermediate model in the current iteration may be determined as the trained reconstruction model, and may be stored and/or output.</p><p id="p-0164" num="0163">In <b>850</b>, the reconstruction module <b>530</b> may update the intermediate model based on the difference between the plurality of output images and the plurality of sample images. For example, the reconstruction module <b>530</b> may update the weight parameters in the intermediate model based on the difference between the plurality of output images and the plurality of sample images.</p><p id="p-0165" num="0164">It should be noted that the above description is merely provided for the purposes of illustration, and not intended to limit the scope of the present disclosure. For persons having ordinary skills in the art, multiple variations and modifications may be made under the teachings of the present disclosure. However, those variations and modifications do not depart from the scope of the present disclosure.</p><p id="p-0166" num="0165"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an exemplary model training phase and an exemplary model application phase according to some embodiments of the present disclosure.</p><p id="p-0167" num="0166">Training data <b>910</b> (as illustrated in operation <b>710</b> of the process <b>700</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref>) including a plurality of training data sets (e.g., <b>912</b>) may be obtained. As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the training data set <b>912</b> may include sample k-space data <b>914</b> served as training input data and ground truth <b>916</b>. The sample k-space data <b>914</b> may be applied phase modulation <b>918</b> (as illustrated in operation <b>710</b> of the process <b>700</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref>). The sample k-space data <b>914</b> may include a plurality of second k-space data sets (e.g., D<sub>1</sub>&#x2032;, D<sub>2</sub>&#x2032; . . . ) each of which is an aliased k-space data set including k-space from a plurality of sample slices (e.g., s<sub>1</sub>&#x2032;+s<sub>2</sub>&#x2032;+ . . . ) corresponding to a sample acquisition period (e.g., P<sub>1</sub>&#x2032;, P<sub>2</sub>&#x2032; . . . ). The ground truth <b>916</b> may include a plurality of sample images (e.g., I<sub>1,1</sub>&#x2032;, I<sub>1,2</sub>&#x2032;, I<sub>2,1</sub>&#x2032;, I<sub>2,2</sub>&#x2032; . . . ) each of which corresponds to a sample slice (e.g., s<sub>1</sub>&#x2032;,s<sub>2</sub>&#x2032; . . . ) and a sample acquisition period (e.g., P<sub>1</sub>&#x2032;, P<sub>2</sub>&#x2032; . . . ).</p><p id="p-0168" num="0167">The training data <b>910</b> may be used in the training process <b>920</b> (as illustrated in operation <b>720</b> of the process <b>700</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref> and the process <b>800</b> in <figref idref="DRAWINGS">FIG. <b>8</b></figref>) to obtain the trained reconstruction model <b>930</b>.</p><p id="p-0169" num="0168">In application phase of the trained reconstruction model <b>930</b>, target k-space data <b>940</b> (as illustrated in <figref idref="DRAWINGS">FIGS. <b>6</b>B-<b>6</b>C</figref>, and operation <b>630</b> of the process <b>600</b> in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>) may be input into the trained reconstruction model <b>930</b>. As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the target k-space data <b>940</b> may be applied phase modulation <b>942</b> (as illustrated in <figref idref="DRAWINGS">FIGS. <b>6</b>B-<b>6</b>C</figref>, and operation <b>620</b> of the process <b>600</b> in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>). The target k-space data <b>940</b> may include a plurality of first k-space data sets (e.g., D<sub>1</sub>, D<sub>2 </sub>. . . ) each of which is an aliased k-space data set including k-space from a plurality of target slices (e.g., s<sub>1</sub>+s<sub>2</sub>+ . . . ) corresponding to a target acquisition period (e.g., P<sub>1</sub>, P<sub>2 </sub>. . . ). The output of the trained reconstruction model <b>930</b> based on the target k-space data <b>940</b> may include a plurality of target unaliased images (e.g., I<sub>1,1</sub>, I<sub>1,2</sub>, I<sub>2,1</sub>, I<sub>2,2</sub>) each of which corresponds to a target slice (e.g., s<sub>1</sub>, s<sub>2 </sub>. . . ) and a target acquisition period (e.g., P<sub>1</sub>, P<sub>2 </sub>. . . ).</p><p id="p-0170" num="0169">It should be noted that the above description is merely provided for the purposes of illustration, and not intended to limit the scope of the present disclosure. For persons having ordinary skills in the art, multiple variations and modifications may be made under the teachings of the present disclosure. However, those variations and modifications do not depart from the scope of the present disclosure.</p><p id="p-0171" num="0170"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart illustrating an exemplary process for MR imaging according to some embodiments of the present disclosure. In some embodiments, the process <b>1000</b> may be implemented in the MRI system <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, the process <b>1000</b> may be stored in a storage device (e.g., the storage device <b>150</b>, or the storage <b>320</b> of the processing device <b>140</b>) as a form of instructions, and can be invoked and/or executed by the processing device <b>140</b> (e.g., the processor <b>310</b> of the processing device <b>140</b>, or one or more modules in the processing device <b>140</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). The operations of the illustrated process <b>1000</b> presented below are intended to be illustrative. In some embodiments, the process <b>1000</b> may be accomplished with one or more additional operations not described, and/or without one or more of the operations discussed. Additionally, the order in which the operations of the process <b>1000</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> and described below is not intended to be limiting.</p><p id="p-0172" num="0171">In <b>1010</b>, the processing device <b>140</b> (e.g., the acquisition module <b>520</b>) may obtain target k-space data related to an ROI of an object.</p><p id="p-0173" num="0172">In some embodiments, the target k-space data may be acquired by scanning, using an MRI device (e.g., the scanner <b>110</b>), the ROI of the object. In some embodiments, the target k-space data may be acquired by single-slice excitation or multi-slice excitation (e.g., SMS). In some embodiments, the target k-space data may be undersampled or fully sampled.</p><p id="p-0174" num="0173">In some embodiments, the target k-space data may be autocalibration acquisition data including the following features. The target k-space data may be acquired from a plurality of slices of the ROI of the object that are simultaneously excited. The target k-space data may be acquired in a plurality of acquisition periods so that a series of temporal frames each of which corresponds to one of the plurality of slices and one of the plurality of acquisition periods are reconstructed from the target k-space data. The target k-space data may be phase-modulated by applying a transmit phase that varies along the phase encoding direction and/or the temporal dimension (e.g., the plurality of acquisition periods). In some embodiments, the target k-space data may be acquired by performing operations <b>610</b> and <b>620</b> of the process <b>600</b> in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>.</p><p id="p-0175" num="0174">In <b>1020</b>, the processing device <b>140</b> (e.g., the reconstruction module <b>530</b>) may generate, based on the target k-space data using a trained reconstruction model, one or more target images. The trained reconstruction model may be a machine learning model. In some embodiments, the processing device <b>140</b> may input the target k-space data into the trained reconstruction model. The trained reconstruction model may output the one or more target images based on the target k-space data.</p><p id="p-0176" num="0175">In some embodiments, the processing device <b>140</b> may generate, based on the target k-space data using the trained reconstruction model, a target images corresponding to a target slice of the ROI. In some embodiments, the processing device <b>140</b> may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images (temporal frames) each of which corresponds to a same target slice of the ROI and one of a plurality of target acquisition periods. In some embodiments, the processing device <b>140</b> may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI. In some embodiments, the processing device <b>140</b> may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images (temporal frames) each of which corresponds to one of a plurality of target slices of the ROI and one of a plurality of target acquisition periods.</p><p id="p-0177" num="0176">Merely by way of example, the target k-space data may be autocalibration acquisition data described above. The processing device <b>140</b> may generate, based on the target k-space data using a trained reconstruction model, a plurality of target images (temporal frames) each of which corresponds to one of a plurality of target slices of the ROI and one of a plurality of target acquisition periods. Details regarding the imaging process in this embodiment may be similar to the description in connection with <figref idref="DRAWINGS">FIGS. <b>6</b>A-<b>9</b></figref> in the present disclosure.</p><p id="p-0178" num="0177">It should be noted that the above description is merely provided for the purposes of illustration, and not intended to limit the scope of the present disclosure. For persons having ordinary skills in the art, multiple variations and modifications may be made under the teachings of the present disclosure. However, those variations and modifications do not depart from the scope of the present disclosure.</p><p id="p-0179" num="0178">Having thus described the basic concepts, it may be rather apparent to those skilled in the art after reading this detailed disclosure that the foregoing detailed disclosure is intended to be presented by way of example only and is not limiting. Various alterations, improvements, and modifications may occur and are intended to those skilled in the art, though not expressly stated herein. These alterations, improvements, and modifications are intended to be suggested by this disclosure, and are within the spirit and scope of the exemplary embodiments of this disclosure.</p><p id="p-0180" num="0179">Moreover, certain terminology has been used to describe embodiments of the present disclosure. For example, the terms &#x201c;one embodiment,&#x201d; &#x201c;an embodiment,&#x201d; and/or &#x201c;some embodiments&#x201d; mean that a particular feature, structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present disclosure. Therefore, it is emphasized and should be appreciated that two or more references to &#x201c;an embodiment&#x201d; or &#x201c;one embodiment&#x201d; or &#x201c;an alternative embodiment&#x201d; in various portions of this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures or characteristics may be combined as suitable in one or more embodiments of the present disclosure.</p><p id="p-0181" num="0180">Further, it will be appreciated by one skilled in the art, aspects of the present disclosure may be illustrated and described herein in any of a number of patentable classes or context including any new and useful process, machine, manufacture, or composition of matter, or any new and useful improvement thereof. Accordingly, aspects of the present disclosure may be implemented entirely hardware, entirely software (including firmware, resident software, micro-code, etc.) or combining software and hardware implementation that may all generally be referred to herein as a &#x201c;unit,&#x201d; &#x201c;module,&#x201d; or &#x201c;system.&#x201d; Furthermore, aspects of the present disclosure may take the form of a computer program product embodied in one or more computer readable media having computer readable program code embodied thereon.</p><p id="p-0182" num="0181">A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein, for example, in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms, including electro-magnetic, optical, or the like, or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that may communicate, propagate, or transport a program for use by or in connection with an instruction execution system, apparatus, or device. Program code embodied on a computer readable signal medium may be transmitted using any appropriate medium, including wireless, wireline, optical fiber cable, RF, or the like, or any suitable combination of the foregoing.</p><p id="p-0183" num="0182">Computer program code for carrying out operations for aspects of the present disclosure may be written in any combination of one or more programming languages, including an object oriented programming language such as Java, Scala, Smalltalk, Eiffel, JADE, Emerald, C++, C#, VB. NET, Python or the like, conventional procedural programming languages, such as the &#x201c;C&#x201d; programming language, Visual Basic, Fortran 2003, Perl, COBOL 2002, PHP, ABAP, dynamic programming languages such as Python, Ruby and Groovy, or other programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider) or in a cloud computing environment or offered as a service such as a Software as a Service (SaaS).</p><p id="p-0184" num="0183">Furthermore, the recited order of processing elements or sequences, or the use of numbers, letters, or other designations therefore, is not intended to limit the claimed processes and methods to any order except as may be specified in the claims. Although the above disclosure discusses through various examples what is currently considered to be a variety of useful embodiments of the disclosure, it is to be understood that such detail is solely for that purpose, and that the appended claims are not limited to the disclosed embodiments, but, on the contrary, are intended to cover modifications and equivalent arrangements that are within the spirit and scope of the disclosed embodiments. For example, although the implementation of various components described above may be embodied in a hardware device, it may also be implemented as a software only solution, e.g., an installation on an existing server or mobile device.</p><p id="p-0185" num="0184">Similarly, it should be appreciated that in the foregoing description of embodiments of the present disclosure, various features are sometimes grouped together in a single embodiment, figure, or description thereof for the purpose of streamlining the disclosure aiding in the understanding of one or more of the various embodiments. This method of disclosure, however, is not to be interpreted as reflecting an intention that the claimed subject matter requires more features than are expressly recited in each claim. Rather, claimed subject matter may lie in less than all features of a single foregoing disclosed embodiment.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system for simultaneous multi-slice (SMS) imaging, comprising:<claim-text>a magnetic resonance imaging (MRI) device configured to scan a region of interest (ROI) of an object;</claim-text><claim-text>at least one storage device including a set of instructions; and</claim-text><claim-text>at least one processor configured to communicate with the at least one storage device, wherein when executing the set of instructions, the at least one processor is configured to direct the system to perform operations including:<claim-text>obtaining target k-space data related to the ROI of the object; and</claim-text><claim-text>generating, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI at one of a plurality of target acquisition periods.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the target k-space data includes a plurality of first k-space data sets each of which is acquired from the plurality of target slices in one of the plurality of target acquisition periods.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. (canceled)</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating, based on the target k-space data using the trained reconstruction model, the plurality of target images includes:<claim-text>inputting the target k-space data into the trained reconstruction model; and</claim-text><claim-text>outputting, by the trained reconstruction model, the plurality of target images based on the target k-space data.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein obtaining the target k-space data related to the ROI of the object includes:<claim-text>causing the MRI device to apply one or more multiband excitation radio frequency (RF) pulses to the ROI to simultaneously excite, for one or more times, the plurality of target slices of the ROI;</claim-text><claim-text>causing the MRI device to apply phase modulation to at least one of the excited target slices by applying, to each of the at least one of the excited target slices, a transmit phase that varies with a plurality of target acquisition periods and/or a phase encoding direction; and</claim-text><claim-text>acquiring the target k-space data from the plurality of excited target slices of the ROI at the plurality of target acquisition periods.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the transmit phases applied to two or more of the plurality of target slices are different.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein generating, based on the target k-space data using the trained reconstruction model, the plurality of target images includes:<claim-text>generating a plurality of target aliased images by performing inverse Fourier transform on the target k-space data, each of the plurality of target aliased images corresponding to the plurality of target slices and one of the plurality of target acquisition periods;</claim-text><claim-text>inputting the plurality of aliased images into the trained reconstruction model; and</claim-text><claim-text>outputting, by the trained reconstruction model, the plurality of target images based on the plurality of target aliased images.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein generating, based on the target k-space data using the trained reconstruction model, the plurality of target images includes:<claim-text>determining a plurality of reference data sets based on the target k-space data, each of the plurality of reference data sets corresponding to one of the plurality of target slices and one of the plurality of target acquisition periods, the plurality of reference data sets providing unaliased information for unaliasing of the plurality of target slices in the target k-space data; and</claim-text><claim-text>generating, based on the target k-space data and the plurality of reference data sets, the plurality of target images using the trained reconstruction model.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the trained reconstruction model includes a machine learning model.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the trained reconstruction model is provided by:<claim-text>obtaining a plurality of training data sets, each of the plurality of training data sets including sample k-space data and a plurality of sample unaliased images, wherein<claim-text>each of the plurality of sample unaliased images corresponds to one of a plurality of sample slices of a sample and one of a plurality of sample acquisition periods; and</claim-text><claim-text>for each of at least one of the plurality of sample slices, phases of the corresponding sample k-space data vary based on the plurality of sample acquisition periods and/or the phase encoding direction; and</claim-text></claim-text><claim-text>obtaining the trained reconstruction model by training a preliminary model based on the plurality of training data sets.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the sample k-space data includes real k-space data that is acquired by simultaneously exciting the plurality of sample slices, the plurality of sample unaliased images being generated based on the sample k-space data.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the sample k-space data is undersampled.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the sample k-space data includes synthesized k-space data that is obtained by<claim-text>obtaining a plurality of sample k-space data sets by performing Fourier transform on the plurality of sample unaliased images, each of the plurality of sample k-space data sets corresponding to one of the plurality of sample unaliased images; and</claim-text><claim-text>applying phase modulation to the sample k-space data sets so that for each of at least one of the plurality of sample slices, the sample phases of the corresponding sample k-space data sets vary based on the plurality of sample acquisition periods and/or the phase encoding direction; and</claim-text><claim-text>obtaining a plurality of second k-space data sets by combining the sample k-space data sets corresponding to the sample acquisition period, each of the plurality of second k-space data sets corresponding to the plurality of sample slices and one of the plurality of sample acquisition periods, the sample k-space data sets including the plurality of second k-space data sets.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the synthesized k-space data is obtained further by<claim-text>applying an undersampling strategy to the plurality of second k-space data sets or the plurality of sample k-space data sets by replacing a portion of data in the plurality of second k-space data sets or the plurality of sample k-space data sets with zero.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein obtaining the trained reconstruction model by training the preliminary model based on the plurality of training data sets includes:<claim-text>for each of at least one of the plurality of training data sets, generating a plurality of sample aliased images by performing inverse Fourier transform on the sample k-space data of the training data set, each of the plurality of sample aliased images corresponding to the plurality of sample slices and one of the plurality of sample acquisition periods; and</claim-text><claim-text>obtaining the trained reconstruction model by training the preliminary model based on the plurality of sample aliased images of the each of the at least one of the plurality of training data sets.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein obtaining the trained reconstruction model by training the preliminary model based on the plurality of training data sets includes:<claim-text>obtaining the trained reconstruction model by performing an iteration process including one or more iterations, at least one of the one or more iterations including:<claim-text>outputting, by an intermediate model, a plurality of output images based on the sample k-space data of one of the plurality of training data sets, the intermediate model including the preliminary model in a first iteration of the one or more iterations of the iteration process or an updated model generated in a previous iteration of the at least one of the one or more iterations, each of the plurality of output images corresponding to one of the plurality of sample unaliased images of the one of the plurality of training data sets; and</claim-text><claim-text>updating the intermediate model based on a difference between the plurality of output images and the plurality of sample unaliased images of the one of the plurality of training data sets.</claim-text></claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>each of the plurality of target acquisition periods corresponds to a physiological motion phase of the ROI; and</claim-text><claim-text>the plurality of target images form a physiological motion cine of the ROI.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the ROI of the object includes at least a portion of a heart or a lung.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of target images are used for perfusion analysis and indicate a change of a density of a contrast agent in the plurality of target slices over time.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A method for simultaneous multi-slice (SMS) imaging implemented on a machine including one or more processors and one or more storage devices, comprising:<claim-text>obtaining target k-space data related to a region of interest (ROI) of an object; and</claim-text><claim-text>generating, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI at one of a plurality of target acquisition periods.</claim-text></claim-text></claim><claim id="CLM-21-57" num="21-57"><claim-text><b>21</b>-<b>57</b>. (canceled)</claim-text></claim><claim id="CLM-00058" num="00058"><claim-text><b>58</b>. A non-transitory computer readable medium, comprising at least one set of instructions, wherein when executed by one or more processors of a computing device, the at least one set of instructions causes the computing device to perform a method, the method comprising:<claim-text>obtaining target k-space data related to a region of interest (ROI) of an object; and</claim-text><claim-text>generating, based on the target k-space data using a trained reconstruction model, a plurality of target images each of which corresponds to one of a plurality of target slices of the ROI at one of a plurality of target acquisition periods.</claim-text></claim-text></claim></claims></us-patent-application>
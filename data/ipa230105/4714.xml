<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004715A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004715</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17939271</doc-number><date>20220907</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>2022100518068</doc-number><date>20220117</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>279</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>253</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>33</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>279</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>253</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>3347</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD AND APPARATUS FOR CONSTRUCTING OBJECT RELATIONSHIP NETWORK, AND ELECTRONIC DEVICE</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</orgname><address><city>Beijing</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>WANG</last-name><first-name>Peng</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>ZHU</last-name><first-name>Hengshu</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>DONG</last-name><first-name>Zheng</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>YAO</last-name><first-name>Kaichun</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>QIN</last-name><first-name>Chuan</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</orgname><role>03</role><address><city>Beijing</city><country>CN</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method and an apparatus for constructing an object relationship network and an electronic device are provided by the present disclosure, relating to the field of artificial intelligence technologies, such as deep neural networks, deep learning, etc. A specific implementation solution is: extracting keywords in respective text contents corresponding to a plurality of objects to obtain keywords corresponding to respective objects; and according to the keywords corresponding to the objects, a similarity between the plurality of objects is determined; and then according to the similarity between the plurality of objects, an object relationship network between the plurality of objects is constructed. Since the object relationship network constructed by means of the similarity between the plurality of objects can accurately describe a closeness degree of a relationship between the objects, thus, the plurality of objects can be managed effectively by means of the constructed object relationship network.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="96.01mm" wi="131.66mm" file="US20230004715A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="192.62mm" wi="133.69mm" file="US20230004715A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="121.58mm" wi="133.69mm" file="US20230004715A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="194.14mm" wi="133.69mm" file="US20230004715A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="215.82mm" wi="134.96mm" file="US20230004715A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="199.56mm" wi="149.52mm" file="US20230004715A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="104.06mm" wi="128.61mm" file="US20230004715A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application claims priority to Chinese Patent Application No. 202210051806.8, filed on Jan. 17, 2022, which is hereby incorporated by reference in its entirety.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to the field of data processing technologies, and in particular, to the field of artificial intelligence technologies, such as deep neural networks, deep learning and the like, and specifically, to a method and an apparatus for constructing an object relationship network, and an electronic device.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">When management is performed on a plurality of objects, taking a plurality of management policies and regulations, such as, recruiting regulations, regulations of people management, cadre management, organization management, in an enterprise as an example, association relationships, such as, a mutual reference relationship, an upstream and downstream dependency relationship, generally exist among the regulations.</p><p id="p-0005" num="0004">In view of the existence of the association relationships among the regulations, if a certain regulation is adjusted, for example, the regulation is changed, a linkage change may be caused to other regulations which have an association relationship with the regulation. Therefore, how to effectively manage the plurality of objects is a problem to be solved urgently by those skilled in the present disclosure.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">According to a first aspect of the present disclosure, a method for constructing an object relationship network is provided, and the method for constructing the object relationship network may include:</p><p id="p-0007" num="0006">extracting keywords in respective text contents corresponding to a plurality of objects to obtain keywords corresponding to respective objects;</p><p id="p-0008" num="0007">determining a similarity between the plurality of objects according to the keywords corresponding to the objects; and</p><p id="p-0009" num="0008">constructing an object relationship network between the plurality of objects according to the similarity between the plurality of objects.</p><p id="p-0010" num="0009">According to a second aspect of the present disclosure, a method for training a classification model is provided, and the method for training the classification model may include:</p><p id="p-0011" num="0010">acquiring a plurality of sample word segmentation combinations, where each of the sample word segmentation combinations corresponds to a label, and the label is used for indicating whether a sample word segmentation combination is a keyword;</p><p id="p-0012" num="0011">inputting sample vector representations corresponding to the plurality of sample word segmentation combinations into an initial classification model, to obtain prediction results corresponding to respective ones of the sample word segmentation combinations; where a prediction result is used for indicating whether a sample word segmentation combination is predicted to be a keyword; and</p><p id="p-0013" num="0012">updating a network parameter of the initial classification model according to the prediction results and labels corresponding to the sample word segmentation combinations.</p><p id="p-0014" num="0013">According to a third aspect of the present disclosure, an apparatus for constructing an object relationship network is provided, and the apparatus for constructing the object relationship network may include:</p><p id="p-0015" num="0014">at least one processor; and</p><p id="p-0016" num="0015">a memory communicatively coupled to the at least one processor, wherein the memory stores instructions which are executable by the at least one processor, the instructions are executed by the at least one processor, to enable the at least one processor to:</p><p id="p-0017" num="0016">extract keywords in respective text contents corresponding to a plurality of objects to obtain keywords corresponding to respective objects;</p><p id="p-0018" num="0017">determine a similarity between the plurality of objects according to the keywords corresponding to the objects; and</p><p id="p-0019" num="0018">construct an object relationship network between the plurality of objects according to the similarity between the plurality of objects.</p><p id="p-0020" num="0019">According to a fourth aspect of the present disclosure, an electronic device is provided, and the electronic device may include:</p><p id="p-0021" num="0020">at least one processor; and</p><p id="p-0022" num="0021">a memory communicatively coupled to the at least one processor;</p><p id="p-0023" num="0022">where the memory stores instructions which are executable by the at least one processor, where the instructions are executed by the at least one processor, to enable the at least one processor to execute the method for training a classification model according to the second aspect.</p><p id="p-0024" num="0023">According to a fifth aspect of the present disclosure, a non-transitory computer-readable storage medium storing computer instructions is provided, where the computer instructions are used for causing a computer to execute the method for constructing an object relationship network according to the first aspect, or the method for training a classification model according to the second aspect.</p><p id="p-0025" num="0024">It should be understood that, the contents described in this section are not intended to identify key or critical features of embodiments of the present disclosure, nor to limit the scope of the present disclosure. Other features of the present disclosure will become readily apparent from the following description.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0026" num="0025">The accompanying drawings are used for better understanding of the present solution, and are not intended to limit the present disclosure, where:</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic flowchart of a method for constructing an object relationship according to a first embodiment of the present disclosure;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic flowchart of a method for extracting keywords corresponding to respective objects according to a second embodiment of the present disclosure;</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic flowchart of a method for determining a similarity between a first object and a second object according to a third embodiment of the present disclosure;</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic flowchart of a method for constructing an object relationship network between a plurality of objects according to a fourth embodiment of the present disclosure;</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic diagram of an object relationship network according to an embodiment of the present disclosure;</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic flowchart of a method for training a classification model according to a fifth embodiment of the present disclosure;</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a schematic flowchart of a method for updating network parameters of an initial classification model according to a sixth embodiment of the present disclosure;</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic structural diagram of an apparatus for constructing an object relationship network according to a seventh embodiment of the present disclosure;</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a schematic structural diagram of an apparatus for training a classification model according to an eighth embodiment of the present disclosure; and</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a schematic block diagram of an electronic device according to an embodiment of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0037" num="0036">Illustrative embodiments of the present disclosure will be described below with reference to accompanying drawings, where various details of embodiments of the present disclosure are included to facilitate understanding, which should be considered as merely illustrative. Accordingly, a person of ordinary skill in the art should recognize that various changes and modifications of the embodiments described herein may be made without departing from the scope and spirit of the present disclosure. Also, descriptions of well-known functions and structures are omitted in the following description for clarity and conciseness.</p><p id="p-0038" num="0037">In the embodiments of the present disclosure, &#x201c;at least one&#x201d; means one or more, &#x201c;a plurality of&#x201d; means two or more than two. &#x201c;And/or&#x201d;, which describes an association relationship of associated objects, represents that there may exist three relationships. For example, A and/or B, which may represent three cases: A exists alone, A and B exist at the same time, and B exists alone, where A and B may be singular or plural. In textual description of the present disclosure, the character &#x201c;/&#x201d; generally indicates that the associated objects before and after are of an &#x201c;or&#x201d; relationship. In addition, in the embodiments of the present disclosure, &#x201c;first&#x201d;, &#x201c;second&#x201d;, &#x201c;third&#x201d;, &#x201c;fourth&#x201d;, &#x201c;fifth&#x201d; and &#x201c;sixth&#x201d; are only used for distinguishing contents of different objects, and do not have other special meanings.</p><p id="p-0039" num="0038">Technical solutions provided by the embodiments of the present disclosure can be applied to the field of artificial intelligence technologies, such as deep neural networks, deep learning. Taking a scenario of regulation management in an enterprise as an example, generally, there exists a plurality of management regulations in the enterprise. Generally, there exists an association relationship between the regulations, for example, a mutual reference relationship and an upstream and downstream dependency relationship. If a certain regulation is adjusted, for example, the regulation is changed, a linkage change may be caused to other regulations which have an association relationship with the regulation.</p><p id="p-0040" num="0039">Currently, when management is performed on a plurality of regulations, the plurality of regulations are generally managed manually. However, when the manner of manual management is adopted, not only labor cost is expensive, but also it is difficult to quantify a closeness degree of a relationship between the regulations since whether there exists a relationship between the regulations is determined based on experience without support of an accurate mathematical model, thereby causing great difficulty and low efficiency in the management. Therefore, how to effectively manage the plurality of regulations is an urgent problem to be solved by a person skilled in the art in the present disclosure.</p><p id="p-0041" num="0040">In order to effectively manage the plurality of regulations, considering that the relationship between the regulations is mainly reflected by text contents corresponding to the regulations, hence, keywords in respective text contents corresponding to the plurality of regulations may be extracted to obtain keywords corresponding to respective regulations; a similarity between the plurality of regulations may be determined according to the keywords corresponding to the regulations; and then an object relationship network between the plurality of regulations may be constructed according to the similarity between the plurality of regulations. In view that the object relationship network which is constructed by means of the similarity between the plurality of regulations can accurately describe the closeness degree of the relationship between the regulations, therefore, the plurality of regulations can effectively be managed by means of the constructed object relationship network.</p><p id="p-0042" num="0041">Based on the above technical concept, embodiments of the present disclosure provide a method for constructing an object relationship network. The method for constructing the object relationship network provided in the present disclosure will be described in detail through specific embodiments. It should be understood that the following specific embodiments may be combined with each other, and the same or similar concept or process may not be repeated in some embodiments.</p><heading id="h-0007" level="1">First Embodiment</heading><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic flowchart of a method for constructing an object relationship network according to a first embodiment of the present disclosure. The method for constructing the object relationship network may be executed by software and/or a hardware apparatus. For example, the hardware apparatus may be a terminal or a server. Illustratively, with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the method for constructing the object relationship network may include the following.</p><p id="p-0044" num="0043">S<b>101</b>: Extract keywords in respective text contents corresponding to a plurality of objects to obtain keywords corresponding to respective objects.</p><p id="p-0045" num="0044">Taking an example where the objects are regulations in an enterprise, illustratively, when acquiring respective text contents corresponding to a plurality of regulations, considering that formats of different regulation documents are various, for example, a picture format, a portable document format (PDF), a PPT format, a Word format, and the like, thus different acquiring methods may be used to acquire the respective text contents corresponding to the plurality of regulations.</p><p id="p-0046" num="0045">For a regulation document in a picture format or a PDF format, illustratively, an optical character recognition (OCR) technology may be used to extract effective text contents in the regulation document. For a regulation document in a PPT format or a Word format, illustratively, a Microsoft Office software tool may be used to convert the regulation document into text contents, to acquire effective text contents in the regulation document, which may be specifically set according to actual needs. Here, the embodiments of the present disclosure are only described by taking the documents in these formats as examples, but it does not mean that the embodiments of the present disclosure are merely limited thereto. Illustratively, after the respective text contents corresponding to the plurality of regulations are acquired, the text contents may also be stored in a txt format uniformly, so as to facilitate reading and writing of a computer program.</p><p id="p-0047" num="0046">Illustratively, when the keywords in the respective text contents corresponding to the plurality of objects are extracted, the keywords in the respective text contents corresponding to the plurality of objects may be extracted by using an existing keyword extraction algorithm; and the keywords in the respective text contents corresponding to the plurality of objects may also be extracted by using a keyword extraction model obtained through training based on deep learning, which may be specifically set according to actual needs. A method for extracting the keywords is not specifically limited in the embodiments of the present disclosure.</p><p id="p-0048" num="0047">After the keywords corresponding to respective objects are obtained through extracting the keywords in the respective text contents corresponding to the plurality of objects, considering that the keywords can better express the text contents corresponding to the objects to some extent, a similarity between the plurality of objects can be determined according to the keywords corresponding to the objects, that is, the following S<b>102</b> is executed.</p><p id="p-0049" num="0048">S<b>102</b>: Determine a similarity between the plurality of objects according to the key words corresponding to the objects.</p><p id="p-0050" num="0049">Generally, the similarity between two objects and a closeness degree of a relationship between the two objects are in a positive correlation relationship. That is, the larger the similarity between the two objects is, the higher the closeness degree of the relationship between the two objects is. Conversely, the smaller the similarity between the two objects is, the lower the closeness degree of the relationship between the two objects is.</p><p id="p-0051" num="0050">After the similarity between the plurality of objects is determined, an object relationship network between the plurality of objects may be constructed according to the similarity between the plurality of objects, that is, the following S<b>103</b> is executed.</p><p id="p-0052" num="0051">S<b>103</b>: Construct an object relationship network between the plurality of objects according to the similarity between the plurality of objects.</p><p id="p-0053" num="0052">It can be seen that, in the embodiment of the present disclosure, through extracting the keywords in the respective text contents corresponding to the plurality of objects, the keywords corresponding to respective objects are obtained; according to the keywords corresponding to the objects, the similarity between the plurality of objects is determined; and then according to the similarity between the plurality of objects, the object relationship network between the plurality of objects is constructed. In view that the object relationship network constructed by means of the similarity between the plurality of objects can accurately describe the closeness degree of the relationship between the objects, thus, the plurality of objects can be managed effectively by means of the constructed object relationship network.</p><p id="p-0054" num="0053">With reference to the embodiment shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, when the objects are regulations in the enterprise, a regulation relationship network between the regulations in the enterprise may be constructed by using the technical solution shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In view that the regulation relationship network constructed by means of the similarity between the plurality of regulations can accurately describe a closeness degree of a relationship between the regulations, therefore, the plurality of objects can be effectively managed by means of the constructed regulation relationship network. Compared with the prior art where the regulations are managed manually, labor cost is reduced, and the closeness degree of the relationship between the regulations can be intelligently described. This can not only provide an automation management tool for a manager of the enterprise, but also provide scientific data support for the management of the enterprise.</p><p id="p-0055" num="0054">Based on the embodiment shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in order to facilitate understanding of how to extract the keywords in the respective text contents corresponding to the plurality of objects in S<b>101</b>, a second embodiment shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is described in detail in the following.</p><heading id="h-0008" level="1">Second Embodiment</heading><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic flowchart of a method for extracting keywords corresponding to respective objects according to a second embodiment of the present disclosure. The method may also be executed by software and/or a hardware apparatus. Illustratively, with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the method for extracting the keywords corresponding to respective objects may include the following.</p><p id="p-0057" num="0056">S<b>201</b>: For each object of the plurality of objects, input a text content corresponding to the each object into a keyword extraction model, and obtain respective vector representations corresponding to a plurality of word combinations by means of a word segmentation model in the keyword extraction model.</p><p id="p-0058" num="0057">Illustratively, when the respective vector representations corresponding to the plurality of word combinations are acquired by means of the word segmentation model in the keyword extraction model, the plurality of word segmentations in the text content may be extracted first by means of the word segmentation model; vector representations corresponding to the word segmentations can be determined according to word embedding vectors and part-of-speech vectors corresponding to the word segmentations; and then the respective vector representations corresponding to the plurality of word combinations are determined according to the vector representations corresponding to the word segmentations, where the plurality of word combinations are formed by a plurality of adjacent word segmentations.</p><p id="p-0059" num="0058">Illustratively, when the plurality of word segmentations in the text content are extracted by means of the word segmentation model in the keyword extraction model, word segmentation processing may be performed on the text content by means of the word segmentation model, to obtain the plurality of word segmentations and the part of speech of each word segmentation; further, the word embedding vectors corresponding to the word segmentations are determined; and when the part-of-speech vectors corresponding to the word segmentations are determined, the part-of-speech vectors corresponding to the word segmentations can be determined according to the parts of speech of the word segmentations, thereby acquiring the word embedding vectors and the part-of-speech vectors corresponding to the word segmentations. Illustratively, the part of speech may be a verb, a noun, a preposition, or an adjective, etc., which may be specifically set according to actual needs.</p><p id="p-0060" num="0059">Still taking the example where the objects are regulations in an enterprise, illustratively, in the embodiment of the present disclosure, assuming that there are D regulations in total, and each regulation corresponds to a respective regulation document, i.e., there are a total of D regulation documents. When the vector representations corresponding to the word segmentations are determined, a Chinese word segmentation algorithm in the word segmentation model, for example jieba word segmentation, may be used to perform the word segmentation processing on a text content corresponding to an i-th regulation document of the D regulation documents, which may be recorded as d<sup>(i)</sup>, so that a word segmentation list corresponding to a plurality of word segmentations and the part of speech of each word segmentation can be obtained, where a word segmentation list may be recorded as w<sup>(i)</sup>, and the parts of speech of the word segmentations may be recorded as p<sup>(i)</sup>.</p><p id="p-0061" num="0060">After the word segmentation list w<sup>(i) </sup>corresponding to the i-th regulation document is acquired, a word embedding vector e<sub>j</sub><sup>(i) </sup>corresponding to each of the word segmentations may be learned by using a word2vec technology in the word segmentation model; where the word embedding vector is used for representing semantic information of each word segmentation, and j represents a j-th word segmentation in the word segmentation list w<sup>(i) </sup>corresponding to the i-th regulation document. In addition, a dictionary of part of speech in the word segmentation model may be used to perform one-hot encoding on the part of speech of each word segmentation, so as to generate a part-of-speech vector p<sub>j</sub><sup>(i)</sup>, where the part-of-speech vector is used to represent part-of-speech information of each word segmentation in the contexts, thereby acquiring word embedding vectors and part-of-speech vectors corresponding to the word segmentations.</p><p id="p-0062" num="0061">After the word embedding vectors and the part-of-speech vectors corresponding to the word segmentations are acquired, the vector representations corresponding to the word segmentations may be determined according to the word embedding vectors and the part-of-speech vectors corresponding to the word segmentations. Illustratively, in conjunction with the above description, taking a word segmentation being the j-th word segmentation in the word segmentation list w<sup>(i) </sup>corresponding to the i-th regulation document as an example, when a vector representation corresponding to the word segmentation is determined according to the word embedding vector e<sub>j</sub><sup>(i) </sup>and the part-of-speech vector p<sub>j</sub><sup>(i) </sup>corresponding to the word segmentation, a connecting operation may be performed on the word embedding vector e<sub>j</sub><sup>(i) </sup>and the part-of-speech vector p<sub>j</sub><sup>(i)</sup>, and reference may be made to the following formula 1:</p><p id="p-0063" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>x</i><sub>j</sub><sup>(i)</sup>=concatenate(<i>e</i><sub>j</sub><sup>(i)</sup><i>,p</i><sub>j</sub><sup>(i)</sup>))&#x2003;&#x2003;Formula 1<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0064" num="0062">where x<sub>j</sub><sup>(i) </sup>represents a vector representation corresponding to the j-th word segmentation corresponding to the i-th regulation document, and for a matrix corresponding to the i-th regulation document, reference may be made to the following formula 2:</p><p id="p-0065" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>X</i><sup>(i)</sup>=[<i>x</i><sub>1</sub><sup>(i)</sup><i>,x</i><sub>2</sub><sup>(i)</sup><i>, . . . , x</i><sub>N</sub><sub><sub2>i</sub2></sub><sup>(i)</sup>]&#x2003;&#x2003;Formula 2<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0066" num="0063">where X<sup>(i) </sup>represents a matrix corresponding to the i-th regulation document, and N<sub>i </sub>represents the quantity of word segmentations corresponding to the i-th regulation document.</p><p id="p-0067" num="0064">After the vector representations corresponding to respective word segmentations are acquired, considering that the granularity of word segmentation is relatively fine under normal circumstances, an N-gram combination operation may be performed on the word segmentations in sequence. Assuming that a preset sliding window value N=2, 3, . . . , k, then k adjacent words in the word segmentations may be combined into a new word, that is, a word combination. The word combination is a sequence of a plurality of adjacent word segmentations, thus a plurality of word combinations are obtained, and vector representations corresponding to the plurality of word combinations may be determined according to the word segmentations included in the word combinations.</p><p id="p-0068" num="0065">Illustratively, if a certain regulation document corresponds to six word segmentations and the preset sliding window value N is 2, then five word combinations may be obtained through the N-gram combination. The five word combinations respectively include: a word combination formed by word segmentation 1 and word segmentation 2, a word combination formed by word segmentation 2 and word segmentation 3, a word combination formed by word segmentation 3 and word segmentation 4, a word combination formed by word segmentation 4 and word segmentation 5, and a word combination formed by word segmentation 5 and word segmentation 6.</p><p id="p-0069" num="0066">After the respective vector representations corresponding to the plurality of word combinations are obtained through the foregoing operations, the respective vector representations corresponding to the plurality of word combinations may be input into a classification model in the keyword extraction model, to screen the plurality of word combinations to obtain a keyword, that is, S<b>202</b> is executed. It can be understood that the keywords are also word combinations.</p><p id="p-0070" num="0067">S<b>202</b>: Input the respective vector representations corresponding to the plurality of word combinations into a classification model in the keyword extraction model to obtain the keywords corresponding to the objects.</p><p id="p-0071" num="0068">It can be seen that, in the embodiment of the present disclosure, when the keywords corresponding to respective objects are extracted, the text contents corresponding to the objects may be input into the keyword extraction model first, and the respective vector representations corresponding to the plurality of word combinations are obtained by means of the word segmentation model in the keyword extraction model; and then, the respective vector representations corresponding to the plurality of word combinations are input into the classification model in the keyword extraction model to obtain the keywords corresponding to the objects. In this way, the keywords corresponding to the objects can be accurately extracted by means of the keyword extraction model, thereby improving the accuracy of the acquired keywords.</p><p id="p-0072" num="0069">Based on any one of the foregoing embodiments, in the above S<b>102</b>, when the similarity between the plurality of objects is determined according to the keywords corresponding to the plurality of objects, generally, for any two objects among the plurality of objects, the similarity may be determined. In the following description, take an example where any two objects among the plurality of objects may be recorded as a first object and a second object and where the similarity between the first object and the second object is determined according to respective keywords of the first object and the second object, to describe how to determine the similarity between the plurality of objects according to the keywords corresponding to the plurality of objects, and reference may be made to a third embodiment in the following.</p><heading id="h-0009" level="1">Third Embodiment</heading><p id="p-0073" num="0070"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic flowchart of a method for determining a similarity between a first object and a second object according to a third embodiment of the present disclosure. The method may also be executed by software and/or a hardware apparatus. Illustratively, with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the method may include the following.</p><p id="p-0074" num="0071">S<b>301</b>: Determine, according to respective keywords corresponding to the first object and the second object, an intersection keyword and a union keyword corresponding to the first object and the second object.</p><p id="p-0075" num="0072">Illustratively, assuming that the keywords corresponding to the first object include: keyword a, keyword b, keyword c, keyword d, and keyword e; and the keywords corresponding to the second object include: keyword a, keyword b, keyword c, keyword f, and keyword g; then the intersection keywords corresponding to the first object and the second object include the keyword a, the keyword b, and the keyword c, and the corresponding union keywords include the keyword a, the keyword b, the keyword c, the keyword d, the keyword e, a the keyword f, and the keyword g.</p><p id="p-0076" num="0073">S<b>302</b>: Determine, according to a keyword corresponding to the first object, a first vector representation corresponding to the first object, and determine, according to a keyword corresponding to the second object, a second vector representation corresponding to the second object.</p><p id="p-0077" num="0074">Illustratively, in the embodiment of the present disclosure, when the first vector representation corresponding to the first object is determined according to the keywords corresponding to the first object, word embedding vectors of respective keywords corresponding to the first object may be learned by using a word2vec technology; and the word embedding vectors of respective keywords are averaged to obtain the first vector representation corresponding to the first object. Similarly, when the second vector representation corresponding to the second object is determined according to the keywords corresponding to the second object, word embedding vectors of respective keywords corresponding to the second object may also be learned by using the word2vec technology; and the word embedding vectors of respective keywords are averaged to obtain the second vector representation corresponding to the second object.</p><p id="p-0078" num="0075">It should be understood that, in the embodiment of the present disclosure, there is no sequence between S<b>301</b> and S<b>302</b>. Step S<b>301</b> may be executed first, and then step S<b>302</b> is executed; or, step S<b>302</b> may be executed first and then the step S<b>301</b> is executed; or, step S<b>301</b> and step S<b>302</b> may be executed at the same time, which may be specifically set according to actual needs. Here, the embodiment of the present disclosure is only described by taking the step S<b>301</b> being executed first and then the step S<b>302</b> being executed as an example, but it does not mean that the embodiment of the present disclosure is merely limited thereto.</p><p id="p-0079" num="0076">S<b>303</b>: Determine the similarity between the first object and the second object according to the intersection keyword, the union keyword, the first vector representation, and the second vector representation.</p><p id="p-0080" num="0077">Illustratively, when the similarity between the first object and the second object is determined according to the intersection keywords, the union keywords, the first vector representation and the second vector representation, a first similarity, such as a jaccard similarity, between the first object and the second object may be determined according to a ratio of the quantity of the intersection keywords to the quantity of the union keywords; according to the first vector representation and the second vector representation, a second similarity between the first object and the second object is determined, such as a cosine similarity, an Euclidean distance similarity; and then, the similarity between the first object and the second object is determined according to the first similarity and the second similarity.</p><p id="p-0081" num="0078">Illustratively, when the similarity between the first object and the second object is determined according to the first similarity and the second similarity, an average value of the first similarity and the second similarity may be directly determined, and the average value is determined as the similarity between the first object and the second object; or, a weighted average may also be performed on the first similarity and the second similarity, where the weights are different, and a weighted average result is determined as the similarity between the first object and the second object, thereby acquiring the similarity between the first object and the second object.</p><p id="p-0082" num="0079">It can be seen that, in the embodiment of the present disclosure, when the similarity between the first object and the second object is determined, the intersection keyword and the union keyword corresponding to the first object and the second object may be determined according to respective keywords corresponding to the first object and the second object; the first vector representation corresponding to the first object is determined according to the keyword corresponding to the first object, and the second vector representation corresponding to the second object is determined according to the keyword corresponding to the second object; and then, the similarity between the first object and the second object is determined according to the intersection keyword, the union keyword, the first vector representation, and the second vector representation jointly, thereby effectively improving the accuracy of the determined similarity.</p><p id="p-0083" num="0080">Based on any one of the foregoing embodiments, for ease of understanding, how to construct an object relationship network between the plurality of objects according to the similarity between the plurality of objects in S<b>103</b> is described in detail in a fourth embodiment shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><heading id="h-0010" level="1">Fourth Embodiment</heading><p id="p-0084" num="0081"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic flowchart of a method for constructing an object relationship network between a plurality of objects according to a fourth embodiment of the present disclosure, and the method may also be executed by software and/or a hardware apparatus. Illustratively, with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the method may include the following.</p><p id="p-0085" num="0082">S<b>401</b>: Determine target objects from a plurality of objects according to the similarity between the plurality of objects, where a similarity corresponding to the target objects is greater than a pre-set threshold value.</p><p id="p-0086" num="0083">The value of the preset threshold may be set according to actual needs, and here, the value of the preset threshold is not specifically limited in the embodiment of the present disclosure.</p><p id="p-0087" num="0084">Considering that if a similarity value between two objects is small, it is indicated that a closeness degree of a relationship between the two objects is low, and for objects with a relatively low closeness degree of relationship, there is no need to construct a relationship. Therefore, after the similarity between the plurality of objects is determined, a target object with a similarity greater than the pre-set threshold value may be further selected from the plurality of objects according to the similarity values, In this way, subsequently, an object relationship network including only the target objects may be constructed without considering objects with a relatively low closeness degree of relationship, and thus, the object relationship network is simplified effectively.</p><p id="p-0088" num="0085">After target objects with a high closeness degree of relationship is determined from the plurality of objects, degrees of centrality corresponding to the target objects may be further determined, and the following S<b>402</b> is executed.</p><p id="p-0089" num="0086">S<b>402</b>: Determine degrees of centrality corresponding to the target objects, where the degrees of centrality are used for indicating positions of the target objects in an object relationship network to be generated.</p><p id="p-0090" num="0087">Illustratively, a social network algorithm may be used to determine the degrees of centrality corresponding to the target objects, and other similar algorithms may also be used to determine the degrees of centrality corresponding to the target objects, which may be specifically set according to actual needs.</p><p id="p-0091" num="0088">S<b>403</b>: Construct the object relationship network according to the degrees of centrality corresponding to the target objects.</p><p id="p-0092" num="0089">Illustratively, when the object relationship network is constructed according to the degrees of centrality corresponding to the target objects, in a possible implementation, the object relationship network may be constructed only according to the degrees of centrality corresponding to the target objects. In the constructed object relationship network, target objects with relatively close positions have a relatively high closeness degree of relationship. If a certain target object is adjusted, for example, an object is changed, a linkage change may be caused to a target object at a relatively close position, and a target object at a relatively far position may not be caused to change. In this way, the plurality of objects can be effectively managed based on the object relationship network.</p><p id="p-0093" num="0090">In another possible implementation, the target objects may be clustered first to obtain a plurality of clustering results; where the target objects in different clustering results have different node identifiers in the object relationship network to be generated; and the object relationship network is constructed according to the degrees of centrality and the node identifiers corresponding to the target objects. Illustratively, a node identifier may be a color of a node, a filling content of the node, and the like, as long as the target objects in different clustering results can be distinguished. Illustratively, with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, which is a schematic diagram of an object relationship network according to an embodiment of the present disclosure, the target objects represented by nodes with the same filling content in <figref idref="DRAWINGS">FIG. <b>5</b></figref> have a high closeness degree of relationship between them. If a certain target object is adjusted, for example, if an object is changed, a linkage change may be caused to a target object in the same clustering result. In this way, the plurality of objects can be effectively managed based on the object relationship network.</p><p id="p-0094" num="0091">It can be seen that, in the embodiment of the present disclosure, when the object relationship network is constructed, the target objects may be determined from the plurality of objects firstly according to the similarity between the plurality of objects; the degrees of centrality corresponding to the target objects are determined; and then the object relationship network is constructed according to the degrees of centrality corresponding to the target objects. In this way, if a certain target object is adjusted, a target object on which the linkage adjustment occurs may be determined visually according to the object relationship network, thereby implementing effective management of the plurality of objects.</p><p id="p-0095" num="0092">Based on any one of the foregoing embodiments, before the keywords corresponding to the objects are acquired by means of the keyword extraction model, it is needed to obtain the keyword extraction model through training. Illustratively, when the keyword extraction model is being trained, although the keyword extraction model includes a word segmentation model and a classification model, however, in an embodiment of the present disclosure, only the classification model may be trained, so that after the classification model is obtained by training, the trained keyword extraction model may be obtained according to an existing word segmentation model and the classification model obtained by training. Hereinafter, how to train and obtain a classification model in the embodiment of the present disclosure will be described in detail in a fifth embodiment shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><heading id="h-0011" level="1">Fifth Embodiment</heading><p id="p-0096" num="0093"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic flowchart of a method for training a classification model according to a fifth embodiment of the present disclosure, and the method may also be executed by software and/or a hardware apparatus. Illustratively, with reference to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the method for training the classification model may include the following.</p><p id="p-0097" num="0094">S<b>601</b>: Acquire a plurality of sample word segmentation combinations, where each of the sample word segmentation combinations corresponds to a label, and the label is used for indicating whether a sample word segmentation combination is a keyword.</p><p id="p-0098" num="0095">Illustratively, when the plurality of sample word segmentation combinations are acquired, in a possible implementation, the plurality of sample word segmentation combinations may be a plurality of sample word segmentation combinations which are all manually labeled, for example, a plurality of sample word segmentation combinations which are adopted in a first iteration process.</p><p id="p-0099" num="0096">In another possible implementation, considering that it is relatively difficult to obtain the plurality of sample word segmentation combinations which are all manually labeled, thus, in the plurality of sample word segmentation combinations, some of the sample word segmentation combinations are the plurality of sample word segmentation combinations which are manually labeled, and some of the sample word segmentation combinations are new sample word segmentation combinations which are obtained based on classification results of the plurality of sample word segmentation combinations. For example, the plurality of sample word segmentation combinations which are manually labeled are taken as initial training samples, and classification results of the sample combined word segmentations are obtained by means of the initial classification model. If the classification results indicate that some sample word segmentation combinations are keywords, the sample word segmentation combinations corresponding to these keywords can be used as new sample word segmentation combinations after manual checking. The plurality of sample word segmentation combinations which are manually labeled and the new sample word segmentation combinations are taken as the plurality of sample word segmentation combinations, for example, the plurality of sample word segmentation combinations used in a plurality of iteration processes.</p><p id="p-0100" num="0097">After the plurality of sample word segmentation combinations are acquired, the following S<b>602</b> may be executed.</p><p id="p-0101" num="0098">S<b>602</b>: Input sample vector representations corresponding to the plurality of sample word segmentation combinations into an initial classification model, to obtain prediction results corresponding to respective sample word segmentation combinations; where a prediction result is used for indicating whether a sample word segmentation combination is predicted to be a keyword.</p><p id="p-0102" num="0099">Illustratively, in an embodiment of the present disclosure, when the sample vector representations corresponding to the plurality of sample word segmentation combinations are acquired, the sample vector representations corresponding to the sample word segmentation combinations may be acquired by means of the word segmentation model. A specific implementation method thereof is similar to the method for acquiring the vector representations corresponding to the word combinations in S<b>201</b>, and reference may be made to the related description of acquiring respective vector representations corresponding to the word combinations in S<b>201</b>, which is not repeated in the embodiment of the present disclosure here.</p><p id="p-0103" num="0100">After the sample vector representations corresponding to the plurality of sample word segmentation combinations are input into the initial classification model to obtain the prediction results corresponding to respective sample word segmentation combinations, network parameters of the initial classification model can be updated according to the prediction results and labels corresponding to the sample word segmentation combinations, i.e., the following S<b>603</b> is executed.</p><p id="p-0104" num="0101">S<b>603</b>: Update network parameters of the initial classification model according to the prediction results and labels corresponding to the sample word segmentation combinations.</p><p id="p-0105" num="0102">Illustratively, when the network parameters of the initial classification model are updated according to the prediction results and the labels corresponding to the sample word segmentation combinations, if an updated classification model converges, the updated classification model is directly determined as a final classification model; and if the updated classification model does not converge, the above steps S<b>601</b> to S<b>603</b> are repeated to update the network parameters of the classification model until the updated classification model converges, and the converged classification model is determined as the final classification model, so as to obtain the classification model through training.</p><p id="p-0106" num="0103">It can be seen that, in the embodiments of the present disclosure, when the classification model is trained, the plurality of sample word segmentation combinations can be obtained first; and the sample vector representations corresponding to the plurality of sample word segmentation combinations are input into the initial classification model to obtain the prediction results corresponding to respective sample word segmentation combinations; and then, the network parameters of the initial classification model are updated according to the prediction results and the labels corresponding to the sample word segmentation combinations, so that a classification model with higher accuracy can be acquired, thereby improving the accuracy of the acquired classification model.</p><p id="p-0107" num="0104">Based on the embodiment shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, for ease of understanding, how to update the network parameters of the initial classification model according to the prediction results and the labels corresponding to the sample word segmentation combinations in S<b>603</b> is described in detail in a sixth embodiment shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><heading id="h-0012" level="1">Sixth Embodiment</heading><p id="p-0108" num="0105"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a schematic flowchart of a method for updating network parameters of an initial classification model according to a sixth embodiment of the present disclosure, and the method may also be executed by software and/or a hardware apparatus. Illustratively, with reference to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the method may include the following.</p><p id="p-0109" num="0106">S<b>701</b>: Construct a loss function corresponding to the sample word segmentation combinations according to the prediction results and the labels corresponding to the sample word segmentation combinations.</p><p id="p-0110" num="0107">Illustratively, the loss function may be a cross entropy loss function, and may also be other loss functions, which may be specifically set according to actual needs.</p><p id="p-0111" num="0108">S<b>702</b>: Update the network parameters of the initial classification model according to the loss function corresponding to the sample word segmentation combinations.</p><p id="p-0112" num="0109">Illustratively, when the network parameters of the initial classification model are updated according to a loss function of the sample word segmentation combinations, since the plurality of sample word segmentation combinations are training samples used for performing a training operation, an average loss function corresponding to the plurality of sample word segmentation combinations can be determined according to loss functions corresponding to respective sample word segmentation combinations, and the network parameters of the initial classification model can be updated according to the average loss function.</p><p id="p-0113" num="0110">It can be seen that, in the embodiment of the present disclosure, when the classification model is trained, the loss function corresponding to the sample word segmentation combinations may be constructed according to the prediction results and the labels corresponding to the sample word segmentation combinations; and the network parameters of the initial classification model are updated according to the loss functions corresponding to the sample word segmentation combinations, so that a classification model with high accuracy can be acquired, thereby improving the accuracy of the acquired classification model.</p><heading id="h-0013" level="1">Seventh Embodiment</heading><p id="p-0114" num="0111"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic structural diagram of an apparatus <b>80</b> for constructing an object relationship network according to a seventh embodiment of the present disclosure. For example, with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the apparatus <b>80</b> for constructing the object relationship network may include:</p><p id="p-0115" num="0112">an extracting unit <b>801</b>, configured to extract keywords in respective text contents corresponding to a plurality of objects to obtain keywords corresponding to respective objects;</p><p id="p-0116" num="0113">a determining unit <b>802</b>, configured to determine a similarity between the plurality of objects according to the keywords corresponding to the objects; and</p><p id="p-0117" num="0114">a constructing unit <b>803</b>, configured to construct an object relationship network between the plurality of objects according to the similarity between the plurality of objects.</p><p id="p-0118" num="0115">In an embodiment, the extracting unit <b>801</b> includes a first extracting module and a second extracting module,</p><p id="p-0119" num="0116">the first extracting module is configured to input the text contents corresponding to the objects into a keyword extraction model, and obtain respective vector representations corresponding to a plurality of word combinations by means of a word segmentation model in the keyword extraction model; and</p><p id="p-0120" num="0117">the second extracting module is configured to input the respective vector representations corresponding to the plurality of word combinations into a classification model in the keyword word extraction model to obtain the keywords corresponding to the objects.</p><p id="p-0121" num="0118">In an embodiment, the first extracting module includes a first extracting sub-module, a second extracting sub-module and a third extracting sub-module,</p><p id="p-0122" num="0119">the first extracting sub-module is configured to extract a plurality of word segmentations in the text contents by means of the word segmentation model;</p><p id="p-0123" num="0120">the second extracting sub-module is configured to determine, according to word embedding vectors and part-of-speech vectors corresponding to the word segmentations, vector representations corresponding to the word segmentations; and</p><p id="p-0124" num="0121">the third extracting sub-module is configured to determine, according to the vector representations corresponding to the word segmentations, the respective vector representations corresponding to the plurality of word combinations, where the plurality of word combinations are formed by a plurality of adjacent word segmentations.</p><p id="p-0125" num="0122">In an embodiment, the plurality of objects include a first object and a second object, and the determining unit <b>802</b> includes a first determining module, a second determining module, and a third determining module;</p><p id="p-0126" num="0123">the first determining module is configured to determine, according to respective keywords corresponding to the first object and the second object, an intersection keyword and a union keyword corresponding to the first object and the second object;</p><p id="p-0127" num="0124">the second determining module is configured to determine, according to a keyword corresponding to the first object, a first vector representation corresponding to the first object, and determine, according to a keyword corresponding to the second object, a second vector representation corresponding to the second object; and</p><p id="p-0128" num="0125">the third determining module is configured to determine a similarity between the first object and the second object according to the intersection keyword, the union keyword, the first vector representation, and the second vector representation.</p><p id="p-0129" num="0126">In an embodiment, the third determining module includes a first determining sub-module, a second determining sub-module and a third determining sub-module,</p><p id="p-0130" num="0127">the first determining sub-module is configured to determine a first similarity between the first object and the second object according to a ratio of the quantity of the intersection keyword to the quantity of the union keyword;</p><p id="p-0131" num="0128">the second determining sub-module is configured to determine a second similarity between the first object and the second object according to the first vector representation and the second vector representation; and</p><p id="p-0132" num="0129">the third determining sub-module is configured to determine the similarity between the first object and the second object according to the first similarity and the second similarity.</p><p id="p-0133" num="0130">In an embodiment, the constructing unit <b>803</b> includes a first constructing module, a second constructing module, and a third constructing module;</p><p id="p-0134" num="0131">the first constructing module is configured to determine target objects from the plurality of objects according to the similarity between the plurality of objects; where a similarity corresponding to the target objects is greater than a pre-set threshold value;</p><p id="p-0135" num="0132">the second constructing module is configured to determine degrees of centrality corresponding to the target objects, where the degrees of centrality are used for indicating positions of the target objects in an object relationship network to be generated; and</p><p id="p-0136" num="0133">the third constructing module is configured to construct the object relationship network according to the degrees of centrality corresponding to the target objects.</p><p id="p-0137" num="0134">In an embodiment, the third constructing module includes a first constructing sub-module and a second constructing sub-module;</p><p id="p-0138" num="0135">the first constructing sub-module is configured to cluster the target objects to obtain a plurality of clustering results; where the target objects in different clustering results have different node identifiers in the object relationship network to be generated; and</p><p id="p-0139" num="0136">the second constructing sub-module is configured to construct the object relationship network according to the degrees of centrality and the node identifiers corresponding to the target objects.</p><p id="p-0140" num="0137">The apparatus <b>80</b> for constructing the object relationship network provided by the embodiments of the present disclosure can execute technical solutions of the method for constructing an object relationship network as shown in any one of the above embodiments. Implementation principles and beneficial effects thereof are similar to implementation principles and beneficial effects of the method for constructing the object relationship network. Reference can be made to the implementation principles and the beneficial effects of the method for constructing the object relationship network, and the details thereof are not described herein again.</p><heading id="h-0014" level="1">Eighth Embodiment</heading><p id="p-0141" num="0138"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a schematic structural diagram of an apparatus <b>90</b> for training a classification model according to an eighth embodiment of the present disclosure. Illustratively, with reference to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the apparatus <b>90</b> for training the classification model may include:</p><p id="p-0142" num="0139">an acquiring unit <b>901</b>, configured to acquire a plurality of sample word segmentation combinations, where each of the sample word segmentation combinations corresponds to a label, and the label is used for indicating whether a sample word segmentation combination is a keyword;</p><p id="p-0143" num="0140">a processing unit <b>902</b>, configured to input sample vector representations corresponding to the plurality of sample word segmentation combinations into an initial classification model, to obtain prediction results corresponding to respective ones of the sample word segmentation combinations; where a prediction result is used for indicating whether a sample word segmentation combination is a keyword; and</p><p id="p-0144" num="0141">an updating unit <b>903</b>, configured to update network parameters of the initial classification model according to the prediction results and labels corresponding to the sample word segmentation combinations.</p><p id="p-0145" num="0142">In an embodiment, the updating unit <b>903</b> includes a first updating module and a second updating module;</p><p id="p-0146" num="0143">the first updating module is configured to construct, according to the prediction results and the labels corresponding to the sample word segmentation combinations, a loss function corresponding to the sample word segmentation combinations; and</p><p id="p-0147" num="0144">the second updating module is configured to update the network parameters of the initial classification model according to the loss function corresponding to the sample word segmentation combinations.</p><p id="p-0148" num="0145">The apparatus <b>90</b> for training the classification model provided by the embodiments of the present disclosure can execute technical solutions of the method for training a classification model as shown in any one of the above embodiments. Implementation principles and beneficial effects thereof are similar to implementation principles and beneficial effects of the method for training the classification model. Reference can be made to the implementation principles and the beneficial effects of the method for training the classification model, and the details thereof are not described herein again.</p><p id="p-0149" num="0146">According to embodiments of the present disclosure, the present disclosure further provides an electronic device, a readable storage medium, and a computer program product.</p><p id="p-0150" num="0147">According to an embodiment of the present disclosure, the present disclosure further provides a computer program product. The computer program product includes a computer program which is stored in a readable storage medium. At least one processor of an electronic device can read the computer program from the readable storage medium, and executes the computer program to cause the electronic device to execute the solution provided by any one of the above embodiments.</p><p id="p-0151" num="0148"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a schematic block diagram of an electronic device <b>100</b> according to an embodiment of the present disclosure. The electronic device is intended to represent various forms of digital computers, such as a laptop computer, a desktop computer, a workstation, a personal digital assistant, a server, a blade server, a mainframe computer, and other suitable computers. The electronic device may also represent a variety of forms of mobile apparatuses, such as the personal digital assistant, a cellular telephone, a smart phone, a wearable device, and other similar computing apparatuses. The components shown herein, their connections and relationships, and their functions are only illustrative, which are not intended to limit implementations of the present disclosure described and/or claimed herein.</p><p id="p-0152" num="0149">As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the device <b>100</b> includes a computing unit <b>1001</b> which may perform various appropriate operations and processes according to a computer program stored in a read only memory (ROM) <b>1002</b> or a computer program loaded into a random access memory (RAM) <b>1003</b> from a storage unit <b>1008</b>. In the RAM <b>1003</b>, various programs and data which are necessary for operations of the storage device <b>100</b> are also stored. The computing unit <b>1001</b>, the ROM <b>1002</b>, and the RAM <b>1003</b> are connected to each other via a bus <b>1004</b>. An input/output (I/O) interface <b>1005</b> is also connected to the bus <b>1004</b>.</p><p id="p-0153" num="0150">A plurality of components in the device <b>100</b> are connected to the I/O interface <b>1005</b>, including: an input unit <b>1006</b>, such as a keyboard, a mouse; an output unit <b>1007</b>, such as various types of displays, speakers; a storage unit <b>1008</b>, such as a magnetic disk, an optical disk; and a communication unit <b>1009</b>, such as a network card, a modem, a wireless communication transceiver. The communication unit <b>1009</b> allows the device <b>100</b> to exchange information/data with other devices through a computer network such as the Internet and/or various telecommunication networks.</p><p id="p-0154" num="0151">The computing unit <b>1001</b> may be a variety of general and/or special processing components with processing and computing capabilities. Some examples of the computing unit <b>1001</b> include, but are not limited to, a central processing unit (CPU), a graphics processing unit (GPU), a variety of specific artificial intelligence (AI) computing chips, a variety of computing units running machine learning model algorithms, a digital signal processor (DSP), and any suitable processor, controller, microcontroller, etc. The computing unit <b>1001</b> executes the various methods and processes described above, such as a method for constructing an object relationship network or a method for training a classification model. For example, in some embodiments, the method for constructing the object relationship network or the method for training the classification model may be implemented as a computer software program which is tangibly embodied in a machine-readable medium, such as the storage unit <b>1008</b>. In some embodiments, some or all of the computer program may be loaded into and/or installed onto the device <b>100</b> via the ROM <b>1002</b> and/or the communications unit <b>1009</b>. When the computer program is loaded into the RAM <b>1003</b> and executed by the computing unit <b>1001</b>, one or more steps of the above method for constructing the object relationship network or the method for training the classification model may be executed. Alternatively, in other embodiments, the computing unit <b>1001</b> may be configured to execute the method for constructing the object relationship network or the method for training the classification model in any other suitable manner (e.g., by means of firmware).</p><p id="p-0155" num="0152">Various implementation manners of the systems and techniques described above herein may be implemented in a digital electronic circuit system, an integrated circuit system, a field programmable gate array (FPGA), an application specific integrated circuit (ASIC), an application specific standard product (ASSP), a system-on-chip (SOC) system, a complex programmable logic device (CPLD), computer hardware, firmware, software, and/or a combination thereof. These various implementations may include an implementation implemented in one or more computer programs that are executable and/or interpretable in a programmable system including at least one programmable processor. The programmable processor may be a specific or a general programmable processor, and may receive data and instructions from a storage system, at least one input apparatus, and at least one output apparatus, and transmit data and instructions to the storage system, the at least one input apparatus, and at least one output apparatus.</p><p id="p-0156" num="0153">Program codes for implementing the method of the present disclosure may be written in any combination of one or more programming languages. The program codes may be provided to a processor or a controller of a general computer, a specific computer, or other programmable data processing apparatuses, such that the program codes, when being executed by the processor or the controller, cause the functions/operations which are specified in flowcharts and/or block diagrams to be executed. The program codes may execute entirely by a machine, partially by a machine, partially by a machine as a stand-alone software package and partially by a remote machine, or entirely by a remote machine or server.</p><p id="p-0157" num="0154">In the context of the present disclosure, a machine readable medium may be a tangible media that may contain or store a program for use by an instruction execution system, apparatus, or device or a program for use in connection with an instruction execution system, apparatus, or device. The machine readable medium may be a machine readable signal medium or a machine readable storage medium. The machine readable medium may include, but is not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples of the machine readable storage medium may include an electrical connection based on one or more wires, a portable computer disk, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a compact disc read-only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing.</p><p id="p-0158" num="0155">To provide for interaction with a user, the systems and techniques described herein may be implemented on a computer having: a display apparatus (e.g., a CRT (cathode ray tube) or an LCD (liquid crystal display) monitor) for displaying information to the user; and a keyboard and a pointing apparatus (e.g., a mouse or a trackball) by which the user can provide an input to a computer. Other kinds of apparatuses may also be used to provide for interaction with the user. For example, feedback provided to the user may be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and may receive an input from the user in any form, including an acoustic input, a speech input, or a tactile input.</p><p id="p-0159" num="0156">The systems and techniques described herein may be implemented in a computing system which includes a back-end component (e.g., as a data server), or a computing system which includes a middleware component (e.g., an application server), or a computing system which includes a front-end component (e.g., a user computer having a graphical user interface or a web browser, through which the user may interact with an implementation of the systems and techniques described herein), or a computing system which includes any combination of such back-end, middleware, or front-end components. The components of the systems may be interconnected by digital data communications (e.g., a communication network) in any form or medium. Examples of the communication network include a local area network (LAN), a wide area network (WAN), and the Internet.</p><p id="p-0160" num="0157">The computing system may include a client and a server. The client and the server are generally remote from each other and typically interact through the communication network. The relationship between the client and the server arises by virtue of computer programs running on respective computers and having a client-server relationship therebetween. The server may be a cloud server, which is also referred to as a cloud computing server or a cloud host, and it is a host product in a cloud computing service system, so as to solve defects of difficult management and weak business scalability existing in a traditional physical host and a VPS (Virtual Private Server) service. The server may also be a server of a distributed system, or a server combined with a block chain.</p><p id="p-0161" num="0158">It should be understood that the steps may be reordered, added, or deleted using the various forms of flow shown above. For example, the steps described in the present disclosure may be executed in parallel, may be executed sequentially, or may be executed in a different order, as long as desired results of the technical solutions disclosed in the present disclosure can be achieved, which is not limited herein.</p><p id="p-0162" num="0159">The above specific implementations do not limit the protection scope of the present disclosure. It should be understood by a person skilled in the art that various modifications, combinations, sub-combinations and replacements can be made according to design requirements and other factors. Any modifications, equivalent replacements, improvements and the like made within the spirit and principle of the present disclosure shall all be included within the protection scope of the present disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for constructing an object relationship network, comprising:<claim-text>extracting keywords in respective text contents corresponding to a plurality of objects to obtain keywords corresponding to respective objects;</claim-text><claim-text>determining a similarity between the plurality of objects according to the keywords corresponding to the objects; and</claim-text><claim-text>constructing an object relationship network between the plurality of objects according to the similarity between the plurality of objects.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the extracting the keywords in the respective text contents corresponding to the plurality of objects to obtain the keywords corresponding to respective objects comprises:<claim-text>for each object of the plurality of objects, inputting a text content corresponding to the each object into a keyword extraction model, and obtaining respective vector representations corresponding to a plurality of word combinations by means of a word segmentation model in the keyword extraction model; and</claim-text><claim-text>inputting the respective vector representations corresponding to the plurality of word combinations into a classification model in the keyword extraction model to obtain the keywords corresponding to the objects.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the obtaining the respective vector representations corresponding to the plurality of word combinations by means of the word segmentation model in the keyword extraction model comprises:<claim-text>extracting a plurality of word segmentations in the text content by means of the word segmentation model;</claim-text><claim-text>determining, according to word embedding vectors and part-of-speech vectors corresponding to the word segmentations, vector representations corresponding to the word segmentations; and</claim-text><claim-text>determining, according to the vector representations corresponding to the word segmentations, the respective vector representations corresponding to the plurality of word combinations, wherein the plurality of word combinations are formed by a plurality of adjacent word segmentations.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of objects comprise a first object and a second object, and determining a similarity between the first object and the second object according to the keywords corresponding to the objects comprises:<claim-text>determining, according to respective keywords corresponding to the first object and the second object, an intersection keyword and a union keyword corresponding to the first object and the second object;</claim-text><claim-text>determining, according to a keyword corresponding to the first object, a first vector representation corresponding to the first object, and determining, according to a keyword corresponding to the second object, a second vector representation corresponding to the second object; and</claim-text><claim-text>determining the similarity between the first object and the second object according to the intersection key word, the union key word, the first vector representation, and the second vector representation.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the determining the similarity between the first object and the second object according to the intersection keyword, the union keyword, the first vector representation, and the second vector representation comprises:<claim-text>determining a first similarity between the first object and the second object according to a ratio of a quantity of the intersection keyword to a quantity of the union keyword;</claim-text><claim-text>determining a second similarity between the first object and the second object according to the first vector representation and the second vector representation; and</claim-text><claim-text>determining the similarity between the first object and the second object according to the first similarity and the second similarity.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the plurality of objects comprise a first object and a second object, and determining a similarity between the first object and the second object according to the keywords corresponding to the objects comprises:<claim-text>determining, according to respective keywords corresponding to the first object and the second object, an intersection keyword and a union keyword corresponding to the first object and the second object;</claim-text><claim-text>determining, according to a keyword corresponding to the first object, a first vector representation corresponding to the first object, and determining, according to a keyword corresponding to the second object, a second vector representation corresponding to the second object; and</claim-text><claim-text>determining the similarity between the first object and the second object according to the intersection key word, the union key word, the first vector representation, and the second vector representation.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the determining the similarity between the first object and the second object according to the intersection keyword, the union keyword, the first vector representation, and the second vector representation comprises:<claim-text>determining a first similarity between the first object and the second object according to a ratio of a quantity of the intersection keyword to a quantity of the union keyword;</claim-text><claim-text>determining a second similarity between the first object and the second object according to the first vector representation and the second vector representation; and</claim-text><claim-text>determining the similarity between the first object and the second object according to the first similarity and the second similarity.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the plurality of objects comprise a first object and a second object, and determining a similarity between the first object and the second object according to the keywords corresponding to the objects comprises:<claim-text>determining, according to respective keywords corresponding to the first object and the second object, an intersection keyword and a union keyword corresponding to the first object and the second object;</claim-text><claim-text>determining, according to a keyword corresponding to the first object, a first vector representation corresponding to the first object, and determining, according to a keyword corresponding to the second object, a second vector representation corresponding to the second object; and</claim-text><claim-text>determining the similarity between the first object and the second object according to the intersection key word, the union key word, the first vector representation, and the second vector representation.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the constructing the object relationship network between the plurality of objects according to the similarity between the plurality of objects comprises:<claim-text>determining target objects from the plurality of objects according to the similarity between the plurality of objects, wherein a similarity corresponding to the target objects is greater than a pre-set threshold value;</claim-text><claim-text>determining degrees of centrality corresponding to the target objects, wherein the degrees of centrality are used for indicating positions of the target objects in an object relationship network to be generated; and</claim-text><claim-text>constructing the object relationship network according to the degrees of centrality corresponding to the target objects.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the constructing the object relationship network according to the degrees of centrality corresponding to the target objects comprises:<claim-text>clustering the target objects to obtain a plurality of clustering results, wherein the target objects in different clustering results have different node identifiers in the object relationship network to be generated; and</claim-text><claim-text>constructing the object relationship network according to the degrees of centrality and the node identifiers corresponding to the target objects.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the constructing the object relationship network between the plurality of objects according to the similarity between the plurality of objects comprises:<claim-text>determining target objects from the plurality of objects according to the similarity between the plurality of objects, wherein a similarity corresponding to the target objects is greater than a pre-set threshold value;</claim-text><claim-text>determining degrees of centrality corresponding to the target objects, wherein the degrees of centrality are used for indicating positions of the target objects in an object relationship network to be generated; and</claim-text><claim-text>constructing the object relationship network according to the degrees of centrality corresponding to the target objects.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the constructing the object relationship network between the plurality of objects according to the similarity between the plurality of objects comprises:<claim-text>determining target objects from the plurality of objects according to the similarity between the plurality of objects, wherein a similarity corresponding to the target objects is greater than a pre-set threshold value;</claim-text><claim-text>determining degrees of centrality corresponding to the target objects, wherein the degrees of centrality are used for indicating positions of the target objects in an object relationship network to be generated; and</claim-text><claim-text>constructing the object relationship network according to the degrees of centrality corresponding to the target objects.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the constructing the object relationship network between the plurality of objects according to the similarity between the plurality of objects comprises:<claim-text>determining target objects from the plurality of objects according to the similarity between the plurality of objects, wherein a similarity corresponding to the target objects is greater than a pre-set threshold value;</claim-text><claim-text>determining degrees of centrality corresponding to the target objects, wherein the degrees of centrality are used for indicating positions of the target objects in an object relationship network to be generated; and</claim-text><claim-text>constructing the object relationship network according to the degrees of centrality corresponding to the target objects.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the constructing the object relationship network between the plurality of objects according to the similarity between the plurality of objects comprises:<claim-text>determining target objects from the plurality of objects according to the similarity between the plurality of objects, wherein a similarity corresponding to the target objects is greater than a pre-set threshold value;</claim-text><claim-text>determining degrees of centrality corresponding to the target objects, wherein the degrees of centrality are used for indicating positions of the target objects in an object relationship network to be generated; and</claim-text><claim-text>constructing the object relationship network according to the degrees of centrality corresponding to the target objects.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A method for training a classification model, comprising:<claim-text>acquiring a plurality of sample word segmentation combinations, wherein each of the sample word segmentation combinations corresponds to a label, and the label is used for indicating whether a sample word segmentation combination is a keyword;</claim-text><claim-text>inputting sample vector representations corresponding to the plurality of sample word segmentation combinations into an initial classification model, to obtain prediction results corresponding to respective ones of the sample word segmentation combinations; wherein a prediction result is used for indicating whether a sample word segmentation combination is predicted to be a keyword; and</claim-text><claim-text>updating network parameters of the initial classification model according to the prediction results and labels corresponding to the sample word segmentation combinations.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the updating the network parameters of the initial classification model according to the prediction results and the labels corresponding to the sample word segmentation combinations comprises:<claim-text>constructing a loss function corresponding to the sample word segmentation combinations according to the prediction results and the labels corresponding to the sample word segmentation combinations; and</claim-text><claim-text>updating the network parameters of the initial classification model according to the loss function corresponding to the sample word segmentation combinations.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. An apparatus for constructing an object relationship network, comprising:<claim-text>at least one processor; and</claim-text><claim-text>a memory communicatively coupled to the at least one processor, wherein the memory stores instructions which are executable by the at least one processor, the instructions are executed by the at least one processor, to enable the at least one processor to:</claim-text><claim-text>extract keywords in respective text contents corresponding to a plurality of objects to obtain keywords corresponding to respective objects;</claim-text><claim-text>determine a similarity between the plurality of objects according to the keywords corresponding to the objects; and</claim-text><claim-text>construct an object relationship network between the plurality of objects according to the similarity between the plurality of objects.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. An electronic device comprising:<claim-text>at least one processor; and</claim-text><claim-text>a memory communicatively coupled to the at least one processor;</claim-text><claim-text>wherein the memory stores instructions which are executable by the at least one processor, and the instructions are executed by the at least one processor, to enable the at least one processor to execute the method for training a classification model according to <claim-ref idref="CLM-00015">claim 15</claim-ref>.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A non-transitory computer-readable storage medium storing computer instructions, wherein the computer instructions are used for causing a computer to execute the method for constructing an object relationship network according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A non-transitory computer-readable storage medium storing computer instructions, wherein the computer instructions are used for causing a computer to execute the method for training a classification model according to <claim-ref idref="CLM-00015">claim 15</claim-ref>.</claim-text></claim></claims></us-patent-application>
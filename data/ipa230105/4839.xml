<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004840A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004840</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931385</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>62</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>6221</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>6257</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS FOR ADAPTIVE TRAINING OF A MACHINE LEARNING SYSTEM PROCESSING TEXTUAL DATA</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16838527</doc-number><date>20200402</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11475329</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17931385</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>62828872</doc-number><date>20190403</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>RELX Inc.</orgname><address><city>Miamisburg</city><state>OH</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Hebenthal</last-name><first-name>Douglas C.</first-name><address><city>Bellevue</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Saretto</last-name><first-name>Cesare John</first-name><address><city>Greenbrier</city><state>TN</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Tracy</last-name><first-name>James</first-name><address><city>Murfreesboro</city><state>TN</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Clinkenbeard</last-name><first-name>Richard</first-name><address><city>Franklin</city><state>TN</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Liu</last-name><first-name>Christopher</first-name><address><city>Redmond</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>RELX Inc.</orgname><role>02</role><address><city>Miamisburg</city><state>OH</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">In one embodiment, a method for adaptive training of a machine learning system configured to predict answers to questions associated with textual data includes receiving predicted answers to questions associated with textual data. The predicted answers are generated based at least in part on one or more first models of a machine learning system. The one or more first models are associated with a first accuracy score. The method further includes determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required. In response to determining based at least in part on the quality control parameter that an evaluation of the questions by one or more external entities is required, the questions associated with the textual data and the textual data are sent to the one or more external entities for evaluation.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="234.95mm" wi="141.31mm" file="US20230004840A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="138.85mm" wi="158.75mm" orientation="landscape" file="US20230004840A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="257.39mm" wi="198.37mm" orientation="landscape" file="US20230004840A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="194.65mm" wi="142.49mm" orientation="landscape" file="US20230004840A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="259.25mm" wi="151.47mm" file="US20230004840A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="221.15mm" wi="151.72mm" file="US20230004840A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="196.85mm" wi="172.89mm" orientation="landscape" file="US20230004840A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 16/838,527 entitled &#x201c;SYSTEMS AND METHODS FOR ADAPTIVE TRAINING OF A MACHINE LEARNING SYSTEM PROCESSING TEXTUAL DATA&#x201d; and filed on Apr. 2, 2020, which claims priority to U.S. Provisional Patent Application No. 62/828,872 entitled &#x201c;SYSTEMS AND METHODS FOR ADAPTIVE TRAINING OF A MACHINE LEARNING SYSTEM PROCESSING TEXTUAL DATA&#x201d; and filed on Apr. 3, 2019, which are hereby incorporated by reference in their entireties.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Certain embodiments of the present invention are directed to machine learning systems processing textual data. More particularly, some embodiments of the present invention provide systems and methods for adaptive training of a machine learning system processing textual data.</p><p id="p-0004" num="0003">With the demands on processing textual and natural language data ever increasing, machine learning systems are typically employed in analyzing and categorizing the textual and natural language data and other information included in large numbers of documents and files. Machine learning (ML) systems include prediction models that are generally trained based on currently known true answers up to a certain point in time. However, external factors can influence the accuracy of answers predicted by the conventional ML systems based on the trained models. Consequently, the actual accuracy of the predicted answers, for example, decreases over time, although the confidence in each predicted answer as calculated by the conventional ML systems remains high. Thus, conventional ML systems typically require, on a continuous basis, identifying inaccuracies of the predicted results, collecting additional data for training the models, and retraining the models. The continuous training of conventional ML system is labor intensive, time-consuming, and becomes more complex with the amount of training data increasing.</p><p id="p-0005" num="0004">Hence it is highly desirable to provide and/or improve techniques for adaptive training of machine learning systems processing textual data.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0006" num="0005">Certain embodiments of the present invention are directed to machine learning systems processing textual data. More particularly, some embodiments of the present invention provide systems and methods for adaptive training of a machine learning system processing textual data.</p><p id="p-0007" num="0006">According to some embodiments, a method for adaptive training of a machine learning system configured to predict answers to questions associated with textual data includes receiving predicted answers to questions associated with textual data. The predicted answers are generated based at least in part on one or more first models of a machine learning system. The one or more first models are associated with a first accuracy score. The method further includes determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required. In response to determining based at least in part on the quality control parameter that an evaluation of the questions by one or more external entities is required, the questions associated with the textual data and the textual data are sent to the one or more external entities for evaluation. The method further includes receiving true answers to the questions from the one or more external entities and determining one or more accuracy parameters based at least in part on the true answers and the predicted answers. In response to the one or more accuracy parameters being smaller than a predetermined minimum threshold, an accuracy degradation event is identified, and the quality control parameter is increased. In response to a truth counter of at least one question being larger than a first predetermined truth threshold, one or more second models are generated, and a second accuracy score associated with the one or more second models is determined. In response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, the one or more first models are replaced with the one or more second models at the machine learning system.</p><p id="p-0008" num="0007">According to certain embodiments, a system for adaptive training of a machine learning system configured to predict answers to questions associated with textual data includes one or more processors and a memory storing instructions. The instructions, when executed by the one or more processors, cause the system to perform receiving predicted answers to questions associated with textual data. The predicted answers are generated based at least in part on one or more first models of a machine learning system. The one or more first models are associated with a first accuracy score. The instructions, when executed by the one or more processors, cause the system to further perform determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required. In response to determining based at least in part on the quality control parameter that an evaluation of the questions by one or more external entities is required, the questions associated with the textual data and the textual data are sent to the one or more external entities for evaluation. The instructions, when executed by the one or more processors, cause the system to further perform receiving true answers to the questions from the one or more external entities and determining one or more accuracy parameters based at least in part on the true answers and the predicted answers. In response to the one or more accuracy parameters being smaller than a predetermined minimum threshold, an accuracy degradation event is identified, and the quality control parameter is increased. In response to a truth counter of at least one question being larger than a first predetermined truth threshold, one or more second models are generated, and a second accuracy score associated with the one or more second models is determined. In response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, the one or more first models are replaced with the one or more second models at the machine learning system.</p><p id="p-0009" num="0008">According to some embodiments, a non-transitory computer readable storage medium storing one or more programs. The one or more programs includes instructions, when executed by one or more processors, causing a system for adaptive training of a machine learning system configured to predict answers to questions associated with textual data to perform receiving predicted answers to questions associated with textual data. The predicted answers are generated based at least in part on one or more first models of a machine learning system. The one or more first models are associated with a first accuracy score. The instructions, when executed by the one or more processors, cause the system to further perform determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required. In response to determining based at least in part on the quality control parameter that an evaluation of the questions by one or more external entities is required, the questions associated with the textual data and the textual data are sent to the one or more external entities for evaluation. The instructions, when executed by the one or more processors, cause the system to further perform receiving true answers to the questions from the one or more external entities and determining one or more accuracy parameters based at least in part on the true answers and the predicted answers. In response to the one or more accuracy parameters being smaller than a predetermined minimum threshold, an accuracy degradation event is identified, and the quality control parameter is increased. In response to a truth counter of at least one question being larger than a first predetermined truth threshold, one or more second models are generated, and a second accuracy score associated with the one or more second models is determined. In response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, the one or more first models are replaced with the one or more second models at the machine learning system.</p><p id="p-0010" num="0009">Depending upon embodiment, one or more benefits may be achieved. These benefits and various additional objects, features and advantages of the present invention can be fully appreciated with reference to the detailed description and accompanying drawings that follow.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a simplified diagram showing a system for adaptive training of a machine learning system processing textual data according to one embodiment of the present invention.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a simplified diagram showing the machine learning component as part of the system as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> according to one embodiment of the present invention.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a simplified timing diagram for the result evaluation component as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> according to one embodiment of the present invention.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a simplified diagram showing a method for adaptive training of a machine learning system processing textual data according to one embodiment of the present invention.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a simplified diagram showing a method for adaptive training of a machine learning system processing textual data according to one embodiment of the present invention.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a simplified diagram showing a computing system for implementing a system for adaptive training of a machine learning system processing textual data according to one embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0017" num="0016">Conventional systems and methods are often not capable of efficiently adapting to changes in external factors that influence the accuracy of results predicted by a machine learning (ML) system. Conventional systems and methods typically require continuous training of the ML system to account for such changes. In particular, conventional ML systems are trained on historical truths. Historical truths include, for example, actual results confirmed to be true by entities that are external to the ML system. Thus, conventional ML systems are continuously retrained, when new historical truths become available, to correct for the changes in external factors.</p><p id="p-0018" num="0017">Certain embodiments of the present invention are directed to machine learning systems processing textual data. More particularly, some embodiments of the present invention provide systems and methods for adaptive training of a machine learning system processing textual data.</p><p id="p-0019" num="0018">In some embodiments, the systems and methods provide for a machine learning system that automatically adapts to changes in external factors that can influence the accuracy of results predicted by the ML system. For example, predicted results include predictions about the content of contract documents written in natural languages. As an example, a conventional natural language processing algorithm is generally susceptible to inaccuracies when encountering language in documents that the algorithm has not previously seen nor been trained on.</p><p id="p-0020" num="0019">In certain embodiments, inaccuracies in predicted results are improved upon by collecting additional truth samples and retraining the ML system without the need of creating new prediction algorithms. For example, truth samples include predicted results that were verified and/or corrected by external evaluation entities (e.g., by human experts). In some examples, the systems and methods are capable of spotting inaccuracies in the predicted results. For example, in response to spotting inaccuracies in the predicted results, inaccuracies are decreased by dynamically collecting additional truth samples from the external evaluation entities. As an example, in response to receiving additional truth samples, the ML system is automatically retrained after a predetermined truth interval. In one example, the predetermined truth interval represents a predetermined number of times when truth samples are received from the external evaluation entities. In some examples, new prediction models generated by retraining the ML system are promoted if the new models outperform the current prediction models of the ML system. For example, the new models outperform the current models if the accuracy of the new models is increased as compared to the accuracy of the current models based on the historical truth samples and/or the additional truth samples. In certain examples, the systems and methods include dynamically adjusting the requested number of additional truth samples based at least in part on accuracy of the current models.</p><p id="p-0021" num="0020">Benefits of certain embodiments include that the automatic nature of retraining the ML system in predetermined truth intervals increases the speed of adaptation with respect to changing external factors and reduces the number of external evaluation. In some embodiments, other benefits include cost reduction with respect to employing human expert to evaluate the predicted results. In certain embodiments, additional benefits include that the decreased need and cost of employing specialized software engineer and/or data scientist to modify the ML algorithms for improved accuracy.</p><p id="p-0022" num="0021">In certain embodiments, one or more solutions rooted in computer technology overcome one or more problems specifically arising in the realm of computer technology. Other embodiments included monitoring the accuracy determination of the ML system and, if certain criteria are met, raising an alert for intervention and/or improvement of the ML system. Yet another embodiment includes continuously training and generating new prediction models based at least in part on new truth samples that are requested at predetermined frequency intervals.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a simplified diagram showing a system <b>100</b> for adaptive training of a machine learning system processing textual data according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. The system <b>100</b> includes a document organizer component <b>102</b>, a document processing component <b>104</b>, a machine learning component <b>106</b>, an extraction user interface (UI) component <b>108</b>, a repository API component <b>110</b>, and a repository <b>112</b>. For example, the document organizer component <b>102</b> includes a front-end UI component <b>114</b> and is configured to organize, categorize, and select documents <b>116</b> for storing in the repository <b>112</b>, and/or further managing and analyzing the documents <b>116</b> by the system <b>100</b>. As an example, the document processing component <b>104</b> is included in the repository API component <b>110</b>.</p><p id="p-0024" num="0023">In some embodiments, documents <b>116</b> include textual data and/or content written in natural languages. Examples of documents <b>116</b> include contracts, patent licenses, trademark licenses, copyright licenses, technology licenses, joint ventures agreements, confidentiality agreements, research agreements, material supply agreements, manufacturing agreements, statements of work, and amendments and addenda of the forgoing documents. In certain examples, the repository API component <b>110</b> is configured to receive data from the document organizer component <b>102</b>, the document processing component <b>104</b>, the machine learning component <b>106</b>, and/or the extraction UI component <b>108</b>, and store the received data in the repository <b>112</b>. In other examples, the extraction UI component provides a user interface configured for users to interact with data and documents received from the document organizer component <b>102</b>, the document processing component <b>104</b>, the machine learning component <b>106</b>, and/or the repository API component <b>110</b>. In some examples, the user interface of the extraction UI component is configured to allow users to interact with data and documents stored in the repository <b>112</b>.</p><p id="p-0025" num="0024">In certain embodiments, the document processing component <b>104</b> is configured to receive data associated with the documents <b>116</b> from the document organizer component <b>102</b> for further processing. In some examples, the processing by the document processing component <b>104</b> includes, for example, applying optical character recognition techniques to the received data of the documents <b>116</b>. As an example, the document processing component <b>104</b> is configured to parse the received data to identify, classify, and mark particular sections within the documents <b>116</b>. In certain examples, the document processing component <b>104</b> is configured to add metadata to the documents <b>116</b> based at least in part on the processing of the documents <b>116</b>. In other examples, the document processing component <b>104</b> is configured to convert between formats and/or presentation styles of the data associated with the documents <b>116</b>, and, for example, generate formatted documents of the converted data. In yet other examples, the document processing component <b>104</b> is configured to generate reports, annotations and/or documentations of the processed documents <b>116</b>.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a simplified diagram showing the machine learning component <b>106</b> as part of the system <b>100</b> according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. The machine learning component <b>106</b> includes a prediction component <b>202</b>, a result processing component <b>204</b>, an accuracy store <b>206</b>, a result evaluation component <b>208</b>, a training component <b>210</b>, and a staging component <b>212</b>. In some examples, the prediction component <b>202</b> is configured to receive documents <b>214</b> processed by the system <b>100</b>. For example, the processed documents <b>214</b> include textual data.</p><p id="p-0027" num="0026">In some embodiments, the prediction component <b>202</b> is configured to generate the predicted results <b>216</b> based at least in part on one or more models <b>218</b> of the machine learning system. For example, the predicted results include predicted answers to questions associated with textual data of the processed documents <b>214</b>. In some examples, the prediction component <b>202</b> is configured to generate predicted answers to questions associated with textual data of the processed documents <b>214</b>. In certain examples, the prediction component <b>202</b> is configured to generate a goodness, a predictive error, a robustness value, and/or an confidence score associated with the predicted answer based at least in part on the one or more models <b>218</b> of the machine learning system. For example, the one or more models <b>218</b> are associated with an accuracy score. As an example, the one or more models <b>218</b> are generated by using supervised, semi-supervised and/or unsupervised machine learning techniques. In some examples, the machine learning techniques include neural networks, feature selection and classification, rule-based learning, and/or similarity measure techniques.</p><p id="p-0028" num="0027">In certain embodiments, the result processing component <b>204</b> is configured to receive the predicted results <b>216</b>. For example, the predicted results <b>216</b> include predicted answers to questions associated with textual data of the processed documents <b>214</b>. As an example, the predicted answers to questions associated with textual data are received by the result processing component <b>204</b> in response to a request or push event.</p><p id="p-0029" num="0028">According to some embodiments, the result processing component <b>204</b> is configured to determine based at least in part on a quality control parameter whether an evaluation of the predicted results by one or more external entities <b>222</b> is required. In some examples, the result processing component <b>204</b> is configured to determine that an evaluation of the predicted results is required if the quality control parameter is equal to or smaller than a predetermined quality threshold. For example, predetermined quality threshold is 10%, 20%, 30%, 40%, or 50%.</p><p id="p-0030" num="0029">According to certain embodiments, the quality control parameter includes a number of required evaluations performed by the one or more external entities <b>222</b>. In some examples, the result processing component <b>204</b> is configured to not determine whether an evaluation by the one or more external entities <b>222</b> is required until receiving a predetermined minimum number of truth samples. For example, the predetermined minimum number is based on the type, load and/or set of processed documents <b>214</b>. As an example, the predetermined minimum number is equal to 100, 200, 300, 400, or 500 truth samples.</p><p id="p-0031" num="0030">In some embodiments, the result processing component <b>204</b> is configured to generate the quality control parameter based at least in part on one or more factors. Examples of the one or more factors include one or more static configuration parameters associated with the textual data, a current environment associated with the textual data, an identity of a requester associated with a request, a confidence associated with the predicated answers, and/or a request frequency. In some examples, the quality control parameter includes a Boolean parameter. For example, the Boolean parameter (e.g., requiresEvaluation) is determined as follows:</p><p id="p-0032" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mrow>       <mrow>        <mrow>         <mrow>          <mi>requiresE</mi>          <mo>&#x2062;</mo>          <mi>valuation</mi>         </mrow>         <mo>=</mo>         <mrow>          <mi>fieldBase</mi>          <mo>+</mo>          <mi>environmentConfig</mi>          <mo>+</mo>          <mi>identityScore</mi>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <mi>dataSetSampleCount</mi>             <mo>&#x3c;</mo>             <mi>dataSetMinSample</mi>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xb7;</mo>           <mn>100</mn>          </mrow>          <mo>+</mo>          <mrow>           <mrow>            <mo>(</mo>            <mrow>             <mi>confidence</mi>             <mo>&#x3c;</mo>             <mi>dataSetMinConf</mi>            </mrow>            <mo>)</mo>           </mrow>           <mo>&#xb7;</mo>           <mn>100</mn>          </mrow>         </mrow>        </mrow>        <mo>)</mo>       </mrow>       <mo>+</mo>       <mrow>        <mo>(</mo>        <mrow>         <mi>hasActiveEvent</mi>         <mo>&#xb7;</mo>         <mi>accuracyScaleSetting</mi>        </mrow>        <mo>)</mo>       </mrow>      </mrow>      <mo>&#x3c;</mo>      <mi>Random</mi>     </mrow>     <mo>,</mo>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mrow>      <mi>Equation</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mn>1</mn>     </mrow>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0033" num="0031">where fieldBase represents a minimum value of prediction evaluations, environmentConfig represents a weighted value based on environmental parameters (e.g., region, date, time of day), identityScore represents a weighted value based on the requester identify (e.g., uploader, customer, project), dataSetSampleCount represents a number of samples collected for a given customer, dataSetMinSample represents a minimum number of samples required to be collected prior to training of the ML system and generating predicted results for a new customer, confidence represents confidence associated with the predicted results generated by the prediction component <b>202</b>, dataSetMinConf represents a minimum confidence required for the predicted results to bypass evaluation by one or more external entities <b>222</b>, hasActiveEvent represents a Boolean value for an active accuracy degradation event, accuracyScaleSetting represents a percentage number of evaluations required for an auto-scaling event, and Random represents a random number in the range 0 to 1.</p><p id="p-0034" num="0032">In certain embodiments, the result processing component <b>204</b> is configured, in response to determining based at least in part on the quality control parameter that an evaluation by one or more external entities is required, send the questions associated with the textual data and the textual data of the processed documents <b>214</b> to the external evaluation entities <b>222</b> for evaluation.</p><p id="p-0035" num="0033">According to some embodiments, the external evaluation entities <b>222</b> are configured to evaluate the questions associated with textual data and the textual data of the processed documents <b>214</b>. In some examples, the external entities <b>222</b> are configured to generate true results <b>224</b> based at least in part on the textual data of the processed documents <b>214</b>. In certain examples, the external entities <b>222</b> are configured to generate true answers to the questions based at least in part on the textual data of the processed documents <b>214</b>. For example, the external entities <b>222</b> are configured to evaluate the questions based on the textual data through a mechanical evaluation, a virtual evaluation, and/or a natural evaluation. In one example, the external entities <b>222</b> include humans who review the questions and provide true answers to the reviewed questions based on the textual data of the processed documents <b>214</b>. In other examples, the external entities <b>222</b> include virtual evaluation systems configured to generate true answers for certain questions based at least in part on criteria and/or features of the textual data of the processed documents <b>214</b>. In some examples, the external entities <b>222</b> are configured to evaluate the questions based on the textual data of the processed documents <b>214</b> without knowledge of the predicted answers generated by the prediction component <b>202</b>.</p><p id="p-0036" num="0034">According to certain embodiments, the result evaluation component <b>208</b> is configured to receive the true results <b>224</b> from the external evaluation entities <b>222</b>. In some examples, the result evaluation component <b>208</b> is configured to receive the true answers generated by the external evaluation entities <b>220</b>. In certain examples, the result evaluation component <b>208</b> is configured to determine one or more accuracy parameters based at least in part on the true answers generated by the external evaluation entities <b>222</b> and the predicted answers generated by the prediction component <b>202</b>. In some examples, the result processing component <b>204</b> is configured to increase the number of required evaluations based at least in part on the one or more accuracy parameters determined by the result evaluation component <b>208</b>. In other examples, the result evaluation component <b>208</b> is configured to store the determined one or more accuracy parameters in the accuracy store <b>206</b> for retrieval by the machine learning system. For example, the result evaluation component <b>208</b> is configured to store an accuracy deviation in the accuracy store <b>206</b> for retrieval by the machine learning system. As an example, the accuracy deviation is equal to a difference of the one or more accuracy parameters and a predetermined minimum threshold.</p><p id="p-0037" num="0035">In some embodiments, the result evaluation component <b>208</b> is configured to, in response to the one or more accuracy parameters being smaller than the predetermined minimum threshold, identify an accuracy degradation event. For example, the predetermined minimum threshold represents an accuracy threshold. In some examples, the accuracy degradation event is triggered if the one or more accuracy parameters fall below the predetermined minimum threshold. For example, the predetermined minimum threshold represents a user-specified minimum value of accuracy.. In certain examples, the result evaluation component <b>208</b> is configured to increase the predetermined minimum threshold in response to the accuracy score of the models <b>218</b> increasing over time.</p><p id="p-0038" num="0036"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a simplified timing diagram for the result evaluation component <b>208</b> according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. In some examples, the result evaluation component <b>208</b> receives true results from the external evaluation entities <b>222</b> at sample points <b>302</b><sub>1-n</sub>. For example, at sample points <b>302</b><sub>1-n </sub>the result evaluation component <b>208</b> determines the accuracy parameter <b>304</b>. As an example, the result evaluation component <b>208</b> determines that the accuracy parameter <b>304</b> at sample points <b>302</b><sub>1-4 </sub>(e.g., at sample points <b>1</b>-<b>4</b>) is larger than the accuracy threshold <b>306</b>. In another example, the result evaluation component <b>208</b> determines that the accuracy parameter <b>304</b> at sample point <b>302</b><sub>5 </sub>(e.g., at sample point <b>5</b>) is smaller than the accuracy threshold <b>306</b>. In yet another example, the result evaluation component <b>208</b> determines that between the sample point <b>302</b><sub>4 </sub>and the sample point <b>302</b><sub>5 </sub>(e.g., between sample point <b>4</b> and sample point <b>5</b>) the accuracy parameter changes from a value that is larger than the accuracy threshold <b>306</b> to a value that is smaller the accuracy threshold <b>306</b>. In certain examples, the result evaluation component <b>208</b> determines that the accuracy parameter <b>304</b> at time t<sub>0 </sub>is equal to the accuracy threshold <b>306</b>. For example, the result evaluation component <b>208</b> determines that the accuracy parameter changes from a value that is larger than the accuracy threshold <b>306</b> at a time prior to time to to a value that is smaller the accuracy threshold <b>306</b> at time after time to. As an example, the result evaluation component <b>208</b>, in response to the accuracy parameter <b>304</b> being smaller than the accuracy threshold <b>306</b>, identifies the accuracy degradation event <b>308</b>. In one example, the accuracy degradation event <b>308</b> starts at time to. In some examples, the result evaluation component <b>208</b> determines that the accuracy parameter <b>304</b> at time t<sub>1 </sub>is equal to the accuracy threshold <b>306</b>. For example, the result evaluation component <b>208</b> determines that the accuracy parameter changes from a value that is smaller than the accuracy threshold <b>306</b> at a time prior to time t<sub>1 </sub>to a value that is larger the accuracy threshold <b>306</b> at time after time t<sub>1</sub>. As an example, the result evaluation component <b>208</b>, in response to the accuracy parameter <b>304</b> being larger than the accuracy threshold <b>306</b>, clears the accuracy degradation event <b>308</b>. In one example, the accuracy degradation event <b>308</b> ends at the time t<sub>1</sub>. In another example, the result evaluation component <b>208</b>, in response to the accuracy parameter <b>304</b> being larger than the accuracy threshold <b>306</b> over a rolling accuracy window (e.g., over a predetermined number of samples or a predetermined time duration), clears the accuracy degradation event <b>308</b>.</p><p id="p-0039" num="0037">In some embodiments, the result evaluation component <b>208</b> is configured to, in response to the one or more accuracy parameters being equal to or larger than the predetermined minimum threshold, clear the identified accuracy degradation event <b>308</b>. In some examples, in response to the accuracy degradation event <b>308</b> being cleared, the result evaluation component <b>208</b> is configured to determine an evaluation number that indicates the number of evaluations performed by the external evaluation entities <b>222</b>. For example, the evaluation number is equal to the number of sample points <b>302</b> for the duration of the accuracy degradation event <b>308</b>. As an example, the result evaluation component <b>208</b> is configured to store the evaluation number and the truth counter <b>226</b> in the accuracy store <b>206</b> for retrieval by the machine learning system. In one example, the result evaluation component <b>208</b> is configured to store the truth counter <b>226</b> if the accuracy degradation event <b>308</b> is cleared. For example, the result evaluation component <b>208</b> is configured to set the value of hasActiveEvent in Equation 1 to zero if the accuracy degradation event <b>308</b> is cleared. In some examples, the result evaluation component <b>208</b> is configured to store the truth counter <b>226</b> in the accuracy store <b>206</b> in response to identifying the accuracy degradation event <b>308</b>.</p><p id="p-0040" num="0038">In certain embodiments, the number of sample points <b>302</b> for the duration of the accuracy degradation event <b>308</b> is equal to the number of results received from the external evaluation entities <b>222</b> at sample points <b>302</b> after time to and before time t<sub>1</sub>. In some examples, in response to the accuracy degradation event <b>308</b> being identified by the result evaluation component <b>208</b>, the result processing component <b>204</b> is configured to change the quality control parameter so that the frequency of required evaluations by the external evaluation entities <b>222</b> is increased. For example, in response to increasing the frequency of required evaluations, the number of sample points <b>302</b> increases in magnitude for the duration of the accuracy degradation event <b>308</b>. In certain examples, in response to the accuracy degradation event <b>308</b> being cleared by the result evaluation component <b>208</b>, the result processing component <b>204</b> is configured to change the quality control parameter so that the frequency of required evaluations by the external evaluation entities <b>222</b> is decreased. For example, in response to decreasing the frequency of required evaluations, the number of sample points <b>302</b> decreases in magnitude outside the accuracy degradation event <b>308</b>.</p><p id="p-0041" num="0039">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in certain embodiments, the result evaluation component <b>208</b> is configured, in response to the one or more accuracy parameters being smaller than a predetermined minimum threshold, increase the truth counter <b>226</b>. For example, the result evaluation component <b>208</b> is configured to increase the truth counter <b>226</b> for each question associated with textual data of the processed documents <b>214</b>. As an example, in response to identifying an accuracy degradation event, the result evaluation component <b>208</b> is configured to store the truth counter <b>226</b> in the accuracy store <b>206</b>. In some examples, the result evaluation component <b>208</b> is configured to determine based at least in part on the quality control parameter whether an evaluation of the questions by the external evaluation entities <b>222</b> is required until the accuracy degradation event is cleared. For example, the result evaluation component <b>208</b> is configured to clear the accuracy degradation event if the one or more accuracy parameters are equal to or larger than the predetermined minimum threshold. In certain examples, the result processing component <b>204</b> is configured to increase the quality control parameter.</p><p id="p-0042" num="0040">According to some embodiments, the training component <b>210</b> is configured to, in response to the truth counter <b>224</b> of at least one question being larger than a predetermined truth threshold, generate one or more models <b>228</b> of the machine learning system. For example, the predetermined truth threshold is equal to 500, 1,000, 1,500 or 2,000. In some examples, the training component <b>210</b> is configured to generate models <b>228</b> of the machine learning system by training the models <b>228</b> using training data and known true answers associated with the training data. For example, in response to training the models based at least in part on training data and known true answers associated with the training data, the prediction component <b>202</b> is configured to predict answers to the questions on non-training data using the trained models. As an example, the training component <b>210</b> is configured to generate one or more models <b>228</b> by training the one or more models <b>228</b> based at least in part on one or more combinations of truth data. In one example, the truth data includes the true answers and the textual data associated with the true answers. In certain examples, the one or more combinations of truth data include truth data generated after the accuracy degradation event <b>308</b> is identified by the result evaluation component <b>208</b>. In other examples, the one or more combinations of truth data include truth data generated before and after the accuracy degradation event <b>308</b> is identified. In other examples, the training component <b>210</b> is configured to send the one or more models <b>228</b> to the staging component <b>212</b>. For example, the staging component <b>212</b> is configured to receive the one or more models <b>228</b> from the training component <b>210</b> to determine an accuracy score of the one or more models <b>228</b>.</p><p id="p-0043" num="0041">According to certain embodiments, the staging component <b>212</b> is configured to determine an accuracy score associated with the one or more models <b>228</b>. For example, the staging component <b>212</b> is configured to determine accuracy scores for each model of the one or more models <b>228</b> based on the truth data. In some examples, the staging component <b>212</b> is configured to, in response to the accuracy score of the models <b>228</b> being larger than the accuracy score associated with the models <b>218</b>, replace the one or more models <b>218</b> with the one or more models <b>228</b> at the prediction component <b>202</b> of the machine learning system. For example, the accuracy score of the models <b>228</b> is larger than the accuracy score of the models <b>218</b> if the accuracy score of each model of the models <b>228</b> is larger than the accuracy score of each model of the models <b>218</b>. In certain examples, the staging component <b>212</b> is configured to promote the models <b>228</b> to the prediction component <b>202</b> if the accuracy score of the models <b>228</b> is larger than the accuracy score of the models <b>218</b>. According to some examples, the staging component <b>212</b> is configured to, in response to the accuracy score of models <b>228</b> being smaller than or equal to the accuracy score of models <b>218</b>, wait for the truth counter to increase further. For example, the staging component <b>212</b> is configured to, in response to the truth counter being larger than a predetermined truth threshold, generate the one or more models <b>228</b>, and determine the accuracy score associated with the one or more models <b>228</b>.</p><p id="p-0044" num="0042"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> is a simplified diagram showing a method for adaptive training of a machine learning system processing textual data according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. The method <b>400</b> includes processes <b>402</b>-<b>420</b> that are performed using one or more processors. Although the above has been shown using a selected group of processes for the method, there can be many alternatives, modifications, and variations. For example, some of the processes may be expanded and/or combined. Other processes may be inserted to those noted above. Depending upon the embodiment, the sequence of processes may be interchanged with others replaced.</p><p id="p-0045" num="0043">In some embodiments, some or all processes (e.g., steps) of the method <b>400</b> are performed by the system <b>100</b>. In certain examples, some or all processes (e.g., steps) of the method <b>400</b> are performed by a computer and/or a processor directed by a code. For example, a computer includes a server computer and/or a client computer (e.g., a personal computer). In some examples, some or all processes (e.g., steps) of the method <b>400</b> are performed according to instructions included by a non-transitory computer-readable medium (e.g., in a computer program product, such as a computer-readable flash drive). For example, a non-transitory computer-readable medium is readable by a computer including a server computer and/or a client computer (e.g., a personal computer, and/or a server rack). As an example, instructions included by a non-transitory computer-readable medium are executed by a processor including a processor of a server computer and/or a processor of a client computer (e.g., a personal computer, and/or server rack).</p><p id="p-0046" num="0044">In some embodiments, at the process <b>402</b>, a predicted answers to questions associated with textual data is received. The predicted answers is generated based at least in part on one or more first models of a machine learning system. The one or more first models are associated with a first accuracy score. At the process <b>404</b>, whether an evaluation of the questions by one or more external entities is required is determined based at least in part on a quality control parameter. At process <b>406</b>, in response to determining based at least in part on the quality control parameter that an evaluation of the questions by one or more external entities is required, the questions associated with the textual data and the textual data are sent to the one or more external entities for evaluation. At process <b>408</b>, true answers to the questions from the one or more external entities are received. One or more accuracy parameters based at least in part on the true answers and the predicted answers are determined at process <b>410</b>. In response to the one or more accuracy parameters being smaller than a predetermined minimum threshold, an accuracy degradation event is identified at process <b>412</b>, and the quality control parameter is increased at process <b>414</b>. In response to a truth counter of at least one question being larger than a first predetermined truth threshold, one or more second models are generated at process <b>416</b>, and a second accuracy score associated with the one or more second models is determined at process <b>418</b>. At process <b>420</b>, in response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, the one or more first models with the one or more second models are replaced at the machine learning system.</p><p id="p-0047" num="0045"><figref idref="DRAWINGS">FIG. <b>4</b>B</figref> is a simplified diagram showing a method for adaptive training of a machine learning system processing textual data according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. In addition to the processes <b>402</b>-<b>420</b>, as shown in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, the method <b>430</b> further includes processes <b>432</b>-<b>438</b> that are performed using one or more processors. Although the above has been shown using a selected group of processes for the method, there can be many alternatives, modifications, and variations. For example, some of the processes may be expanded and/or combined. Other processes may be inserted to those noted above. Depending upon the embodiment, the sequence of processes may be interchanged with others replaced.</p><p id="p-0048" num="0046">In some embodiments, some or all processes (e.g., steps) of the method <b>430</b> are performed by the system <b>100</b>. In certain examples, some or all processes (e.g., steps) of the method <b>430</b> are performed by a computer and/or a processor directed by a code. For example, a computer includes a server computer and/or a client computer (e.g., a personal computer). In some examples, some or all processes (e.g., steps) of the method <b>430</b> are performed according to instructions included by a non-transitory computer-readable medium (e.g., in a computer program product, such as a computer-readable flash drive). For example, a non-transitory computer-readable medium is readable by a computer including a server computer and/or a client computer (e.g., a personal computer, and/or a server rack). As an example, instructions included by a non-transitory computer-readable medium are executed by a processor including a processor of a server computer and/or a processor of a client computer (e.g., a personal computer, and/or server rack).</p><p id="p-0049" num="0047">In some embodiments, at the process <b>432</b>, in response to the one or more accuracy parameters being equal to or larger than the predetermined minimum threshold, the accuracy degradation event is cleared. For example, in response to the accuracy degradation event being cleared, an evaluation number is determined at the process <b>434</b>, and, at the process <b>436</b>, the evaluation number and the truth counter is stored in a storage for retrieval by the machine learning system. The evaluation number indicates a number of evaluations performed by one or more external entities from a time when the accuracy degradation event is identified. At the process <b>438</b>, whether an evaluation of the questions by one or more external entities is required is determined based at least in part on a quality control parameter until the accuracy degradation event is cleared.</p><p id="p-0050" num="0048"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a simplified diagram showing a computing system for implementing a system for adaptive training of a machine learning system processing textual data according to one embodiment of the present invention. This diagram is merely an example, which should not unduly limit the scope of the claims. One of ordinary skill in the art would recognize many variations, alternatives, and modifications. The computing system <b>500</b> includes a bus <b>502</b> or other communication mechanism for communicating information, a processor <b>504</b>, a display <b>506</b>, a cursor control component <b>508</b>, an input device <b>510</b>, a main memory <b>512</b>, a read only memory (ROM) <b>514</b>, a storage unit <b>516</b>, and a network interface <b>518</b>. In some embodiments, some or all processes (e.g., steps) of the method <b>400</b> are performed by the computing system <b>500</b>. In some examples, the bus <b>502</b> is coupled to the processor <b>504</b>, the display <b>506</b>, the cursor control component <b>508</b>, the input device <b>510</b>, the main memory <b>512</b>, the read only memory (ROM) <b>514</b>, the storage unit <b>516</b>, and/or the network interface <b>518</b>. In certain examples, the network interface is coupled to a network <b>520</b>. For example, the processor <b>504</b> includes one or more general purpose microprocessors. In some examples, the main memory <b>512</b> (e.g., random access memory (RAM), cache and/or other dynamic storage devices) is configured to store information and instructions to be executed by the processor <b>504</b>. In certain examples, the main memory <b>512</b> is configured to store temporary variables or other intermediate information during execution of instructions to be executed by processor <b>504</b>. For examples, the instructions, when stored in the storage unit <b>516</b> accessible to processor <b>504</b>, render the computing system <b>500</b> into a special-purpose machine that is customized to perform the operations specified in the instructions. In some examples, the ROM <b>514</b> is configured to store static information and instructions for the processor <b>504</b>. In certain examples, the storage unit <b>516</b> (e.g., a magnetic disk, optical disk, or flash drive) is configured to store information and instructions.</p><p id="p-0051" num="0049">In some embodiments, the display <b>506</b> (e.g., a cathode ray tube (CRT), an LCD display, or a touch screen) is configured to display information to a user of the computing system <b>500</b>. In some examples, the input device <b>510</b> (e.g., alphanumeric and other keys) is configured to communicate information and commands to the processor <b>504</b>. For example, the cursor control <b>508</b> (e.g., a mouse, a trackball, or cursor direction keys) is configured to communicate additional information and commands (e.g., to control cursor movements on the display <b>506</b>) to the processor <b>504</b>.</p><p id="p-0052" num="0050">According to some embodiments, a method for adaptive training of a machine learning system configured to predict answers to questions associated with textual data includes receiving predicted answers to questions associated with textual data. The predicted answers are generated based at least in part on one or more first models of a machine learning system. The one or more first models are associated with a first accuracy score. The method further includes determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required. In response to determining based at least in part on the quality control parameter that an evaluation of the questions by one or more external entities is required, the questions associated with the textual data and the textual data are sent to the one or more external entities for evaluation. The method further includes receiving true answers to the questions from the one or more external entities and determining one or more accuracy parameters based at least in part on the true answers and the predicted answers. In response to the one or more accuracy parameters being smaller than a predetermined minimum threshold, an accuracy degradation event is identified, and the quality control parameter is increased. In response to a truth counter of at least one question being larger than a first predetermined truth threshold, one or more second models are generated, and a second accuracy score associated with the one or more second models is determined. In response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, the one or more first models are replaced with the one or more second models at the machine learning system. For example, the method is implemented according to at least <figref idref="DRAWINGS">FIG. <b>1</b></figref>, <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and/or <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0053" num="0051">In some examples, the quality control parameter indicates a number of required evaluations performed by the one or more external entities. In certain examples, the determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required includes increasing the number of required evaluations based at least in part on the determined one or more accuracy parameters.</p><p id="p-0054" num="0052">In other examples, the generating one or more second models includes training the one or more second models based at least in part on one or more combinations of truth data. The truth data includes the true answers and the textual data associated with the true answers. For example, one or more combinations of truth data include truth data generated after the accuracy degradation event is identified. As an example, one or more combinations of truth data include truth data generated before and after the accuracy degradation event is identified. In some examples, the determining a second accuracy score associated with the one or more second models includes determining accuracy scores for each model of the one or more second model based on the truth data.</p><p id="p-0055" num="0053">In some examples, the second accuracy score is larger than the first accuracy score if an accuracy score of each model of the one or more second models is larger than an accuracy score of each model of the one or more first models. In certain examples, the method further includes, in response to the second accuracy score being smaller than or equal to the first accuracy score, waiting for the truth counter to increase further. In response to the second accuracy score being smaller than or equal to the first accuracy score, the one or more second models is generated, and the second accuracy score associated with the one or more second models is determined. In other examples, the method further includes determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required until the accuracy degradation event is cleared.</p><p id="p-0056" num="0054">In certain examples, the method further includes, in response to the one or more accuracy parameters being equal to or larger than the predetermined minimum threshold, clearing the accuracy degradation event. For example, the predicted answers to questions associated with textual data are received in response to a request or push event. In some examples, the method further includes generating the quality control parameter based at least in part on one or more factors. The one or more factors include one or more static configuration parameters associated with the textual data, a current environment associated with the textual data, an identity of a requester associated with the request, a confidence associated with the predicated answers, and a request frequency. In other examples, the receiving true answers to the questions from the one or more external entities includes evaluating the questions based on the textual data by the one or more external entities through a mechanical evaluation, a virtual evaluation, or a natural evaluation.</p><p id="p-0057" num="0055">In some examples, the questions based on the textual data are evaluated by the one or more external entities without knowledge of the predicted answers. In other examples, the method further includes storing the determined one or more accuracy parameters in a storage for retrieval by the machine learning system. For example, the method further includes storing an accuracy deviation in the storage for retrieval by the machine learning system. The accuracy deviation is equal to a difference of the one or more accuracy parameters and the predetermined minimum threshold. In certain examples, the method further includes, in response to the accuracy degradation event being cleared, determining an evaluation number. The evaluation number indicates a number of evaluations performed by one or more external entities from a time when the accuracy degradation event is identified. In response to the accuracy degradation event being cleared, the evaluation number and the truth counter is stored in a storage for retrieval by the machine learning system.</p><p id="p-0058" num="0056">In other examples, the method further includes, in response to the identifying an accuracy degradation event, storing the truth counter in a storage for retrieval by the machine learning system. For example, the method further includes increasing the predetermined minimum threshold in response to the first accuracy score increasing over time.</p><p id="p-0059" num="0057">According to certain embodiments, a system for adaptive training of a machine learning system configured to predict answers to questions associated with textual data includes one or more processors and a memory storing instructions. The instructions, when executed by the one or more processors, cause the system to perform receiving predicted answers to questions associated with textual data. The predicted answers are generated based at least in part on one or more first models of a machine learning system. The one or more first models are associated with a first accuracy score. The instructions, when executed by the one or more processors, cause the system to further perform determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required. In response to determining based at least in part on the quality control parameter that an evaluation of the questions by one or more external entities is required, the questions associated with the textual data and the textual data are sent to the one or more external entities for evaluation. The instructions, when executed by the one or more processors, cause the system to further perform receiving true answers to the questions from the one or more external entities and determining one or more accuracy parameters based at least in part on the true answers and the predicted answers. In response to the one or more accuracy parameters being smaller than a predetermined minimum threshold, an accuracy degradation event is identified, and the quality control parameter is increased. In response to a truth counter of at least one question being larger than a first predetermined truth threshold, one or more second models are generated, and a second accuracy score associated with the one or more second models is determined. In response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, the one or more first models are replaced with the one or more second models at the machine learning system. For example, the system is implemented according to at least <figref idref="DRAWINGS">FIG. <b>1</b></figref>, <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and/or <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0060" num="0058">In some examples, the quality control parameter indicates a number of required evaluations performed by the one or more external entities. In certain examples, the determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required includes increasing the number of required evaluations based at least in part on the determined one or more accuracy parameters.</p><p id="p-0061" num="0059">In other examples, the generating one or more second models includes training the one or more second models based at least in part on one or more combinations of truth data. The truth data includes the true answers and the textual data associated with the true answers. For example, one or more combinations of truth data include truth data generated after the accuracy degradation event is identified. As an example, one or more combinations of truth data include truth data generated before and after the accuracy degradation event is identified. In some examples, the determining a second accuracy score associated with the one or more second models includes determining accuracy scores for each model of the one or more second model based on the truth data. In some examples, the second accuracy score is larger than the first accuracy score if an accuracy score of each model of the one or more second models is larger than an accuracy score of each model of the one or more first models.</p><p id="p-0062" num="0060">According to certain embodiments, a non-transitory computer readable storage medium storing one or more programs. The one or more programs includes instructions, when executed by one or more processors, causing a system for adaptive training of a machine learning system configured to predict answers to questions associated with textual data to perform receiving predicted answers to questions associated with textual data. The predicted answers are generated based at least in part on one or more first models of a machine learning system. The one or more first models are associated with a first accuracy score. The instructions, when executed by the one or more processors, cause the system to further perform determining based at least in part on a quality control parameter whether an evaluation of the questions by one or more external entities is required. In response to determining based at least in part on the quality control parameter that an evaluation of the questions by one or more external entities is required, the questions associated with the textual data and the textual data are sent to the one or more external entities for evaluation. The instructions, when executed by the one or more processors, cause the system to further perform receiving true answers to the questions from the one or more external entities and determining one or more accuracy parameters based at least in part on the true answers and the predicted answers. In response to the one or more accuracy parameters being smaller than a predetermined minimum threshold, an accuracy degradation event is identified, and the quality control parameter is increased. In response to a truth counter of at least one question being larger than a first predetermined truth threshold, one or more second models are generated, and a second accuracy score associated with the one or more second models is determined. In response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, the one or more first models are replaced with the one or more second models at the machine learning system. For example, the system is implemented according to at least <figref idref="DRAWINGS">FIG. <b>1</b></figref>, <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and/or <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0063" num="0061">For example, some or all components of various embodiments of the present invention each are, individually and/or in combination with at least another component, implemented using one or more software components, one or more hardware components, and/or one or more combinations of software and hardware components. In another example, some or all components of various embodiments of the present invention each are, individually and/or in combination with at least another component, implemented in one or more circuits, such as one or more analog circuits and/or one or more digital circuits. In yet another example, while the embodiments described above refer to particular features, the scope of the present invention also includes embodiments having different combinations of features and embodiments that do not include all of the described features. In yet another example, various embodiments and/or examples of the present invention can be combined.</p><p id="p-0064" num="0062">Additionally, the methods and systems described herein may be implemented on many different types of processing devices by program code comprising program instructions that are executable by the device processing subsystem. The software program instructions may include source code, object code, machine code, or any other stored data that is operable to cause a processing system to perform the methods and operations described herein. Other implementations may also be used, however, such as firmware or even appropriately designed hardware configured to perform the methods and systems described herein.</p><p id="p-0065" num="0063">The systems' and methods' data (e.g., associations, mappings, data input, data output, intermediate data results, final data results, etc.) may be stored and implemented in one or more different types of computer-implemented data stores, such as different types of storage devices and programming constructs (e.g., RAM, ROM, EEPROM, Flash memory, flat files, databases, programming data structures, programming variables, IF-THEN (or similar type) statement constructs, application programming interface, etc.). It is noted that data structures describe formats for use in organizing and storing data in databases, programs, memory, or other computer-readable media for use by a computer program.</p><p id="p-0066" num="0064">The systems and methods may be provided on many different types of computer-readable media including computer storage mechanisms (e.g., CD-ROM, diskette, RAM, flash memory, computer's hard drive, DVD, etc.) that contain instructions (e.g., software) for use in execution by a processor to perform the methods' operations and implement the systems described herein. The computer components, software modules, functions, data stores and data structures described herein may be connected directly or indirectly to each other in order to allow the flow of data needed for their operations. It is also noted that a module or processor includes a unit of code that performs a software operation, and can be implemented for example as a subroutine unit of code, or as a software function unit of code, or as an object (as in an object-oriented paradigm), or as an applet, or in a computer script language, or as another type of computer code. The software components and/or functionality may be located on a single computer or distributed across multiple computers depending upon the situation at hand.</p><p id="p-0067" num="0065">The computing system can include client devices and servers. A client device and server are generally remote from each other and typically interact through a communication network. The relationship of client device and server arises by virtue of computer programs running on the respective computers and having a client device-server relationship to each other.</p><p id="p-0068" num="0066">This specification contains many specifics for particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations, one or more features from a combination can in some cases be removed from the combination, and a combination may, for example, be directed to a subcombination or variation of a subcombination.</p><p id="p-0069" num="0067">Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.</p><p id="p-0070" num="0068">Although specific embodiments of the present invention have been described, it will be understood by those of skill in the art that there are other embodiments that are equivalent to the described embodiments. Accordingly, it is to be understood that the invention is not to be limited by the specific illustrated embodiments, but only by the scope of the appended claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230004840A1-20230105-M00001.NB"><img id="EMI-M00001" he="16.93mm" wi="76.20mm" file="US20230004840A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for adaptive training of a machine learning system configured to predict answers to questions associated with textual data, the method comprising:<claim-text>receiving predicted answers to questions associated with textual data, the predicted answers being generated based at least in part on one or more first models of a machine learning system, the one or more first models being associated with a first accuracy score;</claim-text><claim-text>receiving true answers to the questions from the one or more external entities;</claim-text><claim-text>determining one or more accuracy parameters based at least in part on the true answers and the predicted answers;</claim-text><claim-text>in response to a truth counter of at least one question being larger than a first predetermined truth threshold:<claim-text>generating one or more second models; and</claim-text><claim-text>determining a second accuracy score associated with the one or more second models; and</claim-text></claim-text><claim-text>in response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, replacing, at the machine learning system, the one or more first models with the one or more second models.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the generating one or more second models includes training the one or more second models based at least in part on one or more combinations of truth data, the truth data including the true answers and the textual data associated with the true answers.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the second accuracy score is larger than the first accuracy score if an accuracy score of each model of the one or more second models is larger than an accuracy score of each model of the one or more first models.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, and further comprising:<claim-text>in response to the second accuracy score being smaller than or equal to the first accuracy score, waiting for the truth counter to increase further; and</claim-text><claim-text>in response to the truth counter being larger than a second predetermined truth threshold:<claim-text>generating the one or more second models; and</claim-text><claim-text>determining the second accuracy score associated with the one or more second models.</claim-text></claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, and further comprising:<claim-text>in response to the one or more accuracy parameters being equal to or larger than the predetermined minimum threshold, clearing the accuracy degradation event.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the predicted answers to questions associated with textual data are received in response to a request or push event.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the receiving true answers to the questions from the one or more external entities includes evaluating the questions based on the textual data by the one or more external entities through a mechanical evaluation, a virtual evaluation, or a natural evaluation.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the questions based on the textual data are evaluated by the one or more external entities without knowledge of the predicted answers.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, and further comprising:<claim-text>storing the determined one or more accuracy parameters in a storage for retrieval by the machine learning system.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, and further comprising:<claim-text>storing an accuracy deviation in the storage for retrieval by the machine learning system, the accuracy deviation being equal to a difference of the one or more accuracy parameters and the predetermined minimum threshold.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, and further comprising:<claim-text>in response to the accuracy degradation event being cleared:<claim-text>determining an evaluation number, the evaluation number indicating a number of evaluations performed by one or more external entities from a time when the accuracy degradation event is identified; and</claim-text><claim-text>storing the evaluation number and the truth counter in a storage for retrieval by the machine learning system.</claim-text></claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, and further comprising:<claim-text>changing the first predetermined truth threshold based on the stored evaluation number.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, and further comprising:<claim-text>in response to the identifying an accuracy degradation event, storing the truth counter in a storage for retrieval by the machine learning system.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, and further comprising:<claim-text>increasing the predetermined minimum threshold in response to the first accuracy score increasing over time.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A system for adaptive training of a machine learning system configured to predict answers to questions associated with textual data, the system comprising:<claim-text>one or more processors; and</claim-text><claim-text>a memory storing instructions, the instructions, when executed by the one or more processors, causing the system to perform:<claim-text>receiving predicted answers to questions associated with textual data, the predicted answers being generated based at least in part on one or more first models of a machine learning system, the one or more first models being associated with a first accuracy score;</claim-text><claim-text>receiving true answers to the questions from the one or more external entities;</claim-text><claim-text>determining one or more accuracy parameters based at least in part on the true answers and the predicted answers;</claim-text><claim-text>in response to a truth counter of at least one question being larger than a first predetermined truth threshold:<claim-text>generating one or more second models; and</claim-text><claim-text>determining a second accuracy score associated with the one or more second models; and</claim-text></claim-text><claim-text>in response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, replacing, at the machine learning system, the one or more first models with the one or more second models.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref> wherein the generating one or more second models includes training the one or more second models based at least in part on one or more combinations of truth data, the truth data including the true answers and the textual data associated with the true answers.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref> wherein the one or more combinations of truth data include truth data generated after the accuracy degradation event is identified.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref> wherein the determining a second accuracy score associated with the one or more second models includes determining accuracy scores for each model of the one or more second models based on the truth data.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00018">claim 18</claim-ref> wherein the second accuracy score is larger than the first accuracy score if an accuracy score of each model of the one or more second models is larger than an accuracy score of each model of the one or more first models.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A non-transitory computer readable storage medium storing one or more programs, the one or more programs comprising instructions, when executed by one or more processors, causing a system for adaptive training of a machine learning system configured to predict answers to questions associated with textual data to perform:<claim-text>receiving predicted answers to questions associated with textual data, the predicted answers being generated based at least in part on one or more first models of a machine learning system, the one or more first models being associated with a first accuracy score;</claim-text><claim-text>receiving true answers to the questions from the one or more external entities;</claim-text><claim-text>determining one or more accuracy parameters based at least in part on the true answers and the predicted answers;</claim-text><claim-text>in response to a truth counter of at least one question being larger than a first predetermined truth threshold:<claim-text>generating one or more second models; and</claim-text><claim-text>determining a second accuracy score associated with the one or more second models; and</claim-text></claim-text><claim-text>in response to the second accuracy score being larger than the first accuracy score associated with the one or more first models, replacing, at the machine learning system, the one or more first models with the one or more second models.</claim-text></claim-text></claim></claims></us-patent-application>
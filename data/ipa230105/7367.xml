<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007368A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007368</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17878332</doc-number><date>20220801</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>8549</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>166</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>43</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>45</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>8549</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>166</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200801</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>43076</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>4532</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHODS AND SYSTEMS FOR PROVIDING DYNAMIC SUMMARIES OF MISSED CONTENT FROM A GROUP WATCHING EXPERIENCE</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17350313</doc-number><date>20210617</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11451885</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17878332</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>ROVI GUIDES, INC.</orgname><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Chandrashekar</last-name><first-name>Padmassri</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Emmanuel</last-name><first-name>Daina</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Harb</last-name><first-name>Reda</first-name><address><city>Issaquah</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Shah</last-name><first-name>Akshay Chetan</first-name><address><city>Mumbai</city><country>IN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Systems and methods are presented for providing dynamic summaries of missed content of content streaming on multiple device. A plurality of groups for a concurrent presentation of a content is identified, and a selection is received by a user via a second device to join a first group of the plurality of groups for the concurrent presentation of the content. Based on a user via the second device joining a group, a determination is made as to whether a user via the second device missed any content from the concurrent presentation of the content for the first group. Based on the detection of missed content, the system generates for the second device one or more summaries of the missed content segments and the missed reactions to the segments based on preferences associated with the user profile. In response to generating the summaries, the summaries are presented via the second device to the user.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="117.69mm" wi="156.13mm" file="US20230007368A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="232.49mm" wi="172.89mm" orientation="landscape" file="US20230007368A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="231.22mm" wi="171.53mm" orientation="landscape" file="US20230007368A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="231.06mm" wi="174.33mm" orientation="landscape" file="US20230007368A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="239.35mm" wi="171.37mm" file="US20230007368A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="202.61mm" wi="185.00mm" file="US20230007368A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="228.09mm" wi="162.14mm" orientation="landscape" file="US20230007368A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="235.37mm" wi="172.89mm" file="US20230007368A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="246.80mm" wi="177.38mm" file="US20230007368A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="177.12mm" wi="98.55mm" file="US20230007368A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">The present disclosure relates to methods and systems for providing summaries of missed content and, more particularly, to methods and systems for generating summaries of missed content and reactions to the missed content based on simultaneously streaming content to multiple devices in a group.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0003" num="0002">Although some viewers enjoy watching movies, shows, or other content alone, many viewers prefer to do so with friends or family. Watching content with others can enrich the user's viewing experience, for instance, by facilitating shared commentary and/or reactions to particular scenes or segments of the content. Scheduling conflicts and other factors, however, sometimes make it difficult for viewers to find a mutually convenient time to watch content together and lead to a viewer missing content during a concurrent presentation with friends or family. Conventional systems for providing a user with summaries of missed content present a singular summary for all missed portions of a show without regard to the relevance of the whole summary to the current content being played to the user, much less consideration of the shared commentary and/or reactions to particular scenes or segments from friends or family. Further, some viewers consuming the content with multiple groups may want to catch up on the shared commentary and/or reactions to particular scenes or segments from each group as they enter; however, catching up may be burdensome because of the large amount of content to sift through and, in fact, may impede a user's enjoyment of the content. Furthermore, the amount of bandwidth and time required to present a summary of all missed portions of the content can be substantial. The amount of time required to consume a lengthy summary may overwhelm a user's viewing experience and may diminish the user's ability to consume the shared commentary and/or reactions to particular scenes or segments.</p><p id="p-0004" num="0003">To overcome these problems, methods and systems are disclosed herein for providing a user with summaries of missed content, especially summaries for missed portions relevant to the shared commentary and/or reactions to particular scenes or segments of the content, which are described herein. In one example, the present disclosure provides a system for generating a concurrent presentation of content to multiple devices for a group watch. The system comprises a memory communication port and control circuitry. The memory is configured to store, in association with metadata for content, shared commentary and/or reactions to particular scenes or segments of the content, and/or the like, captured via a sensor, such as a camera, a microphone, a heart rate sensor, and/or the like, during display of the content via a first device. In some embodiments, a summary application detects that a user via a second device missed a previous portion of content including shared commentary and/or reactions to particular scenes or segments of the content. For example, a summary application may receive information that a user via a second device joined a group watch for concurrent presentation after a group watch via a first device has started the show being played. In some examples, a summary application receives information that the user via the second device has left the concurrent presentation and subsequently returned to a room (e.g., virtual room) in which the show is being played and detects what content was played and comments and reactions were inputted while the user was gone from the room (e.g., virtual room). The summary application, having detected which content and shared commentary and/or reactions to particular scenes or segments were presented in the missed content, accesses metadata that identifies storylines based on time stamps. The summary application then generate a summary for the missed portions of that content and shared commentary and/or reactions to particular scenes or segments. Therefore, if the user missed different portions of, for example, three segments and shared analysis and/or reactions to particular scenes or segments, the summary application can generate a summary of the missed portions specific to the current storyline. The summary application then causes for presentation the specific summaries for the user via the second device.</p><p id="p-0005" num="0004">In some embodiments, the system via control circuitry is configured to identify a plurality of groups for concurrent presentation of content. For example, a user is searching for groups that are watching a particular program in a watch group&#x2014;e.g., a family group, a coworkers group, and unknown users, all-consuming the baseball game&#x2014;each group from the plurality of groups being associated with one or more first devices, for example, a first device that joins/starts a group watch (e.g., college friends group) by initiating the concurrent presentation of the content (e.g., NY Yankees vs. Boston Red Sox baseball game). In some embodiments, the control circuitry receives, by a second device associated with a user profile, a selection to join a first group of the plurality of groups for the concurrent presentation of the content. For example, the user wants to join a concurrent presentation (e.g., group watch) of a movie, show, match, etc.; however, the user joins the presentation after the start time. In some embodiments, in response to receiving the selection to join the first group, the control circuitry detects that the user via the second device has missed portions of the concurrent presentation of the content (e.g., Yankees vs. Red Sox game) for the first group. The missed portion may include a plurality of content segments and a plurality of reactions from the one or more first devices of the first group. The control circuitry may then generate for the second device one or more summaries of the plurality of content segments and the plurality of reactions based on preferences associated with the user profile. For example, a user joining a content item (e.g., Yankees vs. Red Sox game) with college friends may have different preferences than if joining a family group or a group based on personal similarities where the user does not know the others members. In some embodiments, in response to the generating, the control circuitry may cause for the presentation one or more summaries for the second device. Thus, the summary application operates more efficiently than conventional systems in its consumption of bandwidth and processing. By displaying less information during the summary of the current storyline, the summary application spares users from time-consuming summaries that impede the user's consumption and avoids inundating the user with less relevant information in the content summary. The summary application reduces both the time required by conventional systems to play back summaries and the bandwidth and processing required by those systems.</p><p id="p-0006" num="0005">In some embodiments, the control circuitry generates one or more summaries of the missed segments of the content for the second devices by retrieving metadata for the identified missed portion. The control circuitry then extracts a content storyline identifier from the retrieved metadata for the plurality of content segments and a reaction storyline identifier from the retrieved metadata for the plurality of reactions. For example, the control circuitry identifies the shared commentary and/or reactions to particular scenes or segments of the content missed by a user via the second device. The control circuitry identifies a plurality of storyline-specific portions in the missed portion. Each of the plurality of storyline-specific portions is associated with the segment storyline identifier or reaction storyline identifier. The control circuitry generates summaries for the plurality of storyline-specific portions in the missed content. The control circuitry then combines the summaries for the plurality of storyline-specific portions in the missed portion to generate the storyline-specific summary of the portion of the missed portion comprising the segment storyline identifier or reaction storyline identifier. The summary application may present summaries of missed portions of storylines and missed comments and reactions more efficiently and at more relevant times as a show progresses through various storylines which improves a user's enjoyment of content and retention of the storylines, as well as allows the user to catch up to the conversation among the group.</p><p id="p-0007" num="0006">In some embodiments, the control circuitry generates one or more summaries of the missed segments of the content for the second device by accessing user preferences associated with the user profile. Further, the control circuitry retrieves metadata for the identified missed portion and extracts a reaction storyline identifier from the retrieved metadata for the identified missed portion. For example, the control circuitry extracts the shared commentary and/or reactions to particular scenes or segments and generates a list of the comments and reactions. Based on the generated list of the comments and reactions, the control circuitry may sort the commentary and reactions based on the largest number of interactions from one or more first devices. For example, comments that received more likes, up-votes, or responses are listed higher in the list for presentation to the second user device. In some embodiments, the control circuitry further combines the extracted reaction storyline identifiers in the missed portion to generate a storyline-specific summary of reactions for the missed portion. In some embodiments, a summary application may then concatenate the snippets of content and reactions into a single summary video or present several snippets to a user that collectively summarize the missed portions of the content.</p><p id="p-0008" num="0007">In some embodiments, the control circuitry is further configured to identify the plurality of segments in the missed content, wherein each of the plurality of segments is associated with a segment summary. The control circuitry then generates for each segment of the plurality of segments a popularity score based on user preferences. For example, the interactions (e.g., likes, up-votes, comments) with each segment are tracked to determine the popularity score. The control circuitry then updates each segment of the plurality of segments with the respective popularity score. In some embodiments, the control circuitry retrieves each segment from the plurality of segments having a popularity score above a threshold, wherein each segment of the plurality of segments comprises segment summaries for the respective segment in the plurality of segments in the missed content. In some embodiments, the control circuitry is configured to combine the retrieved segment summaries with popularity scores above the threshold for presentation. In some embodiments, a summary application may then concatenate the snippets of content based on popularity scores for reactions into a single summary video or present several snippets to a user that collectively summarize the missed portions of the content. In some embodiments, the summarized content is provided based on a popularity score. In some embodiments, the summarized content is provided based on a chronicled sequence of events and a popularity score. For example, the top ten reactions are identified, and they are provided in the sequence of the content as they occurred during the missed portion of the content.</p><p id="p-0009" num="0008">In some embodiments, the concurrent presentation of the content may include a virtual concurrent presentation of the content on a plurality of devices. For example, a system may cause presentation of synchronized content on multiple devices. In another example, multiple users desire to consume the latest baseball game between New York Yankees and Boston Red Sox at home. The first user is in Boston, while the second user is in New York. To improve their enjoyment of the content, the users are consuming the content in a watch group for concurrent and synchronized presentation on their devices in their homes.</p><p id="p-0010" num="0009">In some embodiments, the control circuitry identifies a geographical location of the one or more first devices and a geographical location of the second device. The control circuitry determines that the geographical location of the one or more first devices and the geographical location of the second device are different geographical locations. If the first device and second device are in the same location, a summary of the missed portions may not be necessary. In some embodiments, the different geographical location is a predefined distance between the two devices.</p><p id="p-0011" num="0010">In some embodiments, the control circuitry identifies the plurality of groups for concurrent presentation of the content by identifying a user profile associated with each device in each group of the plurality of groups. In some embodiments, the control circuitry retrieves from a social media database metadata related to each profile in each group of the plurality of groups. The control circuitry generates a group identifier based on the retrieved metadata for each user profile in a respective group. The group identifier is indicative of the social link between a first user and a second user based on a first user profile associated with the first user and a second user profile associated with the second user. The type of social link may include one or more of a parent, a sibling, a grandparent, a cousin, an uncle, an aunt, a child, a friend, and a coworker.</p><p id="p-0012" num="0011">In some embodiments, the control circuitry may determine a summary endpoint of the summary being generated for presentation. The summary endpoint is a point at which the presentation of the summary will complete. In some embodiments, the control circuitry then modifies the summary to include a summary for the content being generated for presentation between a current point in the content and the summary endpoint.</p><p id="p-0013" num="0012">In some embodiments, the causing for presentation of the one or more summaries for the second device includes identifying a secondary display from a plurality of displays associated with the second device. The secondary display is available to display the summary and is not presenting the content or the reactions. The control circuitry directs the secondary display to present the summary.</p><p id="p-0014" num="0013">In some embodiments, to present the one or more summaries for the second device, the control circuitry further includes identifying a primary display from a plurality of displays. The primary display is presenting the concurrent presentation of the content. The control circuitry then directs the primary display to pause the concurrent presentation of the content during the presentation of the generated summary.</p><p id="p-0015" num="0014">In some embodiments, the system is integrated to social media networks (e.g., Facebook, Twitter, LinkedIn, etc.) and media consumption platforms (e.g., TiVo, Netflix, Amazon). For example, the system accesses the databases of the social network and the media consumption platforms to gain insight into the users. Using the insight from these platforms and networks, i.e., metadata about the users consuming content, permits the system to better characterize groups for shared content presentation. In some embodiments, the groups may be pre-defined as private groups based on social media groups. In some embodiments, the groups may be public groups that require an invitation to join chat rooms for discussion of games or can be forum-based groups. In some embodiments, an event start time is regarded as TP<sub>1</sub>, and TP<sub>2 </sub>may be at a later time in the programming. The timepoints may keep a threshold of TP<sub>1</sub>+x where x is a value of significance for content progress to provide a catch-up preview to the user. That is, for the user to appreciate the catch-up, there has to be something to catch up on. If the user missed the introductory credits of a program, there might not be anything to catch-up on.</p><p id="p-0016" num="0015">In some embodiments, where a value of significance for content progress has occurred, the system may provide the user with a catch-up summary (summary of missed content) based on the various groups prioritized and the activity level in the specific groups.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0017" num="0016">The above and other objects and advantages of the disclosure will be apparent upon consideration of the following detailed description, taken in conjunction with the accompanying drawings, in which like reference characters refer to like parts throughout, and in which:</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an illustrative example of a system for generating summaries of missed content and reactions to the missed content based on simultaneously streaming content to multiple devices in a group, in accordance with some embodiments of the disclosure;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example database of a system for generating the summaries of missed content and reactions to the missed content, in accordance with some embodiments of the disclosure;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example database of collected reactions for generating the summaries of missed content and reactions to the missed content, in accordance with some embodiments of the disclosure;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts exemplary systems, servers and related hardware for generating the summaries of missed content and reactions to the missed content, in accordance with some embodiments of the disclosure;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts exemplary systems, servers and related hardware for generating the summaries of missed content and reactions to the missed content, in accordance with some embodiments of the disclosure;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts an illustrative example of a system of user devices for joining a group and generating summaries of missed content and reactions from the group, in accordance with some embodiments of the present disclosure;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts an illustrative example of a user interface application for selecting groups for content for concurrent presentation, in accordance with some embodiments of the present disclosure;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of a detailed illustrative process for generating the summaries of missed content and reactions to the missed content, in accordance with some embodiments of the disclosure;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is another flowchart of a detailed illustrative process for providing summaries of missed content and reactions from the simultaneous presentation of content on multiple devices, in accordance with some embodiments of the disclosure;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart of a detailed illustrative process for generating summaries of the missed content based on user preferences, in accordance with some embodiments of the disclosure;</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0028" num="0027">The present disclosure is related to methods and systems for providing a user with summaries of missed content, especially summaries for missed portions relevant to the shared commentary and/or reactions to particular scenes or segments of the content item. An exemplary user equipment device may be capable of displaying a variety of content types, such as standard video content, audio or a combination of both.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an illustrative example of a system for providing summaries of multiple content items from a group watching a concurrent presentation of content, in accordance with some embodiments of the disclosure. <figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a first device <b>102</b>, associated with a first group <b>141</b> of users, which is displaying content <b>104</b> (illustrated as an image of a movie). User equipment <b>102</b> is depicted as a television device in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In some embodiments, user equipment <b>102</b> may be a smartphone, a smart television, a personal computer, a laptop computer, a tablet computer, or any other type of computing device that has displays and/or audio drivers, such as speakers, that are respectively configured to visibly and/or audibly present content to one or more nearby users and suitable for rendering content (e.g., movies, television shows, linear programming, and over-the-top (OTT) content) during the concurrent presentation of the content among a plurality of devices, for example, synchronized presentation of the same content on multiple devices. In some examples, the devices are in distinct locations apart from each other. The user equipment is also displaying a time bar <b>105</b> that includes a current position indicator <b>106</b>, which is approximately 80 percent complete for the content.</p><p id="p-0030" num="0029">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, two viewers <b>141</b> are observing content <b>104</b> on a first device <b>102</b>. While content <b>104</b> is generated for consumption on the first device <b>102</b>, a supplemental content <b>111</b> (e.g., chatbox) is generated among all users present in the group consuming the content. For example, the second content may be shared commentary and/or reactions to particular scenes or segments as they happen or video streaming of different users viewing the scenes or segments. In some embodiments, a camera may be a part of the first device <b>102</b> and the second device <b>108</b> and may track the faces of viewers <b>141</b> and <b>142</b>. In some embodiments, the one or more first devices employ a camera system that captures the users' facial expressions so that the users in the group consuming the concurrent presentation can interact and engage as they both consume the content at different devices. In some embodiments, the supplemental content may include video and audio streaming of facial expressions and sounds of the users consuming the content <b>104</b> on the first device <b>102</b>. In the illustrative example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the supplemental content <b>111</b> shares comments from Jerry (&#x201c;The gorilla is nice&#x201d;) <b>112</b>, Steven (&#x201c;I like the gorilla&#x201d;) <b>113</b>, and Clara (&#x201c;Me three!!!&#x201d;) <b>114</b> as content <b>104</b> is presented on the first device. Further, viewer or viewers <b>142</b> may join the first group watch to consume content <b>104</b> on a second device <b>108</b>. The second device may be in a remote and different geographical location. The summary application detects that viewers <b>142</b> associated with the second device <b>108</b> missed some portion of the content <b>104</b> between two timepoints, TP<sub>1 </sub>and TP<sub>2 </sub>because a user arrived late to the group watch. In some embodiments, the two-timepoints, TP<sub>1 </sub>and TP<sub>2 </sub>may be in the middle, end, or multiple missed portions, each with two-timepoints, TP<sub>1 </sub>and TP<sub>2</sub>. In some embodiments, the summary application may determine that viewer or viewers <b>142</b> missed this portion of the content by tracking viewers that are present in the group watch of the concurrent presentation of the content <b>104</b>. As part of the missed portion of the content, the summary application may determine that the viewer or viewers <b>142</b> also missed portions of the reactions and shared commentary during the presentation of content <b>104</b>. In a scenario in which the camera is unable to detect one or more viewers for a time period, the summary application may determine that the user or users are absent and may record portions of the content <b>104</b> and supplemental content <b>111</b> and indicate that a viewer is missing in an interaction log the shared commentary and/or reactions to particular scenes or segments from the other viewers. In some embodiments, the summary application may track which portions of content a viewer is present for and log that information in an interaction log specific to a viewer. The summary application may then reference the interaction log for that viewer at a later time and determine that particular content, or portions of content <b>104</b> and supplemental content <b>111</b> (e.g., the shared commentary and/or reactions to particular portions of content), are not in the interaction log, which indicates that the viewer missed the content or portions of content and the reactions to those portions. The summary application may detect when viewer <b>142</b> returns to the viewing area of content <b>104</b> at a timepoint TP<sub>2 </sub>(marked by current position indicator <b>106</b>), e.g., using the same techniques used to build the interaction log. The summary application may also determine that a summary of the missed content between timepoints TP<sub>1 </sub>and TP<sub>2 </sub>should be presented to viewer <b>142</b> without interrupting the playback of content <b>104</b> for viewer <b>141</b> on the first device <b>102</b>.</p><p id="p-0031" num="0030">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the summary application determines which portions of the missed content and supplemental content <b>111</b> to include in the summary for viewer <b>142</b> on second device <b>108</b>. For example, the summary application may compare the time period, user engagement (number of comments and likes that were received for a scene) for which viewer <b>142</b> was absent from the viewing watch group to the timeline of the content <b>104</b>. Using this information, the summary application can determine which time period of the content <b>104</b> and supplemental content <b>111</b> the viewer <b>142</b> has missed. The summary application may split content <b>104</b> into portions of any appropriate size, and the portions may not be the same size. In some embodiments, the summary application may split content <b>104</b> into portions that also received supplemental content <b>111</b>. The portions illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> are exemplary. In some embodiments, the summary application may split content <b>104</b> into portions where supplemental content was received and present only portions of content with supplementary comments. In some embodiments, the summary application may generate a summary based on the portions of content and the supplemental content on the second device <b>108</b>. The summary application may then continue to prepare the summary based on the missed content (portions of the content and supplements content). Upon the viewer <b>142</b> with the second device <b>108</b> joining the group watch of content <b>104</b>, a summary may be presented on the second device <b>108</b> to catch up on the missed content <b>110</b>. For example, a number of users commented on a football game when an exciting play occurred, and the summary application may split content <b>104</b> into portions that include the exciting play that received reactions from users. Based on the reactions received for the content, the summary application may provide the portion along with the reaction to the second device upon a user arriving late to the viewing of the content.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example of a table that the system employs, which contains information about parameters, mechanism and weightage providing summaries of multiple content items from concurrent presentation via group watch, in accordance with some embodiments of the disclosure. The table structure provides parameters, mechanism and weightage for which a summary application may consider to evaluate how to generate a summary. The summary application may consider a parameter from the event highlights, including audio, video, subtitles and metadata analysis and evaluate the parameter using the associated mechanisms. For example, the summary application may sample the audio, video, subtitles, and metadata as per the user's preferences. The summary application may consider the video including the angle which the user prefers to view the content. Based on the user's preferences, the summaries may be generated from the missed portion of content <b>104</b> including the supplemental content <b>111</b>. The summary application may collect such data to track user preferences and learn user preferences based on the events and the user inputs.</p><p id="p-0033" num="0032">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in some embodiments, the table structure may be utilized to determine event-specific groups that the user may want to join. For example, the user may want to join a particular group for the presentation of a football game. In some embodiments, the user may want to join a group based on the content that the user wants to consume. For example, a user wants to watch a show and searches for groups that are watching this show. In some embodiments, the system may recommend groups to the user to join based on the user preferences. For example, the user enjoys watching sporting events with college friends. In another example, the user enjoys watching shows with a brother. Based on a sporting event searched by the user, the system may recommend a college buddies group to join. Similarly, based on a show searched by the user, the system may recommend a family group to join. In another embodiment, the user may want to join a group based on the popularity of the group or another metric. For example, the user may want to join the most popular group, or a funny group, or a group of like-minded supporters of a sports team for the concurrent presentation. The system searches for and recommends groups for the user to join for simultaneous presentation. In some embodiments, a recommendation of a listing of the identified groups is provided for the user to join. The system may evaluate each group based on the conversations made within the group consuming the content and a social link to the second device user. In some embodiments, the highest activity (e.g., engagement) within a group may be used to assess whether a user may want to join the group. For example, the summary application may track the number of comments and likes received in response to an event occurring in the content. In yet another embodiment, the system may evaluate the terminology used in the group to determine if the user may want to join the group. For example, using technical terms that are not suitable for a novice may be identified. In still another embodiment, the system may evaluate the emotional tones of the group to determine if the user may want to join the group. In each case, the summary application considers the particular parameters, e.g., events, content, activity, technical terminology, and emotions, to identify the group and its characteristics. Such data is continuously tracked and updated to improve the weightage of each of the parameters.</p><p id="p-0034" num="0033">In some embodiments, the conversations in the group are analyzed to determine relevance to the event, group activity, technicality, emotions, etc., and are prioritized. For example, a group of friends who are consuming content together but are engaging with personal supplemental content not related to the content may not be desirable, while on the other hand, friends who provide supplemental content related to the content may be more desirable. In some embodiments, data from a social network may be accessed to determine the preferences of the users within the group. Each of the groups may be different based on the users within each group. In some embodiments, each user is associated with a user device concurrently consuming the content. The groups for the user to join with the second device may be based on user preferences. For example, the user may prefer to consume some content with college friends where video cameras <b>413</b> are employed to capture facial expressions. On the other hand, the user may prefer to engage with the users only based on chat for other groups.</p><p id="p-0035" num="0034">In some embodiments, the system may consider the information when evaluating the missed portion from the content (e.g., content <b>104</b>), including the supplemental content <b>111</b> (e.g., reactions, shared comments, etc.). Often content (e.g., movie, show, or sporting event) comprises one or more storylines, which are narratives that, along with other narratives, make up a plot. Portions of the content may correspond to various storylines. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the data structure evaluates each portion of the content to determine how to weigh each parameter based on user feedback. This indicates which missed portions the user may be interested in to catch up, upon joining the presentation. Content may contain contiguous reactions and feedback or may switch between several reactions and feedback. In some embodiments, the information describing the portions and reactions that make up a missed portion of the content may be stored in the content metadata. By analyzing the metadata, the summary application may be able to determine which portions and reactions viewer <b>142</b>, for example, missed based on the timepoints TP<sub>1 </sub>and TP<sub>2</sub>.</p><p id="p-0036" num="0035">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, viewer <b>142</b> has missed a first part of storyline A, a first part storyline B, and a second storyline A, and has arrived during a presentation of a second part of storyline B (denoted as SL-A, SL-B, and SL-A in <figref idref="DRAWINGS">FIG. <b>1</b></figref>). Similarly, the missed parts include the feedback received from other users in the group. The summary application determines a storyline-specific summary for viewer <b>142</b> when viewer <b>142</b> joins at timepoint TP<sub>2</sub>. The summary application may create a summary that includes a portion of the content and supplemental content associated with that portion that is necessary for viewer <b>142</b> to understand the content <b>104</b> and the engagement by other users at timepoint TP<sub>2 </sub>in the group. In other words, the summary application is generating content related to storyline B at timepoint TP<sub>2 </sub>and the reactions received. Therefore, the summary application can generate a summary relevant to the current content by summarizing the storyline B content that was missed by viewer <b>142</b> between timepoints TP<sub>1 </sub>and TP<sub>2</sub>. In some embodiments, the summary application may further include other portions of content <b>104</b> on which storyline B is dependent in the summary at timepoint TP<sub>2</sub>. The summary application may access the data structure in <figref idref="DRAWINGS">FIG. <b>2</b></figref> to determine which portions of storylines A and B to include in the summary based on dependency. In some embodiments, the summary application may summarize other missed portions of content <b>104</b> at a later point. In some embodiments, the summary application may summarize other missed portions of content <b>104</b> at the beginning and may present the supplemental content first. For example, the summary application may present a summary of the missed portions of shared content and reactions before playing the scene associated with the reactions. In another example, the summary application may present a summary of the missed portions of reaction at the end of the program, as there are no other sections of reaction after viewer <b>142</b> arrives.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example database of collected reactions for providing summaries of missed content from a concurrent presentation of content in a group on multiple devices, in accordance with some embodiments of the disclosure. The database includes information about users, events, actions (activity), a time stamp for each action, event ID, start and stop time of the event, and a score derived based on an algorithm, as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Often content comprises one or more reactions and shared commentary which are narratives of the discussion between users that, along with other narratives, makes up a plot of the discussion between multiple users. For example, missing part of a discussion between users may cause the subsequent discussion to be disconnected and hard to follow. The reaction to the content may correspond to various storylines. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the data structure assigns each event in a content item to a particular storyline ID (e.g., storylines A, B, and C). This indicates which portions are related to the same storyline (i.e., they make up the same narrative) and may lead to grouping of reactions from the user even when they are not in sequence. Content may contain contiguous storylines or may switch between several storylines. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, additional information in the data structure may include start and endpoints of each event, the reactions or shared comments received for the event and the time stamp when the reaction or shared comment is received. In some embodiments, a score is generated for each reaction to track the relevance of the reaction. For example, the more people that comment on a reaction or shared comment, the higher the score is. In some embodiments, the information describing the portions and storylines that make up content may be stored in the metadata of the content. By analyzing the metadata, the summary application may be able to determine which portions and storylines viewer <b>142</b> missed based on the timepoints TP<sub>1 </sub>and TP<sub>2</sub>.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts exemplary systems, servers and related hardware for generating summaries of missed content and reactions to the missed content based on simultaneously streaming content to multiple devices in a group, in accordance with some embodiments of the disclosure. A user may access content and the content interface application (and its display screens described above and below) from one or more of their user equipment devices. Each device may connect to the communication network where content may be transmitted, processed, and pushed out. <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a generalized embodiment of illustrative user equipment device <b>400</b>. More specific implementations of user equipment devices are discussed above in connection with <figref idref="DRAWINGS">FIG. <b>5</b></figref>. User equipment device <b>400</b> may receive content and data via input/output (I/O) path <b>416</b>. I/O path <b>416</b> may provide content (e.g., broadcast programming, on-demand programming, Internet content, content available over a local area network (LAN) or wide area network (WAN), and/or other content) and data to control circuitry <b>412</b>, which includes processing circuitry <b>410</b> and storage <b>414</b>. Control circuitry <b>412</b> may be used to send and receive commands, requests, and other suitable data using I/O path <b>416</b>.</p><p id="p-0039" num="0038">Control circuitry <b>412</b> may be based on any suitable processing circuitry such as processing circuitry <b>410</b>. As referred to herein, processing circuitry should be understood to mean circuitry based on one or more microprocessors, microcontrollers, digital signal processors, programmable logic devices, field-programmable gate arrays (FPGAs), application-specific integrated circuits (ASICs), etc., and may include a multi-core processor (e.g., dual-core, quad-core, hexa-core, or any suitable number of cores) or supercomputer. In some embodiments, processing circuitry may be distributed across multiple separate processors or processing units. In some embodiments, control circuitry <b>412</b> executes instructions for a content interface application stored in memory (i.e., storage <b>414</b>). Specifically, control circuitry <b>412</b> may be instructed by the user interface application to perform the functions discussed above and below. For example, the user interface application may provide instructions to control circuitry <b>412</b> to generate the video and audio content for display. In some implementations, any action performed by control circuitry <b>412</b> may be based on instructions received from the user interface application.</p><p id="p-0040" num="0039">In client/server-based embodiments, control circuitry <b>412</b> may include communications circuitry suitable for communicating with a content application server or other networks or servers. The instructions for carrying out the above-mentioned functionality may be stored on the content application server. Communications circuitry may include a cable modem, an integrated-services digital network (ISDN) modem, a digital subscriber line (DSL) modem, a telephone modem, Ethernet card, or a wireless modem for communications with other equipment, or any other suitable communications circuitry. Such communications may involve the Internet or any other suitable communications networks or paths (which are described in more detail in connection with <figref idref="DRAWINGS">FIG. <b>5</b></figref>). In some embodiments, an antenna <b>408</b> is provided in the user equipment device <b>400</b>. The antenna <b>408</b> may be used for communication with the network of antennas. In addition, communications circuitry may include circuitry that enables peer-to-peer communication of user equipment devices, or communication of user equipment devices in locations remote from each other (described in more detail below).</p><p id="p-0041" num="0040">Memory may be an electronic storage device provided as storage <b>414</b> that is part of control circuitry <b>412</b>. As referred to herein, the phrase &#x201c;electronic storage device&#x201d; or &#x201c;storage device&#x201d; should be understood to mean any device for storing electronic data, computer software, or firmware, such as random-access memory, read-only memory, hard drives, optical drives, digital video disc (DVD) recorders, compact disc (CD) recorders, BLU-RAY disc (BD) recorders, BLU-RAY 3D disc recorders, digital video recorders (DVR, sometimes called a personal video recorder, or PVR), solid state devices, quantum storage devices, gaming consoles, gaming media, or any other suitable fixed or removable storage devices, and/or any combination of the same. Storage <b>414</b> may be used to store various types of content described herein as well as content data and content application data that are described above. Nonvolatile memory may also be used (e.g., to launch a boot-up routine and other instructions). Cloud-based storage may be used to supplement storage <b>414</b> or instead of storage <b>414</b>.</p><p id="p-0042" num="0041">Control circuitry <b>412</b> may include video generating circuitry and tuning circuitry, such as one or more analog tuners, one or more MPEG-2 decoders or other digital decoding circuitry, high-definition tuners, or any other suitable tuning or video circuits or combinations of such circuits. Encoding circuitry (e.g., for converting over-the-air, analog, or digital signals to MPEG signals for storage) may also be provided. Control circuitry <b>412</b> may also include scaler circuitry for upconverting and down-converting content into the preferred output format of the user equipment device <b>400</b>. Control Circuitry <b>412</b> may also include digital-to-analog converter circuitry and analog-to-digital converter circuitry for converting between digital and analog signals. The tuning and encoding circuitry may be used by the user equipment device to receive and to display, play, or record content. In some embodiments, the control circuitry may include an HD antenna.</p><p id="p-0043" num="0042">In one embodiment, speakers <b>406</b> may be provided as integrated with other elements of user equipment device <b>400</b> or may be stand-alone units. The audio and other content displayed on display <b>404</b> may be played through speakers <b>406</b>. In some embodiments, the audio may be distributed to a receiver (not shown), which processes and outputs the audio via speakers <b>406</b>.</p><p id="p-0044" num="0043">In some embodiments, a sensor (not shown) is provided in the user equipment device <b>400</b>. The sensor may be used to monitor, identify, and determine user presence in the proximity of the user device. For example, the user interface application running on a user equipment device may receive status data from the sensor, servers, or any other equipment device indicating the status of the group watch party. In particular, a notification may be displayed on the user equipment device that a watch party started and that the user is missing out on the fun in the cousin's group.</p><p id="p-0045" num="0044">The user interface application may be implemented using any suitable architecture. For example, it may be a stand-alone application wholly implemented on user equipment device <b>400</b>. In such an approach, instructions of the application are stored locally (e.g., in storage <b>414</b>), and data for use by the application is downloaded on a periodic basis (e.g., from an out-of-band feed, from an Internet resource, or using another suitable approach). Control circuitry <b>412</b> may retrieve instructions of the application from storage <b>414</b> and process the instructions to generate any of the displays discussed herein. Based on the processed instructions, control circuitry <b>412</b> may determine what action to perform when input is received from input interface <b>402</b>. For example, the movement of a cursor on an audio user interface element may be indicated by the processed instructions when input interface <b>402</b> indicates that a user interface <b>118</b> was selected.</p><p id="p-0046" num="0045">In some embodiments, the user interface application is a client/server-based application. Data for use by a thick or thin client implemented on user equipment device <b>400</b> is retrieved on-demand and in collaboration with other devices from the first group by issuing requests to a server remote to the user equipment device <b>400</b>. In one example of a client/server-based content application, control circuitry <b>412</b> runs a web browser that interprets web pages provided by a remote server. For example, the remote server may store the instructions for the application in a storage device. The remote server may process the stored instructions using circuitry (e.g., control circuitry <b>412</b>) and generate the displays discussed above and below. The client device may receive the displays generated by the remote server and may display the content of the displays locally on user equipment device <b>400</b> that is synchronized with the content of the displays on other equipment devices <b>400</b> associated in the first group. This way, the processing of the instructions is performed remotely by the server while the resulting displays are provided locally on user equipment device <b>400</b>. User equipment device <b>400</b> may receive inputs from the user via input interface <b>402</b> and transmit those inputs to the remote server for processing and generating the corresponding displays. For example, user equipment device <b>400</b> may transmit, via antenna <b>408</b>, communication to the remote server, indicating that a user interface element was selected via input interface <b>402</b>. The remote server may process instructions in accordance with that input and generate a display of content identifiers associated with the selected user interface element as described in greater detail with reference to <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The generated display is then transmitted to user equipment device <b>400</b> for concurrent presentation to the user as well as to other members in the group watch.</p><p id="p-0047" num="0046">In some embodiments, the user interface application is downloaded and interpreted or otherwise run by an interpreter or virtual machine (run by control circuitry <b>412</b>). In some embodiments, the user interface application may be encoded in the ETV Binary Interchange Format (EBIF), received by control circuitry <b>412</b> as part of a suitable feed, and interpreted by a user agent running on control circuitry <b>412</b>. For example, the user interface application may be an EBIF application. In some embodiments, the user interface application may be defined by a series of JAVA-based files that are received and run by a local virtual machine or other suitable middleware executed by control circuitry <b>412</b>. In some of such embodiments (e.g., those employing MPEG-2 or other digital media encoding schemes), the user interface application may be, for example, encoded and transmitted in an MPEG-2 object carousel with the MPEG audio of a program.</p><p id="p-0048" num="0047">User equipment device <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> can be implemented in system <b>500</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref> as user media equipment <b>514</b>, computer equipment <b>518</b>, wireless user communications device <b>522</b> or any other type of user equipment suitable for accessing content, such as a non-portable gaming machine. For simplicity, these devices may be referred to herein collectively as user equipment or user equipment devices and may be substantially similar to user equipment devices described above. User equipment devices, on which a user interface application may be implemented, may function as stand-alone devices or may be part of a network of devices. Various network configurations of devices may be implemented and are discussed in more detail below.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts exemplary systems, servers and related hardware for providing summaries of multiple contents from group watching a concurrent presentation, in accordance with some embodiments of the disclosure. A user equipment device utilizing at least some of the system features described above in connection with <figref idref="DRAWINGS">FIG. <b>5</b></figref> may not be classified solely as user media equipment <b>514</b>, computer equipment <b>516</b>, or a wireless user communications device <b>522</b>. For example, user media equipment <b>514</b> may, like some computer equipment <b>516</b>, be Internet-enabled, allowing for access to Internet content, while wireless user computer equipment <b>522</b> may, like some user media equipment <b>514</b>, include a tuner allowing for access to media programming. The user interface application may have the same layout on various types of user equipment or may be tailored to the display capabilities of the user equipment. For example, on wireless user computer equipment <b>516</b>, the user interface application may be provided as a website accessed by a web browser. In another example, the user interface application may be scaled down for wireless user communications devices <b>522</b>.</p><p id="p-0050" num="0049">The user equipment devices may be coupled to communications network <b>510</b>. Communications network <b>510</b> may be one or more networks including the Internet, a mobile phone network, mobile voice or data network (e.g., a 4G, 5G or LTE network), cable network, public switched telephone network, or other types of communications network or combinations of communications networks.</p><p id="p-0051" num="0050">System <b>500</b> includes content source <b>502</b> and content reaction data source <b>504</b> coupled to communications network <b>510</b>. Communications with the content source <b>502</b> and the Content reaction data source <b>504</b> may be exchanged over one or more communications paths but are shown as a single path in <figref idref="DRAWINGS">FIG. <b>5</b></figref> to avoid overcomplicating the drawing. Although communications between sources <b>502</b> and <b>504</b> with user equipment devices <b>514</b>, <b>516</b>, and <b>522</b> are shown through communications network <b>510</b>, in some embodiments, sources <b>502</b> and <b>504</b> may communicate directly with user equipment devices <b>514</b>, <b>516</b>, and <b>522</b>.</p><p id="p-0052" num="0051">Content source <b>502</b> may include one or more types of content distribution equipment including a media distribution facility, satellite distribution facility, programming sources, intermediate distribution facilities and/or servers, Internet providers, on-demand media servers, and other content providers. Content reaction data source <b>504</b> may provide content data, such as shared comments and reactions from other viewers consuming the content as described above. Content reaction data source <b>504</b> may be provided to the user equipment devices using any suitable approach. In some embodiments, shared comments and reactions from Content reaction data source <b>504</b> may be provided to users' equipment using a client/server approach. For example, a user equipment device may pull content data from a server, or a server may present the content data to a user equipment device. Content reaction data source <b>504</b> may provide user equipment devices <b>514</b>, <b>516</b> and <b>522</b> the content reactions received from user equipment devices <b>514</b>, <b>516</b> and <b>522</b> or any other user devices including the interface application itself or software updates for the user interface application.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts an illustrative example of a device user interface application for selecting groups for content for concurrent presentation, in accordance with some embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a generalized embodiment of an illustrative system <b>600</b> in which a first group <b>601</b> of users is causing for presentation a content item on individual user devices, for example, the user equipment devices <b>102</b> and <b>108</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and the system <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> can be implemented. The presentation of the content on each device is synchronized. System <b>600</b> includes an array of user devices (e.g., first device) (e.g., <b>604</b><i>a</i>, <b>604</b><i>b</i>, etc.) causing for presentation the content item (e.g., <b>603</b><i>a</i>, <b>603</b><i>b</i>, etc.), with each content device configured to provide supplemental content (e.g., <b>602</b><i>a</i>, <b>602</b><i>b</i>, etc.). The user devices (e.g., first device <b>604</b><i>a</i>, <b>604</b><i>b</i>, etc.) may be coupled to storage device <b>606</b>, server <b>608</b> and a second user device <b>610</b> providing a selection to join the first group <b>601</b>. The second device <b>610</b> can communicate bidirectionally with other systems. Communications with the user devices (e.g., first device <b>604</b><i>a</i>, <b>604</b><i>b</i>, etc.) and storage device <b>606</b> may be exchanged over one or more communications paths but are shown as a single path in <figref idref="DRAWINGS">FIG. <b>6</b></figref> to avoid overcomplicating the drawing.</p><p id="p-0054" num="0053">The supplemental content (e.g., <b>602</b><i>a</i>, <b>602</b><i>b</i>, etc.) may be cataloged with time stamps based on the progress of the content item. The supplemental content <b>602</b> may be associated with the content items (e.g., <b>603</b><i>a</i>, <b>603</b><i>b</i>, etc.) received from the user devices (e.g., first device <b>604</b><i>a</i>, <b>604</b><i>b</i>, etc.) and delivered to the storage device <b>606</b>. The content items <b>603</b> and supplemental content <b>602</b> are connected to server <b>608</b> for processing for content item recognition and geographical origin determination. The content items <b>603</b> and supplemental content <b>602</b> are processed through automated content recognition. The automated content recognition can store, allocate based on content and process for presentation a summary based on the user via the second device missing the content items and supplemental content <b>602</b>. Server <b>608</b> may be a collection of servers connected to the storage device for improved processing. The second user device that joins the first group <b>601</b>, may include a user interface <b>612</b> and a summary application <b>614</b>, that communicates with the storage device <b>606</b>. All of the communication between the user devices <b>610</b> in the first group, servers and the second device joining the first group may be through one or more networks including the Internet, a mobile phone network, mobile voice or data network (e.g., a 4G, 5G or LTE network), or other types of communications network or combinations of communications networks.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts another illustrative example of a device user interface application for selecting groups for content for concurrent presentation, in accordance with some embodiments of the present disclosure. As discussed above, in some embodiments, a user of the second device may select a user interface application <b>702</b> via a user device <b>108</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) incorporated into or accompanying the user interface application <b>702</b>. The user interface application <b>702</b> may be inserted into an application on any user device in response to the user searching for a group watch party. Upon determining user preferences for a group watch party, the user interface application <b>702</b> may display content items <b>704</b>, <b>706</b>, <b>708</b>, <b>710</b> with options to select the group. In the illustrative example, the user device displays options to join one of group &#x201c;Bob, Sam Bert, Tom,&#x201d; group &#x201c;Office Champs,&#x201d; group &#x201c;Palo Alto Champs group&#x201d; and group &#x201c;College Buddies,&#x201d; as shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. As previously discussed, the groups may be arranged based on the preference of the user. In some embodiments, the user searches for groups based on the characteristics of the group. For example, the system provides a number of groups to join, a funny group or a group that includes superfans of a sports team. In some embodiments, the user may search for a group based on the specific content, for example, a particular football game.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart of a detailed illustrative process for providing determining the missed content from the group watching the concurrent presentation, in accordance with some embodiments of the disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in accordance with some embodiments, a process <b>800</b> may be executed by processing circuitry <b>410</b> (<figref idref="DRAWINGS">FIG. <b>4</b></figref>). It should be noted that process <b>800</b> or any step thereof could be performed on, or provided by, the system of <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref> or any of the devices shown in <figref idref="DRAWINGS">FIGS. <b>1</b>, <b>6</b> and <b>7</b></figref>. In addition, one or more of process <b>800</b> may be incorporated into or combined with one or more other steps described herein (e.g., incorporated into steps of processes <b>900</b>-<b>1200</b>). For example, process <b>800</b> may be executed by control circuitry <b>412</b> (<figref idref="DRAWINGS">FIG. <b>4</b></figref>) as instructed by a user interface application implemented on a user device in order to present a summary of the missed content item based on the user device joining the first group after the concurrent presentation has started. Also, one or more steps of process <b>800</b> may be incorporated into or combined with one or more steps of any other process or embodiment.</p><p id="p-0057" num="0056">As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, process <b>800</b> begins at step <b>802</b>. At step <b>804</b>, the summary application detects missed content containing a plurality of missed reactions and a plurality of portions of an event in the content. For example, the summary application may detect that a viewer (e.g., viewer or viewers <b>142</b> near user device <b>108</b>) is absent during a time period while user equipment <b>102</b> is presenting content (e.g., content <b>104</b>). The user is late to streaming the movie, show, or sporting event as part of a group. In some embodiments, the user joins the group late based on identifying the group after the concurrent presentation has started. In some embodiments, the summary application may detect a viewer's absence through the use of a camera <b>413</b> (e.g., as part of user equipment <b>400</b>), which tracks viewers' faces. As described above, the summary application may build and access an interaction log for each viewer. In some embodiments, the summary application may access this interaction log from a remote server, and one or more devices (e.g., user equipment devices <b>514</b> and <b>516</b>) may contribute to logging the viewer's interaction with content. Other techniques for determining whether a user has interacted with specific content and/or the level to which a user has interacted with specific content are described in greater detail in Agarwal et al. U.S. Patent Publ. No. 2016/0088352, published on Mar. 24, 2016, which is hereby incorporated by reference herein in its entirety. In some embodiments, the summary application may detect the viewer's presence through use of an additional user device (e.g., additional user device <b>144</b> or user equipment <b>514</b>). The control circuitry (e.g., control circuitry <b>412</b>) may detect the presence of the additional user device (e.g., through Bluetooth or Wi-Fi connectivity, GPS data, or another method). If the control circuitry detects that the additional user device has moved a certain distance away from a playback device (e.g., user equipment device <b>102</b>), the summary application may determine that the viewer is not currently consuming the media and therefore is missing portions of the content including shared commentary and reactions to scenes. In some embodiments, the summary application may receive direct user input indicating that one viewer is temporarily leaving the viewer area, is late to join the viewing area on their independent device and may receive additional input when the viewer returns or rejoins the group watch. The summary application may record all portions which the user equipment played while the viewer was absent in an interaction log for that viewer (e.g., viewer <b>142</b>). The summary application may consult the interaction log to determine that portions of the content the viewer has missed. The summary application may further consult a logic table (e.g., the table depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) and consult a data structure of user engagement (e.g., the data structure depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) to determine which storylines correspond to the portions that the viewer has missed. For example, the summary application may query the data structure using start and end times of the viewer's missed content, e.g., TP<sub>1 </sub>and TP<sub>2</sub>. Using the start and end times of the viewer's missed content, the query would identify rows from the data structure that coincide with the start and end times of the viewer's missed content. The data rows returned by this query would include users, events and actions for storylines in the missed content.</p><p id="p-0058" num="0057">At step <b>806</b>, the summary application determines whether a storyline of content is being generated for concurrent presentation. For example, the summary application may determine if the media content source <b>502</b> is providing content to user devices (e.g., user equipment <b>410</b>) and if control circuitry (e.g., control circuitry <b>412</b>) is causing the presentation of content on user device <b>102</b>. In some embodiments, the summary application may determine whether the content being generated for display on user equipment <b>102</b> contains part of a storyline. For example, some content may be output (e.g., commercials or advertisements) that is not part of a storyline in content. The summary application may determine whether the content is associated with a storyline by accessing metadata associated with the content being presented (e.g., metadata in a data table such as <figref idref="DRAWINGS">FIG. <b>2</b></figref>) and may determine that the current presentation of content has no associated storyline or has data in the data table indicating there is no storyline. If the summary application determines that a storyline of content is not being generated for presentation, process <b>800</b> continues at step <b>830</b>. If instead, the summary application determines that a storyline of content is being generated for presentation, process <b>800</b> continues at step <b>808</b>.</p><p id="p-0059" num="0058">At step <b>830</b>, the summary application waits for a storyline transition. This may entail control circuitry (e.g., control circuitry <b>412</b>) accessing a data structure such as the data table illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, identifying that a storyline has concluded and continuing to <b>802</b>. For example, the control circuitry may check metadata for the current content being presented to multiple devices as described above and then wait for a predetermined amount of time (e.g., 2 seconds) before checking whether the metadata has changed. Thus, the summary application may determine, based on the metadata in a data table (e.g., as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>), at what timepoint a storyline transition will occur if such a point is available. For a live program, for example, a sporting event, the summary application will need to decipher when a pause in the sporting event has occurred&#x2014;in some instance, a commercial. At the timepoint of the storyline transition, process <b>800</b> continues at steps <b>802</b> and <b>804</b> again. In some embodiments, the summary application may obtain metadata for the current portion to determine the current storyline and also retrieve metadata for the reactions received.</p><p id="p-0060" num="0059">At step <b>808</b>, the summary application identifies the storyline of portions where reactions have been received in the content generated for presentation. In some embodiments, the control circuitry may access metadata sent embedded in data files that comprise the content or in data files provided to the control circuitry in parallel with the content. In some embodiments, the control circuitry may access a data table (e.g., the data structure depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) to determine which storyline corresponds to the portion of the content that the user equipment <b>102</b> is currently generating, e.g., using time markers for the content.</p><p id="p-0061" num="0060">At step <b>810</b>, the summary application determines if a user (e.g., viewer <b>142</b>) has missed a portion of the storyline. The control circuitry (e.g., control circuitry <b>412</b>) may access a data structure (e.g., the data table depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>) to determine which portions and reactions of the content that the user equipment <b>102</b> has already presented correspond to the same storyline that the user equipment <b>102</b> is currently generating. The summary application may then compare the portions of the same storyline with an interaction log for the user via the second device to see if any of the portions of the same storyline are absent from the log, indicating that the user missed those portions. In some embodiments, an interaction log contains a list of content and portions thereof (e.g., by time stamp) and reactions received for the portions, along with a unique identifier for the user as depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Each row in such a log indicates portions of content the user missed based on a system of absence from the first group. If the summary application determines that the viewer has not missed any of the portions corresponding to the current storyline, then process <b>800</b> continues at step <b>830</b>. If, instead, the summary application determines that the viewer has missed one or more portions corresponding to the current storyline, then process <b>800</b> continues at step <b>812</b>.</p><p id="p-0062" num="0061">At step <b>812</b>, the summary application generates for the second device summaries of the missed content and the missed reactions based on preferences associated with the user profile. The control circuitry (e.g., control circuitry <b>412</b>) may identify the portion IDs for the portions of the storyline that the viewer has missed by accessing a data structure (e.g., the data structure depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The control circuitry may then retrieve summaries for the portions of the storyline in the missed content. In some embodiments, control circuitry generates the summary by highlighting the reactions and the content about which the reactions were received. For example, the summaries may include a display of the shared comment from the one or more first devices along with a short clip of the video during which the comment was received. The metadata for each portion of the content or the metadata for the reactions received may contain identifiers that are stored in a database (e.g., content source <b>502</b>), for the portions of the content about which a reaction was received. The reaction may be a comment, a like, or a video and audio including facial expressions in response to the scenes. The control circuitry may retrieve the reactions from the content source <b>502</b> and may transmit the reactions or summaries of the reactions to the summary application. For example, suppose multiple users provide similar comments: the algorithm may summarize and combine the comments into &#x201c;Jerry, Steve and Clara liked the gorilla, especially when this segment was playing.&#x201d; In that case, once the control circuitry has retrieved all the reactions and summaries for the portions of the storyline that the viewer has missed, the summary application may combine by splicing the portions together to generate a summary for the entirety of the missed content.</p><p id="p-0063" num="0062">At step <b>814</b>, the summary application causes for the presentation of the generated summary. The summary may comprise summaries for one or more portions of missed content. In some embodiments, the control circuitry (e.g., control circuitry <b>412</b>) may transmit the summary to a secondary user device (e.g., additional user device <b>144</b>, user equipment <b>514</b>, or user equipment <b>516</b>) via I/O path (e.g., I/O path <b>416</b>). In some embodiments, the summary application may display the summary on the same device on which it is displaying content <b>110</b> (e.g., user equipment <b>108</b>).</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of a detailed illustrative process for providing summaries of missed content from a group watch party, in accordance with some embodiments of the disclosure. At step <b>902</b>, the system identifies a plurality of groups for concurrent presentation of content. For example, the system searches for groups that the user is likely to join based on the user's preferences. In some embodiments, the system may identify the groups based on the user's request to search for a particular group, for example, relatives or friends. In some embodiments, the system may identify groups based on the content the user is looking to consume. The system may further narrow the groups to particular groups based on preferences inputted. In some embodiments, the system may access the metadata associated with the user's historical viewing history to determine the type of group the user prefers to consume content with. For example, the system tracks every group the user has joined in the past. The information is stored in a database including the location, time, date, type of content, other users and any other suitable information.</p><p id="p-0065" num="0064">At <b>904</b>, the system receives a selection via a second device to join a first group of the plurality of groups for the concurrent presentation of the content. In some embodiments, the system selects the group based on user preferences. In another example, the system may receive a selection via the second device to join a cousin's group watching a sporting event.</p><p id="p-0066" num="0065">At <b>906</b>, the system determines whether a user via the second device missed portions of the concurrent presentation of the content for the first group. In some embodiments, the summary application detects content missed by a user via the second device containing a plurality of missed reactions and a plurality of portions of an event in the content. For example, as the second device joins the show's presentation, movie or event, the system determines that the user is joining the group watch after the presentation has commenced. In some embodiments, the missed portion may be due to the user leaving the group and returning to the group. In some embodiments, based on the sensors on the user device, the system may detect that the device is streaming content from the group watch. In another embodiment, a camera may capture that the user is not in the vicinity of the user device. The system uses the start and end times of the viewer's missed content. The system would identify rows from the data structure that coincide with the start and end times of the viewer's missed content. If the system determines a user via a second device missed portions of the concurrent presentation of the content for the first group (&#x201c;Yes&#x201d; at <b>906</b>), then, at <b>908</b>, the system determines whether there were missed reactions. This occurs without the user's input. If, on the other hand, the system determines a user via a second device has not missed portions of the concurrent presentation of the content for the first group (&#x201c;No&#x201d; at <b>906</b>), then <b>902</b> may be repeated.</p><p id="p-0067" num="0066">At <b>910</b>, the system generates for the user via the second device summaries of the missed content including the missed reactions. The control circuitry (e.g., control circuitry <b>412</b>) may identify the portion IDs for the portions of the storyline that the viewer has missed by accessing a data structure (e.g., the data structure depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The control circuitry may then retrieve summaries for the portions of the storyline in the missed content. In some embodiments, control circuitry <b>412</b> generates the summary by highlighting the reactions and the content about which the reactions were received. For example, the summaries may include a display of the shared comments from one or more first devices along with a short clip of the video during which the comments were received.</p><p id="p-0068" num="0067">At <b>912</b>, the system causes the presentation of one or more summaries for the second device. The summary may include summaries for one or more portions of content and the reactions the user missed. In some embodiments, the control circuitry <b>412</b> (e.g., control circuitry <b>412</b>) may transmit the summary to a second user device (e.g., additional user device <b>144</b>, user equipment <b>514</b>, or user equipment <b>516</b>) via I/O path (e.g., I/O path <b>416</b>). In some embodiments, the summary application <b>614</b> may display the summary on the same device on which it is displaying content <b>110</b> (e.g., user equipment <b>108</b>).</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart of a detailed illustrative process for providing summaries of multiple content items based on user preferences, in accordance with some embodiments of the disclosure. Process <b>812</b>A is one embodiment of a method for performing step <b>812</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref> and begins after step <b>810</b>. At step <b>1002</b>, the summary application <b>614</b> accesses user preferences associated with the user profile. In some embodiments, the control circuitry <b>412</b> may access metadata sent embedded in data files that comprise the content or in data files provided to the control circuitry <b>412</b> in parallel with the content. The metadata may include user preferences based on the content for each portion. The control circuitry <b>412</b> may access a data structure (e.g., the data structure depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) and an interaction log for viewer B indicating which portions of the content viewer B consumed, both of which may be stored in a storage (e.g., storage <b>414</b>). At step <b>1004</b>, the summary application <b>614</b> retrieves metadata for the identified missed portion. In some embodiments, the summary application <b>614</b> may analyze the metadata to locate the field that comprises the missed portions. The system uses the start and end times of the viewer's missed content <b>110</b>. The system would identify rows from the data structure that coincide with the start and end times of the viewer's missed content <b>110</b>.</p><p id="p-0070" num="0069">At step <b>1006</b>, the summary application <b>614</b> extracts a reaction storyline from the retrieved metadata for the identified missed portion. For example, the control circuitry <b>412</b> identifies specific portions in the missed content. Each of the portions may also be associated with reactions received by the user in the first group. The control circuitry <b>412</b> may access a data structure (e.g., the data structure depicted in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) and an interaction log for viewer <b>142</b> indicating which portions of the content viewer <b>142</b> consumed, both of which may be stored in a storage (e.g., storage <b>414</b>). The summary application <b>614</b> may determine that portions that do not appear in the interaction log are missed portions of the content. The summary application <b>614</b> may further identify which portions, of the portions that do not appear in the interaction log, have a reaction (e.g., from the data structure of <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The summary application <b>614</b> may, using this information, identify missed portions with a reaction to generate for the user.</p><p id="p-0071" num="0070">At step <b>1008</b>, the summary application <b>614</b> combines the extracted reaction storyline in the missed portion to generate a storyline-specific summary of reactions for the missed portion. The summary application <b>614</b> may combine the reactions by creating a new file with the compiled reactions or summaries of the reactions. For example, the summary application <b>614</b> may retrieve metadata for each portion being summarized (e.g., as displayed in the data structure of <figref idref="DRAWINGS">FIG. <b>3</b></figref>). Using this information, the summary application <b>614</b> may determine a chronological order in which to display the reactions or reaction summaries. Additionally, or alternatively, the summary application <b>614</b> may order the reactions or reaction summaries according to other criteria. For example, the summary application <b>614</b> may (e.g., using control circuitry <b>412</b>) access metadata that describes how the portions are interconnected. The metadata may indicate that certain portions contain the same character, narrative, event, or some other component. The summary application <b>614</b> may then order the portion summaries according to portions that possess such similarities. The control circuitry may store the newly combined reactions or reaction summary in storage. The summary application <b>614</b> may transmit the portion summaries, in the correct order, to a queue on server <b>504</b> or directly to user equipment or display devices. Process <b>812</b>A then continues with step <b>814</b>, in which the summary application causes for presentation the one or more summaries for the second device.</p><p id="p-0072" num="0071">It is contemplated that the steps or descriptions of <figref idref="DRAWINGS">FIGS. <b>8</b>-<b>10</b></figref> may be used with any other embodiment of this disclosure. In addition, the steps and descriptions are described in relation to <figref idref="DRAWINGS">FIGS. <b>8</b>-<b>10</b></figref> may be done in alternative orders or in parallel to further the purposes of this disclosure. Any of these steps may also be skipped or omitted from the process. Furthermore, it should be noted that any of the devices or equipment discussed in relation to <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>5</b></figref> could be used to perform one or more of the steps in <figref idref="DRAWINGS">FIGS. <b>8</b>-<b>10</b></figref>.</p><p id="p-0073" num="0072">As used herein, &#x201c;a user interface application&#x201d; refers to a form of content through an interface that facilitates access to audio, music, news and podcast content on one or more display devices operating on any capable device. In some embodiments, the user interface application may be provided as an online application (i.e., provided on a website) or as a stand-alone application on a server, user device, etc. The user interface application may also communicate with an antenna array or telematics array to receive content via a network. Various devices and platforms that may implement the user interface application are described in more detail below. In some embodiments, the user interface application and/or any instructions for performing any of the embodiments discussed herein may be encoded on computer-readable media. Computer-readable media includes any media capable of storing instructions and/or data. The computer-readable media may be transitory, including, but not limited to, propagating electrical or electromagnetic signals, or may be non-transitory, including, but not limited to, volatile and nonvolatile computer memory or storage devices such as a hard disk, floppy disk, USB drive, DVD, CD, media card, register memory, processor caches, random access memory (RAM), etc.</p><p id="p-0074" num="0073">As referred to herein, the terms &#x201c;media asset&#x201d; and &#x201c;content&#x201d; should be understood to mean an electronically consumable user asset, such as television programming, as well as pay-per-view programs, on-demand programs (as in video-on-demand (VOD) systems), Internet content (e.g., streaming content, downloadable content, webcasts, etc.), a collection of episodes in a series, a single episode in a series, video clips, audio, content information, pictures, rotating images, documents, playlists, websites, articles, books, electronic books, blogs, advertisements, chat sessions, social media, chat rooms, applications, games, and/or any other media or multimedia and/or combination of the same. Guidance applications also allow users to navigate among and locate content. As referred to herein, the term &#x201c;multimedia&#x201d; should be understood to mean content that utilizes at least two different content forms described above, for example, text, audio, images, video, or interactivity content forms. Content may be recorded, played, displayed or accessed by user equipment devices, but can also be part of a live performance.</p><p id="p-0075" num="0074">As referred to herein, the phrase &#x201c;group watch&#x201d; or &#x201c;group watch party&#x201d; or &#x201c;concurrently presented to group watch party&#x201d; should be understood to mean two or more devices where the same content is streamed simultaneously their respective devices with the device's locations being remote from each other. For example, the first device presents a football game in New York, while the second device presents that same football game in Florida and simultaneously providing feedback via a chat room, a video conferencing software or any other means for providing reactions to the content. The intent of the group watch is to simulate the two users watching the football game together.</p><p id="p-0076" num="0075">As referred to herein, the phrase &#x201c;in response&#x201d; should be understood to mean automatically, directly and immediately as a result of, without further input from the user, or automatically based on the corresponding action where intervening inputs or actions may occur.</p><p id="p-0077" num="0076">The processes described above are intended to be illustrative and not limiting. One skilled in the art would appreciate that the steps of the processes discussed herein may be omitted, modified, combined, and/or rearranged, and any additional steps may be performed without departing from the scope of the invention. More generally, the above disclosure is meant to be exemplary and not limiting. Only the claims that follow are meant to set bounds as to what the present invention includes. Furthermore, it should be noted that the features and limitations described in any one example may be applied to any other example herein, and flowcharts or examples relating to one example may be combined with any other example in a suitable manner, done in different orders, or done in parallel. In addition, the systems and methods described herein may be performed in real time. It should also be noted that the systems and/or methods described above may be applied to, or used in accordance with, other systems and/or methods.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-01-40" num="01-40"><claim-text><b>1</b>-<b>40</b>. (canceled)</claim-text></claim><claim id="CLM-00041" num="00041"><claim-text><b>41</b>. A method comprising:<claim-text>receiving, from a first device, a selection to join a group of devices for a concurrent presentation of content; and</claim-text><claim-text>in response to receiving the selection;<claim-text>determining, for the first device, missed content from the concurrent presentation prior to joining of the first device, wherein the missed content comprises (i) content segments of the content and (ii) reactions transmitted by one or more devices of the group of devices;</claim-text><claim-text>generating a summary of the content segments and the reactions based on preferences associated with the first device; and</claim-text><claim-text>causing to be presented the summary for the first device.</claim-text></claim-text></claim-text></claim><claim id="CLM-00042" num="00042"><claim-text><b>42</b>. The method of <claim-ref idref="CLM-00041">claim 41</claim-ref>, wherein generating the summary based on the preferences comprises:<claim-text>accessing a data structure comprising a content parameter and a sampling criterion corresponding to the content parameter;</claim-text><claim-text>selecting the content segments and associated reactions based on the content parameter;</claim-text><claim-text>extracting preferred segment samples from the selected content segments and reactions that match the sampling criterion; and</claim-text><claim-text>generating the summary to include the preferred segment samples.</claim-text></claim-text></claim><claim id="CLM-00043" num="00043"><claim-text><b>43</b>. The method of <claim-ref idref="CLM-00041">claim 41</claim-ref>, wherein generating the summary comprises:<claim-text>accessing metadata that comprises a content storyline identifier for the content segments;</claim-text><claim-text>determining a reaction storyline associated with the content storyline identifier;</claim-text><claim-text>identifying a plurality of storyline-specific portions associated with the content storyline identifier or the reaction storyline; and</claim-text><claim-text>generating a storyline-specific summary for the plurality of storyline-specific portions.</claim-text></claim-text></claim><claim id="CLM-00044" num="00044"><claim-text><b>44</b>. The method of <claim-ref idref="CLM-00043">claim 43</claim-ref>, wherein generating the storyline-specific summary comprises:<claim-text>generating summaries corresponding to the plurality of storyline-specific portions; and</claim-text><claim-text>combining the summaries to generate the storyline-specific summary.</claim-text></claim-text></claim><claim id="CLM-00045" num="00045"><claim-text><b>45</b>. The method of <claim-ref idref="CLM-00041">claim 41</claim-ref>, wherein the concurrent presentation of content comprises a virtual presentation of the content on a plurality of devices.</claim-text></claim><claim id="CLM-00046" num="00046"><claim-text><b>46</b>. The method of <claim-ref idref="CLM-00041">claim 41</claim-ref>, further comprising:<claim-text>identifying user profiles corresponding to the group of devices;</claim-text><claim-text>accessing, from a social media database, metadata associated with the user profiles; and</claim-text><claim-text>generating, based on the metadata, an identifier indicating a social link between a first user profile and a second user profile of the user profiles.</claim-text></claim-text></claim><claim id="CLM-00047" num="00047"><claim-text><b>47</b>. The method of <claim-ref idref="CLM-00046">claim 46</claim-ref>, wherein a type of the social link comprises one or more of a parent, a sibling, a grandparent, a cousin, an uncle, an aunt, a child, a friend, and a coworker.</claim-text></claim><claim id="CLM-00048" num="00048"><claim-text><b>48</b>. The method of <claim-ref idref="CLM-00041">claim 41</claim-ref>, wherein the selection is received at a first time, the method further comprising:<claim-text>determining that the first device previously left the concurrent presentation at a second time; and</claim-text><claim-text>wherein the missed content for the first device was presented to the group between the second time and the first time.</claim-text></claim-text></claim><claim id="CLM-00049" num="00049"><claim-text><b>49</b>. The method of <claim-ref idref="CLM-00041">claim 41</claim-ref>, wherein causing to be presented the summary comprises:<claim-text>identifying a display associated with the first device, wherein the display is not presenting the content; and</claim-text><claim-text>directing the second display to present the summary.</claim-text></claim-text></claim><claim id="CLM-00050" num="00050"><claim-text><b>50</b>. The method of <claim-ref idref="CLM-00041">claim 41</claim-ref>, wherein the content comprises a sporting event, and wherein the summary comprises highlights from the sporting event and reactions from the one or more devices corresponding to the highlights.</claim-text></claim><claim id="CLM-00051" num="00051"><claim-text><b>51</b>. A system comprising:<claim-text>memory configured to store content for concurrent presentation; and</claim-text><claim-text>control circuitry configured to:<claim-text>receive, from a first device, a selection to join a group of devices for a concurrent presentation of content; and</claim-text><claim-text>in response to receiving the selection;<claim-text>determine, for the first device, missed content from the concurrent presentation prior to joining of the first device, wherein the missed content comprises (i) content segments of the content and (ii) reactions transmitted by one or more devices of the group of devices;</claim-text><claim-text>generate a summary of the content segments and the reactions based on preferences associated with the first device; and</claim-text><claim-text>cause to be presented the summary for the first device.</claim-text></claim-text></claim-text></claim-text></claim><claim id="CLM-00052" num="00052"><claim-text><b>52</b>. The system of <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the control circuitry, when generating the summary based on the preferences, is configured to:<claim-text>access a data structure comprising a content parameter and a sampling criterion corresponding to the content parameter;</claim-text><claim-text>select the content segments and associated reactions based on the content parameter;</claim-text><claim-text>extract preferred segment samples from the selected content segments and reactions that match the sampling criterion; and</claim-text><claim-text>generate the summary to include the preferred segment samples.</claim-text></claim-text></claim><claim id="CLM-00053" num="00053"><claim-text><b>53</b>. The system of <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the control circuitry, when generating the summary, is configured to:<claim-text>access metadata that comprises a content storyline identifier for the content segments;</claim-text><claim-text>determine a reaction storyline associated with the content storyline identifier;</claim-text><claim-text>identify a plurality of storyline-specific portions associated with the content storyline identifier or the reaction storyline; and</claim-text><claim-text>generate a storyline-specific summary for the plurality of storyline-specific portions.</claim-text></claim-text></claim><claim id="CLM-00054" num="00054"><claim-text><b>54</b>. The system of <claim-ref idref="CLM-00053">claim 53</claim-ref>, wherein the control circuitry, when generating the storyline-specific summary, is configured to:<claim-text>generate summaries corresponding to the plurality of storyline-specific portions; and</claim-text><claim-text>combine the summaries to generate the storyline-specific summary.</claim-text></claim-text></claim><claim id="CLM-00055" num="00055"><claim-text><b>55</b>. The system of <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the concurrent presentation of content comprises a virtual presentation of the content on a plurality of devices.</claim-text></claim><claim id="CLM-00056" num="00056"><claim-text><b>56</b>. The system of <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the control circuitry is further configured to:<claim-text>identify user profiles corresponding to the group of devices;</claim-text><claim-text>access, from a social media database, metadata associated with the user profiles; and</claim-text><claim-text>generate, based on the metadata, an identifier indicating a social link between a first user profile and a second user profile of the user profiles.</claim-text></claim-text></claim><claim id="CLM-00057" num="00057"><claim-text><b>57</b>. The system of <claim-ref idref="CLM-00056">claim 56</claim-ref>, wherein a type of the social link comprises one or more of a parent, a sibling, a grandparent, a cousin, an uncle, an aunt, a child, a friend, and a coworker.</claim-text></claim><claim id="CLM-00058" num="00058"><claim-text><b>58</b>. The system of <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the selection is received at a first time, and wherein the control circuitry is further configured to:<claim-text>determine that the first device previously left the concurrent presentation at a second time; and</claim-text><claim-text>wherein the missed content for the first device was presented to the group between the second time and the first time.</claim-text></claim-text></claim><claim id="CLM-00059" num="00059"><claim-text><b>59</b>. The system of <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the control circuitry, when causing to be presented the summary, is configured to:<claim-text>identify a display associated with the first device, wherein the display is not presenting the content; and</claim-text><claim-text>direct the second display to present the summary.</claim-text></claim-text></claim><claim id="CLM-00060" num="00060"><claim-text><b>60</b>. The system of <claim-ref idref="CLM-00051">claim 51</claim-ref>, wherein the content comprises a sporting event, and wherein the summary comprises highlights from the sporting event and reactions from the one or more devices corresponding to the highlights.</claim-text></claim></claims></us-patent-application>
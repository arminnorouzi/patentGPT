<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003761A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003761</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17849772</doc-number><date>20220627</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>21182764.7</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>P</subclass><main-group>15</main-group><subgroup>18</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>11</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>P</subclass><main-group>15</main-group><subgroup>18</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>011</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>1114</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>2562</main-group><subgroup>0219</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">BODY POSITION DETECTION</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>KONINKLIJKE PHILIPS N.V.</orgname><address><city>Eindhoven</city><country>NL</country></address></addressbook><residence><country>NL</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>ZEINSTRA</last-name><first-name>Michiel Hans</first-name><address><city>BLAUWHUIS</city><country>NL</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>BREMER</last-name><first-name>Petrus Johannes</first-name><address><city>DRACHTEN</city><country>NL</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>BEUTICK</last-name><first-name>Jeroen</first-name><address><city>ZWOLLE</city><country>NL</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>VAN DER SCHOOT</last-name><first-name>Frank</first-name><address><city>EINDHOVEN</city><country>NL</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present invention relates to body position detection. In order to improve body position detection, a computer-implemented method is provided that comprises the steps of:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">a) receiving (210) accelerometer data from an accelerometer mounted on a user,</li></ul></p><p id="p-0002" num="0000">wherein the received accelerometer data comprises three acceleration components including a first acceleration component in a first axis direction, a second acceleration component in a second axis direction substantially perpendicular to the first axis direction, and a third acceleration component in a third axis direction substantially perpendicular to a plane formed by the first and second axes; and</p><p id="p-0003" num="0000">wherein the first axis direction is parallel to a frontal axis of the user, the second axis direction is parallel to a longitudinal axis of the user, and the third axis direction is parallel to a sagittal axis of the user;<ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0000">b) determining (220), based on the received accelerometer data, at least one body position based on a comparison between an absolute value of a projection of a gravity vector on a plane formed by two of the first, second, and third axes and an absolute value of an acceleration component in a remaining axis direction.</li></ul></p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="91.95mm" wi="158.75mm" file="US20230003761A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="205.23mm" wi="133.77mm" orientation="landscape" file="US20230003761A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="203.37mm" wi="125.14mm" orientation="landscape" file="US20230003761A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="205.23mm" wi="128.19mm" file="US20230003761A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="216.49mm" wi="146.47mm" file="US20230003761A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="217.76mm" wi="148.67mm" file="US20230003761A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="240.03mm" wi="120.06mm" file="US20230003761A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="179.75mm" wi="151.98mm" file="US20230003761A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD OF THE INVENTION</heading><p id="p-0004" num="0001">The present invention relates to body position detection. In particular, the present invention relates to a computer-implemented method and an apparatus for body position detection, to a body detection system, to a computer program product, and to a computer-readable data carrier.</p><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0005" num="0002">Accelerometers are often used to calculate a tilt angle. They can only do this reliably when they are static and not moving. Trigonometry calculations are often used to obtain the angle from the raw values from trigonometry calculations and matrix operations. These calculations typically require sinus, cosine, and/or tangent calculations and complex matrix operations, which usually require relatively high processing power.</p><heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0006" num="0003">There may be a need to provide an improved body position detection method and device.</p><p id="p-0007" num="0004">The object of the present invention is solved by the subject-matter of the independent claims. Further embodiments and advantages of the invention are incorporated in the dependent claims. Furthermore, it shall be noted that all embodiments of the present invention concerning a computer-implemented method might be carried out with the order of the steps as described, nevertheless this has not to be the only and essential order of the steps of the method as presented herein. The computer-implemented method disclosed herein can be carried out with another order of the disclosed steps without departing from the respective method embodiment, unless explicitly mentioned to the contrary hereinafter.</p><p id="p-0008" num="0005">Technical terms are used by their common sense. If a specific meaning is conveyed to certain terms, definitions of terms will be given in the following in the context of which the terms are used.</p><p id="p-0009" num="0006">According to a first aspect of the present invention, there is provided a computer-implemented method for body position detection, comprising the steps of:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0007">a) receiving accelerometer data from an accelerometer mounted on a user,</li></ul></p><p id="p-0010" num="0008">wherein the received accelerometer data comprises three acceleration components including a first acceleration component in a first axis direction, a second acceleration component in a second axis direction substantially perpendicular to the first axis direction, and a third acceleration component in a third axis direction substantially perpendicular to a plane formed by the first and second axes; and</p><p id="p-0011" num="0009">wherein the first axis direction is parallel to a frontal axis of the user, the second axis direction is parallel to a longitudinal axis of the user, and the third axis direction is parallel to a sagittal axis of the user;<ul id="ul0004" list-style="none">    <li id="ul0004-0001" num="0010">b) determining, based on the received accelerometer data, at least one body position based on a comparison between an absolute value of a projection of a gravity vector on a plane formed by two of the first, second, and third axes and an absolute value of an acceleration component in a remaining axis direction.</li></ul></p><p id="p-0012" num="0011">The inventors of the present disclosure have found out that trigonometry calculations and complex matrix operations require a relatively high calculation effort by a microcontroller. The inventors of the present disclosure have also found out that detecting the body position based on the projected length of the gravity on another vector of the accelerometer coordinate system may cause position detection issues when the accelerometer coordinate system is tilted.</p><p id="p-0013" num="0012">Towards this end, a computer-implemented method is proposed that detects at least one body position by the use of an accelerometer by means of comparing an absolute value of a projection of a gravity vector on a plane with an absolute value of the other axis. In some examples, certain body positions may be determined by comparing absolute values of two of the three acceleration components, and/or determining a sign of a value of one of the three acceleration components. By this approach, no trigonometry functions are required. This approach may reduce the calculation power compared with conventional trigonometry functions, in particular for position detection when the accelerometer coordinate system is tilted.</p><p id="p-0014" num="0013">According to an embodiment of the present invention, the body position comprises a sleeping position and a non-sleeping position. Step b) further comprises the step of determining whether the user is in a sleeping position or in a non-sleeping position based on a comparison between an absolute value of the projection of the gravity vector on the plane formed by the first and third axis directions and an absolute value of the second acceleration component.</p><p id="p-0015" num="0014">In other words, in order to detect that a user is going from any sleeping position to a non-sleeping position, the value of the plane is compared with the value of the other axis. For example in sleeping position, the vector &#x221a;{square root over (A<sub>x</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)} will be equal to 1 G, independent if the user is in a supine, prone, left, or right position. The second acceleration component A<sub>y </sub>will be zero, since this axis is horizontal with respect to the earth. When the user goes to standing, the vector &#x221a;{square root over (A<sub>x</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)} will decrease and the absolute value of A<sub>y </sub>will increase. A toggle moment may be defined by means of a threshold, for example when |A<sub>y</sub>|&#x3e;&#x221a;{square root over (A<sub>x</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)}, which is at 45&#xb0;.</p><p id="p-0016" num="0015">According to an embodiment of the present invention, the absolute value of the second acceleration component is multiplied by a tangent of a desired angle for the comparison. In order to remain flexible on the angle of toggling, it is also proposed to multiply the threshold by the tangent of a desired angle. This will be explained hereafter and in particular with respect to the embodiment shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0017" num="0016">According to an embodiment of the present invention, when it is determined that the user is in a non-sleeping position, the method further comprises the step of determining, based on a sign of a value of the second acceleration component, whether the user is in a standing or an upside-down position.</p><p id="p-0018" num="0017">In other words, in order to distinguish between upside down and standing positions, the system can look at the value of the y-axis. When A<sub>y </sub>is positive, the user is in a standing position and when A<sub>y </sub>is negative, the user is in an upside-down position. This will be explained hereafter and in particular with respect to the embodiment shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0019" num="0018">According to an embodiment of the present invention, when it is determined that the user is in a sleeping position, the method further comprises the step of determining whether the user is in a flat position or in a side position based on (i) a comparison between an absolute value of the third acceleration component with an absolute value of the first acceleration component, or (ii) a comparison between an absolute value of a projection of a gravity vector on a plane formed by the second and third axes and an absolute value of the first acceleration component.</p><p id="p-0020" num="0019">This will be explained hereafter and in particular with respect to the embodiments shown in <figref idref="DRAWINGS">FIGS. <b>8</b> and <b>9</b></figref>.</p><p id="p-0021" num="0020">According to an embodiment of the present invention, the absolute value of the first acceleration component is multiplied by a tangent of a desired angle for the comparison.</p><p id="p-0022" num="0021">This will be explained hereafter and in particular with respect to the embodiment shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0023" num="0022">According to an embodiment of the present invention, when it is determined that the user is in a side position, the method further comprises the step of determining, based on a sign of a value of the first acceleration component, whether the user is in a left or right position.</p><p id="p-0024" num="0023">This will be explained hereafter and in particular with respect to the embodiment shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0025" num="0024">According to an embodiment of the present invention, when it is determined that the user is in a flat position, the method further comprises the step of determining, based on a sign of a value of the third acceleration component, whether the user is in a supine or prone position.</p><p id="p-0026" num="0025">This will be explained hereafter and in particular with respect to the embodiment shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>.</p><p id="p-0027" num="0026">According to an embodiment of the present invention, the method further comprises the steps of detecting, based on the received accelerometer data, a movement of the user, and determining the body position of the user using an unfiltered value of the three acceleration components, if the movement is below a pre-defined threshold.</p><p id="p-0028" num="0027">The inventors of the present disclosure have found out that moving from one sleeping position to an opposite sleeping position (180&#xb0;)within quickly may cause a wrong position detection when filtering (or averaging) of samples is applied. For example, rotating device from position &#x2018;supine&#x2019; to position &#x2018;prone&#x2019; within 1 second may cause a wrong position detection and a side position could be signalled to the system.</p><p id="p-0029" num="0028">To prevent false position detection by filtering, movement detection is applied instead of filtering. When movement is below a threshold, new position is calculated based on unfiltered values. This will be explained hereafter and in particular with respect to the embodiments shown in <figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref>.</p><p id="p-0030" num="0029">According to an embodiment of the present invention, the detection of the movement of the user further comprises the steps of calculating a resultant vector of the three acceleration components, and determining that the user is moving when the resultant vector exceeds a moving threshold.</p><p id="p-0031" num="0030">According to an embodiment of the present invention, the detection of the movement of the user further comprises the steps of calculating an average of a plurality of consecutive samples that are within a certain range of a moving average for each of the three acceleration components, calculating, for each sample, a difference between a sample value of the respective sample and the average, and determining that the user is moving when one or more sample values exceed a threshold from the moving average.</p><p id="p-0032" num="0031">This will be explained hereafter and in particular with respect to the embodiments shown in <figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref>.</p><p id="p-0033" num="0032">According to a second aspect of the present invention, there is provided an apparatus comprising a communications module configured to receive accelerometer data from an accelerometer mounted on a user, and a processing unit configured to perform the steps of the method according to the first aspect and any associated example.</p><p id="p-0034" num="0033">According to a third aspect of the present invention, there is provided a body position detection system, which comprises an accelerometer mountable on a user, and a data processing apparatus according to the second aspect and any associated example.</p><p id="p-0035" num="0034">According to a further aspect of the present invention, there is provided a computer program product comprising instructions instructions to cause the apparatus of the second aspect or the body position detection system of the third aspect to execute the steps of the method according to the first aspect and any associated example.</p><p id="p-0036" num="0035">According to another aspect of the present invention, there is provided a computer-readable data carrier having stored thereon the computer program product.</p><p id="p-0037" num="0036">It should be appreciated that all combinations of the foregoing concepts and additional concepts discussed in greater detail below (provided such concepts are not mutually inconsistent) are contemplated as being part of the inventive subject matter disclosed herein. In particular, all combinations of claimed subject matter appearing at the end of this disclosure are contemplated as being part of the inventive subject matter disclosed herein.</p><p id="p-0038" num="0037">These and other aspects of the invention will be apparent from and elucidated with reference to the embodiment(s) described hereinafter.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0039" num="0038">In the drawings, like reference characters generally refer to the same parts throughout the different views. Also, the drawings are not necessarily to scale, emphasis instead generally being placed upon illustrating the principles of the invention.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a block diagram of an exemplary apparatus for body position detection.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an alternate embodiment of an apparatus.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a flow chart describing a computer-implemented method for body position detection.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> show a coordinate system, as may be defined by an accelerometer-based device.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows various sleeping positions.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the detection of the sleeping and non-sleeping positions.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows the detection of standing and upside down positions.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a cross section of a user in an &#x2018;ideal&#x2019; supine position. The middle picture shows a situation where the user is tilted 30&#xb0;. The right picture shows the compensation of the tilting by using vector &#x221a;{square root over (A<sub>x</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)} for determination between flat and side positions instead of using vector A<sub>z </sub>only.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the detection of flat and side positions.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows the detection of left and right positions.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows the detection of standing and upside down positions.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows a full position detection.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows a typical movement within 1 second from supine to prone in case averaging of samples is applied, in accordance with the prior art.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows a representation of the second movement detection.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION OF THE EMBODIMENTS</heading><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram of an exemplary apparatus <b>10</b> for body position detection, in accordance with an embodiment. The apparatus <b>10</b> may receive accelerometer data from an accelerometer <b>20</b>. The apparatus <b>10</b> and the accelerometer <b>20</b> form a body position detection system <b>100</b>.</p><p id="p-0055" num="0054">The apparatus <b>10</b> may include one or more processing units <b>12</b>. Optionally, as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the apparatus <b>10</b> may include a memory <b>14</b>, one or more communications modules <b>16</b>, and one or more applications <b>18</b>.</p><p id="p-0056" num="0055">In general, the apparatus <b>10</b> may comprise various physical and/or logical components for communicating and manipulating information, which may be implemented as hardware components (e.g., computing devices, processors, logic devices), executable computer program instructions (e.g., firmware, software) to be executed by various hardware components, or any combination thereof, as desired for a given set of design parameters or performance constraints. Although <figref idref="DRAWINGS">FIG. <b>1</b></figref> may show a limited number of components by way of example, it can be appreciated that a greater or a fewer number of components may be employed for a given implementation.</p><p id="p-0057" num="0056">In some examples, the apparatus <b>10</b> may be implemented by a computing platform such as a mobile platform, personal computer (PC) platform, and/or consumer electronics (CE) platform supporting various networking, communications, and/or multimedia capabilities. Such capabilities may be supported by various networks, such as a Wide Area Network (WAN), Local Area Network (LAN), Metropolitan Area Network (MAN), wireless WAN (WWAN), wireless LAN (WLAN), wireless MAN (WMAN), wireless personal area network (WPAN), Worldwide Interoperability for Microwave Access (WiMAX) network, broadband wireless access (BWA) network, the Internet, and/or any other wired or wireless network in accordance with the described embodiments.</p><p id="p-0058" num="0057">In some implementations, the apparatus <b>10</b> may comprise a system within and/or coupled to a computing device such as PC, desktop PC, notebook PC, laptop computer, mobile internet device (MID), mobile computing device, smart phone, personal digital assistant (PDA), mobile telephone, or other type of computing device in accordance with the described embodiments. The computing device may include, for example, an electronic display.</p><p id="p-0059" num="0058">In some implementations, the apparatus <b>10</b> may be implemented as a sleep position trainer. This sleep position trainer prevents the user sleeping in a predefined position by detection of that position and provide the user feedback. The feedback can be a mechanical actuator, a lighting indication or any other indication that stimulates the user to turn into another sleeping position. The detection of the sleep position and the actuator can be in separate devices connected by any kind of connection system (for example a wireless network).</p><p id="p-0060" num="0059">Returning to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the processing unit(s) <b>12</b> may execute instructions to perform the method described herein, which will be explained in detail with respect to the embodiment shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0061" num="0060">The memory <b>14</b> may include, but is not limited to, volatile memory and/or non-volatile memory. The memory <b>14</b> may be used to store body positions, processor instructions, and other data and instructions to enable the processor to perform the techniques described herein.</p><p id="p-0062" num="0061">The one or more communications modules <b>16</b> may include hardware and/or software to enable the apparatus <b>10</b> to receive data from the accelerometer <b>20</b>, and to communicate with other devices and/or a network. For example, the one or more communications modules <b>16</b> may receive accelerometer data via a wired connection or via a wireless connection. The one or more communications modules <b>16</b> may also provide cellular telephone communications, and/or other data communications for the apparatus <b>10</b>.</p><p id="p-0063" num="0062">The one or more applications <b>18</b> may include various software and/or hardware-based applications that provide functionality to the apparatus <b>10</b>. The one or more applications <b>16</b> may include an application that orients the accelerometer data. The one or more applications <b>16</b> may include, for example, cellular telephone applications, messaging applications, health and fitness applications, etc.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an alternate embodiment of an apparatus <b>10</b>, where the accelerometer <b>20</b> is included within apparatus <b>10</b>. The apparatus <b>10</b> may be substantially functionally equivalent to the system illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a flow chart describing a computer-implemented method <b>200</b> for body position detection, in accordance with an embodiment. Beginning at block <b>210</b> i.e. step a), an apparatus, such as apparatus <b>10</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> or in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, may receive accelerometer data from an accelerometer mounted on a user in block <b>120</b>. The accelerometer may be e.g. a waist-mounted accelerometer, a head-mounted accelerometer, a chest-mounted accelerometer, etc. As discussed above, the accelerometer may be separate from the apparatus, or a component of the apparatus.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> illustrate a coordinate system, as may be defined by an accelerometer-based device. The reference coordinates may define a first axis direction X, a second axis direction Y, and a third axis direction Z. In particular, the first axis direction X is parallel to a frontal axis of a user the second axis direction Y is parallel to a longitudinal axis of the user, and the third axis direction Z is parallel to a sagittal axis of the user. Thus, the received accelerometer data comprises three acceleration components including a first acceleration component A<sub>x </sub>in the first axis direction X, a second acceleration component A<sub>y </sub>in the second axis direction Y, and a third acceleration component A<sub>z </sub>in the third axis direction Z. Embodiments may rotate the observed coordinate system to the above-described reference coordinate system, such that the body position detection algorithm can have a consistent frame of reference.</p><p id="p-0067" num="0066">Turning back to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, at block <b>220</b>, the apparatus processes the received accelerometer data and determines at least one body position based on a comparison between an absolute value of a projection of a gravity vector on a plane formed by two of the first, second, and third axes and an absolute value of an acceleration component in a remaining axis direction. Some body positions may be determined based on a comparison between absolute values of two of the three acceleration components and/or a sign of a value of one of the three acceleration components.</p><p id="p-0068" num="0067">Thus, the body position of a user can be calculated by a simple algorithm. The simple algorithm does not require trigonometric calculations and can be applied to small low power micro controllers without using floating-point. Furthermore, the length of the gravity vector as projected on a plane instead on its perpendicular vector to prevent position detection issues with a tilted accelerometer coordinate system.</p><p id="p-0069" num="0068">In the following, processing methods for determining the body position will be elucidated.</p><p id="p-0070" num="0069">Since one needs to know in which sleeping position the user is, the number of positions is limited. Sleeping positions can be defined as supine, prone, left and right. Besides this, also non-sleep positions can be determined, such as standing and upside down.</p><p id="p-0071" num="0070">Sleeping vs Non-Sleeping Position</p><p id="p-0072" num="0071">The sleeping position can be detected by the projection of the gravity vector on the plane formed by the first and third axis directions, i.e. both x-axis and z-axis. <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a cross section of a user in a supine position. When the user is turning around in the bed, the vector &#x221a;{square root over (A<sub>x</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)} will remain equal to 1 G (in stable position, exactly at flat level). It does not matter in which position the user is lying on the bed (e.g. supine, side, or prone) because the vector &#x221a;{square root over (A<sub>x</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)} will be 1 G is all cases.</p><p id="p-0073" num="0072">When the user is going to stand up, i.e. in a non-sleeping position, the vector &#x221a;{square root over (A<sub>x</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)} will decrease to zero because both the x-axis and the z-axis will become parallel to the earth and the acceleration component in the y-axis will increase from 0 to 1 G.</p><p id="p-0074" num="0073">Since an accelerometer has tolerance and may not be calibrated in production, it may be risky to use fixed thresholds. Instead of fixed thresholds, it may be beneficial to use the axis excluded in the vector; in this example the |A<sub>y</sub>|. So when the |A<sub>y</sub>| becomes &#x3e;vector &#x221a;{square root over (A<sub>x</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)}, the user is supposed to be in a non-sleeping position. When the |A<sub>y</sub>| is lower, the user is considered to be in a sleeping position. Toggle moment will be at 45&#xb0;.</p><p id="p-0075" num="0074">In order to remain flexible on the angle of toggling, the threshold may be multiplied based on the y-axis by the tangent of a desired angle. For example, <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an exemplary algorithm when using 40&#xb0; and 50&#xb0; as hysteretic toggle angles for going from sleep to non-sleep position and back. In this example, &#x3bb;1=tan(50&#xb0;) and &#x3bb;2=tan(40&#xb0;).</p><p id="p-0076" num="0075">Standing vs Upside Down Position</p><p id="p-0077" num="0076">When the user is in a non-sleeping position, two variants are possible: standing and upside down. In order to distinguish between upside down and standing positions, the system can look at the value of the second acceleration component A<sub>y </sub>in the second axis direction Y. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, when the A<sub>y </sub>is positive, the user is standing and when the A<sub>y </sub>is negative, the user is upside down.</p><p id="p-0078" num="0077">Flat vs Side Position</p><p id="p-0079" num="0078">Flat position (supine or prone) and side position (left or right) may be detected by one axis only, for example z-axis. The left image of <figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an &#x2018;ideal&#x2019; supine situation. In this case, the absolute value of the third acceleration component A<sub>z </sub>will show the maximum value and the first acceleration component A<sub>x </sub>is zero.</p><p id="p-0080" num="0079">However, in some situations, the user may be tilted up to 30&#xb0; in a horizontal position. In this case, the absolute value of the third acceleration component A<sub>z </sub>will already be decreased in that situation as can be seen in the middle picture of <figref idref="DRAWINGS">FIG. <b>8</b></figref>. To compensate for that, the vector &#x221a;{square root over (A<sub>y</sub><sup>2</sup>+A<sub>z</sub><sup>2</sup>)} can be used as shown in the right picture of <figref idref="DRAWINGS">FIG. <b>8</b></figref> to compare with vector A<sub>x</sub>.</p><p id="p-0081" num="0080">In order to remain flexible on the angle of toggling, the threshold may also be multiplied based on the first acceleration component A<sub>x </sub>in the x-axis by the tangent of a desired angle. For example, <figref idref="DRAWINGS">FIG. <b>9</b></figref> shows the algorithm when using 40&#xb0; and 50&#xb0; as hysteretic toggle angles for going from sleep to non-sleep position and back. In this example, &#x3bb;1=tan(50&#xb0;) and &#x3bb;2=tan(40&#xb0;).</p><p id="p-0082" num="0081">Left vs Right Position</p><p id="p-0083" num="0082">When the user is in a side position, two variants are possible: left and right. In order to distinguish between left and right positions, the system can look at the value of the first acceleration component A<sub>x</sub>. As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, when A<sub>x </sub>is positive, the user is in a right position. When A<sub>x </sub>is negative, the user is in a left position.</p><p id="p-0084" num="0083">Supine vs Prone Position</p><p id="p-0085" num="0084">When the user is in a flat position, two variants are possible: supine and prone. In order to distinguish between supine and prone positions, the system can look at the value of the third acceleration component A<sub>z</sub>. As shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, when A<sub>z </sub>is positive, the user is in a supine position, and when A<sub>z </sub>is negative, the user is in a prone position.</p><p id="p-0086" num="0085">Full Position Detection</p><p id="p-0087" num="0086">The above-discussed position detections may be combined to give a total algorithm as shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. In the example shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the first priority is set to the detection of sleeping and non-sleeping positions. The second priority is set to the detection of flat and side positions. The last priority is to determine within the three main positions the direction by the sign of a value of one of the three acceleration components.</p><p id="p-0088" num="0087">Movement Detection</p><p id="p-0089" num="0088">During the testing, the inventors of the present disclosure have discovered that moving from one sleeping position to an opposite position (180&#xb0;) within 1 second may cause a wrong position detection in case averaging of samples is applied which is intentionally not done in the disclosure. For example, as shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, rotating device from position &#x2018;supine&#x2019; to position &#x2018;prone&#x2019; within 1 second may cause a wrong position detection and standing position could be signalled to the system. Typical movement (e.g. within about 1 second) from supine to prone may produce the following averaging buffer of the z-axis data (A<sub>z</sub>). Even if at the final time of the movement the physical position is &#x2018;prone&#x2019; (&#x2212;63) the averaged value used for position calculation is &#x2212;1 that stands &#x2018;right&#x2019;. The buffer will soon fill-up with the correct values (&#x2212;63) and the momentary averaged value will also stabilize at &#x2212;63 that will give a valid &#x2018;prone&#x2019; position.</p><p id="p-0090" num="0089">In order to solve the above-identified problem, instead of filtering, movement detection is applied. This may prevent the system from calculation with artificial numbers causing a wrong position detection.</p><p id="p-0091" num="0090">The first movement detection may be based on the fact that the resulting vector of all axes should be 1 G when in stable position. The resulting vector can be calculated with:</p><p id="p-0092" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>&#x221a;{square root over (<i>A</i><sub>x</sub><sup>2</sup><i>+A</i><sub>y</sub><sup>2</sup><i>A</i><sub>z</sub><sup>2</sup>)}<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0093" num="0000">Movement may be defined when the resulting vector exceeds a threshold, such as:</p><p id="p-0094" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>|&#x221a;{square root over (<i>A</i><sub>x</sub><sup>2</sup><i>A</i><sub>y</sub><sup>2</sup><i>A</i><sub>z</sub><sup>2</sup>)}&#x2212;1<i>G|</i>&#x2265;MovingThreshold<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0095" num="0091">Since the first movement detection can be tricked by applying an acceleration of 2 G from the ground. That means that the 1 G directed to ground will become 1 G directed upwards. The vector will remain equal to 1 G and no movement is detected while there is. Therefore, in some examples, a second movement detection may be required.</p><p id="p-0096" num="0092">The second movement detection may be based on several consecutive samples that are within a certain range of the moving average. <figref idref="DRAWINGS">FIG. <b>14</b></figref> shows an example. In this case, the average of n samples is calculated, where n is an integer number greater than 1. For each sample, delta between its value and the average is calculated. When all sample values are within a threshold from the moving average, the user is considered as stable. This calculation is performed for x, y and z-axis.</p><p id="p-0097" num="0093">It should also be understood that, unless clearly indicated to the contrary, in any methods claimed herein that include more than one step or act, the order of the steps or acts of the method is not necessarily limited to the order in which the steps or acts of the method are recited.</p><p id="p-0098" num="0094">All definitions, as defined and used herein, should be understood to control over dictionary definitions, definitions in documents incorporated by reference, and/or ordinary meanings of the defined terms.</p><p id="p-0099" num="0095">The indefinite articles &#x201c;a&#x201d; and &#x201c;an,&#x201d; as used herein in the specification and in the claims, unless clearly indicated to the contrary, should be understood to mean &#x201c;at least one.&#x201d;</p><p id="p-0100" num="0096">The phrase &#x201c;and/or,&#x201d; as used herein in the specification and in the claims, should be understood to mean &#x201c;either or both&#x201d; of the elements so conjoined, i.e., elements that are conjunctively present in some cases and disjunctively present in other cases. Multiple elements listed with &#x201c;and/or&#x201d; should be construed in the same fashion, i.e., &#x201c;one or more&#x201d; of the elements so conjoined. Other elements may optionally be present other than the elements specifically identified by the &#x201c;and/or&#x201d; clause, whether related or unrelated to those elements specifically identified.</p><p id="p-0101" num="0097">As used herein in the specification and in the claims, &#x201c;or&#x201d; should be understood to have the same meaning as &#x201c;and/or&#x201d; as defined above. For example, when separating items in a list, &#x201c;or&#x201d; or &#x201c;and/or&#x201d; shall be interpreted as being inclusive, i.e., the inclusion of at least one, but also including more than one, of a number or list of elements, and, optionally, additional unlisted items. Only terms clearly indicated to the contrary, such as &#x201c;only one of&#x201d; or &#x201c;exactly one of,&#x201d; or, when used in the claims, &#x201c;consisting of,&#x201d; will refer to the inclusion of exactly one element of a number or list of elements. In general, the term &#x201c;or&#x201d; as used herein shall only be interpreted as indicating exclusive alternatives (i.e. &#x201c;one or the other but not both&#x201d;) when preceded by terms of exclusivity, such as &#x201c;either,&#x201d; &#x201c;one of,&#x201d; &#x201c;only one of,&#x201d; or &#x201c;exactly one of.&#x201d;</p><p id="p-0102" num="0098">As used herein in the specification and in the claims, the phrase &#x201c;at least one,&#x201d; in reference to a list of one or more elements, should be understood to mean at least one element selected from any one or more of the elements in the list of elements, but not necessarily including at least one of each and every element specifically listed within the list of elements and not excluding any combinations of elements in the list of elements. This definition also allows that elements may optionally be present other than the elements specifically identified within the list of elements to which the phrase &#x201c;at least one&#x201d; refers, whether related or unrelated to those elements specifically identified.</p><p id="p-0103" num="0099">In the claims, as well as in the specification above, all transitional phrases such as &#x201c;comprising,&#x201d; &#x201c;including,&#x201d; &#x201c;carrying,&#x201d; &#x201c;having,&#x201d; &#x201c;containing,&#x201d; &#x201c;involving,&#x201d; &#x201c;holding,&#x201d; &#x201c;composed of,&#x201d; and the like are to be understood to be open-ended, i.e., to mean including but not limited to. Only the transitional phrases &#x201c;consisting of&#x201d; and &#x201c;consisting essentially of&#x201d; shall be closed or semi-closed transitional phrases, respectively.</p><p id="p-0104" num="0100">In another exemplary embodiment of the present invention, a computer program or a computer program element is provided that is characterized by being adapted to execute the method steps of the method according to one of the preceding embodiments, on an appropriate system.</p><p id="p-0105" num="0101">The computer program element might therefore be stored on a computer unit, which might also be part of an embodiment of the present invention. This computing unit may be adapted to perform or induce a performing of the steps of the method described above. Moreover, it may be adapted to operate the components of the above described apparatus. The computing unit can be adapted to operate automatically and/or to execute the orders of a user. A computer program may be loaded into a working memory of a data processor. The data processor may thus be equipped to carry out the method of the invention.</p><p id="p-0106" num="0102">This exemplary embodiment of the invention covers both, a computer program that right from the beginning uses the invention and a computer program that by means of an up-date turns an existing program into a program that uses the invention.</p><p id="p-0107" num="0103">Further on, the computer program element might be able to provide all necessary steps to fulfil the procedure of an exemplary embodiment of the method as described above.</p><p id="p-0108" num="0104">According to a further exemplary embodiment of the present invention, a computer readable medium, such as a CD-ROM, is presented wherein the computer readable medium has a computer program element stored on it which computer program element is described by the preceding section.</p><p id="p-0109" num="0105">A computer program may be stored and/or distributed on a suitable medium, such as an optical storage medium or a solid state medium supplied together with or as part of other hardware, but may also be distributed in other forms, such as via the internet or other wired or wireless telecommunication systems.</p><p id="p-0110" num="0106">However, the computer program may also be presented over a network like the World Wide Web and can be downloaded into the working memory of a data processor from such a network. According to a further exemplary embodiment of the present invention, a medium for making a computer program element available for downloading is provided, which computer program element is arranged to perform a method according to one of the previously described embodiments of the invention.</p><p id="p-0111" num="0107">While several inventive embodiments have been described and illustrated herein, those of ordinary skill in the art will readily envision a variety of other means and/or structures for performing the function and/or obtaining the results and/or one or more of the advantages described herein, and each of such variations and/or modifications is deemed to be within the scope of the inventive embodiments described herein. More generally, those skilled in the art will readily appreciate that all parameters, dimensions, materials, and configurations described herein are meant to be exemplary and that the actual parameters, dimensions, materials, and/or configurations will depend upon the specific application or applications for which the inventive teachings is/are used. Those skilled in the art will recognize, or be able to ascertain using no more than routine experimentation, many equivalents to the specific inventive embodiments described herein. It is, therefore, to be understood that the foregoing embodiments are presented by way of example only and that, within the scope of the appended claims and equivalents thereto, inventive embodiments may be practiced otherwise than as specifically described and claimed. Inventive embodiments of the present disclosure are directed to each individual feature, system, article, material, kit, and/or method described herein. In addition, any combination of two or more such features, systems, articles, materials, kits, and/or methods, if such features, systems, articles, materials, kits, and/or methods are not mutually inconsistent, is included within the inventive scope of the present disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method for body position detection, comprising the steps of:<claim-text>a) receiving accelerometer data from an accelerometer mounted on a user,<claim-text>wherein the received accelerometer data comprises three acceleration components including a first acceleration component in a first axis direction, a second acceleration component in a second axis direction substantially perpendicular to the first axis direction, and a third acceleration component in a third axis direction substantially perpendicular to a plane formed by the first and second axes; and</claim-text><claim-text>wherein the first axis direction is parallel to a frontal axis of the user, the second axis direction is parallel to a longitudinal axis of the user, and the third axis direction is parallel to a sagittal axis of the user; and</claim-text></claim-text><claim-text>b) determining, based on the received accelerometer data, at least one body position based on a comparison between an absolute value of a projection of a gravity vector on a plane formed by two of the first, second, and third axes and an absolute value of an acceleration component in a remaining axis direction.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. Computer-implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the at least one body position comprises a sleeping position and a non-sleeping position; and</claim-text><claim-text>wherein step b) further comprises the step of determining whether the user is in a sleeping position or in a non-sleeping position based on a comparison between an absolute value of the projection of the gravity vector on the plane formed by the first and third axis directions and an absolute value of the second acceleration component.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. Computer-implemented method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,<claim-text>wherein the absolute value of the second acceleration component is multiplied by a tangent of a desired angle for the comparison.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. Computer-implemented method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,<claim-text>wherein, when it is determined that the user is in a non-sleeping position, the method further comprises the step of determining, based on a sign of a value of the second acceleration component, whether the user is in a standing or an upside-down position.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. Computer-implemented method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,<claim-text>wherein, when it is determined that the user is in a sleeping position, the method further comprises the step of determining whether the user is in a flat position or in a side position based on (i) a comparison between an absolute value of the third acceleration component with an absolute value of the first acceleration component, or (ii) a comparison between an absolute value of a projection of a gravity vector on a plane formed by the second and third axes and an absolute value of the first acceleration component.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. Computer-implemented method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>,<claim-text>wherein the absolute value of the first acceleration component is multiplied by a tangent of a desired angle for the comparison.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. Computer-implemented method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>,<claim-text>wherein, when it is determined that the user is in a side position, the method further comprises the step of determining, based on a sign of a value of the first acceleration component, whether the user is in a left or right position.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. Computer-implemented method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>,<claim-text>wherein, when it is determined that the user is in a flat position, the method further comprises the step of determining, based on a sign of a value of the third acceleration component, whether the user is in a supine or prone position.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. Computer-implemented method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>detecting, based on the received accelerometer data, a movement of the user; and</claim-text><claim-text>determining the at least one body position of the user using an unfiltered value of the three acceleration components, if the movement is below a pre-defined threshold.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. Computer-implemented method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>,<claim-text>wherein the detection of the movement of the user further comprises:</claim-text><claim-text>calculating a resultant vector of the three acceleration components; and</claim-text><claim-text>determining that the user is moving when the resultant vector exceeds a moving threshold.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. Computer-implemented method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>,<claim-text>wherein the detection of the movement of the user further comprises:</claim-text><claim-text>calculating an average of a plurality of consecutive samples that are within a certain range of a moving average for each of the three acceleration components;</claim-text><claim-text>calculating, for each sample, a difference between a sample value of the respective sample and the average; and</claim-text><claim-text>determining that the user is moving when one or more sample values exceed a threshold from the moving average.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An apparatus comprising<claim-text>a communications module configured to receive accelerometer data from an accelerometer mounted on a user; and</claim-text><claim-text>a processing unit configured to perform the steps of the method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A body position detection system, comprising:<claim-text>an accelerometer mountable on a user; and</claim-text><claim-text>an apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A computer program product comprising instructions to cause the apparatus or the body position detection system to execute the steps of the method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A computer-readable data carrier having stored thereon the computer program product of <claim-ref idref="CLM-00014">claim 14</claim-ref>.</claim-text></claim></claims></us-patent-application>
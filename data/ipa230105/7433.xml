<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007434A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007434</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17784056</doc-number><date>20201203</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-228963</doc-number><date>20191219</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>S</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>R</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>R</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>7</main-group><subgroup>307</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>2205</main-group><subgroup>022</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>2400</main-group><subgroup>03</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">CONTROL APPARATUS, SIGNAL PROCESSING METHOD, AND SPEAKER APPARATUS</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Sony Group Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Nishigori</last-name><first-name>Shuichiro</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Takeda</last-name><first-name>Hirofumi</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Suzuki</last-name><first-name>Shiro</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Watanabe</last-name><first-name>Takahiro</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Sony Group Corporation</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/045028</doc-number><date>20201203</date></document-id><us-371c12-date><date>20220609</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A control apparatus according to an embodiment of the present technology includes an audio control section and a vibration control section.</p><p id="p-0002" num="0000">The audio control section generates audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component. The vibration control section generates a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="191.52mm" wi="149.35mm" file="US20230007434A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="210.48mm" wi="151.21mm" file="US20230007434A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="151.55mm" wi="131.57mm" file="US20230007434A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="143.68mm" wi="143.76mm" file="US20230007434A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="174.92mm" wi="162.73mm" file="US20230007434A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="137.33mm" wi="158.33mm" file="US20230007434A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="208.96mm" wi="147.91mm" orientation="landscape" file="US20230007434A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="183.05mm" wi="133.60mm" file="US20230007434A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="205.06mm" wi="157.65mm" orientation="landscape" file="US20230007434A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="190.75mm" wi="160.95mm" orientation="landscape" file="US20230007434A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="178.39mm" wi="137.16mm" file="US20230007434A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="210.06mm" wi="114.38mm" file="US20230007434A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="77.98mm" wi="98.89mm" file="US20230007434A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="152.74mm" wi="151.30mm" file="US20230007434A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="246.80mm" wi="143.85mm" orientation="landscape" file="US20230007434A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0001">The present technology relates to a control apparatus, a signal processing method, and a speaker apparatus.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0004" num="0002">In recent years, applications of stimulating the sense of touch via human skin or the like through a tactile reproduction device have been utilized in various scenes.</p><p id="p-0005" num="0003">As tactile reproduction devices therefor, eccentric rotating mass (ERM), linear resonant actuator (LRA), and the like have been currently widely used, and devices with a resonant frequency that is a frequency (about several 100 Hz) that provides good sensitivity for the human sense of touch have been widely used for them (e.g., see Patent Literature 1).</p><p id="p-0006" num="0004">Since the frequency band that provides high sensitivity for the human sense of touch is several 100 Hz, vibration reproduction devices that handle this band of several 100 Hz have been mainstream.</p><p id="p-0007" num="0005">As other tactile reproduction devices, an electrostatic tactile display and a surface acoustic wave tactile display aiming at controlling a friction coefficient of a touched portion and realizing a desired tactile sense have been proposed (e.g., see Patent Literature 2). In addition, an airborne ultrasonic tactile display utilizing an acoustic radiation pressure of converged ultrasonic waves and an electrotactile display that electrically stimulates nerves and muscles that are connected to a tactile receptor have been proposed.</p><p id="p-0008" num="0006">For applications utilizing those devices, especially for music listening, a vibration reproduction device is built in a headphone casing to reproduce vibration at the same time as music reproduction, to thereby emphasize bass sound.</p><p id="p-0009" num="0007">Moreover, wearable (neck) speakers that do not take the form of headphones and are used hanging around a neck have been proposed. The wearable speakers include one (e.g., see Patent Literature 3) that transmits vibration to a user from the back together with sound output from the speaker by utilizing their contact with a user's body and one (e.g., see Patent Literature 4) that transmits vibration to a user by utilizing a resonance of a back pressure of speaker vibration.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0010" num="0008">Patent Literature 1: Japanese Patent Application Laid-open No. 2016-202486</p><p id="p-0011" num="0009">Patent Literature 2: Japanese Patent Application Laid-open No. 2001-255993</p><p id="p-0012" num="0010">Patent Literature 3: Japanese Patent Application Laid-open No. HEI 10-200977</p><p id="p-0013" num="0011">Patent Literature 4: Japanese Patent Application No. 2017-43602</p><heading id="h-0005" level="1">DISCLOSURE OF INVENTION</heading><heading id="h-0006" level="1">Technical Problem</heading><p id="p-0014" num="0012">In headphones and wearable speakers that provide tactile presentation, in a case where a vibration signal is generated from an audio signal and presented, if a vibration signal is generated from an audio signal containing human voices in great amount, an uncomfortable or unpleasant vibration that is not desired to be provided generally may occur.</p><p id="p-0015" num="0013">In view of the above-mentioned circumstances, the present technology provides a control apparatus, a signal processing method, and a speaker apparatus, which are capable of removing or reducing a generally uncomfortable or unpleasant vibration.</p><heading id="h-0007" level="1">Solution to Problem</heading><p id="p-0016" num="0014">A control apparatus according to an embodiment of the present technology includes an audio control section and a vibration control section.</p><p id="p-0017" num="0015">The audio control section generates audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component.</p><p id="p-0018" num="0016">The vibration control section generates a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels.</p><p id="p-0019" num="0017">The vibration control section may be configured to limit a band of the audio signals of the plurality of channels or a difference signal of the audio signals of the plurality of channels to a first frequency or less.</p><p id="p-0020" num="0018">The vibration control section may output, as the vibration control signal, a monaural signal obtained by mixing the audio signals of the respective channels for an audio signal having a frequency equal to or lower than a second frequency lower than the first frequency among the audio signals of the plurality of channels, and the difference signal for an audio signal exceeding the second frequency and being equal to or lower than the first frequency among the audio signals of the plurality of channels.</p><p id="p-0021" num="0019">The first frequency may be 500 Hz or less.</p><p id="p-0022" num="0020">The second cutoff frequency may be 150 Hz or less.</p><p id="p-0023" num="0021">The first audio component may be a voice sound.</p><p id="p-0024" num="0022">The second audio component may be a sound effect and a background sound.</p><p id="p-0025" num="0023">The audio signals of the two channels may be audio signals of left and right channels.</p><p id="p-0026" num="0024">The vibration control section may include an adjustment section that adjusts a gain of the vibration control signal on the basis of an external signal.</p><p id="p-0027" num="0025">The adjustment section may be configured to be capable of switching between activation and deactivation of generation of the vibration control signal.</p><p id="p-0028" num="0026">The vibration control section may include an addition section that generates a monaural signal obtained by mixing the audio signals of the two channels.</p><p id="p-0029" num="0027">The vibration control section may include a subtraction section that takes a difference between the audio signals. In this case, the subtraction section is configured to be capable of adjusting a degree of reduction of the difference.</p><p id="p-0030" num="0028">A signal processing method according to an embodiment of the present technology includes: generating audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component; and generating a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels.</p><p id="p-0031" num="0029">A speaker apparatus according to an embodiment of the present technology includes an audio output unit, a vibration output unit, an audio control section, and a vibration control section.</p><p id="p-0032" num="0030">The audio control section generates audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component, and drives the audio output unit.</p><p id="p-0033" num="0031">The vibration control section generates a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels, and drives the vibration output unit.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0008" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0034" num="0032"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a perspective view and a bottom view of a speaker apparatus according to a first embodiment of the present technology.</p><p id="p-0035" num="0033"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a perspective view showing a state in which the speaker apparatus is mounted on a user.</p><p id="p-0036" num="0034"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic cross-sectional view of main parts of the speaker apparatus.</p><p id="p-0037" num="0035"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram showing a configuration example of the speaker apparatus.</p><p id="p-0038" num="0036"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a graph showing a vibration detection threshold as a mechanism of the human sense of touch.</p><p id="p-0039" num="0037"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows graphs of signals in which low-pass filtering is performed on the spectrum of an audio signal.</p><p id="p-0040" num="0038"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart for generating a vibration signal from an audio signal in a first embodiment of the present technology.</p><p id="p-0041" num="0039"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows graphs showing the spectrum before difference processing is performed, the spectrum after the difference processing is performed, and the spectrum after the difference processing is performed while leaving the low frequency.</p><p id="p-0042" num="0040"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram showing the internal configuration of the vibration control section of the speaker apparatus in this embodiment.</p><p id="p-0043" num="0041"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart for generating a vibration signal from an audio signal in the first embodiment of the present technology.</p><p id="p-0044" num="0042"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows top views showing a speaker arrangement in audio signal formats of 5.1 channels and 7.1 channels.</p><p id="p-0045" num="0043"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a schematic diagram showing stream data in a predetermined period of time relating to sound and vibration.</p><p id="p-0046" num="0044"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a schematic diagram showing user interface software for controlling the gain of audio/vibration signals.</p><p id="p-0047" num="0045"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a graph showing signal examples of a sound effect and a background sound.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0009" level="1">MODE(S) FOR CARRYING OUT THE INVENTION</heading><p id="p-0048" num="0046">Embodiments according to the present technology will be described below with reference to the drawings.</p><p id="p-0049" num="0047">&#x3c;First Embodiment&#x3e;</p><p id="p-0050" num="0048">(Basic Configuration of Speaker Apparatus)</p><p id="p-0051" num="0049"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a perspective view (a) and a bottom view (b) showing a configuration example of a speaker apparatus in an embodiment of the present technology. This speaker apparatus (sound output apparatus) <b>100</b> has a function of actively presenting vibration (tactile sense) to a user U at the same time as presenting sound. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the speaker apparatus <b>100</b> is, for example, a wearable speaker that is mounted on both shoulders of the user U.</p><p id="p-0052" num="0050">The speaker apparatus <b>100</b> includes a right speaker <b>100</b>R, a left speaker <b>100</b>L, and a coupler <b>100</b>C that couples the right speaker <b>100</b>R with the left speaker <b>100</b>L. The coupler <b>100</b>C is formed in an arbitrary shape capable of hanging around the neck of the user U, and the right speaker <b>100</b>R and the left speaker <b>100</b>L are positioned on both shoulders or upper portions of the chest of the user U.</p><p id="p-0053" num="0051"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic cross-sectional view of main parts of the right speaker <b>100</b>R and the left speaker <b>100</b>L of the speaker apparatus <b>100</b> in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>. The right speaker <b>100</b>R and the left speaker <b>100</b>L typically have a left-right symmetric structure. It should be noted that <figref idref="DRAWINGS">FIG. <b>3</b></figref> is merely a schematic view, and therefore it is not necessarily equivalent to the shape and dimension ratio of the speaker shown in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>.</p><p id="p-0054" num="0052">The right speaker <b>100</b>R and the left speaker <b>100</b>L include, for example, audio output units <b>250</b>, vibration presentation units <b>251</b>, and casings <b>254</b> that house them. The right speaker <b>100</b>R and the left speaker <b>100</b>L typically reproduce audio signals by a stereo method. Reproduction sound is not particularly limited as long as it is reproducible sound or voice that is typically a musical piece, a conversation, a sound effect, or the like.</p><p id="p-0055" num="0053">The audio output units <b>250</b> are electroacoustic conversion-type dynamic speakers. The audio output unit <b>250</b> includes a diaphragm <b>250</b><i>a, </i>a voice coil <b>250</b><i>b </i>wound around the center portion of the diaphragm <b>250</b><i>a, </i>a fixation ring <b>250</b>c that retains the diaphragm <b>250</b><i>a </i>to the casing <b>254</b>, and a magnet assembly <b>250</b><i>d </i>disposed facing the diaphragm <b>250</b><i>a. </i>The voice coil <b>250</b><i>b </i>is disposed perpendicular to a direction of a magnetic flux produced in the magnet assembly <b>250</b><i>d. </i>When an audio signal (alternate current) is supplied into the voice coil <b>250</b><i>b, </i>the diaphragm <b>250</b><i>a </i>vibrates due to electromagnetic force that acts on the voice coil <b>250</b><i>b. </i>By the diaphragm <b>250</b><i>a </i>vibrating in accordance with the signal waveform of the audio signal, reproduction sound waves are generated.</p><p id="p-0056" num="0054">The vibration presentation unit <b>251</b> includes a vibration device (vibrator) capable of generating tactile vibration, such as an eccentric rotating mass (ERM), a linear resonant actuator (LRA), or a piezoelectric element. The vibration presentation unit <b>251</b> is driven when a vibration signal for tactile presentation prepared in addition to a reproduction signal is input. The amplitude and frequency of the vibration are also not particularly limited. The vibration presentation unit <b>251</b> is not limited to a case where it is constituted by the single vibration device, and the vibration presentation unit <b>251</b> may be constituted by a plurality of vibration devices. In this case, the plurality of vibration devices may be driven at the same time or may be driven individually.</p><p id="p-0057" num="0055">The casing <b>254</b> has an opening potion (sound input port) <b>254</b><i>a </i>for passing audio output (reproduction sound) to the outside, in a surface opposite to the diaphragm <b>250</b><i>a </i>of the audio output unit <b>250</b>. The opening potion <b>254</b><i>a </i>is formed in a straight line shape to conform to a longitudinal direction of the casing <b>254</b> as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, though not limited thereto. The opening potion <b>254</b><i>a </i>may be constituted by a plurality of through-holes or the like.</p><p id="p-0058" num="0056">The vibration presentation unit <b>251</b> is, for example, disposed on an inner surface on a side opposite to the opening potion <b>254</b><i>a </i>of the casing <b>254</b>. The vibration presentation unit <b>251</b> presents tactile vibration to the user via the casing <b>254</b>. In order to improve the transmissivity of tactile vibration, the casing <b>254</b> may be partially constituted by a relatively low rigidity material. The shape of the casing <b>254</b> is not limited to the shape shown in the figure, and an appropriate shape such as a disk-shape or a rectangular parallelepiped-shape can be employed.</p><p id="p-0059" num="0057">Next, a control system of the speaker apparatus <b>100</b> will be described. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram showing a configuration example of the speaker apparatus applied in this embodiment.</p><p id="p-0060" num="0058">The speaker apparatus <b>100</b> includes a control apparatus <b>1</b> that controls driving of the audio output units <b>250</b> and the vibration presentation units <b>251</b> of the right speaker <b>100</b>R and the left speaker <b>100</b>L. The control apparatus <b>1</b> and other elements to be described later are built in the casing <b>254</b> of the right speaker <b>100</b>R or the left speaker <b>100</b>L.</p><p id="p-0061" num="0059">An external device <b>60</b> is an external device such as a smartphone or a remote controller, which will be described later in detail, and operation information such as a switch or a button by a user is wirelessly transmitted and input to the control apparatus <b>1</b> (which will be described later).</p><p id="p-0062" num="0060">As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the control apparatus <b>1</b> includes an audio control section <b>13</b> and a vibration control section <b>14</b>.</p><p id="p-0063" num="0061">The control apparatus <b>1</b> can be provided by hardware components used in a computer, such as a central processing unit (CPU), a random access memory (RAM), and a read only memory (ROM), and necessary software. Instead of or in addition to the CPU, a programmable logic device (PLD) such as a field programmable gate array (FPGA), or a digital signal processor (DSP), other application specific integrated circuit (ASIC), and the like may be used. The control apparatus <b>1</b> executes a predetermined program, so that the audio control section <b>13</b> and the vibration control section <b>14</b> are configured as functional blocks.</p><p id="p-0064" num="0062">The speaker apparatus <b>100</b> includes storage (storage section) <b>11</b>, a decoding section <b>12</b>, an audio output section <b>15</b>, a vibration output section <b>16</b>, and a communication section <b>18</b> as other hardware.</p><p id="p-0065" num="0063">On the basis of a musical piece or other audio signal as an input signal, the audio control section <b>13</b> generates an audio control signal for driving the audio output section <b>15</b>. The audio signal is data for sound reproduction (audio data) stored in the storage <b>11</b> or a server device <b>50</b>.</p><p id="p-0066" num="0064">The vibration control section <b>14</b> generates a vibration control signal for driving the vibration output section <b>16</b> on the basis of a vibration signal. The vibration signal is generated utilizing the audio signal, as will be described below.</p><p id="p-0067" num="0065">The storage <b>11</b> is a storage device capable of storing an audio signal, such as a nonvolatile semiconductor memory. In this embodiment, the audio signal is stored in the storage <b>11</b> as digital data encoded as appropriate.</p><p id="p-0068" num="0066">The decoding section <b>12</b> decodes the audio signal stored in the storage <b>11</b>. The decoding section <b>12</b> may be omitted as necessary or may be configured as a functional block that forms a part of the control apparatus <b>1</b>.</p><p id="p-0069" num="0067">The communication section <b>18</b> is constituted by a communication module connectable to a network <b>10</b> with a wire (e.g., USB cable) or wirelessly by Wi-Fi, Bluetooth (registered trademark), or the like. The communication section <b>18</b> is configured as a receiving section capable of communicating with the server device <b>50</b> via the network <b>10</b> and capable of acquiring the audio signal stored in the server device <b>50</b>.</p><p id="p-0070" num="0068">The audio output section <b>15</b> includes the audio output units <b>250</b> of the right speaker <b>100</b>R and the left speaker <b>100</b>L shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, for example.</p><p id="p-0071" num="0069">The vibration output section <b>16</b> includes the vibration presentation units <b>251</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, for example.</p><p id="p-0072" num="0070">(Typical Operation of Speaker Apparatus)</p><p id="p-0073" num="0071">Next, a typical operation of the speaker apparatus <b>100</b> configured in the above-mentioned manner will be described.</p><p id="p-0074" num="0072">The control apparatus <b>1</b> generates signals (audio control signal and vibration control signal) for driving the audio output section <b>15</b> and the vibration output section <b>16</b> by receiving the signals from the server device <b>50</b> or reading the signals from the storage <b>11</b>.</p><p id="p-0075" num="0073">Next, the decoding section <b>12</b> performs suitable decoding processing on the acquired data to thereby take out audio data (audio signal), and inputs the audio data to the audio control section <b>13</b> and the vibration control section <b>14</b>, respectively.</p><p id="p-0076" num="0074">The audio data format may be a linear PCM format of raw data or may be a data format that is highly efficiently encoded by an audio codec, such as MP3 or AAC.</p><p id="p-0077" num="0075">The audio control section <b>13</b> and the vibration control section <b>14</b> perform various types of processing on the input data. Output (audio control signal) of the audio control section <b>13</b> is input into the audio output section <b>15</b>, and output (vibration control signal) of the vibration control section <b>14</b> is input into the vibration output section <b>16</b>. The audio output section <b>15</b> and the vibration output section <b>16</b> each include a D/A converter, a signal amplifier, and a reproduction device (equivalent to the audio output units <b>250</b> and the vibration presentation units <b>251</b>).</p><p id="p-0078" num="0076">The D/A converter and the signal amplifier may be included in the audio control section <b>13</b> and the vibration control section <b>14</b>. The signal amplifier may include a volume adjustment section that is adjusted by the user U, an equalization adjustment section, a vibration amount adjustment section by gain adjustment, and the like.</p><p id="p-0079" num="0077">On the basis of the input audio data, the audio control section <b>13</b> generates an audio control signal for driving the audio output section <b>15</b>. On the basis of the input tactile data, the vibration control section <b>14</b> generates a vibration control signal for driving the vibration output section <b>16</b>.</p><p id="p-0080" num="0078">Here, if a wearable speaker is used, since a vibration signal is rarely prepared separately from an audio signal in broadcast content, package content, net content, game content, and the like, sound with high correlation with vibration is generally utilized. In other words, processing is performed on the basis of an audio signal, and the generated vibration signal is output.</p><p id="p-0081" num="0079">When such vibration is presented, the user may feel it as a generally unfavorable vibration. For example, when quotes and narrations in content such as movies, dramas, animation, and games, live sounds in sports videos, and the like are presented as vibration, the user feels like the body is shaken by the voices of other people and often feels uncomfortable.</p><p id="p-0082" num="0080">In addition, since those audio components have a relatively large sound volume, and their center frequency band is also within the vibration presentation frequency range (several 100 Hz), they will provide larger vibration than other vibration components and will mask the components of shocks, rhythms, feel, and the like, by which vibration is originally desired to be provided.</p><p id="p-0083" num="0081">On the other hand, if the content in which an audio signal and a vibration signal are individually prepared is reproduced, the vibration that provides the user with a sense of discomfort or an unpleasant feeling should not be presented, because a content creator creates the vibration signal with the creator's intention in advance. However, since the preference of human senses differs among individuals, there is a possibility that an uncomfortable or unpleasant vibration may be presented in some cases.</p><p id="p-0084" num="0082">In the active vibration wearable speaker, the control apparatus <b>1</b> of this embodiment is configured as follows in order to remove or reduce an uncomfortable or unpleasant vibration for the user.</p><p id="p-0085" num="0083">(Control Apparatus)</p><p id="p-0086" num="0084">The control apparatus <b>1</b> includes the audio control section <b>13</b> and the vibration control section <b>14</b> as described above. The audio control section <b>13</b> and the vibration control section <b>14</b> are configured to have the functions to be described below in addition to the functions described above.</p><p id="p-0087" num="0085">The audio control section <b>13</b> generates an audio control signal for each of a plurality of channels with audio signals of the plurality of channels each including a first audio component and a second audio component different from the first audio component as input signals. The audio control signal is a control signal for driving the audio output section <b>15</b>.</p><p id="p-0088" num="0086">The first audio component is typically a voice sound. The second audio component is another audio component other than the voice sound, for example, a sound effect or a background sound. The second audio component may be both the sound effect and the background sound or may be either one of them.</p><p id="p-0089" num="0087">In this embodiment, the plurality of channels are two channels of a left channel and a right channel. The number of channels is not limited to two of the left and right channels and may be three or more channels in which a center, a rear, a subwoofer, and the like are added to the above two channels.</p><p id="p-0090" num="0088">The vibration control section <b>14</b> generates a vibration control signal for vibration presentation by taking the difference of the audio signals of the two channels among the plurality of channels. The vibration control signal is a control signal for driving the vibration output section <b>16</b>.</p><p id="p-0091" num="0089">As will be described later, for the voice sound, the same signal is usually used in the left and right channels, and the above-mentioned difference processing is performed to obtain a vibration control signal in which the voice sound is canceled. This makes it possible to generate a vibration control signal based on an audio signal other than the voice sound, such as a sound effect or a background sound.</p><p id="p-0092" num="0090">On the other hand, as a human tactile sense mechanism, a vibration detection threshold as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is known (cited from &#x201c;Four cahnnels mediate the mechanical aspects of touch&#x201d;, S. J. Bolanowski 1988). Centering on the frequencies between 200 and 300 Hz, at which a human is most sensitive to vibration, sensitivity becomes duller as being away from this frequency band. Typically, the range of several Hz to <b>1</b> kHz is considered to be the vibration presentation range. In reality, however, frequencies of 500 Hz or more affect the sense of hearing and is regarded as noise, and thus the upper limit is set to approximately 500 Hz.</p><p id="p-0093" num="0091">In this embodiment, the vibration control section <b>14</b> has a low-pass filter function of limiting the band of the audio signal to a predetermined frequency (first frequency) or less. (A) of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a spectrum (logarithmic spectrum) <b>61</b> of the audio signal, and (B) of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a spectrum <b>62</b> subjected to low-pass filtering (e.g., cutoff frequency of 500 Hz) performed on the spectrum <b>61</b>. The vibration control section <b>14</b> generates a vibration signal using the audio signal (spectrum <b>62</b>) obtained after the low-pass filtering. The first frequency is not limited to 500 Hz, but it may be a lower frequency than 500 Hz.</p><p id="p-0094" num="0092">Regarding the number of channels of the vibration signal, the signals obtained by limiting the bands of the left and right audio signals may be output as vibration signals of the two channels as they are. However, if different vibrations are presented on the left side and right side, the user may feel a sense of discomfort. In this embodiment, a monaural signal obtained by mixing the left and right channels is output as the same vibration signal on the left side and right side. Such mixed monaural signal is calculated as an average value of the audio signals of the left and right channels, for example, as shown in the following (Equation 1).</p><p id="p-0095" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>VM</i>(<i>t</i>)=(<i>AL</i>(<i>t</i>)+<i>AR</i>(<i>t</i>))+0.5 &#x2003;&#x2003;(Equation 1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0096" num="0093">Here, VM(t) is a value at a time t in the vibration signal, AL(t) is a value at the time t of the left channel of the band-limited audio signal, and AR(t) is a value at the time t of the right channel of the band-limited audio signal.</p><p id="p-0097" num="0094">The above-mentioned configuration of the speaker apparatus <b>100</b> makes it possible to reproduce sound and vibration with respect to existing content. In this embodiment, the signal processing using (Equation 1) is performed on the digital audio signals corresponding to the two channels of the existing content in the vibration control section <b>14</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, and thus it is possible to remove or reduce the noise caused by quotes, narrations, live broadcasting, and the like.</p><p id="p-0098" num="0095">Incidentally, it is considered that the elements constituting a stereo audio signal of two channels in general content include, as three major elements, a voice sound such as quotes and narrations, a sound effect for representation, and a background sound such as music and environmental sounds.</p><p id="p-0099" num="0096">(Content sound=Voice sound+Sound effect+Background sound)</p><p id="p-0100" num="0097">The content creator generates final content by adjusting the sound quality and volume of each constitutional element and then perform mixing. At that time, in consideration of the sense of sound localization (direction of sound arrival), the voice is usually assigned as the same signal in the left and right channels such that the voice can be constantly heard from a stable position (front) as the foreground. The sound effect and the background sound are usually assigned as different signals in the left and right channels in order to enhance the sense of realism.</p><p id="p-0101" num="0098"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a graph showing signal examples of a sound effect <b>141</b> (e.g., chime sound) and a background sound <b>142</b> (e.g., musical piece). Each signal has left channel data (upper stage) and right channel data (lower stage).</p><p id="p-0102" num="0099">It is found that both the sound effect <b>141</b> and the background sound <b>142</b> have signals that are similar in shape in the left and right channels but are different.</p><p id="p-0103" num="0100">The two-channel sound mixing is shown in (Equation 2) and (Equation 3). Here, AL(t) is a value at a time t in the left channel of the audio signal, AR(t) is a value at the time t of the right channel of the audio signal, S(t) is a value at the time t of a voice signal, EL(t) is a value at the time t of the left channel of a sound effect signal, ER(t) is a value at the time t of the right channel of the sound effect signal, ML(t) is a value at the time t of the left channel of a background sound signal, and MR(t) is a value at the time t of the right channel of the background sound signal.</p><p id="p-0104" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>AL</i>(<i>t</i>)=<i>S</i>(<i>t</i>)+<i>EL</i>(<i>t</i>)+<i>ML</i>(<i>t</i>) &#x2003;&#x2003;(Equation 2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0105" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>AR</i>(<i>t</i>)=<i>S</i>(<i>t</i>)+<i>ER</i>(<i>t</i>)+<i>MR</i>(<i>t</i>) &#x2003;&#x2003;(Equation 3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0106" num="0101">Here, the signal subjected to the difference processing of the left and right channels in the audio signal as in the following (Equation 4) is used as a vibration signal VM(t), and thus S(t) is canceled. As a result, vibration is not provided in response to the audio signals of quotes, narrations, live broadcasting, and the like, and an unpleasant vibration is removed.</p><p id="p-0107" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>VM</i>(<i>t</i>)=<i>AL</i>(<i>t</i>)&#x2212;<i>AR</i>(<i>t</i>)=<i>EL</i>(<i>t</i>)&#x2212;<i>ER</i>(<i>t</i>)+<i>ML</i>(<i>t</i>)&#x2212;<i>MR</i>(<i>t</i>) &#x2003;&#x2003;(Equation 4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0108" num="0102">Note that (Equation 4) may be AR(t)&#x2212;AL(t).</p><p id="p-0109" num="0103">As described above, the vibration control section <b>14</b> is not limited to the following case where the audio signals of the left and right channels are band-limited, the band-limited audio signals of the left and right channels are subjected to the difference processing, and the audio signal subjected to the difference processing is output as a vibration control signal. For example, as shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the vibration control section <b>14</b> may perform difference processing on the audio signals of the left and right channels, and perform band-limiting processing on the audio signal (difference signal) subjected to the difference processing, thus outputting the band-limited difference signal as a vibration control signal.</p><p id="p-0110" num="0104"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart showing another example of the procedure for generating a vibration signal from an audio signal, which is executed in the vibration control section <b>14</b>.</p><p id="p-0111" num="0105">In Step S<b>71</b>, with the audio signal, which has been output from the decoding section <b>12</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, being used as an input, the difference signal of the audio signals of the left and right channels is obtained according to (Equation 4) described above.</p><p id="p-0112" num="0106">Subsequently, in Step <b>72</b>, similarly to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, low-pass filtering at a cutoff frequency of a predetermined frequency (e.g., 500 Hz) or less is performed on the difference signal obtained in Step S<b>71</b>, and thus a band-limited audio signal is obtained.</p><p id="p-0113" num="0107">Subsequently, in Step <b>73</b>, the band-limited signal obtained in Step S<b>72</b> is multiplied by a gain coefficient corresponding to the vibration volume specified by the user with an external UI or the like.</p><p id="p-0114" num="0108">Subsequently, in Step <b>74</b>, the signal obtained in Step S<b>73</b> is output as a vibration control signal to the vibration output section <b>16</b>.</p><p id="p-0115" num="0109">Depending on the mixing method by the content creator, it is conceivable that the voice is subjected to effects such as reverberation and compressor to give an effect of emphasis. In such a case, different signals are assigned to the left and right channels, and even in this case, the main component of the voice is assigned as the same signal to the left and right channels. Thus, an uncomfortable or unpleasant vibration due to the voice is further reduced by the difference signal (Equation 4) as compared with the normal signal.</p><p id="p-0116" num="0110">Meanwhile, for VM(t), a signal from which the signal (central localization component) with the same magnitude is removed at the same time in both the left and right channels is obtained by (Equation 4) described above, but a signal with the same magnitude is included at the same time in each term of EL(t), ER(t), ML(t), and MR(t) in (Equation 2) and (Equation 3).</p><p id="p-0117" num="0111">In other words, when the processing of (Equation 4) is performed, the following negative effects may occur in which a signal, by which vibration is originally desired to be provided, is impaired and no vibration is provided. Further, since VM(t) in (Equation 4) is a difference result, the magnitude of the signal may become smaller than that of the original signal if the correlation between the original signals is high.</p><p id="p-0118" num="0112">For example, (A) of <figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a mixed monaural signal ((L+R)&#xd7;0.5) of the audio signals of the left and right channels before the difference processing (which corresponds to the spectrum <b>62</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>), and (B) of <figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a spectrum (L-R) <b>81</b> of the audio signal after the difference processing, respectively. In the spectrum <b>81</b> obtained after the difference processing, the overall level falls from the maximum value L<b>1</b> of the spectrum <b>62</b> (e.g., &#x2212;24 dB). Further, signals below 150 Hz are impaired.</p><p id="p-0119" num="0113">So, the band at the lower limit frequency (e.g., 150 Hz) or less of the voice (human voice) is excluded from the target of the difference processing and then subjected to addition processing of the left and right signals of (Equation 1). The band exceeding the lower limit frequency is removed by the difference processing. Thus, it is possible to maintain the low-frequency signal component, by which vibration is desired to be provided, as shown in (C) of <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0120" num="0114">In other words, the vibration control section <b>14</b> outputs a monaural signal obtained by mixing the audio signals of the respective channels, as a vibration control signal, for the audio signal having a frequency equal to or lower than the second frequency (150 Hz in this example) lower than the first frequency (500 Hz in this example), and outputs the difference signal of those audio signals, as a vibration control signal, for the audio signal having a frequency exceeding the second frequency and being equal to or lower than the first frequency, among the audio signals of the plurality of channels.</p><p id="p-0121" num="0115">Note that the values of the first frequency and the second frequency are not limited to the above example and can be arbitrarily set.</p><p id="p-0122" num="0116"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram showing an example of the internal configuration of the vibration control section <b>14</b> of the speaker apparatus <b>100</b> in this embodiment.</p><p id="p-0123" num="0117">The vibration control section <b>14</b> includes an addition section <b>91</b>, an LPF section <b>92</b>, a subtraction section <b>93</b>, a BPF section <b>94</b>, a synthesis section <b>95</b>, and an adjustment section <b>96</b>.</p><p id="p-0124" num="0118">The addition section <b>91</b> downmixes the audio signals of the two channels received via the communication section <b>18</b> to a monaural signal according to (Equation 1).</p><p id="p-0125" num="0119">The LPF section <b>92</b> performs low-pass filtering at a cutoff frequency of 150 Hz to convert the main component of the audio signal into a signal having a band of 150 Hz or less.</p><p id="p-0126" num="0120">The subtraction section <b>93</b> performs difference processing on the audio signals of the two channels received via the communication section <b>18</b> according to (Equation 4).</p><p id="p-0127" num="0121">The BPF section <b>94</b> converts the main component of the audio signal into a signal of 150 Hz to 500 Hz by bandpass filtering with a passband of 150 Hz to 500 Hz.</p><p id="p-0128" num="0122">The synthesis section <b>95</b> synthesizes the signal input from the LPF section <b>92</b> and the signal input from the BPF section <b>94</b>.</p><p id="p-0129" num="0123">The adjustment section <b>96</b> is for adjusting the gain of the entire vibration control signal when adjusting the volume of vibration through an input operation or the like from the external device <b>60</b>. The adjustment section <b>96</b> outputs the gain-adjusted vibration control signal to the vibration output section <b>16</b>.</p><p id="p-0130" num="0124">The adjustment section <b>96</b> may further be configured to be capable of switching between the activation and deactivation of the generation of the vibration control signal, which is performed in the addition processing by the addition section <b>91</b>, the band-limiting processing by the LPF section <b>92</b> or BPF section <b>94</b>, and the subtraction processing by the subtraction section <b>93</b>. In the case of the processing in which the generation of the vibration control signal is not performed (hereinafter, also referred to as generation deactivation processing), the audio signal of each channel is directly input to the adjustment section <b>96</b>, and a vibration control signal is generated.</p><p id="p-0131" num="0125">Whether or not to adopt the generation deactivation processing can be arbitrarily set by the user. Typically, a control command of the generation deactivation processing is input to the adjustment section <b>96</b> via the external device <b>60</b>.</p><p id="p-0132" num="0126">Note that, as will be described later, the subtraction section <b>93</b> may also be configured to be capable of adjusting the degree of reduction when taking the difference of the audio signals of the left and right channels, via the external device <b>60</b>. In other words, the present technology is not limited to the case where all the generation of the vibration control signal derived from the voice sound is excluded, and the magnitude of the vibration derived from the voice sound may be configured to be arbitrarily settable according to the preference of the user.</p><p id="p-0133" num="0127">As the method of adjusting the degree of reduction, for example, a difference signal between the left-channel audio signal of the two channels and the right-channel audio signal, which is multiplied by a coefficient, is used as a vibration control signal. The coefficient can be arbitrarily set, and the audio signal multiplied by the coefficient may also be the left-channel audio signal instead of the right-channel audio signal.</p><p id="p-0134" num="0128"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart relating to a series of processing for generating the vibration signal from the audio signal in this embodiment.</p><p id="p-0135" num="0129">In Step S<b>101</b>, the addition section <b>91</b> performs addition processing of the left and right signals of (Equation 1). Subsequently, in Step S<b>102</b>, the LPF section <b>92</b> performs low-pass filtering at a cutoff frequency of 150 Hz on the signal obtained after the addition processing.</p><p id="p-0136" num="0130">Subsequently, in Step S<b>103</b>, the subtraction section <b>93</b> performs difference processing of the left and right signals of (Equation 4). At that time, a voice reduction coefficient (to be described later) adjusted by the user, which is input from the external device <b>60</b>, may be considered.</p><p id="p-0137" num="0131">Subsequently, in Step S<b>104</b>, the BPF section <b>94</b> performs bandpass filtering at cutoff lower limit frequency of 150 Hz and upper limit frequency of 500 Hz, on the signal obtained after the difference processing. The cutoff upper limit frequency is appropriately selected in the same manner as in the lower limit frequency.</p><p id="p-0138" num="0132">Subsequently, in Step S<b>105</b>, the synthesis section <b>95</b> performs synthesizing processing of the signal after the processing in Step S<b>102</b> and the signal after the processing in Step <b>104</b>.</p><p id="p-0139" num="0133">Subsequently, in Step S<b>106</b>, a signal, which is obtained by multiplying the signal obtained after the processing of Step S<b>105</b> by a vibration gain coefficient set by the user with an external user interface (UI) or the like, is obtained by the adjustment section <b>96</b>. Subsequently, in Step S<b>107</b>, the signal obtained after the processing of Step S<b>106</b> is output as a vibration control signal to the vibration output section <b>16</b> or <b>251</b>.</p><p id="p-0140" num="0134">As described above, according to this embodiment, it is possible to remove or reduce a vibration component providing a sense of discomfort or an unpleasant feeling for a user when the vibration signal is generated from the received audio signal.</p><heading id="h-0010" level="1">Second Embodiment</heading><p id="p-0141" num="0135">For example, in disc standards of DVDs, Blue-Ray, and the like, digital broadcasting systems, game content, and the like, audio signals of 5.1 channel or 7.1 channel are used as multi-channel audio formats.</p><p id="p-0142" num="0136">In those formats, the configuration shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref> is recommended as the speaker arrangement, and a content creator allocates the audio signals of respective channels on the assumption of the speaker arrangement. In particular, human voices such as quotes and narrations are generally assigned to the front center channel (FC in <figref idref="DRAWINGS">FIG. <b>11</b></figref>) so as to be heard from the front of a listener.</p><p id="p-0143" num="0137">When the multi-channel audio format as described above is used as an input, the remaining signal, excluding the signal of the front center channel, is downmixed and converted into a monaural signal or a stereo signal. Subsequently, the signal having been subjected to low-pass filtering (e.g., cutoff frequency of 500 Hz) is output as a vibration control signal.</p><p id="p-0144" num="0138">As a result, the vibration output section does not vibrate in accordance with a human voice, and the user does not feel an unpleasant vibration.</p><p id="p-0145" num="0139">When downmixing is performed from the 5.1 channel and the 7.1 channel, for example, the following (Equation 5) and (Equation 6) are used, respectively.</p><p id="p-0146" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>VM</i>(<i>t</i>)=&#x3b1;<i>FL</i>(<i>t</i>)+&#x3b2;<i>FR</i>(<i>t</i>)+&#x3b3;<i>SL</i>(<i>t</i>)+&#x3b4;<i>SR</i>(<i>t</i>)+&#x3b5;<i>SW</i>(<i>t</i>) &#x2003;&#x2003;(Equation 5)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0147" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>VM</i>(<i>t</i>)=&#x3b1;<i>FL</i>(<i>t</i>)+&#x3b2;<i>FR</i>(<i>t</i>)+&#x3b3;<i>SL</i>(<i>t</i>)+&#x3b4;<i>SR</i>(<i>t</i>)+&#x3b5;<i>SW</i>(<i>t</i>)+&#x3b8;<i>LB</i>(<i>t</i>)+&#x3bc;<i>RB</i>(<i>t</i>) &#x2003;&#x2003;(Equation 6)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0148" num="0140">Here, VM(t) is a value at the time t of the vibration signal, and FL(t), FR(t), SL(t), SR(t), SW(t), LB(t), and RB(t) are values at the time t of the audio signals corresponding to FL, FR, SL, SR, SW, LB, and RB of the speaker arrangement, respectively. In addition, &#x3b1;, &#x3b2;, &#x3b3;, &#x3b4;, &#x3b5;, &#x3b8;, and &#x3bc; are downmix coefficients in the respective signals.</p><p id="p-0149" num="0141">The downmix coefficient may be any numerical value, or each coefficient may be set to, for example, 0.2 in the case of (Equation 5) and 0.143 in the case of (Equation 6) by equally dividing all channels.</p><p id="p-0150" num="0142">In this embodiment, as described above, the signal obtained after removing or reducing the signal of the front center channel of the multi-channel audio signal and downmixing the other channels becomes a vibration signal. This makes it possible to reduce or remove an unpleasant vibration responsive to a human voice during vibration presentation with a multi-channel audio signal being used as an input.</p><heading id="h-0011" level="1">Third Embodiment</heading><p id="p-0151" num="0143">The first and second embodiments of the present technology remove or reduce voice in content and maintain the necessary vibration components as much as possible, but they may not be suitable depending on, for example, music content in which a rhythmic feeling is desirably expressed as vibration, or a subjective preference of the user.</p><p id="p-0152" num="0144">In this regard, there is provided a mechanism that allows the user to voluntarily select the implementation of the present technology. In this case, the control of activation/deactivation may be performed by software in a content transmitter (e.g., the external device <b>60</b> such as a smartphone, a television, or a game machine), or the control may be performed with an operation unit such as a hardware switch or button (not shown) provided to the casing <b>254</b> of the speaker apparatus <b>100</b>.</p><p id="p-0153" num="0145">A function of adjusting the degree of voice reduction may be provided in addition to the control of activation/deactivation. Equation (7) below shows an equation in which the degree of voice reduction is adjusted with respect to (Equation 4). (Equation 8) for (5.1 channel) and (Equation 9) for (7.1 channel) show the case of the multi-channel audio signals.</p><p id="p-0154" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>VM</i>(<i>t</i>)=<i>AL</i>(<i>t</i>)&#x2212;<i>AR</i>(<i>t</i>)&#xd7;Coeff &#x2003;&#x2003;(Equation 7)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0155" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>VM</i>(<i>t</i>)=&#x3b1;<i>FL</i>(<i>t</i>)+&#x3b2;<i>FR</i>(<i>t</i>)+&#x3b3;<i>SL</i>(<i>t</i>)+&#x3b4;<i>SR</i>(<i>t</i>)+&#x3b5;<i>SW</i>(<i>t</i>)+<i>FC</i>(<i>t</i>)&#xd7;Coeff &#x2003;&#x2003;(Equation 8)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0156" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>VM</i>(<i>t</i>)=&#x3b1;<i>FL</i>(<i>t</i>)+&#x3b2;<i>FR</i>(<i>t</i>)+&#x3b3;<i>SL</i>(<i>t</i>)+&#x3b4;<i>SR</i>(<i>t</i>)+&#x3b5;<i>SW</i>(<i>t </i>)+&#x3b8;<i>LB</i>(<i>t</i>)+&#x3bc;<i>RB</i>(<i>t</i>)+<i>FC</i>(<i>t</i>)&#xd7;Coeff &#x2003;&#x2003;(Equation 9)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0157" num="0146">Here, Coeff is a voice reduction coefficient and takes a positive real number of 1.0 or less. As Coeff becomes closer to 1.0, the voice reduction effect becomes better, and as Coeff becomes closer to 0, the voice reduction effect is reduced.</p><p id="p-0158" num="0147">In this embodiment, such an adjustment function is provided, so that the user can freely adjust the degree of voice reduction (i.e., the degree of vibration) in accordance with the user's own preference.</p><p id="p-0159" num="0148">The coefficients Coeff of (Equation 7), (Equation 8), and (Equation 9) are adjusted by the user in the external device <b>60</b>. The adjusted coefficient Coeff is input from the external device <b>60</b> to the subtraction section <b>93</b> (see <figref idref="DRAWINGS">FIG. <b>9</b></figref>).</p><p id="p-0160" num="0149">In the subtraction section <b>93</b>, the difference processing of the audio signal according to (Equation 7), (Equation 8), and (Equation 9) is performed in response to the number of input channels.</p><heading id="h-0012" level="1">Fourth Embodiment</heading><p id="p-0161" num="0150">In the above description, an embodiment has been described in which the vibration signal is generated from the audio signal to present the vibration to the user. In this embodiment, a case where a vibration signal independent of an audio signal is included as a configuration of future content will be described.</p><p id="p-0162" num="0151"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a schematic diagram showing stream data in a predetermined period of time (e.g., several milliseconds) relating to sound and vibration.</p><p id="p-0163" num="0152">Such stream data <b>121</b> includes a header <b>122</b>, audio data <b>123</b>, and vibration data <b>124</b>. The stream data <b>121</b> may include video data.</p><p id="p-0164" num="0153">The header <b>122</b> stores information about the entire frame, such as a sync word for recognizing the top of the stream, the overall data size, and information representing the data type. Each of the audio data <b>123</b> and the vibration data <b>124</b> is stored after the header <b>122</b>. The audio data <b>123</b> and the vibration data <b>124</b> are transmitted to the speaker apparatus <b>100</b> over time.</p><p id="p-0165" num="0154">Here, as an example, it is assumed that the audio data is left and right two-channel audio signals and that the vibration data is four-channel vibration signals.</p><p id="p-0166" num="0155">For example, voice sounds, sound effects, background sounds, and rhythms are set for those four channels. Each part such as a vocal, base, guitar, or drum of a music band may be set.</p><p id="p-0167" num="0156">The external device <b>60</b> is provided with user interface software (UI or GUI (external operation input section)) <b>131</b> for controlling the gain of audio/vibration signals (see <figref idref="DRAWINGS">FIG. <b>13</b></figref>). The user operates a control tool (e.g., slider) displayed on the screen to control the signal gain of each channel of the audio/signals.</p><p id="p-0168" num="0157">Thus, the gain of the channel corresponding to the vibration signal that the user feels unfavorable among the output vibration signals is reduced, and thus the user can reduce or remove an unpleasant vibration according to the user's own preference.</p><p id="p-0169" num="0158">As described above, in this embodiment, when the audio signal and the vibration signal are independently received, a channel, by which vibration is not desired to be provided, among the vibration signal channels used for vibration presentation, is controlled on the user interface, thereby muting or reducing the vibration. This allows the user to reduce or remove an unpleasant vibration in accordance with the user's own preference.</p><p id="p-0170" num="0159">&#x3c;Other Technologies&#x3e;</p><p id="p-0171" num="0160">In the first embodiment described above, the description has been made with respect to the two-channel stereo sound that is most frequently used in the existing content, but it is also conceivable that the content of one-channel monaural sound is processed in some cases.</p><p id="p-0172" num="0161">In this case, since the difference processing of the left and right channels is impossible, it is conceivable that the component of a human voice is estimated and removed. For example, a technique of separating a monaural channel sound source may be used. Specifically, a non-negative matrix factorization (NMF) and a robust principal component analysis (RPCA) are used. Using those techniques, the signal component of the human voice is estimated, and the estimated signal component is subtracted from VM(t) in Equation 1 to reduce the vibration resulting from the voice.</p><p id="p-0173" num="0162">Note that the present technology may also take the following configurations.<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0163">(1) A control apparatus, including:</li></ul></p><p id="p-0174" num="0164">an audio control section that generates audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component; and</p><p id="p-0175" num="0165">a vibration control section that generates a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels.<ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0166">(2) The control apparatus according to (1), in which</li></ul></p><p id="p-0176" num="0167">the vibration control section limits a band of the audio signals of the plurality of channels or a difference signal of the audio signals of the plurality of channels to a first frequency or less.<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0168">(3) The control apparatus according to (2), in which</li></ul></p><p id="p-0177" num="0169">the vibration control section outputs, as the vibration control signal,<ul id="ul0004" list-style="none">    <li id="ul0004-0001" num="0000">    <ul id="ul0005" list-style="none">        <li id="ul0005-0001" num="0170">a monaural signal obtained by mixing the audio signals of the respective channels for an audio signal having a frequency equal to or lower than a second frequency lower than the first frequency among the audio signals of the plurality of channels, and</li>        <li id="ul0005-0002" num="0171">the difference signal for an audio signal exceeding the second frequency and being equal to or lower than the first frequency among the audio signals of the plurality of channels.</li>    </ul>    </li>    <li id="ul0004-0002" num="0172">(4) The control apparatus according to (2) or (3), in which</li></ul></p><p id="p-0178" num="0173">the first frequency is 500 Hz or less.<ul id="ul0006" list-style="none">    <li id="ul0006-0001" num="0174">(5) The control apparatus according to (3), in which    <ul id="ul0007" list-style="none">        <li id="ul0007-0001" num="0175">the second cutoff frequency is 150 Hz or less.</li>    </ul>    </li>    <li id="ul0006-0002" num="0176">(6) The control apparatus according to any one of (1) to (5), in which</li></ul></p><p id="p-0179" num="0177">the first audio component is a voice sound.<ul id="ul0008" list-style="none">    <li id="ul0008-0001" num="0178">(7) The control apparatus according to any one of (1) to (6), in which</li></ul></p><p id="p-0180" num="0179">the second audio component is a sound effect and a background sound.<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0180">(8) The control apparatus according to any one of (1) to (7), in which</li></ul></p><p id="p-0181" num="0181">the audio signals of the two channels are audio signals of left and right channels.<ul id="ul0010" list-style="none">    <li id="ul0010-0001" num="0182">(9) The control apparatus according to any one of (1) to (8), in which</li></ul></p><p id="p-0182" num="0183">the vibration control section includes an adjustment section that adjusts a gain of the vibration control signal on the basis of an external signal.<ul id="ul0011" list-style="none">    <li id="ul0011-0001" num="0184">(10) The control apparatus according to (9), in which</li></ul></p><p id="p-0183" num="0185">the adjustment section is configured to be capable of switching between activation and deactivation of generation of the vibration control signal.<ul id="ul0012" list-style="none">    <li id="ul0012-0001" num="0186">(11) The control apparatus according to any one of (1) to (9), in which</li></ul></p><p id="p-0184" num="0187">the vibration control section includes an addition section that generates a monaural signal obtained by mixing the audio signals of the two channels.<ul id="ul0013" list-style="none">    <li id="ul0013-0001" num="0188">(12) The control apparatus according to any one of (1) to (11), in which</li></ul></p><p id="p-0185" num="0189">the vibration control section includes a subtraction section that takes a difference between the audio signals, and</p><p id="p-0186" num="0190">the subtraction section is configured to be capable of adjusting a degree of reduction of the difference.<ul id="ul0014" list-style="none">    <li id="ul0014-0001" num="0191">(13) A signal processing method, including:</li></ul></p><p id="p-0187" num="0192">generating audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component; and</p><p id="p-0188" num="0193">generating a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels.<ul id="ul0015" list-style="none">    <li id="ul0015-0001" num="0194">(14) A speaker apparatus, including:</li></ul></p><p id="p-0189" num="0195">an audio output unit;</p><p id="p-0190" num="0196">a vibration output unit;</p><p id="p-0191" num="0197">an audio control section that generates audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component, and drives the audio output unit; and</p><p id="p-0192" num="0198">a vibration control section that generates a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels, and drives the vibration output unit.</p><heading id="h-0013" level="1">REFERENCE SIGNS LIST</heading><p id="p-0193" num="0000"><ul id="ul0016" list-style="none">    <li id="ul0016-0001" num="0199"><b>1</b> control apparatus</li>    <li id="ul0016-0002" num="0200"><b>10</b> external network</li>    <li id="ul0016-0003" num="0201"><b>11</b> storage</li>    <li id="ul0016-0004" num="0202"><b>12</b> decoding section</li>    <li id="ul0016-0005" num="0203"><b>13</b> audio control section</li>    <li id="ul0016-0006" num="0204"><b>14</b> tactile (vibration) control section</li>    <li id="ul0016-0007" num="0205"><b>15</b> audio output section</li>    <li id="ul0016-0008" num="0206"><b>16</b> tactile (vibration) output section</li>    <li id="ul0016-0009" num="0207"><b>20</b>, <b>22</b> speaker section</li>    <li id="ul0016-0010" num="0208"><b>21</b> oscillator</li>    <li id="ul0016-0011" num="0209"><b>60</b> external device</li>    <li id="ul0016-0012" num="0210"><b>80</b> tactile presentation apparatus</li>    <li id="ul0016-0013" num="0211"><b>100</b>, <b>200</b>, <b>300</b> speaker apparatus</li>    <li id="ul0016-0014" num="0212"><b>100</b>C coupler</li>    <li id="ul0016-0015" num="0213"><b>100</b>L left speaker</li>    <li id="ul0016-0016" num="0214"><b>100</b>R right speaker</li>    <li id="ul0016-0017" num="0215"><b>250</b> audio output unit</li>    <li id="ul0016-0018" num="0216"><b>251</b> tactile (vibration) presentation unit</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A control apparatus, comprising:<claim-text>an audio control section that generates audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component; and</claim-text><claim-text>a vibration control section that generates a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the vibration control section limits a band of the audio signals of the plurality of channels or a difference signal of the audio signals of the plurality of channels to a first frequency or less.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The control apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the vibration control section outputs, as the vibration control signal,<claim-text>a monaural signal obtained by mixing the audio signals of the respective channels for an audio signal having a frequency equal to or lower than a second frequency lower than the first frequency among the audio signals of the plurality of channels, and</claim-text><claim-text>the difference signal for an audio signal exceeding the second frequency and being equal to or lower than the first frequency among the audio signals of the plurality of channels.</claim-text></claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The control apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the first frequency is 500 Hz or less.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The control apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the second cutoff frequency is 150 Hz or less.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first audio component is a voice sound.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the second audio component is a sound effect and a background sound.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the audio signals of the two channels are audio signals of left and right channels.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the vibration control section includes an adjustment section that adjusts a gain of the vibration control signal on a basis of an external signal.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The control apparatus according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein<claim-text>the adjustment section is configured to be capable of switching between activation and deactivation of generation of the vibration control signal.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the vibration control section includes an addition section that generates a monaural signal obtained by mixing the audio signals of the two channels.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The control apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the vibration control section includes a subtraction section that takes a difference between the audio signals, and</claim-text><claim-text>the subtraction section is configured to be capable of adjusting a degree of reduction of the difference.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A signal processing method, comprising:<claim-text>generating audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component; and</claim-text><claim-text>generating a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A speaker apparatus, comprising:<claim-text>an audio output unit;</claim-text><claim-text>a vibration output unit;</claim-text><claim-text>an audio control section that generates audio control signals of a plurality of channels with audio signals of the plurality of channels as input signals, the audio signals each including a first audio component and a second audio component different from the first audio component, and drives the audio output unit; and</claim-text><claim-text>a vibration control section that generates a vibration control signal for vibration presentation by taking a difference between audio signals of two channels among the plurality of channels, and drives the vibration output unit.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003838A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003838</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363643</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>484</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>254</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>48</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>86</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>894</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>484</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>254</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00624</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00362</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>7</main-group><subgroup>4802</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>86</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>894</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">TIME-OF-FLIGHT (TOF) LASER CONTROL FOR ELECTRONIC DEVICES</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Sony Semiconductor Solutions Corporation</orgname><address><city>Kanagawa</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Xu</last-name><first-name>Jianming</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Xiao</last-name><first-name>Sa</first-name><address><city>Valkenswaard</city><country>NL</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Time-of-flight laser control for electronic devices. In one implementation, an electronic device includes a memory, a time-of-flight (TOF) sensor system including a TOF sensor, and a laser, and an electronic processor. The electronic processor is configured to control the laser to emit initial light pulses above a threshold emission level for a predetermined period of time, receive the depth information based on the initial light pulses emitted by the laser, determine whether a living object is in a nominal hazard zone of the laser based on the depth information, responsive to determining that the living object is not in the nominal hazard zone of the laser, control the laser to emit additional light pulses above the threshold emission level, wherein the laser has a specific laser classification, and wherein the threshold emission level is above an ANSI Z136.1 specification threshold emission level for the specific laser classification.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="89.58mm" wi="158.75mm" file="US20230003838A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="224.45mm" wi="195.83mm" file="US20230003838A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="215.22mm" wi="115.91mm" file="US20230003838A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="215.22mm" wi="172.30mm" file="US20230003838A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="188.21mm" wi="179.49mm" file="US20230003838A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="235.37mm" wi="140.72mm" file="US20230003838A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="236.81mm" wi="185.25mm" file="US20230003838A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="238.59mm" wi="192.28mm" file="US20230003838A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="217.17mm" wi="171.96mm" orientation="landscape" file="US20230003838A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="240.71mm" wi="200.15mm" file="US20230003838A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND OF THE INVENTION</heading><heading id="h-0002" level="1">1. Field of the Invention</heading><p id="p-0002" num="0001">This application relates generally to time-of-flight (TOF) sensors. More specifically, this application relates to laser controls for electronic devices including TOF sensors.</p><heading id="h-0003" level="1">2. Description of Related Art</heading><p id="p-0003" num="0002">Nowadays handheld device usage (e.g., mobile phones, tablets, top set controllers, etc.) is more popular than ever. To increase user satisfaction and improve handheld device performance, TOF sensor systems have been included in handheld devices. TOF sensor systems include a TOF sensor and a laser that issues a series of laser pulses. The TOF sensor uses the laser signal reflected from an object or scene to accurately generate depth information of the scene and distance between the electronic device and the target.</p><p id="p-0004" num="0003">However, laser light poses safety risks to human beings, and the potential for eye damage is often the modality that requires the most stringent regulation for laser device use. In controlled environments, laser safety may be practiced via laser administration regulations (such as interlock inside laser device apparatus, etc.) and laser safety personal protection (such as wearing laser protection goggles, etc.).</p><p id="p-0005" num="0004">Laser safety guidelines are specified in ANSI Z136.1 specification. Maximum Permissible Exposure (MPE (&#x3bb;, T)) is the highest power or energy density of the laser source that is considered safe and has negligible probability of causing any damage to the eye. MPE values are the design criterion in laser safety control. MPE value is related to laser wavelength, laser emission power and the amount of laser exposure time to human beings.</p><p id="p-0006" num="0005">Conventionally, a photoelectric signal time length is used as a criterion to determine laser working status or laser energy level. A preset time length threshold is used to turn off the laser if the measured time length exceeds the threshold value. However, the photoelectric signal time length does not clearly relate to laser eye safety class specification and calibration.</p><heading id="h-0004" level="1">BRIEF SUMMARY OF THE INVENTION</heading><p id="p-0007" num="0006">The present disclosure addresses the above-noted shortcomings and provides an implementation method that, preferably, is ANSI laser safety specification classified and calibrated. The present disclosure also addresses handheld devices TOF sensor system usage situations in uncontrolled environments.</p><p id="p-0008" num="0007">Specifically, the present disclosure uses image processing and neural network logic to identify the presence of living objects (and in particular, living humans) in the scene. Coupled with an ambient light sensor to select eye pupil apertures, and parallel to TOF depth information measurement, the present disclosure achieves adaptable laser energy emission and laser safety control.</p><p id="p-0009" num="0008">The assembly of the present disclosure is small in footprint and is a simple and cost-effective approach in TOF handheld device applications. The assembly of the present disclosure is also field upgradable due to data processing and control algorithms in an on-chip package, in an image signal processor package (ISP), in an electronic processor (e.g., a micro-processor or a micro-controller) on a local printed circuit board (PCB), or in a remote platform via a serial bus (e.g., I2C/SPI).</p><p id="p-0010" num="0009">To achieve the best device performance under MPE specification consideration, the laser emission power and integration time is controlled to provide better image quality and accurate depth information measurement while complying with the ANSI Z136.1 specification. Various aspects of the present disclosure relate to TOF laser control for electronic devices.</p><p id="p-0011" num="0010">In one aspect of the present disclosure, there is provided an electronic device comprising a memory, a time-of-flight (TOF) sensor system, and an electronic processor. The memory storing a list of laser classifications and corresponding maximum permissible exposure (MPE) values. The TOF sensor system including a TOF sensor configured to generate depth information from light reflected of one or more objects, and a laser configured to emit light pulses. The electronic processor is configured to control the laser to emit initial light pulses above a threshold emission level for a predetermined period of time, receive the depth information that is generated by the TOF sensor, the depth information based on the initial light pulses emitted by the laser, determine whether a living object is in a nominal hazard zone of the laser based on the depth information, responsive to determining that the living object is not in the nominal hazard zone of the laser, control the laser to emit additional light pulses above the threshold emission level, wherein the laser has a specific laser classification, and wherein the threshold emission level is above an ANSI Z136.1 specification threshold emission level for the specific laser classification.</p><p id="p-0012" num="0011">In another aspect of the present disclosure, there is provided a method. The method includes controlling, with an electronic processor, a laser to emit initial light pulses above a threshold emission level for a predetermined period of time. The method includes receiving, with the electronic processor, depth information that is generated by a TOF sensor, the depth information based on the initial light pulses emitted by the laser. The method includes determining, with the electronic processor, whether a living object is in a nominal hazard zone of the laser based on the depth information. The method also includes responsive to determining that the living object is not in the nominal hazard zone of the laser, controlling, with the electronic processor, the laser to emit additional light pulses above the threshold emission level. The laser has a specific laser classification and the threshold emission level is above an ANSI Z136.1 specification threshold emission level for the specific laser classification.</p><p id="p-0013" num="0012">In yet another aspect of the present disclosure, there is provided a non-transitory computer-readable medium. The set of operations includes controlling a laser to emit initial light pulses above a threshold emission level for a predetermined period of time. The set of operations includes receiving depth information that is generated by a TOF sensor, the depth information based on the initial light pulses emitted by the laser. The set of operations includes determining whether a living object is in a nominal hazard zone of the laser based on the depth information. The set of operations also includes responsive to determining that the living object is not in the nominal hazard zone of the laser, controlling the laser to emit additional light pulses above the threshold emission level. The laser has a specific laser classification and the threshold emission level is above an ANSI Z136.1 specification threshold emission level for the specific laser classification.</p><p id="p-0014" num="0013">In this manner, the above aspects of the present disclosure provide for improvements in at least the technical field of imaging, as well as the related technical fields of signal processing, image processing, and the like.</p><p id="p-0015" num="0014">This disclosure can be embodied in various forms, including hardware or circuits controlled by computer-implemented methods, computer program products, computer systems and networks, user interfaces, and application programming interfaces; as well as hardware-implemented methods, signal processing circuits, image sensor circuits, application specific integrated circuits, field programmable gate arrays, and the like. The foregoing summary is intended solely to give a general idea of various aspects of the present disclosure, and does not limit the scope of the disclosure in any way.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">DESCRIPTION OF THE DRAWINGS</heading><p id="p-0016" num="0015">These and other more detailed and specific features of various embodiments are more fully disclosed in the following description, reference being had to the accompanying drawings, in which:</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is block diagram that illustrates a time-of-flight (TOF) sensor environment, in accordance with various aspects of the present disclosure;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram that illustrates a process for monitoring the laser and laser control, in accordance with various aspects of the present disclosure;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of illustrating a process that is a balanced approach between laser energy emission and laser safety control, in accordance with various aspects of the present disclosure;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart that illustrates a derivation of the allowable laser emission energy, in accordance with various aspects of the present disclosure;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram that illustrates a calibration of a TOF laser module L-I (laser light intensity vs. laser driver current) curve, in accordance with various aspects of the present disclosure;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating a process for laser current sensing and data acquisition and processing with the electronic device <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in accordance with various aspects of the present disclosure;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a circuit diagram illustrating a first example of the current sensing apparatus <b>114</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in accordance with various aspects of the present disclosure;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a circuit diagram illustrating a second example of the current sensing apparatus <b>114</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in accordance with various aspects of the present disclosure;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a circuit diagram illustrating a third example of the current sensing apparatus <b>114</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in accordance with various aspects of the present disclosure;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a circuit diagram illustrating an example of ambient light detection circuitry, in accordance with various aspects of the present disclosure;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart that illustrates a first example process of the data processing and laser safety control block in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in accordance with various aspects of the present disclosure;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart that illustrates a second example process of the data processing and laser safety control block in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in accordance with various aspects of the present disclosure;</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref> are flowcharts illustrating examples of a neural network that determines whether a living object exists in a scene, in accordance with various aspects of the present disclosure; and</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart that illustrates an example of the data processing and laser safety control performed by an off-chip electronic processor, in accordance with various aspects of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0031" num="0030">In the following description, numerous details are set forth, such as flowcharts, data tables, and system configurations. It will be readily apparent to one skilled in the art that these specific details are merely exemplary and not intended to limit the scope of this application.</p><p id="p-0032" num="0031">Moreover, while the present disclosure focuses mainly on examples in which the processing circuits are used in mobile, it will be understood that this is merely one example of an implementation. It will further be understood that the disclosed systems and methods can be used in any device in which there is a need to perform laser safety with TOF sensors. Furthermore, the TOF sensor system implementations described below may be incorporated into an electronic apparatus, including but not limited to a smartphone, a tablet computer, a laptop computer, and the like.</p><p id="p-0033" num="0032">TOF Sensor Environment</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is block diagram that illustrates a time-of-flight (TOF) sensor environment <b>10</b>, in accordance with various aspects of the present disclosure. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the TOF sensor environment <b>10</b> includes an electronic device <b>100</b> and a scene <b>102</b>. The electronic device <b>100</b> includes an electronic processor <b>104</b>, a memory <b>106</b>, and a TOF sensor system <b>108</b> including a TOF sensor <b>110</b>, a laser <b>112</b>, and a current sensing apparatus <b>114</b>.</p><p id="p-0035" num="0034">In some embodiments, the electronic device <b>100</b> may include fewer or additional components in configurations different from that illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Also, the electronic device <b>100</b> may perform additional functionality than the functionality described herein. In addition, the functionality of the electronic device <b>100</b> may be at least partly incorporated into a server or other electronic devices. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the electronic processor <b>104</b>, the memory <b>106</b>, and the TOF sensor system <b>106</b> are electrically coupled by one or more control or data buses enabling communication between the components.</p><p id="p-0036" num="0035">The electronic processor <b>104</b> (e.g., microprocessor, application specification integrated circuit (ASIC), field-programmable gate array (FPGA), or other suitable electronic processor) executes machine-readable instructions stored in the memory <b>106</b>. For example, the electronic processor <b>104</b> may execute instructions stored in the memory <b>106</b> to perform the functionality described herein.</p><p id="p-0037" num="0036">The memory <b>106</b> may include a program storage area (for example, read only memory (ROM)) and a data storage area (for example, random access memory (RAM), and/or other non-transitory, machine-readable media). In some examples, the program storage area may store the instructions to perform some or all of the functions and processes described herein.</p><p id="p-0038" num="0037">The TOF sensor system <b>108</b> includes a TOF sensor <b>110</b>, a laser <b>112</b>, and a current sensing apparatus <b>114</b>. The TOF sensor <b>110</b> is configured to receive light pulses reflected off of an object and generate depth information between the electronic device <b>100</b> and the object. The laser <b>112</b> is configured to emit the light pulses that are reflected off the object. In some examples, the laser <b>112</b> may be a vertical-cavity surface-emitting laser (VCSEL), a single laser diode, or other single laser type. In other examples, the laser <b>112</b> may be a matrix laser or other multi-laser type. In yet other examples, the laser <b>112</b> is generally a semiconductor-based laser.</p><p id="p-0039" num="0038">The current sensing apparatus <b>114</b> is configured to sense a laser current being used by the laser <b>112</b>. The current sensing apparatus <b>114</b> is described and illustrated in greater detail below with respect to <figref idref="DRAWINGS">FIGS. <b>7</b>-<b>9</b></figref>.</p><p id="p-0040" num="0039">The scene <b>102</b> includes an object <b>116</b>. The object <b>116</b> may be a living object or a non-living object. When the object <b>116</b> is a living object, the object <b>116</b> may also be a living human or other living object that is not human (e.g., animals, trees, or other living objects that are not human).</p><p id="p-0041" num="0040">Laser Safety Control</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram that illustrates a process <b>200</b> for monitoring the laser and laser control, in accordance with various aspects of the present disclosure. In the example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the process <b>200</b> includes a determination of maximum permissible exposure (MPE) process <b>202</b>, a determination of nominal hazard zone process (NHZ) <b>204</b>, a determination of total laser energy allowed for certain laser safety class process <b>206</b>, a laser L-I curve calibration process <b>208</b>, a laser current sensing and digitization process <b>210</b>, and data processing and laser safety control process <b>212</b>.</p><p id="p-0043" num="0042">Input parameters are provided to the determination of MPE process <b>202</b> and the determination of NHZ process <b>204</b>. In some examples, the input parameters may include laser safety class specification, laser characteristics (wavelength, beam diameter, divergence, laser duty cycle, laser maximum power, or other suitable laser characteristics), TOF optical path (diffuse or specular window and its attenuation), and/or limited eye pupil apertures corresponding to different ambient light situations.</p><p id="p-0044" num="0043">The determination of MPE process <b>202</b> determines MPE values from the input parameters. The determination of NHZ process <b>204</b> determines the nominal hazard zone value from the input parameters. The determination of total laser energy allowed for certain laser safety class process <b>206</b> uses the MPE values that are determined and the NHZ that is determined. The determination of total laser energy allowed for certain laser safety class process <b>206</b> determines a tabulated exposure time and Maximum Permissible Exposure values. Specifically, the determination of total laser energy allowed for certain laser safety class process <b>206</b> outputs a tabulated total allowable laser energy values corresponding to certain (MPE (&#x3bb;, T)) values under nominal hazard zone value and certain exposure time.</p><p id="p-0045" num="0044">The laser L-I curve calibration process <b>208</b> calibrates function parameters for a light-current curve that characterizes the required emission properties of the laser <b>112</b> from the tabulated total allowable laser energy values corresponding to certain (MPE (&#x3bb;, T)) values under nominal hazard zone value and certain exposure time.</p><p id="p-0046" num="0045">The laser current sensing and digitization process <b>210</b> senses laser current with a current sensing apparatus within the TOF sensor and monitors laser driver current in real-time. The laser current sensing and digitization process <b>210</b> also digitizes the laser current and provides the digitized data to the electronic processor <b>104</b> for the data processing and laser safety control process <b>212</b>. The electronic processor <b>104</b> receives the digitized data, image data, and TOF depth information to monitor and control laser light emission by the laser <b>112</b>.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of illustrating a process <b>300</b> that is a balanced approach between laser energy emission and laser safety control, in accordance with various aspects of the present disclosure. In the example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the process <b>300</b> includes the laser <b>112</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> sending laser pulses with an energy level above a safety threshold level for a short time (at block <b>302</b>). Even though the initial laser pulses have the energy level above the safety threshold, the short period of time (e.g., 100 microseconds) is preferably arranged to be short enough to maintain the total laser energy emitted to be well within the safety requirements set forth by the ANSI Z136.1 specification.</p><p id="p-0048" num="0047">While sending the laser pulses (or shortly after), the process <b>300</b> includes the electronic processor <b>104</b> obtaining a red-green-blue (RGB) image and/or a near-infrared (near-IR) image for image processing (at block <b>304</b>). Responsive to obtaining the RGB image and/or the near-IR image, the electronic processor <b>104</b> determines whether a living object is in the nominal hazard zone (decision block <b>306</b>). For example, the electronic processor <b>104</b> performs image processing to identify the living object and determines whether the living object that is identified is in the nominal hazard zone.</p><p id="p-0049" num="0048">Responsive to determining that the living object is in the nominal hazard zone (&#x201c;YES&#x201d; at decision block <b>306</b>), the electronic processor <b>104</b> controls the laser <b>112</b> to reduce the laser emission energy to a laser safety level and continually send laser pulses at the reduced laser emission energy level for a determined integration time (at block <b>308</b>). After the determined integration time expires, the electronic processor <b>104</b> controls the laser <b>112</b> to obtain the RGB image and/or IR image and depth information (at block <b>310</b>) and then repeats the process <b>300</b> (at block <b>302</b>). Responsive to determining that the living is not in the nominal hazard zone (&#x201c;NO&#x201d; at decision block <b>306</b>), the electronic processor <b>104</b> controls the laser <b>112</b> to maintain the laser emission energy above the laser safety level for better image and depth measurement accuracy and until the setting integration time (i.e., the exposure time) is completed (at block <b>312</b>) and then repeats the process <b>300</b> (at block <b>302</b>).</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart that illustrates a derivation <b>400</b> of the allowable laser emission energy, in accordance with various aspects of the present disclosure. In the example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the derivation <b>400</b> includes the electronic processor <b>104</b> determines a plurality of laser characteristics of the laser <b>112</b> (at block <b>402</b>). For example, the electronic processor <b>104</b> determines the laser wavelength, the pulse frequency, waveform, duty cycle, and the laser safety class of the laser <b>112</b>.</p><p id="p-0051" num="0050">The derivation <b>400</b> includes the electronic processor <b>104</b> determining the MPE value after determining the laser wavelength, the laser pulse operation frequency, the laser safety class (at block <b>404</b>).</p><p id="p-0052" num="0051">After determining the MPE value, the electronic processor <b>104</b> determines a series of integration time (at block <b>406</b>) and determines a series of laser permissible irradiances corresponding to the series of integration time T that is determined (at block <b>408</b>).</p><p id="p-0053" num="0052">After determining the series of laser permissible irradiances corresponding to the series of the integration time T, the electronic processor <b>104</b> determines eye pupil aperture parameters corresponding to different ambient light situations (at block <b>410</b>) and determines a series of allowable laser emission energies at object site based on the eye pupil aperture parameters corresponding to different ambient light conditions and the series of permissible irradiances (at block <b>412</b>).</p><p id="p-0054" num="0053">After obtaining the series of allowable laser emission energies at the object site, the electronic processor <b>104</b> determines laser beam characteristics, TOF optical path parameters, and optic effective gain (at block <b>414</b>) and determines a series of allowable laser emission energies at the laser <b>112</b> with the laser beam characteristics, the TOF module optical path parameters, and the optic effective gain (at block <b>416</b>).</p><p id="p-0055" num="0054">The electronic processor <b>104</b> outputs a tabulated data set of allowable laser emission energies and laser safety zone distances (at block <b>418</b>). In some examples, the tabulated data set is stored in non-volatile memory for laser safety classification and laser emission energy control by the electronic processor <b>104</b>.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram that illustrates a calibration <b>500</b> of a TOF laser module L-I (laser light intensity vs. laser driver current) curve, in accordance with various aspects of the present disclosure. In the example of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the calibration <b>500</b> includes a computer <b>502</b>, an optical power meter <b>504</b>, a laser diode driver <b>506</b>, a TOF laser <b>508</b>, a current sensing apparatus <b>510</b>, a temperature monitoring apparatus <b>512</b>, and an integrating sphere <b>514</b>.</p><p id="p-0057" num="0056">The computer <b>502</b> controls the laser diode driver <b>506</b> to drive the TOF laser <b>508</b> to emit a range of light intensities while in parallel measuring the laser current with the current sensing apparatus <b>510</b> and the temperature with the temperature monitoring apparatus <b>512</b>. The computer <b>502</b> also communicates with the optical power meter <b>504</b> to a collect a series of data corresponding to a range of light intensities emitted by the TOF laser <b>508</b> and diffused by the integrating sphere <b>514</b>.</p><p id="p-0058" num="0057">The computer <b>502</b> receives the range of light intensities measured by the optical power meter <b>504</b> and the corresponding laser currents measured by the current sensing apparatus <b>510</b>. The computer <b>502</b> generates the L-I curve from the range of light intensities measured by the optical power meter <b>504</b> and the corresponding laser currents measured by the current sensing apparatus <b>510</b>.</p><p id="p-0059" num="0058">After the calibration <b>500</b>, the L-I curve function parameters are stored in the memory <b>106</b> of the electronic device <b>100</b> for the purpose of laser safety monitoring and controlling. In the example of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the laser driver current is monitored by laser current sensing apparatus in the electronic device <b>100</b>, along with an ambient light sensor for eye pupil aperture parameter selection in determining laser safety classification and laser emission energy control.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating a process for laser current sensing and data acquisition and processing with the electronic device <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in accordance with various aspects of the present disclosure. In the example of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the process <b>600</b> includes current sensing detection <b>602</b>, signal amplification <b>604</b>, signal digitization <b>606</b>, and signal processing and laser safety control <b>608</b>.</p><p id="p-0061" num="0060">The electronic device <b>100</b> uses the current sensing apparatus <b>114</b> to sense the laser current (at block <b>602</b>). The electronic device <b>100</b> uses a signal amplifier to amplify the laser signal (at block <b>604</b>). The electronic device <b>100</b> uses an analog-to-digital converter (ADC) to convert the amplified laser signal from an analog signal to a digital signal (at block <b>606</b>). The electronic device <b>100</b> then performs signal processing and laser safety control based on the signal processing (at block <b>608</b>).</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a circuit diagram illustrating a first example <b>700</b> of the current sensing apparatus <b>114</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in accordance with various aspects of the present disclosure. In the first example <b>700</b>, the current sensing apparatus <b>114</b> is a single shunt resistor <b>702</b> connected to a signal amplifier <b>704</b> to convert the current-sensing resistor's differential signal to a single-ended signal. The output of amplifier <b>704</b> is sent to an analog-to-digital (ADC) <b>706</b> that is connected to a processor <b>708</b>.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a circuit diagram illustrating a second example <b>800</b> of the current sensing apparatus <b>114</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in accordance with various aspects of the present disclosure. In the second example <b>800</b>, the current sensing apparatus <b>114</b> is a shunt resistor <b>802</b> connected to a digital current monitor (INA226) <b>804</b>.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a circuit diagram illustrating a third example <b>900</b> of the current sensing apparatus <b>114</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in accordance with various aspects of the present disclosure. In the third example <b>900</b>, the current sensing apparatus <b>114</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> includes two shunt resistors <b>902</b> and <b>904</b>, a load <b>906</b>, and a current sensing integrating circuit <b>908</b> that handles the mathematical processing of current-sensing data accumulation and averaging, freeing up the processor (e.g., electronic processor <b>104</b>) for other system tasks.</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a circuit diagram illustrating an example of ambient light detection circuitry <b>1000</b>, in accordance with various aspects of the present disclosure. In the example of <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the ambient light detection circuitry <b>1000</b> includes a photodiode <b>1002</b> and transimpedance amplifier <b>1004</b> to convert the light signal from the photodiode <b>1002</b> to an analog voltage that may be further converted to a digital data with an analog-to-digital converter (ADC) and provided to an electronic processor for selection of corresponding eye pupil aperture stored in memory <b>106</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0066" num="0065">However, the ambient light detection circuitry <b>1000</b> is not limited to the above example. The ambient light detection circuitry <b>1000</b> may be any circuitry that detects ambient light. For example, the ambient light detection circuitry <b>1000</b> may be a TOF sensor (e.g., the TOF sensor <b>110</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>) that uses one image frame without emitting laser light to detect the ambient light in the environment of the TOF sensor.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart that illustrates a first example process <b>1100</b> of the data processing and laser safety control block <b>212</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in accordance with various aspects of the present disclosure. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is described with respect to the electronic processor <b>104</b> and the memory <b>106</b> of the electronic device <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0068" num="0067">In the first example <b>1100</b>, the electronic processor <b>104</b> receives depth information (at block <b>1102</b>). The electronic processor <b>104</b> may calculate depth information from the IR image, or receive the depth information from block <b>1102</b>. While the electronic processor <b>104</b> calculates depth information, the depth information calculation by the electronic processor <b>104</b> may include a near-infrared (near-IR) image, a color (i.e., RGB) image, or a thermal image (at block <b>1104</b>).</p><p id="p-0069" num="0068">Responsive to receiving the depth information and the at least one of the near-IR image, the color image, or the thermal image, the electronic processor <b>104</b> uses logic (block <b>1106</b>) to determine whether to use the depth information by itself or use the depth information in combination with at least one of the near-IR image, the color image, or the thermal image.</p><p id="p-0070" num="0069">Responsive to determining whether to just use the depth information by itself or use the depth information in combination with the at least one of the near-IR image, the color image, or the thermal image, the electronic processor <b>104</b> uses a neural network (i.e., a pretrained model) to detect whether a living object is in a field-of-view (FOV) of the TOF sensor (at block <b>1108</b>). For example, the electronic processor <b>104</b> uses the neural network to detect a living object with just the depth information. Additionally, in some examples, the electronic processor <b>104</b> uses the neural network to detect that the living object is a living human with the depth information and in combination with the at least one of the near-IR image, the color image, or the thermal image. The neural network may be pretrained to detect eye movement, gestures, or other suitable human characteristics to determine whether the living object is a living human or not.</p><p id="p-0071" num="0070">Responsive to determining to that a living is in the FOV of the TOF sensor, the electronic processor <b>104</b>, receives sensor control information from sensor control circuitry (block <b>1110</b>), retrieves a look-up table from the memory <b>106</b> (block <b>1112</b>), and performs signal processing to determine whether the pixel data exceeds a certain energy level set in the look-up table (at block <b>1114</b>). The look-up table includes a list of laser classifications and corresponding safety laser emission levels.</p><p id="p-0072" num="0071">Specifically, when the electronic processor <b>104</b> detects a living human with the neural network, the electronic processor <b>104</b> uses the depth information and the sensor control information to calculate the laser energy level on the human body surface (at block <b>1116</b>). When the laser energy level exceeds a predefined level, the electronic processor <b>104</b> uses control logic (block <b>1116</b>) to trigger the sensor control circuitry (block <b>1110</b>) and single laser control circuitry (<b>1118</b>) to lower the emitted energy on the human surface.</p><p id="p-0073" num="0072">The neural network, signal processing, and control logic may be on a single chip, a separate ISP chip, or an off-chip processor that is locally assembled on the PCB board of the TOF sensor system, or on an electronic device platform via serial communication, such as SPI or I2C bus. For example, the neural network and control logic may be stored in the memory <b>106</b> and the signal processing may be performed by the electronic processor <b>104</b>.</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart that illustrates a second example process <b>1200</b> of the data processing and laser safety control block <b>212</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in accordance with various aspects of the present disclosure. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is described with respect to the electronic processor <b>104</b> and the memory <b>106</b> of the electronic device <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>12</b></figref> differs from <figref idref="DRAWINGS">FIG. <b>11</b></figref> in that the single laser control <b>1118</b> of <figref idref="DRAWINGS">FIG. <b>11</b></figref> is replaced with a laser matrix control <b>1202</b> that controls a matrix laser <b>1206</b> instead of the single laser <b>1120</b>. The matrix laser <b>1206</b> includes a plurality of lasers instead of a single laser.</p><p id="p-0076" num="0075">In the example of <figref idref="DRAWINGS">FIG. <b>12</b></figref>, when the electronic processor <b>104</b> determines that the laser energy level exceeds a predefined level at the certain detected living object location, the control logic (block <b>1204</b>) will either trigger the sensor control circuitry <b>1110</b> or trigger the area control for the matrix laser <b>1206</b> (or the spot control lasers) at a certain location. This control by the electronic processor <b>104</b> will lower the emitted energy on a specific detected human surface while maintaining the emitted energy on non-human surfaces.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref> are flowcharts illustrating examples <b>1300</b> and <b>1400</b> of a neural network that determines whether a living object exists in a scene, in accordance with various aspects of the present disclosure. <figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref> are described with respect to the electronic processor <b>104</b> and the memory <b>106</b> of the electronic device <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0078" num="0077">In the example <b>1300</b>, the scene <b>1302</b> includes plurality of trees. While trees are living objects, trees are not living humans. Therefore, the electronic processor <b>104</b> does not detect any living humans in the scene <b>1302</b> with the neural network <b>1304</b>. Consequently, the electronic processor <b>104</b> does change the emission level of the laser.</p><p id="p-0079" num="0078">In the example <b>1400</b>, the scene <b>1402</b> includes a person that moves in the scene <b>1404</b>. Therefore, the electronic processor <b>104</b> does detect a living human in the scenes <b>1402</b> and <b>1404</b> with the neural network <b>1406</b>. Consequently, the electronic processor <b>104</b> extracts the coordinates of the living human in the scenes <b>1402</b> and <b>1404</b> and outputs two bounding boxes coordinates and the detect human region-of-interest (ROI). In some examples, the electronic processor <b>104</b> may control the laser control circuitry to lower emissions of a portion of a plurality of lasers forming a matrix laser. The portion of the plurality of lasers corresponding to the lasers of the plurality of lasers that emit light at the bounding boxes coordinates.</p><p id="p-0080" num="0079">Additionally, in some examples, the bounding boxes coordinates may be aligned with TOF depth information to determine whether the living human is approaching closer to TOF sensor or away from the TOF sensor. In some examples, when the living human is approaching the TOF sensor, the electronic processor <b>104</b> may control the laser to further reduce laser emissions. In other examples, when the living human is moving away from the TOF sensor, the electronic processor <b>104</b> may control the laser to maintain or increase laser emissions.</p><p id="p-0081" num="0080"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart that illustrates an example <b>1500</b> of the data processing and laser safety control performed by an off-chip electronic processor, in accordance with various aspects of the present disclosure. In the example <b>1500</b>, the off-chip electronic processor accepts digitized current sensing data-in (block <b>1502</b>) via a communication bus (e.g., a SPI/I2C bus). The off-chip electronic processor stores the current sensing data-in in a circular buffer <b>1504</b>. The off-chip electronic processor has matching filtering (block <b>1506</b>) to filter the incoming data to reduce noise and increase signal data integrity. The off-chip electronic processor sends the filtered data to perform data summation (block <b>1508</b>) with an integration time (<b>1510</b>) input for the purpose of measurement accuracy and data integrity. At the same time, the off-chip electronic processor receives processed RGB image, IR image, or thermal image data (block <b>1512</b>) and depth information (block <b>1512</b>) (e.g., from ISP and TOF sensor, respectively) in which an indication of a potential living object is presented in the TOF sensor field-of-view (FOV) and within the laser safety hazard zone.</p><p id="p-0082" num="0081">The off-chip electronic processor then retrieves a set of laser safety thresholds (block <b>1514</b>) from the tabulated classifications (block <b>1516</b>) and used as comparison criteria for laser current classification (<b>1518</b>) and laser safety action (block <b>1520</b>). The logical laser safety actions include giving the user an audible or visible warning (block <b>1522</b>) (e.g., tell the user the device is too close for usage), adapting laser emission energy reduction through programmable setting procedures and values (block <b>1524</b>), or turning off the laser when a user ignores the audible or visible warning for the protection of the user and the user's subject (block <b>1526</b>). When the off-chip electronic processor determines that no living object is detected in the TOF sensor field-of-view within laser safety hazard zone, the laser will continue to emit laser pulses above laser safety threshold values from the perspective of increasing detecting signal-to-noise ratio value and enhancing TOF depth measurement accuracy.</p><heading id="h-0007" level="1">CONCLUSION</heading><p id="p-0083" num="0082">With regard to the processes, systems, methods, heuristics, etc. described herein, it should be understood that, although the steps of such processes, etc. have been described as occurring according to a certain ordered sequence, such processes could be practiced with the described steps performed in an order other than the order described herein. It further should be understood that certain steps could be performed simultaneously, that other steps could be added, or that certain steps described herein could be omitted. In other words, the descriptions of processes herein are provided for the purpose of illustrating certain embodiments, and should in no way be construed so as to limit the claims.</p><p id="p-0084" num="0083">Accordingly, it is to be understood that the above description is intended to be illustrative and not restrictive. Many embodiments and applications other than the examples provided would be apparent upon reading the above description. The scope should be determined, not with reference to the above description, but should instead be determined with reference to the appended claims, along with the full scope of equivalents to which such claims are entitled. It is anticipated and intended that future developments will occur in the technologies discussed herein, and that the disclosed systems and methods will be incorporated into such future embodiments. In sum, it should be understood that the application is capable of modification and variation.</p><p id="p-0085" num="0084">All terms used in the claims are intended to be given their broadest reasonable constructions and their ordinary meanings as understood by those knowledgeable in the technologies described herein unless an explicit indication to the contrary is made herein. In particular, use of the singular articles such as &#x201c;a,&#x201d; &#x201c;the,&#x201d; &#x201c;said,&#x201d; etc. should be read to recite one or more of the indicated elements unless a claim recites an explicit limitation to the contrary.</p><p id="p-0086" num="0085">The Abstract of the Disclosure is provided to allow the reader to quickly ascertain the nature of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition, in the foregoing Detailed Description, it can be seen that various features are grouped together in various embodiments for the purpose of streamlining the disclosure. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter lies in less than all features of a single disclosed embodiment. Thus the following claims are hereby incorporated into the Detailed Description, with each claim standing on its own as a separately claimed subject matter.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An electronic device comprising:<claim-text>a memory storing a list of laser classifications and corresponding maximum permissible exposure (MPE) values;</claim-text><claim-text>a time-of-flight (TOF) sensor system including<claim-text>a TOF sensor configured to generate depth information from light reflected of one or more objects, and</claim-text><claim-text>a laser configured to emit light pulses; and</claim-text></claim-text><claim-text>an electronic processor configured to<claim-text>control the laser to emit initial light pulses above a threshold emission level for a predetermined period of time,</claim-text><claim-text>receive the depth information that is generated by the TOF sensor, the depth information based on the initial light pulses emitted by the laser,</claim-text><claim-text>determine whether a living object is in a nominal hazard zone of the laser based on the depth information,</claim-text><claim-text>responsive to determining that the living object is not in the nominal hazard zone of the laser, control the laser to emit additional light pulses above the threshold emission level,</claim-text><claim-text>wherein the laser has a specific laser classification, and</claim-text><claim-text>wherein the threshold emission level is above an ANSI Z136.1 specification threshold emission level for the specific laser classification.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The electronic device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, to determine whether the living object is in the nominal hazard zone of the laser based on the depth information, the electronic processor is further configured to<claim-text>determine whether a living human is in the nominal hazard zone of the laser based on the depth information, and</claim-text><claim-text>responsive to determining that the living human is in the nominal hazard zone of the laser, control the laser to emit the additional light pulses below the threshold emission level.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The electronic device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic processor is further configured to determine whether a living human is in the nominal hazard zone of the laser with a neural network.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The electronic device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic processor is further configured to<claim-text>receive the depth information for image processing and at least one of near-infrared image, a red-green-blue (RGB) image, or a thermal image, and</claim-text><claim-text>determine whether the living object is in the nominal hazard zone of the laser based on the depth information and the at least one of the near-infrared image, the red-green-blue (RGB) image, or the thermal image.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The electronic device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, to control the laser to emit the additional light pulses above the threshold emission level, the electronic processor is further configured to<claim-text>retrieve the specific laser classification of the laser from the memory,</claim-text><claim-text>determine the corresponding MPE values associated with the specific laser classification,</claim-text><claim-text>process the depth information with the corresponding MPE values to determine whether the depth information indicates that an energy level of the additional light pulses should be increased, decreased, or maintained relative to the initial light pulses, and</claim-text><claim-text>responsive to determining that the depth information indicates that the energy level of the additional light pulses should be increased, control the laser to emit the additional light pulses at an increased emission level relative to an emission level of the initial light pulses,</claim-text><claim-text>responsive to determining that the depth information indicates that the energy level of the additional light pulses should be decreased, control the laser to emit the additional light pulses at a reduced emission level relative to the emission level of the initial light pulses, and</claim-text><claim-text>responsive to determining that the depth information indicates that the energy level of the additional light pulses should be maintained, control the laser to emit the additional light pulses at the emission level of the initial light pulses.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The electronic device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the laser is one of a single laser or a plurality of lasers forming an array of lasers.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The electronic device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the laser is the plurality of lasers forming the array of lasers, and<claim-text>wherein, to determine whether the living object is in the nominal hazard zone of the laser based on the depth information, the electronic processor is further configured to</claim-text><claim-text>determine whether a living human is in the nominal hazard zone of the laser based on the depth information,</claim-text><claim-text>responsive to determining that the living human is in the nominal hazard zone of the laser, generate coordinate bounding boxes of the living human,</claim-text><claim-text>responsive to generating the coordinate bounding boxes of the living human, identify a portion of the plurality of lasers that emit light in an area corresponding to the coordinate bounding boxes, and</claim-text><claim-text>control the portion of the plurality of lasers to emit the additional light pulses below the threshold emission level.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The electronic device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, to control the laser to emit the initial light pulses above the threshold emission level for the predetermined period of time, the electronic processor is further configured to<claim-text>retrieve a laser L-I curve from the memory, and</claim-text><claim-text>control the laser to emit the initial light pulses above the threshold emission level for the predetermined period of time based on the laser L-I curve.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The electronic device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>an ambient light sensor configured to detect ambient light in an environment sensed by the TOF sensor,</claim-text><claim-text>wherein the electronic processor is further configured to<claim-text>receive an ambient light detection value indicative of an amount of the ambient light detected in the environment from the ambient light sensor,</claim-text><claim-text>retrieve an eye pupil look-up table from the memory, and</claim-text><claim-text>select an eye pupil parameter based on the ambient light detection value, wherein the eye pupil parameter corresponds to an allowable laser light emission in the environment according to the ANSI Z136.1 specification threshold emission level for the specific laser classification.</claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The electronic device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a current sensing apparatus configured to measure and monitor a laser driver current of the laser,</claim-text><claim-text>wherein the current sensing apparatus is one of a shunt-based current-sensing circuit or non-radiometric magnetic sensing device.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A method comprising:<claim-text>controlling, with an electronic processor, a laser to emit initial light pulses above a threshold emission level for a predetermined period of time;</claim-text><claim-text>receiving, with the electronic processor, depth information that is generated by a TOF sensor, the depth information based on the initial light pulses emitted by the laser;</claim-text><claim-text>determining, with the electronic processor, whether a living object is in a nominal hazard zone of the laser based on the depth information; and</claim-text><claim-text>responsive to determining that the living object is not in the nominal hazard zone of the laser, controlling, with the electronic processor, the laser to emit additional light pulses above the threshold emission level,</claim-text><claim-text>wherein the laser has a specific laser classification, and</claim-text><claim-text>wherein the threshold emission level is above an ANSI Z136.1 specification threshold emission level for the specific laser classification.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein determining whether the living object is in the nominal hazard zone of the laser based on the depth information further includes<claim-text>determining whether a living human is in the nominal hazard zone of the laser based on the depth information, and</claim-text><claim-text>responsive to determining that the living human is in the nominal hazard zone of the laser, controlling the laser to emit the additional light pulses below the threshold emission level.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising determining whether a living human is in the nominal hazard zone of the laser with a neural network.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>receiving the depth information for image processing or from one of near-infrared image, or a red-green-blue (RGB) image, or a thermal image; and</claim-text><claim-text>determining whether the living object is in the nominal hazard zone of the laser based on the depth information and the near-infrared image, or the red-green-blue (RGB) image, or the thermal image.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein controlling the laser to emit the additional light pulses above the threshold emission level further includes<claim-text>retrieving the specific laser classification of the laser from a memory,</claim-text><claim-text>determining the corresponding MPE values associated with the specific laser classification,</claim-text><claim-text>processing the depth information with the corresponding MPE values to determine whether the depth information indicates that an energy level of the additional light pulses should be increased, decreased, or maintained relative to the initial light pulses,</claim-text><claim-text>responsive to determining that the depth information indicates that the energy level of the additional light pulses should be increased, controlling the laser to emit the additional light pulses at an increased emission level relative to an emission level of the initial light pulses,</claim-text><claim-text>responsive to determining that the depth information indicates that the energy level of the additional light pulses should be decreased, controlling the laser to emit the additional light pulses at a reduced emission level relative to the emission level of the initial light pulses, and</claim-text><claim-text>responsive to determining that the depth information indicates that the energy level of the additional light pulses should be maintained, controlling the laser to emit the additional light pulses at the emission level of the initial light pulses.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the laser is one of a single laser or a plurality of lasers forming an array of lasers.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the laser is the plurality of lasers forming the array of lasers, and<claim-text>wherein determining whether the living object is in the nominal hazard zone based on the depth information further includes</claim-text><claim-text>determining whether a living human is in the nominal hazard zone based on the depth information,</claim-text><claim-text>responsive to determining that the living human is in the nominal hazard zone, generating coordinate bounding boxes of the living human,</claim-text><claim-text>responsive to generating the coordinate bounding boxes of the living human, identifying a portion of the plurality of lasers that emit light in an area corresponding to the coordinate bounding boxes, and</claim-text><claim-text>controlling the portion of the plurality of lasers to emit the additional light pulses below the threshold emission level.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A non-transitory computer-readable medium comprising instructions that, when executed by an electronic processor, causes the electronic processor to perform a set of operations comprising:<claim-text>controlling a laser to emit initial light pulses above a threshold emission level for a predetermined period of time;</claim-text><claim-text>receiving depth information that is generated by a TOF sensor, the depth information based on the initial light pulses emitted by the laser;</claim-text><claim-text>determining whether a living object is in a nominal hazard zone of the laser based on the depth information; and</claim-text><claim-text>responsive to determining that the living object is not in the nominal hazard zone of the laser, controlling the laser to emit additional light pulses above the threshold emission level,</claim-text><claim-text>wherein the laser has a specific laser classification, and</claim-text><claim-text>wherein the threshold emission level is above an ANSI Z136.1 specification threshold emission level for the specific laser classification.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein determining whether the living object is in the nominal hazard zone of the laser based on the depth information further includes<claim-text>determining whether a living human is in the nominal hazard zone of the laser based on the depth information, and</claim-text><claim-text>responsive to determining that the living human is in the nominal hazard zone of the laser, controlling the laser to emit the additional light pulses below the threshold emission level.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable medium according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising:<claim-text>receiving an ambient light detection value indicative of an amount of an ambient light detected in an environment from an ambient light sensor;</claim-text><claim-text>retrieving an eye pupil look-up table from the memory; and</claim-text><claim-text>selecting an eye pupil parameter based on the ambient light detection value,</claim-text><claim-text>wherein the eye pupil parameter corresponds to an allowable laser light emission in the environment according to the ANSI Z136.1 specification threshold emission level for the specific laser classification.</claim-text></claim-text></claim></claims></us-patent-application>
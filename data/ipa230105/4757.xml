<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004758A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004758</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930774</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>62</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>6263</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>6259</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>7</main-group><subgroup>005</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20131203</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>40</main-group><subgroup>125</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">System and Method for Validating Data</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16778110</doc-number><date>20200131</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11475251</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17930774</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>The Toronto-Dominion Bank</orgname><address><city>Toronto</city><country>CA</country></address></addressbook><residence><country>CA</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MORIN</last-name><first-name>Nicholas Victor Laurence</first-name><address><city>Toronto</city><country>CA</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KUANG</last-name><first-name>Yunyu</first-name><address><city>Waterloo</city><country>CA</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>SHANMUGANANTHAM</last-name><first-name>Jathavi</first-name><address><city>Scarborough</city><country>CA</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>The Toronto-Dominion Bank</orgname><role>03</role><address><city>Toronto</city><country>CA</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system and method are provided for validating data. The method is executed by a device having a data interface coupled to a processor and includes obtaining a validation set comprising at least one validation case, each validation case comprising at least one test condition. The method also includes obtaining, via the data interface, at least one data set to be validated using the validation set. The method also includes applying the validation set to the at least one data set to validate the data in the data set by, for each record in the at least one data set, validating a value in the record according to the at least one test condition. The method also includes outputting a validation result for each record.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="114.05mm" wi="158.75mm" file="US20230004758A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="217.51mm" wi="163.49mm" orientation="landscape" file="US20230004758A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="220.56mm" wi="169.84mm" orientation="landscape" file="US20230004758A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="212.34mm" wi="163.32mm" orientation="landscape" file="US20230004758A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="212.34mm" wi="162.48mm" orientation="landscape" file="US20230004758A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="165.78mm" wi="143.51mm" orientation="landscape" file="US20230004758A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="208.53mm" wi="185.25mm" orientation="landscape" file="US20230004758A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="203.79mm" wi="185.34mm" orientation="landscape" file="US20230004758A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="240.71mm" wi="123.61mm" orientation="landscape" file="US20230004758A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="251.63mm" wi="123.61mm" orientation="landscape" file="US20230004758A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 16/778,110 filed Jan. 31, 2020, the contents of which are incorporated herein by reference in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The following relates generally to validating data.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Data that is generated for or by a process, and held or used by an organization, may be analyzed for various purposes such as to generate statistical reports, market insights, operational data, etc. Large quantities of statistical data may be generated by the organization during a period of time, e.g., on a quarterly basis. These large quantities of data may also need to be reviewed in a timely manner, e.g., to spot errors in the data and to flag or rectify those errors.</p><p id="p-0005" num="0004">It is found that in many cases these large quantities of data are reviewed manually, e.g., during testing cycles. Such a manual review is time consuming and can be labor intensive and inefficient. These testing and review cycles may also introduce significant delays in identifying an issue with the source of the data, by which time subsequent data may have been generated with the same or similar errors.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0006" num="0005">Embodiments will now be described with reference to the appended drawings wherein:</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram of an example computing environment.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of another example computing environment.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of an example configuration of a statistical analysis device.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of an example configuration of a validation device.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flow diagram illustrating an example of computer executable instructions for validating data.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow diagram illustrating an example of an example of computer executable instructions for.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram of an example of computer executable instructions for.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a graphical illustration of a list of validation test results with all conditions passing.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a graphical illustration of a list of validation test results having failed conditions.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0016" num="0015">It will be appreciated that for simplicity and clarity of illustration, where considered appropriate, reference numerals may be repeated among the figures to indicate corresponding or analogous elements. In addition, numerous specific details are set forth in order to provide a thorough understanding of the example embodiments described herein. However, it will be understood by those of ordinary skill in the art that the example embodiments described herein may be practiced without these specific details. In other instances, well-known methods, procedures and components have not been described in detail so as not to obscure the example embodiments described herein. Also, the description is not to be considered as limiting the scope of the example embodiments described herein.</p><p id="p-0017" num="0016">A system, devices and a process are provided to validate the results of statistical analyses that can eliminate at least some manual review that may be required on a periodic basis. The outputs of a statistical model (e.g., a scoring model) or any consistent data output can be analyzed using the process to flag problems and identify errors in the statistical results to enable an organization to investigate failures, e.g., via a notification, alert, or by interrupting a process that uses the results. The methodology described in greater detail below can also be used in a testing tool such that as statistical models are built and perfected, the testing tool can be used to determine whether the results are trending in the correct direction.</p><p id="p-0018" num="0017">In an implementation, the details to be validated in the data may be determined/defined in advance, prior to applying an automated validation process. Cases to be validated can be obtained from a possible unlimited number of sources. Statistical datasets to be validated may also be obtained from a possible unlimited number of sources. In one example, a dual looping structure may then be applied to validate the statistical data, with the output being a pass/fail result for each record or portion of the data that is analyzed.</p><p id="p-0019" num="0018">The methodology can also be adapted for a completely automated solution, in which the system can automatically derive the validation cases from existing statistical data. In the completely automated solution, details to be validated may be generated based on existing data sets that are made available to the process, which can be validated from a possible unlimited number of sources. The dual looping structure may also be applied to validate the statistical data and the pass/fail results can be output as feedback to the user, e.g., using a notification, alert, or process instructions such as an interruption or fault.</p><p id="p-0020" num="0019">The automated process may therefore analyze the results of an existing process to validate those results. The methodology can also be applied to incoming data that has not yet been statistically analyzed. Machine learning may also be used to train the system to determine the attributes of the data to be validated, in order to generate and improve the automated creation of validation sets.</p><p id="p-0021" num="0020">The process described herein can be applied to financial data (e.g., to determine how much capital to set aside according to regulatory requirements), as well as other types of data such as medical test results, research test data, or other statistical data that is to be validated.</p><p id="p-0022" num="0021">Certain example systems and methods described herein enable data such as statistical output data to be validated. In one aspect, there is provided a device for validating data. The device includes a processor, a data interface coupled to the processor, and a memory coupled to the processor. The memory stores computer executable instructions that when executed by the processor cause the processor to obtain, via the data interface, at least one data set to be validated using a validation set determined according to at least one test condition, wherein the at least one dataset is an output of at least one statistical analysis on at least one input data set; apply the validation set to the at least one data set to validate the data in the data set by, for at least one record in the at least one data set, validating the record according to the at least one test condition; and output a validation result for the data set.</p><p id="p-0023" num="0022">In another aspect, there is provided a method of validating data. The method is executed by a device having a data interface coupled to a processor and includes obtaining, via the data interface, at least one data set to be validated using a validation set determined according to at least one test condition, wherein the at least one dataset is an output of at least one statistical analysis on at least one input data set; applying the validation set to the at least one data set to validate the data in the data set by, for at least one record in the at least one data set, validating the record according to the at least one test condition; and outputting a validation result for the data set.</p><p id="p-0024" num="0023">In another aspect, there is provided non-transitory computer readable medium for validating data. The computer readable medium includes computer executable instructions for obtaining, via the data interface, at least one data set to be validated using a validation set determined according to at least one test condition, wherein the at least one dataset is an output of at least one statistical analysis on at least one input data set; applying the validation set to the at least one data set to validate the data in the data set by, for at least one record in the at least one data set, validating the record according to the at least one test condition; and outputting a validation result for the data set.</p><p id="p-0025" num="0024">In certain example embodiments, at least one validation case can be automatically derived by obtaining a sample data set, analyzing the sample data set, and identifying the at least one test condition from the analyzed sample data set.</p><p id="p-0026" num="0025">In certain example embodiments, at least one validation case can be derived by providing a user interface to enable manual entry of the at least one test condition.</p><p id="p-0027" num="0026">In certain example embodiments, at least one validation case can be obtained from a source, the source having previously derived the at least one test condition.</p><p id="p-0028" num="0027">In certain example embodiments, the device can obtain the sample data set, analyze the sample data set, and automatically identify all test conditions to be validated for the at least one data set to validate. The sample data set can be analyzed by applying an automated process that uses a model derived using a machine learning process.</p><p id="p-0029" num="0028">In certain example embodiments, a notification can be generated indicative of at least one failure to trigger an investigation of the data set.</p><p id="p-0030" num="0029">In certain example embodiments, validating the value in the record can include accessing a first record to be validated, incrementing through each of the at least one test condition to be validated for the first record and, for a second and any additional record to be validated, incrementing to a next record to increment through each of the at least one test condition. The validation results can include a pass or fail indication output as the validating increments through the values.</p><p id="p-0031" num="0030">In certain example embodiments, the data set can be generated using financial data. In certain example embodiments, each data set can include statistical results associated with use of a statistical model.</p><p id="p-0032" num="0031">In certain example embodiments, each data set can include incoming data to a process.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an exemplary computing environment <b>10</b> in which data from a data source <b>12</b> is processed, analyzed or otherwise examined by a statistical analysis module <b>14</b>. In this exemplary environment <b>10</b>, the statistical analysis module <b>14</b> is operated by a device (not shown) having a processor, memory, and an interface to or with the data source <b>12</b> and obtains or receives data sets from the data source <b>12</b> via such an interface. The statistical analysis module <b>14</b> examines the data to perform a statistical or other data analysis or data processing task to generate a statistical output <b>16</b> such as a summary, report, or notification displayed in a GUI of a software program used by an organization or individual. The statistical output <b>16</b> can take various forms dependent upon the requirements or preferences of the application in which the statistical analysis module <b>14</b> is being used.</p><p id="p-0034" num="0033">The statistical analysis may be done for internal monitoring or reporting for the organization or in response to a request, audit or other internal or external process <b>18</b> that uses the statistical output <b>16</b>. For example, the process <b>18</b> may include generating a model scoring report that uses internal and/or external data and is subsequently reported to an external authority or internal body, e.g., analyzing credit card balances, loans, and other customer borrowing activity to determine how much capital needs to be allocated to satisfy a regulatory requirement. The statistical analysis module <b>14</b> may be provided with, receive or otherwise obtain one or more statistical models <b>15</b> that define what or how to analyze the data from the data source <b>12</b> for a particular analysis.</p><p id="p-0035" num="0034">It can be appreciated that the computing environment <b>10</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> can be adapted to be integrated into any computing system, device, or platform, including an existing organization such as a financial institution. Other types of data may also be analyzed within a computing environment <b>10</b> such as that shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, for example, medical testing data, research results, or any other statistical output <b>16</b> for which the results can be validated by testing or otherwise examining one or more test conditions such as ranges, upper or lower thresholds, etc.</p><p id="p-0036" num="0035">Also shown in the computing environment <b>10</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is an output validation module <b>20</b> that can be integrated or interfaced with or otherwise coupled to the statistical analysis module <b>14</b> in order to validate the statistical output <b>16</b>. It can be appreciated that the output validation module <b>20</b> may be operated by a device (not shown) having a processor, memory, and an interface to or with the statistical output <b>16</b> and obtains or receives data sets from the statistical analysis module <b>14</b> or a memory device storing the statistical output <b>16</b> via such an interface. The statistical analysis module <b>14</b> and output validation module <b>20</b> can be hosted or provided by separate devices or systems or can be integrated into the same device or system. For example, the output validation module <b>20</b> can be provided by a separate service or entity that can serve multiple entities that operate or control operation of a statistical analysis module <b>14</b> to provide a validation e.g., as a service.</p><p id="p-0037" num="0036">The output validation module <b>20</b> obtains the statistical output <b>16</b>, e.g., as a number of records in a data set, and analyzes the data against one or more validation cases <b>22</b> as discussed in greater detail below. The validation cases <b>22</b> are obtained, defined, or automatically determined according to one or more test conditions <b>26</b>. The test conditions <b>26</b> can be determined from or by the statistical analysis module <b>14</b>, e.g., based on the type of model <b>15</b>, type of data, an objective of the analysis, the expected results, etc. The test conditions <b>26</b> can also be determined from or by analyzing the data source <b>12</b> directly.</p><p id="p-0038" num="0037">The output validation module <b>20</b> can be coupled to the statistical output module <b>14</b> to perform a parallel validation process or, as illustrated using dashed lines in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, to intercept the statistical output <b>16</b> prior to use of the output <b>16</b> by the process <b>18</b>. The output validation module <b>20</b> may therefore generate validation results <b>24</b> that can be used to provide feedback, alerts, notifications, or control over the execution of the process <b>18</b>. For example, the output validation module <b>20</b> can be inserted or coupled to a statistical analysis workflow (as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>) to validate the statistical output <b>16</b> periodically or in real-time as the output <b>16</b> becomes available and prior to using or relying on the statistical output <b>16</b> in the process. In one example scenario, the process <b>18</b> may include generating a report for an auditor with the validation process being used to confirm the statistical results prior to submitting the report to the auditor, which may also include a feedback mechanism to have certain errors in data points or process operations fixed.</p><p id="p-0039" num="0038">It can be appreciated that the computing environment <b>10</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may also be utilized for validating the models <b>15</b> as they are being built or trained such that the results are analyzed and validated prior to releasing the model <b>15</b> for production. It can also be appreciated that the output validation module <b>20</b> can also be used to examine incoming data that may or may not have been statistically analyzed by the statistical analysis module <b>14</b>. That is, the data source <b>12</b> can be directly fed into the output validation module <b>20</b> as illustrated in dashed lines in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, to enable the contents of the data source <b>12</b> to be validated directly. For example, the data source <b>12</b> may include externally generated data that provides what can be considered &#x201c;statistical&#x201d; values that can be directly analyzed and do not necessarily require an additional statistical analysis.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates another exemplary computing environment <b>30</b> to which the configuration shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> has been adapted. In one aspect, the computing environment <b>30</b> may include a statistical analysis device <b>36</b>, one or more data source devices <b>32</b> providing or otherwise having access to external data sources <b>12</b><i>a, </i>and a communications network <b>34</b> connecting one or more components of the computing environment <b>30</b>. The computing environment <b>30</b> may also include one or more validation devices <b>38</b>. In the example shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the validation device <b>38</b> receives data via the statistical analysis device <b>36</b> after the data has undergone a statistical analysis by a statistical analysis module <b>14</b>, but can also access an external data source <b>12</b><i>a </i>via the communications network <b>34</b> to directly validate one more data sets from the external data source <b>12</b><i>a. </i>In one example, the validation device <b>38</b> may be associated with another organization that relies on the data after having been processed by the statistical analysis device <b>36</b>. The devices <b>36</b>, <b>38</b> may also be part of the same organization, and/or may be integrated into a single device (not shown).</p><p id="p-0041" num="0040">The computing environment <b>30</b> may also include one or more 3<sup>rd </sup>party devices <b>40</b>. The 3<sup>rd </sup>party device <b>40</b> may be considered similar to the devices <b>36</b>, <b>38</b> but in this example does not necessarily process or analyze the data. For example, the 3<sup>rd </sup>party device <b>40</b> may correspond to a member of the public that consumes a report, score, or result generated by the process <b>18</b>, or may correspond to an auditor or other external organization that relies on the statistical output <b>16</b>.</p><p id="p-0042" num="0041">It can be appreciated that the 3<sup>rd </sup>party device <b>40</b> may also receive data that has been validated by the validation device <b>38</b> (as illustrated in dashed lines in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). It can also be appreciated that the validation device <b>38</b> and 3<sup>rd </sup>party device <b>40</b> may include an application programming interface (API) or other interface mechanism or module for interfacing with the statistical analysis device <b>36</b> (or each other) either directly or via the network <b>34</b>. Similarly, the statistical analysis device <b>36</b> may include an API or other interface mechanism or module for interfacing with the external data source <b>12</b><i>a </i>via the data source device <b>32</b>. The data source device <b>32</b> is shown to illustrate one example in which an entity or organization responsible for the external data source <b>12</b><i>a </i>communicates with the statistical analysis device <b>36</b> and/or the validation device <b>38</b> via the network <b>34</b>. However, in other configurations, the statistical analysis device <b>36</b> and/or validation device <b>38</b> may be capable of accessing the external data source <b>12</b><i>a </i>directly, without communicating via another device. It can be appreciated that a statistical analysis device <b>36</b> may in another scenario become a validation device <b>38</b> and vice versa. As such, the scenario and configuration depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref> provides one example for the sake of illustration.</p><p id="p-0043" num="0042">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the statistical analysis device <b>36</b> may also include or have access to an internal data source <b>12</b><i>b, </i>that is, data that is generated or otherwise made available within a same entity or organization. For example, data generated in one business unit of a financial institution may be used in other downstream processes <b>18</b> and therefore could benefit from execution of the statistical analysis module <b>14</b> prior to using the internally sourced data <b>12</b><i>b. </i>In one embodiment, the statistical analysis device <b>36</b> may be one or more computer systems configured to process and store information and execute software instructions to perform one or more processes consistent with the disclosed embodiments. Similarly, the validation device <b>38</b> can have, or have access to, the internal data source <b>12</b><i>b </i>shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> or its own internal data source <b>12</b><i>b </i>(not shown).</p><p id="p-0044" num="0043">The statistical analysis device <b>36</b> and/or validation device <b>38</b> may also include or be a component or service provided by a financial institution system (e.g., commercial bank) that provides financial services accounts to users, processes financial transactions associated with those financial service accounts, and analyzes statistical data to inform investors, customers, and the public generally. Details of such a financial institution system have been omitted for clarity of illustration. The statistical analysis device <b>36</b> and/or validation device <b>38</b> may also include or be a component or service provided by other types of entities and organizations, such as government bodies and private enterprises that would benefit from checking the integrity of data which they did not necessarily generate.</p><p id="p-0045" num="0044">In certain aspects, data source device <b>32</b> (that provides or provides access to the external source of data <b>12</b><i>a</i>), statistical analysis device <b>36</b>, and/or validation device <b>38</b> can include, but is not limited to, a personal computer, a laptop computer, a tablet computer, a notebook computer, a hand-held computer, a personal digital assistant, a mobile phone, an embedded device, a smart phone, a virtual reality device, an augmented reality device, third party portals, and any additional or alternate computing device, and may be operable to transmit and receive data across communication network <b>34</b>.</p><p id="p-0046" num="0045">Communication network <b>34</b> may include a telephone network, cellular, and/or data communication network to connect different types of devices as will be described in greater detail below. For example, the communication network <b>24</b> may include a private or public switched telephone network (PSTN), mobile network (e.g., code division multiple access (CDMA) network, global system for mobile communications (GSM) network, and/or any 3G, 4G, or 5G wireless carrier network, etc.), WiFi or other similar wireless network, and a private and/or public wide area network (e.g., the Internet).</p><p id="p-0047" num="0046">The computing environment <b>30</b> may also include a cryptographic server (not shown) for performing cryptographic operations and providing cryptographic services (e.g., authentication (via digital signatures), data protection (via encryption), etc.) to provide a secure interaction channel and interaction session, etc. Such a cryptographic server can also be configured to communicate and operate with a cryptographic infrastructure, such as a public key infrastructure (PKI), certificate authority (CA), certificate revocation service, signing authority, key server, etc. The cryptographic server and cryptographic infrastructure can be used to protect the various data communications described herein, to secure communication channels therefor, authenticate parties, manage digital certificates for such parties, manage keys (e.g., public and private keys in a PKI), and perform other cryptographic operations that are required or desired for particular applications of the statistical analysis device <b>36</b>, validation device <b>38</b>, 3<sup>rd </sup>party device <b>40</b>, and data source device <b>32</b>. The cryptographic server may be used to protect the data or results of the data by way of encryption for data protection, digital signatures or message digests for data integrity, and by using digital certificates to authenticate the identity of the users and devices within the computing environment <b>30</b>, to inhibit data breaches by adversaries. It can be appreciated that various cryptographic mechanisms and protocols can be chosen and implemented to suit the constraints and requirements of the particular deployment of the computing environment <b>30</b> as is known in the art.</p><p id="p-0048" num="0047">In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, an example configuration of the statistical analysis device <b>36</b> is shown and in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, an example configuration of the validation device <b>38</b> is shown. As can be appreciated from these figures, the devices <b>36</b>, <b>38</b> include several similar components, which will be described once for brevity. Turning first to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, in certain embodiments, the statistical analysis device <b>36</b> may include one or more processors <b>50</b>, a communications module <b>52</b>, and a data interface module <b>54</b> for interfacing with the external data source <b>12</b><i>a </i>and/or internal data source <b>12</b><i>b </i>to retrieve and store data. Communications module <b>52</b> enables the statistical analysis device <b>36</b> to communicate with one or more other components of the computing environment <b>30</b>, such as data source device <b>32</b>, validation device <b>38</b>, 3<sup>rd </sup>party device <b>40</b> (or one of its components), via a bus or other communication network, such as the communication network <b>34</b>. While not delineated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the statistical analysis device <b>36</b> includes at least one memory or memory device that can include a tangible and non-transitory computer-readable medium having stored therein computer programs, sets of instructions, code, or data to be executed by processor <b>50</b>. <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates examples of modules, tools and engines stored in memory on the statistical analysis device <b>26</b> and operated by the processor <b>50</b>. It can be appreciated that any of the modules, tools, and engines shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> may also be hosted externally and be available to the statistical analysis device <b>36</b>, e.g., via the communications module <b>52</b>.</p><p id="p-0049" num="0048">In the example embodiments shown in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref>, the statistical analysis device <b>36</b> and validation device <b>38</b> include a machine learning engine <b>56</b>, a classification module <b>58</b>, a training module <b>60</b>, an output module <b>64</b>, and a process interface module <b>66</b>. Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the statistical analysis device <b>36</b> also includes the statistical analysis module <b>14</b> storing or having access to one or more statistical models <b>15</b>. Similarly, as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the validation device <b>38</b> also includes the output validation module <b>20</b> and may store one or more validation cases <b>22</b>.</p><p id="p-0050" num="0049">The machine learning engine <b>56</b> is used by the statistical analysis module <b>14</b> or output validation module <b>20</b> to generate and train statistical models <b>15</b> or validation cases <b>22</b> to be used in either the statistical analyses being conducted, building or refining the models <b>15</b>, determining validation cases <b>22</b>, and performing a data validation process. The statistical analysis module <b>14</b> or output validation module <b>20</b> may utilize or otherwise interface with the machine learning engine <b>56</b> to both classify data currently being analyzed to generate the statistical models <b>15</b> or validation cases <b>22</b>, and to train classifiers using data that is continually being processed and accumulated by the statistical analysis device <b>36</b> and validation device <b>38</b>.</p><p id="p-0051" num="0050">The machine learning engine <b>56</b> may also perform operations that classify the data from the data source(s) <b>12</b><i>a</i>/<b>12</b><i>b </i>in accordance with corresponding classifications parameters, e.g., based on an application of one or more machine learning algorithms to the data. The machine learning algorithms may include, but are not limited to, a one-dimensional, convolutional neural network model (e.g., implemented using a corresponding neural network library, such as Keras&#xae;), and the one or more machine learning algorithms may be trained against, and adaptively improved using, elements of previously classified profile content identifying expected datapoints. Subsequent to classifying the data, the machine learning engine <b>56</b> may further process each data point to identify, and extract, a value characterizing the corresponding one of the classification parameters, e.g., based on an application of one or more additional machine learning algorithms to each of the data points. By way of the example, the additional machine learning algorithms may include, but are not limited to, an adaptive natural language processing algorithm that, among other things, predicts starting and ending indices of a candidate parameter value within each data point, extracts the candidate parameter value in accordance with the predicted indices, and computes a confidence score for the candidate parameter value that reflects a probability that the candidate parameter value accurately represents the corresponding classification parameter. As described herein, the one or more additional machine learning algorithms may be trained against, and adaptively improved using, the locally maintained elements of previously classified data. Classification parameters may be stored and maintained using the classification module <b>58</b>, and training data may be stored and maintained using the training module <b>60</b>.</p><p id="p-0052" num="0051">In some instances, classification data stored in the classification module <b>58</b> may identify one or more parameters, e.g., &#x201c;classification&#x201d; parameters, that facilitate a classification of corresponding elements or groups of recognized data points based on any of the exemplary machine learning algorithms or processes described herein. The one or more classification parameters may correspond to parameters that can identify expected and unexpected data points for certain types of data.</p><p id="p-0053" num="0052">In some instances, the additional, or alternate, machine learning algorithms may include one or more adaptive, natural-language processing algorithms capable of parsing each of the classified portions of the data being examined and predicting a starting and ending index of the candidate parameter value within each of the classified portions. Examples of the adaptive, natural-language processing algorithms include, but are not limited to, natural-language processing models that leverage machine learning processes or artificial neural network processes, such as a named entity recognition model implemented using a SpaCy&#xae; library.</p><p id="p-0054" num="0053">Examples of these adaptive, machine learning processes include, but are not limited to, one or more artificial, neural network models, such as a one-dimensional, convolutional neural network model, e.g., implemented using a corresponding neural network library, such as Keras&#xae;. In some instances, the one-dimensional, convolutional neural network model may implement one or more classifier functions or processes, such a Softmax&#xae; classifier, capable of predicting an association between a data point and a single classification parameter and additionally, or alternatively, multiple classification parameters.</p><p id="p-0055" num="0054">Based on the output of the one or more machine learning algorithms or processes, such as the one-dimensional, convolutional neural network model described herein, machine learning engine <b>56</b> may perform operations that classify each of the discrete elements of the data being examined as a corresponding one of the classification parameters, e.g., as obtained from classification data stored by the classification module <b>58</b>.</p><p id="p-0056" num="0055">The outputs of the machine learning algorithms or processes may then be used by the statistical analysis module <b>14</b> to generate and train the models <b>15</b> and to use the models <b>15</b> to determine if data points in the current data being examined are expected or unexpected. The outputs of the machine learning algorithms or processes may also be used by the output validation module <b>20</b> to generate and train validation cases <b>22</b> to determine if data points in the current data being examined are expected or unexpected.</p><p id="p-0057" num="0056">Referring again to <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref>, the output module <b>64</b> may be used to provide one or more outputs based on the results generated by the statistical analysis module <b>14</b> or output validation module <b>20</b>. Example outputs include a visual output in a GUI; a flag, alert, notification, or message in a process using (or about to use) the data being analyzed and/or validated; or a process instruction operable to pause, interrupt or halt the process in view of the results of the data validation as discussed above. The output module <b>64</b> may be configured to interface with the process <b>18</b> via the process interface module <b>66</b>. The statistical analysis module <b>14</b> and output validation module <b>20</b> may also be configured to interface with the process <b>18</b> via the process interface module <b>66</b>. The output module <b>64</b> and process interface module <b>66</b> may be embodied as APIs when interfacing with software-based processes <b>18</b> or may include a combination of software and hardware when interfacing with processes <b>18</b> that have hardwired or software/hardware-type interfaces. The statistical analysis module <b>14</b> and output validation module <b>20</b> may be programmed to translate between multiple protocols in order to interface with other components to provide such outputs and such translation can occur within the statistical analysis module <b>14</b>, output data validation module <b>20</b> and/or the output module <b>64</b> or process interface module <b>66</b>. It can be appreciated that the functionality provided by the output module <b>64</b> and process interface module <b>66</b> are delineated as shown in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> for illustrative purposes and such functionality may also be integrated together or into the statistical analysis module <b>14</b> or output data validation module <b>20</b> in other example embodiments.</p><p id="p-0058" num="0057">While not shown in the figures, the 3<sup>rd </sup>party device <b>40</b> may also be configured in a manner similar to the devices <b>36</b>, <b>38</b> to enable the 3<sup>rd </sup>party device <b>40</b> to report, publish, or otherwise use the data from a data source <b>12</b> that has been processed by either or both the devices <b>36</b>, <b>38</b>.</p><p id="p-0059" num="0058">It will be appreciated that any module or component exemplified herein that executes instructions may include or otherwise have access to computer readable media such as storage media, computer storage media, or data storage devices (removable and/or non-removable) such as, for example, magnetic disks, optical disks, or tape. Computer storage media may include volatile and non-volatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data. Examples of computer storage media include RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by an application, module, or both. Any such computer storage media may be part of the data source device <b>32</b>, statistical analysis device <b>36</b>, validation device <b>38</b>, or 3<sup>rd </sup>party device <b>40</b>, or accessible or connectable thereto. Any application or module herein described may be implemented using computer readable/executable instructions that may be stored or otherwise held by such computer readable media.</p><p id="p-0060" num="0059">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, an example illustrating computer executable operations executed by the output validation module <b>20</b> in performing a data validation process is shown, for example in validating data such as statistical output <b>16</b> generated by the statistical analysis module <b>14</b>. At block <b>80</b>, the output validation module <b>20</b> obtains a validation set with one or more validation cases <b>22</b>. Each validation case <b>22</b> includes at least one test condition <b>26</b>, which defines what in the data is to be validated. For example, if a value in the data set should be within a predetermined range in order to be valid, the test condition <b>26</b> can define that range and the validation case <b>22</b> apply that condition. The terms validation set, validation case, and test condition are used in this granularity to provide for flexible and reusable modules, however, a validation set may instead define one or more test conditions or the test condition may itself be the validation case or validation set. On the other hand, different validation cases can be defined with different test conditions that can be assembled in different ways for different types of data sets associated with different types of statistical analyses and/or statistical models <b>15</b>. For example, Test Case A may include test condition 1 and test condition 2 while Test Case B includes test condition 1 and test condition 3. Test Case A may be selected for data from one region while Test Case B is selected for another region. In this way, different test cases <b>22</b> can be defined, reused and applied modularly.</p><p id="p-0061" num="0060">At block <b>82</b>, the output validation module <b>20</b> obtains the one or more data sets to be validated using the validation set. This may include, for example, communicating with the statistical analysis device <b>36</b> via the process interface module <b>66</b> of the validation device <b>38</b> to obtain the statistical output <b>16</b> generated by the statistical analysis module <b>14</b> and which is to be validated.</p><p id="p-0062" num="0061">At block <b>84</b>, the output validation module <b>20</b> applies the validation set to the one or more data sets that are being validated, to validate the data in the one or more data sets according to the test conditions <b>26</b>. The validation set can be applied to the data being validated by iterating through data fields, rows, columns or other records according to what is being validated. An example of the application of a validation set is described in greater detail below.</p><p id="p-0063" num="0062">At block <b>86</b>, the output validation module <b>20</b> outputs a validation result <b>24</b> for each record that is validated, with an indication of whether the value that was examined passed or failed according to the test condition(s) <b>26</b>. For example, if the value contained in a record is outside of a range that is expected given some other condition or variable, the validation result <b>24</b> for that record would fail. The outputting of the validation result at block <b>86</b> may include generating a summary or list of the records with the corresponding result, e.g., within a user interface.</p><p id="p-0064" num="0063">At block <b>88</b>, the validation results <b>24</b> may optionally be provided to a process <b>18</b> that uses the statistical output <b>16</b> as a validation feedback mechanism. For example, the output validation module <b>20</b> may be initiated and called by the statistical analysis module <b>14</b> or statistical analysis device <b>36</b> to perform a scheduled validation or to validate results in real-time before executing a further action in the process <b>18</b>.</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>6</b></figref> provides an example implementation of the operations shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. In this example embodiment, an existing process is running at block <b>100</b>. This existing process can include any process, such as an execution of the statistical analysis module <b>14</b> or the process <b>18</b>, that has data to be validated by the output validation module <b>20</b>. At block <b>102</b> an option is provided for running the validation process. When this option is selected, a number of validation cases <b>22</b> are obtained at stage <b>104</b>. In this example, the validation cases <b>22</b> are shown as a series of files 1, 2, . . . , n; illustrating that any number of validation cases <b>22</b> can be used to perform the validation process. At block <b>106</b> a validation set is built for processing. This may include assembling a list of test conditions <b>26</b> to be applied to each record or other portion of data being validated.</p><p id="p-0066" num="0065">At stage <b>108</b>, a number of data sets to be validated is defined, with each being evaluated against one or more validation cases <b>22</b>. In this example, a series of data sets 1, 2, . . . , n is shown; illustrating that any number of data sets <b>12</b>, <b>16</b> can be obtained for validation in stage <b>108</b>. It may be noted that the process shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> can be applied to statistical output <b>16</b> or incoming data <b>12</b> as discussed above. The data sets <b>12</b>, <b>16</b> to be validated in stage <b>108</b> may be evaluated individually at block <b>110</b> as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> or may be combined and evaluated together depending on the test conditions <b>26</b> being applied and the data being analyzed.</p><p id="p-0067" num="0066">At block <b>112</b>, the output validation module <b>20</b> initiates a dual looping structure, which is an example implementation for block <b>84</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. Here the first (or next) record in the data set being validated is accessed. At block <b>114</b>, the record(s) of the conditions to validate is/are obtained. This may include determining all of the test conditions <b>26</b> to apply against the data record currently being analyzed, as defined by the validation set. At block <b>116</b> the output validation module <b>20</b> determines if the data record is valid for the current test condition <b>26</b> being analyzed. If not, the output validation module <b>20</b> outputs a failure at block <b>118</b>. If the data record is valid for the current test condition <b>26</b>, the output validation module <b>20</b> determines at block <b>120</b> if the current test condition <b>26</b> is the final test condition <b>26</b> to validate for that data record. If not, the output validation module <b>20</b> increments to the next test condition <b>26</b> at block <b>122</b> and repeats blocks <b>114</b>-<b>120</b> until it is determined at block <b>120</b> that all criteria have been analyzed for validity.</p><p id="p-0068" num="0067">When all criteria have been analyzed for validity, the output validation module <b>20</b> determines at block <b>124</b> if the current data record is the final data record to be analyzed. If not, the output validation module <b>20</b> increments to the next data record and repeats blocks <b>112</b>-<b>124</b> for the next data record. Once all data records have been analyzed, at block <b>128</b> the output validation module <b>20</b> outputs a pass result for the data set and returns to the existing process at block <b>130</b>. It can be appreciated that the dual looping structure shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> can be applied in parallel or serially to the other data sets to be validated that are shown in stage <b>108</b>. In this way, the dual looping structure can be applied to a data set to determine if any of the data records of that type contain an error wherein the failure output at block <b>118</b> is indicated.</p><p id="p-0069" num="0068">It can also be appreciated that the validation cases <b>22</b> determined in stage <b>104</b> may be predetermined, selected, or otherwise specified at the time of, or prior to, running the validation process at block <b>102</b>. Such predetermined validation cases <b>22</b> may be specified by an owner of the data source <b>12</b>, an operator of the statistical analysis module <b>14</b>, a third party such as a regulatory or government body, or any other interested party.</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>7</b></figref> provides another example embodiment for validating data using the output validation module <b>20</b>, in a fully automated configuration. In this example embodiment, the fully automated validation process may be selected at block <b>200</b> for data associated with the existing process <b>100</b>. In this example embodiment, the validation process <b>200</b> is executed to automatically determine the validation set to be applied to the data sets to be validated. When the validation process is initiated at block <b>200</b>, a data set used to build the validation set is obtained at block <b>202</b>. The data set is analyzed at block <b>204</b> to determine which validation cases <b>22</b>, including which test conditions <b>26</b>, are to be applied to the rest of the data. For example, the analyses conducted at block <b>204</b> can include applying a machine learning algorithm to the data set to determine test conditions <b>26</b> indicative of whether a data record is valid or not. The machine learning algorithm can be trained based on validation sets determined using the process shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> or by applying a model based on the type of data being validated.</p><p id="p-0071" num="0070">Once the validation set is built for processing at block <b>206</b>, the data sets to be validated are determined at stage <b>108</b>, and the dual looping structure described above can be applied beginning at block <b>110</b>. The implementation of blocks <b>110</b>-<b>130</b> are described above and need not be reiterated here.</p><p id="p-0072" num="0071">An example of an output page <b>300</b> is shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. In the example page <b>300</b>, a validation output <b>304</b> is displayed for each validation case in a list of results <b>302</b>. It can be seen that in this example all test conditions <b>26</b> passed the validation process.</p><p id="p-0073" num="0072">Another example of an output page <b>400</b> is shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. In the example page <b>400</b>, a validation output <b>306</b> is shown that corresponds to a failed test condition <b>306</b>.</p><p id="p-0074" num="0073">It will be appreciated that the examples and corresponding diagrams used herein are for illustrative purposes only. Different configurations and terminology can be used without departing from the principles expressed herein. For instance, components and modules can be added, deleted, modified, or arranged with differing connections without departing from these principles.</p><p id="p-0075" num="0074">The steps or operations in the flow charts and diagrams described herein are just for example. There may be many variations to these steps or operations without departing from the principles discussed above. For instance, the steps may be performed in a differing order, or steps may be added, deleted, or modified.</p><p id="p-0076" num="0075">Although the above principles have been described with reference to certain specific examples, various modifications thereof will be apparent to those skilled in the art as outlined in the appended claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A device for validating data, the device comprising:<claim-text>a processor;</claim-text><claim-text>a data interface coupled to the processor; and</claim-text><claim-text>a memory coupled to the processor, the memory storing computer executable instructions that when executed by the processor cause the device to:<claim-text>obtain, via the data interface, at least one data set to be validated using a validation set determined according to at least one test condition, wherein the at least one dataset is an output of at least one statistical analysis on at least one input data set;</claim-text><claim-text>apply the validation set to the at least one data set to validate the data in the data set by, for at least one record in the at least one data set, validating the record according to the at least one test condition; and</claim-text><claim-text>output a validation result for the data set.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the computer executable instructions cause the device to:<claim-text>in response to the validation result satisfying at least one criterion, transmit the at least one data set to a process for consumption.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the validation set comprises at least one validation case, each validation case comprising at least one test condition.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the computer executable instructions cause the device to:<claim-text>transmit for adjusting, or adjust, the at least one statistical analysis based on the validation results.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one validation case in the validation set is automatically derived by obtaining a sample data set, analyzing the sample data set, and identifying the at least one test condition from the analyzed sample data set.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one validation case in the validation set is derived by providing a user interface to enable manual entry of the at least one test condition.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one validation case in the validation set is obtained from a source, the source having previously derived the at least one test condition.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The device of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the computer executable instructions further cause the device to:<claim-text>obtain the sample data set;</claim-text><claim-text>analyze the sample data set; and</claim-text><claim-text>automatically identify all test conditions to be validated for the at least one data set to validate.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the sample data set is analyzed by applying an automated process that uses a model derived using a machine learning process.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the computer executable instructions further cause the device to:<claim-text>generate a notification indicative of at least one failure to trigger an investigation of the at least one data set.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein validating the record comprises accessing a first record to be validated, incrementing through each of the at least one test condition to be validated for the first record and, for a second and any additional record to be validated, incrementing to a next record to increment through each of the at least one test condition.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The device of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the validation results comprise a pass or fail indication output as the validating increments through values in the records.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data set is generated using financial data.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A method of validating data, the method executed by a device having a data interface coupled to a processor and comprising:<claim-text>obtaining, via the data interface, at least one data set to be validated using a validation set determined according to at least one test condition, wherein the at least one dataset is an output of at least one statistical analysis on at least one input data set;</claim-text><claim-text>applying the validation set to the at least one data set to validate the data in the data set by, for at least one record in the at least one data set, validating the record according to the at least one test condition; and</claim-text><claim-text>outputting a validation result for the data set.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:<claim-text>in response to the validation result satisfying at least one criterion, transmitting the at least one data set to a process for consumption.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the validation set comprises at least one validation case, each validation case comprising at least one test condition.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:<claim-text>transmitting for adjusting, or adjusting, the at least one statistical analysis based on the validation results.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein at least one validation case in the validation set is automatically derived by obtaining a sample data set, analyzing the sample data set, and identifying the at least one test condition from the analyzed sample data set.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein at least one validation case in the validation set is derived by providing a user interface to enable manual entry of the at least one test condition.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A non-transitory computer readable medium for validating data, the computer readable medium comprising computer executable instructions for:<claim-text>obtaining, via a data interface, at least one data set to be validated using a validation set determined according to at least one test condition, wherein the at least one dataset is an output of at least one statistical analysis on at least one input data set;</claim-text><claim-text>applying the validation set to the at least one data set to validate the data in the data set by, for at least one record in the at least one data set, validating the record according to the at least one test condition; and</claim-text><claim-text>outputting a validation result for the data set.</claim-text></claim-text></claim></claims></us-patent-application>
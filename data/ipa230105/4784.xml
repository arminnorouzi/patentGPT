<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004785A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004785</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17901817</doc-number><date>20220901</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-057929</doc-number><date>20200327</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>0454</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">MACHINE LEARNING SYSTEM AND METHOD, INTEGRATION SERVER, INFORMATION PROCESSING APPARATUS, PROGRAM, AND INFERENCE MODEL CREATION METHOD</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/012512</doc-number><date>20210325</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17901817</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>FUJIFILM Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>UEHARA</last-name><first-name>Daiki</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>FUJIFILM Corporation</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Provided are a machine learning system and method, an integration server, an information processing apparatus, a program, and an inference model creation method capable of suppressing a variation in learning data in federated learning and suppressing a variation in an inference accuracy of a model. The integration server receives an input that designates a data search condition and transmits the designated search condition to a plurality of client terminals. Each client terminal performs searching within a medical institution system to which each terminal belongs and transmits a totalization result of the number of pieces of data that matches the search condition to the integration server. The integration server receives an input that designates the required number of pieces of learning data and distributes the number of pieces of learning data used for learning on each client terminal based on the designated required number and on the received totalization result. The client terminal executes machine learning of a local model to be trained using the data in the medical institution system according to the designated type and number of pieces of learning data and transmits the learning result to the integration server. The integration server integrates the received learning results to update a master model.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="99.31mm" wi="158.75mm" file="US20230004785A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="247.73mm" wi="163.24mm" orientation="landscape" file="US20230004785A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="246.30mm" wi="129.12mm" orientation="landscape" file="US20230004785A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="251.12mm" wi="163.66mm" orientation="landscape" file="US20230004785A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="245.53mm" wi="162.98mm" orientation="landscape" file="US20230004785A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="248.24mm" wi="163.24mm" orientation="landscape" file="US20230004785A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="231.65mm" wi="155.36mm" file="US20230004785A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="226.31mm" wi="162.73mm" file="US20230004785A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="243.67mm" wi="126.58mm" file="US20230004785A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="250.61mm" wi="162.22mm" orientation="landscape" file="US20230004785A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="251.12mm" wi="149.10mm" file="US20230004785A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="199.05mm" wi="114.64mm" file="US20230004785A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="230.46mm" wi="162.14mm" file="US20230004785A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="237.24mm" wi="147.15mm" file="US20230004785A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a Continuation of PCT International Application No. PCT/JP2021/012512 filed on Mar. 25, 2021 claiming priority under 35 U.S.C &#xa7; 119(a) to Japanese Patent Application No. 2020-057929 filed on Mar. 27, 2020. Each of the above applications is hereby expressly incorporated by reference, in its entirety, into the present application.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><heading id="h-0003" level="1">1. Field of the Invention</heading><p id="p-0003" num="0002">The present invention relates to a machine learning system and method, an integration server, an information processing apparatus, a program, and an inference model creation method, and particularly relates to a machine learning technique using a federated learning mechanism.</p><heading id="h-0004" level="1">2. Description of the Related Art</heading><p id="p-0004" num="0003">In development of medical artificial intelligence (AI) using deep learning, it is necessary to train an AI model. However, for this learning, it is necessary to extract learning data such as a diagnosis image from a medical institution to an external development site or to an external development server. For this reason, there are few medical institutions that provide the data. Further, even in a case where the data is provided from a medical institution, there is always a privacy-related risk.</p><p id="p-0005" num="0004">On the other hand, in a case where a federated learning mechanism being proposed in H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Ag&#xfc;era y Arcas, &#x201c;Communication-Efficient Learning of Deep Networks from Decentralized Data&#x201d;, arXiv:1602.05629v3 [cs.LG], 28 Feb. 2017 is used, learning is performed on a terminal in which data for training exists, and only a weight parameter of a network model that is a learning result on each terminal is transmitted from a terminal group to an integration server. That is, in federated learning, learning data is not provided to the integration server side, and only data of the learning result on each terminal is provided from the terminal side to the integration server side.</p><p id="p-0006" num="0005">For this reason, learning can be performed without extracting data that requires consideration for privacy to the outside. Thus, federated learning is a technique that has been attracting attention in recent years.</p><p id="p-0007" num="0006">In Micah J Sheller, G Anthony Reina, Brandon Edwards, Jason Martin, and Spyridon Bakas, &#x201c;Multi-Institutional Deep Learning Modeling Without Sharing Patient Data: A Feasibility Study on Brain Tumor Segmentation&#x201d;, arXiv:1810.04304v2 [cs.LG], 22 Oct. 2018, a result of an example in which federated learning is applied to development of a medical AI is reported.</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0008" num="0007">In a case where federated learning is used for development of a medical AI, it is not necessary to extract data such as a diagnosis image. However, contents of the data held by each medical institution vary, and learning environments are different for each client. As a result, results of learning performed by each client also vary.</p><p id="p-0009" num="0008">For this reason, in a case where an AI model is trained by randomly selecting the learning data in a plurality of medical institutions, a variation occurs in inference accuracy of the AI model. According to the content reported in Micah J Sheller, G Anthony Reina, Brandon Edwards, Jason Martin, and Spyridon Bakas, &#x201c;Multi-Institutional Deep Learning Modeling Without Sharing Patient Data: A Feasibility Study on Brain Tumor Segmentation&#x201d;, arXiv: 1810.04304v2 [cs.LG], 22 Oct. 2018, all of data prepared in a verification environment are used as they are as the learning data for training a local model. This still means that there is no method of collecting data for training other than random sampling in actual operation. In a case where data is extracted by random sampling, there may be a variation in the data to be used for learning. Thus, there is a concern that the variation occurs in the inference accuracy of the AI model to be created.</p><p id="p-0010" num="0009">The present invention has been made in view of such circumstances, and an object of the present invention is to provide a machine learning system and method, an integration server, an information processing apparatus, a program, and an inference model creation method capable of suppressing a variation in an inference accuracy of an AI model, which is caused by randomly selected learning data in a case where a federated learning mechanism is implemented in which the AI model can be trained without extracting personal information such as a diagnosis image that requires consideration for privacy from a medical institution to the outside.</p><p id="p-0011" num="0010">A machine learning system according to one aspect of the present disclosure comprises a plurality of client terminals and an integration server. Each of the plurality of client terminals is a terminal installed in a medical institution system of each of a plurality of medical institutions. Each of the client terminals includes a first processor and a first computer-readable medium on which a first program executed by the first processor is recorded. The first processor performs, according to a command of the first program, processing including acquiring a search condition of data from the integration server, searching for data that matches the search condition from within the medical institution system to which the client terminal belongs and totaling search results, transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server, receiving distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated, executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data, and transmitting a learning result of the local model to the integration server. The integration server includes a second processor and a second computer-readable medium on which a second program executed by the second processor is recorded. The second processor performs, according to a command of the second program, processing including storing a master model to be trained on the second computer-readable medium, receiving an input that designates the search condition in a case where the data in the medical institution system is searched for, transmitting the designated search condition to the plurality of client terminals, receiving the totalization result indicating the number of pieces of data that matches the search condition from each of the client terminals, receiving an input that designates the required number of pieces of learning data to be used for learning, distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result, transmitting, to each of the client terminals, the distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals, synchronizing the local model of each client terminal side with the master model before the local model is trained at each of the plurality of client terminals, receiving each of the learning results from the plurality of client terminals, and integrating the received learning results to update the master model.</p><p id="p-0012" num="0011">According to this aspect, it is possible to set the data search condition from the integration server to search for the data in the medical institution system of each medical institution and thus ascertain a possession situation of data for each medical institution in the integration server. Further, according to this aspect, it is possible to designate the type and number of pieces of learning data to be used for learning on each client terminal from the integration server by receiving the totalization result of the number of pieces of data that matches the search result and thus suppress a variation in the learning data. Accordingly, it is possible to suppress a variation in the inference accuracy of the model obtained by performing the learning.</p><p id="p-0013" num="0012">The term &#x201c;plurality of client terminals&#x201d; may be an unspecified large number of client terminals. The client terminal may be configured to include a data storage device that stores the data in the medical institution system, or the data storage device and the client terminal may be separate devices.</p><p id="p-0014" num="0013">In the machine learning system according to another aspect of the present disclosure, the second processor may further issue a notification notifying that the required number is satisfied at a stage where a total number of pieces of the data that matches the search condition is equal to or larger than the required number.</p><p id="p-0015" num="0014">In the machine learning system according to still another aspect of the present disclosure, the first processor may have authority to execute a third program that generates new secondary data using primary data in the medical institution system. The second processor may perform, in a case where a total number of pieces of the data that matches the search condition is less than the required number and the data that matches the search condition is obtainable by operating the third program, processing including distributing the number of pieces of additional data requesting additional data generation to each of the client terminals, and transmitting, to each of the client terminals, additional generation distribution information including designation of the number of pieces of the additional data distributed according to each of the client terminals. The first processor may execute the third program based on the additional generation distribution information to newly generate the secondary data.</p><p id="p-0016" num="0015">In the machine learning system according to still another aspect of the present disclosure, the first processor may start training of the local model in a case where the generation of the secondary data of the designated number of pieces of the additional data is completed.</p><p id="p-0017" num="0016">In the machine learning system according to still another aspect of the present disclosure, the third program may include a trained model in which the secondary data is output by inputting the primary data.</p><p id="p-0018" num="0017">In the machine learning system according to still another aspect of the present disclosure, each of the plurality of client terminals may be a terminal installed in a medical institution network of a different medical institution.</p><p id="p-0019" num="0018">In the machine learning system according to still another aspect of the present disclosure, the integration server may be installed in a medical institution network or outside the medical institution network.</p><p id="p-0020" num="0019">In the machine learning system according to still another aspect of the present disclosure, the learning result transmitted from the client terminal to the integration server may include a weight parameter of the local model after learning.</p><p id="p-0021" num="0020">In the machine learning system according to still another aspect of the present disclosure, data to be searched for by the search condition may include at least one type of data of a two-dimensional image, a three-dimensional image, a moving image, time-series data, or document data.</p><p id="p-0022" num="0021">In the machine learning system according to still another aspect of the present disclosure, the document data may include comments on findings of an electronic medical record.</p><p id="p-0023" num="0022">In the machine learning system according to still another aspect of the present disclosure, models to be trained of each of the local model and the master model may be trained such that comments on findings corresponding to an input image are output, using a combination of an image and comments on findings associated with the image as the learning data.</p><p id="p-0024" num="0023">In the machine learning system according to still another aspect of the present disclosure, models to be trained of each of the local model and the master model may be configured by using a neural network.</p><p id="p-0025" num="0024">An appropriate network model is applied according to a type of the learning data and a type of data that is input in the inference.</p><p id="p-0026" num="0025">In the machine learning system according to still another aspect of the present disclosure, the data used as the learning data may include a two-dimensional image, a three-dimensional image, or a moving image. Models to be trained of each of the local model and the master model may be configured by using a convolutional neural network.</p><p id="p-0027" num="0026">In the machine learning system according to still another aspect of the present disclosure, the data used as the learning data may include time-series data or document data. Models to be trained of each of the local model and the master model may be configured by using a recurrent neural network.</p><p id="p-0028" num="0027">A machine learning method according to still another aspect of the present disclosure is a machine learning method in which a plurality of client terminals and an integration server are used. The method comprises, via each of the plurality of client terminals, which are installed in a medical institution system of each of a plurality of medical institutions, storing a master model to be trained in the integration server, via the integration server, receiving an input that designates a search condition in a case where data in the medical institution system is searched for and transmitting the designated search condition to the plurality of client terminals, via the client terminal, acquiring the search condition from the integration server, searching for data that matches the search condition from within the medical institution system to which the client terminal belongs and totaling search results, and transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server, via the integration server, receiving the totalization result indicating the number of pieces of data that matches the search condition from each of the client terminals, receiving an input that designates the required number of pieces of learning data to be used for learning, distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result, transmitting, to each of the client terminals, distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals, and synchronizing the local model of each client terminal side with the master model before the local model is trained at each of the plurality of client terminals, via the client terminal, receiving the distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated, executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data, and transmitting a learning result of the local model to the integration server, and, via the integration server, receiving each of the learning results from the plurality of client terminals, and integrating the received learning results to update the master model.</p><p id="p-0029" num="0028">An information processing apparatus according to still another aspect of the present disclosure is used as a client terminal connected to an integration server via a communication line and is a terminal installed in a medical institution system of a medical institution. The information processing apparatus comprises a first processor and a first computer-readable medium on which a first program executed by the first processor is recorded. The first processor performs, according to a command of the first program, processing including acquiring a search condition of data from the integration server, searching for data that matches the search condition from within the medical institution system to which the client terminal belongs and totaling search results, transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server, receiving distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated, executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data, and transmitting a learning result of the local model to the integration server.</p><p id="p-0030" num="0029">In the information processing apparatus according to still another aspect of the present disclosure, the first processor may have authority to execute a third program that generates new secondary data using primary data in the medical institution system and execute the third program according to the number of pieces of additional data designated by the integration server to newly generate the secondary data.</p><p id="p-0031" num="0030">A program according to still another aspect of the present disclosure is a program for causing a first computer to function as a client terminal connected to an integration server via a communication line. The program causes the first computer to realize a function of acquiring a search condition of data from the integration server, a function of searching for data that matches the search condition from within a medical institution system to which the client terminal belongs and totaling search results, a function of transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server, a function of receiving distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated, a function of executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data, and a function of transmitting a learning result of the local model to the integration server.</p><p id="p-0032" num="0031">An integration server according to still another aspect of the present disclosure is an integration server connected to a plurality of client terminals via a communication line. The integration server comprises a second processor and a second computer-readable medium on which a second program executed by the second processor is recorded. The second processor performs, according to a command of the second program, processing including storing a master model to be trained on the second computer-readable medium, receiving an input that designates a search condition in a case where data in a medical institution system to which each of the plurality of client terminals belongs is searched for, transmitting the designated search condition to the plurality of client terminals, receiving a totalization result indicating the number of pieces of the data that matches the search condition from each of the client terminals, receiving an input that designates the required number of pieces of learning data to be used for learning, distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result, transmitting, to each of the client terminals, distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals, synchronizing a local model of each client terminal side with the master model before the local model is trained at each of the plurality of client terminals, receiving a learning result of each of the local models from the plurality of client terminals, and integrating the received learning results to update the master model.</p><p id="p-0033" num="0032">In the integration server according to still another aspect of the present disclosure, each of the client terminals may have authority to execute a third program that generates new secondary data using primary data in the medical institution system. The second processor may perform, in a case where a total number of pieces of the data that matches the search condition is less than the required number and the data that matches the search condition is obtainable by operating the third program, processing including distributing the number of pieces of additional data requesting additional data generation to each of the client terminals and transmitting, to each of the client terminals, additional generation distribution information including designation of the number of pieces of the additional data distributed according to each of the client terminals.</p><p id="p-0034" num="0033">A program according to still another aspect of the present disclosure is a program for causing a second computer to function as an integration server connected to a plurality of client terminals via a communication line. The program causes the second computer to realize a function of storing a master model to be trained, a function of receiving an input that designates a search condition in a case where data in a medical institution system to which each of the plurality of client terminals belongs is searched for, a function of transmitting the designated search condition to the plurality of client terminals, a function of receiving a totalization result indicating the number of pieces of the data that matches the search condition from each of the client terminals, a function of receiving an input that designates the required number of pieces of learning data to be used for learning, a function of distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result, a function of transmitting, to each of the client terminals, distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals, a function of synchronizing a local model of each client terminal side with the master model before a local model is trained at each of the plurality of client terminals, a function of receiving a learning result of each of the local models from the plurality of client terminals, and a function of integrating the received learning results to update the master model.</p><p id="p-0035" num="0034">A method for creating an inference model according to still another aspect of the present disclosure is a method of creating an inference model by performing machine learning using a plurality of client terminals and an integration server. The inference model creation method comprises, via each of the plurality of client terminals, which are installed in a medical institution system of each of a plurality of medical institutions, storing a master model to be trained in the integration server, via the integration server, receiving an input that designates a search condition in a case where data in the medical institution system is searched for, and transmitting the designated search condition to the plurality of client terminals, via the client terminal, acquiring the search condition from the integration server, searching for data that matches the search condition from within the medical institution system to which the client terminal belongs and totaling search results, and transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server, via the integration server, receiving the totalization result indicating the number of pieces of data that matches the search condition from each of the client terminals, receiving an input that designates the required number of pieces of learning data to be used for learning, distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result, transmitting, to each of the client terminals, distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals, and synchronizing the local model of each client terminal side with the master model before the local model is trained at each of the plurality of client terminals, via the client terminal, receiving the distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated, executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data, and transmitting a learning result of the local model to the integration server, and, via the integration server, receiving each of the learning results from the plurality of client terminals, and creating, by integrating the received learning results to update the master model, an inference model having higher inference accuracy than the master model before the update.</p><p id="p-0036" num="0035">The inference model creation method is understood as an invention of a method of producing the inference model. The term &#x201c;inference&#x201d; includes concepts of prediction, estimation, classification, and determination. The inference model may be paraphrased as &#x201c;AI model&#x201d;. The inference model may be a model that generates data.</p><p id="p-0037" num="0036">According to the aspects of the present invention, a mechanism is provided in which the possession situation of data in each medical institution system can be checked by designating the search condition from the integration server. According to the aspects of the present invention, since the type and number of pieces of learning data used for learning on each client terminal can be designated from the integration server for each medical institution, it is possible to suppress the variation in the learning data and thus suppress the variation in the inference accuracy of the AI model obtained by learning.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a conceptual diagram showing an outline of an operation of a machine learning system according to an embodiment of the present invention.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram for describing a type of learning data.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a conceptual diagram showing the outline of the operation of the machine learning system in a case where the total number of pieces of learning data is insufficient.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically showing a system configuration example of the machine learning system according to the embodiment of the present invention.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram showing a configuration example of an integration server.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart showing an example of an operation of the integration server based on a data collection program setting I/F program.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart showing the example of the operation of the integration server based on the data collection program setting I/F program.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart showing the example of the operation of the integration server based on the data collection program setting I/F program.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram showing a configuration example of a terminal on a medical institution network.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart showing an example of an operation of a terminal based on a data collection program.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart showing the example of the operation of the terminal based on a local learning management program.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart showing the example of the operation of the integration server based on a master model learning management program.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart showing an example of processing of evaluating an inference accuracy of a master model candidate in the integration server.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a block diagram showing an example of a hardware configuration of a computer.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0052" num="0051">Hereinafter, preferred embodiments of the present invention will be described with reference to the accompanying drawings.</p><p id="p-0053" num="0052">&#x3c;&#x3c;Outline of Machine Learning System&#x3e;&#x3e;</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a conceptual diagram showing an outline of a machine learning system <b>10</b> according to an embodiment of the present invention. The machine learning system <b>10</b> is a computer system that performs machine learning using a federated learning mechanism. Federated learning is sometimes referred to as &#x201c;federation learning&#x201d;, &#x201c;distribution learning&#x201d;, &#x201c;cooperative learning&#x201d;, or &#x201c;combination learning&#x201d;.</p><p id="p-0055" num="0054">The machine learning system <b>10</b> includes a terminal <b>20</b>, which is installed on a network in each medical institution of a plurality of medical institutions, and an integration server <b>30</b>. The terminal <b>20</b> refers to a computing resource existing in a network in which data in a medical institution can be safely accessed, and the terminal <b>20</b> may not physically exist in the medical institution. That is, the terminal <b>20</b> in each medical institution may be a physical machine or a virtual machine, and a specific form thereof is not limited. The terminal <b>20</b> is an example of &#x201c;client terminal&#x201d; according to the present disclosure. A computer network in a medical institution is referred to as &#x201c;medical institution network&#x201d;.</p><p id="p-0056" num="0055">The terminal <b>20</b> is assumed to exist for each data group for training an AI model to be trained. The term &#x201c;for each data group&#x201d; described herein may be understood as &#x201c;for each medical institution&#x201d; that holds a data group to be used for training the AI model. That is, one terminal <b>20</b> is assumed to exist approximately for one medical institution. The computer system constructed on the medical institution network of each medical institution is referred to as a medical institution system MS. A representative example of the medical institution is &#x201c;hospital&#x201d;.</p><p id="p-0057" num="0056">The display of &#x201c;Hospital 1 Client&#x201d;, &#x201c;Hospital 2 Client&#x201d;, . . . , &#x201c;Hospital N Client&#x201d; shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents the medical institution system MS of each medical institution. A number after &#x201c;hospital&#x201d; is an index as an identification number that identifies each medical institution (hospital). The index number may be understood as a client identification (ID) number of the terminal <b>20</b> or may be understood as &#x201c;client ID number&#x201d; of a medical institution having the medical institution system MS including the terminal <b>20</b>.</p><p id="p-0058" num="0057">In addition to the terminal <b>20</b>, each medical institution system MS includes an information system that stores and manages various pieces of medical information in the medical institution, such as a digital imaging and communication in medicine (DICOM) server <b>22</b> and an electronic medical record system <b>24</b>. The DICOM server <b>22</b> is a server that operates according to a DICOM specification. The DICOM server <b>22</b> is a computer that stores and manages various pieces of data including medical images, such as a CT image and an MM image, and comprises a large-capacity external storage device and software for database management.</p><p id="p-0059" num="0058">The electronic medical record system <b>24</b> is a computer system that creates, edits, stores, and manages an electronic medical record. The electronic medical record system <b>24</b> comprises a large-capacity external storage device that stores electronic medical record data and the like and software for database management.</p><p id="p-0060" num="0059">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the display of &#x201c;dots&#x201d; shown below the electronic medical record system <b>24</b> indicates that other information systems (not shown) may exist. Other information systems may be any system that manages data in the medical institution and that can be searched for, and contents of the data are not limited.</p><p id="p-0061" num="0060">The terminal <b>20</b> of each medical institution includes a data collection program <b>220</b> and a local learning management program <b>250</b>. The data collection program <b>220</b> searches for and collects data used for learning from the medical institution network in accordance with an instruction from the integration server <b>30</b>. The data collection program <b>220</b> has a function of recording which data in the medical institution system MS is data that matches a search condition designated by a development entity <b>80</b> of the AI model (master model), a function of totaling the number of pieces of data that matches the designated search condition, and a function of transmitting the totaled number of pieces of data to the integration server <b>30</b>. The search condition used by the data collection program <b>220</b> is provided by the integration server <b>30</b>.</p><p id="p-0062" num="0061">Learning target data to be searched for according to the search condition may be any data stored in the system to which the data collection program <b>220</b> in each terminal <b>20</b> is permitted to connect. For example, the learning target data to be searched for may be electronic medical record data, a two-dimensional medical image, a three-dimensional medical image, a moving image, a combination of comments on findings of the electronic medical record and the two-dimensional image, a combination of the comments on findings of the electronic medical record and the three-dimensional image, or the like.</p><p id="p-0063" num="0062">The local learning management program <b>250</b> is a client program for the distribution learning and performs training processing on a local model to be trained LM by using local data stored in the medical institution system MS as learning data, in cooperation with the data collection program <b>220</b>. The local data means data stored in the medical institution system MS to which the terminal <b>20</b> belongs.</p><p id="p-0064" num="0063">The local learning management program <b>250</b> has functions of starting training of the local model to be trained LM, transmitting a learned weight parameter file to the integration server <b>30</b>, and the like. That is, the local learning management program <b>250</b> has functions of synchronizing a master model to be trained MM before training with the local model to be trained LM, starting the local learning, setting an end condition of the local learning, and transmitting a learning result of the local learning to the integration server <b>30</b> in a case where the local learning ends.</p><p id="p-0065" num="0064">The local model to be trained LM is the AI model to be trained and performs the learning by using each piece of local data in each medical institution. The local model to be trained LM may be simply described as &#x201c;local model&#x201d;. The training of the local model LM using the local data is referred to as &#x201c;local learning&#x201d;. The local model LM is synchronized with the master model to be trained MM of the integration server <b>30</b> before the learning starts.</p><p id="p-0066" num="0065">The integration server <b>30</b> comprises a data collection program setting interface (I/F) <b>32</b> and the master model to be trained MM. The term &#x201c;I/F&#x201d; is an abbreviation for &#x201c;interface&#x201d;. The data collection program setting interface <b>32</b> is an interface for setting various conditions and the like, such as what kind of data is desired to be searched for by the data collection program <b>220</b> of each medical institution system MS and what kind of data type and how many pieces of data are used for learning. In a case where a plurality of types of data are used for learning, the number of pieces of data for each data type used for learning is set.</p><p id="p-0067" num="0066">The data collection program <b>220</b> developed in the terminal <b>20</b> of each medical institution searches for and totals, for each data type, the number of pieces of data that matches the search condition instructed from the integration server <b>30</b> side or the like in the medical institution system MS to which the terminal <b>20</b> belongs and transmits the totalization result to the integration server <b>30</b>.</p><p id="p-0068" num="0067">The master model to be trained MM is a master model to be trained this time. The master model to be trained MM represents a learning model for obtaining an AI model that is desired to be released as a product. The master model to be trained MM may be simply described as &#x201c;master model&#x201d;.</p><p id="p-0069" num="0068">The integration server <b>30</b> may be on a computer network on which the development entity <b>80</b> of the AI model has access rights, and a form of the server may be a physical server, a virtual server, or the like. The integration server <b>30</b> may be installed in the medical institution network or may be installed outside the medical institution network. For example, the integration server <b>30</b> may be installed at a company that is located geographically away from the medical institution and that develops medical AI or may be installed on the cloud.</p><p id="p-0070" num="0069">The development entity <b>80</b> represents a company or the like that is trying to train the master model to be trained MM in order to commercialize the AI model or to further improve the performance of the existing AI model. The term development entity <b>80</b> also includes a developer, an operator, and the like belonging to the company and the like.</p><p id="p-0071" num="0070">The integration server <b>30</b> ascertains a possession situation of data that can be used as the learning data for each medical institution through the data collection program setting interface <b>32</b> and distributes the number of pieces of learning data used for the local learning on each terminal <b>20</b> of the plurality of medical institutions such that the required number of pieces of learning data for the entire learning is secured. At each medical institution, the local learning is executed by using the learning data having the number of pieces of data designated from the integration server <b>30</b>. The integration server <b>30</b> receives respective learning results from the terminals <b>20</b> of the plurality of medical institutions, integrates the learning results, and updates the master model MM.</p><p id="p-0072" num="0071">&#x3c;&#x3c;Example of AI Model&#x3e;&#x3e;</p><p id="p-0073" num="0072">The master model MM and the local model LM are collectively referred to as &#x201c;model to be trained&#x201d;. The model to be trained may be, for example, an AI model for medical image diagnosis assuming application to a computer aided detection/diagnosis (CAD) system. The term &#x201c;CAD&#x201d; includes concepts of both computer aided detection (CADe) and computer aided diagnosis (CADx). Further, the model to be trained may be, for example, an AI model for report creation support that supports creation of a document such as the comments on findings. The term &#x201c;comments on findings&#x201d; includes a concept of diagnostic report. The AI model is configured by using, for example, a hierarchical multi-layer neural network. In the local model LM, a network weight parameter is updated by deep learning using local data LD as learning data. The weight parameter includes a filter coefficient (weight of a connection between nodes) of a filter used for processing of each layer and a bias of a node.</p><p id="p-0074" num="0073">The term &#x201c;neural network&#x201d; is a mathematical model for information processing that simulates a mechanism of a brain-nervous system. Processing using the neural network can be realized by using a computer. A processing unit including the neural network may be configured as a program module.</p><p id="p-0075" num="0074">As a network structure of the neural network used for learning, an appropriate network structure is employed according to a type of data used for input. The AI model for medical image diagnosis may be configured by using, for example, various convolutional neural networks (CNNs) having a convolutional layer. The input data to the AI model may be, for example, medical images such as a two-dimensional image, a three-dimensional image, and a moving image. An output from the AI model may be, for example, information indicating a position of a disease region (lesion portion) or the like in the image, information indicating a class classification such as a disease name, or a combination of the pieces of information.</p><p id="p-0076" num="0075">The AI model that handles time-series data, document data, or the like may be configured by using, for example, various recurrent neural networks (RNNs). The time-series data includes, for example, electrocardiogram waveform data. The document data includes, for example, the comments on findings created by a doctor.</p><p id="p-0077" num="0076">&#x3c;&#x3c;Outline of Machine Learning Method&#x3e;&#x3e;</p><p id="p-0078" num="0077">[1] to [11] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represent the series of flows from the searching and collection of data used for learning to the local learning and further integration into the master model MM. In the following description, operations indicated by arrows and the like numbered [1] to [11] are expressed as operation [1], operation [2], . . . , operation [11]. The machine learning system <b>10</b> according to the present embodiment operates according to procedures 1 to 11 shown below.</p><p id="p-0079" num="0078">&#x3c;Procedure 1&#x3e; The integration server <b>30</b> comprises the data collection program setting interface <b>32</b> for the development entity <b>80</b> making a training plan of the AI model to designate the search condition. The development entity <b>80</b> can designate the search condition through the data collection program setting interface <b>32</b>.</p><p id="p-0080" num="0079">The operation [1] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents an operation in which the development entity <b>80</b> designates the search condition. The search condition is, for example, a condition such as totaling the number of pieces of data in which a ground glass-like shadow is detected as a result of lung CAD execution. This condition can be searched for by inquiring of a database that stores an AI processing result in each medical institution or the like. The lung CAD is an example of an AI processing module using a trained AI model that outputs a detection result of a lung disease region and/or a recognition result of a disease name and the like, using a computed tomography (CT) image of the lung as input data, for example. The term &#x201c;trained AI model&#x201d; here is an AI model that has already been delivered (completed) as a product. Hereinafter, such a trained AI model will be described as &#x201c;delivered AI model&#x201d;. The AI processing module for medical use is not limited to lung CAD and may include various types such as brain CAD and gastrointestinal CAD. The brain CAD outputs a detection result of a disease region and/or a recognition result of a disease name and the like, using a magnetic resonance imaging (Mill) image of the brain as input data, for example. The gastrointestinal CAD outputs a detection result of a disease region (lesion) and/or a recognition result of a disease name and the like, using an endoscopic image of a digestive system such as a stomach and/or an intestine as input data, for example.</p><p id="p-0081" num="0080">&#x3c;Procedure 2&#x3e; As the search condition used by the data collection program <b>220</b>, for example, structural data such as JavaScript object notation (JSON) is provided as a search condition setting file. The term &#x201c;JavaScript&#x201d; is a registered trademark. The operation [2] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents that the search condition setting file is provided to the data collection program <b>220</b>.</p><p id="p-0082" num="0081">&#x3c;Procedure 3&#x3e; The data collection program <b>220</b> reads the search condition setting file to search for data from a system that stores data that can be the learning target, such as the DICOM server <b>22</b> and/or the electronic medical record system <b>24</b>, in accordance with an instruction of the search condition setting file. The operation [3] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents processing of searching for the data via the data collection program <b>220</b>.</p><p id="p-0083" num="0082">The search condition setting file does not have to be a structural data file and may be any data having a format such as providing a search destination which the data collection program <b>220</b> searches for and a plurality of parameters or a single parameter necessary for constructing a search query to the search destination.</p><p id="p-0084" num="0083">The search condition may be a single search condition such as only the data in the DICOM server <b>22</b> in which a search target stores an image inspection result, or may be a search condition that is extended over a plurality of systems in the medical institution such as searching for the electronic medical record data of a patient having a finding of interstitial pneumonia in the electronic medical record system <b>24</b> and a test result image associated with the electronic medical record data.</p><p id="p-0085" num="0084">&#x3c;Procedure 4&#x3e; The data collection program <b>220</b> stores a location of data that matches the search condition in a data storage unit (search result storage unit) such as a database, totals the number of pieces of data, and transmits the totalization result to the integration server <b>30</b>. Only the number of pieces of data is transmitted here. The description &#x201c;only the number of pieces of data&#x201d; here means that the data itself that matches the search result, such as an image and electronic medical record data that satisfy the search condition, is not transmitted, but the information on the number of pieces of data that matches the search condition is transmitted. The operation [4] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents that the totalization result of the number of pieces of data is transmitted to the integration server <b>30</b> and that the integration server <b>30</b> receives the totalization result.</p><p id="p-0086" num="0085">&#x3c;Procedure 5&#x3e; The integration server <b>30</b> receives the totalization result from the data collection program <b>220</b> and stores the totalization result in a data storage unit (totalization result storage unit) such as a database.</p><p id="p-0087" num="0086">&#x3c;Procedure 6&#x3e; The development entity <b>80</b> planning to train the AI model sets how many pieces of data that matches the designated search condition are required, through the data collection program setting interface <b>32</b> of the integration server <b>30</b>. For example, the development entity <b>80</b> sets the number of pieces of data required for learning, such as a need for 1,000 pieces of data in which the ground glass-like shadow is detected as a result of the lung CAD execution. The operation [5] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents an input work in which the development entity <b>80</b> sets the required number of pieces of data (required number).</p><p id="p-0088" num="0087">&#x3c;Procedure 7&#x3e; The integration server <b>30</b> distributes how many pieces of data are required to be used for learning for the terminal <b>20</b> of each medical institution based on the search condition of the data necessary for learning and on the required number of the data and transmits the distribution information to the data collection program <b>220</b> existing in the medical institution system MS of each medical institution. The operation [6] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents the transmission of the distribution information. The distribution described herein means, for example, in a case where the need for 1,000 pieces of data in which the ground glass-like shadow is detected as a result of the lung CAD execution is input to the integration server <b>30</b>, that the number of pieces of data is assumed to be assigned to each medical institution such as 100 cases for a client of a hospital A, 46 cases for a hospital B, . . . , some cases for a hospital C, and the like.</p><p id="p-0089" num="0088">An upper limit is preferably set for the number of pieces of data to be distributed to each medical institution. In the distribution to each medical institution decided by the integration server <b>30</b>, the number of pieces of data used for the local learning at each medical institution is set, for example, up to 100 at maximum for one medical institution. In this case, a form may be employed in which a distribution rule is set such that up to 100 pieces of learning data are distributed to be used for learning in a case where the number of pieces of learning data that matches the search condition is 100 or more in a certain medical institution and such that 46 pieces of learning data are distributed to be used for learning in a case where the number of pieces of learning data that matches the search condition is less than 100, for example, the medical institution has only 46 pieces of learning data that matches the search condition, and the number of pieces of data used for learning in each medical institution is distributed until the required number of pieces of data (for example, 1,000) is reached. The distribution rule is not limited to the above example.</p><p id="p-0090" num="0089">&#x3c;Procedure 8&#x3e; The data collection program <b>220</b> that has received the number of pieces of data that matches the search condition to be used for learning from the integration server <b>30</b>, as necessary, moves the data that matches the condition to a data storage location where the local learning management program <b>250</b> can read the data as the learning data and then activates the local learning management program <b>250</b> to start the training of the local model to be trained (local learning model) LM. The operation [7] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents that the local learning management program <b>250</b> is activated, and the operation [8] represents that the training of the local model to be trained LM is started.</p><p id="p-0091" num="0090">Hereafter, the data used for learning will be identical until the setting is changed or until the training of the master model MM in the integration server <b>30</b> is completed. A ring-shaped arrow shown as the operation [9] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents that the training is performed on the local model LM.</p><p id="p-0092" num="0091">&#x3c;Procedure 9&#x3e; The local learning management program <b>250</b> transmits the learned weight parameter to the integration server <b>30</b> after the training of the local model LM is completed. The integration server <b>30</b> integrates learned weight parameters acquired from the terminal <b>20</b> in each medical institution and updates the master model to be trained MM. The operation [10] in <figref idref="DRAWINGS">FIG. <b>1</b></figref> represents that the local learning management program <b>250</b> acquires the learned weight parameter of the local model LM after the training is completed, and the operation [11] represents that the learned weight parameter is transmitted to the integration server <b>30</b>.</p><p id="p-0093" num="0092">The learning completion condition of the local model LM may be a condition that ends after a designated number of iterations, a condition that data for verification is held in the medical institution network, correct answer data shown in the data for verification is compared with an inference result of the model LM to calculate an inference accuracy, and the training is performed until a designated ratio of accuracy improvement is achieved, or a condition that a time limit is set and that the training is performed within the time limit.</p><p id="p-0094" num="0093">&#x3c;Procedure 10&#x3e; Hereafter, the training of the local learning model and the integration of the weight parameters of the local learning model in the integration server <b>30</b> are repeated until the inference accuracy of the master model MM reaches the desired accuracy.</p><p id="p-0095" num="0094">The flow described in procedures 1 to 10 above is an example in which the total number of pieces of data (total number) that matches the search condition is equal to or larger than the number of pieces of data required for learning and is a flow in a case where the total number of pieces of learning data is sufficient. However, a state is assumed in actual operation where the number of pieces of data required for learning is not sufficient.</p><p id="p-0096" num="0095">&#x3c;&#x3c;Countermeasure in Case where Total Number of Pieces of Learning Data is Insufficient&#x3e;&#x3e;</p><p id="p-0097" num="0096">Hereinafter, a specific example of behavior of the system in a case where the total number of pieces of learning data is insufficient for the required number will be described. Prior to the description, necessary prerequisites are described below.</p><p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram for describing a type of learning data. Regarding the type of data used for learning (learning data), &#x201c;primary data&#x201d; and &#x201c;secondary data&#x201d; are defined as follows.</p><p id="p-0099" num="0098">The term &#x201c;primary data&#x201d; is defined as data that cannot be automatically generated systematically, such as an image that cannot be generated unless a patient is imaged by using a modality, such as an X-ray imaging apparatus or an Mill apparatus, or comments on findings that cannot be generated unless written by a doctor.</p><p id="p-0100" num="0099">On the other hand, &#x201c;secondary data&#x201d; is defined as data that can be automatically generated systematically, such as data obtained by operating lung disease region extraction AI for an image or the like that has already been captured. The secondary data is data that can be generated by a computer using the primary data.</p><p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows, as an example of the primary data, a CT image A and comments on findings associated with the CT image A. The CT image A is an image captured by a CT apparatus. The comments on findings associated with the CT image A are comments on findings written by the doctor who made a diagnosis using the CT image A. The term &#x201c;associated&#x201d; means &#x201c;correlated&#x201d;. As an example of the secondary data, a processing result of the lung disease region extraction AI executed to the CT image A is shown. The data of this processing result may be, for example, a bounding box and/or a segmentation image showing a lung disease region extracted from the CT image A.</p><p id="p-0102" num="0101">The following assumptions are made as a combination of the model to be trained as the local model LM and the master model MM described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref> and the type of the learning data used for learning.</p><p id="p-0103" num="0102">[Assumption A] A case where the training of the model to be trained is performed by using only the primary data as learning data, such as a combination of the CT image A and the comments on findings associated with the CT image A, as described in the left column of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0104" num="0103">[Assumption B] A case where the training of the model to be trained is performed by using, as learning data, a combination of the primary data of the CT image A and the comments on findings associated with the CT image A and the secondary data such as the processing result of the lung disease region extraction AI obtained by operating the delivered (completed) AI model to the CT image A as described in the left and right columns of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0105" num="0104">[Assumption C] A case where the training of the model to be trained is performed by using only the secondary data as learning data, as described in the right column of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0106" num="0105">Under the above assumptions, an example of the operation in the machine learning system <b>10</b> in a case where the total number of pieces of data required for learning is insufficient will be described below.</p><p id="p-0107" num="0106"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a conceptual diagram showing an outline of the operation of the machine learning system <b>10</b> in a case where the total number of pieces of learning data is insufficient. The configuration shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> will be described focusing on differences from <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0108" num="0107">The development entity <b>80</b> knows how many pieces of data that matches the set search condition exist in total through the system in a flow of operations [1] to [4] of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The operations up to [1] to [4] are performed in the same flow as &#x3c;Procedure 1&#x3e; to &#x3c;Procedure 4&#x3e; described above.</p><p id="p-0109" num="0108">The development entity <b>80</b> knows that, for example, 100 pieces of data that matches the search condition exist through the data collection program setting interface <b>32</b>. However, a state is assumed in which the development entity <b>80</b> wants to actually use 200 pieces of data for learning, and 100 pieces of data required for learning are insufficient. In such a case, since a possible response of the development entity <b>80</b> differs depending on which assumption case of the above assumptions A, B, and C is employed for the data required for learning, a countermeasure operation will be described for each assumption case.</p><p id="p-0110" num="0109">[Case of Assumption A]</p><p id="p-0111" num="0110">In a case where the learning data is insufficient in the learning that uses only the primary data as the learning data as in Assumption A, the development entity <b>80</b> needs to wait until the necessary data is generated by each medical institution. In this case, it is troublesome for the development entity <b>80</b> itself to search and check whether the required number of pieces of data has been collected each time. Therefore, there is a preferable configuration in which the system of the integration server <b>30</b> is set to be notified at a stage where the total number of pieces of the data that matches the search condition exceeds 200 and in which the system notifies the development entity <b>80</b> as soon as the condition of the required number of pieces of data is met.</p><p id="p-0112" num="0111">[Case of Assumption B]</p><p id="p-0113" num="0112">In a case where the primary data and the secondary data are used as the learning data as in the case of assumption B and in a case where there is an insufficiency of 100 pieces of learning data as a whole since there are 200 or more pieces of primary data but only 100 pieces of secondary data, the secondary data can be automatically generated programmatically. Therefore, the development entity <b>80</b> instructs the system to additionally generate the secondary data. A flow from the instruction for the additional generation to the actual generation of additional secondary data is described below.</p><p id="p-0114" num="0113">In an operation [5] in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the development entity <b>80</b> designates how many pieces of result data generated from which delivered AI model <b>26</b> is required via the data collection program setting interface <b>32</b>.</p><p id="p-0115" num="0114">The data collection program setting interface <b>32</b> distributes an execution condition of the additional generation designated in the operation [5] in <figref idref="DRAWINGS">FIG. <b>3</b></figref> to the data collection program <b>220</b> in each medical institution. An operation [6] in <figref idref="DRAWINGS">FIG. <b>3</b></figref> represents a flow of distribution related to this additional generation. The distribution here is performed in a case where 100 additional execution results of the delivered AI model <b>26</b> are desired as a whole. For example, assignment for sharing work of addition processing, such as execution of the additional generation processing for 10 execution results in each facility in a case where there are 10 medical institutions, is assumed to be performed.</p><p id="p-0116" num="0115">The data collection program <b>220</b> of each medical institution that has received the execution condition by the operation [6] causes the delivered AI model <b>26</b> that matches the execution condition to execute the processing for 10 execution results. An operation [7] in <figref idref="DRAWINGS">FIG. <b>3</b></figref> represents that the data collection program <b>220</b> causes the delivered AI model <b>26</b> according to the designated execution condition to execute the addition processing.</p><p id="p-0117" num="0116">An operation [8] in <figref idref="DRAWINGS">FIG. <b>3</b></figref> indicates that the delivered AI model <b>26</b> that has received the execution instruction in the operation [7] additionally generates the secondary data. An operation [9] in <figref idref="DRAWINGS">FIG. <b>3</b></figref> indicates that the secondary data (result data) generated by the delivered AI model <b>26</b> is stored in an appropriate location.</p><p id="p-0118" num="0117">In a case where the generation of the designated number of pieces of secondary data is finished, the delivered AI model <b>26</b> notifies the data collection program <b>220</b> that the additional generation processing ends. An operation [10] in <figref idref="DRAWINGS">FIG. <b>3</b></figref> represents an operation of notifying the data collection program <b>220</b> that the addition processing for the designated number of pieces of data ends.</p><p id="p-0119" num="0118">The data collection program <b>220</b> that has received this notification notifies the local learning management program <b>250</b> that the necessary learning data has been prepared in an operation [11] to cause the local learning management program <b>250</b> to start the training of the local model to be trained LM. A flow of subsequent operations related to learning is the same repetition as the flow of the operations [8] to [11] described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Operations [12], [13], and [14] in <figref idref="DRAWINGS">FIG. <b>3</b></figref> are the same as the operations [9], [10], and [11] in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0120" num="0119">[Case of Assumption C]</p><p id="p-0121" num="0120">In a case where the learning data for the model to be trained that uses only the secondary data as the learning data is insufficient as in the assumption C, the secondary data is additionally generated in the same flow as the operations [5] to [14] described in the case of the assumption B, and the learning proceeds.</p><heading id="h-0008" level="1">System Configuration Example</heading><p id="p-0122" num="0121">Next, an example of a specific configuration of the machine learning system <b>10</b> will be described. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically showing a system configuration example of the machine learning system <b>10</b>. First, an example of a medical institution network <b>50</b> will be described. For simplicity of illustration, <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example in which the medical institution network <b>50</b> having an identical system configuration is installed in each of a plurality of medical institutions. However, a medical institution network having a different system configuration for each medical institution may be constructed.</p><p id="p-0123" num="0122">The medical institution network <b>50</b> is a computer network including a CT apparatus <b>52</b>, an MRI apparatus <b>54</b>, a computed radiography (CR) apparatus <b>56</b>, a DICOM server <b>22</b>, an electronic medical record system <b>24</b>, an AI server <b>60</b>, terminals <b>20</b> and <b>62</b>, and an internal communication line <b>66</b>.</p><p id="p-0124" num="0123">The medical institution network <b>50</b> is not limited to the CT apparatus <b>52</b>, the MM apparatus <b>54</b>, and the CR apparatus <b>56</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. Instead of some or all of the apparatuses or in addition to the apparatuses, the medical institution network <b>50</b> may include at least one or a combination of a digital X-ray imaging apparatus, an angiography X-ray diagnosis apparatus, an ultrasound diagnostic apparatus, a positron emission tomography (PET) apparatus, an endoscopic apparatus, a mammography apparatus, and various inspection apparatuses (modalities) which are not illustrated. There may be various combinations of types of inspection apparatuses connected to the medical institution network <b>50</b> for each medical institution.</p><p id="p-0125" num="0124">The DICOM server <b>22</b> performs a communication with another apparatus via the internal communication line <b>66</b>, and transmits and receives various pieces of data including image data. The DICOM server <b>22</b> receives various pieces of data including image data and the like generated by each inspection apparatus such as the CT apparatus <b>52</b>, the Mill apparatus <b>54</b>, and the CR apparatus <b>56</b> through the internal communication line <b>66</b>, and stores and manages the data in a recording medium such as a large-capacity external storage device.</p><p id="p-0126" num="0125">A storage format of the image data and the communication between the apparatuses through the internal communication line <b>66</b> are based on a protocol such as DICOM. Various pieces of data stored on the medical institution network <b>50</b> such as the DICOM server <b>22</b> and the electronic medical record system <b>24</b> can be used as learning data. The learning data created based on the data stored in the DICOM server <b>22</b> and/or in the electronic medical record system <b>24</b> and the like can be stored in the terminal <b>20</b> or in another appropriate storage.</p><p id="p-0127" num="0126">The AI server <b>60</b> executes CAD processing using an AI model already provided as a commercial version. The AI server <b>60</b> includes at least one AI processing module, such as lung CAD and/or brain CAD. The AI processing module in the AI server <b>60</b> corresponds to the delivered AI model <b>26</b> described with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The AI processing module in the AI server <b>60</b> and the delivered AI model <b>26</b> are examples of &#x201c;third program&#x201d; in the present disclosure. The AI server <b>60</b> may include a plurality of types of delivered AI models <b>26</b>.</p><p id="p-0128" num="0127">The AI server <b>60</b> can acquire the data from the DICOM server <b>22</b> and the like via the internal communication line <b>66</b>. The various pieces of data stored in databases of the DICOM server <b>22</b> and/or the electronic medical record system <b>24</b> and the like and various pieces of information including the inference result by the AI server <b>60</b> can be displayed on the terminals <b>20</b> and <b>62</b> connected to the internal communication line <b>66</b>.</p><p id="p-0129" num="0128">As described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the terminal <b>20</b> is a training processing terminal that executes the local learning. The terminal <b>20</b> has a communication function for communicating with the integration server <b>30</b> and is connected to the integration server <b>30</b> via a wide area communication line <b>70</b>. The terminal <b>20</b> can acquire the data from the DICOM server <b>22</b> and/or from the electronic medical record system <b>24</b> and the like via the internal communication line <b>66</b>. Further, the terminal <b>20</b> has authority to execute the AI processing module in the AI server <b>60</b> and causes the AI processing module to operate for the additional generation of new learning data in a case where an instruction indicating that the data is required to be additionally generated is received from the integration server <b>30</b>. Some or all of processing functions of the terminal <b>20</b> may be loaded on the AI server <b>60</b>.</p><p id="p-0130" num="0129">On the other hand, a terminal <b>62</b> may be a display terminal referred to as a PACS viewer or a DICOM viewer. A plurality of terminals <b>62</b> may be connected to the medical institution network <b>50</b>. A form of the terminals <b>20</b> and <b>62</b> is not particularly limited and may be a personal computer, a workstation, a tablet terminal, or the like.</p><p id="p-0131" num="0130">As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the medical institution network <b>50</b> having the same system configuration is constructed in each of the plurality of medical institutions. The integration server <b>30</b> communicates with the terminal <b>20</b> of each medical institution network via the wide area communication line <b>70</b>. The wide area communication line <b>70</b> is an example of &#x201c;communication line&#x201d; according to the present disclosure.</p><p id="p-0132" num="0131">&#x3c;&#x3c;Configuration Example of Integration Server <b>30</b>&#x3e;&#x3e;</p><p id="p-0133" num="0132"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram showing a configuration example of the integration server <b>30</b>. The integration server <b>30</b> can be formed by a computer system configured by using one or a plurality of computers. The integration server <b>30</b> is formed by installing a program on a computer.</p><p id="p-0134" num="0133">The integration server <b>30</b> comprises a processor <b>302</b>, a non-transitory tangible computer-readable medium <b>304</b>, a communication interface <b>306</b>, an input/output interface <b>308</b>, a bus <b>310</b>, an input device <b>314</b>, and a display device <b>316</b>. The processor <b>302</b> is an example of &#x201c;second processor&#x201d; according to the present disclosure. The computer-readable medium <b>304</b> is an example of &#x201c;second computer-readable medium&#x201d; according to the present disclosure.</p><p id="p-0135" num="0134">The processor <b>302</b> includes a central processing unit (CPU). The processor <b>302</b> may include a graphics processing unit (GPU). The processor <b>302</b> is connected to the computer-readable medium <b>304</b>, the communication interface <b>306</b>, and the input/output interface <b>308</b> via the bus <b>310</b>. The input device <b>314</b> and the display device <b>316</b> are connected to the bus <b>310</b> via the input/output interface <b>308</b>.</p><p id="p-0136" num="0135">The computer-readable medium <b>304</b> includes a memory as a main memory and a storage as an auxiliary storage device. The computer-readable medium <b>304</b> may be, for example, a semiconductor memory, a hard disk drive (HDD) device, a solid state drive (SSD) device, or a combination of these devices.</p><p id="p-0137" num="0136">The integration server <b>30</b> is connected to the wide area communication line <b>70</b> (refer to <figref idref="DRAWINGS">FIG. <b>4</b></figref>) via the communication interface <b>306</b>.</p><p id="p-0138" num="0137">The computer-readable medium <b>304</b> stores various programs and pieces of data including a data collection program setting I/F program <b>320</b>, a synchronization program <b>330</b>, a master model to be trained MM, a master model learning management program <b>340</b>, a display control program <b>350</b>, and a database <b>360</b>.</p><p id="p-0139" num="0138">The data collection program setting I/F program <b>320</b> is a program for realizing the data collection program setting interface <b>32</b> described with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>3</b></figref>. In a case where the processor <b>302</b> executes a command of the data collection program setting I/F program <b>320</b>, a computer is caused to function as the data collection program setting interface <b>32</b> (refer to <figref idref="DRAWINGS">FIG. <b>1</b></figref>), together with user interfaces including the input device <b>314</b> and the display device <b>316</b>.</p><p id="p-0140" num="0139">By executing the command of the data collection program setting I/F program <b>320</b>, the processor <b>302</b> functions as a search condition input receiving unit <b>321</b>, a setting file generation unit <b>322</b>, a totalization result acquisition unit <b>323</b>, and a learning data number distribution unit <b>324</b>. The search condition input receiving unit <b>321</b> receives the input of the search condition from an operator of the development entity <b>80</b>. The setting file generation unit <b>322</b> generates the search condition setting file based on the input search condition. The totalization result acquisition unit <b>323</b> acquires, from the terminal <b>20</b> of each medical institution, the totalization result of the number of pieces of data that matches the search condition and stores the totalization result in the database <b>360</b>.</p><p id="p-0141" num="0140">The learning data number distribution unit <b>324</b> distributes the number of pieces of learning data used for learning at each medical institution according to a predetermined distribution rule based on the totalization result obtained from the terminal <b>20</b> of each medical institution and transmits the distribution information to the data collection program <b>220</b> of each medical institution.</p><p id="p-0142" num="0141">The processor <b>302</b> executes the command of the data collection program setting I/F program <b>320</b> to function as a notification setting input receiving unit <b>325</b>, a notification determination unit <b>326</b>, an addition instruction receiving unit <b>327</b>, and an additional generation distribution unit <b>328</b>. The notification setting input receiving unit <b>325</b> receives an input related to the notification setting described as [Case of Assumption A]. The notification determination unit <b>326</b> determines whether or not the total number of pieces of the data that matches the search condition is equal to or larger than the required number to determine whether or not the notification is possible. As described as [Case of Assumption B] and [Case of Assumption C], the addition instruction receiving unit <b>327</b> receives an input for designating the type and number of pieces of data to be added. The additional generation distribution unit <b>328</b> distributes the additional generation processing to each medical institution based on the designated type and on the number of pieces of additional data. The additional generation distribution unit <b>328</b> generates additional generation distribution information including designation of the number of pieces of additional data in a case where each terminal <b>20</b> is requested to additionally generate data and transmits this additional generation distribution information to each terminal <b>20</b>.</p><p id="p-0143" num="0142">The synchronization program <b>330</b> is a program for providing the data of the master model to be trained MM to the terminal <b>20</b> of each medical institution via the communication interface <b>306</b> and synchronizing the local model LM of each terminal <b>20</b> with the master model MM. The processor <b>302</b> executes a command of the synchronization program <b>330</b> to cause the computer to function as a synchronization processing unit. The synchronization program <b>330</b> may be incorporated as a program module of the master model learning management program <b>340</b>.</p><p id="p-0144" num="0143">The master model learning management program <b>340</b> integrates the learned weight parameters as the learning results of the local learning performed in the terminals <b>20</b> in the plurality of medical institutions to perform processing of updating the weight parameter of the master model to be trained MM. The processor <b>302</b> executes a command of the master model learning management program <b>340</b> to cause the computer to function as a learned weight parameter acquisition unit <b>341</b>, a parameter integration unit <b>342</b>, and a model update unit <b>343</b>. The learned weight parameter acquisition unit <b>341</b> acquires the learned weight parameter as the learning result of the local learning performed in the terminals <b>20</b> in the plurality of medical institutions.</p><p id="p-0145" num="0144">The parameter integration unit <b>342</b> integrates the learned weight parameters obtained from the plurality of medical institutions. The integration processing may be processing of obtaining a simple average value or processing of obtaining a weighted average value with appropriate weighting. The model update unit <b>343</b> updates the parameter of the master model to be trained MM by an integration parameter calculated by the parameter integration unit <b>342</b>.</p><p id="p-0146" num="0145">Although not shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the computer-readable medium <b>304</b> of the integration server <b>30</b> may store an accuracy verification program for verifying the inference accuracy of the master model to be trained MM and data for verification. For example, the inference accuracy is checked for a master model candidate including the parameter integrated by the parameter integration unit <b>342</b>, and the model update unit <b>343</b> may update the master model MM in a case where a model with inference accuracy exceeding an accuracy target value is obtained. The accuracy target value is a value indicating a target inference accuracy. For example, the inference accuracy is set higher than the inference accuracy of the latest version of the master model MM, and the master model MM and the accuracy target value are updated every time the inference accuracy is improved. Alternatively, for example, the accuracy target value may be set to a level of accuracy that can be commercialized in place of the master model MM.</p><p id="p-0147" num="0146">The data collection program setting I/F program <b>320</b> and the master model learning management program <b>340</b> are examples of &#x201c;second program&#x201d; in the present disclosure.</p><p id="p-0148" num="0147">Further, in a case where the processor <b>302</b> executes a command of the display control program <b>350</b>, the computer is caused to function as a display control unit. The display control unit generates a signal for display required for a display output to the display device <b>316</b> and performs display control of the display device <b>316</b>.</p><p id="p-0149" num="0148">The display device <b>316</b> is configured with, for example, a liquid crystal display, an organic electro-luminescence (OEL) display, a projector, or an appropriate combination thereof. The input device <b>314</b> is configured with, for example, a keyboard, a mouse, a touch panel, another pointing device, a voice input device, or an appropriate combination thereof. The input device <b>314</b> receives various inputs from an operator. The display device <b>316</b> and the input device <b>314</b> may be integrally configured by using a touch panel.</p><p id="p-0150" num="0149">The display device <b>316</b> can display the inference accuracy in each learning iteration of each master model to be trained MM. The operator can check the progress of training of the master model to be trained MM via the information displayed on the display device <b>316</b>.</p><p id="p-0151" num="0150">&#x3c;&#x3c;Example of Data Collection Program Setting I/F Program <b>320</b>&#x3e;&#x3e;</p><p id="p-0152" num="0151"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart showing an example of the operation of the integration server <b>30</b> based on the data collection program setting I/F program <b>320</b>. Steps in the flowchart shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> are executed by the processor <b>302</b> of the integration server <b>30</b> according to the command of the data collection program setting I/F program <b>320</b>.</p><p id="p-0153" num="0152">In step S<b>11</b>, the processor <b>302</b> receives the input of the search condition. The operator of the development entity <b>80</b> can input information designating the search condition from the input device <b>314</b>.</p><p id="p-0154" num="0153">In step S<b>12</b>, the processor <b>302</b> generates the search condition setting file according to the information input in step S<b>11</b>.</p><p id="p-0155" num="0154">In step S<b>13</b>, the processor <b>302</b> transmits the search condition setting file to the terminal <b>20</b> of each medical institution.</p><p id="p-0156" num="0155">In step S<b>14</b>, the processor <b>302</b> receives, from each terminal <b>20</b>, the totalization result of the number of pieces of data that matches the search condition. A time of acquiring the totalization result from each terminal <b>20</b> may be an appropriate time for each terminal <b>20</b>.</p><p id="p-0157" num="0156">In step S<b>15</b>, the processor <b>302</b> stores the totalization result from each terminal <b>20</b> in the database <b>360</b> or the like. The processor <b>302</b> can display the totalization result from each terminal <b>20</b> on the display device <b>316</b>.</p><p id="p-0158" num="0157">In step S<b>16</b>, the processor <b>302</b> receives the input of the data type and the number of pieces of data required for learning. In a case where the data type required for learning is the same as the data type designated in the search condition, input contents of the search condition may be used. The operator of the development entity <b>80</b> can input information designating the data type and the number of pieces of data required for learning from the input device <b>314</b>.</p><p id="p-0159" num="0158">In step S<b>17</b>, the processor <b>302</b> determines whether or not the total number of pieces of learning data is sufficient for the required number. In a case where the determination result in step S<b>17</b> is a Yes determination, that is, in a case where the total number of pieces of learning data is equal to or larger than the required number, the processor <b>302</b> proceeds to step S<b>18</b>.</p><p id="p-0160" num="0159">In step S<b>18</b>, the processor <b>302</b> distributes the number of pieces of data to each medical institution. Then, in step S<b>19</b>, the processor <b>302</b> transmits the distribution information including the number of pieces of learning data for each medical institution distributed in step S<b>18</b> to the terminal <b>20</b> of each medical institution.</p><p id="p-0161" num="0160">On the other hand, in a case where the determination result in step S<b>17</b> is a No determination, that is, in a case where the total number of pieces of learning data is less than the required number, the processor <b>302</b> proceeds to step S<b>21</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p><p id="p-0162" num="0161">In step S<b>21</b>, the processor <b>302</b> determines whether or not the insufficient data is only the primary data. This determination processing is a step of determining whether or not the case is such as [Case of Assumption A].</p><p id="p-0163" num="0162">In a case where the determination result in step S<b>21</b> is a Yes determination, the processor <b>302</b> proceeds to step S<b>22</b>.</p><p id="p-0164" num="0163">In step S<b>22</b>, the processor <b>302</b> receives an input of a notification setting in a case where the notification is made at the stage where the required number of pieces of primary data is prepared.</p><p id="p-0165" num="0164">In step S<b>23</b>, the processor <b>302</b> waits for the necessary data to be newly generated. The processor <b>302</b> receives information on the latest totalization result from the terminal <b>20</b> of each medical institution at an appropriate time. With the generation of new primary data in the medical institution system MS, the information on the totalization result is updated.</p><p id="p-0166" num="0165">In step S<b>24</b>, the processor <b>302</b> determines whether or not the number of pieces of insufficient primary data satisfies the required number. In a case where the determination result in step S<b>24</b> is a No determination, that is, in a case where the primary data is insufficient, the processor <b>302</b> returns to step S<b>23</b>.</p><p id="p-0167" num="0166">In a case where the determination result in step S<b>24</b> is a Yes determination, that is, in a case where the required number of pieces of primary data or more are prepared, the processing proceeds to step S<b>25</b>.</p><p id="p-0168" num="0167">In step S<b>25</b>, the processor <b>302</b> makes a notification informing that the number of pieces of data required for learning is satisfied. The development entity <b>80</b> can receive this notification through the display device <b>316</b>.</p><p id="p-0169" num="0168">On the other hand, in a case where the determination result in step S<b>21</b> is a No determination, the processor <b>302</b> proceeds to step S<b>31</b>. In step S<b>31</b>, the processor <b>302</b> determines whether or not the insufficient data is only the secondary data. This determination processing is a step of determining whether or not the case is such as [Case of Assumption B] or [Case of Assumption C]. Meanwhile, in a case where the determination result in step S<b>23</b> is a Yes determination, the processor <b>302</b> proceeds to step S<b>32</b>.</p><p id="p-0170" num="0169">In step S<b>32</b>, the processor <b>302</b> receives the input of the delivered AI model to be used and the required number of pieces of data to be added in order to additionally generate new secondary data. The operator of the development entity <b>80</b> can input information such as a required data type and the number of pieces of additional data from the input device <b>314</b>.</p><p id="p-0171" num="0170">In step S<b>33</b>, the processor <b>302</b> distributes the number of pieces of data to be additionally generated to each medical institution based on the information designated in step S<b>32</b>.</p><p id="p-0172" num="0171">In step S<b>34</b>, the processor <b>302</b> transmits the execution condition of the additional generation processing distributed to each medical institution to the terminal <b>20</b> of each medical institution.</p><p id="p-0173" num="0172">After step S<b>34</b> or step S<b>25</b>, the processor <b>302</b> proceeds to step S<b>18</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0174" num="0173">Further, in a case where the determination result in step S<b>31</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a No determination, that is, in a case where both types of primary data and secondary data are insufficient, the processor <b>302</b> proceeds to step S<b>41</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref>. Steps S<b>41</b> to S<b>44</b> are the same as the corresponding steps of steps S<b>22</b> to S<b>25</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>. After step S<b>44</b>, in step S<b>45</b>, the processor <b>302</b> determines whether or not the secondary data needs to be added.</p><p id="p-0175" num="0174">During a period in a case where new primary data is generated, new secondary data may also be generated. In a case where the determination result in step S<b>45</b> is a Yes determination, the processor <b>302</b> proceeds to step S<b>46</b>. Steps S<b>46</b> to S<b>48</b> are the same as the corresponding steps of steps S<b>32</b> to S<b>34</b> in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. After step S<b>48</b>, the processor <b>302</b> proceeds to step S<b>18</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0176" num="0175">On the other hand, in a case where the determination result of step S<b>45</b> in <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a No determination, steps S<b>46</b> to S<b>48</b> are skipped, and the processing proceeds to step S<b>18</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0177" num="0176">The processor <b>302</b> ends the flowchart of <figref idref="DRAWINGS">FIG. <b>6</b></figref> after step S<b>19</b>.</p><p id="p-0178" num="0177">&#x3c;&#x3c;Configuration Example of Terminal <b>20</b> on Medical Institution Network <b>50</b>&#x3e;&#x3e;</p><p id="p-0179" num="0178"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram showing a configuration example of the terminal <b>20</b> on the medical institution network <b>50</b>. The terminal <b>20</b> performing the local learning can be formed by a computer system configured by using one or a plurality of computers.</p><p id="p-0180" num="0179">The terminal <b>20</b> comprises a processor <b>202</b>, a non-transitory tangible computer-readable medium <b>204</b>, a communication interface <b>206</b>, an input/output interface <b>208</b>, a bus <b>210</b>, an input device <b>214</b>, and a display device <b>216</b>. A hardware configuration of the terminal <b>20</b> may be the same as the hardware configuration of the integration server <b>30</b> described with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>. That is, the hardware configurations of the processor <b>202</b>, the computer-readable medium <b>204</b>, the communication interface <b>206</b>, the input/output interface <b>208</b>, the bus <b>210</b>, the input device <b>214</b>, and the display device <b>216</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> may be the same as the corresponding elements shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0181" num="0180">The terminal <b>20</b> is an example of &#x201c;information processing apparatus&#x201d; according to the present disclosure. The processor <b>202</b> is an example of &#x201c;first processor&#x201d; according to the present disclosure. The computer-readable medium <b>204</b> is an example of &#x201c;first computer-readable medium&#x201d; according to the present disclosure.</p><p id="p-0182" num="0181">The terminal <b>20</b> is connected to a learning data storage unit <b>280</b> via the communication interface <b>206</b> or via the input/output interface <b>208</b>. The learning data storage unit <b>280</b> is configured to include a storage that stores the learning data to be used for machine learning by the terminal <b>20</b>. The term &#x201c;learning data&#x201d; is data for training used for machine learning and is synonymous with &#x201c;data for learning&#x201d; or &#x201c;training data&#x201d;. The learning data storage unit <b>280</b> may be a storage or the like of the DICOM server <b>22</b> and/or of the electronic medical record system <b>24</b> described with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref> and may be a storage corresponding to &#x201c;appropriate location&#x201d; described as the operation [9] of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0183" num="0182">Here, an example in which the learning data storage unit <b>280</b> and the terminal <b>20</b> that executes the training processing are configured as separate apparatuses will be described. However, the functions may be formed by one computer, or the processing functions may be shared and formed by two or more computers.</p><p id="p-0184" num="0183">The computer-readable medium <b>204</b> of the terminal <b>20</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> stores various programs, which include the data collection program <b>220</b> and the local learning management program <b>250</b>, and data. The data collection program <b>220</b> and the local learning management program <b>250</b> are examples of &#x201c;first program&#x201d; in the present disclosure.</p><p id="p-0185" num="0184">The processor <b>202</b> executes a command of the data collection program <b>220</b> to cause the computer to function as a search condition setting file acquisition unit <b>221</b>, a data search unit <b>222</b>, a search result storage unit <b>223</b>, a totalization result transmission processing unit <b>224</b>, a distribution information acquisition unit <b>225</b>, and an additional generation processing unit <b>226</b>. The search condition setting file acquisition unit <b>221</b> acquires the search condition setting file from the integration server <b>30</b>.</p><p id="p-0186" num="0185">The data search unit <b>222</b> searches for the data that matches the search condition from a database or the like on the medical institution network <b>50</b> based on the search condition described in the search condition setting file. The search result by the data search unit <b>222</b> is stored in the search result storage unit <b>223</b>. The totalization result transmission processing unit <b>224</b> performs processing of totaling the search results stored in the search result storage unit <b>223</b> and transmitting information on the number of pieces of data that matches the search condition (totalization result) to the integration server <b>30</b>.</p><p id="p-0187" num="0186">The distribution information acquisition unit <b>225</b> acquires, from the integration server <b>30</b>, the distribution information including the designation of the number of pieces of data to be used for learning. The data collection program <b>220</b> causes the local learning management program <b>250</b> to perform the local learning using the learning data of the number of pieces of data designated in the distribution information.</p><p id="p-0188" num="0187">In a case where the total number of pieces of data required for learning is less than the required number, the additional generation processing unit <b>226</b> causes the delivered AI model <b>26</b> to operate to additionally generate the number of pieces of additional data related to the designation in accordance with the instruction for the additional generation from the integration server <b>30</b>.</p><p id="p-0189" num="0188">The processor <b>202</b> executes a command of the local learning management program <b>250</b> to cause the computer to function as a synchronization processing unit <b>251</b>, a learning data acquisition unit <b>252</b>, the local model to be trained LM, an error calculation unit <b>254</b>, an optimizer <b>255</b>, a learning result storage unit <b>256</b>, and a learning result transmission processing unit <b>257</b>.</p><p id="p-0190" num="0189">The synchronization processing unit <b>251</b> communicates with the integration server <b>30</b> via the communication interface <b>206</b> to synchronize the master model to be trained MM in the integration server <b>30</b> with the local model to be trained LM in the terminal <b>20</b> side.</p><p id="p-0191" num="0190">The learning data acquisition unit <b>252</b> acquires the learning data that matches the search condition from the learning data storage unit <b>280</b>. The number of pieces of learning data used for local learning is the number of pieces of data designated in the distribution information. The learning data acquisition unit <b>252</b> may be configured to include a data input terminal for receiving data from an external apparatus or from another signal processing unit in the apparatus. Further, the learning data acquisition unit <b>252</b> may be configured to include the communication interface <b>206</b>, the input/output interface <b>208</b>, a media interface for performing reading and writing on a portable external storage medium such as a memory card (not shown), or an appropriate combination of these interfaces.</p><p id="p-0192" num="0191">The learning data acquired via the learning data acquisition unit <b>252</b> is input to the local model to be trained LM.</p><p id="p-0193" num="0192">The error calculation unit <b>254</b> calculates an error between a predicted value indicated by a score which is output from the local model to be trained LM and the correct answer data. The error calculation unit <b>254</b> evaluates the error using a loss function. The loss function may be, for example, a cross entropy or a mean square error.</p><p id="p-0194" num="0193">The optimizer <b>255</b> performs processing of updating a weight parameter of the local model to be trained LM from the calculation result of the error calculation unit <b>254</b>. The optimizer <b>255</b> performs calculation processing of obtaining an update amount of the weight parameter of the local model to be trained LM and update processing of the weight parameter of the local model to be trained LM according to the calculated update amount of the weight parameter, by using the error calculation result obtained from the error calculation unit <b>254</b>. The optimizer <b>255</b> updates the weight parameter based on an algorithm such as backpropagation.</p><p id="p-0195" num="0194">The terminal <b>20</b> in which the local learning management program <b>250</b> is incorporated functions as a local learning apparatus that executes the machine learning on the terminal <b>20</b> by using the local data in the medical institution as learning data. The terminal <b>20</b> reads the learning data, which is the local data, from the learning data storage unit <b>280</b> to execute the machine learning for the local model to be trained LM using the learning data of the number of pieces of data designated in the distribution information. The terminal <b>20</b> can update, in a case where the learning data is read in units of mini-batch in which a plurality of pieces of learning data are collected, the weight parameter.</p><p id="p-0196" num="0195">The local learning management program <b>250</b> repeats an iteration of the training processing until a learning end condition is satisfied for the local model to be trained LM. After the learning end condition is satisfied, the weight parameter of the local model to be trained LM is stored in the learning result storage unit <b>256</b> as the learning result.</p><p id="p-0197" num="0196">The learning result transmission processing unit <b>257</b> performs processing of transmitting the learning result (that is, the learned weight parameter) to the integration server <b>30</b>. The weight parameter of the trained local model to be trained LM stored in the learning result storage unit <b>256</b> is transmitted to the integration server <b>30</b> via the communication interface <b>206</b> through the wide area communication line <b>70</b> (refer to <figref idref="DRAWINGS">FIG. <b>4</b></figref>).</p><p id="p-0198" num="0197">The processor <b>202</b> executes a command of a display control program <b>260</b> to cause the computer to function as the display control unit. The display control unit generates a signal for display required for a display output to the display device <b>216</b> and performs display control of the display device <b>216</b>. Further, although not shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the computer-readable medium <b>204</b> of the terminal <b>20</b> may store an accuracy verification program for verifying the inference accuracy of the local model to be trained LM and data for verification.</p><p id="p-0199" num="0198">As described above, the local learning management program <b>250</b> is constructed on the terminal <b>20</b> on the medical institution network <b>50</b>. The local learning management program <b>250</b> has a function of synchronizing the master model MM before performing training with the local model LM, a function of starting the local learning, a function of setting an end condition of local learning, and a function of transmitting the result of local learning to the integration server <b>30</b> in a case where the local learning ends.</p><p id="p-0200" num="0199">&#x3c;&#x3c;Example of Data Collection Program <b>220</b>&#x3e;&#x3e;</p><p id="p-0201" num="0200"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart showing an example of the operation of the terminal <b>20</b> based on the data collection program <b>220</b>. Steps in the flowchart shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref> are executed by the processor <b>202</b> according to the command of the data collection program <b>220</b>.</p><p id="p-0202" num="0201">In step S<b>51</b>, the processor <b>202</b> receives the search condition setting file from the integration server <b>30</b>. The search condition setting file transmitted from the integration server <b>30</b> in step S<b>13</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref> is received by the processor <b>202</b>.</p><p id="p-0203" num="0202">Next, in step S<b>52</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the processor <b>202</b> searches for the data that matches the search condition set in the search condition setting file from within the medical institution system MS.</p><p id="p-0204" num="0203">In step S<b>53</b>, the processor <b>202</b> stores the storage location information of the data that matches the search condition and totals the number of pieces of data.</p><p id="p-0205" num="0204">In step S<b>54</b>, the processor <b>202</b> transmits the totalization result obtained in step S<b>53</b> to the integration server <b>30</b>.</p><p id="p-0206" num="0205">Thereafter, in step S<b>55</b>, the processor <b>202</b> waits for the reception of the instruction from the integration server <b>30</b>.</p><p id="p-0207" num="0206">In step S<b>56</b>, the processor <b>202</b> determines whether or not the distribution information has been received from the integration server <b>30</b>. In a case where the determination result in step S<b>56</b> is a No determination, the processing returns to step S<b>55</b>. In a case where the determination result in step S<b>56</b> is a Yes determination, that is, in a case where the processor <b>202</b> receives the distribution information, the processing proceeds to step S<b>57</b>.</p><p id="p-0208" num="0207">In step S<b>57</b>, the processor <b>202</b> determines whether or not the instruction for the additional generation has been received. In a case where the determination result in step S<b>57</b> is a No determination, that is, in a case where new learning data is not necessary to be added, the processor <b>202</b> proceeds to step S<b>61</b>.</p><p id="p-0209" num="0208">In a case where the determination result in step S<b>57</b> is a Yes determination, that is, in a case where new learning data is necessary to be added by the additional generation of the secondary data, the processor <b>202</b> proceeds to step S<b>58</b>.</p><p id="p-0210" num="0209">In step S<b>58</b>, the processor <b>202</b> causes the delivered AI model <b>26</b> to execute processing of additionally generating the secondary data according to the received execution condition.</p><p id="p-0211" num="0210">In step S<b>59</b>, the processor <b>202</b> determines whether or not the addition processing is completed. In a case where the determination result in step S<b>59</b> is a No determination, the processing returns to step S<b>58</b> and waits for the completion of the additional generation processing.</p><p id="p-0212" num="0211">In a case where the determination result in step S<b>59</b> is a Yes determination, that is, in a case where the generation of the secondary data of the number of pieces of additional data designated in the execution condition is completed, the processor <b>202</b> proceeds to step S<b>60</b>.</p><p id="p-0213" num="0212">In step S<b>60</b>, the processor <b>202</b> notifies the local learning management program that the addition processing is completed.</p><p id="p-0214" num="0213">Next, in step S<b>61</b>, the processor <b>202</b> collects the pieces of learning data of the type and number of pieces of data designated in the distribution information.</p><p id="p-0215" num="0214">Then, in step S<b>62</b>, the processor <b>202</b> starts the local learning management program <b>250</b>. After step S<b>62</b>, the processor <b>202</b> ends the flowchart of <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p><p id="p-0216" num="0215">&#x3c;&#x3c;Example of Local Learning Management Program <b>250</b>&#x3e;&#x3e;</p><p id="p-0217" num="0216"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart showing an example of the operation of the terminal <b>20</b> based on the local learning management program <b>250</b>. Steps in the flowchart shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref> are executed by the processor <b>202</b> according to the command of the local learning management program <b>250</b>.</p><p id="p-0218" num="0217">In step S<b>71</b>, the processor <b>202</b> synchronizes the local model LM with the master model MM. In a case where the local model LM is synchronized with the master model MM, for example, a form may be employed in which the parameter file used by the model is updated and the program reads the updated file to proceed with learning, or a form may be employed in which a virtual container image and the like are centrally managed in the integration server <b>30</b> side and are developed in the terminal <b>20</b> side. With the synchronization processing, the master model MM becomes the local model to be trained LM in an initial state before the learning is started.</p><p id="p-0219" num="0218">In step S<b>72</b>, the processor <b>202</b> executes the local learning using the local data. The training processing on the local model LM synchronized with the master model MM is started by the local learning management program <b>250</b> to proceed with the local learning, using the local data in the medical institution system MS to which the terminal <b>20</b> belongs.</p><p id="p-0220" num="0219">In step S<b>73</b>, the processor <b>202</b> determines whether or not the learning end condition is satisfied. Here, examples of the learning end condition include the following conditions.</p><p id="p-0221" num="0220">[Example 1] The number of iterations is designated in advance, and learning is ended after the designated number of iterations.</p><p id="p-0222" num="0221">[Example 2] The data for verification is stored in the medical institution network <b>50</b>, and accuracy comparison is performed between the inference result obtained by inputting the data for verification into the trained model and the correct answer to calculate the inference accuracy. The learning is performed until the accuracy improvement of a designated ratio is achieved. That is, the inference accuracy of the learning model is calculated by using the data for verification, and the learning is ended in a case where the accuracy improvement of the designated ratio is achieved.</p><p id="p-0223" num="0222">[Example 3] A time limit is set, and the learning is performed within the time limit. In a case where the time limit is reached, the learning is ended.</p><p id="p-0224" num="0223">The end condition of any one of [Example 1] to [Example 3] may be set, or a logical product (AND) or a logical sum (OR) of the plurality of conditions may be set as the end condition.</p><p id="p-0225" num="0224">In a case where the determination result in step S<b>73</b> is a No determination, the processor <b>202</b> returns to step S<b>72</b> to continue the local learning processing. On the other hand, in a case where the determination result in step S<b>73</b> is a Yes determination, the processor <b>202</b> proceeds to step S<b>74</b> to end the learning.</p><p id="p-0226" num="0225">After the learning is ended, in step S<b>75</b>, the processor <b>202</b> transmits the learning result to the integration server <b>30</b>. For example, the processor <b>202</b> stores the weight parameter of the trained model in a file and transmits the weight parameter thereof to the integration server <b>30</b> through the wide area communication line <b>70</b>.</p><p id="p-0227" num="0226">Each terminal <b>20</b> of the plurality of medical institutions executes the machine learning for each local model LM using the data on different medical institution networks <b>50</b> as learning data and transmits a learning result to the integration server <b>30</b> through the wide area communication line <b>70</b>.</p><p id="p-0228" num="0227">&#x3c;&#x3c;Example of Master Model Learning Management Program <b>340</b>&#x3e;&#x3e;</p><p id="p-0229" num="0228"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart showing an example of an operation of the integration server <b>30</b> based on the master model learning management program <b>340</b>. Steps in the flowchart shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref> are executed by the processor <b>302</b> of the integration server <b>30</b> according to the command of the master model learning management program <b>340</b>.</p><p id="p-0230" num="0229">In step S<b>81</b>, the processor <b>302</b> receives the learning result from the terminal <b>20</b> of each medical institution.</p><p id="p-0231" num="0230">In step S<b>82</b>, the processor <b>302</b> integrates the learning results obtained from the plurality of terminals <b>20</b> to create the master model candidate.</p><p id="p-0232" num="0231">In step S<b>83</b>, the processor <b>302</b> evaluates the inference accuracy for the created master model candidate. That is, the processor <b>302</b> causes the master model candidate to perform the inference by using the data for verification prepared in advance as an input to calculate the inference accuracy and compares the inference accuracy with the accuracy target value. Further, the processor <b>302</b> stores, in the database <b>360</b>, the calculated inference accuracy and the comparison result between the inference accuracy and the accuracy target value in association (correlation) with the master model candidate.</p><p id="p-0233" num="0232">For the inference accuracy of the master model candidate to be compared with the accuracy target value in a case where processing of step S<b>83</b> is performed, an instantaneous value or a statistical value, such as an average value or a median value, is used as an appropriate value. An example of processing contents in the inference accuracy evaluation applied to step S<b>83</b> will be described below with reference to <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0234" num="0233">In step S<b>84</b>, the processor <b>302</b> determines whether or not the master model candidate having an inference accuracy higher than the accuracy target value is obtained. In a case where the determination result in step S<b>84</b> is a Yes determination, that is, in a case where the inference accuracy of the master model candidate exceeds the accuracy target value, the processor <b>302</b> ends the learning (step S<b>87</b>) and proceeds to step S<b>88</b>.</p><p id="p-0235" num="0234">In step S<b>88</b>, the processor <b>302</b> sets a master model candidate having the inference accuracy higher than the accuracy target value, as the latest model having improved performance after learning, stores the model in the data storage unit such as the database <b>360</b> in an appropriate format such as a file, and sends notification that learning is ended. Here, as a notification method, a message queue, a general inter-processing communication, or the like may be used. The notification that the learning is ended may be displayed on the display device <b>316</b> or may be transmitted to the terminal <b>20</b>. After step S<b>88</b>, the processor <b>302</b> ends the flowchart of <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0236" num="0235">On the other hand, in a case where the determination result in step S<b>84</b> is a No determination, that is, in a case where the master model candidate having the inference accuracy higher than the accuracy target value is not obtained, the processor <b>302</b> proceeds to step S<b>85</b>.</p><p id="p-0237" num="0236">In step S<b>85</b>, the processor <b>302</b> updates the master model candidate whose inference accuracy is improved as compared with the current master model MM as the master model to be trained MINI and next time, synchronizes this model with the local model LM of each terminal <b>20</b> and repeats steps S<b>71</b> to S<b>75</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref> and steps S<b>81</b> to S<b>85</b> in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. Accordingly, the local model LM with improved inference accuracy as compared with the inference accuracy before the update can be obtained.</p><p id="p-0238" num="0237">&#x3c;&#x3c;Example of Inference Accuracy Evaluation Processing&#x3e;&#x3e;</p><p id="p-0239" num="0238"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart showing an example of processing of evaluating the inference accuracy of the master model candidate in the integration server <b>30</b>. The flowchart shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref> is applied to step S<b>83</b> of <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0240" num="0239">In step S<b>91</b> of <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the processor <b>302</b> causes the master model candidate to execute the inference with the data for verification as an input.</p><p id="p-0241" num="0240">In step S<b>92</b>, the processor <b>302</b> calculates the inference accuracy of the master model candidate based on the inference result and on the correct answer data.</p><p id="p-0242" num="0241">In step S<b>93</b>, the processor <b>302</b> compares the inference accuracy of the master model candidate with the accuracy target value. The accuracy target value may be compared with an instantaneous value of the inference accuracy of the master model candidate. In the comparison, several iterations of the procedures of steps S<b>81</b> to S<b>93</b> may be performed, the inference accuracy at each iteration may be recorded each time, and a statistical value, such as an average value or a median value, of the recorded inference accuracies may be compared with the accuracy target value.</p><p id="p-0243" num="0242">In step S<b>94</b>, the processor <b>302</b> stores the inference accuracy of the master model candidate and the comparison result between the inference accuracy and the accuracy target value in the database <b>360</b>.</p><p id="p-0244" num="0243">After step S<b>94</b>, the processor <b>302</b> ends the flowchart of <figref idref="DRAWINGS">FIG. <b>13</b></figref> and returns to the flowchart of <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0245" num="0244">The integration server <b>30</b> performs the learning iteration until the master model MINI having the inference accuracy higher than the accuracy target value is obtained. Alternatively, in a case where the master model MINI having an inference accuracy higher than the accuracy target value is not obtained even though iterations are performed by the designated upper limit number of iterations, the integration server <b>30</b> may adopt the master model MM from which the maximum inference accuracy is obtained in the search processing so far, as the product model.</p><p id="p-0246" num="0245">In the new master model MINI created by performing the machine learning method using the machine learning system <b>10</b> according to the present embodiment in this manner, the inference accuracy is improved as compared with the master model before the learning.</p><p id="p-0247" num="0246">According to the present embodiment, it is possible to update an inference performance of the master model MM. In a case where the new master model created by performing the machine learning method according to the present embodiment is provided for sale or the like, preferably, the number of the clients used for the learning, the number of pieces of data for verification used for verification of the accuracy, and the like are described in an attached document provided at the time of sale. For the number of the clients used for the learning, for example, the classification of the clients is preferably displayed such as &#x201c;hospital_how many cases&#x201d;, &#x201c;clinic with bed_how many cases&#x201d;, and &#x201c;clinic without bed_how many cases&#x201d; as a client profile.</p><p id="p-0248" num="0247">It is also conceivable to train the delivered AI model, which is the current product, as the master model to be trained MINI to upgrade the version from the delivered AI model. As a preliminary procedure in this case, information indicating the inference accuracy in the previous version and the inference accuracy in the new version and information indicating the number of the clients used for additional learning and the classification of the clients are presented to a medical institution, and an approval is received from the medical institution before the version is upgraded. After the approval is obtained, the version is upgraded.</p><p id="p-0249" num="0248">The machine learning method implemented by the machine learning system <b>10</b> according to the present embodiment is an example of &#x201c;inference model creation method&#x201d; in the present disclosure, and the master model MINI after learning, which is obtained by learning, is an example of &#x201c;inference model&#x201d; in the present disclosure.</p><p id="p-0250" num="0249">&#x3c;&#x3c;Example of Hardware Configuration of Computer&#x3e;&#x3e;</p><p id="p-0251" num="0250"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a block diagram showing an example of a hardware configuration of a computer. A computer <b>800</b> may be a personal computer, a workstation, or a server computer. The computer <b>800</b> may be used as a part or all of the terminal <b>20</b>, the integration server <b>30</b>, the DICOM server <b>22</b>, the electronic medical record system <b>24</b>, the AI server <b>60</b>, and the terminal <b>62</b> described above, or may be used as an apparatus having a plurality of functions thereof.</p><p id="p-0252" num="0251">The computer <b>800</b> comprises a central processing unit (CPU) <b>802</b>, a random access memory (RAM) <b>804</b>, a read only memory (ROM) <b>806</b>, a graphics processing unit (GPU) <b>808</b>, a storage <b>810</b>, a communication unit <b>812</b>, an input device <b>814</b>, a display device <b>816</b>, and a bus <b>818</b>. The GPU <b>808</b> may be provided as necessary.</p><p id="p-0253" num="0252">The CPU <b>802</b> reads out various programs stored in the ROM <b>806</b>, the storage <b>810</b>, or the like, and executes various processing. The RAM <b>804</b> is used as a work area of the CPU <b>802</b>. Further, the RAM <b>804</b> is used as a storage unit for temporarily storing the read program and various pieces of data.</p><p id="p-0254" num="0253">The storage <b>810</b> includes, for example, a hard disk apparatus, an optical disk, a magneto-optical disk, a semiconductor memory, or a storage device configured by using an appropriate combination thereof. The storage <b>810</b> stores various programs, data, and the like required for inference processing and/or learning processing. The program stored in the storage <b>810</b> is loaded into the RAM <b>804</b>, and the CPU <b>802</b> executes the program. Thus, the computer <b>800</b> functions as units for performing various processing defined by the program.</p><p id="p-0255" num="0254">The communication unit <b>812</b> is an interface that performs communication processing with an external apparatus in a wired manner or a wireless manner and that exchanges information with the external apparatus. The communication unit <b>812</b> may play a role of an information acquisition unit that receives an input such as an image.</p><p id="p-0256" num="0255">The input device <b>814</b> is an input interface that receives various operation inputs to the computer <b>800</b>. The input device <b>814</b> is configured with, for example, a keyboard, a mouse, a touch panel, another pointing device, a voice input device, or an appropriate combination thereof.</p><p id="p-0257" num="0256">The display device <b>816</b> is an output interface for displaying various pieces of information. The display device <b>816</b> is configured with, for example, a liquid crystal display, an organic electro-luminescence (OEL) display, a projector, or an appropriate combination thereof.</p><p id="p-0258" num="0257">&#x3c;&#x3c;Program for Operating Computer&#x3e;&#x3e;</p><p id="p-0259" num="0258">A program causing a computer to realize some or all of at least one processing function among various processing functions, such as a data search function, a data collection function, and a local learning function in each terminal <b>20</b> and a data collection program setting OF function, a search condition setting function, a learning data distribution function, and a master model learning management function including a master model candidate creation function and an inference accuracy evaluation function in the integration server <b>30</b>, which are described in the above embodiment, may be recorded on a computer-readable medium as a non-transitory tangible information storage medium, such as an optical disk, a magnetic disk, or a semiconductor memory, and the program may be provided with the information storage medium.</p><p id="p-0260" num="0259">Further, instead of the form in which the program is provided by being stored in such a non-transitory tangible computer-readable medium, a program signal may be provided as a download service using a telecommunication line such as the Internet.</p><p id="p-0261" num="0260">A service may be possible in which some or all of at least one processing function among various processing functions, such as the data search function, the data collection function, and the local learning function in each terminal <b>20</b> and the data collection program setting I/F function, the search condition setting function, the learning data distribution function, and the master model learning management function including the master model candidate creation function and the inference accuracy evaluation function in the integration server <b>30</b>, which are described in the above embodiment, are provided as an application server and the processing function is provided via a telecommunication line.</p><p id="p-0262" num="0261">&#x3c;&#x3c;Hardware Configuration of Each Processing Unit&#x3e;&#x3e;</p><p id="p-0263" num="0262">Hardware structures of processing units that execute various pieces of processing, such as the search condition input receiving unit <b>321</b>, the setting file generation unit <b>322</b>, the totalization result acquisition unit <b>323</b>, the learning data number distribution unit <b>324</b>, the notification setting input receiving unit <b>325</b>, the notification determination unit <b>326</b>, the addition instruction receiving unit <b>327</b>, the additional generation distribution unit <b>328</b>, the learned weight parameter acquisition unit <b>341</b>, the parameter integration unit <b>342</b>, and the model update unit <b>343</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and the search condition setting file acquisition unit <b>221</b>, the data search unit <b>222</b>, the search result storage unit <b>223</b>, the totalization result transmission processing unit, <b>224</b>, the distribution information acquisition unit <b>225</b>, the additional generation processing unit <b>226</b>, the synchronization processing unit <b>251</b>, the learning data acquisition unit <b>252</b>, the local model to be trained LM, the error calculation unit <b>254</b>, the optimizer <b>255</b>, the learning result storage unit <b>256</b>, and the learning result transmission processing unit <b>257</b> shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, are various processors as shown below, for example.</p><p id="p-0264" num="0263">The various processors include a CPU which is a general-purpose processor that functions as various processing units by executing a program, a GPU which is a processor specialized for image processing, a programmable logic device (PLD) such as a field programmable gate array (FPGA) which is a processor capable of changing a circuit configuration after manufacture, a dedicated electric circuit such as an application specific integrated circuit (ASIC) which is a processor having a circuit configuration specifically designed to execute specific processing, and the like.</p><p id="p-0265" num="0264">One processing unit may be configured by one of these various processors or may be configured by two or more processors having the same type or different types. For example, one processing unit may be configured by a plurality of FPGAs, a combination of a CPU and an FPGA, or a combination of a CPU and a GPU. Further, the plurality of processing units may be configured by one processor. As an example in which the plurality of processing units are configured by one processor, firstly, as represented by a computer such as a client and a server, a form in which one processor is configured by a combination of one or more CPUs and software and in which the processor functions as the plurality of processing units may be adopted. Secondly, as represented by a system on chip (SoC) or the like, a form in which a processor that realizes the function of the entire system including the plurality of processing units via one integrated circuit (IC) chip is used may be adopted. As described above, the various processing units are configured by using one or more various processors as a hardware structure.</p><p id="p-0266" num="0265">Further, as the hardware structure of the various processors, more specifically, an electric circuit (circuitry) in which circuit elements such as semiconductor elements are combined may be used.</p><p id="p-0267" num="0266">&#x3c;&#x3c;Advantages According to Present Embodiment&#x3e;&#x3e;</p><p id="p-0268" num="0267">With the machine learning system <b>10</b> according to the embodiment of the present invention, the following advantages are obtained.</p><p id="p-0269" num="0268">[1] Learning can be performed without extracting personal information, such as a diagnosis image, that requires consideration for privacy from a medical institution to the outside.</p><p id="p-0270" num="0269">[2] It is possible to search for and collect the data used for learning from within the medical institution system MS or to additionally generate new data in a case where the learning data is insufficient.</p><p id="p-0271" num="0270">[3] A mechanism is provided in which the development entity <b>80</b> can control the type and number of pieces of data used for local learning at each medical institution while ascertaining the data possession situation of each medical institution. Accordingly, it is possible to suppress a variation in the data used for learning and thus suppress a variation in the inference accuracy of the AI model created by the learning.</p><heading id="h-0009" level="1">Modification Example 1</heading><p id="p-0272" num="0271">In the embodiment, the AI model for medical image diagnosis has been described as an example. However, the scope of application of the technique of the present disclosure is not limited to this example. For example, the present disclosure may be applied even in a case where learning is performed on an AI model using time-series data as input data or on an AI model using document data as input data. The time-series data may be, for example, electrocardiogram waveform data. The document data may be, for example, a diagnostic report, and the present disclosure may be applied to training of an AI model for supporting creation of a report. The electrocardiogram waveform data is an example of &#x201c;inspection data&#x201d; in the present disclosure.</p><p id="p-0273" num="0272">The data used for learning may be a combination of different kinds of data acquired by different modalities. The data used for the learning may be a combination of a plurality of types of different kinds of data, such as a combination of images and time-series data or a combination of images and document data.</p><heading id="h-0010" level="1">Modification Example 2</heading><p id="p-0274" num="0273">In the embodiment, an example in which an accuracy target value by learning is set and the inference accuracy of the master model candidate is compared with the accuracy target value has been described. However, the accuracy target value may be updated as necessary. Instead of or in combination with the comparison with the accuracy target value, the learning may proceed under a condition that the inference accuracy of the model is maximized within the time limit or the designated number of iterations.</p><p id="p-0275" num="0274">&#x3c;&#x3c;Other&#x3e;&#x3e;</p><p id="p-0276" num="0275">The matters described in the configuration and the modification example described in the embodiment may be used in combination as appropriate, and some matters may be replaced. The present invention is not limited to the embodiment described above, and various modifications may be made without departing from the scope of the present invention.</p><heading id="h-0011" level="1">EXPLANATION OF REFERENCES</heading><p id="p-0277" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0276"><b>10</b>: machine learning system</li>        <li id="ul0002-0002" num="0277"><b>20</b>: terminal</li>        <li id="ul0002-0003" num="0278"><b>22</b>: DICOM server</li>        <li id="ul0002-0004" num="0279"><b>24</b>: electronic medical record system</li>        <li id="ul0002-0005" num="0280"><b>26</b>: delivered AI model</li>        <li id="ul0002-0006" num="0281"><b>30</b>: integration server</li>        <li id="ul0002-0007" num="0282"><b>32</b>: data collection program setting interface</li>        <li id="ul0002-0008" num="0283"><b>50</b>: medical institution network</li>        <li id="ul0002-0009" num="0284"><b>52</b>: CT apparatus</li>        <li id="ul0002-0010" num="0285"><b>54</b>: MM apparatus</li>        <li id="ul0002-0011" num="0286"><b>56</b>: CR apparatus</li>        <li id="ul0002-0012" num="0287"><b>60</b>: AI server</li>        <li id="ul0002-0013" num="0288"><b>62</b>: terminal</li>        <li id="ul0002-0014" num="0289"><b>66</b>: internal communication line</li>        <li id="ul0002-0015" num="0290"><b>70</b>: wide area communication line</li>        <li id="ul0002-0016" num="0291"><b>80</b>: development entity</li>        <li id="ul0002-0017" num="0292"><b>202</b>: processor</li>        <li id="ul0002-0018" num="0293"><b>204</b>: computer-readable medium</li>        <li id="ul0002-0019" num="0294"><b>206</b>: communication interface</li>        <li id="ul0002-0020" num="0295"><b>208</b>: input/output interface</li>        <li id="ul0002-0021" num="0296"><b>210</b>: bus</li>        <li id="ul0002-0022" num="0297"><b>214</b>: input device</li>        <li id="ul0002-0023" num="0298"><b>216</b>: display device</li>        <li id="ul0002-0024" num="0299"><b>220</b>: data collection program</li>        <li id="ul0002-0025" num="0300"><b>221</b>: search condition setting file acquisition unit</li>        <li id="ul0002-0026" num="0301"><b>222</b>: data search unit</li>        <li id="ul0002-0027" num="0302"><b>223</b>: search result storage unit</li>        <li id="ul0002-0028" num="0303"><b>224</b>: totalization result transmission processing unit</li>        <li id="ul0002-0029" num="0304"><b>225</b>: distribution information acquisition unit</li>        <li id="ul0002-0030" num="0305"><b>226</b>: additional generation processing unit</li>        <li id="ul0002-0031" num="0306"><b>250</b>: local learning management program</li>        <li id="ul0002-0032" num="0307"><b>251</b>: synchronization processing unit</li>        <li id="ul0002-0033" num="0308"><b>252</b>: learning data acquisition unit</li>        <li id="ul0002-0034" num="0309"><b>254</b>: error calculation unit</li>        <li id="ul0002-0035" num="0310"><b>255</b>: optimizer</li>        <li id="ul0002-0036" num="0311"><b>256</b>: learning result storage unit</li>        <li id="ul0002-0037" num="0312"><b>257</b>: learning result transmission processing unit</li>        <li id="ul0002-0038" num="0313"><b>260</b>: display control program</li>        <li id="ul0002-0039" num="0314"><b>280</b>: learning data storage unit</li>        <li id="ul0002-0040" num="0315"><b>302</b>: processor</li>        <li id="ul0002-0041" num="0316"><b>304</b>: computer-readable medium</li>        <li id="ul0002-0042" num="0317"><b>306</b>: communication interface</li>        <li id="ul0002-0043" num="0318"><b>308</b>: input/output interface</li>        <li id="ul0002-0044" num="0319"><b>310</b>: bus</li>        <li id="ul0002-0045" num="0320"><b>314</b>: input device</li>        <li id="ul0002-0046" num="0321"><b>316</b>: display device</li>        <li id="ul0002-0047" num="0322"><b>320</b>: data collection program setting I/F program</li>        <li id="ul0002-0048" num="0323"><b>321</b>: search condition input receiving unit</li>        <li id="ul0002-0049" num="0324"><b>322</b>: setting file generation unit</li>        <li id="ul0002-0050" num="0325"><b>323</b>: totalization result acquisition unit</li>        <li id="ul0002-0051" num="0326"><b>324</b>: learning data number distribution unit</li>        <li id="ul0002-0052" num="0327"><b>325</b>: notification setting input receiving unit</li>        <li id="ul0002-0053" num="0328"><b>326</b>: notification determination unit</li>        <li id="ul0002-0054" num="0329"><b>327</b>: addition instruction receiving unit</li>        <li id="ul0002-0055" num="0330"><b>328</b>: additional generation distribution unit</li>        <li id="ul0002-0056" num="0331"><b>330</b>: synchronization program</li>        <li id="ul0002-0057" num="0332"><b>340</b>: master model learning management program</li>        <li id="ul0002-0058" num="0333"><b>341</b>: learned weight parameter acquisition unit</li>        <li id="ul0002-0059" num="0334"><b>342</b>: parameter integration unit</li>        <li id="ul0002-0060" num="0335"><b>343</b>: model update unit</li>        <li id="ul0002-0061" num="0336"><b>350</b>: display control program</li>        <li id="ul0002-0062" num="0337"><b>360</b>: database</li>        <li id="ul0002-0063" num="0338"><b>800</b>: computer</li>        <li id="ul0002-0064" num="0339"><b>802</b>: CPU</li>        <li id="ul0002-0065" num="0340"><b>804</b>: RAM</li>        <li id="ul0002-0066" num="0341"><b>806</b>: ROM</li>        <li id="ul0002-0067" num="0342"><b>808</b>: GPU</li>        <li id="ul0002-0068" num="0343"><b>810</b>: storage</li>        <li id="ul0002-0069" num="0344"><b>812</b>: communication unit</li>        <li id="ul0002-0070" num="0345"><b>814</b>: input device</li>        <li id="ul0002-0071" num="0346"><b>816</b>: display device</li>        <li id="ul0002-0072" num="0347"><b>818</b>: bus</li>        <li id="ul0002-0073" num="0348">LM: local model to be trained</li>        <li id="ul0002-0074" num="0349">MM: master model to be trained</li>        <li id="ul0002-0075" num="0350">MS: medical institution system</li>        <li id="ul0002-0076" num="0351">S<b>11</b> to S<b>48</b>: processing steps by data collection program setting I/F program</li>        <li id="ul0002-0077" num="0352">S<b>51</b> to S<b>62</b>: processing steps by data collection program</li>        <li id="ul0002-0078" num="0353">S<b>71</b> to S<b>75</b>: processing steps by local learning management program</li>        <li id="ul0002-0079" num="0354">S<b>81</b> to S<b>88</b>: processing steps by master model learning management program</li>        <li id="ul0002-0080" num="0355">S<b>91</b> to S<b>94</b>: steps of inference accuracy evaluation processing</li>    </ul>    </li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A machine learning system comprising:<claim-text>a plurality of client terminals; and</claim-text><claim-text>an integration server,</claim-text><claim-text>wherein each of the plurality of client terminals is a terminal installed in a medical institution system of each of a plurality of medical institutions,</claim-text><claim-text>each of the client terminals includes<claim-text>a first processor, and</claim-text><claim-text>a first computer-readable medium on which a first program executed by the first processor is recorded,</claim-text></claim-text><claim-text>the first processor performs, according to a command of the first program, processing including<claim-text>acquiring a search condition of data from the integration server,</claim-text><claim-text>searching for data that matches the search condition from within the medical institution system to which the client terminal belongs and totaling search results,</claim-text><claim-text>transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server,</claim-text><claim-text>receiving distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated,</claim-text><claim-text>executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data, and</claim-text><claim-text>transmitting a learning result of the local model to the integration server,</claim-text></claim-text><claim-text>the integration server includes<claim-text>a second processor, and</claim-text><claim-text>a second computer-readable medium on which a second program executed by the second processor is recorded, and</claim-text></claim-text><claim-text>the second processor performs, according to a command of the second program, processing including<claim-text>storing a master model to be trained on the second computer-readable medium,</claim-text><claim-text>receiving an input that designates the search condition in a case where the data in the medical institution system is searched for,</claim-text><claim-text>transmitting the designated search condition to the plurality of client terminals,</claim-text><claim-text>receiving the totalization result indicating the number of pieces of the data that matches the search condition from each of the client terminals,</claim-text><claim-text>receiving an input that designates the required number of pieces of learning data to be used for learning,</claim-text><claim-text>distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result,</claim-text><claim-text>transmitting, to each of the client terminals, the distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals,</claim-text><claim-text>synchronizing the local model of each client terminal side with the master model before the local model is trained at each of the plurality of client terminals,</claim-text><claim-text>receiving each of the learning results from the plurality of client terminals, and</claim-text><claim-text>integrating the received learning results to update the master model.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref><claim-text>wherein the second processor further issues a notification notifying that the required number is satisfied at a stage where a total number of pieces of the data that matches the search condition is equal to or larger than the required number.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the first processor has authority to execute a third program that generates new secondary data using primary data in the medical institution system,</claim-text><claim-text>the second processor performs, in a case where a total number of pieces of the data that matches the search condition is less than the required number and the data that matches the search condition is obtainable by operating the third program, processing including<claim-text>distributing the number of pieces of additional data requesting additional data generation to each of the client terminals, and</claim-text><claim-text>transmitting, to each of the client terminals, additional generation distribution information including designation of the number of pieces of the additional data distributed according to each of the client terminals, and</claim-text></claim-text><claim-text>the first processor executes the third program based on the additional generation distribution information to newly generate the secondary data.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The machine learning system according to <claim-ref idref="CLM-00003">claim 3</claim-ref>,<claim-text>wherein the first processor starts training of the local model in a case where the generation of the secondary data of the designated number of pieces of the additional data is completed.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The machine learning system according to <claim-ref idref="CLM-00003">claim 3</claim-ref>,<claim-text>wherein the third program includes a trained model in which the secondary data is output by inputting the primary data.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein each of the plurality of client terminals is a terminal installed in a medical institution network of a different medical institution.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the integration server is installed in a medical institution network or outside the medical institution network.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the learning result transmitted from the client terminal to the integration server includes a weight parameter of the local model after learning.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein data to be searched for by the search condition includes at least one type of data of a two-dimensional image, a three-dimensional image, a moving image, time-series data, or document data.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The machine learning system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>,<claim-text>wherein the document data includes comments on findings of an electronic medical record.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein models to be trained of each of the local model and the master model are trained such that comments on findings corresponding to an input image are output, using a combination of an image and comments on findings associated with the image as the learning data.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein models to be trained of each of the local model and the master model are configured by using a neural network.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the data used as the learning data includes a two-dimensional image, a three-dimensional image, or a moving image, and</claim-text><claim-text>models to be trained of each of the local model and the master model are configured by using a convolutional neural network.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The machine learning system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the data used as the learning data includes time-series data or document data, and</claim-text><claim-text>models to be trained of each of the local model and the master model are configured by using a recurrent neural network.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A machine learning method in which a plurality of client terminals and an integration server are used, the method comprising:<claim-text>via each of the plurality of client terminals, which are installed in a medical institution system of each of a plurality of medical institutions,</claim-text><claim-text>storing a master model to be trained in the integration server;</claim-text><claim-text>via the integration server,</claim-text><claim-text>receiving an input that designates a search condition in a case where data in the medical institution system is searched for; and</claim-text><claim-text>transmitting the designated search condition to the plurality of client terminals;</claim-text><claim-text>via the client terminal,</claim-text><claim-text>acquiring the search condition from the integration server;</claim-text><claim-text>searching for data that matches the search condition from within the medical institution system to which the client terminal belongs and totaling search results; and</claim-text><claim-text>transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server;</claim-text><claim-text>via the integration server,</claim-text><claim-text>receiving the totalization result indicating the number of pieces of the data that matches the search condition from each of the client terminals;</claim-text><claim-text>receiving an input that designates the required number of pieces of learning data to be used for learning;</claim-text><claim-text>distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result;</claim-text><claim-text>transmitting, to each of the client terminals, the distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals; and</claim-text><claim-text>synchronizing the local model of each client terminal side with the master model before the local model is trained at each of the plurality of client terminals;</claim-text><claim-text>via the client terminal,</claim-text><claim-text>receiving the distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated;</claim-text><claim-text>executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data; and</claim-text><claim-text>transmitting a learning result of the local model to the integration server; and</claim-text><claim-text>via the integration server,</claim-text><claim-text>receiving each of the learning results from the plurality of client terminals; and</claim-text><claim-text>integrating the received learning results to update the master model.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. An information processing apparatus that is used as a client terminal connected to an integration server via a communication line and is a terminal installed in a medical institution system of a medical institution, the information processing apparatus comprising:<claim-text>a first processor; and</claim-text><claim-text>a first computer-readable medium on which a first program executed by the first processor is recorded,</claim-text><claim-text>wherein the first processor performs, according to a command of the first program, processing including<claim-text>acquiring a search condition of data from the integration server,</claim-text><claim-text>searching for data that matches the search condition from within the medical institution system to which the client terminal belongs and totaling search results,</claim-text><claim-text>transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server,</claim-text><claim-text>receiving distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated,</claim-text><claim-text>executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data, and</claim-text><claim-text>transmitting a learning result of the local model to the integration server.</claim-text></claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A non-transitory, computer readable tangible recording medium which records thereon a program for causing a first computer to function as a client terminal connected to an integration server via a communication line, the program causing the first computer to realize:<claim-text>a function of acquiring a search condition of data from the integration server;</claim-text><claim-text>a function of searching for data that matches the search condition from within a medical institution system to which the client terminal belongs and totaling search results;</claim-text><claim-text>a function of transmitting a totalization result indicating the number of pieces of the data that matches the search condition to the integration server;</claim-text><claim-text>a function of receiving distribution information in which a type and the number of pieces of learning data used for learning at the client terminal are designated;</claim-text><claim-text>a function of executing machine learning of a local model to be trained in accordance with an instruction of the distribution information using data in the medical institution system to which the client terminal belongs as the learning data; and</claim-text><claim-text>a function of transmitting a learning result of the local model to the integration server.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. An integration server connected to a plurality of client terminals via a communication line, the integration server comprising:<claim-text>a second processor; and</claim-text><claim-text>a second computer-readable medium on which a second program executed by the second processor is recorded,</claim-text><claim-text>wherein the second processor performs, according to a command of the second program, processing including<claim-text>storing a master model to be trained on the second computer-readable medium,</claim-text><claim-text>receiving an input that designates a search condition in a case where data in a medical institution system to which each of the plurality of client terminals belongs is searched for,</claim-text><claim-text>transmitting the designated search condition to the plurality of client terminals,</claim-text><claim-text>receiving a totalization result indicating the number of pieces of the data that matches the search condition from each of the client terminals,</claim-text><claim-text>receiving an input that designates the required number of pieces of learning data to be used for learning,</claim-text><claim-text>distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result,</claim-text><claim-text>transmitting, to each of the client terminals, distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals,</claim-text><claim-text>synchronizing a local model of each client terminal side with the master model before the local model is trained at each of the plurality of client terminals,</claim-text><claim-text>receiving a learning result of each of the local models from the plurality of client terminals, and</claim-text><claim-text>integrating the received learning results to update the master model.</claim-text></claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A non-transitory, computer readable tangible recording medium which records thereon a program for causing a second computer to function as an integration server connected to a plurality of client terminals via a communication line, the program causing the second computer to realize:<claim-text>a function of storing a master model to be trained;</claim-text><claim-text>a function of receiving an input that designates a search condition in a case where data in a medical institution system to which each of the plurality of client terminals belongs is searched for;</claim-text><claim-text>a function of transmitting the designated search condition to the plurality of client terminals;</claim-text><claim-text>a function of receiving a totalization result indicating the number of pieces of the data that matches the search condition from each of the client terminals;</claim-text><claim-text>a function of receiving an input that designates the required number of pieces of learning data to be used for learning;</claim-text><claim-text>a function of distributing the number of pieces of the learning data used for learning at each of the client terminals based on the designated required number of pieces of the learning data and on the received totalization result;</claim-text><claim-text>a function of transmitting, to each of the client terminals, distribution information including the designation of the number of pieces of the learning data distributed according to each of the client terminals;</claim-text><claim-text>a function of synchronizing a local model of each client terminal side with the master model before the local model is trained at each of the plurality of client terminals;</claim-text><claim-text>a function of receiving a learning result of each of the local models from the plurality of client terminals; and</claim-text><claim-text>a function of integrating the received learning results to update the master model.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A method of creating an inference model by performing the machine learning method according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, the method comprising<claim-text>creating, by integrating the received learning results to update the master model, an inference model having higher inference accuracy than the master model before the update.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005275A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005275</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17929406</doc-number><date>20220902</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>58</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>R</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>T</subclass><main-group>7</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>T</subclass><main-group>7</main-group><subgroup>22</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>16</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>20</main-group><subgroup>58</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>R</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>T</subclass><main-group>7</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>T</subclass><main-group>7</main-group><subgroup>22</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>08</class><subclass>G</subclass><main-group>1</main-group><subgroup>161</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>R</subclass><main-group>2300</main-group><subgroup>302</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>R</subclass><main-group>2300</main-group><subgroup>8093</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>T</subclass><main-group>2201</main-group><subgroup>022</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">VEHICULAR CONTROL SYSTEM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16949051</doc-number><date>20201012</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11436840</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17929406</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16600657</doc-number><date>20191014</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10803329</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16949051</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16221690</doc-number><date>20181217</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10445600</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16600657</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16059536</doc-number><date>20180809</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10157322</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16221690</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15681699</doc-number><date>20170821</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10049285</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>16059536</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>14994595</doc-number><date>20160113</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>9740945</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>15681699</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>62103220</doc-number><date>20150114</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>MAGNA ELECTRONICS INC.</orgname><address><city>Auburn Hills</city><state>MI</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Divekar</last-name><first-name>Rohan J.</first-name><address><city>Auburn Hills</city><state>MI</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>VanOphem</last-name><first-name>Paul A.</first-name><address><city>Washington</city><state>MI</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A vehicular control system includes a camera and a control having a processor that processes image data captured by the camera to determine an approaching vehicle that is approaching an intersection forward of the equipped vehicle. The system determines projected path of the equipped vehicle. Estimated time to arrival of the approaching vehicle at the intersection is determined at least in part by processing of captured image data. Responsive to determination that the equipped vehicle will complete a turn at the intersection before the estimated time to arrival elapses, the system may determine that it is safe to proceed along the projected path of travel. Responsive at least in part to determination that the equipped vehicle will not complete the turn at the intersection before the estimated time to arrival elapses, the system may determine that it is not safe to proceed along the projected path of travel.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="125.81mm" wi="67.06mm" file="US20230005275A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="113.96mm" wi="115.49mm" file="US20230005275A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="217.42mm" wi="165.69mm" orientation="landscape" file="US20230005275A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="145.88mm" wi="69.09mm" file="US20230005275A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="227.25mm" wi="146.22mm" orientation="landscape" file="US20230005275A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a continuation of U.S. patent application Ser. No. 16/949,051, filed Oct. 12, 2020, now U.S. Pat. No. 11,436,840, which is a continuation of U.S. patent application Ser. No. 16/600,657, filed Oct. 14, 2019, now U.S. Pat. No. 10,803,329, which is a continuation of U.S. patent application Ser. No. 16/221,690, filed Dec. 17, 2018, now U.S. Pat. No. 10,445,600, which is a continuation of U.S. patent application Ser. No. 16/059,536, filed Aug. 9, 2018, now U.S. Pat. No. 10,157,322, which is a continuation of U.S. patent application Ser. No. 15/681,699, filed Aug. 21, 2017, now U.S. Pat. No. 10,049,285, which is a continuation of U.S. patent application Ser. No. 14/994,595, filed Jan. 13, 2016, now U.S. Pat. No. 9,740,945, which claims the filing benefits of U.S. provisional application Ser. No. 62/103,220, filed Jan. 14, 2015, which is hereby incorporated herein by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE INVENTION</heading><p id="p-0003" num="0002">The present invention relates generally to a vehicle collision avoidance system for a vehicle and, more particularly, to a system that utilizes vehicle-to-vehicle communications.</p><heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0004" num="0003">Use of vehicle-to-vehicle (V2V) communications and vehicle-to-infrastructure (V2I) communications are known. Such car2car or vehicle to vehicle (V2V) and vehicle to infrastructure (car2X or V2X or V2I) technology provides for communication between vehicles and/or infrastructure based on information provided by one or more vehicles and/or information provided by a remote server or the like. Examples of such systems are described in U.S. Pat. No. 7,580,795, which is hereby incorporated herein by reference in its entirety.</p><heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0005" num="0004">The present invention provides a collision avoidance system for a vehicle that utilizes information from V2V communication systems to determine the degree of hazard that an approaching vehicle represents to the equipped vehicle when the driver of the equipped vehicle is contemplating maneuvering the equipped vehicle into the path of travel of the approaching vehicle. The system may determine an estimated time to arrival of another vehicle at a location in the targeted path of travel of the equipped vehicle and may determine if the time to arrival is above a threshold time (whereby the system may indicate to the driver of the equipped vehicle that it is safe to proceed with the driving maneuver) or below a threshold time (whereby the system may indicate to the driver of the equipped vehicle that it is not safe to proceed with the driving maneuver). The system may be responsive at least in part to V2V communications and vehicle-to-infrastructure (V2I or V2X) communications and/or GPS data indicative of the location and movement of the equipped vehicle and the approaching vehicle. The system may also be responsive to image processing of image data captured by one or more cameras of the vehicle, such as a forward viewing camera. The image processor may, responsive to image processing of captured image data, determine a projected path of travel of the vehicle, and may determine the presence of an object in the projected path of travel.</p><p id="p-0006" num="0005">These and other objects, advantages, purposes and features of the present invention will become apparent upon review of the following specification in conjunction with the drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a plan view of an intersection showing a driving scenario where a vehicle equipped with the driver assistance system of the present invention is maneuvered through a left turn at the intersection;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow chart of the algorithm of the driver assistance system of the present invention, showing the determination by the system whether or not it is safe for the vehicle to be driven through the intersection;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a plan view of another driving scenario where a vehicle equipped with the driver assistance system of the present invention is maneuvered onto a road and into the traffic traveling along the road; and</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flow chart of the algorithm of the driver assistance system of the present invention, showing the determination by the system whether or not it is safe for the vehicle to be driven into the traffic situation on the road.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0011" num="0010">A vehicle collision avoidance system and/or driver assist system and/or alert system operates to determine when a collision may be likely and to provide a warning or alert to the driver. The system of the present invention utilizes vehicle-to-vehicle (V2V) communications and vehicle-to-infrastructure (V2I or V2X) communications to determine the approach of a vehicle to an intersection at or ahead of the subject vehicle. If the system determines that it is unsafe for the subject vehicle to proceed (such as to turn in a path that intersects the path of the approaching vehicle), the system generates an alert to the driver of the subject vehicle. The system may utilize the V2X communications to determine a status of a traffic light at the intersection and/or may utilize a GPS system of the vehicle to determine the location and separation distance of the vehicles, as discussed below. The vehicle communication systems may utilize aspects of the systems described in U.S. Pat. Nos. 6,690,268; 6,693,517; 7,156,796 and/or 7,580,795, and/or U.S. Publication Nos. US-2012-0218412, US-2012-0062743, US-2015-0158499; US-2015-0124096 and/or US-2015-0352953, which are all hereby incorporated herein by reference in their entireties.</p><p id="p-0012" num="0011">Many accidents are caused at intersections, because these are the locations where two or more roads cross each other and activities, such as turning left, crossing over and turning right and the like, have the potential for conflicts resulting in crashes.</p><p id="p-0013" num="0012">Often, at such intersections, accidents are caused due to driver misjudgment, either of the subject vehicle speed or trajectory or of an approaching vehicle speed or trajectory. For example, and such as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, drivers often misjudge the speed at which an approaching vehicle is arriving from the opposite direction at the intersection while the subject vehicle is turning left (and thus potentially crossing or intersecting the path of travel of the approaching vehicle).</p><p id="p-0014" num="0013">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a possible collision scenario involves the subject vehicle (Car A), which has to yield to let the approaching vehicle (Car B) pass through the intersection. But Car A can make its left turn if Car B is far enough away from the intersection (and/or approaching the intersection at a slow enough speed). Often, it is difficult for a driver (such as the driver of Car A) to judge the speed of the oncoming car, and to judge the time required for it to reach the intersection. If the driver of Car A makes the decision to go even when Car B is approaching at the same time at the intersection, then a collision is possible.</p><p id="p-0015" num="0014">The yield collision warning algorithm of the present invention can help the driver make a more safe and accurate decision in such a scenario and can prevent accidents. The algorithm and system of the present invention utilizes V2V (Vehicle to Vehicle) and V2I (Vehicle to Infrastructure) sensors or communication systems to determine the likelihood or possibility of a collision and, if the system determines that a collision is possible or likely, the system generates an alert to warn the driver.</p><p id="p-0016" num="0015">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the algorithm used to predict collision scenario receives heading information (such as speed and direction) of the approaching vehicle and of the subject vehicle, such as from V2V communication systems and V2V radios or transceivers of the vehicles. In the algorithm of the present invention, the heading angles of the approaching vehicle (CAR B) may be calculated from the GPS data and shared with Car A via V2V communication. Based on the determined heading angles, the direction of motion of each vehicle is calculated in relation to the other vehicle. The system or algorithm may also receive a communication from a V2X or V2I system that is indicative of the state of the stop light at the intersection (e.g., red, yellow, green), and the system may also determine whether or not the driver of the subject vehicle intends to turn across the intersection (such as responsive to a determination that a turn signal of the subject vehicle is activated).</p><p id="p-0017" num="0016">As Car A and Car B both are communicating with the infrastructure (via V2X communication) they may also receive information on the distance from the intersection. Both these distances are taken into account by the algorithm (via receipt of such information from the V2X system) to predict the time to arrival of Car B to the intersection. If this time is sufficient enough for Car A to complete the left turn (i.e., the determined time to arrival of Car B at the intersection is greater than a threshold time or value), the driver is indicated to proceed, otherwise the driver is warned of the collision possibility.</p><p id="p-0018" num="0017">Optionally, the algorithm can be further advanced to include automatic emergency braking, where the system will actuate or control the brake system of Car A to automatically brake the vehicle in the situation where the algorithm determines or calculates a high probability that a collision may occur. Optionally, the algorithm may be reversed in countries which have left hand drive systems for the vehicles.</p><p id="p-0019" num="0018">With reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, if the subject vehicle is at an entry to a road (such as if the driver of the subject vehicle in leaving a parking lot or the like) and the vehicle has to enter a high speeding lane, the driver of the subject vehicle has to judge the speed of the high speed vehicles approaching the subject vehicle location. A slight misjudgment can cause an accident.</p><p id="p-0020" num="0019">Based on the V2V communications and GPS data, the system may calculate the lateral distance of the target (approaching) vehicle (Car B in <figref idref="DRAWINGS">FIG. <b>3</b></figref>) from the subject vehicle (Car A in <figref idref="DRAWINGS">FIG. <b>3</b></figref>). From this information, the system can further calculate the time to arrival of the target vehicle to the entry ramp or location of Car A where it is about to enter the road. The algorithm can alert the driver of Car A if there is a high probability of collision if the driver of Car A goes ahead with the turning/entering maneuver.</p><p id="p-0021" num="0020">As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the algorithm used to predict such a collision scenario receives heading information of both vehicles, such as from V2V radios or the like and calculates the lateral and longitudinal distance between the vehicles based at least in part on GPS data or geographical location information. The system may determine the time to arrival based on the speed and distance from Car B to Car A. If the determined time to arrival is greater than a threshold time or value, then the system determines that there is sufficient space for the subject vehicle to enter the road lane and may indicate to the driver to proceed with the driving maneuver. However, if the determined time to arrival is less than the threshold time or value, then the system determines that there is not sufficient space for the subject vehicle to enter the road lane and may alert the driver to not proceed with the driving maneuver.</p><p id="p-0022" num="0021">The algorithm of the present invention may also apply to the scenario where the vehicle turning right on a red signal fails to yield for the oncoming vehicle. Optionally, the algorithm can be further advanced to include automatic emergency braking, where the system will actuate or control the brake system of Car A to automatically brake the vehicle in the situation where the algorithm determines or calculates a high probability that a collision may occur. Optionally, the algorithm may be reversed in countries which have left hand drive systems for the vehicles.</p><p id="p-0023" num="0022">Another common scenario is where a driver is turning out of a parking lot and has to cross or cut through multiple lanes of slow moving traffic (such as traveling left to right in front of the vehicle) to get to the far lanes to are traveling in the opposite direction (such as right to left in front of the vehicle). This is often a very dangerous situation especially when there is a left turn lane present and other vehicles are traveling faster in the left turn lane. The system of the present invention may utilize V2V communications to determine the speed and location of the other vehicles on the road and can protect/warn of potential collisions as the subject vehicle is driven out of the parking lot (or side street or the like).</p><p id="p-0024" num="0023">Therefore, the algorithm/feature or system of the present invention can be useful for drivers to avoid conflicts and accidents due to misjudgment at an intersection or any free turn on right scenarios. The algorithm of the present invention can be further used as a part of an autonomous or partial autonomous vehicle control system.</p><p id="p-0025" num="0024">Optionally, the vehicle collision avoidance system and/or driver assistance system and/or alert system may operate to capture images exterior of the vehicle and may process the captured image data to display images and to detect objects or other vehicles (such as vehicles that may not have a V2V communication system or radio) at or near the vehicle and in the predicted path of the vehicle, such as to assist a driver of the vehicle in maneuvering the vehicle. The vision system includes an image processor or image processing system that is operable to receive image data from one or more cameras and provide an output to a display device for displaying images representative of the captured image data. Optionally, the vision system may provide a top down or bird's eye or surround view display and may provide a displayed image that is representative of the subject vehicle, and optionally with the displayed image being customized to at least partially correspond to the actual subject vehicle.</p><p id="p-0026" num="0025">The system may operate responsive to the communications and to image processing of image data captured by a forward facing camera at the vehicle (such as a camera disposed at and behind the windshield of the vehicle and viewing forwardly through the windshield and in the direction of travel of the vehicle). For example, a forward facing camera may capture image data representative of the projected path of travel of the vehicle, and, via processing of such captured image data, an image processor may determine an object or objects present in the field of view of the camera and in the forward path of travel of the vehicle. The system includes a control that is operable to process vehicle information to determine an estimated time to arrival of the other vehicle at a location in a projected path of travel of the equipped vehicle. Responsive at least in part to a determination that the estimated time to arrival is less than a threshold amount, the control generates an alert to the driver of the equipped vehicle that it is not safe to proceed along the projected path of travel. Moreover, responsive at least in part to (i) a determination that the estimated time to arrival is greater than the threshold amount and (ii) a determination via image processing of captured image data that an object is present in the projected path of travel of the equipped vehicle, the control generates an alert to the driver of the equipped vehicle that it is not safe to proceed along the projected path of travel. Optionally, responsive at least in part to a determination that (i) the estimated time to arrival is greater than a threshold amount and (ii) a determination via image processing of captured image data that an object is not present in the projected path of travel of the equipped vehicle, the control may generate an indication to the driver of the equipped vehicle that it is safe to proceed along the projected path of travel.</p><p id="p-0027" num="0026">The camera or sensor may comprise any suitable camera or sensor. Optionally, the camera may comprise a &#x201c;smart camera&#x201d; that includes the imaging sensor array and associated circuitry and image processing circuitry and electrical connectors and the like as part of a camera module, such as by utilizing aspects of the vision systems described in International Publication Nos. WO 2013/081984 and/or WO 2013/081985, which are hereby incorporated herein by reference in their entireties.</p><p id="p-0028" num="0027">The system includes an image processor operable to process image data captured by the camera or cameras, such as for detecting objects or other vehicles or pedestrians or the like in the field of view of one or more of the cameras. For example, the image processor may comprise an EYEQ2 or EYEQ3 image processing chip available from Mobileye Vision Technologies Ltd. of Jerusalem, Israel, and may include object detection software (such as the types described in U.S. Pat. Nos. 7,855,755; 7,720,580 and/or 7,038,577, which are hereby incorporated herein by reference in their entireties), and may analyze image data to detect vehicles and/or other objects. Responsive to such image processing, and when an object or other vehicle is detected, the system may generate an alert to the driver of the vehicle and/or may generate an overlay at the displayed image to highlight or enhance display of the detected object or vehicle, in order to enhance the driver's awareness of the detected object or vehicle or hazardous condition during a driving maneuver of the equipped vehicle.</p><p id="p-0029" num="0028">The vehicle may include any type of sensor or sensors, such as imaging sensors or radar sensors or lidar sensors or ladar sensors or ultrasonic sensors or the like. The imaging sensor or camera may capture image data for image processing and may comprise any suitable camera or sensing device, such as, for example, a two dimensional array of a plurality of photosensor elements arranged in at least 640 columns and 480 rows (at least a 640&#xd7;480 imaging array, such as a megapixel imaging array or the like), with a respective lens focusing images onto respective portions of the array. The photosensor array may comprise a plurality of photosensor elements arranged in a photosensor array having rows and columns. Preferably, the imaging array has at least 300,000 photosensor elements or pixels, more preferably at least 500,000 photosensor elements or pixels and more preferably at least 1 million photosensor elements or pixels. The imaging array may capture color image data, such as via spectral filtering at the array, such as via an RGB (red, green and blue) filter or via a red/red complement filter or such as via an RCC (red, clear, clear) filter or the like. The logic and control circuit of the imaging sensor may function in any known manner, and the image processing and algorithmic processing may comprise any suitable means for processing the images and/or image data.</p><p id="p-0030" num="0029">The camera module and circuit chip or board and imaging sensor may be implemented and operated in connection with various vehicular vision-based systems, and/or may be operable utilizing the principles of such other vehicular systems, such as a vehicle headlamp control system, such as the type disclosed in U.S. Pat. Nos. 5,796,094; 6,097,023; 6,320,176; 6,559,435; 6,831,261; 7,004,606; 7,339,149 and/or 7,526,103, which are all hereby incorporated herein by reference in their entireties, a rain sensor, such as the types disclosed in commonly assigned U.S. Pat. Nos. 6,353,392; 6,313,454; 6,320,176 and/or 7,480,149, which are hereby incorporated herein by reference in their entireties, a vehicle vision system, such as a forwardly, sidewardly or rearwardly directed vehicle vision system utilizing principles disclosed in U.S. Pat. Nos. 5,550,677; 5,670,935; 5,760,962; 5,877,897; 5,949,331; 6,222,447; 6,302,545; 6,396,397; 6,498,620; 6,523,964; 6,611,202; 6,201,642; 6,690,268; 6,717,610; 6,757,109; 6,802,617; 6,806,452; 6,822,563; 6,891,563; 6,946,978 and/or 7,859,565, which are all hereby incorporated herein by reference in their entireties, a trailer hitching aid or tow check system, such as the type disclosed in U.S. Pat. No. 7,005,974, which is hereby incorporated herein by reference in its entirety, a reverse or sideward imaging system, such as for a lane change assistance system or lane departure warning system or for a blind spot or object detection system, such as imaging or detection systems of the types disclosed in U.S. Pat. Nos. 7,881,496; 7,720,580; 7,038,577; 5,929,786 and/or 5,786,772, which are hereby incorporated herein by reference in their entireties, a video device for internal cabin surveillance and/or video telephone function, such as disclosed in U.S. Pat. Nos. 5,760,962; 5,877,897; 6,690,268 and/or 7,370,983, and/or U.S. Publication No. US-2006-0050018, which are hereby incorporated herein by reference in their entireties, a traffic sign recognition system, a system for determining a distance to a leading or trailing vehicle or object, such as a system utilizing the principles disclosed in U.S. Pat. No. 6,396,397 and/or 7,123,168, which are hereby incorporated herein by reference in their entireties, and/or the like.</p><p id="p-0031" num="0030">Changes and modifications in the specifically described embodiments can be carried out without departing from the principles of the invention, which is intended to be limited only by the scope of the appended claims, as interpreted according to the principles of patent law including the doctrine of equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A vehicular control system, the vehicular control system comprising:<claim-text>a camera housed in a camera module;</claim-text><claim-text>wherein the camera module is disposed at and behind a windshield of a vehicle equipped with the vehicular control system, the camera viewing through the windshield forward of the equipped vehicle and operable to capture image data;</claim-text><claim-text>wherein the camera comprises an imaging sensor comprising at least one million photosensor elements arranged in a two dimensional array of columns and rows;</claim-text><claim-text>a control comprising a processor operable to process image data captured by the camera to detect an approaching vehicle present forward of the equipped vehicle, wherein the approaching vehicle is approaching an intersection of at least two roads forward of the equipped vehicle;</claim-text><claim-text>wherein the vehicular control system determines projected path of travel of the equipped vehicle;</claim-text><claim-text>wherein image data captured by the camera is processed at the control to determine estimated time to arrival of the approaching vehicle at the intersection;</claim-text><claim-text>wherein the projected path of travel of the equipped vehicle comprises a turn by the equipped vehicle at the intersection and across a traffic lane of the road along which the approaching vehicle is traveling;</claim-text><claim-text>wherein, responsive at least in part to determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will not complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, the vehicular control system determines that it is not safe to proceed along the projected path of travel;</claim-text><claim-text>wherein, responsive at least in part to (i) determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, and (ii) determination via image processing of captured image data that an object is present in the projected path of travel of the equipped vehicle, the vehicular control system determines that it is not safe to proceed along the projected path of travel; and</claim-text><claim-text>wherein, responsive at least in part to (i) determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, and (ii) determination via image processing of captured image data that no object is present in the projected path of travel of the equipped vehicle, the vehicular control system determines that it is safe for the equipped vehicle to proceed along the projected path of travel.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the vehicular control system determines the projected path of travel of the equipped vehicle at least in part via processing at the control of captured image data.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The vehicular control system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the processor of the control comprises an image processing chip, and wherein the projected path of travel of the equipped vehicle is determined at least in part by processing of captured image data by the image processing chip of the processor.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The vehicular control system of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the camera module comprises at least one electrical connector.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The vehicular control system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the camera module houses the image processing chip.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the vehicular control system controls braking of the equipped vehicle responsive to determination that a collision may occur at the intersection.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The vehicular control system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the determined collision that may occur at the intersection comprises collision with the approaching vehicle.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the vehicular control system receives information pertaining to a state of a traffic signal light at the intersection.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The vehicular control system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the vehicular control system receives the information pertaining to the state of the traffic signal light at the intersection via a wireless communication.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the vehicular control system determines the projected path of travel of the equipped vehicle in part responsive to activation of a turn signal of the equipped vehicle.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determined object comprises a pedestrian.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising a radar sensor disposed at the equipped vehicle, the radar sensor sensing forward of the vehicle and operable to capture radar data, wherein determination of the estimated time of arrival of the approaching vehicle at the intersection is based in part on processing at the control of captured radar data.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, comprising a radar sensor disposed at the equipped vehicle, the radar sensor sensing forward of the vehicle and operable to capture radar data, wherein determination of presence of the object in the projected path of travel of the equipped vehicle is based in part on processing at the control of captured radar data.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the vehicular control system generates an alert to a driver of the equipped vehicle responsive to determination that it is not safe to proceed along the projected path of travel.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determination of location of equipped vehicle relative to the approaching vehicle utilizes GPS data.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determination of distance of equipped vehicle to the approaching vehicle utilizes GPS data.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The vehicular control system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determination of a heading angle of the approaching vehicle utilizes GPS data.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A vehicular control system, the vehicular control system comprising:<claim-text>a camera housed in a camera module;</claim-text><claim-text>wherein the camera module is disposed at and behind a windshield of a vehicle equipped with the vehicular control system, the camera viewing through the windshield forward of the equipped vehicle and operable to capture image data;</claim-text><claim-text>wherein the camera comprises an imaging sensor comprising at least one million photosensor elements arranged in a two dimensional array of columns and rows;</claim-text><claim-text>a control comprising a processor operable to process image data captured by the camera to detect an approaching vehicle present forward of the equipped vehicle, wherein the approaching vehicle is approaching an intersection of at least two roads forward of the equipped vehicle;</claim-text><claim-text>wherein the processor of the control comprises an image processing chip;</claim-text><claim-text>wherein the vehicular control system determines projected path of travel of the equipped vehicle;</claim-text><claim-text>wherein image data captured by the camera is processed at the control to determine estimated time to arrival of the approaching vehicle at the intersection;</claim-text><claim-text>wherein the projected path of travel of the equipped vehicle comprises a turn by the equipped vehicle at the intersection and across a traffic lane of the road along which the approaching vehicle is traveling;</claim-text><claim-text>wherein, responsive at least in part to determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will not complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, the vehicular control system determines that it is not safe to proceed along the projected path of travel;</claim-text><claim-text>wherein, responsive at least in part to (i) determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, and (ii) determination via image processing of captured image data that an object is present in the projected path of travel of the equipped vehicle, the vehicular control system determines that it is not safe to proceed along the projected path of travel;</claim-text><claim-text>wherein, responsive at least in part to (i) determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, and (ii) determination via image processing of captured image data that no object is present in the projected path of travel of the equipped vehicle, the vehicular control system determines that it is safe for the equipped vehicle to proceed along the projected path of travel; and</claim-text><claim-text>wherein the vehicular control system controls braking of the equipped vehicle responsive to determination that a collision may occur at the intersection.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The vehicular control system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the determined object comprises a pedestrian.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The vehicular control system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the vehicular control system generates an alert to a driver of the equipped vehicle responsive to determination that it is not safe to proceed along the projected path of travel.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The vehicular control system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the vehicular control system receives information pertaining to a state of a traffic signal light at the intersection.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The vehicular control system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the determined collision that may occur at the intersection comprises collision with the approaching vehicle.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The vehicular control system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the vehicular control system determines the projected path of travel of the equipped vehicle at least in part via processing at the control of captured image data.</claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. A vehicular control system, the vehicular control system comprising:<claim-text>a camera housed in a camera module;</claim-text><claim-text>wherein the camera module is disposed at and behind a windshield of a vehicle equipped with the vehicular control system, the camera viewing through the windshield forward of the equipped vehicle and operable to capture image data;</claim-text><claim-text>wherein the camera comprises an imaging sensor comprising at least one million photosensor elements arranged in a two dimensional array of columns and rows;</claim-text><claim-text>a control comprising a processor operable to process image data captured by the camera to detect an approaching vehicle present forward of the equipped vehicle, wherein the approaching vehicle is approaching an intersection of at least two roads forward of the equipped vehicle;</claim-text><claim-text>wherein the vehicular control system determines projected path of travel of the equipped vehicle;</claim-text><claim-text>wherein image data captured by the camera is processed at the control to determine estimated time to arrival of the approaching vehicle at the intersection;</claim-text><claim-text>wherein the projected path of travel of the equipped vehicle comprises a turn by the equipped vehicle at the intersection and across a traffic lane of the road along which the approaching vehicle is traveling;</claim-text><claim-text>wherein the vehicular control system receives information pertaining to a state of a traffic signal light at the intersection;</claim-text><claim-text>wherein, responsive at least in part to determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will not complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, the vehicular control system determines that it is not safe to proceed along the projected path of travel;</claim-text><claim-text>wherein, responsive at least in part to (i) determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, and (ii) determination via image processing of captured image data that an object is present in the projected path of travel of the equipped vehicle, the vehicular control system determines that it is not safe to proceed along the projected path of travel;</claim-text><claim-text>wherein, responsive at least in part to (i) determination that, while proceeding along the projected path of travel of the equipped vehicle, the equipped vehicle will complete the turn at the intersection before the estimated time to arrival of the approaching vehicle at the intersection elapses, and (ii) determination via image processing of captured image data that no object is present in the projected path of travel of the equipped vehicle, the vehicular control system determines that it is safe for the equipped vehicle to proceed along the projected path of travel; and</claim-text><claim-text>wherein the vehicular control system controls braking of the equipped vehicle responsive to determination that a collision may occur at the intersection.</claim-text></claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The vehicular control system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the vehicular control system determines the projected path of travel of the equipped vehicle in part responsive to activation of a turn signal of the equipped vehicle.</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The vehicular control system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the determined object comprises a pedestrian.</claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The vehicular control system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the determined collision that may occur at the intersection comprises collision with the approaching vehicle.</claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The vehicular control system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the vehicular control system generates an alert to a driver of the equipped vehicle responsive to determination that it is not safe to proceed along the projected path of travel.</claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. The vehicular control system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the vehicular control system determines the projected path of travel of the equipped vehicle at least in part via processing at the control of captured image data.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005507A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005507</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17856881</doc-number><date>20220701</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>031</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2187</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0489</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>11</class><subclass>B</subclass><main-group>27</main-group><subgroup>031</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2187</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0489</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEM AND METHOD OF GENERATING MEDIA CONTENT FROM LIVESTREAMING MEDIA CONTENT</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63218296</doc-number><date>20210703</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Logitech Europe S.A.</orgname><address><city>Lausanne</city><country>CH</country></address></addressbook><residence><country>CH</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>CREETH</last-name><first-name>Andrew John</first-name><address><city>San Mateo</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KAISER</last-name><first-name>Sean Elliot</first-name><address><city>Vancouver</city><country>CA</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The embodiments described herein provide streamlined video editing functionalities that can be integrated into the broadcast software, providing a streamer the ability to select video clips to be sent to viewers and saved during a livestreaming session, edit the saved clips after the livestreaming session to generate short-form video content, including necessary information, such as real-time alerts of viewers that appeared during the livestreaming session.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="100.67mm" wi="158.75mm" file="US20230005507A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="231.82mm" wi="150.54mm" orientation="landscape" file="US20230005507A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="228.18mm" wi="147.24mm" orientation="landscape" file="US20230005507A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="237.07mm" wi="151.64mm" file="US20230005507A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="141.56mm" wi="141.90mm" file="US20230005507A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="233.93mm" wi="169.59mm" orientation="landscape" file="US20230005507A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="198.20mm" wi="130.30mm" file="US20230005507A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="226.74mm" wi="148.25mm" file="US20230005507A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="204.55mm" wi="132.16mm" file="US20230005507A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="217.25mm" wi="132.67mm" file="US20230005507A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="201.34mm" wi="136.31mm" file="US20230005507A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="207.69mm" wi="133.77mm" file="US20230005507A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims benefit of U.S. provisional patent application Ser. No. 63/218,296, filed Jul. 3, 2021, which is herein incorporated by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Field</heading><p id="p-0003" num="0002">Embodiments of the present disclosure generally relate to local broadcast software and, more particularly, to integrated and automated editing functionalities within the local broadcast software.</p><heading id="h-0004" level="1">Description of the Related Art</heading><p id="p-0004" num="0003">The established industries of online video streaming, such as YouTube&#xae;, Vimeo&#xae;, and Facebook&#xae;, and internet-based multiplayer gaming combined have led to a new industry of livestreaming, such as Twitch&#xae;, YouTube Gaming&#xae;, and Facebook Gaming&#xae;. The online video streaming primarily serves pre-recorded short-form video, such as several minutes long, while the livestreaming often broadcasts live video, such as a user's gaming experience, often over an hour. During a livestreaming session, broadcast software provides a user (also referred to as a &#x201c;streamer&#x201d;) with various functionalities, such as the use of overlays, which are graphical elements to be added to the live video. Once such a livestreaming session is completed, the broadcasted content is either discarded or edited to create a short-form video containing highlights from the broadcasted content that a user may wish to upload to an online video streaming platform.</p><p id="p-0005" num="0004">Conventionally, this post-livestreaming video editing requires saving a broadcasted content within local memory, such as a hard drive of a personal computer, painstakingly cutting clips from the broadcasted content, adding selected saved clips in a sequential order to form a timeline, manually adding transitions between clips, or the like, within a video editing software. Furthermore, a broadcasted content saved on a local memory may not include real-time alerts that appear, for example, when a viewer subscribes, follows, or donates to the streamer during a livestreaming session.</p><p id="p-0006" num="0005">Accordingly, there is a need in the art for streamlined video editing functionalities that can be integrated into the broadcast software, providing a streamer the ability to generate short-form content with the necessary information, such as real-time alerts during a livestreaming session.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0007" num="0006">Described herein is a system and method for capturing viewer interactions, such as real-time alerts, to a live stream of a video file during its streaming, integrating the viewer interactions with the video file, and providing a short-form content video to a video-sharing platform. The short-form content video includes selections of portions of the video file, alterations of the video file, and transitions between selected portions of the video file.</p><p id="p-0008" num="0007">Embodiments described herein provide a method of rendering video files. The method includes sending one or more video files to a plurality of live streaming platforms to make the video files available to a plurality of viewers, receiving streaming events from the plurality of live streaming platforms, where the streaming events include viewer interactions to the video files, rendering a short-form content video by editing, combining the video files, and integrating the streaming events into the short-form content video, and sending the short-form content video to a plurality of video-sharing sites.</p><p id="p-0009" num="0008">Embodiments described herein provide a system for rendering video files, the system comprising: a processor; and a memory coupled to the processor and having loaded therein, for execution by the processor, video editing software. The video editing software being configured to: upload one or more video files to a plurality of live streaming platforms; receive streaming event information that includes viewer interactions to the video files; render a short-form content video by editing, combining the video files, and integrating the streaming event information into the short-form content video; and send the short-form content video to a plurality of video-sharing sites.</p><p id="p-0010" num="0009">Embodiments described herein also provide a non-transitory computer-readable medium comprising instructions that are executable in a processor of a computer system to carry out a method of scheduling a plurality of workloads for execution in a cluster of nodes, the method comprising: uploading one or more video files to a plurality of live streaming platforms; receiving streaming event information that includes viewer interactions to the one or more video files; editing, combining the one or more video files, and integrating the streaming event information to create a preview of a short-form content video; rendering the preview into the short-form content video; and sending the short-form content video to a plurality of video-sharing sites.</p><p id="p-0011" num="0010">Embodiments described herein also provide a method of rendering video files, the method comprising: uploading one or more video files to a plurality of live streaming platforms; receiving streaming event information that includes viewer interactions to the one or more video files; editing, combining the one or more video files, and integrating the streaming event information to create a preview of a short-form content video; rendering the preview into the short-form content video; and sending the short-form content video to a plurality of video-sharing sites.</p><p id="p-0012" num="0011">Further embodiments include a computer-readable medium containing instructions for carrying out one more aspects of the above method and a system configured to carry out one or more aspects of the above method.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012">So that the manner in which the above-recited features of the present disclosure can be understood in detail, a more particular description of the disclosure, briefly summarized above, may be had by reference to embodiments, some of which are illustrated in the appended drawings. It is to be noted, however, that the appended drawings illustrate only typical embodiments of this disclosure and are therefore not to be considered limiting of its scope, for the disclosure may admit to other equally effective embodiments.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> depicts a first portion of a data streaming environment according to one embodiment.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> depicts a second portion of a data streaming environment according to one embodiment.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>B</figref> depict a method of generating media content from livestreaming media content, according to one embodiment.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a flow of operations for the local broadcast software, the server, and the live streaming platforms, according to one embodiment.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts a flow of operations for the local broadcast software, according to one embodiment.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts a flow of operations for the user editing video, according to one embodiment.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> depicts a flow of operations for the server, according to one embodiment.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> depicts a flow of operations for the multi-stream function of the server, according to one embodiment.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>6</b>C</figref> depicts a flow of operations for the API data collector function of the server, according to one embodiment.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a flow of operations for a live streaming platform, according to one embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0024" num="0023">To facilitate understanding, identical reference numerals have been used, where possible, to designate identical elements that are common to the figures. It is contemplated that elements and features of one embodiment may be beneficially incorporated in other embodiments without further recitation.</p><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0025" num="0024">The embodiments described herein provide streamlined video editing functionalities that can be integrated into broadcast software, providing a streamer the ability to select video clips to be saved during a livestreaming session, edit the saved clips to generate short-form video content, including necessary information, such as real-time alerts that appeared during the livestreaming session, after the livestreaming session.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIGS. <b>1</b>A and <b>1</b>B</figref> depict a data streaming environment <b>100</b> according to one embodiment. The data streaming environment <b>100</b> includes a user device <b>102</b>, a server <b>104</b>, one or more live-streaming platforms <b>106</b>, one or more viewers <b>108</b>, a method for collecting viewer interactions <b>110</b>, and one or more streaming service application programming interfaces (APIs) <b>112</b>. The data streaming environment <b>100</b> further includes a network <b>116</b> that facilitates communication between the user device <b>102</b> and the server <b>104</b> and between the server <b>104</b> and the one or more streaming service APIs <b>112</b>. In some embodiments, the data streaming environment <b>100</b> further includes alternative API data sources <b>114</b>. The network <b>116</b> generally represents any data communications network suitable for transmitting video and audio data (e.g., the Internet) between different locations.</p><p id="p-0027" num="0026">Examples of the user device <b>102</b> can include, without limitation, a laptop, a personal computer, a tablet, a smartphone, a virtual or augmented reality computing device, or any related personal computing device. The user device <b>102</b> includes a local broadcast software <b>118</b> stored in a non-volatile memory of the user device <b>102</b>. The local broadcast software <b>118</b>, when executed by a processor of the user device <b>102</b>, receives a game signal <b>120</b> and, optionally, a user signal <b>122</b> from the user device <b>102</b> and retrieves a graphical overlay <b>124</b> from the server <b>104</b> via the network <b>116</b>. The local broadcast software <b>118</b> then produces, by a video encoder <b>126</b>, a video file based on the game signal <b>120</b>, the optional user signal <b>122</b>, and the graphical overlay <b>124</b>. The local broadcast software <b>118</b> further sends authentication information to a selected one of the one or more of live-streaming platforms <b>106</b> to identify a user uploading the video file and uploads the video file to a multi-stream service <b>128</b> using a streaming protocol <b>130</b>. Additionally, the local broadcast software <b>118</b> stores the user settings that are related to the live-streaming platform <b>106</b> and used for broadcasting, the encoding settings that are used to produce a video file by the video encoder <b>126</b>, and the stream settings that are used to upload a video file to the live-streaming platform <b>106</b>. The one or more live-streaming platforms <b>106</b> include, without limitation, Twitch&#xae;, YouTube Gaming&#xae;, Facebook Gaming&#xae;, UStream&#xae;, Periscope&#xae;, Mixer&#xae;, and Smashcast&#xae;.</p><p id="p-0028" num="0027">The game signal <b>120</b> includes, but is not limited to, an audio/video signal from a video game, a specific application unrelated to a video game, or the user's operating system environment, including some or all applications the user has executed. Multiple game signals <b>120</b> and user signals <b>122</b> may also be combined to create the game signal <b>120</b> or user signal <b>122</b>.</p><heading id="h-0008" level="1">Local Broadcast Software</heading><p id="p-0029" num="0028">Functions of the local broadcast software <b>118</b> include but are not limited to: (1) receiving a game signal <b>120</b> and, optionally, a user signal <b>122</b> from the user device <b>102</b>; (2) using the network <b>116</b> to retrieve the graphical overlay <b>124</b> from the server <b>104</b>; (3) using the video encoder <b>126</b> to produce a video file from the game signal <b>120</b>, the optional user signal <b>122</b>, and the graphical overlay <b>124</b>; (4) storing the video file for a set interval; (5) sending authentication information to the live-streaming platform <b>106</b> to identify the user uploading the video file; (6) uploading the video file to a multi-stream service <b>128</b> of the server using a streaming protocol <b>130</b>; (7) storing user settings related to, but not limited to: (7a) the live-streaming platform <b>106</b> to which the user may broadcast their encoded video file; (7b) encoding settings used to configure and optimize the video encoder <b>126</b>; and (7c) streaming settings used to configure and optimize the streaming protocol <b>130</b> used to upload the video file to the live-streaming platform <b>106</b>; and (8) integrated video editing.</p><heading id="h-0009" level="1">Integrated Video Editing</heading><p id="p-0030" num="0029">In the embodiments described herein, the local broadcast software <b>118</b> further includes integrated video editing functionalities that generate a short-form content video of a livestreaming content and upload it to an online video streaming platform, such asYouTube&#xae;, Vimeo&#xae;, Facebook&#xae;, and Dailymotion&#xae;. Alternatively or additionally, a generated short-form content video can be saved in a local memory device, such as the memory of the user device <b>102</b>. The video editing functionalities are integrated within the local broadcast software <b>118</b> and thus can be performed without separate video editing software.</p><p id="p-0031" num="0030">The integrated video editing functions of the local broadcast software <b>118</b> include but are not limited to: (1) setup a combination of keys (referred to as a &#x201c;hotkey&#x201d;) by a user; (2) during a livestreaming, when a hotkey is pressed, save the following data, which is not limited to: (2a) a video file having a length of the set interval stored by the local broadcast software <b>118</b> at the time when the hotkey is pressed; (2b) the user settings stored by the local broadcast software <b>118</b>; (2c) information relating to alternative data sources <b>114</b> via the graphics overlay file; and (2d) metadata about the data received from the streaming service APIs <b>112</b> and the alternative API data sources <b>114</b> via the graphics overlay file; (3) after the livestreaming, display all of the video files saved during the livestreaming and any relevant data relating to the video files; (4) allow a user video editing options, but not limited to: (4a) review individual video files; (4b) edit (e.g., trim down) one or more of the video files; (4c) drag individual video files on the display and rearrange the order of the video files; (4d) choose a type and/or duration of transition between adjacent video files; (4e) select video files to be included in a short-form content video to be generated; and (4f) optionally, add audio to the short-form content video to be generated; (5) generate a preview of a short-form content video to be generated; (6) render (e.g., compiling and generating) the previewed short-form content video; (7) publish the generated short-form content video to a video-sharing platform, such as YouTube&#xae;, Vimeo&#xae;, Facebook&#xae;, Dailymotion&#xae;; and (8) export the generated short-form content video to a local memory device of the user device.</p><heading id="h-0010" level="1">Server Elements</heading><p id="p-0032" num="0031">The server <b>104</b> includes a method for persistent storage, such as a non-volatile memory, and a method for initiating and responding to internet requests, such as a web server. The server <b>104</b> stores and makes various user settings available for retrieval, including the user's overlay configuration <b>132</b> and the user's graphical overlay <b>124</b>. The alternative API data sources <b>114</b> are data sources unrelated to the one or more streaming service APIs <b>112</b> used to create the graphical overlay <b>124</b>. The server <b>104</b> also includes an API data collector <b>134</b>, which is responsible for aggregating data from one or more streaming service APIs <b>112</b> and alternative API data sources <b>114</b>. Data gathered by the API data collector <b>134</b> is then used in combination with the user's overlay configuration <b>132</b> to populate the graphical overlay <b>124</b>. The server <b>104</b> further includes the multi-stream service <b>128</b>, which stores and maintains the user's connections to the live-streaming platform <b>106</b>. The one or more streaming service APIs <b>112</b> and the alternative API data sources <b>114</b> connection(s) may be unidirectional or bilateral. The one or more streaming service APIs <b>112</b> and the alternative API data sources <b>114</b> may also be a RESTful service, a persistent WebSockets connection, or any other method of regularly publishing and sharing information between disparate internet systems. In the embodiment depicted, the server <b>104</b> responds to requests from the local broadcast software <b>118</b> executing on the user device <b>102</b> and retrieves the overlay configuration <b>132</b> as needed.</p><p id="p-0033" num="0032">Functions of the server <b>104</b> include, but are not limited to: (1) responding to requests from the local broadcast software <b>118</b>, the user device <b>102</b>, or the streaming service API <b>112</b>; (2) hosting a web page that allows users to edit their overlay configuration <b>132</b>; (3) providing an API data collector <b>134</b>, which may perform, but is not limited to, the following actions: (3a) maintaining persistent connections with the streaming service API(s) <b>112</b>; (3b) receiving data from the alternative API data sources <b>114</b>; (3c) storing metadata about the data received from the streaming service APIs <b>112</b> and the alternative API data sources <b>114</b>; (3d) storing data aggregated from one or more sources related to the user in the user's account; (4) generating the graphical overlay <b>124</b> based on the user's overlay configuration <b>132</b> at set intervals, based on specific data events as they are received in real time by the API data collector <b>134</b>, upon request, or otherwise as needed; (5) maintaining user account information; (6) hosting the multi-stream service <b>128</b>; and (7) hosting and websites required to support the disclosed system.</p><heading id="h-0011" level="1">Multi-Stream Service</heading><p id="p-0034" num="0033">Functions of the multi-stream service <b>128</b> in the server <b>104</b> include but are not limited to: (1) storing user configuration settings to control which of the one or more livestreaming platforms <b>106</b> to which an uploaded video file should be redistributed; (2) optionally receiving authentication information from the local broadcast software <b>118</b>; (3) if authentication information is received, forwarding said authentication information to the one or more live-streaming platforms <b>106</b>; (4) receiving the uploaded video file from the local broadcast software <b>118</b> via a streaming protocol <b>130</b>; (5) optionally decoding the video file, then re-encoding the file to optimize it for individual streaming platform(s) <b>106</b>; or (6) uploading the video file to one or more live-streaming platforms <b>106</b> using a streaming protocol <b>130</b>.</p><heading id="h-0012" level="1">Livestreaming Functions</heading><p id="p-0035" num="0034">Functions of each of the one or more live-streaming platforms <b>106</b> include but are not limited to: (1) storing account details for the user; (2) receiving authentication information from the local broadcast software <b>118</b> and/or the multi-stream service <b>128</b>; (3) using the authentication information to identify the user uploading the video file; (4) receiving the uploaded video file from the multi-stream service <b>128</b> via a streaming protocol <b>130</b>; (5) decoding the video file; (6) playing the decoded video file for viewers <b>108</b> to consume on the user's channel; (7) gathering metadata about viewer interactions <b>110</b> including, but not limited to: (7a) the type of interaction; (7b) the time of the interaction; (7c) a viewer's <b>108</b> account details; (8) storing viewer interactions <b>110</b> for retrieval by the streaming service API(s) <b>112</b>; (9) providing Streaming Service APIs; and (10) Providing Alternative API Data sources.</p><p id="p-0036" num="0035">Functions of the one or more streaming service APIs <b>112</b> include but are not limited to: (1) retrieving viewer interactions <b>110</b> for processing; (2) processing viewer interactions <b>110</b> into stream events <b>136</b> formatted for use in the streaming service APIs <b>112</b>; and (3) sending the stream events <b>136</b> to the API data collector <b>134</b> via the streaming service APIs <b>112</b>.</p><p id="p-0037" num="0036">Functions of the alternative API data sources <b>114</b> include but are not limited to: (1) receive data directly from the video game; (2) receive data from a computer vision and/or an artificial intelligence engine analysis of the game; and (3) receive data from third-party APIs related to the user's game, the user, or the viewers <b>108</b>.</p><heading id="h-0013" level="1">Integrated Video Editing Example</heading><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>B</figref> illustrate a method <b>200</b> of generating media content from livestreaming media content using one or more of the elements found in the data streaming environment <b>100</b> described in <figref idref="DRAWINGS">FIGS. <b>1</b>A-<b>1</b>B</figref>, according to one embodiment.</p><p id="p-0039" num="0038">At activity <b>202</b>, the method <b>200</b> includes collecting a plurality of media content segments from a livestream of media content. The live streamed media content can be provided from a source providing live video, such as a user's gaming experience. Activity <b>202</b> can include performing activities <b>204</b>-<b>214</b>, as shown in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> and discussed below.</p><p id="p-0040" num="0039">At activity <b>204</b> of activity <b>202</b>, the method <b>200</b> includes receiving, by a first electronic device, a first user input. The first user input, which forms a game signal (<figref idref="DRAWINGS">FIG. <b>3</b></figref>), can be created by a user pressing a &#x201c;hotkey&#x201d; on the first electronic device, is received while livestreaming media content is being generated.</p><p id="p-0041" num="0040">At activity <b>206</b> of activity <b>202</b>, the method <b>200</b> includes storing a first portion of the livestreaming media content within a first memory location based on the received user input. In some embodiments, the first portion of the livestreaming media content comprises a first captured media content generated prior to receiving the first user input. In other embodiments, the first portion of the livestreaming media content comprises a first captured media content generated after receiving the first user input. In yet another embodiment, the first portion of the livestreaming media content comprises a first captured media content that includes a first portion generated before receiving the first user input and a second portion generated after receiving the first user input. The first captured media content includes a portion of the livestreaming media content that has a length that extends for a first period of time. In one example, after receiving the first user input the local broadcast software <b>118</b> is configured to automatically collect livestreaming media content that occurred a first period of time (e.g., 30 seconds) before the user input was received and collect livestreaming media content that occurs a second period of time (e.g., 60 seconds) after the user input was received, and thus form a livestreaming media content clip that has a fixed length (e.g., 90 seconds).</p><p id="p-0042" num="0041">At activity <b>208</b> of activity <b>202</b>, the method <b>200</b> includes storing metadata within a second memory location based on the received first user input. The metadata comprises information related to the first captured media content, such as information selected from a group consisting of an identifier associated with a user, a time stamp taken when the user's first user input was received, the livestream media content information (e.g., type of livestreaming media content), streaming platform information (e.g., information regarding), sidebar information (e.g., chat text), and information relating to real-time alerts generated during the collection of the livestream of media content.</p><p id="p-0043" num="0042">At activity <b>210</b> of activity <b>202</b>, the method <b>200</b> includes receiving, by the first electronic device, a second user input. The second user input, which forms a game signal (<figref idref="DRAWINGS">FIG. <b>3</b></figref>), can be formed by a user pressing a &#x201c;hotkey&#x201d; on the first electronic device a second time, is received while the livestreaming media content is still being generated. In some embodiments, if the second user input is received in close proximity in time from the first user input the local broadcast software <b>118</b> can use this added input to set a priority level of the livestreaming media content that is being collected. In one example, if the second user input is received in quick succession (e.g., &#x3c;1 second) from the first user input the livestreaming media content that is being collected might be given a higher priority than a case where the second user input is received after a certain period of time has elapsed (e.g., 2-5 seconds) or even received while the livestreaming media content is still being collected after the first user input was received.</p><p id="p-0044" num="0043">At activity <b>212</b> of activity <b>202</b>, if the second user input is received after the first livestreaming media content has been collected and/or stored in a memory location, the method <b>200</b> includes storing a second portion of the livestreaming media content within a third memory location based on the received second user input. In some embodiments, the second portion of the livestreaming media content comprises a second captured media content generated prior to receiving the second user input. In other embodiments, the second portion of the livestreaming media content comprises a second captured media content generated after receiving the second user input. In yet another embodiment, the second portion of the livestreaming media content comprises a second captured media content that includes a first portion generated before receiving the first user input and a second portion generated after receiving the first user input. The second captured media content includes a portion of the livestreaming media content that has a length that extends for a second period of time. In one example, after receiving the second user input the local broadcast software <b>118</b> is configured to automatically collect livestreaming media content that occurred a first period of time (e.g., 30 seconds) before the user input was received and collect livestreaming media content that occurs a second period of time (e.g., 60 seconds) after the user input was received, and thus form a livestreaming media content clip that has a fixed length (e.g., 90 seconds).</p><p id="p-0045" num="0044">At activity <b>214</b> of activity <b>202</b>, the method <b>200</b> includes storing metadata within a fourth memory location based on the received second user input. The metadata can include information related to the second captured media content, such as information selected from a group consisting of an identifier associated with a user, a time stamp taken when the user's first user input was received, the livestream of media content information, streaming platform information, sidebar information, and information relating to real-time alerts generated during the collection of the livestream of media content.</p><p id="p-0046" num="0045">Referring back to <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, at activity <b>216</b>, in one example, the method <b>200</b> includes simultaneously displaying, by use of the first electronic device, a first portion of the first captured media content, the metadata of the first captured media content, a first portion of the second captured media content, and the metadata of the second captured media content. In some embodiments, the process of simultaneously displaying the first portion of the first captured media content, the metadata of the first captured media content, the first portion of the second captured media content, and the metadata of the second captured media content is completed automatically by one or more software applications. In some embodiments, the one or more software applications include instructions that are being executed by a processor running on the first electronic device.</p><p id="p-0047" num="0046">At activity <b>218</b>, in one example, the method <b>200</b> includes generating a rendered media content that includes at least a portion of the first captured media content and the second captured media content. The process of generating the rendered media content can include performing at least one of: adding a media transition between the first captured media content and the second captured media content to form a first rendered section; altering the media content within the first captured media content; or altering the media content within the second captured media content.</p><p id="p-0048" num="0047">At activity <b>220</b>, the method <b>200</b> includes publishing the generated rendered media content to a video sharing platform. In some embodiments, the video-sharing platform can include YouTube&#xae;, Vimeo&#xae;, Facebook&#xae;, or Dailymotion&#xae;.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a flow of operations for the local broadcast software, the server, and the live streaming platforms, according to one embodiment. In step <b>302</b>, the user creates a game signal by pressing a &#x201c;hotkey&#x201d; (e.g., spacebar, return, or F13 on a keyboard). In step <b>304</b>, a video file is sent by the local broadcast software <b>118</b> to the server <b>104</b>. The server <b>104</b> sends in step <b>306</b> the video file to one or more live streaming platforms <b>106</b>. In step <b>308</b>, the viewers on the live streaming platforms provide their interactions to the video file. In step <b>310</b>, the viewer interactions are converted into streaming events and sent to the server <b>104</b>. In step <b>312</b>, a graphical overlay provided by the user has its content updated by the streaming events. In step <b>314</b>, the user creates another game signal by pressing a hotkey. In step <b>316</b>, another video file is sent by the local broadcast software <b>118</b> to the server. In step <b>318</b>, the server sends the video file to the one or more live streaming platforms. In step <b>320</b>, viewer interactions to the video file are captured by the live streaming platforms and converted to streaming events. In step <b>322</b>, the streaming events provide content to the graphical overlay, and in step <b>326</b>, the user performs video editing functions to create a short form video which is then sent to a video sharing platform <b>350</b>.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts a flow of operations for the function of the local broadcast software, according to one embodiment. In step <b>402</b>, the function receives a game or user input, such as a hotkey being pressed. In step <b>404</b>, the function creates or retrieves a video file saved on a disk in the user's device. In an embodiment, the retrieved video file is tagged with an identity and represented by an icon on the screen of the user device. The function, in step <b>406</b>, encodes a prescribed length of the video and sends in step <b>408</b> the encoded video file and authentication of a user to the server, where the authentication identifies the user who is the source of the video file. (See items 5-6 in the Local Broadcast Software section above). In step <b>410</b>, the function performs video editing (further described in <figref idref="DRAWINGS">FIG. <b>5</b></figref>) to create a short-form content video. In step <b>412</b>, the function saves the short form content video on the user device. (See items 6-8 in the Integrated Video Editing section above). The hotkey may be pressed multiple times, each time causing steps <b>404</b>-<b>412</b> to be performed.</p><p id="p-0051" num="0050">In step <b>414</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the function sends the short form content video to a video sharing platform. (See item 7 in the Integrated Video Editing section above). In one embodiment, the video sharing platform is the same as the live streaming platform. In some embodiments, the video sharing platform is selected based on the live streaming platform to which the video file was sent.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts a flow of operations for the function of the user generating and editing a video, according to one embodiment. In step <b>502</b>, the function determines whether the hotkey has been pressed and whether a live streaming is in process. If so, then in step <b>504</b>, the function saves the video file, which has a prescribed length, to the disk in the user device, and in step <b>506</b> saves the user settings. The prescribed length may be a portion of the video before the hotkey is pressed, a portion during the live streaming, and a portion after the live streaming terminates. (See item 2 in the Integrated Video Editing section above). In step <b>508</b>, the function receives a populated graphical overlay file from the server. The graphical overlay file contains stream events from the live streaming platforms and data from the alternative API data source and related metadata. In one embodiment, the stream events are tagged as to their type and time. For example, if a viewer donates funds during the live streaming, the type is a donation, and the time indicates a point in the video file to which the viewer is reacting, where a link is provided in the video or in information about the video as to where to donate the funds. In step <b>509</b>, the function performs steps <b>502</b>-<b>508</b> each time the hotkey is pressed, resulting in multiple video files stored in the user device. However, if the end of the live streaming event is reached then the flow may then proceed on to steps <b>510</b>-<b>518</b>.</p><p id="p-0053" num="0052">In step <b>510</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the function, with the help of the user, edits, displays, and re-orders the video files saved during the live streaming as well as the complete video files stored on disk that were the source of the video files sent for viewer interaction. (See item 4 in the Integrated Video Editing section above). In step <b>512</b>, the function adds or alters a transition between adjacent video files. In one embodiment, a transition is selected based on the tags that identify the video file and tags identifying the streaming event which the video file received. (See item 4d of in the Integrated Video Editing section above). In step <b>514</b>, the function optionally adds audio to the short form content video. (See item 4f in the Integrated Video Editing section above). In step <b>516</b>, the function generates a preview for the user of the short form content video. (See item 5 in the Integrated Video Editing section above). In step <b>518</b>, the function renders the preview of the short form content video. (See item 6 in the Integrated Video Editing section above).</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> depicts a flow of operations for the function of the server, according to one embodiment. In step <b>602</b>, the function receives a video file and user authentication from the local broadcast software <b>118</b>. (See item 4 in the Multi-Stream Service section above). In step <b>604</b>, the function performs the multi-stream service, which is further described in reference to <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>. (See also item 6 in the Server Elements section above). In step <b>606</b>, the function receives stream events from the live stream platforms. (See item 3c in the Multi-Stream Service section above). In step <b>608</b>, the function performs the API data collector operation, which is further described in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref>. (See also items 3b and 3c in the Multi-Stream Service section above). In step <b>610</b>, the function performs the overlay configuration operation, which populates the graphical overlay according to the overlay configuration specified by the user. (See in the Multi-Stream Service section above). In step <b>612</b>, the function forms the graphical overlay file from the populated graphical overlay. In step <b>614</b>, the function sends the graphical overlay file to the local broadcast software <b>118</b>. (See item 2 in the Integrated Video Editing section above).</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> depicts a flow of operations for the function of the multi-stream service of the server, according to one embodiment. In step <b>652</b>, the function saves the user configuration settings. (See item 1 in the Multi-Stream Service section above). In step <b>654</b>, the function awaits receipt of the user authentication. (See item 2 in the Multi-Stream Service section above). If the user authentication is received, as determined in step <b>654</b>, then the function sends in step <b>656</b> the user authentication to the live streaming platforms. (See item 6 in the Multi-Stream Service section above). In step <b>658</b>, the function awaits the receipt of the video file. (See item 4 in the Multi-Stream Service section above). If the video file is received, as determined in step <b>658</b>, the function optionally decodes the video file and re-codes the video file in step <b>660</b>. (See item 5 in the Multi-Stream Service section above). In step <b>662</b>, the function sends the encoded video file to the live streaming platforms. (See item 6 in the Multi-Stream Service section above).</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>6</b>C</figref> depicts a flow of operations for the function of the API data collector of the server, according to one embodiment. In step <b>682</b>, the function receives stream events from the live streaming APIs. In step <b>684</b>, the function receives data from alternative API data sources. In step <b>686</b>, the function saves the metadata for the data and stream events. In step <b>688</b>, the function sends the stream events, data, and metadata to the server. (See item 3 in the Server Elements section above).</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a flow of operations for the function of a live streaming platform, according to one embodiment. In step <b>702</b>, the function receives a video file from the server. In step <b>704</b>, the function receives a user authentication. (See item 2 in the Livestreaming Functions section above). In step <b>706</b>, the function decodes the video file. (See item 5 in the Livestreaming Functions section above). In step <b>708</b>, the function sends the decoded video file to the viewers. (See item 6 in the Livestreaming Functions section above). In step <b>710</b>, the function gathers interactions from the viewers of the decoded video file. (See item 7 in the Livestreaming Functions section above). In step <b>712</b>, the function converts the viewer interactions to stream events. In step <b>714</b>, the function sends the stream events to the server. (See Livestreaming Functions section above).</p><p id="p-0058" num="0057">While the foregoing is directed to embodiments of the present disclosure, other and further embodiments of the disclosure may be devised without departing from the basic scope thereof, and the scope thereof is determined by the claims that follow.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of rendering video files, the method comprising:<claim-text>uploading one or more video files to a plurality of live streaming platforms;</claim-text><claim-text>receiving streaming event information that includes viewer interactions to the one or more video files;</claim-text><claim-text>editing, combining the one or more video files, and integrating the streaming event information to create a preview of a short-form content video;</claim-text><claim-text>rendering the preview into the short-form content video; and</claim-text><claim-text>sending the short-form content video to a plurality of video-sharing sites.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising, while receiving the streaming event information, saving the uploaded one or more video files and the streaming event information in response to the receipt of a game signal.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the game signal is generated based on input received from a user, wherein the input received from the user comprises the user pressing a hotkey.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising sending authorization for a user to the live streaming platforms to identify the user sending the video files.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a pre-set time interval limits a length of the one or more video files.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein streaming event information is formed by an analysis, performed by an artificial intelligence engine, of the one or more video files.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the streaming event information conforms to a graphical overlay based on a pre-defined overlay configuration provided by a user sending the video files.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the viewer interactions of the streaming event information include at least one of a type of viewer interaction, a time of the interaction, and viewer account details.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>further comprising storing the one or more video files in a buffer for use in rendering the short-form content video; and</claim-text><claim-text>wherein combining video files includes combining the uploaded one or more video files.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein combining video files includes providing a transition between one or more video files that are adjacent to each other in time.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A system for rendering video files, the system comprising:<claim-text>a processor; and</claim-text><claim-text>a memory coupled to the processor and having loaded therein, for execution by the processor, video editing software,</claim-text><claim-text>wherein the video editing software is configured to:<claim-text>upload one or more video files to a plurality of live streaming platforms;</claim-text><claim-text>receive streaming event information that includes viewer interactions to the video files;</claim-text><claim-text>render a short-form content video by editing, combining the video files, and integrating the streaming event information into the short-form content video; and</claim-text><claim-text>send the short-form content video to a plurality of video-sharing sites.</claim-text></claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the video editing software is further configured to, while receiving the streaming event information, save the uploaded one or more video files and the streaming event information in response to the receipt of a game signal.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the video editing software is further configured to send authorization for a user to the live streaming platforms to identify the user sending the video files.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein streaming event information is formed by an analysis, performed by an artificial intelligence engine, of the one or more video files.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the streaming event information conforms to a graphical overlay based on a pre-defined overlay configuration provided by a user sending the video files.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the viewer interactions include a type of interaction, a time of the interaction, and viewer account details.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A non-transitory computer-readable medium comprising instructions that are executable in a processor of a computer system to carry out a method of scheduling a plurality of workloads for execution in a cluster of nodes, the method comprising:<claim-text>uploading one or more video files to a plurality of live streaming platforms;</claim-text><claim-text>receiving streaming event information that includes viewer interactions to the one or more video files;</claim-text><claim-text>editing, combining the one or more video files, and integrating the streaming event information to create a preview of a short-form content video;</claim-text><claim-text>rendering the preview into the short-form content video; and</claim-text><claim-text>sending the short-form content video to a plurality of video-sharing sites.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising, while receiving the streaming event information, saving the uploaded one or more video files and the streaming event information in response to the receipt of a game signal.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the game signal is generated based on input received from a user, wherein the input received from the user comprises the user pressing a hotkey.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the method further comprises sending authorization for a user to the live streaming platforms to identify the user sending the video files.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein streaming event information is formed by an analysis, performed by an artificial intelligence engine, of the one or more video files.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the viewer interactions of the streaming event information include at least one of a type of viewer interaction, a time of the interaction, and viewer account details.</claim-text></claim></claims></us-patent-application>
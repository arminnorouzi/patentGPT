<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007135A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007135</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17748061</doc-number><date>20220519</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2021-110864</doc-number><date>20210702</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>44</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>00403</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>00915</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>00488</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>1</main-group><subgroup>442</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">IMAGE FORMING APPARATUS</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>TOSHIBA TEC KABUSHIKI KAISHA</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Kato</last-name><first-name>Hiroyuki</first-name><address><city>Mishima Shizuoka</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">According to one embodiment, an image forming apparatus includes a voice input interface and a processor. The voice input interface is configured to acquire an input voice input through a microphone. The processor is configured to recognize a content of a job instructed by voice from the input voice acquired by the voice input interface and to identify a speaker from the input voice and, if voices output from a plurality of speakers in the same period are acquired, configured to set an execution order of a plurality of jobs that are recognized from the voices output from the speakers and to execute the jobs in the set execution order.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="198.71mm" wi="156.21mm" file="US20230007135A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="213.11mm" wi="158.24mm" file="US20230007135A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="163.83mm" wi="162.48mm" file="US20230007135A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="95.67mm" wi="162.05mm" file="US20230007135A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="155.28mm" wi="92.63mm" file="US20230007135A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="236.73mm" wi="113.20mm" file="US20230007135A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is based upon and claims the benefit of priority from Japanese Patent Application No. 2021-110864, filed on Jul. 2, 2021, the entire contents of which are incorporated herein by reference.</p><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">Embodiments described herein relate generally to an image forming apparatus, a method for an image forming apparatus, and an image forming system.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">In the related art, regarding an image forming apparatus such as a digital multi-functional peripheral, a voice operation system that executes an execution instruction of a job by voice using voice recognition is disclosed. However, the voice operation system that is applied to the image forming apparatus in the related art does not have a function of identifying a speaker who executes a voice operation in many cases. Therefore, the image forming apparatus such as a digital multi-functional peripheral to which the voice operation system is applied has a problem in that any one can instruct to execute a job by voice.</p><p id="p-0005" num="0004">In addition, by providing a function of identifying users to the voice operation system, usage authority can be checked for the individual users. However, if an image forming apparatus receives instructions by voice, a case where a plurality of users instruct the image forming apparatus to execute a plurality of different jobs in the same period is more likely to occur. Therefore, it is desired that an image forming apparatus that can smoothly process a plurality of jobs instructed by a plurality of users even if the users instruct the image forming apparatus to execute the jobs in the same period by voice.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">DESCRIPTION OF THE DRAWINGS</heading><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration example of a digital multi-functional peripheral as an image forming apparatus according to an embodiment;</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating a configuration example of a processing system including the digital multi-functional peripheral as the image forming apparatus;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating a configuration example of a user information database stored in the digital multi-functional peripheral as the image forming apparatus;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating a configuration example of a function database that stores information regarding a voice execution function stored in the digital multi-functional peripheral as the image forming apparatus;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating a registration process of the voice execution function by the digital multi-functional peripheral as the image forming apparatus; and</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating an execution process of a job corresponding to a voice instruction by the digital multi-functional peripheral as the image forming apparatus.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0012" num="0011">Embodiments provide an image forming apparatus that can smoothly process jobs instructed by users by voice.</p><p id="p-0013" num="0012">In general, according to one embodiment, an image forming apparatus includes a voice input interface and a processor. The voice input interface is configured to acquire an input voice input through a microphone. The processor is configured to recognize a content of a job instructed by voice from the input voice acquired by the voice input interface and to identify a speaker from the input voice and, if voices output from a plurality of speakers in the same period are acquired, configured to set an execution order of a plurality of jobs that are recognized from the voices output from the speakers and to execute the jobs in the set execution order.</p><p id="p-0014" num="0013">Hereinafter, an embodiment will be described with reference to the drawings.</p><p id="p-0015" num="0014">First, a configuration of a digital multi-functional peripheral (MFP) <b>1</b> as an image forming apparatus according to the embodiment will be described.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a configuration example of the digital multi-functional peripheral <b>1</b> as the image forming apparatus according to the embodiment.</p><p id="p-0017" num="0016">As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the digital multi-functional peripheral <b>1</b> includes a scanner <b>2</b>, a printer <b>3</b>, and an operation panel <b>4</b>. Further, the digital multi-functional peripheral <b>1</b> includes a microphone <b>6</b> that inputs a voice and a speaker unit <b>7</b> that outputs a voice.</p><p id="p-0018" num="0017">The scanner <b>2</b> is provided in a main body upper portion of the digital multi-functional peripheral. The scanner <b>2</b> is a device that optically reads an image of a document. The scanner <b>2</b> includes a control unit <b>20</b> and an image reading unit <b>21</b>. The image reading unit <b>21</b> reads an image of a document set on a document table glass. In addition, the image reading unit <b>21</b> reads an image of a document that is conveyed by an automatic document feeder (ADF).</p><p id="p-0019" num="0018">The control unit <b>20</b> of the scanner <b>2</b> controls the scanner <b>2</b>. The control unit <b>20</b> is configured with a processor, a memory, and the like. The control unit <b>20</b> executes various processes by the processor executing programs stored in the memory. For example, the control unit <b>20</b> causes the image reading unit <b>21</b> to execute a scanning process in response to an operation instruction from a system control unit <b>5</b>.</p><p id="p-0020" num="0019">The printer <b>3</b> forms an image on a medium such as paper. The printer <b>3</b> includes a control unit <b>30</b> and an image forming unit <b>31</b>. The image forming unit <b>31</b> forms an image on paper picked up from a paper feed cassette. The image forming unit <b>31</b> may form an image using any image forming method. For example, in an electrophotographic method, the image forming unit <b>31</b> forms a developer image on an image carrier such as a photoconductive drum and transfers the developer image on the image carrier to the medium. In addition, in an ink jet method, the image forming unit <b>31</b> forms an image on paper with ink ejected from an ink jet head.</p><p id="p-0021" num="0020">The control unit <b>30</b> of the printer <b>3</b> controls the printer <b>3</b>. The control unit <b>30</b> is configured with a processor, a memory, and the like. The control unit <b>30</b> executes various processes by the processor executing programs stored in the memory. For example, the control unit <b>30</b> causes the image forming unit <b>31</b> to execute an image forming process (printing process) in response to an operation instruction from the system control unit <b>5</b>.</p><p id="p-0022" num="0021">The operation panel <b>4</b> is a user interface. The operation panel <b>4</b> includes a control unit <b>40</b>, a display unit (display) <b>41</b>, a touch panel <b>42</b>, and an operation button <b>43</b>. The display unit <b>41</b> displays an operation guide or the like. The touch panel <b>42</b> is provided on a display screen of the display unit <b>41</b>. The touch panel <b>42</b> detects a portion touched by a user on the display screen of the display unit <b>41</b>.</p><p id="p-0023" num="0022">The control unit <b>40</b> of the operation panel <b>4</b> controls the operation panel <b>4</b>. The control unit <b>40</b> is configured with a processor, a memory, and the like. The control unit <b>40</b> executes various processes by the processor executing programs stored in the memory. For example, the control unit <b>40</b> controls the display of the display unit <b>41</b> in response to an instruction from the system control unit <b>5</b>.</p><p id="p-0024" num="0023">The system control unit <b>5</b> controls the entire MFP <b>1</b>. The system control unit <b>5</b> includes a processor <b>50</b>, a ROM <b>51</b>, a RAM <b>52</b>, a storage device <b>53</b>, a communication interface (I/F) <b>54</b>, an interface <b>55</b>, and an interface <b>56</b>.</p><p id="p-0025" num="0024">The processor <b>50</b> executes various processing functions by executing programs. The processor <b>50</b> is, for example, a CPU. The processor <b>50</b> is connected to the control unit <b>20</b> of the scanner <b>2</b>, the control unit <b>30</b> of the printer <b>3</b>, and the control unit <b>40</b> of the operation panel <b>4</b> via the interface.</p><p id="p-0026" num="0025">The RAM <b>52</b> functions as a working memory or a buffer memory. The ROM <b>51</b> is a non-rewritable nonvolatile memory. The ROM <b>51</b> functions as a program memory that stores a program. The processor <b>50</b> executes various processing functions by executing the programs stored in the ROM <b>51</b> or the storage device <b>53</b> using the RAM <b>52</b>.</p><p id="p-0027" num="0026">The storage device <b>53</b> is a rewritable nonvolatile memory. For example, the storage device <b>53</b> is configured with a hard disk drive (HDD) or a solid-state drive (SSD). The storage device <b>53</b> stores data such as control data, a control program, or setting information.</p><p id="p-0028" num="0027">The storage device <b>53</b> includes storage areas <b>531</b>, <b>532</b>, and <b>533</b>. The storage area <b>531</b> stores various programs. For example, the storage area <b>531</b> stores a voice recognition program for recognizing a content of a voice and a person identification (person recognition) program for specifying a speaker from a voice. The processor <b>50</b> recognizes a voice input through the microphone <b>6</b> or the like by executing the voice recognition program. In addition, the processor <b>50</b> executes personal (authentication) identification for specifying a person who outputs the input voice by executing the person identification program.</p><p id="p-0029" num="0028">The storage area <b>532</b> stores a user information database that stores information (user information) regarding pre-registered users (registrants). The storage area <b>533</b> stores a registration function database that stores information regarding a function that is executed by voice recognition set by a registrant. The user information stored in the storage area <b>532</b> and the information stored in the storage area <b>533</b> will be described below in detail.</p><p id="p-0030" num="0029">The communication interface <b>54</b> is an interface for data communication with an external apparatus. For example, the communication interface <b>54</b> communicates with a user terminal such as a PC or a mobile terminal via a network. The communication interface <b>54</b> may input voice information from a user terminal such as a PC, the voice information instructing to execute a job such as image printing (print job).</p><p id="p-0031" num="0030">The interface <b>55</b> connects the microphone <b>6</b> that inputs a voice. The interface <b>55</b> is an example of the voice input interface. The interface <b>55</b> is an interface for acquiring the voice (input voice) input through the microphone <b>6</b>. The processor <b>50</b> acquires the voice input to the microphone <b>6</b> via the interface <b>55</b>. If the microphone is a microphone <b>106</b> connected to a user terminal <b>101</b>, the communication interface <b>54</b> functions as a voice input interface.</p><p id="p-0032" num="0031">The interface <b>56</b> connects the speaker unit <b>7</b> that outputs a voice. The interface <b>56</b> is an example of the voice output interface. The interface <b>56</b> is an interface for outputting a voice signal of the voice output from the speaker unit <b>7</b>. The processor <b>50</b> outputs the voice signal of the voice output from the speaker unit <b>7</b> via the interface <b>56</b>. If the speaker unit is a speaker unit <b>107</b> connected to the user terminal <b>101</b>, the communication interface <b>54</b> functions as the voice output interface.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram schematically illustrating a configuration example of a processing system where the user terminal <b>101</b> is connected to the digital multi-functional peripheral <b>1</b>.</p><p id="p-0034" num="0033">In the network system illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a plurality of user terminals <b>101</b> are connected to the digital multi-functional peripheral <b>1</b>. Each of the user terminals <b>101</b> may be a personal computer (PC) or may be a mobile terminal such as a smartphone or a tablet PC. The user terminal <b>101</b> includes the microphone <b>106</b> and the speaker unit <b>107</b>. The microphone <b>106</b> and the speaker unit <b>107</b> may be included in the user terminal <b>101</b> or may be connected to the user terminal <b>101</b> via the interface.</p><p id="p-0035" num="0034">The digital multi-functional peripheral <b>1</b> receives an execution instruction of a job from each of the user terminals <b>101</b>. For example, the digital multi-functional peripheral <b>1</b> acquires an execution instruction of a job from a voice input to the microphone <b>106</b> of the user terminal <b>101</b>. In addition, the digital multi-functional peripheral <b>1</b> may output an execution content of a job by voice from the speaker unit <b>107</b> depending on a recognition result of the voice input to the microphone <b>106</b> of the user terminal <b>101</b>.</p><p id="p-0036" num="0035">Next, the operation of the voice recognition of the digital multi-functional peripheral <b>1</b> as the image forming apparatus according to the embodiment will be described.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating a configuration example of the user information database (DB) stored in the storage area <b>532</b> by the digital multi-functional peripheral <b>1</b>.</p><p id="p-0038" num="0037">The user information stored in the user information database of the storage area <b>532</b> is information regarding a registrant who gives an execution instruction of an operation (job) to the digital multi-functional peripheral by voice. The digital multi-functional peripheral <b>1</b> permits the execution of the job by the voice instruction for the user whose user information is registered in the user information database. In addition, the digital multi-functional peripheral <b>1</b> has a function of restricting a process to be permitted for a user based on the information stored in the user information DB.</p><p id="p-0039" num="0038">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the user information database stores information such as a user ID, a user name, voice data, an execution authority, an upper limit of a used amount, a function ID, a function name, or priority as the user information per user.</p><p id="p-0040" num="0039">The user ID is identification information for identifying the user. The user name is the name of the user. The voice data is voice data for person identification for identifying the user from the input voice. The voice data may be characteristic data of the voice extracted from the voice. The execution authority is information representing a function that is permitted to be executed by the digital multi-functional peripheral <b>1</b> for the user. The upper limit of the used amount is information representing a used amount or a use condition that is permitted for the user.</p><p id="p-0041" num="0040">The function ID and the function name are information representing a function (voice execution function) that is executed by a voice registered by the user. The function ID is identification information for identifying the voice execution function registered by the user. The function name is the name of the voice execution function registered by the user. The priority is information representing priority relating to execution of a job instructed by the user. The priority may be a serially set priority order or may be information (for example, a group name or a position) for determining the priority order.</p><p id="p-0042" num="0041">For example, a user whose user ID is &#x201c;USER1&#x201d; has a user name &#x201c;AAAA&#x201d;, and authorities for executing jobs such as copy, scan, or print. In addition, for the user &#x201c;USER1&#x201d;, the number of sheets for color printing is limited to 100 sheets, and the number of sheets for monochrome printing is not limited. Further, the user &#x201c;USER1&#x201d; registers a function having a function name &#x201c;Economy Copy&#x201d; and a function ID &#x201c;FUNC1&#x201d; as a function (registered function) that is registered to be executable by the voice instruction. In addition, since the priority of the user &#x201c;USER1&#x201d; is &#x201c;1&#x201d;, the job is preferentially executed prior to jobs of the other users.</p><p id="p-0043" num="0042">In addition, in the example illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a user whose user ID is &#x201c;USER2&#x201d; has a user name &#x201c;RBBB&#x201d; and execution authorities for copy and print. In addition, for the user &#x201c;USER2&#x201d;, the number of sheets for color printing is limited to 50 sheets, and the number of sheets for monochrome printing is limited to 50 sheets. Further, the user &#x201c;USER2&#x201d; registers a function having a function name &#x201c;Copy for Conference Material&#x201d; and a function ID &#x201c;FUNC2&#x201d; as a function (registered function) that is registered to be executable by the voice instruction. In addition, since the priority of the user &#x201c;USER2&#x201d; is &#x201c;2&#x201d;, the execution order of the job is set to be the next to the job of the user having the priority &#x201c;1&#x201d;.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating a configuration example of the function database (DB) stored in the storage area <b>533</b> by the digital multi-functional peripheral <b>1</b>.</p><p id="p-0045" num="0044">The function database stored in the storage area <b>533</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> stores information regarding a function (voice execution function) that is executable in the digital multi-functional peripheral <b>1</b> by a voice instruction from a user. The digital multi-functional peripheral <b>1</b> specifies the voice execution function to be executed based on the information registered in the function database in response to the voice instruction from the user specified by speaker identification based on voice.</p><p id="p-0046" num="0045">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the function database stores information such as a function ID, a function name, and a set value. The function ID is identification information for identifying the voice execution function. The function name is the name of the voice execution function registered by the user. The set value is setting information representing the content of the voice execution function.</p><p id="p-0047" num="0046">In the example illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the voice execution function having a function ID &#x201c;FUNC1&#x201d; has a function name &#x201c;Economy Copy&#x201d; and is a job of copying the execution content represented by the set value.</p><p id="p-0048" num="0047">Specifically, in the set value of the function having the function ID &#x201c;FUNC1&#x201d;, the color mode is monochrome, the density is automatic, the paper is A4, the duplex printing mode is single side to double side, and the Nin1 mode is 2in1. As a result, the voice execution function having the function ID &#x201c;FUNC1&#x201d; is set as a copy job of printing an image of a document on both sides of the paper A4 in 2in1 with the automatic density setting of monochrome.</p><p id="p-0049" num="0048">In addition, the function having a function ID &#x201c;FUNC2&#x201d; has a function name &#x201c;Copy for Conference Material&#x201d; and is a job of copying the execution content represented by the set value. Specifically, in the set value of the function having the function ID &#x201c;FUNC2&#x201d;, the color mode is color, the density is automatic, the paper is A4, the duplex printing mode is single side to double side, and the Nin1 mode is &#x201c;None&#x201d;. As a result, the voice execution function having the function ID &#x201c;FUNC2&#x201d; is set as a copy job of printing an image of a document on both sides of the paper A4 with the automatic density setting of color.</p><p id="p-0050" num="0049">Next, a registration process of the voice execution function that is instructed to be executed in the digital multi-functional peripheral <b>1</b> from a user by voice will be described.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart illustrating an operation example of the registration process of the voice execution function that is executed in the digital multi-functional peripheral <b>1</b> by the voice of the user.</p><p id="p-0052" num="0051">First, the processor <b>50</b> of the digital multi-functional peripheral <b>1</b> receives the registration process of the voice execution function for the user in response to the voice instruction from the user. The user whose user information is registered instructs the digital multi-functional peripheral <b>1</b> to execute the registration process of the function that is executed by voice in the digital multi-functional peripheral <b>1</b> through the microphone <b>6</b> or the microphone <b>106</b> of the user terminal <b>101</b>. The digital multi-functional peripheral <b>1</b> acquires, as an input voice, the voice instruction to register the voice execution function output from the user. The digital multi-functional peripheral <b>1</b> recognizes the input voice, recognizes the registration instruction of the voice execution function, and registers the recognized content as the voice execution function.</p><p id="p-0053" num="0052">The processor <b>50</b> acquires the voice (input voice) including the registration instruction of the voice execution function input to the microphone <b>6</b> (or the microphone <b>106</b>) by the user (ACT <b>11</b>). If the input voice is acquired, the processor <b>50</b> executes voice recognition and person identification on the input voice.</p><p id="p-0054" num="0053">That is, the processor <b>50</b> recognizes the content of the input voice by executing the voice recognition program (ACT <b>12</b>). The processor <b>50</b> executes a process corresponding to the content of the input voice recognized by voice. Here, it is assumed that the content of the input voice acquired in ACT <b>11</b> is the registration instruction of the voice execution function.</p><p id="p-0055" num="0054">In addition, the processor <b>50</b> identifies a speaker of the input voice by executing the person identification program (ACT <b>13</b>). Here, it is assumed that the processor <b>50</b> specifies which user registered in the user information database is the speaker of the input voice. For example, the processor <b>50</b> calculates a similarity between feature data of the input voice and feature data of the voice data (voice data for person identification) of each of the users registered in the user information database. If the similarity between the feature data of the input voice and the feature data of the voice data is a predetermined value or more, the processor <b>50</b> determines that the user of the voice data is the speaker of the input voice.</p><p id="p-0056" num="0055">If the processor <b>50</b> cannot specify that the speaker of the input voice is the user whose voice data is registered in the user information database (ACT <b>14</b>, NO), the processor <b>50</b> ends the registration process of the function.</p><p id="p-0057" num="0056">If the processor <b>50</b> specifies that the speaker of the input voice is the user whose voice data is registered in the user information database (ACT <b>14</b>, YES), the processor <b>50</b> executes the registration of the voice execution function for the user (ACT <b>15</b>). For example, the processor <b>50</b> acquires an input voice including a content of a voice execution function that is output to the microphone <b>6</b> by the user. The processor <b>50</b> recognizes the content of the voice execution function output by the user by executing the voice recognition program.</p><p id="p-0058" num="0057">The processor <b>50</b> specifies the content of the voice execution function that is instructed to be registered by the user based on the recognition result of the input voice. If the content of the specified voice execution function is a function that is executable by the user, the processor <b>50</b> issues a function ID for the voice execution function. The processor <b>50</b> registers the issued function ID and a function name in the user information database as the user information of the user. In addition, the processor <b>50</b> determines a set value representing the content of the specified voice execution function, correlates the function ID and the function name with each other, and registers the set value representing the content of the voice execution function in the function database.</p><p id="p-0059" num="0058">For example, it is assumed that the registered user outputs a voice &#x201c;register the function in MFP&#x201d;, &#x201c;the function name is &#x201c;Economy Copy&#x201d;, both sides, monochrome, register in 2in1&#x201d; to the microphone <b>6</b>. As a result, the processor <b>50</b> collects the voice &#x201c;register the function in MFP&#x201d; output to the microphone <b>6</b> by the user through the microphone <b>6</b>, and inputs the voice collected through the microphone <b>6</b> as the input voice. The processor <b>50</b> recognizes the content of the input voice is &#x201c;register the function in MFP&#x201d; by executing the voice recognition program. In addition, the processor <b>50</b> specifies a user who is the speaker of the input voice by executing the person identification program.</p><p id="p-0060" num="0059">Further, the processor <b>50</b> specifies that the content of the voice execution function is &#x201c;the function name is &#x201c;Economy Copy&#x201d;, both sides, monochrome, register in 2in1&#x201d; from the input voice by the voice recognition. If the content of the specified voice execution function is a function that is executable by the user, the processor <b>50</b> issues a function ID. The processor <b>50</b> correlates the issued function ID and a function name with the user and registers the correlated information in the user information database. In addition, the processor <b>50</b> correlates the set value representing the content of the specified voice execution function with the function ID and the function name, and registers the correlated information in the function database.</p><p id="p-0061" num="0060">Next, the operation in which the digital multi-functional peripheral <b>1</b> as the image forming apparatus according to the embodiment executes a process in response to the voice instruction from the user will be described.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating an operation example in which the digital multi-functional peripheral <b>1</b> as the image forming apparatus according to the embodiment executes various functions in response to the voice instruction from the user.</p><p id="p-0063" num="0062">The processor <b>50</b> of the digital multi-functional peripheral <b>1</b> executes a process of a job instructed by each user in response to the voice instruction from the user. The user whose user information is registered outputs a job that is executed in the digital multi-functional peripheral <b>1</b> to the microphone <b>6</b> or the microphone <b>106</b> of the user terminal <b>101</b> by voice. The digital multi-functional peripheral <b>1</b> acquires, as an input voice, the voice instruction to execute the job output from the user. The digital multi-functional peripheral <b>1</b> recognizes the input voice, recognizes the content of the voice instruction, and receives the execution instruction of the job as the recognized content.</p><p id="p-0064" num="0063">The processor <b>50</b> acquires the voice (input voice) including the execution instruction of the job input to the microphone <b>6</b> (or the microphone <b>106</b>) by the user via the interface <b>55</b> (ACT <b>111</b>). For example, the user instructs the content of the job by voice. Specifically, the user instructs the content of the job by voice by outputting a voice &#x201c;both sides, monochrome, copy in 2in1&#x201d;. In addition, the user may instruct execution of a function registered as the voice execution function by voice. For example, by outputting a voice &#x201c;Economy Copy&#x201d;, the user may instruct execution of the voice execution function of which the function name is registered as &#x201c;Economy Copy&#x201d; by voice.</p><p id="p-0065" num="0064">If the input voice is acquired via the interface <b>55</b>, the processor <b>50</b> executes voice recognition and person identification on the input voice. The processor <b>50</b> recognizes the content of the input voice by executing the voice recognition program (ACT <b>112</b>). Here, it is assumed that the content of the input voice acquired in ACT <b>11</b> is the execution instruction of the job.</p><p id="p-0066" num="0065">In addition, the processor <b>50</b> identifies a user (speaker) of the input voice by executing the person identification program (ACT <b>113</b>). For example, the processor <b>50</b> identifies the speaker based on a similarity between feature data of the input voice and feature data of the voice data (voice data for person identification) of each of the users registered in the user information database.</p><p id="p-0067" num="0066">If the processor <b>50</b> cannot specify that the speaker of the input voice is the user registered in the user information database (ACT <b>114</b>, NO), the processor <b>50</b> does not receive the execution of the job. However, even for an unregistered user (user that is not recognized as a registered user), the processor <b>50</b> may receive execution of a job of a specific function. In this case, if the content of the job recognized from the input voice is a job content that is permitted for an unregistered user, the processor <b>50</b> may execute subsequent processes after ACT <b>115</b>.</p><p id="p-0068" num="0067">If the processor <b>50</b> specifies that the speaker of the input voice is the user whose voice data is registered in the user information database (ACT <b>114</b>, YES), the processor <b>50</b> checks an execution authority of the user (ACT <b>115</b>). The processor <b>50</b> determines whether or not the content of the job recognized from the input voice includes a function for which the user does not have the execution authority. For example, if the content of the job recognized from the input voice includes a function for which the user does not have the execution authority, the processor <b>50</b> determines that the user does not have the execution authority for the job. If the processor <b>50</b> determines that the user does not have the execution authority (ACT <b>115</b>, NO), the processor <b>50</b> stops execution of the job instructed by the input voice.</p><p id="p-0069" num="0068">If the processor <b>50</b> determines that the user has the execution authority for the job instructed by voice (ACT <b>115</b>, YES), the processor <b>50</b> determines whether or not the used amount of the job instructed by voice is within an upper limit set for the user (ACT <b>116</b>). The processor <b>50</b> calculates the used amount of the user if the job instructed by voice is executed. The processor <b>50</b> determines whether or not the calculated used amount is within the upper limit of the used amount set for the user. If the processor <b>50</b> determines that the used amount exceeds the upper limit after the execution of the job instructed by voice (ACT <b>116</b>, NO), the processor <b>50</b> stops the execution of the job instructed by voice.</p><p id="p-0070" num="0069">If the processor <b>50</b> determines that the used amount is within the upper limit even after the execution of the job instructed by voice (ACT <b>116</b>, YES), the processor <b>50</b> determines whether or not a plurality of jobs are instructed from a plurality of users in the same period (ACT <b>117</b>). It is assumed that, if a job is instructed by voice, another job is instructed from another user before the voice instruction is not completed.</p><p id="p-0071" num="0070">For the voice instruction of the job to the digital multi-functional peripheral <b>1</b>, a period of time is required until speech of one user ends from the start of the speech. On the other hand, the processor <b>50</b> of the digital multi-functional peripheral <b>1</b> recognizes voices output by a plurality of users in the same period on a user by user basis. As a result, even if a plurality of users instructs jobs by voice in the same period, the digital multi-functional peripheral <b>1</b> can receive the voice instructions of the jobs from the plurality of users.</p><p id="p-0072" num="0071">If a plurality of jobs input from a plurality of users by voice in the same period are received (ACT <b>117</b>), the processor <b>50</b> sets a processing order (execution order) for executing the plurality of jobs (ACT <b>118</b>). As the processing order in which the plurality of jobs instructed by the plurality of speakers in the same period are executed, the processor <b>50</b> sets an execution order of processes to be executed concurrently and an execution order of processes to be executed serially.</p><p id="p-0073" num="0072">The processor <b>50</b> specifies concurrently executable processes among the plurality of jobs. The processor <b>50</b> sets a processing order of the plurality of jobs so as to concurrently execute the concurrently executable processes. For example, the processor <b>50</b> sets the processing order so as to concurrently execute a process using the scanner <b>2</b> (scan job) and a process using the printer <b>3</b> (print job). If a first user instructs the scan job by voice instruction, the processor <b>50</b> sets the execution order to execute the print job instructed by a second user in the same period concurrently with the scan job of the first user.</p><p id="p-0074" num="0073">In addition, the processor <b>50</b> sets the execution order for the process to be executed serially among the plurality of jobs. For example, a plurality of print jobs instructed from a plurality of users cannot be executed concurrently because one printer is used. Therefore, the processor <b>50</b> sets the execution order to serially execute the plurality of print jobs instructed from the plurality of users.</p><p id="p-0075" num="0074">The processor <b>50</b> sets the execution order based on the priority set for each of the users who instructs the plurality of jobs by voice. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the priority of the user (referred to as &#x201c;user 1&#x201d;) whose user ID is &#x201c;USER1&#x201d; is &#x201c;1&#x201d;, and the priority of the user (referred to as &#x201c;user 2&#x201d;) whose user ID is &#x201c;USER2&#x201d; is &#x201c;2&#x201d;. Therefore, the user 1 and the user 2 instruct jobs to be executed serially in the same period by voice, the processor <b>50</b> sets the execution order to execute the job of the user 2 next to the job of the user 1.</p><p id="p-0076" num="0075">In addition, the processor <b>50</b> determines an execution content for each of the jobs received by the voice instruction (ACT <b>119</b>). If a job is received from one user, the processor <b>50</b> sets the execution content of the job based on the content of the voice instruction by the user, default settings, and the like.</p><p id="p-0077" num="0076">In addition, if a plurality of jobs are received from a plurality of users, the processor <b>50</b> determines the execution content of each of the jobs such that each of the jobs can easily understand the execution results of the plurality of jobs. For example, if a plurality of print jobs are received from a plurality of users in the same period, the processor <b>50</b> sets an output method of paper for the print job of each of the users.</p><p id="p-0078" num="0077">In a specific example, if the printer <b>3</b> includes a plurality of output trays, the processor <b>50</b> sets the execution content of each of the jobs such that the results of the print jobs of the users are output to different output trays, respectively. As a result, the results of the print jobs instructed from the plurality of users in the same period can be output to the different output trays, respectively. In addition, if an output tray of the printer <b>3</b> is configured to be movable, the processor <b>50</b> sets the execution content of each of the jobs such that the output tray moves whenever the result of the print job of each of the users is output. As a result, the results of the print jobs instructed from the plurality of users in the same period can be output to different positions (or different directions) on the output tray.</p><p id="p-0079" num="0078">After determining the execution content of each of the jobs received by the voice instruction, the processor <b>50</b> outputs a voice representing the execution content from the speaker unit <b>7</b> (ACT <b>120</b>). For example, if the processor <b>50</b> determines the execution contents for the plurality of jobs instructed from the plurality of users in the same period, the processor <b>50</b> outputs a voice representing the execution order and the execution contents of the jobs from the speaker unit <b>7</b>. As a result, the users who instruct the jobs by voice can check the contents of the jobs to be executed based on the voice recognition results by voice.</p><p id="p-0080" num="0079">In addition, after determining the execution content of each of the jobs received by the voice instruction, the processor <b>50</b> executes the jobs including the set execution contents in the set execution order (ACT <b>121</b>).</p><p id="p-0081" num="0080">According to the above-described process, the digital multi-functional peripheral according to the embodiment recognizes the content of the job instructed by voice from the input voice, and identifies the user of the input voice. If voice instructions output from a plurality of users in the same period are acquired, the digital multi-functional peripheral sets the execution order for a plurality of jobs instructed from the plurality of users by voice.</p><p id="p-0082" num="0081">As a result, in the embodiment, even if a plurality of users execute voice instructions in the same period, jobs instructed by the users can be smoothly executed.</p><p id="p-0083" num="0082">In addition, the digital multi-functional peripheral according to the embodiment sets the execution order to concurrently execute concurrently executable processes among a plurality of jobs instructed from a plurality of users in the same period by voice. As a result, even if a plurality of jobs are instructed from different users, the plurality of jobs can be smoothly processed by concurrently executing concurrently executable processes.</p><p id="p-0084" num="0083">In addition, the digital multi-functional peripheral according to the embodiment sets the execution order for a plurality of jobs instructed from a plurality of users in the same period by voice based on the priority set for each of the users. As a result, the plurality of jobs instructed from the plurality of users can be executed in the preset order of priority, the plurality of jobs can be smoothly processed.</p><p id="p-0085" num="0084">In addition, the digital multi-functional peripheral according to the embodiment is set to output, using different output methods, results of a plurality of jobs instructed from a plurality of users in the same period by voice. As a result, the plurality of jobs instructed from the plurality of users in the same period by voice can be easily distinguished from each other per user.</p><p id="p-0086" num="0085">In addition, the digital multi-functional peripheral according to the embodiment may set the upper limit of the number of executable times for a plurality of jobs recognized by voices output from a plurality of speakers in the same period. If the number of execution times of a plurality of jobs recognized from voices output from a plurality of speakers in the same period exceeds the upper limit, the processor <b>50</b> may disable execution of jobs corresponding to a difference from a predetermined number of times.</p><p id="p-0087" num="0086">In this case, the processor <b>50</b> outputs the disabled jobs from the speaker unit <b>7</b> via the interface <b>56</b> by voice. In addition, the processor <b>50</b> may cause the display unit or the like of the operation panel <b>4</b> to display information representing the disabled jobs. In addition, the processor <b>50</b> may record information representing the disabled jobs in a storage device or the like as log information.</p><p id="p-0088" num="0087">As a result, the users can recognize the jobs that are disabled because the number of execution times exceeds the upper limit.</p><p id="p-0089" num="0088">While certain embodiments have been described, these embodiments have been presented by way of example only, and are not intended to limit the scope of the inventions. Indeed, the novel embodiments described herein may be embodied in a variety of other forms; furthermore, various omissions, substitutions and changes in the form of the embodiments described herein may be made without departing from the spirit of the inventions. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of the inventions.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image forming apparatus, comprising:<claim-text>a voice input interface configured to acquire an input voice input through a microphone;</claim-text><claim-text>a processor configured to<claim-text>recognize a content of a job instructed by voice from the input voice acquired by the voice input interface,</claim-text></claim-text><claim-text>identify a speaker from the input voice,<claim-text>if voices output from a plurality of speakers in the same period are acquired, set an execution order of a plurality of jobs that are recognized from the voices output from the plurality of speakers, and</claim-text><claim-text>execute the jobs in the set execution order.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image forming apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the processor sets an execution order so as to concurrently execute concurrently executable processes among the jobs.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image forming apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the processor sets an execution order of the jobs based on a priority set for each of the plurality of speakers.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image forming apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein if the jobs include a plurality of print jobs, the processor sets different paper discharge methods for the print jobs.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image forming apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a voice output interface configured to output a voice signal output from a speaker,<claim-text>wherein the processor causes the speaker to output a voice via the voice output interface, the voice representing execution contents for the plurality of jobs that are recognized from voices output from the plurality of speakers in the same period.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image forming apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a user information database comprising registered user information.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image forming apparatus according to <claim-ref idref="CLM-00006">claim 6</claim-ref>,<claim-text>wherein the registered user information comprises at least one of a user ID, a user name, voice data, an execution authority, an upper limit of a used amount, a function ID, a function name, and a priority per user.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A method for an image forming apparatus, comprising:<claim-text>acquiring an input voice input through a microphone of a voice input interface;</claim-text><claim-text>recognizing a content of a job instructed by voice from the input voice acquired;</claim-text><claim-text>identifying a speaker from the input voice;</claim-text><claim-text>if voices output from a plurality of speakers in the same period are acquired, setting an execution order of a plurality of jobs that are recognized from the voices output from the plurality of speakers; and</claim-text><claim-text>executing the jobs in the set execution order.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:<claim-text>setting an execution order so as to concurrently execute concurrently executable processes among the jobs.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:<claim-text>setting an execution order of the jobs based on a priority set for each of the plurality of speakers.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:<claim-text>if the jobs include a plurality of print jobs, setting different paper discharge methods for the print jobs.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:<claim-text>outputting a voice signal output from a speaker of a voice output interface,</claim-text><claim-text>causing the speaker to output a voice via the voice output interface, the voice representing execution contents for the plurality of jobs that are recognized from voices output from the plurality of speakers in the same period.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:<claim-text>identifying the speaker from the input voice by correlating the input voice to a user information database comprising registered user information comprising at least one of a user ID, a user name, voice data, an execution authority, an upper limit of a used amount, a function ID, a function name, and a priority per user.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. An image forming system, comprising:<claim-text>an user terminal comprising:<claim-text>a voice input interface configured to acquire an input voice input through a microphone;</claim-text><claim-text>a processor configured to<claim-text>recognize a content of a job instructed by voice from the input voice acquired by the voice input interface,</claim-text><claim-text>identify a speaker from the input voice,</claim-text><claim-text>if voices output from a plurality of speakers in the same period are acquired, set an execution order of a plurality of jobs that are recognized from the voices output from the plurality of speakers, and</claim-text><claim-text>execute the jobs in the set execution order; and</claim-text></claim-text></claim-text><claim-text>an image forming apparatus comprising:<claim-text>a scanner,</claim-text><claim-text>a printer, and</claim-text><claim-text>a controller for executing scanning, executing printing, and communicating with the user terminal.</claim-text></claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The image forming system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>,<claim-text>wherein the processor sets an execution order so as to concurrently execute concurrently executable processes among the jobs.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The image forming system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>,<claim-text>wherein the processor sets an execution order of the jobs based on a priority set for each of the plurality of speakers.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The image forming system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>,<claim-text>wherein if the jobs include a plurality of print jobs, the processor sets different paper discharge methods for the print jobs.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The image forming system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising a voice output interface configured to output a voice signal output from a speaker,<claim-text>wherein the processor causes the speaker to output a voice via the voice output interface, the voice representing execution contents for the plurality of jobs that are recognized from voices output from the plurality of speakers in the same period.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The image forming system according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the image forming apparatus further comprises a user information database comprising registered user information.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The image forming system according to <claim-ref idref="CLM-00019">claim 19</claim-ref>,<claim-text>wherein the registered user information comprises at least one of a user ID, a user name, voice data, an execution authority, an upper limit of a used amount, a function ID, a function name, and a priority per user.</claim-text></claim-text></claim></claims></us-patent-application>
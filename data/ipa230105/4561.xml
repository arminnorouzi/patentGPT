<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004562A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004562</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17941626</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>2452</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>242</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>2457</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>25</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>248</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0482</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>279</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>24522</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>243</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>24578</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>252</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>063</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>248</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0482</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>279</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS FOR AUTOMATED ANALYSIS OF BUSINESS INTELLIGENCE</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16437311</doc-number><date>20190611</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11468054</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17941626</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>JPMorgan Chase Bank, N.A.</orgname><address><city>New York</city><state>NY</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>CHAUDHURI</last-name><first-name>Sutanu</first-name><address><city>Glen Mills</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>BOLLA</last-name><first-name>Mallikharjun R.</first-name><address><city>Downingtown</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>RAO</last-name><first-name>Boda Sarath</first-name><address><city>Chadds Ford</city><state>PA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>BAYOU</last-name><first-name>Getnet</first-name><address><city>Washington</city><state>DC</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>DANDAMUDI</last-name><first-name>Thirumala Raja</first-name><address><city>Wilmington</city><state>DE</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>ABBOTT</last-name><first-name>Josh</first-name><address><city>Galena</city><state>OH</state><country>US</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>COLLURAY</last-name><first-name>Sheela</first-name><address><city>Exton</city><state>PA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>JPMorgan Chase Bank, N.A.</orgname><role>02</role><address><city>New York</city><state>NY</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method, system, and medium for automated analysis of business intelligence each: receive natural language input from a user; evaluate, via a natural language understanding processor that includes a parser and an interpreter, the natural language input to determine an intent of the user; determine the intent of the user and generate a query based on a context manager; send an identification of the failure to a failure analysis system for human intervened analysis and refinement of a natural language model used by the natural language understand processor; assess, via a context manager processor, to determine a user interest in one or more portions of results of the query, a scrolling of the user through the results of the query; and refine, based on the user interest in the one or more portions of the results of the query, an output of the results of the query.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="166.12mm" wi="92.63mm" file="US20230004562A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="233.34mm" wi="178.56mm" orientation="landscape" file="US20230004562A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="217.25mm" wi="94.66mm" file="US20230004562A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="221.91mm" wi="136.65mm" orientation="landscape" file="US20230004562A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The application is a continuation of U.S. patent application Ser. No. 16/437,311, filed Jun. 11, 2019. The disclosure of the above-identified document, including the specification, drawings, and claims, is incorporated herein by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE INVENTION</heading><p id="p-0003" num="0002">The present invention generally relates to systems and methods for automated analysis of business intelligence.</p><heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0004" num="0003">Often, end users of business intelligence/reporting tools, or similar web interfaces, need to wait a considerable amount of time, ranging from hours to days, to get an ad-hoc report that may not be available through a user interface. For reports that are available, user friendly features are limited and often require extensive Human Computer Interaction, which means a user is often required to click on several tabs/buttons, or navigate through different link and sources like Help Desk or Subject Matter Expert to retrieve the required information or customized reports. For example, when a user is looking for specific information, such as &#x201c;How many transactions of less than $20 did I make in the last 6 months?&#x201d; or &#x201c;How many user stories are completed in my project?&#x201d;, the user approaches the help desk who in turn approaches production support team, or development team that will frame the relevant query and execute the query against one or more databases.</p><p id="p-0005" num="0004">This flow has security risks with the script executioner able to see the data, which may be sensitive. In addition, there is no learning involved in the current process with the knowledge confined to the developer or production support personnel which may lead to potential single point of failure. Further, the solution gathered is not real time data due to the time and effort involved. Additionally, the queries are often repetitive and not dynamic and have little, if any, possibility for reuse.</p><heading id="h-0004" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0006" num="0005">According to one embodiment, the invention relates to a system for automated analysis of business intelligence. The system comprises: a query interface configured to receive a natural language user input a natural language understanding processor comprising a parser and interpreter to determine a user intent and generate an intermediate query and further based on a context manager; a query processor configured to translate the intermediate query to a database query and execute the database query against a database; and a presentation interface configured to generate a result output that comprises results of the database query in natural language.</p><p id="p-0007" num="0006">According to another embodiment, the invention relates to a method for automated analysis of business intelligence. The method comprises the steps of: receiving, via a query interface, a natural language user input; determining, via a natural language understanding processor comprising a parser and interpreter, a user intent; generating an intermediate query and further based on a context data from a context manager; translating, via a query processor, the intermediate query to a database query and executing the database query against a database; and generating, via a presentation interface, a result output that comprises results of the database query in natural language.</p><p id="p-0008" num="0007">The system may include a specially programmed computer system comprising one or more computer processors, interactive interfaces, electronic storage devices, and networks.</p><p id="p-0009" num="0008">The computer implemented system, method and medium described herein provide unique advantages to entities, organizations and other users, according to various embodiments of the invention. An embodiment of the present invention provides real-time analytics based on Artificial Intelligence (AI) and an interactive Chatbot feature. The innovative framework is directed to minimizing Human-Computer Interaction (HCI) to prevent and/or minimize user dissatisfaction by improving relevancy of reports and minimizes effort and time involved to generate the reports by utilizing Analytics tool. Further, the inventive tool reduces cognitive load associated with complex HCI. Additionally, significant benefits such as, tightened data security, elimination of single point of failure, access to relevant and real time analytics, customizable report formats (e.g., PPT, XLS, Word, etc.), formatting features, ability to bookmark frequently used reports may be available in comparatively lesser time and effort than a traditional business intelligence (BI) tool.</p><p id="p-0010" num="0009">These and other advantages will be described more fully in the following detailed description.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0011" num="0010">In order to facilitate a fuller understanding of the present invention, reference is now made to the attached drawings. The drawings should not be construed as limiting the present invention, but are intended only to illustrate different aspects and embodiments of the invention.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a system for automated analysis of business intelligence, according to an embodiment of the present invention.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a method for automated analysis of business intelligence, according to an embodiment of the present invention.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is an exemplary user interface, according to an embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading><p id="p-0015" num="0014">The following description is intended to convey an understanding of the present invention by providing specific embodiments and details. It is understood, however, that the present invention is not limited to these specific embodiments and details, which are exemplary only. It is further understood that one possessing ordinary skill in the art, in light of known systems and methods, would appreciate the use of the invention for its intended purposes and benefits in any number of alternative embodiments, depending upon specific design and other needs.</p><p id="p-0016" num="0015">An embodiment of the present invention is directed to a user friendly dynamic tool for business intelligence automated analytics that enable end users, e.g., employees, etc. to maximize efficiency and flexibility while interacting with data systems across applications. An embodiment of the present invention provides real-time analytics based on Artificial Intelligence (AI) and an interactive Chatbot interface. The innovative framework may be applicable across various lines of business and scenarios.</p><p id="p-0017" num="0016">The framework capabilities, including ML and AI, lead to a continuous learning process where the tool may be self-trained based on user search pattern and queries. Accordingly, the tool may accurately determine a user's intent with partial queries and further provide the user with choices for any further relevant information.</p><p id="p-0018" num="0017">Embodiments may incorporate a conversational AI program (e.g., Chatbot) using Natural Language Interface to Database (&#x201c;NLIDB&#x201d;) to return real-time information to end users. Embodiments may promote customer-focused instant analytics, accurately determine an end user's needs from a business intelligence perspective, reduce operational costs, effectively use machine learning, and provide different options to export the one or more results.</p><p id="p-0019" num="0018">Embodiments may solve context-specific questions based on a prior question, historical information and/or analysis and may be intuitive to respond to partial queries from an end user. Using machine learning, embodiments may determine a specific intent or need of the user question and provide an optimal and proactive response. In addition, an embodiment of the present invention may respond to partial queries that may be based on prior questions and/or prior interactions.</p><p id="p-0020" num="0019">Embodiments may translate a natural language query provided through an interface (e.g., a Chatbot interface, user input, etc.) to a database query (e.g., Structured Query Language (SQL), other database query language, etc.) that is able to understand various statistical operations, including but not limited to &#x201c;where, when, what, who&#x201d; type of questions referenced in the natural language query, while translating the input to an intermediate query. The intermediate query may then be converted to a specific database query to be executed against the database. The result set from the executed query may be translated back to an intermediate language and then to a natural language response or a graphical representation depending on the context. Other outputs and/or formats may be supported.</p><p id="p-0021" num="0020">Embodiments may use an initial or one-time training imparted through machine learning algorithms to teach the concepts and the intents. The concepts and/or intents may be specific to a database language. This may include various queries that may be supported and/or other specifics. For example, the training may be specific to the database query language. Accordingly, different database query languages may have different training algorithms that may be applied. Alternative interpretations may be provided in the query interface to assist the user in choosing a more meaningful question. Embodiments assume that the user's query is dynamic by nature, and may start with an exploratory query. A context manager may sequentially track recent queries by the user, or by a user with a similar intent, and may use probabilistic methodologies to identify the intent behind the query.</p><p id="p-0022" num="0021">Embodiments are scalable and may be introduced in any reporting tool with plugins to connect to respective databases. The reporting tool where the plugin is targeted may be configured to provide the corpus in a predefined format. For example, metadata related to a table may declare whether a particular column type is PERSON, LOCATION, CURRENCY, TIME, or other domain specific entities, assuming an exhaustive list of such data definitions is exposed.</p><p id="p-0023" num="0022">According to an embodiment of the present invention, an intermediate query tree may be tagged to a security context in order to assess whether a query intent has the necessary entitlements, access and/or rights granted to the logged in user profile.</p><p id="p-0024" num="0023">According to an embodiment of the present invention, an interface may be provided to certain users to teach new concepts or intents based on the learned concepts.</p><p id="p-0025" num="0024">Embodiments may subscribe to specific queries, with the interface (e.g., the Chatbot) providing specific information at the time of access, and/or tagging an interesting insight against another profile or public profile for further consumption.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a system for automated analysis of business intelligence, according to an embodiment of the present invention. System <b>100</b> may include query interface <b>110</b> that receives a query from a user; natural language (NL) understanding component <b>120</b>, query processor <b>130</b>, presentation component <b>140</b>, context manager <b>142</b>, and machine language (ML) driven domain dependent knowledge <b>150</b>.</p><p id="p-0027" num="0026">In one embodiment, query interface <b>110</b> may be hosted or executed on an electronic device, e.g., desktop computer, workstation, tablet computers, smart phones, smart watches, Internet of Things (IoT) appliances, web-accessible devices, etc.</p><p id="p-0028" num="0027">Natural language understanding component <b>120</b> may include NL parser <b>122</b>, which may receive the query from query interface <b>110</b> and parse the query into a NL parser tree or other structure, which may include parts-of-speech tag sets that may be further mapped to statistical query variables and/or corpus synonyms. NL parser <b>122</b> may communicate with NL interpreter <b>124</b>, which may interpret the parsed query, and to failure analysis system <b>126</b> that receives the NL interpretation and identifies any failures in the parsing and/or interpretation for further human intervened analysis and refinement of the model.</p><p id="p-0029" num="0028">Query processor <b>130</b> may receive the interpretation from NL interpreter <b>124</b>, and then translate the interpretation into an intermediate language. Search query formulator <b>134</b> may generate a search from the intermediate language, and may provide the formulated query to search engine <b>136</b>. Natural language parser <b>122</b> may be responsible for tokenizing the sentence, lemmatization, removing stop words relevant to the domain while retaining statistical keywords and corpus related entities create parts-of-speech tagger tree, and propagating the parsed object to NL interpreter <b>124</b>. NL interpreter <b>124</b> may be context agonistic and may not have the historic knowledge of the conversation flow.</p><p id="p-0030" num="0029">In one embodiment, NL Interpreter <b>124</b> may use trained Hidden Markov Models (&#x201c;HMM&#x201d;) while including serialized context from Context Mapper <b>142</b> and consulting Concept Mapper (<b>154</b>) to predict the right intent. In one embodiment, NL interpreter <b>124</b> may have multiple ranked intents with the top ranked intent being propagated to intermediate language translator <b>132</b>. Other models may be implemented.</p><p id="p-0031" num="0030">ML driven domain dependent knowledge <b>150</b> may include domain concepts ontology <b>152</b>, concept mapper <b>154</b>, acronym dictionary <b>156</b>, ML entities/word vectors/training <b>158</b>, and application database (DB) <b>160</b>.</p><p id="p-0032" num="0031">Domain Concepts Ontology <b>152</b> may represent a repository of labelled entities' relevant statistical definitions, such as minimum, maximum, average, percentage, and domain specific entities, and may map database table and column definitions to a pre-defined category. For example, the repository may include metadata related to each of the tables, elaborating on how data column and data table should be mapped to different entities for the domain.</p><p id="p-0033" num="0032">As a non-limiting illustration, Column A in Table X may be mapped to PERSON, while Column B may be mapped to a LOCATION. Acronym dictionary <b>156</b> may keep track of the synonyms related to entities for the domain where the system is hosted.</p><p id="p-0034" num="0033">The architecture may be generic and may cater to different business domains varying from mortgage to workforce management.</p><p id="p-0035" num="0034">Search engine <b>136</b> may interface with application DB <b>160</b>. For example, application DB <b>160</b> may store and manage data relevant to the business domain where the system would be hosted, serialized context, historic conversational data and any feedback received by the user explicitly or implicit.</p><p id="p-0036" num="0035">Presentation component <b>140</b> may include translators responsible for converting the result set after executing the NLIDB query into a sentence with grammatically correct semantics. Presentation component <b>140</b> may represent an interactive user interface. For example, Presentation component <b>140</b> may render a graph, chart, textual response and/or other output back to the channel from where the query was generated.</p><p id="p-0037" num="0036">Context manager <b>142</b> may be responsible for tracking a history of a conversation through, for example, chatbot memory spanned across multiple slots. For example, values stored in context manager <b>142</b> may be passed to NL interpreter <b>124</b>. Similarly, while sending the result set back to presentation component <b>140</b>, context manager <b>142</b> may keep track of an estimated accuracy for and confidence in what is being sent in the response. Feedback from query interface <b>110</b> may pass through context manager <b>142</b>, which may then modify the ranking of possible responses.</p><p id="p-0038" num="0037">In addition, Context manager <b>142</b> may tract user actions and interactions from query interface <b>110</b>, which may include background requests. Context manager <b>142</b> may determine user preferences (e.g., user likes or dislikes) including navigational history of the responses, etc. For example, a user swiftly scrolling through some response graphs may indicate the user is ignoring the response while a longer time may indicate the user is interested in the details. In this example, feedback may be redirected through context manager <b>142</b>. In response to the user's interaction (e.g., type of scrolling, etc.), presentation component <b>140</b> may generate a corresponding output, such as dynamic charts based on the ranked responses instead of providing all possible responses at one time.</p><p id="p-0039" num="0038">While a single component is shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, each component may represent a plurality of components. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a representation example of an architecture. Other variations may be implemented. The system of <figref idref="DRAWINGS">FIG. <b>1</b></figref> may be implemented in a variety of ways. Architecture within system may be implemented as hardware components (e.g., module) within one or more network elements. It should also be appreciated that architecture within system may be implemented in computer executable software (e.g., on a tangible, non-transitory computer-readable medium) located within one or more network elements. Module functionality of architecture within system may be located on a single device or distributed across a plurality of devices including one or more centralized servers and one or more mobile units or end user devices. The architecture depicted in system is meant to be exemplary and non-limiting. For example, while connections and relationships between the elements of system are depicted, it should be appreciated that other connections and relationships are possible. The system described below may be used to implement the various methods herein, by way of example. Various elements of the system may be referenced in explaining the exemplary methods described herein.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a method for automated analysis of business intelligence, according to an embodiment of the present invention. At step <b>205</b>, a user query in natural language may be received. At step <b>210</b>, an embodiment of the present invention may determine user intent using NL parsers and context information. At step <b>215</b>, the user intent may be used to determine an intermediate query through graphs and/or pre-trained ML models. At step <b>220</b>, graph nodes and relationships may be parsed into a database query. At step <b>225</b>, the database query may be executed against a database. At step <b>230</b>, results output may be generated and displayed to the user. At step <b>235</b>, user actions may be tracked for improved accuracy through machine learning. The order illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is merely exemplary. While the process of <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates certain steps performed in a particular order, it should be understood that the embodiments of the present invention may be practiced by adding one or more steps to the processes, omitting steps within the processes and/or altering the order in which one or more steps are performed.</p><p id="p-0041" num="0040">An embodiment of the present invention is directed to supporting querying various data sources through a natural language input.</p><p id="p-0042" num="0041">At step <b>205</b>, a user may enter a query in natural language into a query interface (e.g., an application, program, browser, etc.) executed on an electronic device. Examples may include: &#x201c;How many transactions did I make less than $20 in last 6 months?&#x201d;; &#x201c;How many MDs are located in Brooklyn?&#x201d;; &#x201c;How many user stories are completed in my project ABC?&#x201d;; &#x201c;What is the cash to credit spend ration on travel expenses?&#x201d; The user input may be in text format, voice format and/or other type of communication. The input may be received and/or inferred from a separate interaction or application. For example, an input sentence or phrase may be tokenized to identify various tokens. A context manager may identify and/or enrich the input with additional context.</p><p id="p-0043" num="0042">At step <b>210</b>, the system may determine the user's intent of the query. For example, the system may extract the intent of the query using NL parsers. A machine learning model may include a number of intents with training examples attached thereto. As a part of a conversation with the chatbot, the user may be engaged in a dialog flow. Each time a new question is asked, the Chatbot may determine intent based on a probabilistic model, whether the new query is related to one of the previous queries that have been saved in chatbot's memory based on a similarity ratio.</p><p id="p-0044" num="0043">For example, a parser library may be used to perform parsing. Grammatical relations may be extracted using a pre-trained machine learning model. For example, nouns and prepositions may be extracted from a Parts of Speech Tagger and Typed Dependencies. An embodiment of the present invention may apply semantic analysis with nouns and prepositions. A graph tree may be constructed with the nouns as nodes with prepositions and typed dependencies as edges of graph.</p><p id="p-0045" num="0044">The system may perform various permutations and combinations by substituting features in a parsed tree with features that are stored in its memory slots. A substituted feature that gives a better representation of intent may be selected as a &#x201c;winner&#x201d; and then forwarded to the next component in a pipeline. A substituted feature that leads to a lower probabilistic model may be kept in a memory graph and assigned a lower rank. The feature may also be discarded when the probability assigned reaches a lower threshold, for example.</p><p id="p-0046" num="0045">At step <b>215</b>, the intent may be translated into an intermediate query using graphs and/or pre-trained ML models. For example, the training model may include at least some of the following components: intents, which may be further categorized as &#x201c;what-when-where, who, which&#x201d; questions; statistical determiners (e.g., maximum, minimum, average, median, mode, count, percentage, ratio, etc.), a series of examples to distinguish intents, synonyms, etc. The training model may be trained to understand the depth and/or level of the natural language query based on different training examples.</p><p id="p-0047" num="0046">At step <b>220</b>, the graph nodes and relationships may be parsed into a database query using, for example, adapters (e.g., Oracle, SQL, etc.). For example, a rules engine may convert the intermediate query into a database query. In one embodiment, a SQL syntax may be governed by rules specific to the language (e.g., Oracle, MSSQL, etc.). An intermediate language parser may generate a database query being mapped from the adapter itself. While registering a parser with the component, details relevant to the syntax of a SQL query may be provided.</p><p id="p-0048" num="0047">For example, a graph may be converted to a SQL query using a Database Adapter. The graph may also be used generate alternative models behind or beyond the question.</p><p id="p-0049" num="0048">At step <b>225</b>, the database query may be executed against a database and/or other data sources. For a particular database, a specific set of queries and/or statements may be permitted. In an example involving SQL, only GET or SELECT queries may be permitted for an analytical query. In this example, UPDATE, DELETE, and INSERT may not be permitted. Other variations may be applied and other scenarios may be implemented.</p><p id="p-0050" num="0049">At step <b>230</b>, the results of the query may be generated. For example, the results may be converted to graph and ultimately a natural language response, e.g., text, plot, etc. The response may be provided as a textual response, as a plot, chart or graph, or in any other suitable format as is necessary and/or desired.</p><p id="p-0051" num="0050">For example, conversion of the graph to a NL Query may ensure that the user receives the data in a natural language format rather than a single word response. This may be particularly important for questions, where users may expect a binary response, but the chatbot may provide additional details, such as explaining the reasoning behind the binary response. Response templates may be mapped to question intent with the placeholders being populated by the component.</p><p id="p-0052" num="0051">At step <b>235</b>, the user actions in response to the response may be tracked and used for &#x201c;feed forward&#x201d; learning. For example, the user's actions may be applied to future queries by the user to further refine the query. During a user interaction, the chatbot may collect information relevant to the kind of transition that is occurring during the conversations with respect to nature of the question asked, how much time the user is spending reviewing and selecting a response, any feedback provided by the user, explaining which of the ranked response appear more relevant, the amount of time spent in each of the response screens, what users with similar traits are showing interest in, etc.</p><p id="p-0053" num="0052">For example, the result set may be transformed into various formats, including grid, chart and/or textual view. The Graph representation of the intermediate query in a simplified format, the actual question asked, and the response may be sent back to the user interface. The amount of time spent by the user in each grid and the feedback button clicked, e.g., Bookmark, Incorrect, Correct or More options, may then be stored for further training and reinforced learning.</p><p id="p-0054" num="0053">In a probabilistic model, a NL interpreter may rank the various scenarios based on feedbacks received on the above parameters.</p><p id="p-0055" num="0054">For example, a user may input a first question including &#x201c;How many SW Eng work from DE?&#x201d; A second question may be &#x201c;From Jersey City?&#x201d; In this example, an embodiment of the present invention may determine entities as &#x201c;worker, location and jobfamily.&#x201d;</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is an exemplary user interface, according to an embodiment of the present invention. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, SQL queries may be executed against a database. At input <b>310</b>, a user may enter a query in natural language. The input may be entered by the user via text or voice, selected from a set of options and/or other input or command. Additional specifics may be provided at <b>312</b>, <b>314</b> and <b>316</b>. These inputs may be predetermined and available via drop down windows. Other inputs may be provided. The result set may be transformed into various formats, including text <b>318</b>, grid <b>320</b> and chart <b>322</b>. The Graph representation of the intermediate query in a simplified format, the actual question asked, and the response may be sent back to the user interface. In addition, user interactions may be captured. For example, the amount of time spent by the user in each grid and the feedback button clicked, e.g., Bookmark, Incorrect, Correct or More options represented by <b>324</b>, may be stored for further training and reinforced learning.</p><p id="p-0057" num="0056">It should be recognized that although several embodiments have been disclosed, these embodiments are not exclusive and aspects of one embodiment may be applicable to other embodiments.</p><p id="p-0058" num="0057">Hereinafter, general aspects of implementation of the systems and methods of the invention will be described.</p><p id="p-0059" num="0058">The system of the invention or portions of the system of the invention may be in the form of a &#x201c;processing machine,&#x201d; such as a general purpose computer, for example. As used herein, the term &#x201c;processing machine&#x201d; is to be understood to include at least one processor that uses at least one memory. The at least one memory stores a set of instructions. The instructions may be either permanently or temporarily stored in the memory or memories of the processing machine. The processor executes the instructions that are stored in the memory or memories in order to process data. The set of instructions may include various instructions that perform a particular task or tasks, such as those tasks described above. Such a set of instructions for performing a particular task may be characterized as a program, software program, or simply software.</p><p id="p-0060" num="0059">In one embodiment, the processing machine may be a specialized processor.</p><p id="p-0061" num="0060">As noted above, the processing machine executes the instructions that are stored in the memory or memories to process data. This processing of data may be in response to commands by a user or users of the processing machine, in response to previous processing, in response to a request by another processing machine and/or any other input, from automated scheduling, for example.</p><p id="p-0062" num="0061">As noted above, the processing machine used to implement the invention may be a general purpose computer. However, the processing machine described above may also utilize any of a wide variety of other technologies including a special purpose computer, a computer system including, for example, a microcomputer, mini-computer or mainframe, a programmed microprocessor, a micro-controller, a peripheral integrated circuit element, a CS IC (Customer Specific Integrated Circuit) or ASIC (Application Specific Integrated Circuit) or other integrated circuit, a logic circuit, a digital signal processor, a programmable logic device such as a FPGA, PLD, PLA or PAL, or any other device or arrangement of devices that is capable of implementing the steps of the processes of the invention.</p><p id="p-0063" num="0062">The processing machine used to implement the invention may utilize a suitable operating system. Thus, embodiments of the invention may include a processing machine running the iOS operating system, the OS X operating system, the Android operating system, the Microsoft Windows&#x2122; operating systems, the Unix operating system, the Linux operating system, the Xenix operating system, the IBM AIX&#x2122; operating system, the Hewlett-Packard UX&#x2122; operating system, the Novell Netware&#x2122; operating system, the Sun Microsystems Solaris&#x2122; operating system, the OS/2&#x2122; operating system, the BeOS&#x2122; operating system, the Macintosh operating system, the Apache operating system, an OpenStep&#x2122; operating system or another operating system or platform.</p><p id="p-0064" num="0063">It is appreciated that in order to practice the method of the invention as described above, it is not necessary that the processors and/or the memories of the processing machine be physically located in the same geographical place. That is, each of the processors and the memories used by the processing machine may be located in geographically distinct locations and connected so as to communicate in any suitable manner. Additionally, it is appreciated that each of the processor and/or the memory may be composed of different physical pieces of equipment. Accordingly, it is not necessary that the processor be one single piece of equipment in one location and that the memory be another single piece of equipment in another location. That is, it is contemplated that the processor may be two pieces of equipment in two different physical locations. The two distinct pieces of equipment may be connected in any suitable manner. Additionally, the memory may include two or more portions of memory in two or more physical locations.</p><p id="p-0065" num="0064">To explain further, processing, as described above, is performed by various components and various memories. However, it is appreciated that the processing performed by two distinct components as described above may, in accordance with a further embodiment of the invention, be performed by a single component. Further, the processing performed by one distinct component as described above may be performed by two distinct components. In a similar manner, the memory storage performed by two distinct memory portions as described above may, in accordance with a further embodiment of the invention, be performed by a single memory portion. Further, the memory storage performed by one distinct memory portion as described above may be performed by two memory portions.</p><p id="p-0066" num="0065">Further, various technologies may be used to provide communication between the various processors and/or memories, as well as to allow the processors and/or the memories of the invention to communicate with any other entity; i.e., so as to obtain further instructions or to access and use remote memory stores, for example. Such technologies used to provide such communication might include a network, the Internet, Intranet, Extranet, LAN, an Ethernet, wireless communication via cell tower or satellite, or any client server system that provides communication, for example. Such communications technologies may use any suitable protocol such as TCP/IP, UDP, or OSI, for example.</p><p id="p-0067" num="0066">As described above, a set of instructions may be used in the processing of the invention. The set of instructions may be in the form of a program or software. The software may be in the form of system software or application software, for example. The software might also be in the form of a collection of separate programs, a program module within a larger program, or a portion of a program module, for example. The software used might also include modular programming in the form of object oriented programming. The software tells the processing machine what to do with the data being processed.</p><p id="p-0068" num="0067">Further, it is appreciated that the instructions or set of instructions used in the implementation and operation of the invention may be in a suitable form such that the processing machine may read the instructions. For example, the instructions that form a program may be in the form of a suitable programming language, which is converted to machine language or object code to allow the processor or processors to read the instructions. That is, written lines of programming code or source code, in a particular programming language, are converted to machine language using a compiler, assembler or interpreter. The machine language is binary coded machine instructions that are specific to a particular type of processing machine, i.e., to a particular type of computer, for example. The computer understands the machine language.</p><p id="p-0069" num="0068">Any suitable programming language may be used in accordance with the various embodiments of the invention. Illustratively, the programming language used may include assembly language, Ada, APL, Basic, C, C++, COBOL, dBase, Forth, Fortran, Java, Modula-2, Pascal, Prolog, REXX, Visual Basic, and/or JavaScript, Phyton, for example. Further, it is not necessary that a single type of instruction or single programming language be utilized in conjunction with the operation of the system and method of the invention. Rather, any number of different programming languages may be utilized as is necessary and/or desirable.</p><p id="p-0070" num="0069">Also, the instructions and/or data used in the practice of the invention may utilize any compression or encryption technique or algorithm, as may be desired. An encryption module might be used to encrypt data. Further, files or other data may be decrypted using a suitable decryption module, for example.</p><p id="p-0071" num="0070">As described above, the invention may illustratively be embodied in the form of a processing machine, including a computer or computer system, for example, that includes at least one memory. It is to be appreciated that the set of instructions, i.e., the software for example, that enables the computer operating system to perform the operations described above may be contained on any of a wide variety of media or medium, as desired. Further, the data that is processed by the set of instructions might also be contained on any of a wide variety of media or medium. That is, the particular medium, i.e., the memory in the processing machine, utilized to hold the set of instructions and/or the data used in the invention may take on any of a variety of physical forms or transmissions, for example. Illustratively, the medium may be in the form of paper, paper transparencies, a compact disk, a DVD, an integrated circuit, a hard disk, a floppy disk, an optical disk, a magnetic tape, a RAM, a ROM, a PROM, an EPROM, a wire, a cable, a fiber, a communications channel, a satellite transmission, a memory card, a SIM card, or other remote transmission, as well as any other medium or source of data that may be read by the processors of the invention.</p><p id="p-0072" num="0071">Further, the memory or memories used in the processing machine that implements the invention may be in any of a wide variety of forms to allow the memory to hold instructions, data, or other information, as is desired. Thus, the memory might be in the form of a database to hold data. The database might use any desired arrangement of files such as a flat file arrangement or a relational database arrangement, for example.</p><p id="p-0073" num="0072">In the system and method of the invention, a variety of &#x201c;user interfaces&#x201d; may be utilized to allow a user to interface with the processing machine or machines that are used to implement the invention. As used herein, a user interface includes any hardware, software, or combination of hardware and software used by the processing machine that allows a user to interact with the processing machine. A user interface may be in the form of a dialogue screen for example. A user interface may also include any of a mouse, touch screen, keyboard, keypad, voice reader, voice recognizer, dialogue screen, menu box, list, checkbox, toggle switch, a pushbutton or any other device that allows a user to receive information regarding the operation of the processing machine as it processes a set of instructions and/or provides the processing machine with information. Accordingly, the user interface is any device that provides communication between a user and a processing machine. The information provided by the user to the processing machine through the user interface may be in the form of a command, a selection of data, or some other input, for example.</p><p id="p-0074" num="0073">As discussed above, a user interface is utilized by the processing machine that performs a set of instructions such that the processing machine processes data for a user. The user interface is typically used by the processing machine for interacting with a user either to convey information or receive information from the user. However, it should be appreciated that in accordance with some embodiments of the system and method of the invention, it is not necessary that a human user actually interact with a user interface used by the processing machine of the invention. Rather, it is also contemplated that the user interface of the invention might interact, i.e., convey and receive information, with another processing machine, rather than a human user. Accordingly, the other processing machine might be characterized as a user. Further, it is contemplated that a user interface utilized in the system and method of the invention may interact partially with another processing machine or processing machines, while also interacting partially with a human user.</p><p id="p-0075" num="0074">It will be readily understood by those persons skilled in the art that the present invention is susceptible to broad utility and application. Many embodiments and adaptations of the present invention other than those herein described, as well as many variations, modifications and equivalent arrangements, will be apparent from or reasonably suggested by the present invention and foregoing description thereof, without departing from the substance or scope of the invention.</p><p id="p-0076" num="0075">Accordingly, while the present invention has been described here in detail in relation to its exemplary embodiments, it is to be understood that this disclosure is only illustrative and exemplary of the present invention and is made to provide an enabling disclosure of the invention. Accordingly, the foregoing disclosure is not intended to be construed or to limit the present invention or otherwise to exclude any other such embodiments, adaptations, variations, modifications or equivalent arrangements.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system for automated analysis business intelligence, the system comprising:<claim-text>a query interface that is configured to receive natural language input from a user;</claim-text><claim-text>a natural language understanding processor that includes a parser and an interpreter, wherein the natural language understanding processor is configured to:<claim-text>evaluate the natural language input to determine an intent of the user;</claim-text><claim-text>when the evaluate is successful, determine the intent of the user and generate a query based on a context manager; and</claim-text><claim-text>when the evaluate is unsuccessful due to a failure in at least one from among the parser and the interpreter, sending an identification of the failure to a failure analysis system for human intervened analysis and refinement of a natural language model used by the natural language understand processor; and</claim-text></claim-text><claim-text>a context manager processor that is configured to:<claim-text>assess, to determine a user interest in one or more portions of results of the query, a scrolling of the user through the results of the query; and</claim-text><claim-text>refine, based on the user interest in the one or more portions of the results of the query, an output of the results of the query.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a query processor that is configured to:<claim-text>translate the query into a database query; and</claim-text><claim-text>execute the database query against a database; and</claim-text></claim-text><claim-text>a presentation interface that is configured to generate, in natural language, the results of the query, wherein the results of the query comprise results of the database query.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the generate the query comprises:<claim-text>convert, by the presentation interface, into a graph, the results of the database query; and</claim-text><claim-text>converting, by the presentation interface, the graph into the results of the query.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generate the query comprises: translate, by the natural language understanding processor, the intent into the query by utilizing at least one from among a graph and a machine language model that is trained to understand the depth or level of the intent.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the evaluate comprises:<claim-text>tracking, by the natural language understanding processor, recent queries from the user; and</claim-text><claim-text>utilizing, by the natural language understanding processor, based on the recent queries, probabilistic methodologies to determine the intent of the user.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the results of the query comprises an explanation of a reason for a binary response to the query.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the query interface is further configured to:<claim-text>receive, from the user, feedback about the results of the query; and</claim-text><claim-text>provide, to the context manager, the feedback about the results of the query.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the query interface comprises conversational artificial intelligence that continuously learns from user interactions.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the conversational artificial intelligence is configured to: collect information that is relevant to a type of transition that occurs during a conversation.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the interpreter is in communication with the context manager and a concept mapper that receives inputs from a domain concept ontology and an acronym dictionary.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A method for automated analysis of business intelligence, the method comprising:<claim-text>receiving, via a query interface, natural language input from a user;</claim-text><claim-text>evaluating, via a natural language understanding processor that includes a parser and an interpreter, the natural language input to determine an intent of the user;</claim-text><claim-text>when the evaluating is successful, determining the intent of the user and generating a query based on a context manager;</claim-text><claim-text>when the evaluating is unsuccessful due to a failure in at least one from among the parser and the interpreter, sending an identification of the failure to a failure analysis system for human intervened analysis and refinement of a natural language model used by the natural language understand processor;</claim-text><claim-text>assessing, via a context manager processor, to determine a user interest in one or more portions of results of the query, a scrolling of the user through the results of the query; and</claim-text><claim-text>refining, based on the user interest in the one or more portions of the results of the query, an output of the results of the query.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>translating, by a query processor, the query into a database query;</claim-text><claim-text>executing, by the query processor, the database query against a database; and</claim-text><claim-text>generating, by a presentation interface, in natural language, the results of the query, wherein the results of the query comprise results of the database query.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the generating the results of the query comprises:<claim-text>converting, by the presentation interface, into a graph, the results of the database query; and</claim-text><claim-text>converting, by the presentation interface, the graph into the results of the query.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the generating the query comprises: translating, by the natural language understanding processor, the intent into a query by utilizing at least one from among a graph and a machine language model that is trained to understand the depth or level of the intent.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the evaluating comprises:<claim-text>tracking, by the natural language understanding processor, recent queries from the user; and</claim-text><claim-text>utilizing, by the natural language understanding processor, based on the recent queries, probabilistic methodologies to determine the intent of the user.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the results of the query comprises an explanation of a reason for a binary response to the query.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>receiving, by the query interface, from the user, feedback about the results of the query; and</claim-text><claim-text>providing, by the query interface, to the context manager, the feedback about the results of the query.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the query interface comprises conversational artificial intelligence that continuously learns from user interactions.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising: collecting, by the conversational artificial intelligence, information that is relevant to a type of transition that occurs during a conversation.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the interpreter is in communication with the context manager and a concept mapper that receives inputs from a domain concept ontology and an acronym dictionary.</claim-text></claim></claims></us-patent-application>
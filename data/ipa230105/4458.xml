<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004459A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004459</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17864804</doc-number><date>20220714</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>07</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>06</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>0772</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0679</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>073</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>141</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">ERROR REPORTING FOR NON-VOLATILE MEMORY MODULES</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16730113</doc-number><date>20191230</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11392441</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17864804</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Advanced Micro Devices, Inc.</orgname><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Magro</last-name><first-name>James R.</first-name><address><city>Lakeway</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Balakrishnan</last-name><first-name>Kedarnath</first-name><address><city>Bangalore</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Sridharan</last-name><first-name>Vilas</first-name><address><city>Brookline</city><state>MA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Advanced Micro Devices, Inc.</orgname><role>02</role><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A memory controller includes a memory channel controller adapted to receive memory access requests and dispatch associated commands addressable in a system memory address space to a non-volatile storage class memory (SCM) module. The non-volatile error reporting circuit identifies error conditions associated with the non-volatile SCM module and maps the error conditions from a first number of possible error conditions associated with the non-volatile SCM module to a second, smaller number of virtual error types for reporting to an error monitoring module of a host operating system, the mapping based at least on a classification that the error condition will or will not have a deleterious effect on an executable process running on the host operating system.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="98.47mm" wi="158.75mm" file="US20230004459A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="225.21mm" wi="152.40mm" orientation="landscape" file="US20230004459A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="238.51mm" wi="160.78mm" orientation="landscape" file="US20230004459A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="245.53mm" wi="151.13mm" file="US20230004459A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="203.20mm" wi="131.40mm" orientation="landscape" file="US20230004459A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="145.12mm" wi="146.30mm" file="US20230004459A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 16/730,113, filed Dec. 30, 2019, and entitled &#x201c;ERROR REPORTING FOR NON-VOLATILE MEMORY MODULES,&#x201d; which is incorporated by reference herein in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Computer systems typically use inexpensive and high-density dynamic random access memory (DRAM) chips for main memory. Most DRAM chips sold today are compatible with various double data rate (DDR) DRAM standards promulgated by the Joint Electron Devices Engineering Council (JEDEC). DDR memory controllers are used to manage the interface between various memory accessing agents and DDR DRAMs according to published DDR standards.</p><p id="p-0004" num="0003">A non-volatile dual-inline memory module with persistent storage (&#x201c;NVDIMM-P&#x201d;) is a storage class memory that in some applications can be used in place of standard DDR DIMMs but that includes persistent memory. However, these memories include multiple types of error conditions that are different from DDR error conditions. Furthermore, the error conditions associated with NVDIMM-Ps have different effects on the operating system and running processes that use the memory than the effects of error conditions associated with standard DDR DIMMs.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates in block diagram form an accelerated processing unit (APU) and memory system known in the prior art;</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates in block diagram form a memory controller suitable for use in an APU like that of <figref idref="DRAWINGS">FIG. <b>1</b></figref> according to some embodiments;</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates in block diagram form a data processing system according to some embodiments;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrated in block diagram form a non-volatile buffer according to some embodiments;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating non-volatile memory usage on a computer system according to some embodiments; and</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow diagram of a process for error reporting according to some embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0011" num="0010">In the following description, the use of the same reference numerals in different drawings indicates similar or identical items. Unless otherwise noted, the word &#x201c;coupled&#x201d; and its associated verb forms include both direct connection and indirect electrical connection by means known in the art, and unless otherwise noted any description of direct connection implies alternate embodiments using suitable forms of indirect electrical connection as well.</p><heading id="h-0003" level="1">DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS</heading><p id="p-0012" num="0011">A memory controller includes a command queue, a memory interface queue, and a non-volatile error reporting circuit. The command queue has a first input for receiving memory access commands including volatile reads, volatile writes, non-volatile reads, and non-volatile writes, and an output, and has a plurality of entries. The memory interface queue has an input coupled to the output of the command queue, and an output for coupling to a non-volatile storage class memory (SCM) module. The non-volatile error reporting circuit identifies error conditions associated with the non-volatile DIMM and maps the error conditions from a first number of possible error conditions associated with the non-volatile SCM module to a second, smaller number of virtual error types for reporting to an error monitoring module of a host operating system. The mapping is based at least on a classification that the error condition will or will not have a deleterious effect on an executable process running on the host operating system.</p><p id="p-0013" num="0012">A method includes receiving a plurality of memory access requests including volatile memory reads, volatile memory writes, non-volatile memory reads, and non-volatile memory writes. The method places memory access commands for fulfilling the memory access requests in a memory interface queue and transmits the memory access commands from the memory interface queue to a memory channel coupled to a non-volatile storage class memory (SCM) module. Based on information received over the memory channel, error conditions associated with the memory channel are identified. The error conditions are mapped from a first number of possible error conditions associated with the non-volatile SCM module to a second, smaller number of virtual error types for reporting to an error monitoring module of a host operating system, the mapping based at least on a classification that the error condition will or will not have a deleterious effect on an executable process running on the host operating system.</p><p id="p-0014" num="0013">A data processing system includes a central processing unit, a data fabric coupled to the central processing unit, and a memory controller coupled to the data fabric for fulfilling memory access requests made through the data fabric. The memory controller includes a command queue, a memory interface queue, and a non-volatile error reporting circuit. The command queue has a first input for receiving memory access commands including volatile reads, volatile writes, non-volatile reads, and non-volatile writes, and an output, and has a plurality of entries. The memory interface queue has an input coupled to the output of the command queue, and an output for coupling to a non-volatile storage class memory (SCM) module. The non-volatile error reporting circuit identifies error conditions associated with the non-volatile SCM module and maps the error conditions from a first number of possible error conditions associated with the non-volatile SCM module to a second, smaller number of virtual error types for reporting to an error monitoring module of a host operating system, the mapping based at least on a classification that the error condition will or will not have a deleterious effect on an executable process running on the host operating system.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates in block diagram form an accelerated processing unit (APU) <b>100</b> and memory system <b>130</b> known in the prior art. APU <b>100</b> is an integrated circuit suitable for use as a processor in a host data processing system, and includes generally a central processing unit (CPU) core complex <b>110</b>, a graphics core <b>120</b>, a set of display engines <b>122</b>, a memory management hub <b>140</b>, a data fabric <b>125</b>, a set of peripheral controllers <b>160</b>, a set of peripheral bus controllers <b>170</b>, and a system management unit (SMU) <b>180</b>.</p><p id="p-0016" num="0015">CPU core complex <b>110</b> includes a CPU core <b>112</b> and a CPU core <b>114</b>. In this example, CPU core complex <b>110</b> includes two CPU cores, but in other embodiments CPU core complex <b>110</b> can include an arbitrary number of CPU cores. Each of CPU cores <b>112</b> and <b>114</b> is bidirectionally connected to a system management network (SMN), which forms a control fabric, and to data fabric <b>125</b>, and is capable of providing memory access requests to data fabric <b>125</b>. Each of CPU cores <b>112</b> and <b>114</b> may be unitary cores, or may further be a core complex with two or more unitary cores sharing certain resources such as caches.</p><p id="p-0017" num="0016">Graphics core <b>120</b> is a high performance graphics processing unit (GPU) capable of performing graphics operations such as vertex processing, fragment processing, shading, texture blending, and the like in a highly integrated and parallel fashion. Graphics core <b>120</b> is bidirectionally connected to the SMN and to data fabric <b>125</b>, and is capable of providing memory access requests to data fabric <b>125</b>. In this regard, APU <b>100</b> may either support a unified memory architecture in which CPU core complex <b>110</b> and graphics core <b>120</b> share the same memory space, or a memory architecture in which CPU core complex <b>110</b> and graphics core <b>120</b> share a portion of the memory space, while graphics core <b>120</b> also uses a private graphics memory not accessible by CPU core complex <b>110</b>.</p><p id="p-0018" num="0017">Display engines <b>122</b> render and rasterize objects generated by graphics core <b>120</b> for display on a monitor. Graphics core <b>120</b> and display engines <b>122</b> are bidirectionally connected to a common memory management hub <b>140</b> for uniform translation into appropriate addresses in memory system <b>130</b>, and memory management hub <b>140</b> is bidirectionally connected to data fabric <b>125</b> for generating such memory accesses and receiving read data returned from the memory system.</p><p id="p-0019" num="0018">Data fabric <b>125</b> includes a crossbar switch for routing memory access requests and memory responses between any memory accessing agent and memory management hub <b>140</b>. It also includes a system memory map, defined by basic input/output system (BIOS), for determining destinations of memory accesses based on the system configuration, as well as buffers for each virtual connection.</p><p id="p-0020" num="0019">Peripheral controllers <b>160</b> include a universal serial bus (USB) controller <b>162</b> and a Serial Advanced Technology Attachment (SATA) interface controller <b>164</b>, each of which is bidirectionally connected to a system hub <b>166</b> and to the SMN bus. These two controllers are merely exemplary of peripheral controllers that may be used in APU <b>100</b>.</p><p id="p-0021" num="0020">Peripheral bus controllers <b>170</b> include a system controller or &#x201c;Southbridge&#x201d; (SB) <b>172</b> and a Peripheral Component Interconnect Express (PCIe) controller <b>174</b>, each of which is bidirectionally connected to an input/output (I/O) hub <b>176</b> and to the SMN bus. I/O hub <b>176</b> is also bidirectionally connected to system hub <b>166</b> and to data fabric <b>125</b>. Thus, for example a CPU core can program registers in USB controller <b>162</b>, SATA interface controller <b>164</b>, SB <b>172</b>, or PCIe controller <b>174</b> through accesses that data fabric <b>125</b> routes through I/O hub <b>176</b>. Software and firmware for APU <b>100</b> are stored in a system data drive or system BIOS memory (not shown) which can be any of a variety of non-volatile memory types, such as read-only memory (ROM), flash electrically erasable programmable ROM (EEPROM), and the like. Typically, the BIOS memory is accessed through the PCIe bus, and the system data drive through the SATA interface.</p><p id="p-0022" num="0021">SMU <b>180</b> is a local controller that controls the operation of the resources on APU <b>100</b> and synchronizes communication among them. SMU <b>180</b> manages power-up sequencing of the various processors on APU <b>100</b> and controls multiple off-chip devices via reset, enable and other signals. SMU <b>180</b> includes one or more clock sources (not shown), such as a phase locked loop (PLL), to provide clock signals for each of the components of APU <b>100</b>. SMU <b>180</b> also manages power for the various processors and other functional blocks, and may receive measured power consumption values from CPU cores <b>112</b> and <b>114</b> and graphics core <b>120</b> to determine appropriate power states.</p><p id="p-0023" num="0022">Memory management hub <b>140</b> and its associated physical interfaces (PHYs) <b>151</b> and <b>152</b> are integrated with APU <b>100</b> in this embodiment. Memory management hub <b>140</b> includes memory channels <b>141</b> and <b>142</b> and a power engine <b>149</b>. Memory channel <b>141</b> includes a host interface <b>145</b>, a memory channel controller <b>143</b>, and a physical interface <b>147</b>. Host interface <b>145</b> bidirectionally connects memory channel controller <b>143</b> to data fabric <b>125</b> over a serial presence detect link (SDP). Physical interface <b>147</b> bidirectionally connects memory channel controller <b>143</b> to PHY <b>151</b>, and conforms to the DDR PHY Interface (DFI) Specification. Memory channel <b>142</b> includes a host interface <b>146</b>, a memory channel controller <b>144</b>, and a physical interface <b>148</b>. Host interface <b>146</b> bidirectionally connects memory channel controller <b>144</b> to data fabric <b>125</b> over another SDP. Physical interface <b>148</b> bidirectionally connects memory channel controller <b>144</b> to PHY <b>152</b>, and conforms to the DFI Specification. Power engine <b>149</b> is bidirectionally connected to SMU <b>180</b> over the SMN bus, to PHYs <b>151</b> and <b>152</b> over the APB, and is also bidirectionally connected to memory channel controllers <b>143</b> and <b>144</b>. PHY <b>151</b> has a bidirectional connection to memory channel <b>131</b>. PHY <b>152</b> has a bidirectional connection memory channel <b>133</b>.</p><p id="p-0024" num="0023">Memory management hub <b>140</b> is an instantiation of a memory controller having two memory channel controllers and uses a shared power engine <b>149</b> to control operation of both memory channel controller <b>143</b> and memory channel controller <b>144</b> in a manner that will be described further below. Each of memory channels <b>141</b> and <b>142</b> can connect to state-of-the-art DDR memories such as DDR version four (DDR4), low power DDR4 (LPDDR4), graphics DDR version five (gDDR5), and high bandwidth memory (HBM), and can be adapted for future memory technologies. These memories provide high bus bandwidth and high speed operation. At the same time, they also provide low power modes to save power for battery-powered applications such as laptop computers, and also provide built-in thermal monitoring.</p><p id="p-0025" num="0024">Memory system <b>130</b> includes a memory channel <b>131</b> and a memory channel <b>133</b>. Memory channel <b>131</b> includes a set of dual inline memory modules (DIMMs) connected to a Dedra bus <b>132</b>, including representative DIMMs <b>134</b>, <b>136</b>, and <b>138</b> that in this example correspond to separate ranks. Likewise, memory channel <b>133</b> includes a set of DIMMs connected to a DDRx bus <b>129</b>, including representative DIMMs <b>135</b>, <b>137</b>, and <b>139</b>.</p><p id="p-0026" num="0025">APU <b>100</b> operates as the central processing unit (CPU) of a host data processing system and provides various buses and interfaces useful in modern computer systems. These interfaces include two double data rate (DDRx) memory channels, a PCIe root complex for connection to a PCIe link, a USB controller for connection to a USB network, and an interface to a SATA mass storage device.</p><p id="p-0027" num="0026">APU <b>100</b> also implements various system monitoring and power saving functions. In particular one system monitoring function is thermal monitoring. For example, if APU <b>100</b> becomes hot, then SMU <b>180</b> can reduce the frequency and voltage of CPU cores <b>112</b> and <b>114</b> and/or graphics core <b>120</b>. If APU <b>100</b> becomes too hot, then it can be shut down entirely. Thermal events can also be received from external sensors by SMU <b>180</b> via the SMN bus, and SMU <b>180</b> can reduce the clock frequency and/or power supply voltage in response.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates in block diagram form a memory controller <b>200</b> that is suitable for use in an APU like that of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Memory controller <b>200</b> includes generally a memory channel controller <b>210</b> and a power controller <b>250</b>. Memory channel controller <b>210</b> includes generally an interface <b>212</b>, a memory interface queue <b>214</b>, a command queue <b>220</b>, an address generator <b>222</b>, a content addressable memory (CAM) <b>224</b>, replay control logic <b>231</b> including a replay queue <b>230</b>, a refresh logic block <b>232</b>, a timing block <b>234</b>, a page table <b>236</b>, an arbiter <b>238</b>, an error correction code (ECC) check circuit <b>242</b>, an ECC generation block <b>244</b>, a data buffer <b>246</b>, a non-volatile (NV) buffer <b>247</b>, and a NV queue <b>248</b>.</p><p id="p-0029" num="0028">Interface <b>212</b> has a first bidirectional connection to data fabric <b>125</b> over an external bus, and has an output. In memory controller <b>200</b>, this external bus is compatible with the advanced extensible interface version four specified by ARM Holdings, PLC of Cambridge, England, known as &#x201c;AXI4&#x201d;, but can be other types of interfaces in other embodiments. Interface <b>212</b> translates memory access requests from a first clock domain known as the FCLK (or MEMCLK) domain to a second clock domain internal to memory controller <b>200</b> known as the UCLK domain. Similarly, memory interface queue <b>214</b> provides memory accesses from the UCLK domain to a DFICLK domain associated with the DFI interface.</p><p id="p-0030" num="0029">Address generator <b>222</b> decodes addresses of memory access requests received from data fabric <b>125</b> over the AXI4 bus. The memory access requests include access addresses in the physical address space represented in a normalized format. Address generator <b>222</b> converts the normalized addresses into a format that can be used to address the actual memory devices in memory system <b>130</b>, as well as to efficiently schedule related accesses. This format includes a region identifier that associates the memory access request with a particular rank, a row address, a column address, a bank address, and a bank group. On startup, the system BIOS queries the memory devices in memory system <b>130</b> to determine their size and configuration, and programs a set of configuration registers associated with address generator <b>222</b>. Address generator <b>222</b> uses the configuration stored in the configuration registers to translate the normalized addresses into the appropriate format. Address generator <b>222</b> decodes the address range of the memory, including NVDIMM-P memory, and stores a decoded signal indicating whether the memory access request is a request to NVDIMM-P in command queue <b>220</b>. Arbiter <b>238</b> can then prioritize the NVDIMM-P requests with appropriate priority relative to other requests. Command queue <b>220</b> is a queue of memory access requests received from the memory accessing agents in APU <b>100</b>, such as CPU cores <b>112</b> and <b>114</b> and graphics core <b>120</b>. Command queue <b>220</b> stores the address fields decoded by address generator <b>222</b> as well other address information that allows arbiter <b>238</b> to select memory accesses efficiently, including access type and quality of service (QoS) identifiers. CAM <b>224</b> includes information to enforce ordering rules, such as write after write (WAW) and read after write (RAW) ordering rules.</p><p id="p-0031" num="0030">Error correction code (ECC) generation block <b>244</b> determines the ECC of write data to be sent to the NVDIMM-P. ECC check circuit <b>242</b> checks the received ECC against the incoming ECC. Thus, a memory controller and data processing system as described herein expands the coverage of data integrity checking to provide end-to-end checking by leveraging a limited number of user bits that are stored in the NVDIMM-P device and available for comparison when the corresponding data is later read.</p><p id="p-0032" num="0031">Replay queue <b>230</b> is a temporary queue for storing selected memory accesses picked by arbiter <b>238</b> that are awaiting responses, such as address and command parity responses. Replay control logic <b>231</b> accesses ECC check circuit <b>242</b> to determine whether the returned ECC is correct or indicates an error. Replay control logic <b>231</b> initiates and controls a replay sequence in which accesses are replayed in the case of a parity or ECC error of one of these cycles. Replayed commands are placed in the memory interface queue <b>214</b>.</p><p id="p-0033" num="0032">Refresh logic <b>232</b> includes state machines for various powerdown, refresh, and termination resistance (ZQ) calibration cycles that are generated separately from normal read and write memory access requests received from memory accessing agents. For example, if a memory rank is in precharge powerdown, it must be periodically awakened to run refresh cycles. Refresh logic <b>232</b> generates refresh commands periodically to prevent data errors caused by leaking of charge off storage capacitors of memory cells in DRAM chips. In addition, refresh logic <b>232</b> periodically calibrates ZQ to prevent mismatch in on-die termination resistance due to thermal changes in the system.</p><p id="p-0034" num="0033">Arbiter <b>238</b> is bidirectionally connected to command queue <b>220</b> and is the heart of memory channel controller <b>210</b>. It improves efficiency by intelligent scheduling of accesses to improve the usage of the memory bus. Arbiter <b>238</b> uses timing block <b>234</b> to enforce proper timing relationships by determining whether certain accesses in command queue <b>220</b> are eligible for issuance based on DRAM timing parameters. For example, each DRAM has a minimum specified time between activate commands, known as &#x201c;t<sub>RC</sub>&#x201d;. Timing block <b>234</b> maintains a set of counters that determine eligibility based on this and other timing parameters specified in the JEDEC specification, and is bidirectionally connected to replay queue <b>230</b>. Page table <b>236</b> maintains state information about active pages in each bank and rank of the memory channel for arbiter <b>238</b>, and is bidirectionally connected to replay queue <b>230</b>.</p><p id="p-0035" num="0034">NV buffer <b>247</b> stores NV read commands in NV queue <b>248</b>, both for use in replay sequences, and for managing NV read responses. NV buffer <b>247</b> is bidirectionally connected to memory interface queue <b>214</b> for handling RD_RDY and SEND commands, as further described below.</p><p id="p-0036" num="0035">In response to write memory access requests received from interface <b>212</b>, ECC generation block <b>244</b> computes an ECC according to the write data. Data buffer <b>246</b> stores the write data and ECC for received memory access requests. It outputs the combined write data/ECC to memory interface queue <b>214</b> when arbiter <b>238</b> picks the corresponding write access for dispatch to the memory channel.</p><p id="p-0037" num="0036">Power controller <b>250</b> generally includes an interface <b>252</b> to an advanced extensible interface, version one (AXI), an advanced peripheral bus (APB) interface <b>254</b>, and a power engine <b>260</b>. Interface <b>252</b> has a first bidirectional connection to the SMN, which includes an input for receiving an event signal labeled &#x201c;EVENT_n&#x201d; shown separately in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and an output. APB interface <b>254</b> has an input connected to the output of interface <b>252</b>, and an output for connection to a PHY over an APB. Power engine <b>260</b> has an input connected to the output of interface <b>252</b>, and an output connected to an input of memory interface queue <b>214</b>. Power engine <b>260</b> includes a set of configuration registers <b>262</b>, a microcontroller (&#x3bc;C) <b>264</b>, a self refresh controller (SLFREF/PE) <b>266</b>, and a reliable read/write timing engine (RRW/TE) <b>268</b>. Configuration registers <b>262</b> are programmed over the AXI bus, and store configuration information to control the operation of various blocks in memory controller <b>200</b>. Accordingly, configuration registers <b>262</b> have outputs connected to these blocks that are not shown in detail in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Self refresh controller <b>266</b> is an engine that allows the manual generation of refreshes in addition to the automatic generation of refreshes by refresh logic <b>232</b>. Reliable read/write timing engine <b>268</b> provides a continuous memory access stream to memory or I/O devices for such purposes as DDR interface maximum read latency (MRL) training and loopback testing.</p><p id="p-0038" num="0037">Memory channel controller <b>210</b> includes circuitry that allows it to pick memory accesses for dispatch to the associated memory channel. In order to make the desired arbitration decisions, address generator <b>222</b> decodes the address information into predecoded information including rank, row address, column address, bank address, and bank group in the memory system, and command queue <b>220</b> stores the predecoded information. Configuration registers <b>262</b> store configuration information to determine how address generator <b>222</b> decodes the received address information. Arbiter <b>238</b> uses the decoded address information, timing eligibility information indicated by timing block <b>234</b>, and active page information indicated by page table <b>236</b> to efficiently schedule memory accesses while observing other criteria such as quality of service (QoS) requirements. For example, arbiter <b>238</b> implements a preference for accesses to open pages to avoid the overhead of precharge and activation commands required to change memory pages, and hides overhead accesses to one bank by interleaving them with read and write accesses to another bank. In particular during normal operation, arbiter <b>238</b> normally keeps pages open in different banks until they are required to be precharged prior to selecting a different page.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates in block diagram form a data processing system <b>300</b> according to some embodiments. Data processing system <b>300</b> includes a memory system <b>330</b> and an APU <b>310</b>, and a baseboard management controller (BMC) <b>340</b>. APU <b>310</b> includes memory controllers like memory controller <b>200</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) supporting heterogenous memory channels to interface with memory system <b>330</b>. In addition to normal DDRx memory channels, APU <b>310</b> supports NVDIMM-P <b>338</b> on a heterogenous memory channel <b>331</b> having both normal registered DIMMs or RDIMMs <b>334</b> and <b>336</b> connected over bus <b>332</b>, in addition to a homogeneous memory channel <b>333</b> having only RDIMMs <b>335</b>, <b>337</b>, and <b>339</b> connected over bus <b>329</b>. While in this embodiment heterogenous memory channel <b>331</b> connects to both NVDIMM-Ps and RDIMMs, the heterogenous memory channel has the ability to interface with all NVDIMM-P type DIMMs in some embodiments.</p><p id="p-0040" num="0039">According to the draft NVDIMM-P standard, transactions between the memory controller on APU <b>310</b> and NVDIMM-P <b>338</b> are protected by &#x201c;Link&#x201d; ECC. Link ECC ensures data integrity for the data transfer between the memory controller and the NVDIMM over bus <b>332</b>. In accordance with known ECC mechanisms, it protects against data corruption on the link caused by a random or transient error. The protection varies according to the ECC code used. The ECC may allow, for example, single-bit correction with multiple-bit error detection. In response to detecting an uncorrectable error, the memory controller can replay the transaction so that a transient or random error will not persist, and can also report both correctable and uncorrectable errors to the operating system.</p><p id="p-0041" num="0040">BMC <b>340</b> is a specialized processor mounted to the host circuit board of data processing system <b>300</b> and connected to APU <b>310</b> for providing a control and monitoring capability. BMC <b>340</b> monitors the state of APU <b>310</b> and various other components (not shown separately) of data processing system <b>300</b> by receiving error reports and monitoring status registers and sensors. BMC <b>340</b> is connected to system communication busses such as the depicted peripheral component interconnect express (PCIe) bus and universal serial bus (USB), and may also monitor registers in various system components via an inter-integrated circuit bus to poll for error reports. External access to BMC functions is provided for remote monitoring and control, typically through a dedicated network interface or a connection to the network interface of data processing system <b>300</b>.</p><p id="p-0042" num="0041">While NVDIMM-P type DIMMs are described in this embodiment, other embodiments employ the techniques herein to interface with other types of storage class memory (SCM) modules over a heterogeneous memory channel. As used herein, SCM indicates a memory module with non-volatile memory that is addressable in the system memory space. The non-volatile memory in an SCM module can be buffered with RAM and/or paired with RAM on board the SCM module. The SCM memory address map appears alongside conventional DRAM population from the operating system (OS) perspective. The OS is typically aware that the SCM defined address range is a &#x201c;different&#x201d; type of memory than conventional memory. This distinction is to inform the OS that this memory may be more latent and has a persistent quality.</p><p id="p-0043" num="0042">The OS can map the SCM memory as Direct Access memory or Filesystem Access memory. Direct Access implies the OS accessing the SCM address range as physical addressable memory. File system access implies the OS manages the persistent memory as part of the file system and manages access to the SCM via file-based API. Ultimately the request comes to the memory controller within the SCM address range independent of how the OS at a higher level manages the access.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates in block diagram form an NV buffer <b>400</b> according to some embodiments. NV buffer <b>400</b> is an exemplary instantiation of NV buffer <b>247</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>). NV buffer <b>400</b> includes a non-volatile command queue (&#x201c;NV queue&#x201d;) <b>402</b>, a non-volatile buffer control circuit (&#x201c;NV buffer CTRL&#x201d;) <b>404</b>, a non-volatile error reporting circuit (&#x201c;NV error reporting&#x201d;) <b>406</b>, and a non-volatile error lookup table (&#x201c;NV error LUT&#x201d;) <b>408</b>.</p><p id="p-0045" num="0044">NV queue <b>402</b> is coupled to the output of the command queue <b>220</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) for receiving non-volatile read commands, and stores them as they await fulfillment. NV queue <b>402</b> stores non-volatile read commands to provide them for replay when a recovery sequence is triggered requiring replay of commands.</p><p id="p-0046" num="0045">NV buffer CTRL <b>404</b> handles ready response signals (&#x201c;RD_RDY&#x201d;) received from the non-volatile DIMM indicating that responsive data is available for an associated one of the non-volatile read commands. In response, NV buffer CTRL <b>404</b> causes a SEND command to be placed in the memory interface queue for issuance to the non-volatile DIMM to cause it to send the responsive data. When responsive data is received, NV buffer CTRL <b>404</b> identifies the associated non-volatile read command in NV queue <b>402</b> using a read ID (&#x201c;RID&#x201d;), and removes the associated non-volatile read command from the non-volatile queue.</p><p id="p-0047" num="0046">NV error reporting circuit <b>406</b> is connected to ECC check circuit <b>242</b> and replay control logic <b>231</b> for receiving error codes indicating data errors and link errors associated with the NVDIMM-P or other non-volatile DIMM. The errors are mapped from a first number of possible error conditions indicated by error type identifiers associated with the non-volatile DIMM to a second, smaller number virtual error types for reporting to an error monitoring module of a host operating system. In this embodiment, the mapping is accomplished using NV error LUT <b>408</b>, which is indexed for lookups using the error type identifiers describing the data or link errors. The result of the lookups is a virtual error type for reporting to the error monitoring module, as further described below with respect to <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating non-volatile memory usage on a computer system <b>500</b> according to some embodiments. The depicted software and hardware components are suitable for use with a data processing system as described with respect to <figref idref="DRAWINGS">FIGS. <b>2</b>-<b>4</b></figref>. System <b>500</b> includes a user space <b>510</b> hosted by an operating system kernel (&#x201c;OS kernel&#x201d;) <b>520</b>, a memory controller <b>530</b>, and a non-volatile DIMM, in this embodiment an NVDIMM-P <b>540</b>.</p><p id="p-0049" num="0048">OS kernel <b>520</b> is typically a server OS, but in some implementations is another type of OS such as a personal computer OS or an OS specialized for a particular computational task. OS kernel <b>520</b> runs on a system processor such as APU <b>310</b> (<figref idref="DRAWINGS">FIG. <b>3</b></figref>), and hosts a user space <b>510</b> running user processes <b>512</b> and user applications <b>514</b>. OS kernel <b>520</b> includes an error monitoring module such as machine check architecture <b>522</b>, a non-volatile DIMM driver (&#x201c;NV driver&#x201d;) <b>524</b>, and a file system <b>526</b>. Many other parts of OS kernel <b>520</b> are not shown in order to focus on components that access the non-volatile DIMMs. In some embodiments, multiple OS kernels are present as virtual machines hosted by a hypervisor layer.</p><p id="p-0050" num="0049">While machine check architecture <b>522</b> is depicted in this implementation, other types of error reporting modules are used in other implementations. Machine check architecture <b>522</b> is a known mechanism to provide error reporting from error detection logic in many parts of data processing system <b>500</b> to OS kernel <b>520</b> and higher level software such as a virtual machine manager, applications, and processes. Machine check architecture <b>522</b> is able to process errors, and recover from certain errors, by determining if corrected data can be obtained and executing software routines to correct the errors. In certain conditions, machine check architecture <b>522</b> determines that execution of a particular process cannot proceed based on determining that corrected data cannot be obtained. In such a case, machine check architecture <b>522</b> is able to process the error by passing control to higher-level software or forcing a reset.</p><p id="p-0051" num="0050">NV driver <b>524</b> is a driver module executing on OS kernel <b>520</b> for providing access to memory in NVDIMM-P <b>540</b>. As depicted, NV driver <b>524</b> fulfills memory access instructions from process <b>512</b> and application <b>514</b> (which has one or more executing processes). To fulfill the instructions, NV driver <b>524</b> formats the instructions as appropriate requests to NVDIMM-P <b>540</b> through memory controller <b>530</b>. For example, non-volatile read and non-volatile write requests from NV driver <b>524</b> may result in XREAD and WRITE commands at memory controller <b>530</b>.</p><p id="p-0052" num="0051">File system <b>526</b> executes on OS kernel <b>520</b> to manage data files that include data stored in NVDIMM-P <b>540</b>. File system <b>526</b> may have native support to interface with NVDIMM-P <b>540</b>, or may also employ NV driver <b>524</b> to handle accesses. OS kernel <b>520</b> also accesses NVDIMM-P <b>540</b> through memory controller <b>530</b> for its own memory access needs.</p><p id="p-0053" num="0052">Memory controller <b>530</b> in this embodiment is an implementation of memory controller <b>200</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) or a similar memory controller suitable for accessing NVDIMM-P <b>540</b>, and includes NV error reporting logic <b>532</b> corresponding to NV error reporting logic <b>406</b> (<figref idref="DRAWINGS">FIG. <b>4</b></figref>). In some embodiments, NV error reporting logic <b>532</b> reports errors to machine check architecture <b>522</b> using error reporting information determined according to the process of <figref idref="DRAWINGS">FIG. <b>6</b></figref> discussed further below.</p><p id="p-0054" num="0053">The use of persistent memory such as NVDIMM-P provides a number of challenges in dealing with error reporting and the associated reliability, accessibility, and serviceability (RAS) issues. Such challenges result from the multitude of new error types that occur with non-volatile DIMMS as compared to DRAM DIMMs, which have very few error types. While the error types are defined for certain non-volatile DIMMs such as NVDIMM-P, the manner in which errors are handled and reported to the system is generally not specified, for example in the draft NVDIMM-P standard.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow diagram of process <b>600</b> for reporting errors according to some embodiments. Process <b>600</b> is suitable for implementation with memory controller <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, or other memory controller arrangements, and is performed in this embodiment by the NV error reporting logic <b>406</b> (<figref idref="DRAWINGS">FIG. <b>4</b></figref>) in cooperation with replay logic control circuit <b>231</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>).</p><p id="p-0056" num="0055">Generally, process <b>600</b> handles errors detected at the memory controller and reports them in a manner suitable for error management and fault management within the system. Error management describes actions necessary by operational software, for example the operating system, to manage running programs that may be affected by the error. Error management is controlled by the operating system's error monitoring module, such as machine check architecture <b>522</b>, and generally includes a limited set of responses to errors, such as taking no action, terminating a single affected process, program, or virtual machine, and terminating the system operation. As such, the error monitoring module requires only the error information needed to make decisions about the scope and severity of the error, and to determine what immediate action is to be taken. Fault Management describes optional actions for purposes of diagnosis, repair, and reconfiguration of the underlying hardware. Fault management capability is found in various parts of the data processing system, and for severe faults is directed by BMC <b>340</b> (<figref idref="DRAWINGS">FIG. <b>3</b></figref>).</p><p id="p-0057" num="0056">Referring to process <b>600</b>, the process starts at block <b>602</b> in which it receives an error notification from the non-volatile DIMM, or detects an error at the memory controller, such as a link ECC error detected by ECC check circuit <b>242</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>). Errors reported by the non-volatile DIMM include various types of DRAM errors, media errors (concerning the non-volatile media), cache errors (concerning the cache on the non-volatile DIMM), and thermal errors. Some non-volatile DIMMs report other kinds of errors such as firmware initialization errors. Link errors include transmission errors over the memory channel such as link ECC errors. Host errors are detected at the memory controller and include non-volatile read command timeouts and duplicate RID errors.</p><p id="p-0058" num="0057">Generally, errors reported from a non-volatile DIMM such as an NVDIMM-P have three overall categories: Alert, Urgent, and Interrupt. However, these categories are not sufficient to report an error for error management or fault management as discussed above. These various types of errors provide several dozen individual error identifiers each representing error conditions associated with the non-volatile DIMM. At block <b>604</b>, the error identifier is used to classify the error based on the specific hardware conditions associated with the error. Such a classification may be performed in advance and the results held in a table at the memory controller such as NV error LUT <b>408</b>. The classification is based at least on whether the error condition will or will not have a deleterious effect on an executable process running on the host operating system. Such a determination is typically based on whether the error indicates that data is lost and not recoverable, for example through buffer overflows or bit errors in memory media. The mapping may also be made based on the type of effect that the error condition will have on the executable process. For example, if instruction data is lost a process may be restarted based on saved user data. Such an option may not be available if user data is lost.</p><p id="p-0059" num="0058">At block <b>606</b>, the error conditions are mapped from a first number of possible error conditions associated with the non-volatile DIMM to a second, smaller number of virtual error types. The virtual error types are selected based on virtual errors used by the data processing system's error monitoring module such as machine check architecture <b>522</b> (<figref idref="DRAWINGS">FIG. <b>5</b></figref>). In this embodiment, the virtual error types have a numbered severity level that is used for reporting to the error monitoring module at block <b>608</b>. The virtual error types are then employed to determine what error management response will be taken by the error management module.</p><p id="p-0060" num="0059">While the virtual error type is used for reporting to the error management module, the original error identifier based on the error conditions is reported to BMC <b>340</b> at block <b>610</b>. Associated data such as addresses or instructions involved may also be reported. The reporting mechanism typically loads the information to a register that is polled on behalf of BMC <b>340</b>, but other suitable reporting mechanisms are used in other embodiments. BMC <b>340</b> employs the information for error logging and performing fault management functions such as diagnosing hardware faults and repairing or reconfiguring hardware to mitigate faulty conditions.</p><p id="p-0061" num="0060">Thus, a memory controller and data processing system as described herein improves the ability of the memory controller to handle errors associated with non-volatile DIMMs on a heterogenous memory channel. The techniques herein also provide a mechanism to report non-volatile DIMM error conditions to the system error monitoring module in a way that can be used by the existing error reporting mechanisms for DIMMs. Furthermore, the techniques herein provide an error handling capability that does not depend on variable or unknown methods that may be employed by various non-volatile DIMM vendors to report errors. Instead errors are classified by the memory controller, which appropriately reports the errors to error management and/or fault management mechanisms.</p><p id="p-0062" num="0061">Memory controller <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> or any portions thereof, such as arbiter <b>238</b>, may be described or represented by a computer accessible data structure in the form of a database or other data structure which can be read by a program and used, directly or indirectly, to fabricate integrated circuits. For example, this data structure may be a behavioral-level description or register-transfer level (RTL) description of the hardware functionality in a high level design language (HDL) such as Verilog or VHDL. The description may be read by a synthesis tool which may synthesize the description to produce a netlist including a list of gates from a synthesis library. The netlist includes a set of gates that also represent the functionality of the hardware including integrated circuits. The netlist may then be placed and routed to produce a data set describing geometric shapes to be applied to masks. The masks may then be used in various semiconductor fabrication steps to produce the integrated circuits. Alternatively, the database on the computer accessible storage medium may be the netlist (with or without the synthesis library) or the data set, as desired, or Graphic Data System (GDS) II data.</p><p id="p-0063" num="0062">While particular embodiments have been described, various modifications to these embodiments will be apparent to those skilled in the art. For example, the internal architecture of memory channel controller <b>210</b> and/or power engine <b>250</b> may vary in different embodiments. Memory controller <b>200</b> may interface to other types of memory besides NVDIMM-P and DDRx, such as high bandwidth memory (HBM), RAMbus DRAM (RDRAM), and the like. While the illustrated embodiment showed each rank of memory corresponding to separate DIMMs, in other embodiments each DIMM can support multiple ranks. Further, while a heterogenous memory channel is generally supported, the heterogenous channel may be filled entirely with non-volatile DIMMs.</p><p id="p-0064" num="0063">Accordingly, it is intended by the appended claims to cover all modifications of the disclosed embodiments that fall within the scope of the disclosed embodiments.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A memory controller, comprising:<claim-text>a memory channel controller adapted to dispatch memory access commands addressable in a system memory address space to a non-volatile storage class memory (SCM) module; and</claim-text><claim-text>a non-volatile error reporting circuit operable to identify error conditions associated with the non-volatile SCM module and map the error conditions from a first number of possible error conditions associated with the non-volatile SCM module to a second, smaller number of virtual error types for reporting to an error monitoring module of a host operating system, the mapping based at least on a classification that the error condition will or will not have a deleterious effect on an executable process running on the host operating system.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The memory controller of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the non-volatile error reporting circuit is further operable to report the virtual error types to the error monitoring module of the host operating system.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The memory controller of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the non-volatile error reporting circuit is further operable to report the error conditions to a baseboard management controller of a host data processing system.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The memory controller of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the error conditions include interrupt type errors and urgent type errors.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The memory controller of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the non-volatile error reporting circuit includes a lookup table indexed at least by error codes associated with the error conditions and containing associated virtual error types for the error codes.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The memory controller of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mapping includes a determination of a type of effect that the error condition will have on the executable process.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The memory controller of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mapping includes a determination of a severity level reported to the error monitoring module.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A method, comprising:<claim-text>receiving a plurality of memory access requests addressable in a system address space;</claim-text><claim-text>dispatching commands associated with the memory access requests to a memory channel coupled to a non-volatile storage class memory (SCM) module;</claim-text><claim-text>based on information received over the memory channel, identifying error conditions associated with the memory channel;</claim-text><claim-text>mapping the error conditions from a first number of possible error conditions associated with the non-volatile SCM module to a second, smaller number of virtual error types for reporting to an error monitoring module of a host operating system, the mapping based at least on a classification that the error condition will or will not have a deleterious effect on an executable process running on the host operating system.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising reporting the virtual error types to the error monitoring module of the host operating system.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising reporting the error conditions to a baseboard management controller.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the error conditions include interrupt type errors and urgent type errors.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising indexing a lookup table at least by error codes associated with the error conditions obtaining associated virtual error types for the error codes.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the mapping includes a determination of a type of effect that the error condition will have on the executable process.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the mapping includes determining a severity level to be reported to the error monitoring module.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A data processing system, comprising:<claim-text>a central processing unit;</claim-text><claim-text>a data fabric coupled to the central processing unit; and</claim-text><claim-text>a memory controller coupled to the data fabric for fulfilling memory access requests made through the data fabric, the memory controller comprising:<claim-text>a memory channel controller adapted to receive and dispatch commands addressable in a system memory address space to a non-volatile storage class memory (SCM) module; and</claim-text><claim-text>a non-volatile error reporting circuit operable to identify error conditions associated with the non-volatile SCM module and map the error conditions from a first number of possible error conditions associated with the non-volatile SCM module to a second, smaller number of virtual error types for reporting to an error monitoring module of a host operating system, the mapping based at least on a classification that the error condition will or will not have a deleterious effect on an executable process running on the host operating system.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The data processing system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the non-volatile error reporting circuit is further operable to report the virtual error types to the error monitoring module of the host operating system.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The data processing system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising a baseboard management controller coupled to the central processing unit, wherein the non-volatile error reporting circuit is further operable to report the error conditions to a baseboard management controller.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The data processing system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the error conditions include interrupt type errors and urgent type errors.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The data processing system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the non-volatile error reporting circuit includes a lookup table indexed at least by error codes associated with the error conditions and containing associated virtual error types for the error codes.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The data processing system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the mapping includes a determination of a severity level reported to the error monitoring module.</claim-text></claim></claims></us-patent-application>
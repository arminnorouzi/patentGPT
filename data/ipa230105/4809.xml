<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004810A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004810</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17781539</doc-number><date>20191206</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>082</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e43">PARAMETER OPTIMIZATION DEVICE, PARAMETER OPTIMIZATION METHOD, AND PARAMETER OPTIMIZATION PROGRAM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NEC Corporation</orgname><address><city>Minato-ku, Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>SHIBATA</last-name><first-name>Seiya</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>NEC Corporation</orgname><role>03</role><address><city>Minato-ku, Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2019/047947</doc-number><date>20191206</date></document-id><us-371c12-date><date>20220601</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A parameter optimization device 800 optimizes input CNN structure information and outputs optimized CNN structure information, and includes stride and dilation use layer detection means 811 for extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and stride and dilation use position modification means 812 for changing the stride and dilation parameter information of the convolution layer.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="67.48mm" wi="142.83mm" file="US20230004810A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="231.06mm" wi="144.86mm" file="US20230004810A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="204.30mm" wi="111.59mm" file="US20230004810A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="192.62mm" wi="94.23mm" file="US20230004810A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="231.39mm" wi="97.62mm" file="US20230004810A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="211.33mm" wi="61.55mm" file="US20230004810A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="168.83mm" wi="148.42mm" file="US20230004810A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="224.79mm" wi="155.53mm" file="US20230004810A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="230.46mm" wi="138.01mm" file="US20230004810A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="231.90mm" wi="126.92mm" file="US20230004810A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="84.07mm" wi="155.53mm" file="US20230004810A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">This invention relates to a parameter optimization device, a parameter optimization method, and a parameter optimization program for optimizing parameters used during a convolutional neural network operation.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">Technological development related to image recognition, etc., using a multilayer neural network is actively underway. Such technology is also called deep learning. In particular, a convolutional neural network is widely used in the field of image recognition and other technologies. The convolutional neural network includes a convolutional layer, a pooling layer, and a fully connected layer, as described below. For example, in the convolutional layer, the process of convolving kernels into the entire image is performed.</p><p id="p-0004" num="0003">A set of features that are convolved into the image is obtained by the process of convolving kernels into the entire image (a process of applying a filter to the image). The set of features is also called a feature map. The feature map is obtained by applying an activation function to the convolved values. For example, in the field of image recognition, ReLU (Rectified Linear Unit) is used as an activation function.</p><p id="p-0005" num="0004">As mentioned above, in the convolution layer, the process of convolving kernels (weights and filters) into the image (input image) is performed. At that time, a number of processes are performed to multiply each pixel of the image with each weight of the kernel.</p><p id="p-0006" num="0005">Parameters for representing the convolution layer include a kernel size, an input width, an input height, the number of input channels, an output width, an output height, the number of output channels, padding, a stride, a dilation, etc.</p><p id="p-0007" num="0006">The kernel size is a parameter defining the number of pixels handled by a filter in the convolution process. For example, when the kernel size is 3, a 3&#xd7;3 pixel kernel with a height of 3 pixels&#xd7;a width of 3 pixels is used for convolution.</p><p id="p-0008" num="0007">An input width W, an input height H, the number of input channels Ci, an output width W&#x2032;, an output height H&#x2032;, and the number of output channels Co are values for defining the data size of the image, respectively. A pair of an input width W and an input height H is the input size, and a pair of an output width W&#x2032; and an output height H&#x2032; is the output size.</p><p id="p-0009" num="0008">The plane of input data defined by the input size is a screen or an input screen. The input data consists of screens of the number of input channels. The number of output channels Co among the output data size is often given explicitly as a parameter. Each of the output width W&#x2032; and output height H&#x2032; may be defined by a combination each of the input width W and input height H, and the padding and stride.</p><p id="p-0010" num="0009">The padding is a parameter defined for allowing convolution processing even when the convolution processing range defined by the kernel size exceeds the input width W and input height H. For example, in a convolution process centered on a pixel position at the edge of the screen, off-screen pixels are always referenced. Therefore, for example, the padding size is set to 1 and the value of off-screen pixels is set to a specific value (such as zero). In this way, the convolution process centered on a pixel position at the edge of the screen becomes to be allowed (refer to outside of the thick solid frames in the left sides of <figref idref="DRAWINGS">FIGS. <b>16</b>A and <b>16</b>B</figref>).</p><p id="p-0011" num="0010">For example, if the size of the padding is 0, there are no pixels corresponding to the elements of the kernel, in which case the convolution process cannot be centered on the pixel position at the edge of the screen. Therefore, the output width W&#x2032; or output height H&#x2032; is reduced from the input width W or input height H. In other words, the output size becomes smaller than the input size. In order to keep the output width W&#x2032; and output height H&#x2032; the same as the input width W and input height H, the size of the padding must be set appropriately.</p><p id="p-0012" num="0011">The stride is a parameter defining a movement interval of a kernel in the convolution process.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIGS. <b>16</b>A and <b>16</b>B</figref> are explanatory diagrams for explaining a stride. <figref idref="DRAWINGS">FIG. <b>16</b>A</figref> shows a result of convolving an input image of the input size of 4&#xd7;4 using a kernel whose size is 3. <figref idref="DRAWINGS">FIG. <b>16</b>B</figref> shows a result of convolving an input image of the input size of 5&#xd7;5 using a kernel whose size is 3. Note that the padding size is set to 1 and zero padding is applied around the input image.</p><p id="p-0014" num="0013">In the case where the stride value is 1 (<figref idref="DRAWINGS">FIG. <b>16</b>A</figref>), when the convolution operation is performed, pixels surrounded by dotted lines are referred to, and then pixels, which are off by one pixel, surrounded by broken lines are referred to. Accordingly, all pixels of the screen are used as the center position. If the padding size is properly set, the output size will match the input size. In the case where the stride value is 2 (<figref idref="DRAWINGS">FIG. <b>16</b>B</figref>), pixels surrounded by dotted lines are referred to, and then pixels, which are off by two pixels, surrounded by broken lines are referred to. The output width W&#x2032; is &#xbd; of the input width W, and the output height H&#x2032; is &#xbd; of the input height H &#xbd;. In other words, the output size is &#xbc; of the input size.</p><p id="p-0015" num="0014">The dilation is a parameter defining an interval of pixels referred in the convolution process.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is an explanatory diagram for explaining a dilation. Pixels (shaded area) referred to when D=1 are shown in the left side of <figref idref="DRAWINGS">FIG. <b>17</b></figref>. The pixels referred to when D=2 are shown in the center of <figref idref="DRAWINGS">FIG. <b>17</b></figref>. The pixels referred to when D=3 in the right side of <figref idref="DRAWINGS">FIG. <b>17</b></figref>. Note that D indicates a dilation value. In all cases, the kernel size is 3.</p><p id="p-0017" num="0016">When the dilation value is 1 (the left side of <figref idref="DRAWINGS">FIG. <b>17</b></figref>), the pixel at the center position and the pixels one pixel next to the pixel at the center position, i.e., the surrounding 8 pixels are referred to.</p><p id="p-0018" num="0017">When the dilation value is 2 (the center of <figref idref="DRAWINGS">FIG. <b>17</b></figref>), two neighboring pixels from the pixel at the center position are referred to. In other words, there is an interval between the referred pixels.</p><p id="p-0019" num="0018">By using the dilation, the convolution processing range can be expanded without increasing the amount of operations in the convolution process. For example, when the kernel size is 3 and the dilation value is 2, the rough range of regions referred to in the convolution process is equivalent to that in the convolution process using the kernel whose size is 5 and the dilation whose value is 1. When the dilation value is 3 (the right side of <figref idref="DRAWINGS">FIG. <b>17</b></figref>), the rough range of regions referred to in the convolution process is equivalent to that in the convolution process using the kernel whose size is 7 and the dilation whose value is 1.</p><p id="p-0020" num="0019">Patent literature 1 describes an information processing device that changes parameters of a neural network. However, that information processing device does not handle a dilation as a parameter.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0021" num="0020">PTL 1: Japanese Patent No. 6555411</p><heading id="h-0005" level="1">SUMMARY OF INVENTION</heading><heading id="h-0006" level="1">Technical Problem</heading><p id="p-0022" num="0021">As mentioned above, the deep learning, especially the convolutional layer operation, requires a huge number of multiplications. The huge number of multiplications requires large-scale hardware or a processor with powerful operational capability. When using slow devices, a way to get the devices to work at high speed, by reducing the load of the operation, is required.</p><p id="p-0023" num="0022">It is an object of the present invention to provide a parameter optimization device, a parameter optimization method, and a parameter optimization program, for optimizing parameters used during convolutional neural network operations, that can reduce the number of multiplications in a convolutional layer when the convolutional neural network is operated.</p><heading id="h-0007" level="1">Solution to Problem</heading><p id="p-0024" num="0023">The parameter optimization device that optimizes input CNN structure information and outputs optimized CNN structure information stride and dilation use layer detection means for extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and stride and dilation use position modification means for changing the stride and dilation parameter information of the convolution layer.</p><p id="p-0025" num="0024">The parameter optimization method for optimizing input CNN structure information and outputting optimized CNN structure information according to the present invention includes extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and changing the stride and dilation parameter information of the convolution layer.</p><p id="p-0026" num="0025">The parameter optimization program for optimizing input CNN structure information and outputting optimized CNN structure information according to the present invention causes a computer to execute a process of extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and a process of changing the stride and dilation parameter information of the convolution layer.</p><heading id="h-0008" level="1">ADVANTAGEOUS EFFECTS OF INVENTION</heading><p id="p-0027" num="0026">According to the present invention, the number of multiplications in a convolutional layer can be reduced during convolutional neural network operations.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0028" num="0027">[<figref idref="DRAWINGS">FIG. <b>1</b></figref>] It depicts a block diagram showing an example of a parameter optimization device of the first example embodiment.</p><p id="p-0029" num="0028">[<figref idref="DRAWINGS">FIG. <b>2</b></figref>] It depicts a block diagram of an example of a computer including a CPU.</p><p id="p-0030" num="0029">[<figref idref="DRAWINGS">FIG. <b>3</b></figref>] It depicts an explanatory diagram showing an example of an optimization method of parameter values in the first example embodiment.</p><p id="p-0031" num="0030">[<figref idref="DRAWINGS">FIG. <b>4</b></figref>] It depicts an explanatory diagram showing an example of an input image.</p><p id="p-0032" num="0031">[<figref idref="DRAWINGS">FIG. <b>5</b></figref>] It depicts an explanatory diagram showing an example of an optimization method of parameter values in the first example embodiment.</p><p id="p-0033" num="0032">[<figref idref="DRAWINGS">FIG. <b>6</b></figref>] It depicts a flowchart showing an example of an operation of a parameter optimization device of the first example embodiment.</p><p id="p-0034" num="0033">[<figref idref="DRAWINGS">FIG. <b>7</b></figref>] It depicts an explanatory diagram showing another example of an optimization method of parameter values in the first example embodiment.</p><p id="p-0035" num="0034">[<figref idref="DRAWINGS">FIG. <b>8</b></figref>] It depicts an explanatory diagram showing another example of an optimization method of parameter values in the first example embodiment.</p><p id="p-0036" num="0035">[<figref idref="DRAWINGS">FIG. <b>9</b></figref>] It depicts an explanatory diagram showing another example of an optimization method of parameter values in the first example embodiment.</p><p id="p-0037" num="0036">[<figref idref="DRAWINGS">FIG. <b>10</b></figref>] It depicts a flowchart showing another example of an operation of a parameter optimization device of the first example embodiment.</p><p id="p-0038" num="0037">[<figref idref="DRAWINGS">FIG. <b>11</b></figref>] It depicts a block diagram showing an example of a parameter optimization device of the second example embodiment.</p><p id="p-0039" num="0038">[<figref idref="DRAWINGS">FIG. <b>12</b></figref>] It depicts a flowchart showing an operation of modifying a shortcut process performed by the parameter optimization device of the second example embodiment.</p><p id="p-0040" num="0039">[<figref idref="DRAWINGS">FIG. <b>13</b></figref>] It depicts an explanatory diagram for explaining a general shortcut process.</p><p id="p-0041" num="0040">[<figref idref="DRAWINGS">FIG. <b>14</b></figref>] It depicts an explanatory diagram for explaining a shortcut process including a shortcut addressing process.</p><p id="p-0042" num="0041">[<figref idref="DRAWINGS">FIG. <b>15</b></figref>] It depicts a block diagram showing the main part of a parameter optimization device.</p><p id="p-0043" num="0042">[<figref idref="DRAWINGS">FIG. <b>16</b>A</figref>] It depicts an explanatory diagram for explaining a stride.</p><p id="p-0044" num="0043">[<figref idref="DRAWINGS">FIG. <b>16</b>B</figref>] It depicts an explanatory diagram for explaining a stride.</p><p id="p-0045" num="0044">[<figref idref="DRAWINGS">FIG. <b>17</b></figref>] It depicts an explanatory diagram for explaining a dilation.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0046" num="0045">First, an overview of example embodiments will be given. The connecting line between blocks in each figure indicates a bidirectional or unidirectional line. The unidirectional arrows are a straightforward indication of the direction of signal (data) flow, and do not exclude bidirectionality.</p><heading id="h-0011" level="1">Example Embodiment 1</heading><p id="p-0047" num="0046">Hereinafter, the first example embodiment of the present invention is explained with reference to the drawings. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of a parameter optimization device <b>200</b> of the first example embodiment. The parameter optimization device <b>200</b> of the first example embodiment includes two processing blocks described in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. That is, the parameter optimization device <b>200</b> includes a stride and dilation use layer detection unit <b>211</b> and a stride and dilation use position modification unit <b>212</b>.</p><p id="p-0048" num="0047">The stride and dilation use layer detection unit <b>211</b> extracts parameter information of stride and dilation from input CNN structure information <b>100</b>. For example, the stride and dilation use layer detection unit <b>211</b> obtains each parameter value from the parameter definition file that exists in the CNN structure information <b>100</b>.</p><p id="p-0049" num="0048">The stride and dilation use position modification unit <b>212</b> optimizes a stride value and a dilation value by modifying them based on the parameter information of stride and dilation extracted by the stride and dilation use layer detection unit <b>211</b> according to a logic described below. The stride and dilation use position modification unit <b>212</b> outputs the optimized CNN structure information <b>300</b> to the CNN execution environment connected to the parameter optimization device <b>200</b>.</p><p id="p-0050" num="0049">Each component in the parameter optimization device <b>200</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may be configured with a single piece of hardware, but can also be configured with a single piece of software. Each component may be configured with a plurality of pieces of hardware or a plurality of pieces of software. Further, part of the components may be configured with hardware and the other part with software.</p><p id="p-0051" num="0050">When each component in the parameter optimization device <b>200</b> is realized by a computer having a processor such as a central processing unit (CPU), a memory, etc., the parameter optimization device <b>200</b> can be realized a computer having a CPU shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The CPU <b>1000</b> executes a process (parameter optimization process) in accordance with a program stored in a storage device <b>1001</b> to realize the functions of the stride and dilation use layer detection unit <b>211</b> and the stride and dilation use position modification unit <b>212</b> in the parameter optimization device <b>200</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0052" num="0051">The storage device <b>1001</b> is, for example, a non-transitory computer readable media. The non-transitory computer readable medium is one of various types of tangible storage media. Specific examples of the non-transitory computer readable media include a magnetic storage medium (for example, flexible disk, magnetic tape, hard disk), a magneto-optical storage medium (for example, magneto-optical disc), a compact disc-read only memory (CD-ROM), a compact disc-recordable (CD-R), a compact disc-rewritable (CD-R/W), and a semiconductor memory (for example, a mask ROM, a programmable ROM (PROM), an erasable PROM (EPROM), a flash ROM).</p><p id="p-0053" num="0052">The program may be stored in various types of transitory computer readable media. The transitory computer readable medium is supplied with the program through, for example, a wired or wireless communication channel, or, through electric signals, optical signals, or electromagnetic waves.</p><p id="p-0054" num="0053">The memory <b>1002</b> is a storage means implemented by a RAM (Random Access Memory), for example, and temporarily stores data when the CPU <b>1000</b> executes processing. It can be assumed that a program held in the storage device <b>1001</b> or a temporary computer readable medium is transferred to the memory <b>1002</b> and the CPU <b>1000</b> executes processing based on the program in the memory <b>1002</b>.</p><p id="p-0055" num="0054">Hereinafter, an optimization method in the first example embodiment will be explained with reference to the drawings.</p><p id="p-0056" num="0055">The stride and dilation use layer detection unit <b>211</b> analyzes the layer structure and the parameters that each layer has, based on the input CNN structure information <b>100</b>.</p><p id="p-0057" num="0056">In the case where multiple convolution layers are used, when the processing of a layer, that is not a convolution layer, used between two convolution layers does not use multiple pixels (neurons) and does not change a position relationship of the pixels, the stride and dilation use layer detection unit <b>211</b> ignores the presence of the layer. In other words, the stride and dilation use layer detection unit <b>211</b> determines that the two convolution layers are adjacent. For example, an activation function such as ReLU, and BatchNormalization and DropOut used during inference are per-pixel, i.e. per-neuron multiply accumulation process. Accordingly, multiple pixels are not used and the positional relationship between pixels is not changed. Therefore, in this optimization, layers that are not convolution layers can be ignored. On the other hand, for example, the linear layer (fully connected layer) cannot be ignored because a multiply accumulation process using values of all pixels is performed for the layer, ignoring a positional relationship between pixels. In addition, when a pooling layer is present, the pooling layer cannot be ignored.</p><p id="p-0058" num="0057">The optimization of this example embodiment is applied to multiple adjacent convolution layers obtained by the above method.</p><p id="p-0059" num="0058">The stride and dilation use layer detection unit <b>211</b> brings parameter information of the adjacent convolution layers into three-dimensional information of the layer number (Layer), the dilation (Dilation), and the stride (Stride) as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. <figref idref="DRAWINGS">FIG. <b>4</b></figref> an explanatory diagram showing an input image (bold rectangle) with an input size of 11&#xd7;11. The area enclosed by a dotted box shows a range that is firstly convolved with one kernel. The area enclosed by a dashed box shows a range that is secondly convolved with the kernel. The area enclosed by a chain line box shows a range that is the next convolved with the kernel. The rectangles with halftone dots show pixels of interest for illustrative purposes. The shaded rectangles (shaded areas) show pixels referred to in the convolution process. The size of the padding is 1. Layer (layer number) may also mean the layer itself.</p><p id="p-0060" num="0059">In the upper example shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the dilation value is 2 and the stride value is 2 in Layer <b>3</b>. In such a case, as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the only pixels referred to in the convolution process are the shaded pixels. White areas (pixels other than shaded rectangles or rectangles with halftone dots) are present but never used.</p><p id="p-0061" num="0060">In other words, the white rectangles of input of the Layer 3, which accounts for &#xbe; of the total, are not referred to in the convolution process and is not needed. Therefore, &#xbe; of output of Layer <b>2</b> is unnecessary. The convolution process for these unnecessary pixels is useless.</p><p id="p-0062" num="0061">In such a network, the stride and dilation use position modification unit <b>212</b> changes the stride value in Layer <b>2</b> from 1 to 2. It can be changed so that only the necessary areas in Layer <b>3</b> is computed, as shown in the bottom row in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In addition, since the pixels to be referred to in the Layer <b>3</b> convolution process will be adjacent to each other, the dilation value can be 1. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the numbers of the areas modified by the stride and dilation use position modification unit <b>212</b> are underlined.</p><p id="p-0063" num="0062">In summary, the stride and dilation use position modification unit <b>212</b> changes the stride value in Layer <b>2</b> from 1 to 2, and the dilation value in Layer <b>3</b> from 2 to 1, and change the stride value from 2 to 1. By this, the layer with a dilation value of 2 is no longer needed and the stride can be moved to the previous layer, while the output of Layer <b>3</b> is maintained. Consequently, the stride value of Layer <b>2</b> becomes to be 2, and the calculation amount in each of Layer <b>2</b> and Layer <b>3</b> is reduced to &#xbc;.</p><p id="p-0064" num="0063">As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, this optimization process operates to propagate changes to the previous layer as much as possible. In the example illustrated at the upper row in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, first, at Layers <b>3</b> and <b>6</b>, the stride can be moved to the previous layer as described above. As a result of the movement of the stride from Layer <b>6</b> to Layer <b>5</b>, such a situation arises as both the dilation value and the stride value are 2. Therefore, the optimization can be applied again (refer to the second row in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). After that, the same optimization can then be applied to Layer <b>4</b> (the second row from the bottom in <figref idref="DRAWINGS">FIG. <b>5</b></figref>). Finally, the stride value of 2 moves to Layer <b>3</b> (refer to the lower row in <figref idref="DRAWINGS">FIG. <b>5</b></figref>).</p><p id="p-0065" num="0064">In other words, the optimization in this example embodiment can be applied from a deeper layer to a shallower layer in a phased manner. As shown in the flowchart shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the optimization can be applied repeatedly until there are no more layers where both the stride value and dilation are 2 throughout all layers.</p><p id="p-0066" num="0065">In the example shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the CNN structure information <b>100</b> is input to the parameter optimization device <b>200</b> (step S<b>401</b>). The stride and dilation use layer detection unit <b>211</b> extracts layers in which parameters of stride and dilation are used from the input CNN structure information <b>100</b> (step S<b>402</b>).</p><p id="p-0067" num="0066">Then, the stride and dilation use position modification unit <b>212</b> changes the stride value and the dilation value, based on information of the stride value and the dilation value extracted by the stride and dilation use layer detection unit <b>211</b>, according to the logic described above (step S<b>403</b>).</p><p id="p-0068" num="0067">When there are still layers for which the greatest common divisor of the two parameters g (gcd (Stride, Dilation)) is greater than 1, processes of step S<b>402</b> and step S<b>403</b> are executed again.</p><p id="p-0069" num="0068">When the greatest common divisor g (gcd (Stride, Dilation)) of the two parameters in all layers reaches 1, at step S<b>405</b>, the parameter optimization device <b>200</b> outputs the modified CNN structure information <b>300</b>.</p><p id="p-0070" num="0069">To further generalize, not only when both the stride and the dilation are 2, but also when the greatest common divisor g (gcd (Stride, Dilation)) of the two parameters is greater than 1, the stride value and the dilation value can be changed as follows.</p><p id="p-0071" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>g=gcd </i>(Stride, Dilation)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0072" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>S</i>&#x2032;(<i>L</i>)=<i>S</i>(<i>L</i>)/<i>g </i><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0073" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>S</i>&#x2032;(<i>L&#x2212;</i>1)=<i>S</i>(<i>L</i>&#x2212;1)&#xd7;<i>g </i><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0074" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>D</i>&#x2032;(<i>L</i>)=<i>D</i>(<i>L</i>)/<i>g </i>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0075" num="0070">where S (L) indicates the stride value of the layer L and D (L) indicates the dilation value of the layer L. S (L&#x2212;1) indicates the stride value of the layer (L&#x2212;1). S&#x2032; indicates the stride value after the change and D&#x2032; indicates the dilation value after the change.</p><p id="p-0076" num="0071">For example, in the example shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the stride value is 2 and the dilation value is 4 in Layer <b>3</b> of the CNN. The stride and dilation use position modification unit <b>212</b> changes the stride value in Layer <b>2</b> from 1 to 2, changes the stride value in Layer <b>3</b> from 2 to 1, and changes the dilation value from 4 to 2, using g=gcd (2, 4)=2.</p><p id="p-0077" num="0072">In the example shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the stride value is 4 and the dilation value is 2. In other words, the stride value and the dilation value are reversed from the example shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The stride and dilation use position modification unit <b>212</b> changes the stride value in Layer <b>2</b> from 1 to 2, changes the stride value in Layer <b>3</b> from 4 to 2, and changes the dilation value from 2 to 1, using g=gcd(4, 2)=2.</p><p id="p-0078" num="0073">In the example shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the stride value and the dilation value are 4, respectively. The stride and dilation use position modification unit <b>212</b> changes the stride value in Layer <b>2</b> from 1 to 4, changes the stride value in Layer <b>3</b> from 4 to 1, and changes the dilation value from 1 to 1, using g=gcd(4, 4)=4.</p><p id="p-0079" num="0074">Based on the above concept, the optimization in this example embodiment can be performed as shown in the flowchart shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. In other words, optimization can be applied to all layers by applying the optimization process once to each layer in turn from the deepest layer to the shallowest layer.</p><p id="p-0080" num="0075">In the example shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the CNN structure <b>100</b> is input to the parameter optimization device <b>200</b> (step S<b>501</b>). The parameter optimization device <b>200</b> initializes the layer number n of the layer to be processed (step S<b>502</b>). Specifically, when the total number of all layers is N, the layer number n is set to (N&#x2212;1).</p><p id="p-0081" num="0076">The processes of step S<b>503</b> and step S<b>504</b> are the same as the processes of step S<b>402</b> and step S<b>403</b> described above. However, the processes of step S<b>502</b> and step S<b>503</b> are executed on a single layer.</p><p id="p-0082" num="0077">The processes of step S<b>503</b> and step S<b>504</b> are repeated in order from the deep layer to the shallow layer until processes for all layers have been processed (steps S<b>505</b> and S<b>507</b>).</p><p id="p-0083" num="0078">When the processes are completed for all layers, the parameter optimization device <b>200</b> outputs the modified CNN structure information <b>300</b> (step S<b>506</b>).</p><p id="p-0084" num="0079">If the assumed maximum values of stride and dilation (the maximum value intended to be applied) are less than or equal to a predetermined value (e.g., 6), the above equation (1) means that both the stride value and the dilation value in a given layer are divided by 2 when each of the stride value and the dilation value is a multiple of 2. The equation (1) also means to multiply the stride value for the layer that is one-level shallower than the given layer by 2.</p><p id="p-0085" num="0080">As explained above, the parameter optimization device <b>200</b> of this example embodiment can change the layer to which the stride process is applied to the layer one level before that layer, when both the stride value and the dilation value, that are the convolutional parameters are simultaneously greater than 1 in a certain layer of a convolutional neural network. Therefore, the parameter optimization device <b>200</b> of this example embodiment can reduce processing amount in the given layer and the layer one level before the given layer.</p><p id="p-0086" num="0081">In addition, the effect of improving performance is obtained in device or execution apparatus that are not good at processing dilation that is larger than by also reducing the dilation by the parameter optimization device <b>200</b> of this example embodiment.</p><heading id="h-0012" level="1">Example Embodiment 2</heading><p id="p-0087" num="0082">In the case where a shortcut structure used by ResNet and others exists in a CNN model, when a stride move is applied due to the optimization in the above example embodiment, it may be necessary to modify the processing of the shortcut structure to accommodate the move.</p><p id="p-0088" num="0083">Hereinafter, the second example embodiment of the present invention will be explained with reference to the drawings. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram showing an example of a parameter optimization device <b>201</b> of the second example embodiment. The parameter optimization device <b>201</b> of the second example embodiment includes four processing blocks as shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. That is, the parameter optimization device <b>201</b> includes a stride and dilation use layer detection unit <b>211</b>, a stride and dilation use position modification unit <b>212</b>, a shortcut addressing necessity determination unit <b>213</b>, and a shortcut addressing process introduction unit <b>214</b>. Note that the other components except for the shortcut addressing necessity determination unit <b>213</b> and the shortcut addressing process introduction unit <b>214</b> are the same as those in the configuration of the parameter optimization device <b>200</b> of the first example embodiment.</p><p id="p-0089" num="0084">The shortcut addressing necessity determination unit <b>213</b> determines whether or not shortcut processing exists. The shortcut addressing necessity determination unit <b>213</b> determines whether or not the change by the stride and dilation use position modification unit <b>212</b> requires introduction of a new shortcut structure.</p><p id="p-0090" num="0085">The shortcut addressing process introduction unit <b>214</b> adds a new shortcut structure that is required as a result of the change of the stride value and the dilation value to the CNN model.</p><p id="p-0091" num="0086">The parameter optimization device <b>201</b> performs the same processing as the parameter optimization device <b>200</b> of the first example embodiment, and then, executes the process shown in the flowchart in <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0092" num="0087"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart showing an operation of modifying a shortcut process performed by the parameter optimization device <b>201</b> of the second example embodiment.</p><p id="p-0093" num="0088">When the CNN structure after the parameter change (equivalent to the output CNN structure in the first example embodiment) is input to the parameter optimization device <b>201</b> (step S<b>601</b>), the shortcut addressing necessity determination unit <b>213</b> determines whether or not the change of parameters by the stride and dilation use position modification unit <b>212</b> requires introduction of a new shortcut structure. As an example, the shortcut addressing necessity determination unit <b>213</b> determines whether or not dimensionalities of the input of the pair and the output of the previous pair are the same, regarding three layers as a pair (Step S<b>602</b>). The dimensionality is each dimensionality of the width W, the height H, the number of channels C, etc.</p><p id="p-0094" num="0089">In step S<b>602</b>, when dimensionalities are different, the shortcut addressing process introduction unit <b>214</b> adds a process corresponding to a new shortcut structure that is required as a result of the change of the stride value and the dilation value to the CNN model (step S<b>603</b>). Then, the parameter optimization device <b>201</b> performs the shortcut process including a shortcut addressing process (step S<b>604</b>). A specific introduction method is described below. On the other hand, when dimensionalities match, the parameter optimization device <b>201</b> performs the normal shortcut process.</p><p id="p-0095" num="0090">After the shortcut process has been performed, the parameter optimization device <b>201</b> outputs the CNN structure information <b>300</b> (step S<b>605</b>).</p><p id="p-0096" num="0091"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is an explanatory diagram for explaining a general shortcut process. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is an explanatory diagram for explaining a shortcut process including a shortcut addressing process.</p><p id="p-0097" num="0092">In the network structure shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, three layers are considered a set. Specifically, Layers <b>1</b>, <b>2</b>, and <b>3</b> are the first set, Layers <b>4</b>, <b>5</b>, and <b>6</b> are the second set, and Layers <b>7</b>, <b>8</b>, and <b>9</b> are the third set. The output result of the previous set are added to the output of the current set. This is called a shortcut.</p><p id="p-0098" num="0093">In general, in a shortcut, when the dimensionality (each of W, H, C) of the input and the dimensionality of output are the same, the process of simply adding them together is performed. When the dimensionalities are different, a new convolution process is often introduced so as to eliminate the difference in dimensionalities. For example, a stride is used so as to eliminate differences in W and H, and a 1&#xd7;1 convolution is used so as to eliminate difference in C.</p><p id="p-0099" num="0094">In the example shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, in Layers <b>1</b>, <b>2</b>, and <b>3</b> as the first set, the number of output channels is 64 and the number of input channels is unknown. When the input to Layer <b>1</b> is an image of 3 channels, a 1&#xd7;1 convolution process with 3 input channels and 64 output channels is introduced to a shortcut.</p><p id="p-0100" num="0095">Similarly, in Layers <b>7</b>, <b>8</b>, and <b>9</b> as the third set, the input size to the set and the output size are different (size ratio is 4:1) because a stride is used in Layer <b>7</b>. The number of input channels is 64 and the number of output channels is 128, which are different. Therefore, a 1&#xd7;1 convolution process with the stride value is 2, 64 input channels, and 128 output channels is introduced to a shortcut.</p><p id="p-0101" num="0096">On the other hand, in Layers <b>4</b>, <b>5</b>, and <b>6</b> as the second set, the number of input channels matches the number of output channels at 64. In addition, W and H do not change because the stride values of Layers <b>4</b>, <b>5</b>, and <b>6</b> are all 1. Therefore, introducing a 1&#xd7;1 convolution process, etc. to a shortcut is not required (None).</p><p id="p-0102" num="0097">However, when focusing on Layer <b>7</b>, the stride value and the dilation value are both 2, which can be optimized (refer to the upper row in <figref idref="DRAWINGS">FIG. <b>14</b></figref>). In other words, the stride and dilation use position modification unit <b>212</b> changes the stride value of Layer <b>6</b> to 2, the stride value of Layer <b>7</b> to 1, and the dilation value to 2 (refer to the lower row in <figref idref="DRAWINGS">FIG. <b>14</b></figref>).</p><p id="p-0103" num="0098">When focusing on the second set of Layers <b>4</b>, <b>5</b>, and <b>6</b> after each parameter has been changed, the dimensionalities of W and H will be different in the input and the output. Therefore, it is necessary to introduce a process to match dimensionalities, such as the process in step S<b>603</b> in the flowchart shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0104" num="0099">Note that for Layers <b>4</b>, <b>5</b>, and <b>6</b>, dimensionalities of W and H are different but dimensionalities of C are the same. Therefore, the process that should be introduced is a thinning process of pixels whose stride value corresponds to 2.</p><p id="p-0105" num="0100">The shortcut addressing process may be implemented in any way as long as the modification of shortcut in response to the parameter change can be implemented. For example, when the framework for used deep learning supports only limited processing, as an example, if a layer is not defined (provided) to implement only pixel thinning, a 1&#xd7;1 convolution process may be substituted. The values of the weights for the 1&#xd7;1 convolution are expressed by a square matrix with a dimensionality (number of input channels x number of output channels). In this case, to avoid transforming input value, in the value of the square matrix, only diagonal components should be 1 and all others should be 0. In other words, the square matrix should be a unitary matrix. In the optimization in this example embodiment, the number of input channels and the number of output channels are not increased or decreased, respectively.</p><p id="p-0106" num="0101">As described, when the shortcut process before the shortcut addressing process (the shortcut process before the modification) does not change the input value (the values of W, H) the shortcut addressing process introduction unit <b>214</b> introduces a thinning process with a stride whose value is equal to the stride value after the change by the stride and dilation use position modification unit <b>212</b>, or a 1&#xd7;1 convolution process such that the stride has the same value as the stride value after the change and the weights are represented by a unit matrix. When the shortcut process before the shortcut addressing process includes a 1&#xd7;1 convolution process, the shortcut addressing process introduction unit <b>214</b> changes the stride value of the 1&#xd7;1 convolution process to a value multiplied by the stride value after the change by the stride and dilation use position modification unit <b>212</b>.</p><p id="p-0107" num="0102">As explained above, when there is a shortcut structure used by ResNet and others in the input CNN model, the parameter optimization device <b>201</b> in this example embodiment introduces and executes a process addressing the shortcut structure. As a result, an amount of CNN processing can be reduced even when a shortcut structure exists.</p><p id="p-0108" num="0103"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a block diagram showing the main part of the parameter optimization device. The parameter optimization device <b>800</b> optimizes input CNN structure information and outputs optimized CNN structure information, and comprises stride and dilation use layer detection means <b>811</b> (in the example embodiments, realized by the stride and dilation use layer detection unit <b>211</b>) for extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and stride and dilation use position modification means (in the example embodiments, realized by the stride and dilation use position modification unit <b>212</b>) <b>812</b> for changing the stride and dilation parameter information of the convolution layer.</p><p id="p-0109" num="0104">A part of or all of the above example embodiment may also be described as, but not limited to, the following supplementary notes.</p><p id="p-0110" num="0105">(Supplementary note 1) A parameter optimization device that optimizes input CNN structure information and outputs optimized CNN structure information, comprising:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0106">stride and dilation use layer detection means for extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and</li>        <li id="ul0002-0002" num="0107">stride and dilation use position modification means for changing the stride and dilation parameter information of the convolution layer.</li>    </ul>    </li></ul></p><p id="p-0111" num="0108">(Supplementary note 2) The parameter optimization device according to Supplementary note 1, wherein<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0109">until there are no more pairs of changeable stride and dilation parameters for all convolution layers in the CNN structure,</li>        <li id="ul0004-0002" num="0110">the stride and dilation use layer detection means repeatedly executes a process for extracting the parameter information, and the stride and dilation use position modification means repeatedly executes a process for changing the parameter information.</li>    </ul>    </li></ul></p><p id="p-0112" num="0111">(Supplementary note 3) The parameter optimization device according to Supplementary note 1, wherein<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0112">the stride and dilation use layer detection means executes a process for extracting the parameter information for each layer in the convolution layer in the CNN structure while switching the layer from a deep layer to a shallow layer, and</li>        <li id="ul0006-0002" num="0113">the stride and dilation use position modification means executes a process for changing the parameter information for each layer in the convolution layer in the CNN structure while switching the layer from a deep layer to a shallow layer.</li>    </ul>    </li></ul></p><p id="p-0113" num="0114">(Supplementary note 4) The parameter optimization device according to any one of Supplementary notes 1 to 3, wherein<ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0000">    <ul id="ul0008" list-style="none">        <li id="ul0008-0001" num="0115">when the greatest common divisor of a stride value and a dilation value for a certain convolution layer is greater than 1, the stride and dilation use position modification means changes the stride value for the certain convolution layer to a value obtained by dividing the stride value by the greatest common divisor, the dilation value for the certain convolution layer to a value obtained by dividing the dilation value by the greatest common divisor, and a stride value for the convolution layer that is one-level shallower than the certain convolution layer to a value obtained by multiplying the stride value by the greatest common divisor.</li>    </ul>    </li></ul></p><p id="p-0114" num="0116">(Supplementary note 5) The parameter optimization device according to any one of Supplementary notes 1 to 3, wherein<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0000">    <ul id="ul0010" list-style="none">        <li id="ul0010-0001" num="0117">when both a stride value and a dilation value for a certain layer are 2, the stride and dilation use position modification means changes the stride value for the certain convolution layer to a value obtained by dividing the stride value by 2, the dilation value for the certain convolution layer to a value obtained by dividing the dilation value by 2, and a stride value for the convolution layer that is one-level shallower than the certain layer to a value obtained by multiplying the stride value by 2.</li>    </ul>    </li></ul></p><p id="p-0115" num="0118">(Supplementary note 6) The parameter optimization device according to any one of Supplementary notes 1 to 5, further comprising<ul id="ul0011" list-style="none">    <li id="ul0011-0001" num="0000">    <ul id="ul0012" list-style="none">        <li id="ul0012-0001" num="0119">shortcut addressing necessity determination means for determining whether a modification of a shortcut process due to a result of changing the stride and dilation is required or not in the case where the CNN structure includes the shortcut process, and</li>        <li id="ul0012-0002" num="0120">shortcut addressing process introduction means for modifying the shortcut process when the shortcut addressing necessity determination means determines that the modification of the shortcut process is required.</li>    </ul>    </li></ul></p><p id="p-0116" num="0121">(Supplementary note 7) The parameter optimization device according to Supplementary note 6, wherein<ul id="ul0013" list-style="none">    <li id="ul0013-0001" num="0000">    <ul id="ul0014" list-style="none">        <li id="ul0014-0001" num="0122">the shortcut addressing necessity determination means determines that the modification of the shortcut process is required, when the change of the stride by the stride and dilation use position modification means occurs in two convolution layers across an addition process in the shortcut process.</li>    </ul>    </li></ul></p><p id="p-0117" num="0123">(Supplementary note 8) The parameter optimization device according to Supplementary note 6 or 7, wherein<ul id="ul0015" list-style="none">    <li id="ul0015-0001" num="0000">    <ul id="ul0016" list-style="none">        <li id="ul0016-0001" num="0124">the shortcut addressing process introduction means</li>        <li id="ul0016-0002" num="0125">introduces a thinning process with the stride whose value is equal to the stride value after the change by the stride and dilation use position modification means, or a 1 xl convolution process such that the stride has the same value as the stride value after the change and the weights are represented by a unit matrix, when the shortcut process before the modification does not change input value, and</li>        <li id="ul0016-0003" num="0126">changes the stride of the 1&#xd7;1 convolution process to a value multiplied by the stride value after the change by the stride and dilation use position modification means, when the shortcut process before the modification includes the 1&#xd7;1 convolution process.</li>    </ul>    </li></ul></p><p id="p-0118" num="0127">(Supplementary note 9) A parameter optimization method for optimizing input CNN structure information and outputting optimized CNN structure information, comprising:<ul id="ul0017" list-style="none">    <li id="ul0017-0001" num="0000">    <ul id="ul0018" list-style="none">        <li id="ul0018-0001" num="0128">extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and</li>        <li id="ul0018-0002" num="0129">changing the stride and dilation parameter information of the convolution layer.</li>    </ul>    </li></ul></p><p id="p-0119" num="0130">(Supplementary note 10) The parameter optimization method according to Supplementary note 9, further comprising<ul id="ul0019" list-style="none">    <li id="ul0019-0001" num="0000">    <ul id="ul0020" list-style="none">        <li id="ul0020-0001" num="0131">determining whether a modification of a shortcut process due to a result of changing the stride and dilation is required or not in the case where the CNN structure includes the shortcut process, and</li>        <li id="ul0020-0002" num="0132">when determining that the modification of the shortcut process is required, modifying the shortcut process.</li>    </ul>    </li></ul></p><p id="p-0120" num="0133">(Supplementary note 11) A computer readable recording medium storing a parameter optimization program for optimizing input CNN structure information and outputting optimized CNN structure information, wherein<ul id="ul0021" list-style="none">    <li id="ul0021-0001" num="0000">    <ul id="ul0022" list-style="none">        <li id="ul0022-0001" num="0134">the program causes a processor to execute:</li>        <li id="ul0022-0002" num="0135">a process of extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and</li>        <li id="ul0022-0003" num="0136">a process of changing the stride and dilation parameter information of the convolution layer.</li>    </ul>    </li></ul></p><p id="p-0121" num="0137">(Supplementary note 12) The recording medium according to Supplementary note 11, wherein<ul id="ul0023" list-style="none">    <li id="ul0023-0001" num="0000">    <ul id="ul0024" list-style="none">        <li id="ul0024-0001" num="0138">the program causes a processor to further execute</li>        <li id="ul0024-0002" num="0139">a process of determining whether a modification of a shortcut process due to a result of changing the stride and dilation is required or not in the case where the CNN structure includes the shortcut process, and</li>        <li id="ul0024-0003" num="0140">a process of modifying the shortcut process when determining that the modification of the shortcut process is required.</li>    </ul>    </li></ul></p><p id="p-0122" num="0141">(Supplementary note 13) A parameter optimization program for optimizing input CNN structure information and outputting optimized CNN structure information, causing a computer to execute:<ul id="ul0025" list-style="none">    <li id="ul0025-0001" num="0000">    <ul id="ul0026" list-style="none">        <li id="ul0026-0001" num="0142">a process of extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and</li>        <li id="ul0026-0002" num="0143">a process of changing the stride and dilation parameter information of the convolution layer.</li>    </ul>    </li></ul></p><p id="p-0123" num="0144">(Supplementary note 14) The parameter optimization program according to Supplementary note 13, causing the computer to further execute a process of determining whether a modification of a shortcut process due to a result of changing the stride and dilation is required or not in the case where the CNN structure includes the shortcut process, and a process of modifying the shortcut process when determining that the modification of the shortcut process is required.</p><p id="p-0124" num="0145">Although the invention of the present application has been described above with reference to the example embodiment, the present invention is not limited to the above example embodiment. Various changes can be made to the configuration and details of the present invention that can be understood by those skilled in the art within the scope of the present invention.</p><heading id="h-0013" level="1">REFERENCE SIGNS LIST</heading><p id="p-0125" num="0000"><ul id="ul0027" list-style="none">    <li id="ul0027-0001" num="0146"><b>100</b> Input CNN Structure</li>    <li id="ul0027-0002" num="0147"><b>200</b> Parameter optimization device</li>    <li id="ul0027-0003" num="0148"><b>211</b> Stride and dilation use layer detection unit</li>    <li id="ul0027-0004" num="0149"><b>212</b> Stride and dilation use position modification unit</li>    <li id="ul0027-0005" num="0150"><b>213</b> Shortcut addressing necessity determination unit</li>    <li id="ul0027-0006" num="0151"><b>214</b> Shortcut addressing process introduction unit</li>    <li id="ul0027-0007" num="0152"><b>300</b> Output CNN structure</li>    <li id="ul0027-0008" num="0153"><b>800</b> Parameter optimization device</li>    <li id="ul0027-0009" num="0154"><b>811</b> Stride and dilation use layer detection means</li>    <li id="ul0027-0010" num="0155"><b>812</b> Stride and dilation use position modification means</li>    <li id="ul0027-0011" num="0156"><b>1000</b> CPU</li>    <li id="ul0027-0012" num="0157"><b>1001</b> Storage device</li>    <li id="ul0027-0013" num="0158"><b>1002</b> Memory</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A parameter optimization device that optimizes input CNN structure information and outputs optimized CNN structure information, comprising:<claim-text>a memory storing a software component, and</claim-text><claim-text>one or more processors configured to execute the instructions to</claim-text><claim-text>extract stride and dilation parameter information for each convolution layer from the input CNN structure information, and</claim-text><claim-text>change the stride and dilation parameter information of the convolution layer.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The parameter optimization device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>until there are no more pairs of changeable stride and dilation parameters for all convolution layers in the CNN structure,</claim-text><claim-text>the one or more processors execute the instructions to repeatedly execute a process for extracting the parameter information, and a process for changing the parameter information.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The parameter optimization device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the one or more processors execute the instructions to execute a process for extracting the parameter information for each layer in the convolution layer in the CNN structure while switching the layer from a deep layer to a shallow layer, and</claim-text><claim-text>execute a process for changing the parameter information for each layer in the convolution layer in the CNN structure while switching the layer from a deep layer to a shallow layer.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The parameter optimization device according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein<claim-text>when the greatest common divisor of a stride value and a dilation value for a certain convolution layer is greater than 1, the one or more processors execute the instructions to change the stride value for the certain convolution layer to a value obtained by dividing the stride value by the greatest common divisor, the dilation value for the certain convolution layer to a value obtained by dividing the dilation value by the greatest common divisor, and a stride value for the convolution layer that is one-level shallower than the certain convolution layer to a value obtained by multiplying the stride value by the greatest common divisor.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The parameter optimization device according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein<claim-text>when both a stride value and a dilation value for a certain layer are 2, the one or more processors execute the instructions to change the stride value for the certain convolution layer to a value obtained by dividing the stride value by 2, the dilation value for the certain convolution layer to a value obtained by dividing the dilation value by 2, and a stride value for the convolution layer that is one-level shallower than the certain layer to a value obtained by multiplying the stride value by 2.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The parameter optimization device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, the one or more processors further execute the instructions to<claim-text>determine whether a modification of a shortcut process due to a result of changing the stride and dilation is required or not in the case where the CNN structure includes the shortcut process, and</claim-text><claim-text>modify the shortcut process when it is determined that the modification of the shortcut process is required.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The parameter optimization device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the one or more processors further execute the instructions to determine that the modification of the shortcut process is required, when the change of the stride occurs in two convolution layers across an addition process in the shortcut process.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The parameter optimization device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein<claim-text>the one or more processors execute the instructions to</claim-text><claim-text>introduce a thinning process with the stride whose value is equal to the stride value after the change, or a 1&#xd7;1 convolution process such that the stride has the same value as the stride value after the change and the weights are represented by a unit matrix, when the shortcut process before the modification does not change input value, and</claim-text><claim-text>change the stride of the 1&#xd7;1 convolution process to a value multiplied by the stride value after the change, when the shortcut process before the modification includes the 1&#xd7;1 convolution process.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A parameter optimization method, implemented by a processor, for optimizing input CNN structure information and outputting optimized CNN structure information, comprising:<claim-text>extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and</claim-text><claim-text>changing the stride and dilation parameter information of the convolution layer.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The parameter optimization method according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising<claim-text>determining whether a modification of a shortcut process due to a result of changing the stride and dilation is required or not in the case where the CNN structure includes the shortcut process, and</claim-text><claim-text>when determining that the modification of the shortcut process is required, modifying the shortcut process.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A non-transitory computer readable recording medium storing a parameter optimization program for optimizing input CNN structure information and outputting optimized CNN structure information, wherein<claim-text>the program causes a processor to execute:</claim-text><claim-text>a process of extracting stride and dilation parameter information for each convolution layer from the input CNN structure information, and</claim-text><claim-text>a process of changing the stride and dilation parameter information of the convolution layer.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The recording medium according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein<claim-text>the program causes the processor to further execute</claim-text><claim-text>a process of determining whether a modification of a shortcut process due to a result of changing the stride and dilation is required or not in the case where the CNN structure includes the shortcut process, and</claim-text><claim-text>a process of modifying the shortcut process when determining that the modification of the shortcut process is required.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007224A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007224</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17810092</doc-number><date>20220630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>SE</country><doc-number>2150848-6</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>167</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>03</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20180501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>167</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0304</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>2013</main-group><subgroup>0096</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD AND SYSTEM FOR ALIGNMENT OF DATA</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>TOBII AB</orgname><address><city>Danderyd</city><country>SE</country></address></addressbook><residence><country>SE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>HOGSTROM</last-name><first-name>Jonas</first-name><address><city>Danderyd</city><country>SE</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>ALSMYR</last-name><first-name>Erik</first-name><address><city>Danderyd</city><country>SE</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A user monitoring system receives a first data stream from a first recording device and a second data stream from a second recording device. Each of the first data stream and the second data stream include data relating to an eye of the user. The first data stream and the second data stream overlap temporally. The system processes the first data stream to determine a first blink sequence of the user, processes the second data stream to determine a second blink sequence of the user, and compares the first blink sequence and the second blink sequence to detect a blink pattern present in both the first blink sequence and the second blink sequence. The system determines a temporal offset of the first data stream and the second data stream by comparing respective positions of the blink pattern in the first data stream and the second data stream.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="95.42mm" wi="148.00mm" file="US20230007224A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="209.97mm" wi="150.03mm" file="US20230007224A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="228.09mm" wi="153.67mm" file="US20230007224A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCES TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority to Swedish Application No. 2150848-6, entitled &#x201c;METHOD AND SYSTEM FOR ALIGNMENT OF DATA,&#x201d; filed on Jun. 30, 2021. The entire disclosure of the above-referenced application is incorporated by this reference.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present invention relates to the handling of multiple streams of data that each include blink data relating to a user. More particularly, the invention relates to the use of blink detection and sequence comparison in order to determine a temporal offset between two or more data streams. This temporal offset can then be used to align the data. The invention also relates to a system configured to utilize such a method.</p><heading id="h-0003" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0004" num="0003">When recording multiple streams of data, it can be important to have them temporally aligned, i.e. aligned in time. The delay between data streams recording by different recording apparatuses can be unpredictable and inconsistent, dependent on many different factors, and therefore it may not be straightforward to determine the level of temporal offset. In some situations, this may not be a problem, but in circumstances where temporal alignment is important, this can be a significant issue.</p><p id="p-0005" num="0004">One particular situation where temporal offset of data streams can be problematic is in the field of attention tracking, where a subject or user is monitored using multiple recording devices. For example, subjects may be monitored using a dedicated eye tracking device and an additional camera that records images of a larger portion of the user, such as their head and shoulders, or their whole body. In order to combine the data gathered from both recording devices, the offset of the two data streams must be determined, otherwise it can lead to errors in data interpretation. Where the data relates to small and fast movements, such as in gaze tracking, small errors in determination of temporal offset of the data streams can lead to large errors in interpretation of the data.</p><p id="p-0006" num="0005">For example, if an eye tracking device is working in conjunction with a second recording device, the second recording device may register an event&#x2014;such as a sound or a sudden change in illumination&#x2014;that elicits a reaction from the user. If the timestamp from this event is wrong with respect to the data stream received from the eye tracking device, then conclusions arrived at from this information may be incorrect.</p><p id="p-0007" num="0006">Another example where misaligned streams would be problematic is where a system is designed to capture a dynamic area of attention of a user in conjunction with gaze data, e.g. where a forward-facing camera tracks the changing scene in front of a user and a gaze tracking device determines where the user is looking in the changing scene. If an object is moving in the scene and the user is tracking this object, misaligned data streams may make the user appear to be tracking ahead of or behind the actual object.</p><p id="p-0008" num="0007">For example, a first recording device may capture eye tracking data whilst a second recording device captures an image of the user's head, to provide additional context for analysis of the recording. For example, the second recording device may provide date relating to facial expression or speech of the user. Synchronization of this data may commonly be provided by timestamping the data stream from each recording device. However, timestamping is typically completed noticeably later than when each camera sensor is exposed, resulting in a mismatch between the time stamping of the eye tracking data from the first recording device and the additional data from the second recording device.</p><p id="p-0009" num="0008">It is therefore desired to provide a system and method that overcome or ameliorate the above issues.</p><heading id="h-0004" level="1">BRIEF SUMMARY OF THE INVENTION</heading><p id="p-0010" num="0009">According to a first aspect, there is provided a method of determining a temporal offset of data from two recording devices, the method comprising: receiving a first data stream from a first recording device and a second data stream from a second recording device, wherein each of the first data stream and second data stream include data relating to an eye of the user, and wherein the first data stream and second data stream overlap temporally; processing the first data stream to determine a first blink sequence of the user; processing the second data stream to determine a second blink sequence of the user; comparing the first blink sequence and the second blink sequence to detect a blink pattern present in both the first blink sequence and the second blink sequence; and determining a temporal offset of the first data stream with the second data stream by comparing respective positions of the blink pattern in the first data stream and the second data stream. By determining the temporal offset of the data streams, the data streams may be compared or processed in any desired manner with knowledge of how events recorded in either stream correspond to events recorded in the other stream.</p><p id="p-0011" num="0010">The data streams may include data relating to both eyes of the user. This may provide more robust data, as data relating to each individual eye may be correlated together to ignore or remove data that is determined to be inaccurate. Such methods will be known to the skilled person. The first recording device may be an eye tracking device. The use of an eye tracking device can provide data that indicates the gaze position or gaze direction of a user being monitored. The first data stream may include a gaze signal that is processed to determine the first blink sequence. The first data stream may include an eye openness signal that is processed to determine the first blink sequence. The second recording device may be a system recording an entire face of the user. The second recording device may therefore provide an overview of user reaction to stimuli. For example, the second recording device may include data relating to head movement, facial expression, mouth movement, speech, or other such data. The second data stream may include a video signal that is processed to determine the second blink sequence.</p><p id="p-0012" num="0011">One or more of the first stream and the second data stream may include data relating to a scene viewable by the user. This may be useful in such situations where it is desirable to track the gaze of the user relative to a scene that is moving, for example when the user is moving around an area. The first or second recording device may, for example, be a 360-degree camera.</p><p id="p-0013" num="0012">The first blink sequence and the second blink sequence may be compared by way of determining a time between adjacent blinks in the first blink sequence and second blink sequence. The blink pattern may include at least two blinks, or at least three blinks, or at least four blinks, or at least five blinks. By including a greater number of blinks in a blink pattern, incorrect determinations of temporal offset can be limited or avoided. For example, whilst it is possible that a similar or identical pattern of two blinks may occur multiple times in a sequence, it is much less likely that a similar or identical pattern of five blinks may occur multiple times in the sequence.</p><p id="p-0014" num="0013">The method may further comprise the step of temporally aligning the first data stream with the second data stream using the determined temporal offset. The data streams may, for example, be combined into a single data stream including a combination of data from the first data stream and the second data stream. The method may further comprise: detecting a second blink pattern present in both the first blink sequence and the second blink sequence; determining a second temporal offset of the first data stream and the second data stream by comparing respective positions of the second blink pattern in the first data stream and the second data stream; and determining a drift value or drift coefficient from the temporal offset and the second temporal offset.</p><p id="p-0015" num="0014">Multiple blink patterns can therefore be detected, whereby each blink pattern is used to determine a temporal offset of the first data stream and the second data stream. The detection of multiple blink patterns may allow drift in clock times of the data streams to be accounted for in the alignment process. By detecting temporal offset at multiple places in the data streams, a drift value or drift coefficient may be determined between the data streams. The drift value or drift coefficient may be used to better align the data streams.</p><p id="p-0016" num="0015">According to a second aspect, there is provided a user-monitoring system, comprising: a first recording device configured to output a first data stream and a second recording device configured to output a second data stream, wherein each of the first and second data streams include data relating to an eye of the user and wherein the first data stream and the second data stream overlap temporally. A processor may be configured to: process the first data stream to determine a first blink sequence of the user; process the second data stream to determine a second blink sequence of the user; compare the first blink sequence and the second blink sequence to detect a blink pattern present in both the first blink sequence and the second blink sequence; and determine a temporal offset of the first data stream and the second data stream by comparing respective positions of the blink pattern in the first data stream and the second data stream. By determining the temporal offset of the data streams, the data streams may be compared or processed in any desired manner with knowledge of how events recorded in either stream correspond to events recorded in the other stream.</p><p id="p-0017" num="0016">The first recording device may be an eye tracking device. The use of an eye tracking device can provide data that indicates the gaze position or gaze direction of a user being monitored. The first data stream may include a gaze signal that is processed to determine the first blink sequence. The first data stream may include an eye openness signal that is processed to determine the first blink sequence. The second recording device may be a system recording an entire face of the user. The second recording device may therefore provide an overview of user reaction to stimuli. For example, the second recording device may include data relating to head movement, facial expression, mouth movement, speech, or other such data. The second data stream may include a video signal that is processed to determine the second blink sequence.</p><p id="p-0018" num="0017">One or more of the first stream and the second data stream may include data relating to a scene viewable by the user. This may be useful in such situations where it is desirable to track the gaze of the user relative to a scene that is moving, for example when the user is moving around an area. The first or second recording device may, for example, be a 360-degree camera. The first blink sequence and the second blink sequence may be compared by way of determining a time between adjacent blinks in the first blink sequence and the second blink sequence.</p><p id="p-0019" num="0018">The blink pattern may include at least two blinks, or at least three blinks, or at least four blinks, or at least five blinks. By including a greater number of blinks in a blink pattern, incorrect determinations of temporal offset can be limited or avoided. For example, whilst it is possible that a similar or identical pattern of two blinks may occur multiple times in a sequence, it is much less likely that a similar or identical pattern of five blinks may occur multiple times in the sequence.</p><p id="p-0020" num="0019">The processor may further be configured to temporally align the first data stream with the second data stream using the determined temporal offset. The data streams may, for example, be combined into a single data stream including a combination of data from the first data stream and the second data stream. The processor may be further configured to: detect a second blink pattern present in both the first blink sequence and the second blink sequence; determine a second temporal offset of the first data stream and the second data stream by comparing respective positions of the second blink pattern in the first data stream and the second data stream; and determine a drift value or drift coefficient from the temporal offset and the second temporal offset.</p><p id="p-0021" num="0020">Multiple blink patterns can therefore be detected, whereby each blink pattern is used to determine a temporal offset of the first data stream and the second data stream. The detection of multiple blink patterns may allow drift in clock times of the data streams to be accounted for in the alignment process. By detecting temporal offset at multiple places in the data streams, a drift value or drift coefficient may be determined between the data streams. The drift value or drift coefficient may be used to better align the data streams.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0022" num="0021">Specific embodiments will now be described in detail with reference to the accompanying drawings, in which:</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagrammatic view of a user monitoring system of the second aspect;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIGS. <b>2</b>A and <b>2</b>B</figref> are a graphical depiction of the temporal offset of data streams obtained from the user monitoring system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>; and</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow chart of the method of the first aspect.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading><p id="p-0026" num="0025">Depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is an embodiment of a user monitoring system <b>100</b>. The user monitoring system <b>100</b> is configured to provide multiple data streams of a subject or user <b>102</b> of the user monitoring system <b>100</b>. The user monitoring system <b>100</b> therefore includes a first recording device <b>104</b> and a second recording device <b>106</b>. Each of the first recording device <b>104</b> and the second recording device <b>106</b> are configured to collect data relating to the user <b>102</b>. During this data collection, the user <b>102</b> is looking at a display <b>108</b>, which may be configured to display information to the user <b>102</b>. In other embodiments, the display <b>108</b> may be omitted.</p><p id="p-0027" num="0026">In the depicted user monitoring system <b>100</b>, the first recording device <b>104</b> is an eye tracking device that outputs a gaze signal indicative of a gaze position of a user <b>102</b> on the display <b>108</b> or a gaze direction of the user <b>102</b> relative to the display <b>108</b>. The first recording device is situated towards the bottom of the display <b>108</b>. The positioning of the first recording device <b>104</b> may assist with the viewing of the eyes of the user <b>102</b> when they are viewing the display <b>108</b>, but otherwise is not intrinsic to the invention. The first recording device <b>104</b> uses an image sensor and associated processing to provide data regarding the gaze of the user <b>102</b> to a processor <b>110</b>. In some embodiments, the eye tracking device may include a near-infrared sensor and may include illuminators that shine towards the eye of the user. The illuminators may assist with the detection of the pupil of the user <b>102</b> using well-known effects such as the dark pupil effect or the bright pupil effect. The illuminators may also cause the formation of glints on the cornea of the eye in order to allow pupil center corneal reflection (PCCR) eye tracking or gaze tracking. Alternative arrangements of eye tracking device will be well known to the skilled person. The data from the first recording device <b>104</b> can be processed by the processor <b>110</b> in order to extract blink information relating to the user. By blink information, it is meant that the occurrence of blinks, and subsequently the time between blinks, can be determined.</p><p id="p-0028" num="0027">The blink data may be generated by use of an eye openness signal. The eye openness signal may indicate the relative position of an eyelid, i.e. a degree of closed-ness of the eye of the user, or a pupil detection value, i.e. whether or not the pupil of the eye can be detected by the eye tracking device. In some embodiments, the gaze signal and the eye openness signal may be used together to determine the presence or absence of blinks. For example, eye openness data from an eye openness signal may be combined with gaze data indicating the presence or absence of the detection of a pupil in order to provide a robust blink detection. Any other methods of tracking the blinking of the user may also be used, and will be known to the skilled person.</p><p id="p-0029" num="0028">The second recording device <b>106</b> is an imaging sensor, which, in the depicted embodiment, shows a wider field of view <b>112</b> than the field of view <b>114</b> of the first recording device <b>104</b>. The second recording device <b>106</b> is configured to provide a view of the user <b>102</b> that includes the head and shoulders of the user <b>102</b>. Included in the field of view <b>112</b> are the eyes of the user <b>102</b>, such that the imaging sensor can output an image of the eyes and more specifically any blinking movement of the eyes. As with the first recording device <b>104</b>, the blinking of the user <b>102</b> may be detected using any well-known method that can be determined from the data collected by the respective recording device <b>104</b>, <b>106</b>.</p><p id="p-0030" num="0029">Each of the first recording device <b>104</b> and the second recording device <b>106</b> are in communication with the processor <b>110</b>. In the depicted embodiment, the communication is a wired electrical connection, but this may be any sort of communicable connection including both wired connections and wireless connections such as Bluetooth&#xae; or Wi-Fi&#xae; Any form of connection that allows the conveyance of data between the respective recording device <b>104</b>,<b>106</b> and the processor <b>110</b> may be used. The processor <b>110</b> also includes a memory <b>116</b>, which allows storage of some or all of the data conveyed to it by the first recording device <b>104</b> and the second recording device <b>106</b>.</p><p id="p-0031" num="0030">The invention is not limited to the specific recording devices shown and described in relation to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, the eye tracking device could be replaced by a different recording device such as a imaging device similar to the second recording device. The only limitation for any type of imaging-based recording device is that it captures image data sufficient to detect blinking of the user. Similarly, the data output from the first recording device and the second recording device may not be image data but may be other types of data. For example, the respective recording device may have internal processing that receives image data and converts this into other types of data that can then be processed by the processor. For example, the eye tracking device shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> may output a gaze vector and/or gaze position to the processor and may also output blink data, also known as a blink sequence, that has been determined from the captured image data. In this way, the processing of the user monitoring system may be split between one or more processors, which may be internal to the first and/or second recording devices or external to both of the recording devices.</p><p id="p-0032" num="0031">Blink data may, for example, include the movement of the eyelid of the user, or may include the detection of the partial or total occlusion of the eye or a part of the eye of the user. In one example embodiment, blink data may be data corresponding to a determination that it is not possible to detect the pupil of the user and that therefore the pupil is occluded from view of the recording device. In another example embodiment, blink data may be data corresponding to a movement of the eyelid detected through differential imaging of the eye of the user. These or other different methods for detecting blinks and providing blink data may be used in conjunction with the present invention, such methods being known to those skilled in the art.</p><p id="p-0033" num="0032">Each data stream may include other data in addition to the blink data, such as accompanying image data, sound data, or any other form of data. The invention therefore provides a way in which any data in the stream&#x2014;blink data or otherwise&#x2014;may be aligned with any data in another data stream, by aligning the blink data of both streams.</p><p id="p-0034" num="0033">In some embodiments, the first recording device and/or second recording device may not record image data. For example, one recording device may be an electroencephalogram (EEG) that monitors brain waves. Blinking can be detected using such a device and therefore an EEG may be used along with an eye tracking device or other image-based sensor and the data streams from the two devices may be aligned using the method and system of the present invention. Other non-image based sensors may also be utilized in the system, such as muscle sensors that detect twitching of the eyelid muscles.</p><p id="p-0035" num="0034">In order that the data from the first recording device <b>104</b> and the second recording device <b>106</b> can be used together, for example in future processing or information extraction, it may need be able to be accurately aligned. To achieve this alignment, the present invention utilizes blink sequences gathered from the first recording device <b>104</b> and the second recording device <b>106</b>. Each blink sequence includes at least information regarding the occurrence of a blink and the time of the blink relative to other blinks, for example by providing the time of each blink relative to a datum. The datum need not be an absolute time, but should be a standardized datum from which all blinks may be measured. For example, the datum may be the start of the recording. Alternatively, each blink may be measured from a datum that provides a time-stamp relative to another blink. For example, each blink may be measured in time relative to another blink, effectively providing an interval between one blink and another blink. The blink from which a subsequent blink is measured may be the immediately preceding blink or may be a different preceding blink.</p><p id="p-0036" num="0035">A graphical depiction of blink sequences, or blink data, extracted from first and second recording devices is shown in <figref idref="DRAWINGS">FIGS. <b>2</b>A and <b>2</b>B</figref>. In each case, the blink sequence from the first recording device is labelled as A and the blink sequence from the second recording device is labelled as B.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> shows each of blink sequence A and blink sequence B as it is first extracted. Each of blink sequence A and blink sequence B includes a plurality of blinks, shown as lines along a timeline, and a plurality of spaces between these blinks, which are indicative of the time interval between each of the blinks. Blink data for each blink may be stored as a time period relative to a fixed datum rather than measuring a time interval from adjacent blinks directly, but this makes no difference to the implementation of the present invention. As can be seen, the blink sequence A from a first source and the blink sequence B from a second source are essentially the same, as each is of the same user over a similar time period, and therefore the blinks and the intervals between the blinks are offset. Each of blink sequence A and blink sequence B is received by the processor <b>110</b> with no knowledge of the temporal offset from the other blink sequence. This offset is labelled as X and is an unknown time period. Although the blink sequences A and B are shown graphically in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, the processor <b>110</b> need not process the data graphically, and it may be processed in any other manner, the options for which will be known to the skilled person.</p><p id="p-0038" num="0037">The processor <b>110</b> is therefore configured to determine the offset X between the two blink sequences A and B (also referred to as data streams A and B). This is achieved by detecting a pattern of blinks (a &#x201c;blink pattern&#x201d;) and blink intervals, i.e. the time between respective blinks, that is common to both blink sequences A and B. By detecting the respective blink pattern, the system can then determine that the temporal offset in the blink data from each source is equal to the temporal offset of the detected blink pattern.</p><p id="p-0039" num="0038">A blink pattern that is present in both data streams A and B is depicted as being surrounded by a dotted box in <figref idref="DRAWINGS">FIGS. <b>2</b>A and <b>2</b>B</figref>. The blink pattern within the box is a sequence of three blinks and two blink intervals. In each stream A and B, the blink pattern is identical, with the blink interval between the first blink and the second blink of the sequence being equal in both streams A and B and the blink interval between the second blink and the third blink of the sequence being equal in both streams A and B. Once this blink pattern has been detected by the processor, it is a simple operation to align the streams A and B in order that the data received from each of stream A and stream B may be compared relative to a common datum.</p><p id="p-0040" num="0039">For example, the blink sequence detected in the first blink sequence A may be:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0040">&#x201c;blink; 8300 ms; blink; 1500 ms; blink&#x201d;</li>    </ul>    </li></ul></p><p id="p-0041" num="0041">This pattern of blinks and blink intervals will then be searched for in the whole of the second blink sequence B until a match is found. Once the match is found, the relative alignment of the data from each of blink sequence A and blink sequence B will be determinable.</p><p id="p-0042" num="0042">Once the temporal offset is known, the data can be aligned, as shown in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>. This is graphically shown in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref> by the offset of the beginning of each of data stream A and data stream B. As can be seen, the rest of the blink data, including but not limited to the blink pattern detected in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, is aligned. Thus, any other data received from the first recording device and second recording device, such as gaze data or image data, can also be aligned by processing it with the same temporal offset.</p><p id="p-0043" num="0043">A blink pattern may comprise two or more blinks separated by one or more blink intervals. At a minimum, two blinks are required, but these blinks need not necessarily be adjacent, as long as it can be determined that the interval between the blinks is the same for each blink sequence. It may be beneficial for a blink pattern to be detected that comprises a greater number of blinks. By detecting a blink pattern with a greater number of blinks, it can be determined with more certainty that the detected blink pattern in each of the blink sequences A and B corresponds to the same temporal period, as it is unlikely the exact same blink pattern, i.e. a pattern with the same intervals between blinks, will occur more than once, and the longer the blink pattern the less likely it will be that such a blink pattern will be duplicated within the blink sequences A and B.</p><p id="p-0044" num="0044">If, for example, a blink pattern is detected as occurring more than once in either of the blink sequences A and B, then the system may look for a different blink pattern for comparison purposes, or may look for a longer blink pattern (that may or may not include the original blink pattern), until such a time as it can be shown that the blink pattern occurs only once in the first and second blink sequences A and B. Thus, potential mis-determination of the alignment of the blink sequences A and B can be avoided.</p><p id="p-0045" num="0045">It will be apparent that a failure to match a particular blink pattern to both blink sequences A and B may occur due to a failure of one or more of the recording devices to detect one or more blinks. This may occur, for example, if the user turns their head away from the device or if an eye tracking algorithm fails temporarily. In such cases, if it has not been possible to detect a match to a specific blink pattern, the system may search for a different blink pattern in each of the blink sequences A and B. This process may recur until such a time as a detected blink pattern is found in both of the blink sequences A and B.</p><p id="p-0046" num="0046">It may also be beneficial to repeat the process of blink pattern detection multiple times during a recording session, especially if that session is long. This is because there may be drift between clocks for each recording device over time, and therefore it may be advantageous to determine a temporal offset between the recording devices at multiple times during a recording session. The use of a plurality of different blink patterns throughout a recording session may allow the drift during the session to be detected, and this can also then be used by the system to better align the data streams. Drift may be determined as a drift value or drift coefficient that can be applied across the data streams to assist with alignment.</p><p id="p-0047" num="0047"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow chart showing each step involved in the execution of the disclosed method. In a first step S<b>202</b>, a first data stream and a second data stream are received from the respective first recording device and second recording device referenced in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. These data streams include data relating to the eyes of the user, and in particular include data that allows a processor to determine when the user being recorded has blinked.</p><p id="p-0048" num="0048">The data streams can then be processed in a following step S<b>204</b> in order to determine a blink sequence of the user. Each data stream is processed separately in order to determine an individual blink sequence, i.e. the first data stream is processed to determine a first blink sequence and the second data stream is processed to determine a second blink sequence.</p><p id="p-0049" num="0049">In a further step S<b>206</b>, the first blink sequence and the second blink sequence can be compared to one another in order to detect a blink pattern that occurs in both the first blink sequence and the second blink sequence.</p><p id="p-0050" num="0050">Once a common blink pattern has been detected, the first and second data streams can be aligned S<b>208</b> by comparing the respective positions of the blink pattern within the data streams, and ensuring that the common blink pattern is temporally aligned within the two blink sequences.</p><p id="p-0051" num="0051">Where desirable, the steps from S<b>204</b> to S<b>208</b> may be repeated for additional blink patterns, as shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> by the dotted arrow. This step may additionally be accompanied by the processing of the multiple blink patterns in step S<b>210</b>, in order to determine a drift value or drift coefficient for the system.</p><p id="p-0052" num="0052">Although described in relation to two data streams, the present invention could equally be applied to three, four, or any other number of data streams. In each case, all that is required is that the blink pattern is detected as being present in each of the data streams being considered. All data streams can then be aligned by use of the same blink pattern.</p><p id="p-0053" num="0053">In a further arrangement, more than two data streams could be aligned by using a first blink pattern that is detected, for example, in first and second data streams, and a second blink pattern that is detected, for example, in second and third data streams. This could be particularly useful where the data streams do not necessarily overlap temporally across their whole length, i.e. where first and third data streams each overlap temporally with the second data stream but where first and third data streams do not overlap with each other.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of determining a temporal offset of data from two recording devices, the method comprising:<claim-text>receiving a first data stream from a first recording device and a second data stream from a second recording device, wherein each of the first data stream and the second data stream include data relating to an eye of the user, and wherein the first data stream and the second data stream overlap temporally;</claim-text><claim-text>processing the first data stream to determine a first blink sequence of the user;</claim-text><claim-text>processing the second data stream to determine a second blink sequence of the user;</claim-text><claim-text>comparing the first blink sequence and the second blink sequence to detect a blink pattern present in both the first blink sequence and the second blink sequence; and</claim-text><claim-text>determining a temporal offset of the first data stream and the second data stream by comparing respective positions of the blink pattern in the first data stream and the second data stream.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first recording device comprises an eye tracking device.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first data stream includes a gaze signal that is processed to determine the first blink sequence.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first data stream includes an eye openness signal that is processed to determine the first blink sequence.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second recording device comprises a system recording an entire face of the user.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second data stream includes a video signal that is processed to determine the second blink sequence.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first blink sequence and the second blink sequence are compared by determining a time between adjacent blinks in the first blink sequence and the second blink sequence.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the blink pattern includes (A) at least two blinks, (B) at least three blinks, (C) at least four blinks, or (D) at least five blinks.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising temporally aligning the first data stream with the second data stream using the determined temporal offset.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>detecting a second blink pattern present in both the first blink sequence and the second blink sequence;</claim-text><claim-text>determining a second temporal offset of the first data stream and the second data stream by comparing respective positions of the second blink pattern in the first data stream and the second data stream; and</claim-text><claim-text>determining a drift value or drift coefficient from the temporal offset and the second temporal offset.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A user-monitoring system, comprising:<claim-text>a first recording device configured to output a first data stream and a second recording device configured to output a second data stream, wherein each of the first data stream and the second data stream includes data relating to an eye of the user and wherein the first data stream and the second data stream overlap temporally; and</claim-text><claim-text>a processor configured to:<claim-text>process the first data stream to determine a first blink sequence of the user;</claim-text><claim-text>process the second data stream to determine a second blink sequence of the user;</claim-text><claim-text>compare the first blink sequence and the second blink sequence to detect a blink pattern present in both the first blink sequence and the second blink sequence; and</claim-text><claim-text>determine a temporal offset of the first data stream and the second data stream by comparing respective positions of the blink pattern in the first data stream and the second data stream.</claim-text></claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first recording device comprises an eye tracking device.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first data stream includes a gaze signal that is processed to determine the first blink sequence.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first data stream includes an eye openness signal that is processed to determine the first blink sequence.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the second recording device comprises a system recording the entire face of the user.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the second data stream includes a video signal that is processed to determine the second blink sequence.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first blink sequence and the second blink sequence are compared by determining a time between adjacent blinks in the first blink sequence and the second blink sequence.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the blink pattern includes (A) at least two blinks, (B) at least three blinks, (C) at least four blinks, or (D) at least five blinks.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the processor is further configured to temporally align the first data stream with the second data stream using the determined temporal offset.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The user-monitoring system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the processor is further configured to:<claim-text>detect a second blink pattern present in both the first blink sequence and the second blink sequence;</claim-text><claim-text>determine a second temporal offset of the first data stream and the second data stream by comparing respective positions of the second blink pattern in the first data stream and the second data stream; and</claim-text><claim-text>determine a drift value or drift coefficient from the temporal offset and the second temporal offset.</claim-text></claim-text></claim></claims></us-patent-application>
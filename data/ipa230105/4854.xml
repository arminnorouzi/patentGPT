<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004855A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004855</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363856</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>50</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>505</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">CO-OPERATIVE AND ADAPTIVE MACHINE LEARNING EXECUTION ENGINES</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Texas Instruments Incorporated</orgname><address><city>Dallas</city><state>TX</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MODY</last-name><first-name>Mihir Narendra</first-name><address><city>Bengaluru</city><country>IN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>DESAPPAN</last-name><first-name>Kumar</first-name><address><city>Bengaluru</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>SHURTZ</last-name><first-name>Gregory Raymond</first-name><address><city>Houston</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>JONES</last-name><first-name>Jason A.T.</first-name><address><city>Richmond</city><state>TX</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Techniques for executing machine learning (ML) models including receiving an indication to execute an ML model on a processing core; determining a resource allocation for executing the ML model on the processing core; determining that a layer of the ML model will use a first amount of the resource, wherein the first amount is more than an amount of the resource allocated; determining that an adaptation may be applied to executing the layer of the ML model; executing the layer of the ML model using the adaptation, wherein executing the layer using the adaptation reduces the first amount of the resource used by the layer as compared to executing the layer without using the adaptation; and outputting a result of the ML model based on the executed layer.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="104.48mm" wi="158.75mm" file="US20230004855A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="171.70mm" wi="149.94mm" orientation="landscape" file="US20230004855A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="181.19mm" wi="158.67mm" orientation="landscape" file="US20230004855A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="231.39mm" wi="144.61mm" orientation="landscape" file="US20230004855A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="199.05mm" wi="141.48mm" orientation="landscape" file="US20230004855A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="248.92mm" wi="169.67mm" orientation="landscape" file="US20230004855A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="203.03mm" wi="169.67mm" orientation="landscape" file="US20230004855A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="234.87mm" wi="150.45mm" file="US20230004855A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="143.51mm" wi="127.34mm" file="US20230004855A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="253.83mm" wi="169.25mm" orientation="landscape" file="US20230004855A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="251.71mm" wi="167.13mm" file="US20230004855A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="184.32mm" wi="115.15mm" file="US20230004855A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Machine learning (ML) is becoming an increasingly important part of the computing landscape. Machine learning is a branch of artificial intelligence (AI), and ML helps enable a software system to learn to recognize patterns from data without being directly programmed to do so. Neural networks (NN) are a type of ML which utilize a set of linked and layered functions (e.g., nodes, neurons, etc.) which are weighted to evaluate input data. In some NNs, sometimes referred to as convolution NNs (CNNs), convolution operations are performed in NN layers based on inputs received and weights rather than matrix multiplication used in traditional NN. Layers in CNNs may perform many types of functions, including, but not limited to, convolution, deconvolutional, pooling, up-sample, etc. CNNs are often used in a wide array of applications typically for recognition and classification, such as image recognition and classification, prediction and recommendation systems, speech and language recognition and translation, etc.</p><p id="p-0003" num="0002">As ML becomes increasingly useful, there is a desire to execute complex ML techniques, such as NNs and CNNs, efficiently in devices with relatively limited compute and memory resources, such as embedded, or other low-power devices. To help efficiently run a given ML model, the ML model may be analyzed and optimized to tailor how the ML model is run to a target hardware resources to be used.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0004" num="0003">This disclosure relates to techniques for executing ML models, including receiving an indication to run an ML model on a processing core; determining a resource allocation for running the ML model on the processing core; determining that a layer of the ML model will use a first amount of the resource, wherein the first amount is more than an amount of the resource allocated; determining that an adaptation may be applied to executing the layer of the ML model; executing the layer of the ML model using the adaptation, wherein executing the layer using the adaptation reduces the first amount of the resource used by the layer as compared to running the layer without using the adaptation; and outputting a result of the ML model based on the executed layer.</p><p id="p-0005" num="0004">Another aspect of the present disclosure relates to a non-transitory program storage device comprising instructions stored thereon to cause one or more processors to: receive an ML model, the ML model having one or more layers; simulate executing a layer of the ML model on a target hardware without an adaptation applied to determine a first adaptation criterion; simulate executing the layer of the ML model on the target hardware with the adaptation applied to determine a second adaptation criterion, wherein the adaptation reduces an amount of a resource used by the layer; determine that the adaptation may be applied to the layer based on a comparison of the first adaptation criterion and the second adaptation criterion and an adaptation threshold; and output an indication that the adaptation may be applied to the layer.</p><p id="p-0006" num="0005">Another aspect of the present disclosure relates to an electronic device, comprising: a memory; and one or more processors operatively coupled to the memory, wherein the one or more processors are configured to execute instructions causing the one or more processors to: receive an indication to run an ML model on a processing core; determine a resource allocation for running the ML model on the processing core; determine that a layer of the ML model will use a first amount of the resource, wherein the first amount is more than an amount of the resource allocated; determine that an adaptation may be applied to executing the layer of the ML model; execute the layer of the ML model using the adaptation, wherein executing the layer using the adaptation reduces the first amount of the resource used by the layer as compared to running the layer without using the adaptation; and output a result of the ML model based on the executed layer.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0007" num="0006">For a detailed description of various examples, reference will now be made to the accompanying drawings in which:</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example NN ML model, in accordance with aspects of the present disclosure.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of a device, including hardware for executing ML models, in accordance with aspects of the present disclosure.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a timeline illustrating ML models executing across multiple computing cores, in accordance with aspects of the present disclosure.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating dynamic resource allocation, in accordance with aspects of the present disclosure.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a timeline illustrating ML model execution with adaptation across the computing cores, in accordance with aspects of the present disclosure.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating dynamic resource allocation with adaptation, in accordance with aspects of the present disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> are bock diagrams illustrating precision adaptation, in accordance with aspects of the present disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram illustrating executing an ML model layer using data from external memory with memory adaptation, in accordance with aspects of the present disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram of a process for compiling ML models for target hardware, in accordance with aspects of the present disclosure.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates layer level dynamic resource usage information, in accordance with aspects of the present disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart illustrating a technique for determining adaptations for layers of an ML model, in accordance with aspects of the present disclosure.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart illustrating a technique for adapting execution of an ML model, in accordance with aspects of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0020" num="0019">As ML has becoming more common and powerful, hardware configured to execute ML models has been introduced. As used herein, an ML model may refer to an implementation of one or more ML algorithms which model a behavior, such as object recognition, behavior of a circuit, behavior of a neuron, etc. In cases where a target hardware for executing ML models is known, the ML models may be optimized for the target hardware configurations to help enhance performance. For example, ML models for object recognition, low-light enhancement, and facial recognition may be optimized to execute on a particular a mobile device, such as a smartphone configured with a certain ML processor. As another example, ML models for object recognition, movement prediction, and behavioral prediction may be optimized to execute on specific hardware found in certain partially or fully self-driving automobiles.</p><p id="p-0021" num="0020">Example ML Model</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example NN ML model <b>100</b>, in accordance with aspects of the present disclosure. The example NN ML model <b>100</b> is a simplified example presented to help understand how an NN ML model <b>100</b>, such as a CNN, is structured and trained. Examples of NN ML models may include LeNet, Alex Net, Mobilnet, etc. It may be understood that each implementation of an ML model may execute one or more ML algorithms and the ML model may be trained or tuned in a different way, depending on a variety of factors, including, but not limited to, a type of ML model being used, parameters being used for the ML model, relationships as among the parameters, desired speed of training, etc. In this simplified example, parameter values of W, L, and iref are parameter inputs <b>102</b>, <b>104</b>, and <b>114</b>, which are passed into the ML model <b>100</b>. Each layer (e.g., first layer <b>106</b>, second layer <b>108</b>, and third layer <b>110</b>) includes a plurality of nodes (e.g., neurons) and generally represents a set of operations performed on the parameters, such as a set of matrix multiplications, convolutions, deconvolutions, etc. For example, each node may represent a mathematical function that takes, as input (aside from the nodes of the first layer <b>106</b>), output from a previous layer and a weight. The ML model outputs <b>112</b> are output from the last layer (e.g., the third layer <b>110</b>). The weight is typically adjusted during ML model training and fixed after the ML model training. The specific mathematical function of the node can vary depending on ML model implementation. While the current example addresses three layers, in certain cases the ML model may include any number of layers. Generally, each layer transforms M number of input parameters to N number of output parameters. The parameter inputs to the first layer <b>106</b> are output as inputs to the second layer <b>108</b> with a set of connections. As each node of a layer (such as first layer <b>106</b>) outputs to each node in a subsequent layer (such as second layer <b>108</b>), ML model <b>100</b> is a fully connected NN. Other embodiments may utilize a partially connected NN or another NN design which may not connect each node of a layer to each node of a subsequent layer, where some node connections may skip layers, where no feedback is provided from output to inputs (e.g., Feed Forward CNN), etc.</p><p id="p-0023" num="0022">In this example, first layer <b>106</b> represents a function based on a set of weights that are applied to the input parameters (e.g., input parameters <b>102</b> and <b>104</b>) to generate output from first layer <b>106</b> that is input to the second layer <b>108</b>. Different weights may be applied for the input received from each node of the previous layer by the subsequent layer. For example, for a node of the second layer <b>108</b>, the node applies weights to input received from nodes of the first layer <b>106</b> and the node may apply a different weight to input received from each node of the first layer <b>106</b>. Nodes compute one or more functions based on the inputs received and corresponding weights and outputs a number. In some cases, inputs and output to an ML model layer may be referred to as input or output features of the ML model layer. For example, the node may use a linear combination function which multiplies an input values from a node of the previous layer with a corresponding weight and sums across the results of the multiplication, coupled with a non-linear activation function which acts as a floor for the resulting number for output. It may be understood that any known weighted function may be applied by the node within the scope of this disclosure. This output number may be input to subsequent layers, or if the layer is a final layer, such as third layer <b>110</b> in this example, the number may be output as a result (e.g., output parameters or ML model outputs <b>112</b>).</p><p id="p-0024" num="0023">In some cases, the functions applied by nodes of a layer may differ as between layers. In some cases, each layer may have different resource requirements. For example, when the functions of multiple nodes are performed by a processor, the different functions may have different loads on the processor. Additionally, some functions may have different input or output parameters and thus consume more, or less, memory space and bandwidth. These differing processor and memory loads may also influence an amount of energy to power the processor and memory, as well as an amount of heat generated.</p><p id="p-0025" num="0024">After an ML model, such as NN ML model <b>100</b>, is defined with respect to nodes, layers, etc., the ML model may be trained. In some cases, the ML model <b>100</b> may be trained using a labelled data set corresponding to data to be input to ML model <b>100</b>. For example, an object recognizer may be trained on images of objects. These images may include metadata labelling the object(s) in the image. The ML model <b>100</b> may be initiated with initial weights and the images input to the ML model <b>100</b> to generate predictions. The weights of the nodes may be adjusted based on how accurate the prediction is as compared to the labels. The weights applied by a node may be adjusted during training based on a loss function, which is a function that describes how accurately the predictions of the NN are as compared to the expected results; an optimization algorithm, which helps determine weight settings adjustments based on the loss function; and/or a backpropagation of error algorithm, which applies the weight adjustments back through the layers of the NN. Any optimization algorithm (e.g., gradient descent, mini-batch gradient descent, stochastic gradient descent, adaptive optimizers, momentum, etc.), loss function (e.g., mean-squared error, cross-entropy, maximum likelihood, etc.), and backpropagation of error algorithm (e.g., static or recurrent backpropagation) may be used within the scope of this disclosure.</p><p id="p-0026" num="0025">In some cases, training the ML model <b>100</b> is performed during development of the ML model <b>100</b> and may be performed by a system or device separate from the system or device that runs the trained ML model.</p><p id="p-0027" num="0026">Example Hardware for Executing ML Models</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram <b>200</b> of a device, including hardware for executing ML models, in accordance with aspects of the present disclosure. The device may be system on a chip (SoC), including multiple components configured to perform different tasks. As shown, the device includes one or more central processing unit (CPU) cores <b>202</b>, which may include one or more internal cache memories <b>204</b>. The CPU cores <b>202</b> may be configured for general computing tasks.</p><p id="p-0029" num="0028">The CPU cores <b>202</b> may be coupled to a crossbar (e.g., interconnect) <b>206</b>, which interconnects and routes data between various components of the device. In some cases, the crossbar <b>206</b> may be a memory controller or any other circuit that can provide an interconnect between peripherals. Peripherals may include master peripherals (e.g., components that access memory, such as various processors, processor packages, direct memory access (DMA)/input output components, etc.) and slave peripherals (e.g., memory components, such as double data rate (DDR) random access memory, other types of random access memory, DMA/input output components, etc.). In some cases, the processing cores, such as CPU cores <b>202</b>, ML accelerator <b>208</b>, and other processing cores <b>210</b> and crossbar <b>206</b> may be integrated on a single chip, such as a SoC <b>222</b> with a separate external memory. In this example, the crossbar <b>206</b> couples the CPU cores <b>202</b> with other peripherals, such as an ML accelerator <b>208</b> and other processing cores <b>210</b>, such as a graphics processing unit, radio basebands, coprocessors, microcontrollers, etc., and external memory <b>214</b>, such as DDR memory, dynamic random access memory (DRAM), flash memory, etc., which may be on a separate chip from the SoC. The crossbar <b>206</b> may include or provide access to one or more internal memories that may include any type of memory, such as static random access memory (SRAM), flash memory, etc. The ML accelerator <b>208</b> may include one or more ML cores <b>216</b>. The ML cores <b>216</b> may be processor cores configured to accelerate machine learning models and the ML cores <b>216</b> may include one or more internal caches (not shown).</p><p id="p-0030" num="0029">In operation, such as when executing one or more ML models, the ML cores <b>216</b> may store and access data for executing the one or more ML models in a scratch memory to help improve performance, as compared to storing and accessing the data in the external memory <b>214</b>. In some cases, an amount of data needed by the ML model varies based on the ML models. For example, the amount of data may vary based on the inputs and outputs of layers of the ML model, operations performed in the layers, number of nodes in the layers, etc. In some cases, an amount of scratch memory may be allocated for use by each executing ML model. In this example, the ML accelerator <b>208</b> may include N ML cores <b>216</b> executing N ML models with a corresponding N static memory allocations <b>218</b>. The size of the memory allocations <b>218</b> may be fixed based on the ML model. The static memory allocations <b>218</b> may be made from the one or more internal memories included in or accessible via the crossbar <b>206</b>.</p><p id="p-0031" num="0030">To help facilitate the ML cores <b>216</b> and executing ML models access the memory allocations <b>218</b>, the crossbar may include N DMA engines <b>220</b>. In some cases, each DMA engine may be associated with a particular ML core <b>216</b>. The DMA engines <b>220</b> may be used by applications, such as ML models, to perform memory operations and/or to offload memory management tasks from a processor. Of note, for simplicity, each ML core <b>216</b> is described as executing a single ML model, but it should be understood that any number of ML models may execute on any ML core <b>216</b>, and these ML models may access a corresponding number of static memory allocations <b>218</b>. In some cases, the DMA engines <b>220</b> along with sufficient scratch memory for the static memory allocations <b>218</b> may be integrated on the ML cores <b>216</b>.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a timeline <b>300</b> illustrating ML models executing across multiple computing cores, in accordance with aspects of the present disclosure. The timeline <b>300</b> includes an X-axis plotting time and Y-axis plotting activities performed by the cores <b>302</b>A, <b>302</b>B, . . . <b>302</b><i>n </i>(collectively <b>302</b>). In some cases, each of the cores <b>302</b> may be a general purpose CPU, an ML core, or other processor on which an ML model may be run. In some cases, core <b>302</b> may be a physical core or a logical core. In some cases, the ML core <b>302</b> on which an ML model <b>306</b> is executed may be determined prior to execution, for example during compilation process or during initialization, and may be static once determined. That is, the core <b>302</b> on which an ML model <b>306</b> is run does not change once the ML model <b>306</b> is initialized on the core <b>302</b> until ML model <b>306</b> execution is stopped. As shown, the ML model <b>306</b>A may continue to run on a particular core <b>302</b>A after initialization. In some cases, execution of multiple ML models may be optimized for target hardware during a compilation stage. Part of this optimization may include determining which cores particular ML models of the multiple ML models may execute on. In some cases, multiple ML models may be executed on a single core <b>302</b>. Other ML models, such as ML models <b>306</b>B . . . <b>406</b><i>n</i>, may be initialized and continue to run on other cores, such as cores <b>302</b>B, . . . <b>302</b><i>n</i>. These ML models <b>306</b> may execute concurrently and asynchronously. That is, multiple ML models <b>306</b> may run at the same time without synchronization as between the ML models <b>306</b>.</p><p id="p-0033" num="0032">When initializing an ML model, such as ML model <b>306</b>A, for execution, memory, such as a portion of the shared memory, may be allocated <b>304</b>A for the ML model <b>306</b>A prior to ML model <b>306</b>A execution. The runtime code and parameters for the ML model may be stored in the static allocated memory <b>304</b> for use during ML model execution. As shown each executing ML model, such as <b>306</b>A, <b>306</b>B, . . . <b>306</b><i>n </i>may be associated with a static allocated memory space, such as <b>304</b>A, <b>304</b>B, . . . <b>304</b><i>n</i>, in the shared memory. A total size of the shared memory may then be based on a sum of the size of the static allocated memory spaces for the ML models to be run. In some cases, the size of the static allocated memory space for an ML model may be based on information obtained during the ML model compilation for the target hardware. In other cases, the size of the static allocated memory space for each ML model may be fixed.</p><p id="p-0034" num="0033">In some cases, each layer of an ML model may be associated with different memory usage. For example, each layer may include a different number of nodes utilizing a different set of input parameters and different weights being applied for nodes of the layer, which influence the memory usage of the layer. In some cases, certain layers of an ML model, when executed, may use more memory than the memory available in the static memory. That is, an ML layer memory usage may exceed the size of the static allocated memory space (e.g., a static resource) for the ML model. In such cases, the ML model may be able to access dynamic resources of a target hardware. In the case of memory usage, the target hardware may be configured with dynamic memory (e.g., a common memory pool) that may be allocated to specific cores for use when executing ML model layers which use more memory than what is available in the static allocated memory space for the ML model.</p><p id="p-0035" num="0034">Generally, the target hardware has a limited amount of resources that may be allocated among executing software, such as the multiple ML models. For example, the target hardware may have a certain amount of internal memory available, a certain amount of memory throughput and bandwidth available, and a certain amount of power that the target hardware can draw. In accordance with aspects of the present disclosure, an ML model executing on target hardware may be allocated a set of static resources for execution. In some cases, the static resources may include a certain amount of memory (e.g., the static allocated memory), a certain amount of memory throughput, a certain amount of memory bandwidth, and a certain amount of power/current for the core executing the ML model. If execution of the ML model requires additional resources, dynamic resources from a set of common (e.g., shared between multiple ML models and cores) on-demand resources may be allocated for the ML model as needed. In some cases, the dynamic resources may also include an amount of memory (e.g., dynamic memory), a certain amount of memory throughput, a certain amount of memory bandwidth, and a certain amount of power/current.</p><p id="p-0036" num="0035">In some cases, when resources are dynamically allocated, the multiple ML models may attempt to access one or more dynamic resources. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart <b>400</b> illustrating dynamic resource allocation, in accordance with aspects of the present disclosure. In some cases, a core may determine that a layer of an ML model may use more of a particular resource than has been statically allocated to the ML model for that core. For example, an amount of static and dynamic resources used by the layer of the ML model may be indicated in a common context associated with a set of ML model executing on the target hardware. After a determination is made that the layer of the ML model uses more of a resource than the static allocation, at block <b>402</b>, a callback may be allocated. In some cases, dynamic allocations may be implemented via callback functions to help avoid possible task switching while the resources are being allocated. In some cases, callback functions may be implemented in a software function, such as the runtime code, and call into other external functionality. A callback may be executable code and/or functions passed as an argument into another function. For example, code for a dynamic allocation function may be passed as an argument of a function call. In some cases, parallel threads to threads used by the ML model may also be used. At block <b>404</b>, the amount of the resource, both static and dynamic, requested by the layer of the ML model may be compared to a maximum available amount of the resource available. For example, if a portion of the dynamic resource is in use by another ML model, there may less of the dynamic resource available for allocation. If the amount of the resource requested is less than the amount of the dynamic resource available for allocation, then at block <b>406</b> the dynamic resource may be allocated based on a scheduler policy. In some cases, the scheduler policy may be a need-based or round-robin scheduler. In some cases, the latency may also be checked against a maximum latency. The maximum latency may be based on a maximum time an ML model may take to determine an output (e.g., inference). For example, where the ML model is expected to be used to process video in real time, the maximum latency may be set such that the ML model can be executed within an amount of time available between frames of the video. At block <b>408</b>, the dynamic resources are allocated. In some cases, allocating the dynamic resource may be performed using atomic operations. At block <b>410</b>, the callback allocation returns. In some cases, the dynamic resource requested may already be allocated to the core. For example, another ML model executing on the core may be using the dynamic resource. In such cases, execution may proceed to block <b>412</b> where execution of the layer of the ML model may stall until the dynamic resource becomes available. Returning to block <b>404</b>, if the amount of the resource requested is more than the amount of the dynamic resource available for allocation, then execution may proceed to block <b>412</b> where execution of the layer of the ML model may stall until the dynamic resource becomes available.</p><p id="p-0037" num="0036">In some cases, to help avoid stalling execution of an ML model, execution of the ML model may be adapted based on an adaptation policy. <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a timeline <b>500</b> illustrating ML model execution with adaptation across the computing cores, in accordance with aspects of the present disclosure. The timeline <b>500</b> includes an X-axis plotting time and Y-axis plotting activities performed by the cores <b>502</b>A, <b>502</b>B, . . . <b>502</b>N (collectively <b>502</b>). In some cases, the cores <b>502</b> may be physical general purpose CPUs, ML cores, or other processors on which ML models may be run. In some cases, cores <b>502</b> may be mapped to logical cores. As shown in this example, each core <b>502</b> is shown executing an ML model <b>504</b>, with core <b>1</b> <b>502</b>A executing ML model <b>1</b> <b>504</b>A, core <b>2</b> <b>502</b>B executing ML model <b>2</b> <b>504</b>B, and core n executing ML model n <b>504</b>N. Prior to executing the ML models <b>504</b>, each core is allocated a static memory <b>506</b>, with core <b>1</b> <b>502</b>A being allocated static memory <b>506</b>A, core <b>2</b> <b>502</b>B being allocated static memory <b>506</b>B, and core n <b>502</b>N being allocated static memory <b>506</b>N. In some cases, each static memory <b>506</b> may be a different size.</p><p id="p-0038" num="0037">In some cases, a layer, such as a first layer <b>507</b> of ML model N <b>504</b>N, may use more memory than available in the static memory <b>506</b>N. In such cases, the first layer <b>507</b> may execute using dynamic resources (e.g., dynamic memory). Similarly, a second layer <b>508</b> of the ML model <b>2</b> <b>502</b>B may also execute using dynamic resources. A third layer <b>510</b> of ML model <b>1</b> <b>504</b>A may also use more memory than available in the static memory <b>506</b>A and may attempt to access dynamic resources. In this case, as dynamic resources have been allocated to the first layer <b>507</b> and the second layer <b>508</b>, there may be insufficient dynamic resources to allocate to the third layer <b>510</b>. In such cases, the third layer <b>510</b> may execute under an adaptation policy that alters (e.g., adapts) the execution of the third layer <b>510</b>. In some cases, not every layer of an ML model may be capable of executing under the adaptation policy. For example, a fourth layer <b>512</b> of ML model <b>1</b> <b>504</b>A may not be capable of executing under the adaptation policy and may be allocated dynamic resources. A fifth layer <b>514</b> of ML model <b>2</b> <b>504</b>B may instead be executing under the adaptation policy.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart <b>600</b> illustrating dynamic resource allocation with adaptation, in accordance with aspects of the present disclosure. As shown, flowchart <b>600</b> is similar to flowchart <b>400</b> shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. After the comparison of the availability of requested static and dynamic resources against the maximum available amount of the resource available at block <b>404</b>, an adaptation policy may be implemented at block <b>602</b>. At block <b>602</b>, an amount of the resource, both static and dynamic, that would be used with an adaptation policy implemented is compared to the maximum available amount of the resource available. For example, the common context associated with the ML models may include information indicating an amount of the resource the layer of the ML model would use if an adaptation policy is implemented. As a more detailed example, if an amount of internal memory throughput used by a layer of the ML model is achieved by executing the layer using whole and/or contiguous memory banks of the internal memory and a size of the input features exceeds the size of the whole and/or contiguous memory banks available, the size of the input features under an adaptation policy (e.g., lower precision input features) may be determined. This determination may be made based on information in the common context or determined based on a size of the stored (e.g., in external memory) lower precision input features. This amount of the resource used under the adaptation policy may be compared to the amount of the static and dynamic resource available for allocation to the layer. For example, the size of the lower precision input features may be compared to the size of the whole and/or contiguous memory banks available.</p><p id="p-0040" num="0039">If the amount of the resource under the adaptation policy is less than the amount of the static and dynamic resource available for allocation to the layer, execution proceeds to block <b>406</b> as described above in conjunction with <figref idref="DRAWINGS">FIG. <b>4</b></figref>, where the dynamic resource may be allocated based on a scheduler policy. If the amount of the resource under the adaptation policy is more than the amount of the static and dynamic resource available for allocation to the layer, execution proceeds to block <b>412</b> where execution of the layer of the ML model may stall until the dynamic resource becomes available.</p><p id="p-0041" num="0040">In some cases, the adaptation policy may include various possible alterations to the execution of an ML model layer. These alterations may be used to help reduce the amount of resources of the target hardware used by layers of the ML model. For example, an amount of power/current used by a layer may be adapted by reducing the speed at which the layer is executed on the core and/or executing the layer on a more power-efficient core. Where executing a particular layer on a first core may cause the first core to use more than a certain amount of power (either from executing the particular layer, or in combination with another executing ML model), execution of the particular layer may be adapted by reducing the speed at which the layer is processed by the core, for example, by adjusting the clock of the core or by inserting waits between instructions associated with the layer. In some cases, when executing a particular layer on a first core may cause the first core to use more than a certain amount of power, the particular layer may be executed on a second core. The second core may be a more power-efficient core and/or may be a different type of processing core. For example, the layer may be executed on a digital signal processor (DSP) core rather than an ML core. In some cases, a second, more power-efficient core may be associated with a reduced performance as compared to the first core. Executing the layer using an adaptation policy which adapts the amount of power/current used by the layer helps avoid having to stall the execution of the layer, for example, to reduce power usage to stay within a power and/or thermal budget. Adapting the amount of power/current may result in reduced performance for the layer and the overall ML model but avoids stalling, and thus stopping, execution of the layer entirely for a period of time.</p><p id="p-0042" num="0041">As another example, an amount of memory, an amount of memory throughput, and an amount of memory bandwidth used by a layer may be adapted by adjusting weight and/or input/output feature precision and/or by directly executing the ML model layer in external memory.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. <b>7</b>A and <b>7</b>B</figref> are bock diagrams illustrating precision adaptation, in accordance with aspects of the present disclosure. Diagram <b>700</b> of <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> includes an SoC <b>702</b> with an internal memory <b>704</b>. In some cases, the SoC <b>702</b> may include one or more processing cores along with one or more internal memories <b>704</b>. In some cases, the SoC <b>702</b> may be organized as described with respect to SoC <b>222</b>. The internal memory <b>704</b> may include one or more cache or scratch memories. The SoC <b>702</b> may be coupled to an external memory <b>706</b>. The external memory <b>706</b> may include information associated with one or more ML models to be executed on a core of the SoC <b>702</b>. The information associated with an ML model may include runtime code and parameters for the ML model. The parameters for the ML model may include information that may be dynamically loaded from memory for executing the ML model, such as weights, layer ordering information, structure, memory needed to store data input/output between layers, etc.</p><p id="p-0044" num="0043">A layer of an ML model may receive a set of input features which may be input into nodes of the layer. The nodes of the layer may then determine a function based on one or more features input into the node along with one or more weights input into the node. The determined results of the function for the node may be output as a part of an output feature of the layer. In some cases, the weights and features may be associated with a particular bit precision. For example, the weights for the layer may be in the form of a 16-bit float representing a number between 0 and 1. The number of bits representing the weights and features is associated with a level of precision that is able to be represented. For example, 8-bits can represent up to 256 different values, while 16-bits can represent up to 65,536 different values. However, for certain layers, a difference between the number of values that can be represented by the bits representing the weights and features may not be representative of a difference in the quality of the output of the layer. That is, there may be a negligible difference in the quality of the output of certain layers (and ML model as a whole) if the bit value, and hence precision, of the bits representing the weights for the layer are reduced. For example, layers with relatively large weight values often can be quantized into lower bit values as there is often a larger difference between weight values of the layer.</p><p id="p-0045" num="0044">In some cases, after training of an ML model, weights may be associated with the layers of the ML model. These weights may be considered the high-precision weights <b>708</b>. The bit precision of weights associated with a layer may be reduced, for example, by quantizing (e.g., bucketing) bit values associated with the higher number of bits into equally spaced value buckets based on the values available in the lower bit rate. Layers in where the bit precision of the weights can be reduced with a negligible difference in quality may be identified during a compilation/preparation process of the ML model for the target hardware. The lower-precision weights <b>710</b> for a layer may be generated from the high-precision weights <b>708</b> as a part of the compilation/preparation process for those identified layers. For example, weights for the layer may then be quantized from the set of high-precision weights <b>708</b> into weights for a set of lower-precisions weights <b>710</b>. In some cases, each identified layer of the ML model on which lower-precision weights <b>710</b> have a negligible impact on may have lower-precision weights generated for that layer. These lower-precision weights <b>710</b> may be stored in the external memory <b>706</b>. When an adaptation policy is used for a layer, these lower-precision weights <b>710</b> may be loaded from the external memory <b>706</b> to the internal memory <b>704</b> for use in the ML model. The adaptation policy using lower-precision weights <b>710</b> may help reduce an amount of internal memory <b>704</b>, reduce an amount of memory throughput of the internal memory <b>704</b>, as well as reduce an amount of bandwidth as between the external memory <b>704</b> and the SoC <b>702</b> used to process the layer of the ML model.</p><p id="p-0046" num="0045">Features of an ML model may refer to inputs and outputs of a layer of the ML model. For example, a set of input features, which may represent aspects of a part of an image for a recognizer type ML model, may be input into a first layer of the ML model. This first layer may then output a set of output features. This set of output features then may be input as a set of input features to a second layer of the ML model. In some cases, a bit precision of the input features or output features may also be reduced. Layers in where the bit precision of the input features or output features can be reduced with a negligible difference in quality may be identified during a compilation/preparation process of the ML model for the target hardware.</p><p id="p-0047" num="0046">As shown in diagram <b>750</b> of <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, a layer of an ML model may execute on a SoC <b>752</b>. In a first example, the layer may execute using high-precision features <b>754</b> loaded into the internal memory <b>756</b> from external memory <b>758</b>. The layer of the ML model may then be adapted to output either a set of high-precision output features <b>754</b> or a set of lower-precision features <b>760</b> to external memory <b>758</b> based on the adaption policy. The output high-precision output features <b>754</b> may be used to output a set of lower-precision features <b>760</b>, for example, by quantizing the output high-precision output features <b>754</b> into a set of lower-precision features <b>760</b>. Where the adaptation policy is in place for a next layer, the lower-precision features <b>760</b> may be generated and output to external memory <b>758</b> instead of the high-precision output features <b>754</b>. The output high-precision output features <b>754</b> or lower-precision features <b>760</b> may be then stored in the external memory <b>758</b>.</p><p id="p-0048" num="0047">In a second example, the layer of the ML model may execute on SoC <b>752</b> using lower-precision features <b>760</b> loaded into the internal memory <b>756</b> from external memory <b>758</b>. For example, a previous layer of the ML model may have output lower-precision features <b>760</b>. Where the adaptation policy is used for the current layer, the lower-precision features <b>760</b> may be loaded from the external memory <b>758</b> to the internal memory <b>756</b> for use by the current layer. The adaptation policy using lower-precision features <b>760</b> may help reduce an amount of internal memory <b>756</b>, reduce an amount of memory throughput of the internal memory <b>756</b>, as well as reduce an amount of bandwidth as between the external memory <b>758</b> and the SoC <b>752</b> used to process the layer of the ML model.</p><p id="p-0049" num="0048">In some cases, under an adaptation policy, an ML model layer may execute using data directly from external memory. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a block diagram <b>800</b> illustrating executing an ML model layer using data from external memory with memory adaptation, in accordance with aspects of the present disclosure. As shown in diagram <b>800</b>, a SoC <b>802</b> may include multiple cores <b>804</b> and <b>806</b> executing ML models. In some cases, when an ML model is executed without using an adaptation policy, parameters associated with the ML model, such as weights, layer ordering information, structure, features, etc., may be loaded (e.g., staged) from external memory <b>808</b> into a portion <b>812</b> of internal memory <b>810</b> prior to use by the ML model executing on core <b>804</b>. The ML model then accesses the weights, features, etc., from the portion <b>812</b> of internal memory <b>810</b> when running. In some cases, the ML model layer may directly use external memory <b>808</b> to access the parameters associated with the ML model, rather than loading these parameters from external memory <b>808</b> into the portion <b>812</b> of the internal memory <b>810</b>. For example, such an adaptation may be used to reduce an amount of internal memory <b>810</b> used to process the layer of the ML model. This adaptation may also be used to reduce an internal memory throughput used to process the layer of the ML model. While this adaptation may result in reduced performance for the layer and the overall ML model, this adaptation avoids stalling, and thus stopping, execution of the layer entirely for a period of time.</p><p id="p-0050" num="0049">ML Model Compilation</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram <b>900</b> of a process for compiling ML models for target hardware, in accordance with aspects of the present disclosure. Machine learning models <b>902</b>A, <b>902</b>B . . . <b>902</b><i>n </i>(collectively <b>902</b>) are trained during a training phase of development of the respective ML model <b>902</b>. Training an ML model <b>902</b> teaches the ML model <b>902</b> to perform a task. For example, an ML model <b>902</b> for object recognition may be trained by presenting the ML model <b>902</b> with labeled images, including an object, letting the ML model <b>902</b> attempt to identify the object in the image, and then adjusting parameters of the ML model <b>902</b>, such as weights for layers of the ML model <b>902</b>, based on how well the ML model <b>902</b> recognized the object.</p><p id="p-0052" num="0051">Once an ML model <b>902</b> is trained, the ML model <b>902</b> may be compiled and/or prepared for a target hardware by an ML model complier <b>904</b>A, <b>904</b>B, . . . <b>904</b><i>n </i>(collectively). It may be understood that the compilation process may include multiple processes, steps, operations, etc., which may be performed separately, and/or in an automated fashion. In this example, the target hardware <b>906</b> is shown as a simplified version of the device shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, and the target hardware <b>906</b> includes a SoC <b>908</b> with one or more cores <b>910</b>A, <b>910</b>B, . . . <b>910</b><i>n </i>coupled to a shared memory <b>912</b>. The SoC <b>908</b> is also coupled to external memory <b>914</b>. The ML model compiler <b>904</b> helps prepare the ML model <b>902</b> for execution by the target hardware <b>906</b> by translating the ML model <b>902</b> to a runtime code and parameters <b>916</b>A, <b>916</b>B, . . . <b>916</b><i>n </i>(collectively <b>916</b>) that is compatible with the target hardware <b>906</b>.</p><p id="p-0053" num="0052">It may be understood that the compilation process may include multiple sub-processes. For example, in addition to translating the ML model <b>902</b> to runtime code, the compilation process may also include one or more sub-processes analyzing execution of the ML model <b>902</b> on the target hardware. In cases with multiple ML models <b>902</b> executing on multiple cores <b>910</b>, the ML model compiler <b>904</b> may determine which core <b>910</b> an ML model <b>902</b> should run on. The ML model compiler <b>904</b> may also parameterize the ML model <b>902</b> being compiled. In some cases, the ML parameters may include information that may be dynamically loaded from memory for executing the ML model <b>902</b>, such as weights, layer-ordering information, structure, memory needed to store data input/output between layers, etc.</p><p id="p-0054" num="0053">As shown, trained ML models <b>902</b> may be compiled and/or translated for a target hardware by an ML model complier <b>904</b>. In some cases, simulations may be performed after the ML model is trained and as a part of preparing the trained ML model <b>902</b> for execution on the target hardware <b>906</b>. For example, as a part of the compilation and/or translation process, ML model execution on the target hardware <b>906</b> may be simulated. In some cases, the simulation of the ML model execution may be performed as a separate process from the compilation/translation process.</p><p id="p-0055" num="0054">In some cases, the simulation may be repeated with a number of variations of certain constraints, such as with various amounts of available dynamic memory available to be allocated for the cores. In some cases, these simulations may help determine which layers of the ML model <b>902</b> may be adapted. Layers of the ML model <b>902</b> may be simulated executing on the target hardware with one or more adaptation applied. For example, layers of the ML model <b>902</b> may be simulated executing on the target hardware with high-precision weights as well as lower-precision weights to analyze an impact the lower-precision weights have on the overall quality of the ML model. Layers associated with a negligible impact on quality may be identified as layers on which a weight-precision adaptation policy may be applied. For example, output features of a simulated layer using lower-precision weights may be compared to output features of a simulated layer using high-precision weights. If the difference is below a certain threshold, then the layer may be identified as supporting the weight-precision adaptation policy. As another example, output features of the ML model using lower-precision weights for a layer may be compared to output features of the ML model using higher-precision weights for the layer. If the difference is below a certain threshold, then the layer may be identified as supporting the weight-precision adaptation policy. In some cases, each layer of the ML model <b>902</b> may be simulated with and without one or more adaptations applied. In other cases, a subset of the layers of the ML model <b>902</b> may be simulated with one or more adaptations applied. For example, the layers which use more of a resource than the static allocation of the resources may be simulated with one or more adaptations applied.</p><p id="p-0056" num="0055">Similarly, the layers of the ML model <b>902</b> may be simulated executing on the target hardware with high-precision features as well as lower-precision features to help determine which layers of the ML model <b>902</b> may be adapted. For example, layers of the ML model <b>902</b> may be simulated executing on the target hardware with high-precision features as well as lower-precision features to analyze an impact the lower-precision features have on the overall quality of the ML model. Layers associated with a negligible impact on quality may be identified as layers on which a feature-precision adaptation policy may be applied. For example, output features of the ML model using lower-precision features for a layer may be compared to output features of the ML model using higher-precision features for the layer. If the difference is below a certain threshold, then the layer may be identified as supporting the feature-precision adaptation policy.</p><p id="p-0057" num="0056">Similarly, the layers of the ML model <b>902</b> may be simulated for adaptation policies where the amount of power/current used by a layer may be adapted by reducing a speed at which the layer is executed on the core, executing the layer on a more power-efficient core, and/or executing the ML model layer using data from external memory. For example, layers of the ML model <b>902</b> may be simulated with and without one or more of the adaptations active to determine an impact the adaptation has on ML model execution speed, frames per second, latency, power usage, etc. These impacts may be compared to thresholds to determine whether to identify the layer as one on which a corresponding adaptation may be applied.</p><p id="p-0058" num="0057">After the layers on which an adaptation may be applied are identified, an indication of these layers and what adaptation may be applied may be stored as a part of the runtime code and parameters <b>916</b> associated with the ML model. In some cases, portions of the runtime code and parameters <b>916</b> may be loaded into a common context <b>920</b> in the shared memory <b>912</b>.</p><p id="p-0059" num="0058">After compilation of the ML model <b>902</b> to runtime code <b>916</b> for the target hardware <b>906</b>, the parameters of the ML model <b>902</b> may be stored, for example, in the external memory <b>914</b>. When an ML model <b>902</b> is executed, portions of the runtime code and parameters <b>916</b> may be loaded, for example, into a static memory allocation <b>918</b> in shared memory <b>912</b> or other memory. In some cases, a particular ML model <b>902</b> may be executed by a particular ML core <b>910</b> of the ML cores <b>910</b>. Multiple ML models may be executed concurrently across the multiple ML cores. In some cases, certain ML models may be designated to execute on certain cores of the target hardware.</p><p id="p-0060" num="0059">In some cases, resources used by the layers of the ML models may also be determined as a part of the compilation process. As a part of simulations of the ML model executing on the target hardware, resource use of the target hardware may be monitored on a per-layer basis for the ML models. This layer resource usage information may be stored, for example, in the runtime code and parameters <b>916</b> and loaded as a part of the common context <b>920</b> upon ML model execution. In some cases, the layer resource usage information may be relative to the static resources. For example, the layer resource usage information may indicate cases in which a respective layer uses more of a resource than a static allocation of the resource to a core.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates layer-level dynamic resource usage information <b>1000</b>, in accordance with aspects of the present disclosure. In this example, usage information for four resources may be recorded for each layer of a set of ML models. The resources include an amount of memory <b>1002</b> used by the ML model layer, a number of memory banks <b>1004</b>, indicating a measurement of internal memory throughput, used by the ML model layer, a memory bandwidth usage <b>1006</b> by the ML model layer, and an amount of power/current <b>1008</b> used by the ML model layer. As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the amounts may be relative to static resources. For example, a 0 value indicates that for a layer, an amount of that resource used by the layer does not exceed the static allocation of the resource for the core on which the ML model layer is executing. Non-zero values indicate a number of units of the resource that the layer uses in addition to the static allocation of the resource. That is, non-zero values indicate an amount of a dynamic allocation of the resource used for the layer. Thus, layer <b>3</b> may use an additional 1024 bytes of memory in addition to the static allocated memory space along with 3 additional mA of current in addition to the static allocated current for the core for executing the ML model layer. In some cases, additional resource usage information for layers may be generated indicating resource usage with certain adaptations applied.</p><p id="p-0062" num="0061">In some cases, the additional resource usage information may be stored as a part of the context information. In some cases, the additional resource information may be used to generate one or more adaptation policies. For example, the additional resource information generated with different (and/or different combinations) adaptations applied may be combined with information related to the impact the adaptation has on ML model, such as execution speed, frames per second, latency, power usage, etc. to determine one or more adaptation policies. As a more detailed example, if a layer under a first adaptation, such as weight/feature precision adaptation, uses more of the resource than a second adaptation, such as an adaptation where the layer is executed from external memory, but executes at a higher speed under the first adaptation, the first adaptation may be used as a part of a first adaptation policy and the second adaptation may be used as part of a second adaptation policy. These adaptation policies may be determined as a part of the compilation process and during execution of the ML model, either the first or the second adaptation policies may be applied based on the resources available during execution. For example, where more of the resource is available for dynamic allocation, then the first adaptation policy may be applied to help maintain execution speed with the adaptation policy applied. Where less of the resource is available for dynamic allocation, then the second adaptation policy may be applied to help allow the layer to be executed, rather than stalled.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart <b>1100</b> illustrating a technique for determining adaptations for layers of an ML model, in accordance with aspects of the present disclosure. At block <b>1102</b>, an ML model is received, the ML model having one or more layers. For example, a device configured to prepare ML models to execute on a target hardware may receive an ML model, such an NN ML model. At block <b>1104</b>, a layer of the ML model is simulated executing on a target hardware without an adaptation applied to determine a first adaptation criterion. For example, layers of the ML model may be simulated executing on the target hardware without adaptions applied. This helps establish a baseline measurement of resources used by layers of the ML as well as performance of the layers of the ML model, such as a number of times the ML model or layer may be executed per second, how long layers take to run, etc., output feature values of the layer, and overall output of the ML model.</p><p id="p-0064" num="0063">At block <b>1106</b>, the layer of the ML model is simulated executing on the target hardware with the adaptation applied to determine a second adaptation criterion, wherein the adaptation reduces an amount of a resource used by the layer. For example, layers of the ML model may be simulated with one or more adaptations applied. The resources used as well as performance of the layers of the ML with adaptations applied may be determined.</p><p id="p-0065" num="0064">At block <b>1108</b>, a determination that the adaptation may be applied to the layer based on a comparison of the first adaptation criterion and the second adaptation criterion, and an adaptation threshold is made. For example, the performance of layers of ML with adaptations applied are compared to the performance of corresponding layers of the ML without adaptations applied. As a more detailed example, for adaptations which alter the bit precision of the features and/or weights of the layer, a difference between output feature values and/or output of the ML model executed with and without the adaptation applied to the layer may be compared to a threshold to determine that the adaptation has a negligible affect on the ML model and that the adaptation may be applied to the layer. As another example, for the adaptation which slows down execution of the layer on the processing core, executes the layer on another processing core, or executes the layer from external memory, a performance of the layer, such as a number of times the ML model or layer may be executed per second, how long layers take to run, etc. may be determined in context with one or more other ML models simulated executing on the target hardware. This, in turn, may cause layers of the ML model to be stalled waiting for access to one or more resources, thus reducing the performance of layers of the ML model. The ML model may then be simulated, in context with one or more other ML models with one or more adaptation applied, to determine the performance of the layer with adaptations. The performance of the layer with adaptations are then compared to the performance of the layer without adaptations to see if the performance of the layer with adaptations performs at least a threshold amount better than the performance of the layer without adaptations. In some cases, this threshold may be that there is some improvement. If there is at least a threshold amount of performance improvement, a determination is made that adaptation may be applied to the layer. In some cases, steps <b>1104</b>-<b>1108</b> may be repeated for the layers of the ML model using different adaptations and/or combinations of adaptations. In some cases, these steps may be repeated exhaustively for the layers of the ML and available adaptations.</p><p id="p-0066" num="0065">At block <b>1110</b>, an indication that the adaptation may be applied to the layer is output. For example, an indication of which adaptations may be applied to which layers may be output as a part of the runtime code and parameters associated with the ML model.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart <b>1200</b> illustrating a technique for adapting execution of an ML model, in accordance with aspects of the present disclosure. At block <b>1202</b>, an indication to run an ML model on a processing core is received. For example, a device configured to execute ML models, such as an NN, receives an ML model to execute. The ML model may be associated with runtime code and parameters which indicate layers of the ML to which certain adaptations may be applied. At block <b>1204</b>, a resource allocation for running the ML model on the processing core is determined. For example, a set of static resources may be allocated to the processing core executing the ML model. At block <b>1204</b>, a determination that a layer of the ML model will use a first amount of the resource is made. The first amount is more than an amount of the resource allocated. For example, portions of the runtime code and parameters may indicate an amount of resources used by layers of the ML model. In some cases, this information may be loaded into a common context prior to execution of the ML model. In some cases, an amount of one or more resources used by the ML model may exceed the static allocation of the resources. At block <b>1206</b>, a determination is made that an adaptation may be applied to executing the layer of the ML model. For example, the parameters (and/or context information) associated with the ML model may indicate which adaptations may be applied to which layers. In some cases, where the amount of a resource used by the layer of the ML model exceeds the static allocation of the resource, the amount of the used is compared to an amount of the resource statically allocated and an amount of the resource available for dynamic allocation. If the amount of the resource used by the layer of the ML model exceeds the amount of the resource statically allocated and the amount of the resource available for dynamic allocation, the adaptations applicable to the layer for the resource may be applied. At block <b>1208</b>, the layer of the ML model is executed using the adaptation, wherein executing the layer using the adaptation reduces the first amount of the resource used by the layer as compared to running the layer without using the adaptation. In some examples, the determinations of blocks <b>1204</b> and <b>1206</b> are made while the layer of the ML model is being executed by the respective processing core, and thus adaptations may be determined and implemented during the execution of block <b>1208</b> with execution continuing uninterrupted. At block <b>1210</b>, a result of the ML model, based on the executed layer, is output.</p><p id="p-0068" num="0067">In this description, the term &#x201c;couple&#x201d; may cover connections, communications, or signal paths that enable a functional relationship consistent with this description. For example, if device A generates a signal to control device B to perform an action: (a) in a first example, device A is coupled to device B by direct connection; or (b) in a second example, device A is coupled to device B through intervening component C if intervening component C does not alter the functional relationship between device A and device B, such that device B is controlled by device A via the control signal generated by device A.</p><p id="p-0069" num="0068">Modifications are possible in the described embodiments, and other embodiments are possible, within the scope of the claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method, comprising:<claim-text>receiving an indication to execute a portion of a machine learning (ML) model on a processing core;</claim-text><claim-text>determining a resource allocation for executing the ML model on the processing core;</claim-text><claim-text>determining that a layer of the ML model will use a first amount of a resource that causes the resource allocation to be exceeded;</claim-text><claim-text>determining that an adaptation may be applied to executing the layer of the ML model;</claim-text><claim-text>executing the layer of the ML model using the adaptation, wherein executing the layer using the adaptation reduces the first amount of the resource used by the layer as compared to executing the layer without using the adaptation; and</claim-text><claim-text>outputting a result of the ML model based on the executed layer.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining that the layer of the ML will use the first amount of the resource comprises:<claim-text>receiving a request, from the processing core executing the ML model, for a dynamic allocation of a second amount of the resource; and</claim-text><claim-text>determining that there is an insufficient amount of the resource to allocate the second amount to the processing core.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the resource is dynamically allocated to another executing ML model.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the resource comprises one of an amount of memory, an amount of memory bandwidth, an amount of memory throughput, and an amount of current.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the adaptation comprises at least one of:<claim-text>altering a number of bits used to represent features of the layer;</claim-text><claim-text>altering a number of bits used to represent weights of the layer;</claim-text><claim-text>executing the layer on another processing core;</claim-text><claim-text>executing the layer using data directly from external memory; and</claim-text><claim-text>executing the layer at a reduced speed on the processing core.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein adaptations applicable to the layer are predetermined.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the adaptation applicable to the layer are provided in context information associated with the ML model and wherein the determining that the adaptation may be applied is based on the context information.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A non-transitory program storage device comprising instructions stored thereon to cause one or more processors to:<claim-text>receive a machine learning (ML) model, the ML model having one or more layers;</claim-text><claim-text>simulate executing a layer of the ML model on a target hardware without an adaptation applied to determine a first adaptation criterion;</claim-text><claim-text>simulate executing the layer of the ML model on the target hardware with the adaptation applied to determine a second adaptation criterion, wherein the adaptation reduces an amount of a resource used by the layer;</claim-text><claim-text>determine that the adaptation may be applied to the layer based on a comparison of the first adaptation criterion and the second adaptation criterion and an adaptation threshold; and</claim-text><claim-text>output an indication that the adaptation may be applied to the layer.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The non-transitory program storage device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the resource comprises one of an amount of memory, an amount of memory bandwidth, an amount of memory throughput, and an amount of current.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The non-transitory program storage device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the adaptation comprises at least one of:<claim-text>altering a number of bits used to represent features of the layer;</claim-text><claim-text>altering a number of bits used to represent weights of the layer;</claim-text><claim-text>executing the layer on another processing core;</claim-text><claim-text>executing the layer using data directly from external memory; and</claim-text><claim-text>executing the layer at a reduced speed on a processing core of the one or more processors.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The non-transitory program storage device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first adaptation criterion and the second adaptation criterion comprise an amount of time for executing the layer.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The non-transitory program storage device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first adaptation criterion and the second adaptation criterion comprise output values of the layer.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The non-transitory program storage device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first adaptation criterion and the second adaptation criterion comprise output values of the ML model.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The non-transitory program storage device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the instructions further cause the one or more processors to:<claim-text>determine the amount of the resource will be used by the layer; and</claim-text><claim-text>determine the adaptation to apply for the simulated executing of the layer based on the determined amount.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. An electronic device, comprising:<claim-text>a memory; and</claim-text><claim-text>one or more processors operatively coupled to the memory, wherein the one or more processors are configured to execute instructions causing the one or more processors to:<claim-text>receive an indication to execute a portion of a machine learning (ML) model on a processing core;</claim-text><claim-text>determine a resource allocation for executing the ML model on the processing core;</claim-text><claim-text>determine that a layer of the ML model will use a first amount of a resource that causes the resource allocation to be exceeded;</claim-text><claim-text>determine that an adaptation may be applied to executing the layer of the ML model;</claim-text><claim-text>execute the layer of the ML model using the adaptation, wherein executing the layer using the adaptation reduces the first amount of the resource used by the layer as compared to executing the layer without using the adaptation; and</claim-text><claim-text>output a result of the ML model based on the executed layer.</claim-text></claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the one or more processors configured to determine that the layer of the ML will use the first amount of the resource further cause the one or more processors to:<claim-text>receive a request, from the processing core executing the ML model, for a dynamic allocation of a second amount of the resource; and</claim-text><claim-text>determine that there is an insufficient amount of the resource to allocate the second amount to the processing core.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The device of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the resource is dynamically allocated to another executing ML model.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the resource comprises one of an amount of memory, an amount of memory bandwidth, an amount of memory throughput, and an amount of current.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the adaptation comprises at least one of:<claim-text>altering a number of bits used to represent features of the layer;</claim-text><claim-text>altering a number of bits used to represent weights of the layer;</claim-text><claim-text>executing the layer on another processing core;</claim-text><claim-text>executing the layer using data directly from external memory; and</claim-text><claim-text>executing the layer at a reduced speed on the processing core.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The device of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein adaptations applicable to the layer are predetermined.</claim-text></claim></claims></us-patent-application>
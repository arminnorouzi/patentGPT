<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004818A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004818</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17823584</doc-number><date>20220831</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>10</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>003</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>10</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">TARGETED DATA RETRIEVAL AND DECISION-TREE-GUIDED DATA EVALUATION</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16797398</doc-number><date>20200221</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11488027</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17823584</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Optum, Inc.</orgname><address><city>Minnetonka</city><state>MN</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Narasimhan</last-name><first-name>Ravi</first-name><address><city>Cypress</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">There is a need for more effective and efficient data evaluation. This need can be addressed by, for example, techniques for data evaluation in accordance with a shared decision tree data object. In one example, a method includes generating, using a plurality of feature extraction threads, shared evidentiary data; generating, based on a selected shared evidentiary data subset of the shared evidentiary data that correspond to one or more selected nodes of the shared decision tree data object, refined evidentiary data; processing the refined evidentiary data in accordance with the shared decision tree data object to generate an evaluation output and an explanation output; and displaying an evaluation output user interface comprising user interface data describing the evaluation output and the explanation output.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="107.19mm" wi="158.75mm" file="US20230004818A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="254.25mm" wi="207.69mm" orientation="landscape" file="US20230004818A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="242.65mm" wi="204.47mm" orientation="landscape" file="US20230004818A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="229.95mm" wi="205.82mm" orientation="landscape" file="US20230004818A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="269.07mm" wi="205.66mm" orientation="landscape" file="US20230004818A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="275.93mm" wi="174.67mm" file="US20230004818A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="275.93mm" wi="172.72mm" file="US20230004818A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="275.93mm" wi="172.72mm" file="US20230004818A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="275.93mm" wi="174.24mm" file="US20230004818A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="275.93mm" wi="174.07mm" file="US20230004818A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="215.56mm" wi="158.58mm" orientation="landscape" file="US20230004818A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="274.15mm" wi="204.13mm" orientation="landscape" file="US20230004818A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="232.75mm" wi="157.56mm" orientation="landscape" file="US20230004818A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="243.33mm" wi="155.70mm" orientation="landscape" file="US20230004818A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of U.S. Non-Provisional application Ser. No. 16/797,398, filed Feb. 21, 2020, the contents of which are hereby incorporated herein in its entirety by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Various embodiments of the present invention address technical challenges related to performing data evaluation. Various embodiments of the present invention disclose innovative techniques for performing data evaluation using targeted data retrieval and decision-tree-guided data evaluation.</p><heading id="h-0003" level="1">BRIEF SUMMARY</heading><p id="p-0004" num="0003">In general, embodiments of the present invention provide methods, apparatuses, systems, computing devices, computing entities, and/or the like for performing targeted data retrieval and decision-tree-guided data evaluation. Various embodiments of the present invention disclose techniques for performing targeted data retrieval and decision-tree-guided data evaluation that utilize at least one of structured feature extraction threads, unstructured feature extraction threads, shared feature processing interfaces, feature extraction engines, evidence refinement engines, and shared decision tree data objects.</p><p id="p-0005" num="0004">In accordance with one aspect, a method is provided. In one embodiment, the method comprises generating, using a plurality of feature extraction threads, shared evidentiary data, wherein generating the evidentiary data comprises: identifying one or more structured feature extraction threads of the plurality of feature extraction threads and one or more unstructured feature extraction threads of the plurality of feature extraction threads; causing each structured feature extraction thread of the one or more structured feature extraction threads to extract corresponding per-source retrieved feature data from a corresponding structured data source of one or more structured data sources that is associated with the structured feature extraction thread; causing each unstructured feature extraction thread of the one or more unstructured feature extraction threads to (i) extract corresponding per-source unstructured feature data from a corresponding unstructured data source of one or more unstructured data sources that is associated with the unstructured feature extraction thread, and (ii) process the corresponding per-source unstructured feature data for the unstructured feature extraction thread to generate per-source engineered feature data for the unstructured feature extraction thread; and aggregating each per-source retrieved feature data extracted by a structured feature extraction thread of the one or more structured feature extraction threads and each per-source engineered feature data generated by an unstructured feature extraction thread of the one or more unstructured feature extraction threads to generate the evidentiary data; generating, based on a selected evidentiary data subset of the shared evidentiary data that correspond to one or more selected nodes of the shared decision tree data object, refined evidentiary data; processing the refined evidentiary data in accordance with the shared decision tree data object to generate an evaluation output and an explanation output; and providing, for display via a user interface, at least a portion of the evaluation output comprising user interface data indicative of the evaluation output and the explanation output.</p><p id="p-0006" num="0005">In accordance with another aspect, a computer program product is provided. The computer program product may comprise at least one computer-readable storage medium having computer-readable program code portions stored therein, the computer-readable program code portions comprising executable portions configured to generate, using a plurality of feature extraction threads, shared evidentiary data, wherein generating the evidentiary data comprises: identifying one or more structured feature extraction threads of the plurality of feature extraction threads and one or more unstructured feature extraction threads of the plurality of feature extraction threads; causing each structured feature extraction thread of the one or more structured feature extraction threads to extract corresponding per-source retrieved feature data from a corresponding structured data source of one or more structured data sources that is associated with the structured feature extraction thread; causing each unstructured feature extraction thread of the one or more unstructured feature extraction threads to (i) extract corresponding per-source unstructured feature data from a corresponding unstructured data source of one or more unstructured data sources that is associated with the unstructured feature extraction thread, and (ii) process the corresponding per-source unstructured feature data for the unstructured feature extraction thread to generate per-source engineered feature data for the unstructured feature extraction thread; and aggregating each per-source retrieved feature data extracted by a structured feature extraction thread of the one or more structured feature extraction threads and each per-source engineered feature data generated by an unstructured feature extraction thread of the one or more unstructured feature extraction threads to generate the evidentiary data; generate, based on a selected evidentiary data subset of the shared evidentiary data that correspond to one or more selected nodes of the shared decision tree data object, refined evidentiary data; process the refined evidentiary data in accordance with the shared decision tree data object to generate an evaluation output and an explanation output; and provide, for display via a user interface, at least a portion of the evaluation output comprising user interface data indicative of the evaluation output and the explanation output.</p><p id="p-0007" num="0006">In accordance with yet another aspect, an apparatus comprising at least one processor and at least one memory, including computer program code, is provided. In one embodiment, the at least one memory and the computer program code may be configured to, with the processor, cause the apparatus to generate, using a plurality of feature extraction threads, shared evidentiary data, wherein generating the evidentiary data comprises: identifying one or more structured feature extraction threads of the plurality of feature extraction threads and one or more unstructured feature extraction threads of the plurality of feature extraction threads; causing each structured feature extraction thread of the one or more structured feature extraction threads to extract corresponding per-source retrieved feature data from a corresponding structured data source of one or more structured data sources that is associated with the structured feature extraction thread; causing each unstructured feature extraction thread of the one or more unstructured feature extraction threads to (i) extract corresponding per-source unstructured feature data from a corresponding unstructured data source of one or more unstructured data sources that is associated with the unstructured feature extraction thread, and (ii) process the corresponding per-source unstructured feature data for the unstructured feature extraction thread to generate per-source engineered feature data for the unstructured feature extraction thread; and aggregating each per-source retrieved feature data extracted by a structured feature extraction thread of the one or more structured feature extraction threads and each per-source engineered feature data generated by an unstructured feature extraction thread of the one or more unstructured feature extraction threads to generate the evidentiary data; generate, based on a selected evidentiary data subset of the shared evidentiary data that correspond to one or more selected nodes of the shared decision tree data object, refined evidentiary data; process the refined evidentiary data in accordance with the shared decision tree data object to generate an evaluation output and an explanation output; and provide, for display via a user interface, at least a portion of the evaluation output comprising user interface data indicative of the evaluation output and the explanation output.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0008" num="0007">Having thus described the invention in general terms, reference will now be made to the accompanying drawings, which are not necessarily drawn to scale, and wherein:</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> provides an exemplary overview of an architecture that can be used to practice embodiments of the present invention.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> provides an example data evaluation computing entity in accordance with some embodiments discussed herein.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> provides an example client computing entity in accordance with some embodiments discussed herein.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a data flow diagram of an example process for performing data evaluation using a shared decision tree data object in accordance with some embodiments discussed herein.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart diagram of an example process for generating shared evidentiary data in accordance with some embodiments discussed herein.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart diagram of an example process for causing an unstructured feature extraction thread to process per-source unstructured feature data to generate per-source engineered feature data in accordance with some embodiments discussed herein.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart diagram of an example process for generating per-source engineered feature data for an unstructured feature extraction thread in accordance with some embodiments discussed herein.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart diagram of an example process for generating an evidentiary output in accordance with some embodiments discussed herein.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart diagram of an example process for generating an explanation output in accordance with some embodiments discussed herein.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>10</b></figref> provides an operational example of an evaluation output user interface in accordance with some embodiments discussed herein.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>11</b></figref> provides an operational example of a process for thread coordination by a feature extraction engine in accordance with some embodiments discussed herein.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>12</b></figref> provides an operational example of evaluation criteria data in accordance with some embodiments discussed herein.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>13</b></figref> provides operational examples of data sources of various types in accordance with some embodiments discussed herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0022" num="0021">Various embodiments of the present invention now will be described more fully hereinafter with reference to the accompanying drawings, in which some, but not all embodiments of the inventions are shown. Indeed, these inventions may be embodied in many different forms and should not be construed as limited to the embodiments set forth herein; rather, these embodiments are provided so that this disclosure will satisfy applicable legal requirements. The term &#x201c;or&#x201d; is used herein in both the alternative and conjunctive sense, unless otherwise indicated. The terms &#x201c;illustrative&#x201d; and &#x201c;exemplary&#x201d; are used to be examples with no indication of quality level. Like numbers refer to like elements throughout. Moreover, while certain embodiments of the present invention are described with reference to predictive data analysis, one of ordinary skill in the art will recognize that the disclosed concepts can be used to perform other types of data analysis.</p><heading id="h-0006" level="1">I. OVERVIEW</heading><p id="p-0023" num="0022">Various embodiments of the present invention improve efficiency of performing data evaluation by disclosing techniques that enable targeted data retrieval in order to decrease the amount of data needed to be retrieved prior to performing data evaluation. For example, in some embodiments, a data retrieval engine may limit data retrieval to data deemed related to an input entity (e.g., a patient entity) associated with a particular data evaluation task. By limiting the amount of data needed to be retrieved prior to performing data evaluation, various embodiments of the present invention decrease the computational complexity of data retrieval tasks and (in circumstances where retrieval of data requires utilizing network communications) improve network efficiency of data evaluation architectures that utilize remote data sources. In doing so, various embodiments of the present invention improve efficiency of performing data evaluation.</p><p id="p-0024" num="0023">Furthermore, various embodiments of the present invention address technical challenges related to efficiently and reliably performing data evaluation using distributed data evaluation environments. A distributed data evaluation environment is a software solution configured to perform a data evaluation task using input data retrieved from multiple data sources, often a very large number of data sources. An example of a distributed data evaluation environment is a software solution configured to generate prior authorization determinations for proposed medical operations based on data provided from medical-history-related data sources, medical-claim-related data sources, pharmaceutical-history-related data sources, medical-note-related data sources, and/or the like.</p><p id="p-0025" num="0024">The diversity of input data sources in distributed data evaluation environments presents substantial challenges for software developers that intend to design and deploy data analysis software solutions in the noted distributed data evaluation environments. For example, without employing some degree of parallelism, evaluative data analysis would likely be very inefficient in distributed data evaluation environments because of the often large number of data sources in such distributed data evaluation environments, with the task of data retrieval from the data sources acting as an efficiency bottleneck on the system as a whole.</p><p id="p-0026" num="0025">On the other hand, employing parallelism in such distributed data evaluation environments may lead to other challenges. For example, if the data extraction process is followed by some pre-processing on the data (as is very often the case), coordinating utilization of shared pre-processing resources among various execution in order to avoid deadlock situations threads may be challenging. Thus, various existing distributed data evaluation environments suffer from substantial efficiency and reliability challenges due to the technical challenges identified above as well as similar technical challenges.</p><p id="p-0027" num="0026">Various embodiments of the present invention address the above-noted technical challenges related to efficiently and reliably performing data evaluation in distributed data evaluation environments by providing techniques for parallelized data evaluation that utilize a data-source-specific thread to extract data from each source. By utilizing data-source-specific feature extraction threads, the noted embodiments of the present invention prevent deadlock scenarios where multiple feature threads may attempt to extract data from the same data source and/or using the access interface of the same data source at the same time.</p><p id="p-0028" num="0027">In addition, various embodiments of the present invention address the above-noted technical challenges related to efficiently and reliably performing data evaluation in distributed data evaluation environments by providing techniques for parallelized data evaluation that employ parallelism during data retrieval but limit post-retrieval data processing at the feature-extraction stage to extraction threads configured to retrieve unstructured data from unstructured data sources. By limiting post-retrieval data processing at the feature-extracting-thread level to execution threads configured to retrieve unstructured data from unstructured data sources, various embodiments of the present invention provide protocols for thread coordination that reduce the risk of deadlock scenarios in multi-threaded distributed data evaluation environments.</p><heading id="h-0007" level="1">II. COMPUTER PROGRAM PRODUCTS, METHODS, AND COMPUTING ENTITIES</heading><p id="p-0029" num="0028">Embodiments of the present invention may be implemented in various ways, including as computer program products that comprise articles of manufacture. Such computer program products may include one or more software components including, for example, software objects, methods, data structures, or the like. A software component may be coded in any of a variety of programming languages. An illustrative programming language may be a lower-level programming language such as an assembly language associated with a particular hardware architecture and/or operating system platform. A software component comprising assembly language instructions may require conversion into executable machine code by an assembler prior to execution by the hardware architecture and/or platform. Another example programming language may be a higher-level programming language that may be portable across multiple architectures. A software component comprising higher-level programming language instructions may require conversion to an intermediate representation by an interpreter or a compiler prior to execution.</p><p id="p-0030" num="0029">Other examples of programming languages include, but are not limited to, a macro language, a shell or command language, a job control language, a script language, a database query or search language, and/or a report writing language. In one or more example embodiments, a software component comprising instructions in one of the foregoing examples of programming languages may be executed directly by an operating system or other software component without having to be first transformed into another form. A software component may be stored as a file or other data storage construct. Software components of a similar type or functionally related may be stored together such as, for example, in a particular directory, folder, or library. Software components may be static (e.g., pre-established or fixed) or dynamic (e.g., created or modified at the time of execution).</p><p id="p-0031" num="0030">A computer program product may include a non-transitory computer-readable storage medium storing applications, programs, program modules, scripts, source code, program code, object code, byte code, compiled code, interpreted code, machine code, executable instructions, and/or the like (also referred to herein as executable instructions, instructions for execution, computer program products, program code, and/or similar terms used herein interchangeably). Such non-transitory computer-readable storage media include all computer-readable media (including volatile and non-volatile media).</p><p id="p-0032" num="0031">In one embodiment, a non-volatile computer-readable storage medium may include a floppy disk, flexible disk, hard disk, solid-state storage (SSS) (e.g., a solid state drive (SSD), solid state card (SSC), solid state module (SSM), enterprise flash drive, magnetic tape, or any other non-transitory magnetic medium, and/or the like. A non-volatile computer-readable storage medium may also include a punch card, paper tape, optical mark sheet (or any other physical medium with patterns of holes or other optically recognizable indicia), compact disc read only memory (CD-ROM), compact disc-rewritable (CD-RW), digital versatile disc (DVD), Blu-ray disc (BD), any other non-transitory optical medium, and/or the like. Such a non-volatile computer-readable storage medium may also include read-only memory (ROM), programmable read-only memory (PROM), erasable programmable read-only memory (EPROM), electrically erasable programmable read-only memory (EEPROM), flash memory (e.g., Serial, NAND, NOR, and/or the like), multimedia memory cards (MMC), secure digital (SD) memory cards, SmartMedia cards, CompactFlash (CF) cards, Memory Sticks, and/or the like. Further, a non-volatile computer-readable storage medium may also include conductive-bridging random access memory (CBRAM), phase-change random access memory (PRAM), ferroelectric random-access memory (FeRAM), non-volatile random-access memory (NVRAM), magnetoresistive random-access memory (MRAM), resistive random-access memory (RRAM), Silicon-Oxide-Nitride-Oxide-Silicon memory (SONOS), floating junction gate random access memory (FJG RAM), Millipede memory, racetrack memory, and/or the like.</p><p id="p-0033" num="0032">In one embodiment, a volatile computer-readable storage medium may include random access memory (RAM), dynamic random access memory (DRAM), static random access memory (SRAM), fast page mode dynamic random access memory (FPM DRAM), extended data-out dynamic random access memory (EDO DRAM), synchronous dynamic random access memory (SDRAM), double data rate synchronous dynamic random access memory (DDR SDRAM), double data rate type two synchronous dynamic random access memory (DDR2 SDRAM), double data rate type three synchronous dynamic random access memory (DDR3 SDRAM), Rambus dynamic random access memory (RDRAM), Twin Transistor RAM (TTRAM), Thyristor RAM (T-RAM), Zero-capacitor (Z-RAM), Rambus in-line memory module (RIMM), dual in-line memory module (DIMM), single in-line memory module (SIMM), video random access memory (VRAM), cache memory (including various levels), flash memory, register memory, and/or the like. It will be appreciated that where embodiments are described to use a computer-readable storage medium, other types of computer-readable storage media may be substituted for or used in addition to the computer-readable storage media described above.</p><p id="p-0034" num="0033">As should be appreciated, various embodiments of the present invention may also be implemented as methods, apparatuses, systems, computing devices, computing entities, and/or the like. As such, embodiments of the present invention may take the form of an apparatus, system, computing device, computing entity, and/or the like executing instructions stored on a computer-readable storage medium to perform certain steps or operations. Thus, embodiments of the present invention may also take the form of an entirely hardware embodiment, an entirely computer program product embodiment, and/or an embodiment that comprises combination of computer program products and hardware performing certain steps or operations. Embodiments of the present invention are described below with reference to block diagrams and flowchart illustrations. Thus, it should be understood that each block of the block diagrams and flowchart illustrations may be implemented in the form of a computer program product, an entirely hardware embodiment, a combination of hardware and computer program products, and/or apparatuses, systems, computing devices, computing entities, and/or the like carrying out instructions, operations, steps, and similar words used interchangeably (e.g., the executable instructions, instructions for execution, program code, and/or the like) on a computer-readable storage medium for execution. For example, retrieval, loading, and execution of code may be performed sequentially such that one instruction is retrieved, loaded, and executed at a time. In some exemplary embodiments, retrieval, loading, and/or execution may be performed in parallel such that multiple instructions are retrieved, loaded, and/or executed together. Thus, such embodiments can produce specifically-configured machines performing the steps or operations specified in the block diagrams and flowchart illustrations. Accordingly, the block diagrams and flowchart illustrations support various combinations of embodiments for performing the specified instructions, operations, or steps.</p><heading id="h-0008" level="1">III. EXEMPLARY SYSTEM ARCHITECTURE</heading><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is a schematic diagram of an example architecture <b>100</b> for performing parallelized data evaluation. The architecture <b>100</b> includes a data evaluation system <b>101</b> configured to receive data evaluation requests the client computing entities <b>102</b>, process the data evaluation requests to generate evaluation outputs and/or explanation outputs, provide evaluation output interfaces describing evaluation outputs and/or explanation outputs to the client computing entities <b>102</b>, and/or perform evaluation-based actions based on evaluation outputs and/or explanation outputs. For example, the parallelized data evaluation system <b>107</b> may in some embodiments be configured to generate prior authorization determinations for proposed medical operations based on data provided from medical-history-related data sources, medical-claim-related data sources, pharmaceutical-history-related data sources, medical-note-related data sources, and/or the like.</p><p id="p-0036" num="0035">In some embodiments, data evaluation system <b>101</b> may communicate with at least one of the client computing entities <b>102</b> using one or more communication networks. Examples of communication networks include any wired or wireless communication network including, for example, a wired or wireless local area network (LAN), personal area network (PAN), metropolitan area network (MAN), wide area network (WAN), or the like, as well as any hardware, software and/or firmware required to implement it (such as, e.g., network routers, and/or the like).</p><p id="p-0037" num="0036">The data evaluation system <b>101</b> may include a data evaluation computing entity <b>106</b> and a storage subsystem <b>108</b>. The data evaluation computing entity <b>106</b> may be configured to process the data evaluation requests to generate evaluation outputs and/or explanation outputs, provide evaluation output interfaces describing evaluation outputs and/or explanation outputs to the client computing entities <b>102</b>, and/or perform evaluation-based actions based on evaluation outputs and/or explanation outputs. The storage subsystem <b>108</b> may be configured to store at least a portion of input data utilized by the data evaluation computing entity <b>106</b> to perform parallelized predictive data analysis. The storage subsystem <b>108</b> may further be configured to store at least a portion of configuration data (e.g., model definition data) utilized by the data evaluation computing entity <b>106</b> to perform parallelized predictive data analysis.</p><p id="p-0038" num="0037">The storage subsystem <b>108</b> may include one or more storage units, such as multiple distributed storage units that are connected through a computer network. Each storage unit in the storage subsystem <b>108</b> may store at least one of one or more data assets and/or one or more data about the computed properties of one or more data assets. Moreover, each storage unit in the storage subsystem <b>108</b> may include one or more non-volatile storage or memory media including but not limited to hard disks, ROM, PROM, EPROM, EEPROM, flash memory, MMCs, SD memory cards, Memory Sticks, CBRAM, PRAM, FeRAM, NVRAM, MRAM, RRAM, SONOS, FJG RAM, Millipede memory, racetrack memory, and/or the like.</p><heading id="h-0009" level="2">Exemplary Data Evaluation Computing Entity</heading><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>2</b></figref> provides a schematic of a data evaluation computing entity <b>106</b> according to one embodiment of the present invention. In general, the terms computing entity, computer, entity, device, system, and/or similar words used herein interchangeably may refer to, for example, one or more computers, computing entities, desktops, mobile phones, tablets, phablets, notebooks, laptops, distributed systems, kiosks, input terminals, servers or server networks, blades, gateways, switches, processing devices, processing entities, set-top boxes, relays, routers, network access points, base stations, the like, and/or any combination of devices or entities adapted to perform the functions, operations, and/or processes described herein. Such functions, operations, and/or processes may include, for example, transmitting, receiving, operating on, processing, displaying, storing, determining, creating/generating, monitoring, evaluating, comparing, and/or similar terms used herein interchangeably. In one embodiment, these functions, operations, and/or processes can be performed on data, content, information, and/or similar terms used herein interchangeably.</p><p id="p-0040" num="0039">As indicated, in one embodiment, the data evaluation computing entity <b>106</b> may also include one or more communications interfaces <b>220</b> for communicating with various computing entities, such as by communicating data, content, information, and/or similar terms used herein interchangeably that can be transmitted, received, operated on, processed, displayed, stored, and/or the like.</p><p id="p-0041" num="0040">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in one embodiment, the data evaluation computing entity <b>106</b> may include or be in communication with one or more processing elements <b>205</b> (also referred to as processors, processing circuitry, and/or similar terms used herein interchangeably) that communicate with other elements within the data evaluation computing entity <b>106</b> via a bus, for example. As will be understood, the processing element <b>205</b> may be embodied in a number of different ways.</p><p id="p-0042" num="0041">For example, the processing element <b>205</b> may be embodied as one or more complex programmable logic devices (CPLDs), microprocessors, multi-core processors, coprocessing entities, application-specific instruction-set processors (ASIPs), microcontrollers, and/or controllers. Further, the processing element <b>205</b> may be embodied as one or more other processing devices or circuitry. The term circuitry may refer to an entirely hardware embodiment or a combination of hardware and computer program products. Thus, the processing element <b>205</b> may be embodied as integrated circuits, application specific integrated circuits (ASICs), field programmable gate arrays (FPGAs), programmable logic arrays (PLAs), hardware accelerators, other circuitry, and/or the like.</p><p id="p-0043" num="0042">As will therefore be understood, the processing element <b>205</b> may be configured for a particular use or configured to execute instructions stored in volatile or non-volatile media or otherwise accessible to the processing element <b>205</b>. As such, whether configured by hardware or computer program products, or by a combination thereof, the processing element <b>205</b> may be capable of performing steps or operations according to embodiments of the present invention when configured accordingly.</p><p id="p-0044" num="0043">In one embodiment, the data evaluation computing entity <b>106</b> may further include or be in communication with non-volatile media (also referred to as non-volatile storage, memory, memory storage, memory circuitry and/or similar terms used herein interchangeably). In one embodiment, the non-volatile storage or memory may include one or more non-volatile storage or memory media <b>210</b>, including but not limited to hard disks, ROM, PROM, EPROM, EEPROM, flash memory, MMCs, SD memory cards, Memory Sticks, CBRAM, PRAM, FeRAM, NVRAM, MRAM, RRAM, SONOS, FJG RAM, Millipede memory, racetrack memory, and/or the like.</p><p id="p-0045" num="0044">As will be recognized, the non-volatile storage or memory media may store databases, database instances, database management systems, data, applications, programs, program modules, scripts, source code, object code, byte code, compiled code, interpreted code, machine code, executable instructions, and/or the like. The term database, database instance, database management system, and/or similar terms used herein interchangeably may refer to a collection of records or data that is stored in a computer-readable storage medium using one or more database models, such as a hierarchical database model, network model, relational model, entity&#x2014;relationship model, object model, document model, semantic model, graph model, and/or the like.</p><p id="p-0046" num="0045">In one embodiment, the data evaluation computing entity <b>106</b> may further include or be in communication with volatile media (also referred to as volatile storage, memory, memory storage, memory circuitry and/or similar terms used herein interchangeably). In one embodiment, the volatile storage or memory may also include one or more volatile storage or memory media <b>215</b>, including but not limited to RAM, DRAM, SRAM, FPM DRAM, EDO DRAM, SDRAM, DDR SDRAM, DDR2 SDRAM, DDR3 SDRAM, RDRAM, TTRAM, T-RAM, Z-RAM, RIMM, DIMM, SIMM, VRAM, cache memory, register memory, and/or the like.</p><p id="p-0047" num="0046">As will be recognized, the volatile storage or memory media may be used to store at least portions of the databases, database instances, database management systems, data, applications, programs, program modules, scripts, source code, object code, byte code, compiled code, interpreted code, machine code, executable instructions, and/or the like being executed by, for example, the processing element <b>205</b>. Thus, the databases, database instances, database management systems, data, applications, programs, program modules, scripts, source code, object code, byte code, compiled code, interpreted code, machine code, executable instructions, and/or the like may be used to control certain aspects of the operation of the data evaluation computing entity <b>106</b> with the assistance of the processing element <b>205</b> and operating system.</p><p id="p-0048" num="0047">As indicated, in one embodiment, the data evaluation computing entity <b>106</b> may also include one or more communications interfaces <b>220</b> for communicating with various computing entities, such as by communicating data, content, information, and/or similar terms used herein interchangeably that can be transmitted, received, operated on, processed, displayed, stored, and/or the like. Such communication may be executed using a wired data transmission protocol, such as fiber distributed data interface (FDDI), digital subscriber line (DSL), Ethernet, asynchronous transfer mode (ATM), frame relay, data over cable service interface specification (DOCSIS), or any other wired transmission protocol. Similarly, the data evaluation computing entity <b>106</b> may be configured to communicate via wireless client communication networks using any of a variety of protocols, such as general packet radio service (GPRS), Universal Mobile Telecommunications System (UMTS), Code Division Multiple Access 2000 (CDMA2000), CDMA2000 1&#xd7; (1&#xd7;RTT), Wideband Code Division Multiple Access (WCDMA), Global System for Mobile Communications (GSM), Enhanced Data rates for GSM Evolution (EDGE), Time Division-Synchronous Code Division Multiple Access (TD-SCDMA), Long Term Evolution (LTE), Evolved Universal Terrestrial Radio Access Network (E-UTRAN), Evolution-Data Optimized (EVDO), High Speed Packet Access (HSPA), High-Speed Downlink Packet Access (HSDPA), IEEE 802.11 (Wi-Fi), Wi-Fi Direct, 802.16 (WiMAX), ultra-wideband (UWB), infrared (IR) protocols, near field communication (NFC) protocols, Wibree, Bluetooth protocols, wireless universal serial bus (USB) protocols, and/or any other wireless protocol.</p><p id="p-0049" num="0048">Although not shown, the data evaluation computing entity <b>106</b> may include or be in communication with one or more input elements, such as a keyboard input, a mouse input, a touch screen/display input, motion input, movement input, audio input, pointing device input, joystick input, keypad input, and/or the like. The data evaluation computing entity <b>106</b> may also include or be in communication with one or more output elements (not shown), such as audio output, video output, screen/display output, motion output, movement output, and/or the like.</p><heading id="h-0010" level="2">Exemplary Client Computing Entity</heading><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>3</b></figref> provides an illustrative schematic representative of a client computing entity <b>102</b> that can be used in conjunction with embodiments of the present invention. In general, the terms device, system, computing entity, entity, and/or similar words used herein interchangeably may refer to, for example, one or more computers, computing entities, desktops, mobile phones, tablets, phablets, notebooks, laptops, distributed systems, kiosks, input terminals, servers or server networks, blades, gateways, switches, processing devices, processing entities, set-top boxes, relays, routers, network access points, base stations, the like, and/or any combination of devices or entities adapted to perform the functions, operations, and/or processes described herein. Client computing entities <b>102</b> can be operated by various parties. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the client computing entity <b>102</b> can include an antenna <b>312</b>, a transmitter <b>304</b> (e.g., radio), a receiver <b>306</b> (e.g., radio), and a processing element <b>308</b> (e.g., CPLDs, microprocessors, multi-core processors, coprocessing entities, ASIPs, microcontrollers, and/or controllers) that provides signals to and receives signals from the transmitter <b>304</b> and receiver <b>306</b>, correspondingly.</p><p id="p-0051" num="0050">The signals provided to and received from the transmitter <b>304</b> and the receiver <b>306</b>, correspondingly, may include signaling information/data in accordance with air interface standards of applicable wireless systems. In this regard, the client computing entity <b>102</b> may be capable of operating with one or more air interface standards, communication protocols, modulation types, and access types. More particularly, the client computing entity <b>102</b> may operate in accordance with any of a number of wireless communication standards and protocols, such as those described above with regard to the data evaluation computing entity <b>106</b>. In a particular embodiment, the client computing entity <b>102</b> may operate in accordance with multiple wireless communication standards and protocols, such as UMTS, CDMA2000, 1&#xd7;RTT, WCDMA, GSM, EDGE, TD-SCDMA, LTE, E-UTRAN, EVDO, HSPA, HSDPA, Wi-Fi, Wi-Fi Direct, WiMAX, UWB, IR, NFC, Bluetooth, USB, and/or the like. Similarly, the client computing entity <b>102</b> may operate in accordance with multiple wired communication standards and protocols, such as those described above with regard to the data evaluation computing entity <b>106</b> via a network interface <b>320</b>.</p><p id="p-0052" num="0051">Via these communication standards and protocols, the client computing entity <b>102</b> can communicate with various other entities using concepts such as Unstructured Supplementary Service Data (USSD), Short Message Service (SMS), Multimedia Messaging Service (MMS), Dual-Tone Multi-Frequency Signaling (DTMF), and/or Subscriber Identity Module Dialer (SIM dialer). The client computing entity <b>102</b> can also download changes, add-ons, and updates, for instance, to its firmware, software (e.g., including executable instructions, applications, program modules), and operating system.</p><p id="p-0053" num="0052">According to one embodiment, the client computing entity <b>102</b> may include location determining aspects, devices, modules, functionalities, and/or similar words used herein interchangeably. For example, the client computing entity <b>102</b> may include outdoor positioning aspects, such as a location module adapted to acquire, for example, latitude, longitude, altitude, geocode, course, direction, heading, speed, universal time (UTC), date, and/or various other information/data. In one embodiment, the location module can acquire data, sometimes known as ephemeris data, by identifying the number of satellites in view and the relative positions of those satellites (e.g., using global positioning systems (GPS)). The satellites may be a variety of different satellites, including Low Earth Orbit (LEO) satellite systems, Department of Defense (DOD) satellite systems, the European Union Galileo positioning systems, the Chinese Compass navigation systems, Indian Regional Navigational satellite systems, and/or the like. This data can be collected using a variety of coordinate systems, such as the Decimal Degrees (DD); Degrees, Minutes, Seconds (DMS); Universal Transverse Mercator (UTM); Universal Polar Stereographic (UPS) coordinate systems; and/or the like. Alternatively, the location information/data can be determined by triangulating the client computing entity's <b>102</b> position in connection with a variety of other systems, including cellular towers, Wi-Fi access points, and/or the like. Similarly, the client computing entity <b>102</b> may include indoor positioning aspects, such as a location module adapted to acquire, for example, latitude, longitude, altitude, geocode, course, direction, heading, speed, time, date, and/or various other information/data. Some of the indoor systems may use various position or location technologies including RFID tags, indoor beacons or transmitters, Wi-Fi access points, cellular towers, nearby computing devices (e.g., smartphones, laptops) and/or the like. For instance, such technologies may include the iBeacons, Gimbal proximity beacons, Bluetooth Low Energy (BLE) transmitters, NFC transmitters, and/or the like. These indoor positioning aspects can be used in a variety of settings to determine the location of someone or something to within inches or centimeters.</p><p id="p-0054" num="0053">The client computing entity <b>102</b> may also comprise a user interface (that can include a display <b>316</b> coupled to a processing element <b>308</b>) and/or a user input interface (coupled to a processing element <b>308</b>). For example, the user interface may be a user application, browser, user interface, and/or similar words used herein interchangeably executing on and/or accessible via the client computing entity <b>102</b> to interact with and/or cause display of information/data from the data evaluation computing entity <b>106</b>, as described herein. The user input interface can comprise any of a number of devices or interfaces allowing the client computing entity <b>102</b> to receive data, such as a keypad <b>318</b> (hard or soft), a touch display, voice/speech or motion interfaces, or other input device. In embodiments including a keypad <b>318</b>, the keypad <b>318</b> can include (or cause display of) the conventional numeric (0-9) and related keys (#, *), and other keys used for operating the client computing entity <b>102</b> and may include a full set of alphabetic keys or set of keys that may be activated to provide a full set of alphanumeric keys. In addition to providing input, the user input interface can be used, for example, to activate or deactivate certain functions, such as screen savers and/or sleep modes.</p><p id="p-0055" num="0054">The client computing entity <b>102</b> can also include volatile storage or memory <b>322</b> and/or non-volatile storage or memory <b>324</b>, which can be embedded and/or may be removable. For example, the non-volatile memory may be ROM, PROM, EPROM, EEPROM, flash memory, MMCs, SD memory cards, Memory Sticks, CBRAM, PRAM, FeRAM, NVRAM, MRAM, RRAM, SONOS, FJG RAM, Millipede memory, racetrack memory, and/or the like. The volatile memory may be RAM, DRAM, SRAM, FPM DRAM, EDO DRAM, SDRAM, DDR SDRAM, DDR2 SDRAM, DDR3 SDRAM, RDRAM, TTRAM, T-RAM, Z-RAM, RIMM, DIMM, SIMM, VRAM, cache memory, register memory, and/or the like. The volatile and non-volatile storage or memory can store databases, database instances, database management systems, data, applications, programs, program modules, scripts, source code, object code, byte code, compiled code, interpreted code, machine code, executable instructions, and/or the like to implement the functions of the client computing entity <b>102</b>. As indicated, this may include a user application that is resident on the entity or accessible through a browser or other user interface for communicating with the data evaluation computing entity <b>106</b> and/or various other computing entities.</p><p id="p-0056" num="0055">In another embodiment, the client computing entity <b>102</b> may include one or more components or functionality that are the same or similar to those of the data evaluation computing entity <b>106</b>, as described in greater detail above. As will be recognized, these architectures and descriptions are provided for exemplary purposes only and are not limiting to the various embodiments.</p><p id="p-0057" num="0056">In various embodiments, the client computing entity <b>102</b> may be embodied as an artificial intelligence (AI) computing entity, such as an Amazon Echo, Amazon Echo Dot, Amazon Show, Google Home, and/or the like. Accordingly, the client computing entity <b>102</b> may be configured to provide and/or receive information/data from a user via an input/output mechanism, such as a display, a camera, a speaker, a voice-activated input, and/or the like. In certain embodiments, an AI computing entity may comprise one or more predefined and executable program algorithms stored within an onboard memory storage module, and/or accessible over a network. In various embodiments, the AI computing entity may be configured to retrieve and/or execute one or more of the predefined program algorithms upon the occurrence of a predefined trigger event.</p><heading id="h-0011" level="1">IV. EXEMPLARY SYSTEM OPERATIONS</heading><p id="p-0058" num="0057">As described below, various embodiments of the present invention relate to disclosing techniques for performing data evaluation in a parallelized manner. An exemplary application of the noted parallelized data evaluation concepts relate to determining prior authorization determinations for proposed medical operations. Aspects of the parallelized data evaluation concepts and the automated prior authorization determination concepts are described in greater detail below.</p><p id="p-0059" num="0058">Various embodiments of the present invention utilize the parallelized data evaluation concepts described below to determine prior authorization determinations for proposed medical operations based at least in part on input data associated with corresponding patients related to the proposed medical operations. For example, in some embodiments, the data evaluation computing entity <b>106</b> may extract (e.g., using a parallelized data extraction procedure) evidentiary data describing patient history and/or patient demographics of a patient that is subject of a prior authorization task, refine the extracted evidentiary data in accordance with a decision tree data object that describes the pre-authorization requirements for generating a positive prior authorization determination for the noted prior authorization task in order to isolate portions of the extracted evidentiary that relate to the noted pre-authorization requirements, process the refined evidentiary data in accordance with the decision tree data object in order to determine a prior authorization determination for the proposed medical operation, aggregate the refined evidentiary data used to reach the prior authorization determination to generate an explanation output for the prior authorization determination, and present display data related to the prior authorization determination and the explanation output using a prior authorization user interface configured to display prior-authorization-related data to end-users (e.g., to physicians, nurses, hospital staff, and/or the like).</p><p id="p-0060" num="0059">However, while various embodiments of the present invention describe the data evaluation concepts of the present invention in relation to prior authorization determination for proposed medical operations, a person of ordinary skill in the relevant technology will recognize that the data evaluation concepts can be utilized to perform any data evaluation task in an efficient and reliable manner.</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a data flow diagram of an example process <b>400</b> for performing data evaluation of distributed evidentiary data in accordance a shared decision tree data object. Via the various steps/operations of the process <b>400</b>, the data evaluation computing entity <b>106</b> can reduce occurrence likelihood of deadlock scenarios in predictive data analysis systems that utilize distributed input data sources, thus increasing the operational reliability of the noted predictive data analysis systems.</p><p id="p-0062" num="0061">The process <b>400</b> begins when a feature extraction engine <b>401</b> of the data evaluation computing entity <b>106</b> generates shared evidentiary data <b>411</b> using a plurality of feature extraction threads. The shared evidentiary data <b>411</b> may include a collection of data objects that are deemed related to an input entity, where an input entity may be a data object that describes a real-world entity and/or a real-world phenomenon with respect to which data evaluation is performed. For example, the shared evaluation data may include medical history data of a patient input entity. The shared evidentiary data <b>411</b> may be generated based on input data stored on the storage subsystem <b>108</b> and/or storage data provided by a client computing entity <b>102</b>.</p><p id="p-0063" num="0062">The feature extraction engine <b>401</b> may generate the shared evidentiary data <b>411</b> based on data retrieved from a plurality of evidentiary data sources (not depicted). An evidentiary data source may be any storage platform and/or portion of a storage platform that stores at least one of one or more data assets including evidentiary data associated with one or more input entities. Examples of data sources include clinical data sources, medical claims data sources, lab results data sources, pharmaceutical history data sources, medical note data objects (e.g., physician-generated medical note data objects) and/or the like. In some embodiments, to retrieve data from the plurality of evidentiary data sources, the feature extraction engine <b>401</b> utilizes a plurality of feature extraction threads, where each feature extraction thread may be configured to retrieve evidentiary data associated with a target input entity from an evidentiary data source of the plurality of evidentiary data sources that is associated with the feature extraction thread.</p><p id="p-0064" num="0063">In some embodiment, retrieval of data by the feature extraction threads is performed by data extraction policies that are defined in accordance with the data evaluation. For example, when a data evaluation pertains to a particular patient entity, the feature extraction threads may be configured to retrieve structured data and unstructured data deemed related to the particular patient entity. In some embodiments, retrieval of data by the feature extraction threads is performed by data extraction policies that are defined in accordance with at least a subset of nodes of a decision tree associated with the data evaluation. For example, when a data evaluation pertains to a medical data evaluation subject, the decision tree of the data evaluation may describe the medical data evaluation subject association of the data evaluation, and the threads may be configured to retrieve structured data and unstructured data deemed related to medical information of the particular patient entity.</p><p id="p-0065" num="0064">In some embodiments, to generate the shared evidentiary data <b>411</b>, the feature extraction engine <b>401</b> performs the steps/operations of the process depicted in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. As depicted in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, at step/operation <b>501</b>, the feature extraction engine <b>401</b> causes each structured feature extraction thread of one or more feature extraction threads to extract corresponding retrieved feature data from corresponding structured data source of one or more structured data sources that is associated with the structured feature extraction thread. A structured data source may be a data source that stores structured data, where structured data may include a collection of data objects that are organized in a manner that clearly indicates the relationships between the data objects. Examples of structured data include data stored in at least one of relational databases, graph-based databases, object-oriented databases, and/or the like. A structured feature extraction thread may be a feature extraction thread that is configured to extract data from a structured data source that is associated with the structured feature extraction thread.</p><p id="p-0066" num="0065">At step/operation <b>502</b>, the feature extraction engine <b>401</b> causes each unstructured feature extraction thread of one or more unstructured feature extraction threads to extract corresponding unstructured feature data from an unstructured data source of one or more unstructured data sources. An unstructured data source may be a data source that stores unstructured data, where unstructured data may include a collection of data objects that are not organized in a manner that clearly indicates the relationships between the data objects. Examples of unstructured data include natural language data, such as natural language medical note data.</p><p id="p-0067" num="0066">Operational examples of structured data sets and unstructured data sets are depicted in <figref idref="DRAWINGS">FIG. <b>13</b></figref>. <figref idref="DRAWINGS">FIG. <b>13</b></figref> displays four data sets, three of which are structured data sets and one of which is an unstructured data set. In particular, the four sets displayed in <figref idref="DRAWINGS">FIG. <b>13</b></figref> include a medical claims data set <b>1301</b> that is a structured data set, a clinical notes data set <b>1302</b> that is an unstructured natural language data set, a lab results data set <b>1303</b> that is a structured data set, and a pharmaceutical history data set <b>1304</b> that is a structured data set.</p><p id="p-0068" num="0067">Returning to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, at step/operation <b>503</b>, the feature extraction engine <b>401</b> causes each unstructured feature extraction thread of the one or more unstructured feature extraction threads to process corresponding per-source unstructured feature data for the unstructured feature extraction thread using a shared feature processing interface to generate per-source engineered feature data for the unstructured feature extraction thread.</p><p id="p-0069" num="0068">In some embodiments, the feature extraction engine <b>401</b> causes each unstructured feature extraction thread to utilize a shared feature processing interface accessible by all of the unstructured feature extraction threads in order to generate, based on the corresponding per-source unstructured feature data for the unstructured feature extraction thread, per-source engineered feature data for the unstructured feature extraction thread, where the per-source engineered feature data for an unstructured feature extraction thread may include a collection of structured data objects generated by processing the corresponding per-source unstructured feature data for the unstructured feature extraction thread using the shared feature processing interface.</p><p id="p-0070" num="0069">The shared feature processing interface may include a collection of computer-implemented processes configured to generate inferred structured data based on input unstructured data. An example of a shared feature processing interface is a shared natural language processing (NLP) engine comprising one or more NLP processes configured to generate inferred structured data based on input unstructured natural language data. For example, a shared NLP engine may be configured to extract metadata (e.g., associated patient identifiers, associate diagnosis codes, associated operational codes, and/or the like) from natural language medical note documents.</p><p id="p-0071" num="0070">In some embodiments, step/operation <b>503</b> may be performed on a per-unstructured-thread level in accordance with the process depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. As depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, at step/operation <b>601</b>, an unstructured feature extraction thread determines a feature-relevant subset of per-source unstructured feature data for the particular unstructured feature extraction thread. The feature-relevant subset of the per-source unstructured feature data for the unstructured feature extraction thread may be a collection of data objects from the per-source unstructured feature data that are deemed with certainty to be associated with an input entity subject to the data evaluation. For example, a feature relevant subset may include medical note documents that are deemed with certainty to be associated with a patient input entity subject to the data evaluation.</p><p id="p-0072" num="0071">At step/operation <b>602</b>, the particular unstructured feature extraction thread determines a potentially feature-relevant subset of per-source unstructured feature data for the unstructured feature extraction thread. The potentially feature-relevant subset of the per-source unstructured feature data for the unstructured feature extraction thread may be a collection of data objects from the per-source unstructured feature data that are deemed with some degree of uncertainty to be associated with an input entity subject to the data evaluation. For example, a feature relevant subset may include medical note documents that are deemed with some degree of uncertainty to be associated with a patient input entity subject to the data evaluation.</p><p id="p-0073" num="0072">At step/operation <b>603</b>, the unstructured feature extraction thread generates per-source engineered feature data for the unstructured feature extraction thread based on at least one of the feature-relevant subset for the unstructured feature extraction thread and the potentially feature-relevant subset for the unstructured feature extraction thread. In some embodiments, the unstructured feature extraction thread combines the feature-relevant subset for the unstructured feature extraction thread and at least a portion of the potentially feature-relevant subset for the unstructured feature extraction thread to generate the per-source engineered feature data for the unstructured feature extraction thread.</p><p id="p-0074" num="0073">In some embodiments, step/operation <b>603</b> may be performed in accordance with the process depicted in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. As depicted in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, at step/operation <b>701</b>, the unstructured feature extraction thread determines confirmation data for the potentially feature-relevant subset. The confirmation data may include a collection of data objects that describe, for each data object in the potentially feature-relevant subset, whether association of the data object with an input entity subject to the data evaluation has been confirmed by a secondary authority (e.g., a secondary authority using human-generated data, such as physician confirmatory data, provider confirmatory data, insurance confirmatory data, and/or the like).</p><p id="p-0075" num="0074">At step/operation <b>702</b>, the unstructured feature extraction thread identifies a confirmed subset of potentially-relevant subset based on the confirmation data. In some embodiments, the confirmed subset includes each potentially relevant data object in the potentially-relevant subset whose association with an input entity subject to the data evaluation has been confirmed by at least one data object in the confirmation data. In some embodiments, the confirmed subset includes each potentially relevant data object in the potentially-relevant subset whose association with an input entity subject to the data evaluation has been confirmed by a predefined threshold number of data objects in the confirmation data. In some embodiments, the confirmed subset includes each potentially relevant data object in the potentially-relevant subset whose association with an input entity subject to the data evaluation has been confirmed by a predefined threshold ratio of data objects in the confirmation data. In some embodiments, the confirmed subset includes each potentially relevant data object in the potentially-relevant subset whose association with an input entity subject to the data evaluation has been confirmed by a predefined threshold ratio of data objects related to the potentially relevant data object in the confirmation data.</p><p id="p-0076" num="0075">At step/operation <b>703</b>, the unstructured feature extraction thread generates the per-source engineered feature data for the unstructured feature extraction thread based on the feature-relevant subset for the unstructured feature extraction thread and the confirmed subset of the potentially feature-relevant subset the unstructured feature extraction thread. In some embodiments, the unstructured feature extraction thread combines the following two sets of unstructured data objects in order to generate an aggregated set of unstructured data objects deemed related to an input entity subject to the data evaluation: (i) the set of unstructured data objects (e.g., medical note documents) deemed with certainty to be related to the input entity; and (ii) the set of unstructured data objects deemed with some degree of uncertainty to be related to an input entity subject to the data evaluation and who have been confirmed by the confirmation data in order to provide a selected set of unstructured data objects deemed. Thereafter, the unstructured feature extraction thread may utilize the aggregated set of unstructured data objects to generate per-source engineered feature data for the unstructured feature extraction thread.</p><p id="p-0077" num="0076">Returning to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, at step/operation <b>504</b>, the feature extraction engine <b>401</b> aggregates each per-source retrieved feature data extracted by a structured feature extraction thread of the one or more structured feature extraction threads and each per-source engineered feature data generated by an unstructured feature extraction thread of the one or more unstructured feature extraction threads to generate the shared evidentiary data <b>411</b>. In some embodiments, the feature extraction engine <b>401</b> combines structured data retrieved from structured data sources by structured feature extraction threads and engineered structured data generated based on unstructured data retrieved unstructured data sources by unstructured feature extraction threads to generate the per-source retrieved feature data.</p><p id="p-0078" num="0077">An operational example of a process <b>1100</b> for thread coordination by the feature extraction engine <b>401</b> is depicted in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. As depicted in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the feature extraction engine <b>401</b> causes each structured feature extraction thread <b>1101</b>A-N to retrieve structured data from a respective structured data source <b>1102</b>A-N. For example, the feature extraction engine <b>401</b> causes the structured feature extraction thread <b>1101</b>A to retrieve structured data from a respective structured data source <b>1102</b>A, the structured feature extraction thread <b>1101</b>B to retrieve structured data from a respective structured data source <b>1102</b>B, and the structured feature extraction thread <b>1101</b>N to retrieve structured data from a respective structured data source <b>1102</b>N.</p><p id="p-0079" num="0078">Furthermore, the feature extraction engine <b>401</b> causes each unstructured feature extraction thread <b>1103</b>A-N to retrieve unstructured data from a respective unstructured data source <b>1104</b>A-N and to process the retrieved structured data using a shared feature processing interface <b>1105</b> to generate corresponding engineered structured data.</p><p id="p-0080" num="0079">For example, the feature extraction engine <b>401</b> causes the unstructured feature extraction thread <b>1103</b>A to retrieve unstructured data from a respective unstructured data source <b>1104</b>A and to process the retrieved structured data using a shared feature processing interface <b>1105</b> to generate corresponding engineered structured data. As another example, the feature extraction engine <b>401</b> causes the unstructured feature extraction thread <b>1103</b>B to retrieve unstructured data from a respective unstructured data source <b>1104</b>B and to process the retrieved structured data using a shared feature processing interface <b>1105</b> to generate corresponding engineered structured data. As a further example, the feature extraction engine <b>401</b> causes the unstructured feature extraction thread <b>1103</b>N to retrieve unstructured data from a respective unstructured data source <b>1104</b>N and to process the retrieved structured data using a shared feature processing interface <b>1105</b> to generate corresponding engineered structured data.</p><p id="p-0081" num="0080">Moreover, the feature extraction engine <b>401</b> may in some embodiments cause each unstructured feature extraction thread <b>1103</b>A-N to generate the engineered structured data generated for the unstructured feature extraction thread <b>1103</b>A-N to the feature extraction engine <b>401</b>.</p><p id="p-0082" num="0081">For example, the feature extraction engine <b>401</b> causes the unstructured feature extraction thread <b>1103</b>A to generate the engineered structured data generated for the unstructured feature extraction thread <b>1103</b>A to the feature extraction engine <b>401</b>. As another example, the feature extraction engine <b>401</b> causes the unstructured feature extraction thread <b>1103</b>B to generate the engineered structured data generated for the unstructured feature extraction thread <b>1103</b>B to the feature extraction engine <b>401</b>. For example, the feature extraction engine <b>401</b> causes the unstructured feature extraction thread <b>1103</b>N to generate the engineered structured data generated for the unstructured feature extraction thread <b>1103</b>N to the feature extraction engine <b>401</b>.</p><p id="p-0083" num="0082">Returning to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, subsequent to generating the shared evidentiary data <b>411</b>, the feature extraction engine <b>401</b> provides the shared evidentiary data <b>411</b> to the evidence refinement engine <b>402</b> of the data evaluation computing entity <b>106</b>. The evidence refinement engine <b>402</b> is configured to refined evidentiary data <b>412</b> based on a selected evidentiary data subset of the shared evidentiary data <b>411</b> that correspond to one or more selected nodes of the shared decision tree data object. The shared decision tree data object may be a data object that describes one or more evaluation criteria for a particular data evaluation. The shared decision tree data object may further be associated with a sufficiency criterion that describes one or more combinations of the evaluation criteria described by the shared decision tree data object that satisfy the requirements of the particular data evaluation associated with the shared decision tree data object.</p><p id="p-0084" num="0083">For example, a shared decision tree data object may have five evaluation criteria EC<sub>1</sub>, EC<sub>2</sub>, EC<sub>3</sub>, EC4<sub>4</sub>, and EC<sub>5</sub>. An example sufficiency criterion for the shared decision tree data object may describe that, to satisfy the requirements of the particular data evaluation associated with the shared decision tree data object, the refined evidentiary data must satisfy at least three of the noted five evaluation criteria. Another example sufficiency criterion for the shared decision tree data object may describe that, to satisfy the requirements of the particular data evaluation associated with the shared decision tree data object, the refined evidentiary data must satisfy either at least three of the noted five evaluation criteria if the refined evidentiary data does not satisfy the first evaluation criterion EC<sub>1 </sub>and at least two of the noted five evaluation criteria if the refined evidentiary data satisfies the first evaluation criterion EC<sub>1</sub>. A yet another example sufficiency criterion for the shared decision tree data object may describe that, to satisfy the requirements of the particular data evaluation associated with the shared decision tree data object, the refined evidentiary data must satisfy the first evaluation criterion EC<sub>1 </sub>and at least three other evaluation criteria of the five noted evaluation criteria. A further example sufficiency criterion for the shared decision tree data object may describe that, to satisfy the requirements of the particular data evaluation associated with the shared decision tree data object, the refined evidentiary data must satisfy both of at least one of the first evaluation criterion EC<sub>1 </sub>and the second evaluation criterion EC<sub>2 </sub>and at least two other evaluation criteria of the five noted evaluation criteria.</p><p id="p-0085" num="0084">An operational example of evaluation criteria data object <b>1200</b> that can be used to generate a shared decision tree data object is presented in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. As depicted in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the evaluation criteria data object <b>1200</b> include nine evaluation-criteria-related segments <b>1201</b> and two sufficiency-criterion-related portions <b>1202</b>. In some embodiments, the data evaluation computing entity <b>106</b> may utilize the evaluation criteria data object <b>1200</b> to generate a shared decision tree data objects with nine leaf nodes corresponding to the nine evaluation-criteria-related segments <b>1201</b> of the evaluation criteria data object <b>1200</b> and a sufficiency criterion indicating that at least one of the nine leaf nodes must be met for the shared decision tree data object to be deemed satisfied. In some embodiments, the data evaluation computing entity <b>106</b> may combine evaluation criteria information from two or more evaluation criteria data objects to generate a shared evaluation data object. In some embodiments, the data evaluation computing entity <b>106</b> may receive the shared decision tree data object from a client computing entity <b>102</b> and/or from an external computing entity.</p><p id="p-0086" num="0085">The refined evidentiary data <b>412</b> may include a subset of the shared evidentiary data <b>411</b> that correspond to the evaluation criteria described by the shared decision tree data object for the data evaluation. In some embodiments, generating the refined evidentiary data comprises identifying, based on the shared decision tree data object, one or more evaluation criterion data objects, wherein each evaluation criterion data object of the one or more evaluation criterion data objects corresponds to a selected node of the selected nodes of the shared decision tree data object; determining a classification-relevant subset of the shared evidentiary data that correspond to the one or more evaluation criterion data objects; and generating the refined evidentiary data based on the classification-relevant subset.</p><p id="p-0087" num="0086">After generating the refined evidentiary data <b>412</b>, the evidence refinement engine <b>402</b> provides the refined evidentiary data <b>412</b> to the evaluation engine <b>403</b> of the data evaluation computing entity <b>106</b>. The evaluation engine <b>403</b> may be configured to process the refined evidentiary data in accordance with the shared decision tree data object to generate an evaluation output <b>413</b> and an explanation output <b>414</b>.</p><p id="p-0088" num="0087">The evaluation output <b>413</b> may be a data object that indicates whether the input entity subject to the data evaluation satisfies the requirements of the data evaluation. To generate the evaluation output <b>413</b>, the evidence refinement engine <b>402</b> may determine whether the refined evidentiary data <b>412</b> satisfy the requirements described by the evaluation criteria of the shared decision tree data object and the sufficiency criterion of the shared decision tree data object. In some embodiments, the input entity is a patient input entity, the shared evidentiary data comprises medical history data of the patient input entity, the shared decision tree data object describes authorization criteria for a proposed medical operation, and the evaluation output describes an authorization determination for the proposed medical operation with respect to the patient input entity.</p><p id="p-0089" num="0088">In some embodiments, the evaluation engine <b>403</b> may generate the evaluation output <b>413</b> in accordance with the various steps/operations of the process depicted in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. As depicted in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, at step/operation <b>801</b>, the evaluation engine <b>403</b> determines a per-criterion evaluation for each evaluation criterion of one or more evaluation criteria described by the shared decision tree data object based on the refined evidentiary data <b>412</b>. The per-criterion evaluation for an evaluation criterion may be a data object that describes whether the refined evidentiary data <b>412</b> provides sufficient evidence indicating that the evaluation criterion has been satisfied.</p><p id="p-0090" num="0089">For example, if an evaluation criterion requires history of heart failure, the per-criterion evaluation for the evaluation criterion may indicate whether refined evidentiary data <b>412</b> describing medical history of a corresponding patient input entity describes a history of heart failure in relation to the corresponding patient input entity. As another example, if an evaluation criterion requires chronic kidney disease, the per-criterion evaluation for the evaluation criterion may indicate whether refined evidentiary data <b>412</b> describing medical condition of a corresponding patient input entity describes chronic kidney disease in relation to corresponding patient input entity. As yet another example, if an evaluation criterion requires at least 45 years of age, the per-criterion evaluation for the evaluation criterion may indicate whether refined evidentiary data <b>412</b> describing demographic information of a corresponding patient input entity describes that the corresponding patient input entity is at least 45 years of age.</p><p id="p-0091" num="0090">At step/operation <b>802</b>, the evaluation engine <b>403</b> a positive evaluation subset of the one or more evaluation criteria described by the shared decision tree data object based on each per-criterion evaluation for an evaluation criterion of the one or more evaluation criteria. In some embodiments, the positive evaluation subset comprises each evaluation criteria described by the shared decision tree data object that the refined evidentiary data <b>412</b> indicates as having been satisfied by the shared evidentiary data <b>411</b>.</p><p id="p-0092" num="0091">For example, in some embodiments, if an evaluation criterion requires chronic kidney disease, and further if the per-criterion evaluation for the evaluation criterion indicates that refined evidentiary data <b>412</b> describes that a corresponding patient input entity has chronic kidney disease, the evaluation criteria will be in the positive evaluation subset of the one or more evaluation criteria described by the shared decision tree data object. As another example, if an evaluation criterion requires at least 45 years age, and further if the per-criterion evaluation for the evaluation criterion indicates that refined evidentiary data <b>412</b> describes that a corresponding patient input entity is 55 years of age, the evaluation criteria will be in the positive evaluation subset of the one or more evaluation criteria described by the shared decision tree data object.</p><p id="p-0093" num="0092">At step/operation <b>803</b>, the evaluation engine <b>403</b> generates the evaluation output <b>413</b> based on whether the positive evaluation subset satisfies a sufficiency criterion for the shared decision tree data object. In some embodiments, the sufficiency criterion is a data object describes a threshold count of evaluation criteria described by the shared decision tree data object. In some of the noted embodiments, the evaluation output <b>413</b> describes whether the count of evaluation criteria in the positive evaluation subset satisfies the threshold count of evaluation criteria described by the sufficient criterion. In some embodiments, the sufficiency criterion is a data object describes one or more acceptable evaluation criteria combinations. In some of the noted embodiments, the evaluation output <b>413</b> describes whether at least one of the evaluation criteria in the positive evaluation subset corresponds to at least one of the one or more acceptable evaluation criteria combinations described by the sufficient criterion. In some embodiments, the sufficiency criterion is a data object describes one or more required properties of acceptable evaluation criteria combinations. In some of the noted embodiments, the evaluation output <b>413</b> describes whether at least one of the evaluation criteria in the positive evaluation subset satisfies at least one of the one or more required properties of acceptable evaluation criteria combinations described by the sufficient criterion.</p><p id="p-0094" num="0093">The explanation output <b>414</b> may be a data object that describes at least one mapping between at least a portion of the shared evidentiary data <b>411</b> and at least a portion of the evaluation criteria described by the shared decision tree data object. For example, the explanation output <b>414</b> may describe which portions of the refined evidentiary data <b>412</b> are used as support to reach a determination that a corresponding input entity has satisfied a particular evaluation criterion described by the shared decision tree data object and/or has failed to satisfy a particular evaluation criterion described by the shared decision tree data object. As another example, the explanation output <b>414</b> may describe which evaluation criteria described by the shared decision tree data object have been satisfied by the refined evidentiary data <b>412</b> and/or which evaluation criteria described by the shared decision tree data object have not been satisfied by the refined evidentiary data <b>412</b>.</p><p id="p-0095" num="0094">In some embodiments, the evaluation engine <b>403</b> may generate the explanation output <b>414</b> in accordance with the various steps/operations of the process depicted in <figref idref="DRAWINGS">FIG. <b>9</b></figref>. As depicted in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, at step/operation <b>901</b>, the evaluation engine <b>403</b> determines a per-criterion evaluation for each evaluation criterion of one or more evaluation criteria described by the shared decision tree data object based on the refined evidentiary data <b>412</b>. The per-criterion evaluation for an evaluation criterion may be a data object that describes whether the refined evidentiary data <b>412</b> provides sufficient evidence indicating that the evaluation criterion has been satisfied.</p><p id="p-0096" num="0095">For example, if an evaluation criterion requires history of heart failure, the per-criterion evaluation for the evaluation criterion may indicate whether refined evidentiary data <b>412</b> describing medical history of a corresponding patient input entity describes a history of heart failure in relation to the corresponding patient input entity. As another example, if an evaluation criterion requires chronic kidney disease, the per-criterion evaluation for the evaluation criterion may indicate whether refined evidentiary data <b>412</b> describing medical condition of a corresponding patient input entity describes chronic kidney disease in relation to corresponding patient input entity. As yet another example, if an evaluation criterion requires at least 45 years of age, the per-criterion evaluation for the evaluation criterion may indicate whether refined evidentiary data <b>412</b> describing demographic information of a corresponding patient input entity describes that the corresponding patient input entity is at least 45 years of age.</p><p id="p-0097" num="0096">At step/operation <b>902</b>, the evaluation engine <b>403</b> identifies a criterion-related subset of the refined evidentiary data <b>412</b> for each evaluation criterion of one or more evaluation criteria described by the shared decision tree data object. A criterion-related subset associated with an evaluation criterion may be a data object that describe at least one portion of refined evidentiary data <b>412</b> that is determined to include information deemed pertinent to determining whether the refined evidentiary data <b>412</b> satisfy the evaluation criterion. For example, if an evaluation criterion relates to medical history, the per-criterion subset for the evaluation criterion may be extracted from the medical history data of a corresponding patient input entity. As another example, if an evaluation criterion relates to prescription history, the per-criterion subset for the evaluation criterion may be extracted from the prescription history data of a corresponding patient input entity. As yet another example, if an evaluation criterion relates to patient age, the per-criterion subset for the evaluation criterion may be extracted from the patient profile data and/or patient demographic data of a corresponding patient input entity.</p><p id="p-0098" num="0097">At step/operation <b>903</b>, the evaluation engine <b>403</b> generates the explanation output <b>414</b> based on each per-criterion evaluation for an evaluation criterion and each criterion-related subset for an evaluation criterion. In some embodiments, the evaluation engine <b>403</b> combine at least a portion of on each per-criterion evaluation for an evaluation criterion and at least a portion of each criterion-related subset for an evaluation criterion in order to generate the explanation output <b>414</b>. For example, the evaluation engine <b>403</b> may combine all of on each per-criterion evaluation for an evaluation criterion and all of each criterion-related subset for an evaluation criterion in order to generate the explanation output <b>414</b>.</p><p id="p-0099" num="0098">Returning to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, subsequent to generating the evaluation output <b>413</b> and the explanation output <b>414</b>, the evaluation engine <b>403</b> provides the evaluation output <b>413</b> and the explanation output <b>414</b> to the display engine <b>404</b>. The display engine <b>404</b> is configured to display (e.g., using a decoupled user interface module) an evaluation output user interface <b>415</b> comprising display data describing the evaluation output and the classification explanation output. In some embodiments, the display engine <b>404</b> provides user interface data associated with the evaluation output user interface <b>415</b> to a client computing entity <b>102</b>, where the user interface data may be a collection of data objects that contains display data (e.g., Hyper-Text Markup Language (HTML) data) that can be executed to display the evaluation output user interface <b>415</b>.</p><p id="p-0100" num="0099">An operational example of the evaluation output user interface <b>415</b> is presented in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. As depicted in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the evaluation output user interface <b>415</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref> displays the evaluation output <b>1001</b> at the top-right edge of the evaluation output user interface <b>415</b> and the data evaluation subject matter <b>1002</b> at the top-center of the evaluation output user interface <b>415</b>.</p><p id="p-0101" num="0100">As further depicted in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the evaluation output user interface <b>415</b> of <figref idref="DRAWINGS">FIG. <b>10</b></figref> displays per-criterion evaluations for relevant evaluation criteria in the main region <b>1003</b> of the evaluation output user interface <b>415</b>. Selecting an interactive portion of a per-criterion-evaluation such as the per-criterion evaluation <b>1004</b> may lead to display of information associated with the per-criterion-evaluation, such as the relevant diagnosis code information <b>1005</b> for an evaluation criterion associated with the per-criterion evaluation <b>1004</b> and criterion-related evidentiary data objects <b>1006</b> for the evaluation criterion associated with the per-criterion evaluation <b>1004</b>. Moreover, selecting an interactive portion of a criterion-related evidentiary data object such as the criterion-related evidentiary data <b>1007</b> may lead to display of information associated with the criterion-related evidentiary data, such as a text version and/or an image version of the criterion-related evidentiary data <b>1007</b>.</p><p id="p-0102" num="0101">In some embodiments, the data evaluation computing entity <b>106</b> may perform one or more evaluation-based actions based on at least one of the evaluation output <b>413</b> and the explanation output <b>414</b>. For example, the data evaluation computing entity <b>106</b> may grant and/or deny pre-authorization for a proposed medical operation based on the evaluation output <b>413</b>. Other examples of evaluation-based actions that may be performed by the data evaluation computing entity <b>106</b> include automatic generating of pre-authorization approval notifications, automatic generating of pre-authorization denial notifications, automatic scheduling of pre-authorization-related consultation meetings, automatic scheduling of pre-authorization secondary review tasks, and/or the like.</p><p id="p-0103" num="0102">Accordingly, as described above, the parallelized data evaluation concepts of the present invention can be utilized to perform efficient and reliable data evaluation in a variety of contexts, such as the in the context of performing prior authorization of proposed medical operations in relation to patient needs. For example, in some embodiments, the data evaluation computing entity <b>106</b> may extract (e.g., using a parallelized data extraction procedure) evidentiary data describing patient history and/or patient demographics of a patient that is subject of a prior authorization task, refine the extracted evidentiary data in accordance with a decision tree data object that describes the pre-authorization requirements for generating a positive prior authorization determination for the noted prior authorization task in order to isolate portions of the extracted evidentiary that relate to the noted pre-authorization requirements, process the refined evidentiary data in accordance with the decision tree data object in order to determine a prior authorization determination for the proposed medical operation, aggregate the refined evidentiary data used to reach the prior authorization determination to generate an explanation output for the prior authorization determination, and present display data related to the prior authorization determination and the explanation output using a prior authorization user interface configured to display prior-authorization-related data to end-users (e.g., to physicians, nurses, hospital staff, and/or the like).</p><p id="p-0104" num="0103">The process <b>400</b> further includes managing the operations of the feature extraction engine <b>401</b>, the evidence refinement engine <b>402</b>, the evaluation engine <b>403</b>, and the display engine <b>404</b> using a conductor <b>420</b> of the data evaluation computing entity <b>106</b>. In some embodiments, the conductor <b>420</b> is configured to coordinate sequential operation of various operations of the process <b>400</b>, including at least one of the following: (i) retrieval of structured data associated with an input entity (e.g., a patient entity) from structured data sources using parallel execution of structured feature extraction threads; (ii) retrieval of unstructured data from unstructured data sources associated with an input entity using parallel execution of unstructured feature extraction threads; (iii) pre-processing of retrieved unstructured data to generate engineered feature data using parallel execution of unstructured feature extraction threads; (iv) generation of evidentiary data by the feature extraction engine <b>401</b> (e.g., using one or more parallel execution threads) based on retrieved structured data and engineered data generated by performing pre-processing on retrieved unstructured data; (v) transfer of evidentiary data generated by the feature extraction engine <b>401</b> to the evidence refinement engine <b>402</b>; (vi) refinement of evidentiary data by the evidence refinement engine <b>402</b> (e.g., using one or more parallel execution threads) to generate refined evidentiary data; (vii) transfer of refined evidentiary data generated by the evidence refinement engine <b>402</b> to the evaluation engine <b>403</b>; (viii) generation of evaluation outputs and/or explanation outputs by the evaluation engine <b>403</b> (e.g., using one or more parallel execution threads) based on the refined evidentiary data; (ix) transfer of evaluation outputs and/or explanation outputs generated by the evaluation engine <b>403</b> to the display engine <b>404</b>; and (x) generation of the evaluation output user interfaces by the display engine <b>404</b>.</p><heading id="h-0012" level="1">V. CONCLUSION</heading><p id="p-0105" num="0104">Many modifications and other embodiments will come to mind to one skilled in the art to which this disclosure pertains having the benefit of the teachings presented in the foregoing descriptions and the associated drawings. Therefore, it is to be understood that the disclosure is not to be limited to the specific embodiments disclosed and that modifications and other embodiments are intended to be included within the scope of the appended claims. Although specific terms are employed herein, they are used in a generic and descriptive sense only and not for purposes of limitation.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method for data evaluation in accordance with a shared decision tree data object, the computer-implemented method comprising:<claim-text>generating, using a plurality of feature extraction threads, shared evidentiary data, wherein generating the shared evidentiary data comprises:<claim-text>identifying one or more structured feature extraction threads of the plurality of feature extraction threads and one or more unstructured feature extraction threads of the plurality of feature extraction threads;</claim-text><claim-text>causing each structured feature extraction thread of the one or more structured feature extraction threads to extract corresponding per-source retrieved feature data from a corresponding structured data source that is associated with the structured feature extraction thread;</claim-text><claim-text>causing each unstructured feature extraction thread of the one or more unstructured feature extraction threads to (i) extract corresponding per-source unstructured feature data from a corresponding unstructured data source that is associated with the unstructured feature extraction thread, and (ii) generate per-source engineered feature data for the unstructured feature extraction thread based at least in part on the corresponding per-source unstructured feature data for the unstructured feature extraction thread; and</claim-text><claim-text>generating shared evidentiary data by aggregating each per-source retrieved feature data extracted by a structured feature extraction thread and each per-source engineered feature data generated by an unstructured feature extraction thread;</claim-text></claim-text><claim-text>generating, based at least in part on a selected shared evidentiary data subset of the shared evidentiary data that correspond to one or more selected nodes of the shared decision tree data object, refined evidentiary data;</claim-text><claim-text>generating an evaluation output and an explanation output based at least in part on the refined evidentiary data and the shared decision tree data object; and</claim-text><claim-text>providing, for display via a user interface, at least a portion of the evaluation output comprising user interface data indicative of the evaluation output and the explanation output.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the per-source engineered feature data for an unstructured feature extraction thread of the one or more structured feature extraction threads comprises:<claim-text>determining, by the unstructured feature extraction thread, a feature-relevant subset of the corresponding per-source unstructured feature data for the unstructured feature extraction thread and a potentially feature-relevant subset of the corresponding per-source unstructured feature data for the unstructured feature extraction thread; and</claim-text><claim-text>generating, by the unstructured feature extraction thread, the per-source engineered feature data for the unstructured feature extraction thread based at least in part on at least one of the feature-relevant subset of the corresponding per-source unstructured feature data and the potentially feature-relevant subset of the corresponding per-source unstructured feature data.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer-implemented method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein generating the per-source engineered feature data for the unstructured feature extraction thread based at least in part on at least one of the feature-relevant subset and the potentially feature-relevant subset comprises:<claim-text>determining, by the unstructured feature extraction thread, confirmation data for the potentially feature-relevant subset;</claim-text><claim-text>identifying, by the unstructured feature extraction thread, a confirmed subset of the potentially-relevant subset based at least in part on the confirmation data; and</claim-text><claim-text>generating, by the unstructured feature extraction thread, the per-source engineered feature data based at least in part on the feature-relevant subset and the confirmed subset of the potentially feature-relevant subset.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more selected nodes of the shared decision tree data object comprise one or more leaf nodes of the shared decision tree data object.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the refined evidentiary data comprises:<claim-text>identifying, based at least in part on the shared decision tree data object, one or more evaluation criterion data objects, wherein each evaluation criterion data object of the one or more evaluation criterion data objects corresponds to a selected node of the selected nodes of the shared decision tree data object;</claim-text><claim-text>determining a classification-relevant subset of the shared evidentiary data that correspond to the one or more evaluation criterion data objects; and</claim-text><claim-text>generating the refined evidentiary data based at least in part on the classification-relevant subset.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the evaluation output comprises:<claim-text>for each evaluation criterion data object of one or more evaluation criterion data objects described by the shared decision tree data object, determining a per-criterion evaluation based at least in part on the refined evidentiary data;</claim-text><claim-text>identifying a positive evaluation subset of the one or more evaluation criterion data objects based at least in part on each per-criterion evaluation for an evaluation criterion data object of the one or more evaluation criterion data objects; and</claim-text><claim-text>generating the evaluation output based at least in part on whether the positive evaluation subset satisfies a sufficiency criterion for the shared decision tree data object.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the explanation output comprises:<claim-text>for each evaluation criterion data object of the one or more evaluation criterion data objects, determining a per-criterion evaluation based a corresponding criterion-related subset of the refined evidentiary data; and</claim-text><claim-text>generating the explanation output based at least in part on each per-criterion evaluation for an evaluation criterion data object of the one or more evaluation criterion data objects and each criterion-related subset for an evaluation criterion data object of the one or more evaluation criterion data objects.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the input entity is a patient input entity;</claim-text><claim-text>the shared evidentiary data comprises medical history data of the patient input entity;</claim-text><claim-text>the shared decision tree data object describes authorization criteria for a proposed medical operation; and</claim-text><claim-text>the evaluation output describes an authorization determination for the proposed medical operation with respect to the patient input entity.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. An apparatus for data evaluation in accordance with a shared decision tree data object, the apparatus comprising at least one processor and at least one memory including program code, the at least one memory and the program code configured to, with the processor, cause the apparatus to at least:<claim-text>generate, using a plurality of feature extraction threads, shared evidentiary data, wherein generating the shared evidentiary data comprises:<claim-text>identifying one or more structured feature extraction threads of the plurality of feature extraction threads and one or more unstructured feature extraction threads of the plurality of feature extraction threads;</claim-text><claim-text>causing each structured feature extraction thread of the one or more structured feature extraction threads to extract corresponding per-source retrieved feature data from a corresponding structured data source that is associated with the structured feature extraction thread;</claim-text><claim-text>causing each unstructured feature extraction thread of the one or more unstructured feature extraction threads to (i) extract corresponding per-source unstructured feature data from a corresponding unstructured data source that is associated with the unstructured feature extraction thread, and (ii) generate per-source engineered feature data for the unstructured feature extraction thread based at least in part on the corresponding per-source unstructured feature data for the unstructured feature extraction thread; and</claim-text><claim-text>generating shared evidentiary data by aggregating each per-source retrieved feature data extracted by a structured feature extraction thread and each per-source engineered feature data generated by an unstructured feature extraction thread;</claim-text></claim-text><claim-text>generate, based at least in part on a selected shared evidentiary data subset of the shared evidentiary data that correspond to one or more selected nodes of the shared decision tree data object, refined evidentiary data;</claim-text><claim-text>generate an evaluation output and an explanation output based at least in part on the refined evidentiary data and the shared decision tree data object; and</claim-text><claim-text>provide, for display via a user interface, at least a portion of the evaluation output comprising user interface data indicative of the evaluation output and the explanation output.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein generating the per-source engineered feature data for an unstructured feature extraction thread of the one or more structured feature extraction threads comprises:<claim-text>determining, by the unstructured feature extraction thread, a feature-relevant subset of the corresponding per-source unstructured feature data for the unstructured feature extraction thread and a potentially feature-relevant subset of the corresponding per-source unstructured feature data for the unstructured feature extraction thread; and</claim-text><claim-text>generating, by the unstructured feature extraction thread, the per-source engineered feature data for the unstructured feature extraction thread based at least in part on at least one of the feature-relevant subset of the corresponding per-source unstructured feature data and the potentially feature-relevant subset of the corresponding per-source unstructured feature data.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The apparatus of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein generating the per-source engineered feature data for the unstructured feature extraction thread based at least in part on at least one of the feature-relevant subset and the potentially feature-relevant subset comprises:<claim-text>determining, by the unstructured feature extraction thread, confirmation data for the potentially feature-relevant subset;</claim-text><claim-text>identifying, by the unstructured feature extraction thread, a confirmed subset of the potentially-relevant subset based at least in part on the confirmation data; and</claim-text><claim-text>generating, by the unstructured feature extraction thread, the per-source engineered feature data based at least in part on the feature-relevant subset and the confirmed subset of the potentially feature-relevant subset.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the one or more selected nodes of the shared decision tree data object comprise one or more leaf nodes of the shared decision tree data object.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein generating the refined evidentiary data comprises:<claim-text>identifying, based at least in part on the shared decision tree data object, one or more evaluation criterion data objects, wherein each evaluation criterion data object of the one or more evaluation criterion data objects corresponds to a selected node of the selected nodes of the shared decision tree data object;</claim-text><claim-text>determining a classification-relevant subset of the shared evidentiary data that correspond to the one or more evaluation criterion data objects; and</claim-text><claim-text>generating the refined evidentiary data based at least in part on the classification-relevant subset.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein generating the evaluation output comprises:<claim-text>for each evaluation criterion data object of one or more evaluation criterion data objects described by the shared decision tree data object, determining a per-criterion evaluation based at least in part on the refined evidentiary data;</claim-text><claim-text>identifying a positive evaluation subset of the one or more evaluation criterion data objects based at least in part on each per-criterion evaluation for an evaluation criterion data object of the one or more evaluation criterion data objects; and</claim-text><claim-text>generating the evaluation output based at least in part on whether the positive evaluation subset satisfies a sufficiency criterion for the shared decision tree data object.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein generating the explanation output comprises:<claim-text>for each evaluation criterion data object of the one or more evaluation criterion data objects, determining a per-criterion evaluation based a corresponding criterion-related subset of the refined evidentiary data; and</claim-text><claim-text>generating the explanation output based at least in part on each per-criterion evaluation for an evaluation criterion data object of the one or more evaluation criterion data objects and each criterion-related subset for an evaluation criterion data object of the one or more evaluation criterion data objects.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The apparatus of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein:<claim-text>the input entity is a patient input entity;</claim-text><claim-text>the shared evidentiary data comprises medical history data of the patient input entity;</claim-text><claim-text>the shared decision tree data object describes authorization criteria for a proposed medical operation; and</claim-text><claim-text>the evaluation output describes an authorization determination for the proposed medical operation with respect to the patient input entity.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A computer program product for data evaluation in accordance with a shared decision tree data object, the computer program product comprising at least one non-transitory computer-readable storage medium having computer-readable program code portions stored therein, the computer-readable program code portions configured to:<claim-text>generate, using a plurality of feature extraction threads, shared evidentiary data, wherein generating the shared evidentiary data comprises:<claim-text>identify one or more structured feature extraction threads of the plurality of feature extraction threads and one or more unstructured feature extraction threads of the plurality of feature extraction threads;</claim-text><claim-text>cause each structured feature extraction thread of the one or more structured feature extraction threads to extract corresponding per-source retrieved feature data from a corresponding structured data source of one or more structured data sources that is associated with the structured feature extraction thread;</claim-text><claim-text>cause each unstructured feature extraction thread of the one or more unstructured feature extraction threads to (i) extract corresponding per-source unstructured feature data from a corresponding unstructured data source of one or more unstructured data sources that is associated with the unstructured feature extraction thread, and (ii) process the corresponding per-source unstructured feature data for the unstructured feature extraction thread to generate per-source engineered feature data for the unstructured feature extraction thread; and</claim-text><claim-text>aggregate each per-source retrieved feature data extracted by a structured feature extraction thread of the one or more structured feature extraction threads and each per-source engineered feature data generated by an unstructured feature extraction thread of the one or more unstructured feature extraction threads to generate the shared evidentiary data;</claim-text></claim-text><claim-text>generate, based at least in part on a selected shared evidentiary data subset of the shared evidentiary data that correspond to one or more selected nodes of the shared decision tree data object, refined evidentiary data;</claim-text><claim-text>process the refined evidentiary data in accordance with the shared decision tree data object to generate an evaluation output and an explanation output; and</claim-text><claim-text>display an evaluation output user interface comprising user interface data describing the evaluation output and the explanation output.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The computer program product of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein generating the per-source engineered feature data for an unstructured feature extraction thread of the one or more structured feature extraction threads comprises:<claim-text>determining, by the unstructured feature extraction thread, a feature-relevant subset of the corresponding per-source unstructured feature data for the unstructured feature extraction thread and a potentially feature-relevant subset of the corresponding per-source unstructured feature data for the unstructured feature extraction thread; and</claim-text><claim-text>generating, by the unstructured feature extraction thread, the per-source engineered feature data for the unstructured feature extraction thread based at least in part on at least one of the feature-relevant subset of the corresponding per-source unstructured feature data and the potentially feature-relevant subset of the corresponding per-source unstructured feature data.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computer program product of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein generating the per-source engineered feature data for the unstructured feature extraction thread based at least in part on at least one of the feature-relevant subset and the potentially feature-relevant subset comprises:<claim-text>determining, by the unstructured feature extraction thread, confirmation data for the potentially feature-relevant subset;</claim-text></claim-text><claim-text>identifying, by the unstructured feature extraction thread, a confirmed subset of the potentially-relevant subset based at least in part on the confirmation data; and<claim-text>generating, by the unstructured feature extraction thread, the per-source engineered feature data based at least in part on the feature-relevant subset and the confirmed subset of the potentially feature-relevant subset.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computer program product of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein:<claim-text>the input entity is a patient input entity;</claim-text><claim-text>the shared evidentiary data comprises medical history data of the patient input entity;</claim-text><claim-text>the shared decision tree data object describes authorization criteria for a proposed medical operation; and</claim-text><claim-text>the evaluation output describes an authorization determination for the proposed medical operation with respect to the patient input entity.</claim-text></claim-text></claim></claims></us-patent-application>
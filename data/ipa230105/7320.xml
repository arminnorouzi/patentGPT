<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007321A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007321</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17780950</doc-number><date>20201127</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>19212079.8</doc-number><date>20191128</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2343</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>439</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2662</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>84</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>8352</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>23439</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>439</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2662</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>84</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>8352</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHODS AND DEVICES FOR PROVIDING PERSONALIZED AUDIO TO A USER</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63040129</doc-number><date>20200617</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62961465</doc-number><date>20200115</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Dolby International AB</orgname><address><city>Amsterdam</city><country>NL</country></address></addressbook><residence><country>NL</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Schildbach</last-name><first-name>Wolfgang</first-name><address><city>Nuremberg</city><country>DE</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Schmidt</last-name><first-name>Malte</first-name><address><city>Feucht</city><country>DE</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Dolby International AB</orgname><role>03</role><address><city>Amsterdam</city><country>NL</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2020/083640</doc-number><date>20201127</date></document-id><us-371c12-date><date>20220527</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present application describes a method (<b>400</b>) for providing personalized audio to a user. The method (<b>400</b>) comprises receiving (<b>401</b>) a manifest file (<b>140</b>) for a media element from which audio is to be rendered, wherein the manifest file (<b>140</b>) comprises a description (<b>141</b>) for a plurality of different presentations (<b>152</b>) of audio content of the media element. In addition, the method (<b>400</b>) comprises selecting (<b>402</b>) a presentation (<b>152</b>) from the plurality of presentations (<b>152</b>) based on the manifest file (<b>140</b>). The method (<b>400</b>) further comprises receiving (<b>403</b>) a list of audio track objects comprised within the media element, and selecting (<b>404</b>) an audio track object from the list of audio track objects, in dependence of the selected presentation (<b>152</b>).</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="36.66mm" wi="158.75mm" file="US20230007321A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="199.64mm" wi="131.06mm" file="US20230007321A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="97.37mm" wi="124.04mm" file="US20230007321A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="136.14mm" wi="146.05mm" file="US20230007321A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="161.12mm" wi="146.47mm" file="US20230007321A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="178.99mm" wi="139.78mm" file="US20230007321A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority of the following priority applications: EP application 19212079.8 (reference: D19140EP), filed 28 Nov. 2019, U.S. provisional application 62/961,465 (reference: D19140USP1), filed 15 Jan. 2020 and U.S. provisional application 63/040,129 (reference: D19140USP2), filed 17 Jun. 2020, which are hereby incorporated by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present document relates to methods and devices for providing personalized audio signals to a user, notably a listener.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Modern television (TV) sets enable a user to load software applications onto a platform of the TV set. The platform may be viewed as a browser and the application may be a plugin extension of the browser. The software application may e.g. be provided by a content provider, and it may allow the user to select audio and/or video content from a server of the content provider.</p><p id="p-0005" num="0004">A possible context for providing personalized audio and/or video content to a user is the HbbTV (Hybrid broadcast broadband TV) environment, with the specification ETSI TS 102 796. HbbTV makes use of the HTML5 (hypertext markup language) protocol, which comprises the so-called Media Source Extensions (MSE) application programming interface (API) for enabling content providers to provide software applications for new services (e.g. in the context of Video on Demand, VOD). The MSE API specifies a communication interface which allows an application, e.g. an application on a TV set, to communicate with the browser (also referred to herein as the terminal) of the TV set.</p><p id="p-0006" num="0005">The present document addresses the technical problem of enabling personalization of audio content, notably via the MSE API of HTML5, in an efficient and reliable manner. The technical problem is solved by the independent claims. Preferred examples are described in the dependent claims.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0007" num="0006">According to an aspect, a device and/or apparatus, notably an application unit or a device running an application, for providing personalized audio to a user is described. The device is configured to receive a manifest file for a media element from which audio is to be rendered, wherein the manifest file comprises a description for a plurality of different presentations of audio content of the media element. The descriptions of the different presentations may describe the presentations in such a way that they allow the user to select an appropriate presentation for rendering. Furthermore, the device is configured to select a presentation from the plurality of presentations based on the manifest file (notably based on the descriptions comprised within the manifest file). In addition, the method is configured to receive a list of audio track objects comprised within the media element, and to select an audio track object from the list of audio track objects, in dependence of the selected presentation (and based on knowledge and/or information regarding the ordering of the audio track objects within the list of audio track objects).</p><p id="p-0008" num="0007">According to a further aspect, a device and/or apparatus, notably a terminal, for providing personalized audio to a user is described. The device is configured to receive an initialization segment for a media element from which audio is to be rendered. Furthermore, the device is configured to determine a list of audio track objects for a plurality of different presentations of the media element, based on the initialization segment, and to provide the list of audio track objects for selection of one of the audio track objects for one of the plurality of different presentations. The list of audio track objects may be ordered according to an ordering scheme which is known to the entity (notably to the application) which performs the selection of an audio track object.</p><p id="p-0009" num="0008">According to an aspect, a method for providing personalized audio to a user is described. The method comprises receiving a manifest file for a media element from which audio is to be rendered, wherein the manifest file comprises a description for a plurality of different presentations of audio content of the media element. In addition, the method comprises selecting a presentation from the plurality of presentations based on the manifest file. The method further comprises receiving a list of audio track objects comprised within the media element, and selecting an audio track object from the list of audio track objects, in dependence of the selected presentation.</p><p id="p-0010" num="0009">According to a further aspect, a method for providing personalized audio to a user is described. The method comprises receiving an initialization segment for a media element from which audio is to be rendered. In addition, the method comprises determining a list of audio track objects for a plurality of different presentations of the media element, based on the initialization segment, and providing the list of audio track objects for selection of one of the audio track objects for one of the plurality of different presentations.</p><p id="p-0011" num="0010">It should be noted that the methods described herein can each be implemented in software and/or computer readable code on one or more processors, in whole or in part of the respective methods.</p><p id="p-0012" num="0011">According to a further aspect, a software program is described. The software program may be adapted for execution on a processor and for performing the method steps outlined in the present document when carried out on the processor.</p><p id="p-0013" num="0012">According to another aspect, a storage medium is described. The storage medium may comprise a software program adapted for execution on a processor and for performing the method steps outlined in the present document when carried out on the processor.</p><p id="p-0014" num="0013">According to a further aspect, a computer program product is described. The computer program may comprise executable instructions for performing the method steps outlined in the present document when executed on a computer.</p><p id="p-0015" num="0014">It should be noted that the methods and systems including its preferred embodiments as outlined in the present patent application may be used stand-alone or in combination with the other methods and systems disclosed in this document. Furthermore, all aspects of the methods and systems outlined in the present patent application may be arbitrarily combined. In particular, the features of the claims may be combined with one another in an arbitrary manner.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">SHORT DESCRIPTION OF THE FIGURES</heading><p id="p-0016" num="0015">The invention is explained below in an exemplary manner with reference to the accompanying drawings, wherein</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>1</b><i>a </i></figref>shows an example content distribution network;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>1</b><i>b </i></figref>shows example content of a (Dynamic Adaptive Streaming over HTTP, DASH) manifest, i.e. a Media Presentation Description, file;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b><i>c </i></figref>shows example presentations of audio components within an audio bitstream;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>1</b><i>d </i></figref>shows an example initialization segment of an audio bitstream or media element;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b><i>e </i></figref>shows an example adaptation set and an example preselection for enabling a personalized presentation of audio content;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an example protocol for selecting a personalized presentation using the HTML5 API;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example protocol for selecting a personalized presentation using the MSE API;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>4</b><i>a </i></figref>shows a flow chart of an example method for providing a personalized presentation (executed e.g. by a software application); and</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>4</b><i>b </i></figref>shows a flow chart of an example method for providing a personalized presentation (executed e.g. by a terminal or browser of a TV set).</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0026" num="0025">As indicated above, the present document relates to providing personalized audio content to a listener, notably using HTML5 and the Media Source Extension (MSE) API. In this context <figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an example content distribution (notably broadcasting) network <b>100</b> with a network server <b>101</b> which is configured to provide audio and/or video content, e.g. an audio bitstream <b>121</b>, to a content receiver <b>110</b>. The network server <b>101</b> may be operated by a content provider.</p><p id="p-0027" num="0026">The content receiver <b>110</b> comprises a terminal <b>111</b> which is configured to provide video and/or audio content to a decoder <b>113</b> and subsequently to a rendering unit <b>114</b> (e.g. a loudspeaker). Furthermore, the content receiver <b>110</b> comprises an application <b>112</b>, which is typically provided by the content provider. The application <b>112</b> may be executed on a hardware platform (which may be integrated within a TV set). The terminal <b>111</b> and the application <b>112</b> may communicate with one another via an Application Programming Interface <b>112</b>, e.g. the HTLM5 API or the MSE API.</p><p id="p-0028" num="0027">The content receiver <b>110</b> may be implemented using a single computing entity (such as a TV set) or the content receiver <b>110</b> may be implemented within multiple computing entities (e.g. an entity for the terminal or browser <b>111</b> and a separate entity for the application <b>112</b>).</p><p id="p-0029" num="0028">The audio content may be provided from the server <b>101</b> to the receiver <b>110</b> using the Dynamic Adaptive Streaming over HTTP (DASH), notably the MPEG-DASH, protocol. The DASH protocol is an adaptive bitrate streaming scheme which enables streaming of media (notably video and/or audio) content over the internet from an HTTP web server <b>101</b>. The DASH protocol is specified in ISO/IEC 23009-1:2019 Information technology&#x2014;Dynamic adaptive streaming over HTTP (DASH)&#x2014;Part 1: Media presentation description and segment formats&#x201d; (see https://www.iso.org/standard/79329.html), which is incorporated herein by reference.</p><p id="p-0030" num="0029">The DASH protocol enables the transmission of an audio bitstream <b>121</b> (for a media element) from the server <b>101</b> to the receiver <b>110</b>, wherein the audio bitstream <b>121</b> may comprise a plurality of different audio components (e.g. for different languages, for narrative content, for background music content, for audio effects content, etc.). Furthermore, the DASH protocol enables the definition of different presentations which specify different combinations of one or more of the different audio components or audio objects. A presentation may specify<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0030">the one or more audio components or objects from the plurality of different audio components that are to rendered jointly; and/or</li>        <li id="ul0002-0002" num="0031">how the one or more audio components or objects are to be mixed together for rendering.</li>    </ul>    </li></ul></p><p id="p-0031" num="0032">Possible means for defining a presentation are the so-called adaptation sets and/or the so-called preselections (as shown in <figref idref="DRAWINGS">FIG. <b>1</b><i>e</i></figref>). The DASH protocol allows different audio components (e.g. for different languages) to be assigned to different adaption sets <b>180</b>. An adaptation set <b>180</b> may comprise one or more audio components or audio objects <b>181</b>. Different adaption sets <b>180</b> may e.g. be used to define different sets of audio components <b>181</b> for different groups of listeners (e.g. for different languages). In order to reduce the required bandwidth for an audio bitstream <b>121</b>, the bitstream <b>121</b> may only comprise a subset of the overall number of adaptation sets <b>180</b> which are available for a particular video and/or audio content (or media element).</p><p id="p-0032" num="0033">A further means for defining a presentation are preselections or preselection elements <b>190</b>. A preselection specifies one or more audio components or objects <b>181</b> (from an adaptation set <b>180</b>) and a metadata set <b>191</b> which specifies how the one or more audio components <b>181</b> are to be mixed together. In particular, a preselection may specify how the one or more audio components <b>181</b>, <b>182</b> of an adaptation set are to be mixed together. By providing different preselections with different metadata sets <b>191</b>, different presentations (e.g. with different emphasis on the narrative content or on the music and/or effects content) may be specified in a bit-rate efficient manner.</p><p id="p-0033" num="0034">The DASH protocol specifies a so-called manifest file, which is an XML file that indicates and describes the different components which are comprised within an audio bitstream <b>121</b> or a media element. <figref idref="DRAWINGS">FIG. <b>1</b><i>b </i></figref>shows an example manifest file <b>140</b> which indicates descriptions <b>141</b> for a number of different presentations, wherein the descriptions <b>141</b> for the different presentations may be listed within the manifest file <b>140</b> according to a particular manifest file order <b>142</b>. The manifest file <b>140</b> may provide a description <b>141</b> for each of the different presentations which are available within the audio bitstream <b>121</b> or media element. The description <b>141</b> may be understandable by a user, and may therefore enable the user to select a particular presentation from the media element for rendering. By way of example, the manifest file <b>140</b>, notably the descriptions <b>141</b>, may indicate which languages are available and/or which types of mixes of different audio components <b>181</b>, <b>182</b> are available.</p><p id="p-0034" num="0035"><figref idref="DRAWINGS">FIG. <b>1</b><i>c </i></figref>illustrates an example set <b>150</b> of audio components or objects <b>181</b> that is provided within an audio bitstream <b>121</b> or that is provided for a media element (e.g. within an adaptation set <b>180</b> of the audio bitstream <b>121</b>). A presentation <b>152</b> may be specified in an efficient manner by providing indicators <b>153</b> that enable (dashed box) or disable (clear box) the different audio components or objects <b>181</b> individually.</p><p id="p-0035" num="0036"><figref idref="DRAWINGS">FIG. <b>1</b><i>d </i></figref>shows an example structure of an audio bitstream <b>121</b>. The audio bitstream <b>121</b> may comprise an initialization segment <b>160</b> which specifies the different presentations <b>152</b> which are available within the audio bitstream <b>121</b>. In particular, the initialization segment <b>160</b> may comprise a plurality of presentation sections <b>161</b> indicating the different presentations <b>152</b> which are available. The presentation sections <b>161</b> may be provided within the initialization segment <b>160</b> according to a particular segment order <b>162</b>.</p><p id="p-0036" num="0037">The initialization segment <b>160</b>, notably the different presentation sections <b>161</b>, may indicate so-called audio track objects, wherein each audio track object corresponds to a particular presentation <b>152</b>. Based on the initialization segment <b>160</b> and/or based on the one or more adaptation sets and/or preselection elements in the manifest file <b>140</b>, a list of audio track objects for a corresponding list of presentations <b>152</b> may be generated (by parsing the initialization segment <b>160</b>). The list of audio track objects may be ordered according to the segment order <b>162</b> (which may differ from the manifest file order <b>142</b>).</p><p id="p-0037" num="0038">Furthermore, the audio bitstream <b>121</b> typically comprises media, notably audio, segments <b>170</b> comprising one or more audio components or objects <b>181</b>. The media segments <b>170</b> (which may also be referred to as audio bitstream segment) which are relevant for a particular presentation <b>152</b> may be indicated by the presentation section <b>161</b> for the presentation <b>152</b>. A media segment <b>170</b> may correspond to a certain temporal excerpt of the audio content (e.g. to 20 ms of audio content).</p><p id="p-0038" num="0039">As outlined above, the present document is directed at providing mechanisms for personalized interfaces for providing audio tracks, notably in the context of a Hybrid Broadcast Television (HbbTV) environment. In particular, the present document is directed at enabling the Media Source Extensions (MSE) API for the use of personalization. In this context, a scheme is described which allows matching the list of possible selections or presentations known to the application <b>112</b> (which sits on one side of the MSE API) to the list of selections or presentations known to the terminal <b>111</b> (which sits on the other side of the MSE API).</p><p id="p-0039" num="0040">The term &#x201c;audio track&#x201d; (or audio component or object <b>181</b>) may refer to an interface representing a single audio track from one of the HTML media elements, &#x3c;audio&#x3e; or &#x3c;video&#x3e;. A possible use for accessing an AudioTrack <b>181</b> is to toggle its &#x201c;enabled&#x201d; property <b>153</b> in order to mute and unmute the track or object <b>181</b>. Details are described in https://html.spec.whatwg.org/multipage/media.html#audiotrack or https://developer.mozilla.org/en-US/docs/Web/API/AudioTrack), which are incorporated herein. An &#x201c;AudioTrack object&#x201d; may be defined as a class defined by W3C to identify an entity that can be selected and/or played on its own.</p><p id="p-0040" num="0041">A &#x201c;file audio track&#x201d; may be a track as defined in ISO/IEC 14496-12, section 3.1.19 (which is incorporated herein). The &#x201c;file audio track&#x201d; holds a sequence of access units comprising an elementary stream, as defined in section 8.3 of that document. An &#x201c;initialization segment&#x201d; <b>160</b> may be defined as a sequence of bytes that contain all of the initialization information required to decode a sequence of media segments <b>170</b>, as specified e.g. in https://www.w3.org/TR/2016/REC-media-source-20161117/#init-segment, which is incorporated herein.</p><p id="p-0041" num="0042">The AudioTrack element or AudioTrack object may be used for personalization. Different personalized experiences may be variants derived from a common set <b>150</b> of components or objects <b>181</b>, with some components or objects <b>181</b> being switched on or off. For example, where an English version of a documentary may be the music and effects track mixed with an English dialog, a German version may be derived by mixing the same music and effects track with a German dialog.</p><p id="p-0042" num="0043">Traditionally, the mixing of different personalized experiences would likely have happened at a mixer's desk, located in a production studio. Due to advances in compression technology, next generation audio codecs are able to provide all the different components <b>181</b> directly to the receiver <b>110</b> in one bitstream <b>121</b>, which enables the user to choose and personalize the experiences to a greater extent and in a flexible manner.</p><p id="p-0043" num="0044">Standards for receivers <b>110</b> have defined functionality for distributing and signaling such multi-component streams <b>121</b> to receivers <b>110</b>. A receiver <b>110</b> may be implemented in a software environment resembling that of a standardized web browser. The present document is directed at the functionality of selecting one experience (also referred to herein as a presentation) <b>152</b> out of several different possible presentations <b>152</b>.</p><p id="p-0044" num="0045">As an example, for playback using an HTML5 media element in an HbbTV browser, the W3C specification for HTML5 in tandem with the HbbTV specification TS 102 796 V1.4.1 or higher (which are incorporated herein by reference) specify an interface that enables discovery and selection of individual presentations <b>152</b>. However, if the HTML5 media element is used outside of an HbbTV environment, or if the Media Source Extensions are used for playback, then no such interface is available. <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example protocol for presentation selection in HbbTV, using e.g. the HTML5 API <b>122</b>. <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example protocol for presentation selection, using e.g. the MSE API <b>122</b>.</p><p id="p-0045" num="0046">With regard to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the application <b>112</b> may initialize an HTML5 media element with a URL (Uniform Resource Locator) pointing to a manifest file <b>140</b> stored on a network server <b>101</b>. The terminal <b>111</b> may download and parse the manifest file <b>140</b>. Furthermore, the terminal <b>111</b> may populate a list of AudioTrack objects, which are available within the HTML5 media element. The list of AudioTrack objects may be generated based on the Preselections <b>190</b> (if available) and/or the AdaptationSets <b>180</b> comprised within the media element.</p><p id="p-0046" num="0047">The application <b>112</b> may be configured to retrieve the list of AudioTrack objects from the terminal <b>111</b> via the HTML5 API <b>122</b>. Furthermore, the application <b>112</b> may be configured to match the AudioTrack objects to information <b>141</b> regarding the different presentations <b>152</b> which is available within the manifest file <b>140</b>, and/or with a-priori information. Based on the matching, a particular presentation <b>152</b> (notably preselection) may be selected to be played by enabling the corresponding AudioTrack object, i.e. the corresponding presentation <b>152</b>.</p><p id="p-0047" num="0048">The terminal <b>111</b> may be configured to configure the decoder <b>113</b> to play the selected presentation <b>152</b>. Furthermore, the terminal <b>111</b> may be configured to download the media segments <b>170</b> for the selected presentation <b>152</b> from the network server <b>101</b>, and provide the downloaded segments <b>170</b> to the decoder <b>113</b> for rendering.</p><p id="p-0048" num="0049">Information relating to performing the steps of the protocol shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> can be found in the specification of HbbTV 2.0.2 and the W3C specification, including specifically using the W3C standardized AudioTrack object (which are incorporated by reference herein). The HTML5 media element may be available for TV native applications <b>112</b>. Furthermore, the HTML5 media element may be available on a browser or terminal <b>111</b> that supports using a DASH manifest file <b>140</b> as a source for populating the AudioTrackList.</p><p id="p-0049" num="0050"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example protocol for presentation selection using the MSE API <b>122</b>. Details regarding the MSE API <b>122</b> are specified in https://www.w3.org/TR/2016/REC-media-source-20161117, which is incorporated herein by reference.</p><p id="p-0050" num="0051">As outlined in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the application <b>112</b> may download and parse a manifest file <b>140</b> from a network server <b>101</b>. Furthermore, the application <b>112</b> may select a presentation <b>152</b> based on the data <b>141</b> provided within the manifest file <b>140</b>. The presentation <b>152</b> may comprise a Preselection and/or an AdaptationSet. Furthermore, the application <b>112</b> may be configured to select the referenced asset and/or elementary stream <b>121</b> and download the initialization segment <b>160</b> for the selected stream <b>121</b>. The presentation <b>152</b> may be comprised within one audio stream or several streams may participate with several initialization segments <b>160</b>.</p><p id="p-0051" num="0052">The application <b>112</b> may be further configured to send the one or more initialization segments <b>160</b> to the terminal <b>111</b> (e.g. using the SourceBuffer.appendBuffer( ) call). The terminal <b>111</b> may be configured to parse an initialization segment <b>160</b> (possibly using the decoder <b>113</b>), in order to populate a list of AudioTrack objects for the presentations <b>152</b> signaled in the initialization segment <b>160</b>.</p><p id="p-0052" num="0053">The application <b>112</b> may be configured to retrieve the list of AudioTrack objects, e.g. from the AudioTracks attribute. Furthermore, the application <b>112</b> may be configured to match the AudioTrack objects to information <b>141</b> available within in the manifest file <b>140</b> or to a-priori information. The application <b>112</b> may be further configured to select playback of a presentation <b>152</b> by enabling the corresponding AudioTrack object.</p><p id="p-0053" num="0054">The terminal <b>111</b> may configure the decoder <b>113</b> to play the selected presentation <b>152</b>. Furthermore, the application <b>112</b> may be configured to download the media segments <b>170</b> for the selected presentation <b>152</b>, and to send the media segments <b>170</b> to the terminal <b>111</b>, e.g. using the SourceBuffer.appendBuffer( ) call.</p><p id="p-0054" num="0055">In step <b>7</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the terminal may have previously parsed the initialization segment <b>160</b> only to the minimum level necessary (typically, no further than the AudioSampleEntry), to determine whether audio is included. Specifically, the terminal <b>111</b> may have been configured to not parse into those parts of the initialization segment <b>160</b>, which are datatype specific. Furthermore, the terminal <b>111</b> may have been configured to only parse into the first audio file track. In this case, the terminal <b>111</b> would have made available (at most) only one AudioTrack object per MSE source buffer, as specified in https://www.w3.org/TR/2016/REC-media-source-20161117/, section 1.2 (which is incorporated herein by reference). The resulting audio track object typically would have no specific relation to the number or type of presentations <b>152</b>, which are comprised within the bitstream <b>121</b>. Hence, if only minimal parsing of the initialization segment <b>160</b> is performed, the selection of a personalized presentation <b>152</b> is not possible.</p><p id="p-0055" num="0056">In the present document, a terminal <b>111</b> is described, which is configured to derive from the initialization segment <b>160</b> the total number N of presentations <b>152</b> comprised in all file audio tracks of the initialization segment <b>160</b> and to instantiate N audio track objects corresponding to these N presentations <b>152</b>. The terminal <b>111</b> may be configured to set the properties of the audio track objects matching the presentations <b>152</b>. If the terminal <b>111</b> sets properties, the terminal <b>111</b> may be configured to apply the sort order defined in step <b>14</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0056" num="0057">With regards to step <b>10</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, it should be noted that the application <b>112</b> is typically provided by the same source as the media content (i.e. from the same broadcaster or content provider). As a result of this, the application <b>112</b> may be equipped with a-priori knowledge regarding the number, the type and/or the sort order of presentations <b>152</b> comprised within the media content. It may not be necessary for the AudioTrack objects to reflect the true properties of the underlying presentations <b>152</b> since the AudioTrack objects and/or the properties may already be identified by the order <b>162</b> of the AudioTrack objects within the list of AudioTrack objects.</p><p id="p-0057" num="0058">The terminal <b>111</b> may be configured (in the context of step <b>14</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>) to select one presentation <b>152</b> from a plurality of presentations <b>152</b>. For this purpose, the list of AudioTrack objects may be sorted in a defined order and may be made available in this specific order to the application <b>112</b>. The sorting order, which is used, should be known to the application <b>112</b> so that a presentation selection performed by the application <b>112</b> results in the selection of the right presentation <b>152</b>.</p><p id="p-0058" num="0059">A possible realization of such sort order is to determine the list of audio track objects for every contained file audio track in order of appearance, and for every contained presentation in order of appearance.</p><p id="p-0059" num="0060">By way of example, the list of presentations <b>152</b> may be sorted into strictly ascending or descending order of a unique identifier of the different presentations <b>152</b>, if such an identifier is available for each one of the different presentations <b>152</b>. If such identifier is not available directly, but if the totality of presentation information contained in the initialization segment <b>160</b> uniquely identifies the different presentations individually, a hash over the presentation information of the different presentations may be used as an identifier. In other words, a hash over the presentation information for a particular presentation may be used to determine a unique identifier for this particular presentation. As a result of this, N hash values may be determined as unique identifiers for N different presentations (with N&#x3e;1, e.g. N=2, 3, 4, 5 or more).</p><p id="p-0060" num="0061">Alternatively, an unsorted list may be used. The terminal <b>111</b> may be configured to obtain the presentation IDs from the initialization segment <b>160</b> and set the ID element in the AudioTracks object to the same value. This enables the application <b>112</b> to map the Audio Tracks generated by the terminal <b>111</b> to the information presented in the preselection element by comparing the AudioTrack object IDs with the preselection tag element (from the manifest file <b>140</b>.</p><p id="p-0061" num="0062">An example regarding step <b>14</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> is provided in the context of Table 1. An initialization segment <b>160</b> may comprise two presentations: P2 and P1 (indicated in different sections <b>161</b>, thereby providing a segment order <b>162</b> of the list of audio track objects). These presentations <b>152</b> can be sorted in an audio track list according to the two example methods outlined above:</p><p id="p-0062" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="91pt" align="left"/><thead><row><entry namest="1" nameend="2" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row><row><entry>Sort method A (by order of occurrence)</entry><entry>Sort method B (by identifier)</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>AudioTrack 1: P2</entry><entry>AudioTrack 1: P1</entry></row><row><entry>AudioTrack 2: P1</entry><entry>AudioTrack 2: P2</entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0063" num="0063">In the above example, the application <b>112</b> may learn from the manifest file <b>150</b> of the audio signal that presentation 1 is regular audio and presentation 2 is audio for the visually impaired. The application <b>112</b> now needs to choose whether to enable AudioTrack 1 or AudioTrack 2. Assuming the application <b>112</b> wants to select the audio for the visually impaired, it needs to enable either AudioTrack 1 if Sort Method A was used or AudioTrack 2 if Sort Method B was used by the terminal <b>111</b>. Hence, the application <b>112</b> may apply knowledge regarding the sort method which is applied by the terminal <b>111</b>.</p><p id="p-0064" num="0064">Hence, an application control method for audio processing is described. The method may comprise receiving a manifest file <b>140</b>. Furthermore, the method may comprise selecting a presentation <b>152</b>, e.g. at least an adaptation set or at least a preselection element, (from the manifest file <b>140</b>). The presentation <b>152</b> may be selected based on the information <b>141</b> regarding the different presentations <b>152</b>, which is provided within the manifest file <b>140</b>. The manifest file <b>140</b> may be downloaded from a network server <b>101</b> and may be parsed for pointers identifying a presentation <b>152</b>, notably at least an adaptation set or a preselection element.</p><p id="p-0065" num="0065">The method may further comprise generating or receiving a list of available audio tracks based on selected presentation <b>152</b>, e.g. the adaptation set or the preselection element, using the media source extensions API <b>122</b>. The list of audio tracks may be generated by the terminal <b>111</b>.</p><p id="p-0066" num="0066">In the context of the method, an initialization segment <b>160</b> may be downloaded from a network server <b>101</b>. Furthermore, the initialization segment <b>160</b> may be sent to the terminal <b>111</b> through the media source extensions API <b>122</b>. The terminal <b>111</b> may parse the initialization segment <b>160</b> for generating the list of available AudioTrack objects. The list of AudioTrack objects may be provided to the application <b>112</b> via the MSE API <b>122</b>.</p><p id="p-0067" num="0067">The terminal <b>111</b> may be configured to generate the list of available AudioTrack objects according to a specified order, e.g. the segment order <b>162</b> corresponding to the order of appearance within the initialization segment <b>160</b>. In other words, the specified order may be the order of appearance in the initialization segment <b>160</b>. Alternatively, or in addition, the specified order may be an ascending or descending order of a unique identifier of the AudioTrack objects. The unique identifier may be derived from the presentation properties that are indicated within the initialization segment <b>160</b> using a hashing algorithm.</p><p id="p-0068" num="0068">The selection step may use the list of available AudioTrack objects, and one or more objects may be identified by index into the list. The terminal <b>111</b> may be configured to assign the presentation ID to the ID of AudioTrack objects. The list of AudioTrack objects may be updated based on information obtained from media segments <b>170</b> containing the media (notably the audio content).</p><p id="p-0069" num="0069"><figref idref="DRAWINGS">FIG. <b>4</b><i>a </i></figref>shows a flow chart of an example method <b>400</b> for providing personalized audio to a user. The audio may be comprised within a media element, notably an HTML 5 media (e.g. audio) element. The media element may comprise different audio components <b>181</b>, which may be combined in different manners to provide different presentations <b>152</b>. The different presentations <b>152</b> may be specified as one or more Adaptation Sets and/or Preselections. The method <b>400</b> may be executed by an application <b>112</b> (or a device running the application) within an HbbTV system <b>100</b>.</p><p id="p-0070" num="0070">The method <b>400</b> may comprise receiving <b>401</b> a manifest file <b>140</b> for a media element from which audio is to be rendered. The manifest file <b>140</b> may be downloaded from a network server <b>101</b>. The manifest file <b>140</b> may be a Dynamic Adaptive Streaming over HTTP, referred to as DASH, manifest file. The manifest file <b>140</b> may comprise a description <b>141</b> for a plurality of different presentations <b>152</b> of audio content of the media element. The plurality of presentations <b>152</b> which is indicated within the manifest file <b>140</b> may comprise one or more Preselections and/or Adaptation Sets, notably DASH Preselections and/or Adaptation Sets.</p><p id="p-0071" num="0071">Hence, parsing the manifest file <b>140</b> may be performed to determine a plurality of presentations <b>152</b>, notably an ordered list of presentations <b>152</b>.</p><p id="p-0072" num="0072">The method <b>400</b> further comprises selecting <b>402</b> a presentation <b>152</b> from the plurality of presentations <b>152</b> based on the manifest file <b>140</b>, notably based on the descriptions <b>141</b> of the different presentations <b>152</b>. The selection may be performed by the user (e.g. via a user interface of the application or the device running the application).</p><p id="p-0073" num="0073">In addition, the method <b>400</b> comprises receiving <b>403</b> a list of audio track objects comprised within the media element. The list of audio track objects may be received from a terminal <b>111</b> of the HbbTV system <b>100</b>. In particular, the list of audio track objects may be received via a media selection extension (MSE) application programming interface <b>122</b> (API), notably an HTML 5 MSE API.</p><p id="p-0074" num="0074">The method <b>400</b> may further comprise selecting <b>404</b> an audio track object from the list of audio track objects, in dependence of the selected presentation <b>152</b>. In particular, the audio track object corresponding to the selected presentation <b>152</b> may be selected (and used for rendering). By doing this, a reliable and efficient personalization of audio may be provided within an HbbTV system <b>100</b>.</p><p id="p-0075" num="0075">Furthermore, the method <b>400</b> may comprise retrieving at least one media segment for the selected audio track object. The one or more media segments (comprising the actual audio to be rendered) may be received from a network server <b>101</b>, which may be assigned to the same content provider which provides the manifest file <b>140</b>. The at least one media segment for the selected audio track object may then be provided to the terminal <b>111</b> for rendering of the selected presentation <b>152</b>.</p><p id="p-0076" num="0076">The audio track object may be selected from the list of audio track objects in dependence of information regarding the order <b>162</b> of audio track objects within the list of audio track objects. In particular, the audio track object may be selected from the list of audio track objects in dependence of information regarding the order <b>162</b> of audio track objects within the list of audio track objects relative to the order <b>142</b> of the description <b>141</b> for the plurality of different presentations <b>152</b> within the manifest file <b>140</b>. The information regarding the ordering may be available due to the fact that the manifest file <b>140</b> and the initialization segment <b>160</b> are provided by the same content provider, and/or due to the fact that the application <b>112</b> is provided by the same content provider as the manifest file <b>140</b> and the initialization segment <b>160</b>. By taking into account information regarding the ordering of the list of audio track objects, a reliable selection of personalized audio content is enabled.</p><p id="p-0077" num="0077">The manifest file <b>140</b> may be such that the order <b>142</b> of the description <b>141</b> for the plurality of different presentations <b>152</b> corresponds to, notably is identical to, the order <b>162</b> of audio track objects within the list of audio track objects, thereby enabling a reliable selection of personalized audio content.</p><p id="p-0078" num="0078">The manifest file <b>140</b> may be such that the description <b>141</b> for the plurality of different presentations <b>152</b> is indicative of a numerical identifier for each one of the plurality of different presentations <b>152</b>. Furthermore, the order <b>162</b> of audio track objects within the list of audio track objects may correspond to a predetermined, notably an ascending or descending, order of the numerical identifiers of the plurality of different presentations <b>152</b>. By making use of numerical identifiers and/or a pre-determined ordering according to the numerical identifiers, a reliable selection of personalized audio content is enabled.</p><p id="p-0079" num="0079">The manifest file <b>140</b> may comprise presentation information for each one of the plurality of different presentations <b>152</b>, notably within the description <b>141</b> for the plurality of different presentations <b>152</b>. The same presentation information may also be comprised within the initialization segment <b>160</b> of the media element.</p><p id="p-0080" num="0080">The method <b>400</b> may comprise determining a unique identifier for each one of the plurality of different presentations <b>152</b> based on the presentation information for each one of the plurality of different presentations <b>152</b>, respectively, notably using a hashing algorithm. The determined identifiers may then be used to selecting an audio track object from the list of audio track objects, thereby enabling a reliable selection of personalized audio content.</p><p id="p-0081" num="0081"><figref idref="DRAWINGS">FIG. <b>4</b><i>b </i></figref>shows a flow chart of another method <b>410</b> for providing personalized audio to a user. The method <b>410</b> may be executed by a terminal <b>111</b> within a HbbTV system <b>100</b>. As such, the method <b>410</b> may comprise method steps which are complimentary and/or corresponding to the method steps of method <b>400</b> (which may be executed by a corresponding application <b>112</b> within the HbbTV system <b>100</b>).</p><p id="p-0082" num="0082">The method <b>410</b> comprises receiving <b>411</b> an initialization segment <b>160</b> for the media element from which audio is to be rendered (e.g. from the network server <b>101</b> of the content provider). In addition, the method <b>410</b> comprises determining <b>412</b> a list of audio track objects for a plurality of different presentations <b>152</b> of the media element, based on the initialization segment <b>160</b>. In particular, the initialization segment <b>160</b> may be parsed for determining <b>412</b> the list of audio track objects. The list of audio track objects may be an ordered list, wherein the order of the list may be known to the application <b>112</b>.</p><p id="p-0083" num="0083">The method <b>410</b> further comprises providing <b>413</b> the list of audio track objects for selection of one of the audio track objects for one of the plurality of different presentations <b>152</b>. The list of audio track objects may be provided to an application <b>112</b> of the HbbTV system <b>100</b>. In addition, the method <b>410</b> may comprise receiving at least one media segment <b>170</b> for a selected audio track object and/or rendering the at least one media segment <b>170</b> using a decoder <b>113</b>. Hence, a method <b>410</b> is described which allows for a reliable selection and rendering of personalized audio content.</p><p id="p-0084" num="0084">The list of audio track objects may be ordered in dependence of, notably in accordance to, the order <b>162</b> of appearance of initialization sections <b>161</b> for the different audio track objects within the initialization segment <b>160</b>. By using such ordering of the list of audio track objects a reliable selection and rendering of personalized audio content is enabled.</p><p id="p-0085" num="0085">Alternatively, or in addition, the method <b>410</b> may comprise ordering the list of audio track objects in dependence of unique identifiers for each one of the plurality of different presentations <b>152</b> and/or for each one of the corresponding plurality of audio track objects.</p><p id="p-0086" num="0086">The initialization segment <b>160</b> may comprise presentation information for each one of the plurality of different presentations <b>152</b>. The method <b>410</b> may comprise determining a unique identifier for each one of the plurality of different presentations <b>152</b> and/or for each one of the corresponding plurality of audio track objects based on the presentation information for each one of the plurality of different presentations <b>152</b>, respectively, notably using a hashing algorithm. By making use of unique identifiers, a reliable selection and rendering of personalized audio content is enabled.</p><p id="p-0087" num="0087">Furthermore, an application <b>112</b> and a terminal <b>111</b>, i.e. devices and/or apparatuses, are described in the present document, which are configured to execute the methods <b>400</b> and <b>410</b>, respectively.</p><p id="p-0088" num="0088">The methods and systems described in the present document may be implemented as software, firmware and/or hardware. Certain components may e.g. be implemented as software running on a digital signal processor or microprocessor. Other components may e.g. be implemented as hardware and or as application specific integrated circuits. The signals encountered in the described methods and systems may be stored on media such as random access memory or optical storage media. They may be transferred via networks, such as radio networks, satellite networks, wireless networks or wireline networks, e.g. the Internet. Typical devices making use of the methods and systems described in the present document are portable electronic devices or other consumer equipment which are used to store and/or render audio signals.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-01-20" num="01-20"><claim-text><b>1</b>-<b>20</b>. (canceled)</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. A method for providing personalized audio to a user; wherein the method comprises:<claim-text>receiving a manifest file for a media element from which audio is to be rendered; wherein the manifest file comprises a description for a plurality of presentations of audio content of the media element;</claim-text><claim-text>selecting a presentation from the plurality of presentations based on the manifest file;</claim-text><claim-text>receiving a list of audio track objects comprised within the media element, wherein each audio track object is an entity that can be selected and corresponds to a particular presentation; and</claim-text><claim-text>selecting an audio track object from the list of audio track objects based on the selected presentation, wherein the audio track object is selected from the list of audio track objects based on an order of audio track objects within the list of audio track objects relative to an order of the description for the plurality of presentations.</claim-text></claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising:<claim-text>retrieving at least one media segment for the selected audio track object; and</claim-text><claim-text>providing at least one media segment for the selected audio track object for rendering of the selected presentation.</claim-text></claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the manifest file is such that the order of the description for the plurality of different presentations corresponds to the order of audio track objects within the list of audio track objects.</claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein<claim-text>the description for the plurality of different presentations is indicative of a numerical identifier for each one of the plurality of different presentations; and</claim-text><claim-text>the order of audio track objects within the list of audio track objects corresponds to a predetermined order of the numerical identifiers of the plurality of different presentations.</claim-text></claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the list of audio track objects is received via a media selection extension (MSE) application programming interface (API).</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the manifest file is a Dynamic Adaptive Streaming over HTTP (DASH) manifest file.</claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the manifest file and at least one media segment for the selected audio track object are received from one or more network servers.</claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the plurality of presentations indicated within the manifest file comprises one or more Preselections or Adaptation Sets.</claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the receiving is performed by an application within an Hybrid broadcast broadband TV (HbbTV) system; and the list of audio track objects is received from a terminal of the HbbTV system.</claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref>, further comprising determining a unique identifier for each one of the plurality of different presentations.</claim-text></claim><claim id="CLM-00031" num="00031"><claim-text><b>31</b>. A method for providing personalized audio to a user in a Hybrid broadcast broadband TV (HbbTV) environment, wherein the method comprises:<claim-text>receiving an initialization segment for a media element from which audio is to be rendered;</claim-text><claim-text>determining, based on the initialization segment, a list of audio track objects for a plurality of different presentations of the media element, wherein the list of audio track objects is ordered based on an order of appearance of initialization sections for the different audio track objects within the initialization segment, and wherein each audio track object is an entity that can be selected and corresponds to a particular presentation; and</claim-text><claim-text>providing the list of audio track objects for selection of one of the audio track objects for one of the plurality of different presentations.</claim-text></claim-text></claim><claim id="CLM-00032" num="00032"><claim-text><b>32</b>. The method of <claim-ref idref="CLM-00031">claim 31</claim-ref>, further comprising:<claim-text>receiving at least one media segment for a selected audio track object; and</claim-text><claim-text>rendering the at least one media segment.</claim-text></claim-text></claim><claim id="CLM-00033" num="00033"><claim-text><b>33</b>. The method of <claim-ref idref="CLM-00031">claim 31</claim-ref>, further comprising parsing the initialization segment for determining the list of audio track objects.</claim-text></claim><claim id="CLM-00034" num="00034"><claim-text><b>34</b>. The method of <claim-ref idref="CLM-00031">claim 31</claim-ref>, further comprising ordering the list of audio track objects based on unique identifiers for each one of the plurality of different presentations and for each one of the corresponding plurality of audio track objects.</claim-text></claim><claim id="CLM-00035" num="00035"><claim-text><b>35</b>. The method of <claim-ref idref="CLM-00031">claim 31</claim-ref>, further comprising determining a unique identifier for each one of the plurality of different presentations, and, for each one of the corresponding plurality of audio track objects based on presentation information for each one of the plurality of different presentations, wherein the initialization segment comprises the presentation information for each one of the plurality of different presentations.</claim-text></claim><claim id="CLM-00036" num="00036"><claim-text><b>36</b>. A system for providing personalized audio to a user; the system comprising:<claim-text>a first receiver for receiving a manifest file for a media element from which audio is to be rendered; wherein the manifest file comprises a description for a plurality of different presentations of audio content of the media element;</claim-text><claim-text>a first selector for selecting a presentation from the plurality of presentations based on the manifest file;</claim-text><claim-text>a second receiver for receiving a list of audio track objects comprised within the media element, wherein each audio track object is an entity that can be selected and corresponds to a particular presentation; and</claim-text><claim-text>a second selector for selecting an audio track object from the list of audio track objects, in dependence of the selected presentation, wherein the audio track object is selected from the list of audio track objects based on information regarding an order of audio track objects within the list of audio track objects relative to an order of the description for the plurality of different presentations within the manifest file.</claim-text></claim-text></claim><claim id="CLM-00037" num="00037"><claim-text><b>37</b>. A HbbTV system for providing personalized audio to a user, the system comprising:<claim-text>a receiver for receiving an initialization segment for a media element from which audio is to be rendered;</claim-text><claim-text>a processor for determining a list of audio track objects for a plurality of different presentations of the media element based on the initialization segment, wherein the list of audio track objects is ordered based on an order of appearance of initialization sections for the different audio track objects within the initialization segment, and wherein each audio track object is an entity that can be selected and corresponds to a particular presentation; and</claim-text><claim-text>a renderer for providing the list of audio track objects for selection of one of the audio track objects for one of the plurality of different presentations to an application of the HbbTV system.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005590A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005590</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17561815</doc-number><date>20211224</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>202110757684.X</doc-number><date>20210705</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>20</main-group><subgroup>30</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>10</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>20</main-group><subgroup>30</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>10</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD FOR ALLOWING AND IMPROVING REHABILITATION AT HOME, VR REHABILITATION APPARATUS, AND SYSTEM EMPLOYING METHOD</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>HONG FU TAI PRECISION ELECTRONS (YANTAI) CO., LTD.</orgname><address><city>Yantai</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>HON HAI PRECISION INDUSTRY CO., LTD.</orgname><address><city>New Taipei</city><country>TW</country></address></addressbook><residence><country>TW</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>CHUNG</last-name><first-name>CHENG-FA</first-name><address><city>New Taipei</city><country>TW</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>HUANG</last-name><first-name>KUN-LIN</first-name><address><city>New Taipei</city><country>TW</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>WANG</last-name><first-name>NA</first-name><address><city>Yantai</city><country>CN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>JIAO</last-name><first-name>YU-MING</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method for enabling rehabilitation at home for a user to regain a physical ability by means of an apparatus for physical use collects user information of a user. A virtual object is created based on the user information. The virtual object representing the user is displayed on a displaying mechanism. The virtual object is trained to move and perform rehabilitation actions. Actions and movements performed by the user are collected while the rehabilitation actions are displayed. The copycat actions of the user are compared with the rehabilitation actions and the user is assisted to correctly copy the rehabilitation actions based on the comparison. The user can undergo physiotherapy at home without a physiotherapist being present. A VR rehabilitation system and a VR rehabilitation apparatus applying the method are also provided in addition to the physical apparatus.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="206.42mm" wi="157.23mm" file="US20230005590A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="174.58mm" wi="156.13mm" file="US20230005590A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="207.35mm" wi="159.51mm" file="US20230005590A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="181.69mm" wi="73.24mm" file="US20230005590A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="222.25mm" wi="159.26mm" file="US20230005590A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD</heading><p id="p-0002" num="0001">The subject matter herein generally relates to virtual reality (VR), specifically to method for rehabilitation using VR, a rehabilitation apparatus using VR, and a system employing the method.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Rehabilitation is the process of regaining physical ability after the loss of the ability. The rehabilitation often is executed in a specified place, such as a hospital or a professional center, and each physical disability needs a physiotherapist for assisting. Having to travel to the specified place is inconvenient, and good physiotherapists are few in number. Rehabilitation teaching videos for standard use at home may not be suitable for every patient and so not effective in their purpose.</p><p id="p-0004" num="0003">Thus, there is room for improvement in the art.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0005" num="0004">Implementations of the present disclosure will now be described, by way of example only, with reference to the attached figures.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an embodiment of a rehabilitation apparatus according to the present disclosure.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram illustrating an embodiment of the rehabilitation apparatus in <figref idref="DRAWINGS">FIG. <b>1</b></figref> according to the present disclosure.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an embodiment of a rehabilitation system according to the present disclosure.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an embodiment of method for effective rehabilitation carried out at home according to the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0010" num="0009">The present disclosure is described with reference to accompanying drawings and the embodiments. It will be understood that the specific embodiments described herein are merely part of all embodiments, not all the embodiments. Based on the embodiments of the present disclosure, it is understandable to a person skilled in the art, any other embodiments obtained by persons skilled in the art without creative effort shall all fall into the scope of the present disclosure.</p><p id="p-0011" num="0010">The relationships of orientations or positions denoted by the terms of terms &#x201c;center&#x201d;, &#x201c;longitudinal&#x201d;, &#x201c;lateral&#x201d;, &#x201c;length&#x201d;, &#x201c;width&#x201d;, &#x201c;thickness&#x201d;, &#x201c;up&#x201d;, &#x201c;down&#x201d;, &#x201c;left&#x201d;, &#x201c;right&#x201d;, &#x201c;horizontal&#x201d;, &#x201c;left&#x201d;, &#x201c;top&#x201d;, &#x201c;bottom&#x201d;, &#x201c;inside&#x201d;, &#x201c;outside&#x201d;, &#x201c;clockwise&#x201d;, &#x201c;anticlockwise&#x201d; used herein refer to those illustrated in the accompany drawings, which are only for conveniently describing the invention and simplifying the description, rather than indicating or implying that a device or member has to be in a specific orientation or configured or operated in a specific orientation. In addition, the terms of &#x201c;first&#x201d; and &#x201c;second&#x201d; are for the purpose of describing only and should not be constructed to indicate or imply the relative importance. In the present disclosure, the term &#x201c;some&#x201d; means two or more than two, unless otherwise expressly stated.</p><p id="p-0012" num="0011">In the present disclosure, unless otherwise expressly stated, the terms &#x201c;mounted&#x201d;, &#x201c;link&#x201d;, and &#x201c;connect&#x201d; should be understood broadly, unless otherwise specified and defined, for example, they may be a fixed connection or a removable connection, they may be mechanical connection or electrical connection, and also an inner communication between two members, they may be direct connection, and also an indirect connection via a medium, the skilled persons in the art may understand the meanings of above terms according to specific situations.</p><p id="p-0013" num="0012">In the present disclosure, unless otherwise expressly stated, a structure in which a first feature is &#x201c;on&#x201d; or &#x201c;below&#x201d; a second feature may include an embodiment in which the first feature is in direct contact with the second feature and may also include an embodiment in which the first feature and the second feature are not in direct contact with each other but are in contact via an additional feature formed therebetween. Furthermore, a first feature &#x201c;on,&#x201d; &#x201c;above,&#x201d; or &#x201c;on top of&#x201d; a second feature may include an embodiment in which the first feature is right or obliquely &#x201c;on,&#x201d; &#x201c;above,&#x201d; or &#x201c;on top of&#x201d; the second feature, or just means that the first feature is at a height higher than that of the second feature; while a first feature &#x201c;below,&#x201d; &#x201c;under,&#x201d; or &#x201c;on bottom of&#x201d; a second feature may include an embodiment in which the first feature is right or obliquely &#x201c;below,&#x201d; &#x201c;under,&#x201d; or &#x201c;on bottom of&#x201d; the second feature, or just means that the first feature is at a height lower than that of the second feature.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an apparatus for rehabilitation at home making use of virtual reality (VR) principles (VR rehabilitation apparatus <b>100</b>) for assisting users at home without a physiotherapist, thus no travel time of the user is required. The user can be someone with physical disabilities, or normal persons who want to improve their bodies or a part. The VR rehabilitation apparatus <b>100</b> includes a processor <b>10</b>, a collecting mechanism <b>20</b>, a displaying mechanism <b>30</b>, and a first assisting mechanism <b>40</b>. The processor <b>10</b> connects with the collecting mechanism <b>20</b>, the displaying mechanism <b>30</b>, and the first assisting mechanism <b>40</b>.</p><p id="p-0015" num="0014">The collecting mechanism <b>20</b> is configured to collect user information of the user and transmits the collected user information to the processor <b>10</b>. The user information can include video data, user appearance features, and physiological data. The video data can record an action of each user in real time, for example, capturing a video of the user or his or her actions. The video data also can include environment information surrounding the user and sound information surrounding the user. The user appearance features are used for forming a virtual object corresponding to the user for making the virtual object more personal to the user. The physiological data can include a temperature, a heart rate, a heart rate variability of the user, not being limited. The physiological data can be provided to the processor <b>10</b>, doctors, or physiotherapists to evaluate a rehabilitation for correcting or prompting.</p><p id="p-0016" num="0015">The processor <b>10</b> is configured to create the virtual object based on the user information. The virtual object can be a 3D human model or a VR model. When the virtual object is the VR model, VR glasses are provided to the user for viewing a virtual object. In detail, the method for creating a virtual object of the embodiment can include collecting the user appearance by the collecting mechanism <b>20</b>. The collecting mechanism <b>20</b> studies a body minutely based on a motion correction, and the processor <b>10</b> controls the displaying mechanism <b>30</b> to display the 3D body model. The processor <b>10</b> analyzes a skeletal structure of the 3D body model and generates joint node coordinates as a joint coordinate set. A vector is formed by two adjacent joints. The process <b>10</b> decides the joints to be tracked by the vector and confirms that the 3D body model can be used.</p><p id="p-0017" num="0016">The processor <b>10</b> further controls the displaying mechanism <b>30</b> to display the virtual object. The displaying mechanism <b>30</b> can be a display screen or a projector. The displaying mechanism <b>30</b> can display the virtual object and generate a prompt sound. When the displaying mechanism <b>30</b> is a display screen, the displaying mechanism <b>30</b> can have a touch function, which can be touched by the users for inputting commands. When the displaying mechanism <b>30</b> is a projector, the displaying mechanism <b>30</b> projects the virtual object on a projection screen or other display surfaces.</p><p id="p-0018" num="0017">The processor <b>10</b> also can train the virtual object to move and perform rehabilitation actions. The processor <b>10</b> trains the virtual object, thus the virtual object can portray the rehabilitation actions to form a rehabilitation video. Thus, the users can exercise according to the rehabilitation actions in the rehabilitation video.</p><p id="p-0019" num="0018">The collecting mechanism <b>20</b> also collects actions acted by the users while the user mimes the rehabilitation actions and transmits the collected actions (mimicry actions) to the processor <b>10</b>. While watching the rehabilitation video the user can mime and follow the actions acted by the virtual object. The collecting mechanism <b>20</b> can collect the mimicry actions of the user in real time.</p><p id="p-0020" num="0019">The processor <b>10</b> further compares the mimicry actions with the rehabilitation actions to form a comparison result. The processor <b>10</b> compares the mimicry actions collected by the collecting mechanism <b>20</b> with the rehabilitation actions, thus the comparison result is formed. The comparison result can be displayed on the virtual object. For example, when the mimicry actions are similar or equal to the required rehabilitation actions, the rehabilitation actions acted by the virtual object are displayed in green for indicating correctness of the mimicry actions. When there is a difference between the mimicry actions and the rehabilitation actions, the rehabilitation actions acted by the virtual object are displayed in yellow for indicating incorrectness of the mimicry actions. When seeing the rehabilitation action acted by the virtual object in yellow, the user can re-mime the rehabilitation actions required. In detail, the method for forming comparison result can include: the processor <b>10</b> cooperates with the collecting mechanism <b>20</b> to capture coordinate of each joint based on the confirmed original position of the 3D body model. The vector between two joint nodes is used for determining whether the mimicry actions are correctly acted, thus the comparison result is formed.</p><p id="p-0021" num="0020">The processor <b>10</b> further controls the first assisting mechanism <b>40</b> to assist the user for miming the rehabilitation actions based on the comparison result. When there is a difference between the mimicry actions and the rehabilitation actions, the processor <b>10</b> controls the first assisting mechanism <b>40</b> to assist the user to mime the rehabilitation actions. When the mimicry actions re-mimed by the user are incorrect for a certain number of times or in a certain time period, the processor <b>10</b> controls the first assisting mechanism <b>40</b> to assist the user for miming the rehabilitation actions. The first assisting mechanism <b>40</b> assists the user to mime the rehabilitation actions until the mimicry actions are similar or equal to the rehabilitation actions. It is understood that, when the mimicry actions are similar or equal to the rehabilitation actions, the body function of the user can be expected to recover.</p><p id="p-0022" num="0021">The first assisting mechanism <b>40</b> assists the user to mime the mimicry actions. The processor <b>10</b> controls the first assisting mechanism <b>40</b> to assist the user based on a strength requirement of the rehabilitation actions. The processor <b>10</b> can omit the operation of comparing the mimicry actions with the rehabilitation actions.</p><p id="p-0023" num="0022">If the body function of the user is improved or improving, the first assisting mechanism <b>40</b> can be omitted, the VR rehabilitation apparatus <b>100</b> can prompt the user based on the comparison result.</p><p id="p-0024" num="0023">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in one embodiment, the VR rehabilitation apparatus <b>100</b> can include a frame <b>70</b>. The processor <b>10</b> is disposed inside the frame <b>70</b>. The collecting mechanism <b>20</b> is disposed inside the frame <b>70</b> or outside of the frame <b>70</b>. The displaying mechanism <b>30</b> is disposed in the frame <b>70</b>. The first assisting mechanism <b>40</b> can be slidably disposed on the frame <b>70</b>.</p><p id="p-0025" num="0024">The first assisting mechanism <b>40</b> can assist arm movements of the user to mime the mimicry actions. There is a first assisting mechanism <b>40</b> for each arm of the user. The two first assisting mechanisms <b>40</b> are slidably disposed on the frame <b>70</b>.</p><p id="p-0026" num="0025">The frame <b>70</b> includes two sliding rails <b>71</b> disposed on opposite sides of the frame <b>70</b>. Each first assisting mechanism <b>40</b> includes a first driving module <b>41</b>, a first arm <b>42</b>, a second driving module <b>43</b>, and a first assisting module <b>44</b>. The first driving module <b>41</b> is slidably disposed on one of the sliding rails <b>71</b>, the first arm <b>42</b> connects with the first driving module <b>41</b>. The first driving module <b>41</b> drives the first arm <b>42</b> to move in a specified range. In detail, the first driving module <b>41</b> includes a first driving component <b>412</b> and a second driving component <b>414</b>. The first driving component <b>412</b> connects with the second driving component <b>414</b>, the second driving component <b>414</b> connects with the first arm <b>42</b>.</p><p id="p-0027" num="0026">The first driving component <b>412</b> and the second driving component <b>414</b> can be servo motors. The first driving component <b>412</b> drives the second driving component <b>414</b> and the first arm <b>42</b> to move along an extending direction of the sliding rail <b>71</b>. The second driving component <b>414</b> drives the first arm <b>42</b> to rotate in a circle centered with the second driving component <b>414</b>, thus the first arm <b>42</b> changes from a perpendicular state into a horizontal state. The first arm <b>42</b> can assist the user in providing a certain strength to the arms of the users in achieving certain movements.</p><p id="p-0028" num="0027">In other embodiments, the first driving component <b>412</b> can be a cylinder, a linear motor module, and the like, which is able to drive the second driving component <b>414</b> and the first arm <b>42</b> to move along the extending direction of the sliding rail <b>71</b>. The second driving component <b>414</b> can be an electromagnetic driving component, which is able to drive the first arm <b>412</b> to rotate.</p><p id="p-0029" num="0028">The second driving module <b>43</b> is disposed on the first arm <b>42</b> or the frame <b>71</b>. The first assisting module <b>44</b> is disposed on an end of the first arm <b>42</b> away from the first driving module <b>41</b>. The second driving module <b>43</b> drives the first assisting module <b>44</b> to assist the user in following the mimicry actions.</p><p id="p-0030" num="0029">In detail, the second driving module <b>43</b> includes an electromagnetic driving component. The first assisting module <b>44</b> includes a rotating component <b>442</b>, an adjusting component <b>444</b>, and an assisting component <b>446</b>. The rotating component <b>442</b> can be a slide rail <b>71</b>. The adjusting component <b>444</b> can be a rope. The assisting component <b>446</b> can be a bandage or a bracket, supporting the body of the user. The adjusting component <b>444</b> rolls on the rotating component <b>442</b>. The assisting component <b>446</b> is disposed on an end of the adjusting component <b>444</b> away from the rotating component <b>442</b>. The second driving module <b>43</b> connects with the rotating component <b>442</b> for driving the rotating component <b>442</b> to rotate, and the adjusting component <b>444</b> moves in a specified direction. Thus, the assisting component <b>446</b> assists the user to follow the mimicry actions. The adjusting component <b>444</b> circularly rolls on the rotating component <b>442</b> under the driving of the rotating component <b>442</b>. The assisting component <b>446</b> moves towards to or away from the rotating component <b>442</b> for assisting the user to mime the mimicry actions.</p><p id="p-0031" num="0030">For example, if a forearm of the user does not lift up at a specified position, the collecting mechanism <b>20</b> can collect the incorrect mimicry actions. The processor <b>10</b> compares the mimicry actions collected by the collecting mechanism <b>20</b> with the rehabilitation actions. The comparison result indicates there is a difference between the mimicry actions and the rehabilitation actions. The displaying apparatus <b>30</b> displays the rehabilitation action acted by the virtual object in yellow. After the user re-mimes the mimicry actions a certain number of times, the mimicry actions still being incorrect, the processor <b>10</b> can control the first assisting mechanism <b>40</b> to assist the user based on the comparison result. The second driving module <b>43</b> drives the assisting component <b>446</b> to drop down to the forearm. The user puts the forearm on the assisting component <b>446</b>. Then, the second driving module <b>43</b> drives the assisting component <b>446</b> to lift up for assisting the user to mime the rehabilitation actions. In the above process, when the forearm is placed on the assisting component <b>446</b>, the collecting mechanism <b>20</b> collects the placement, and the processor <b>10</b> controls the second driving module <b>43</b> to drive the assisting component <b>446</b> to be lifted up based on the placement. The user also can control the second driving module <b>43</b> to drive the assisting component <b>446</b> to be lifted up under a voice control, a remote control, and the like. Voice information and remote information can be collected by the collecting mechanism <b>20</b>.</p><p id="p-0032" num="0031">In one embodiment, the first assisting mechanism <b>40</b> further includes a second arm <b>45</b>, a third driving module <b>46</b>, and a second assisting module <b>47</b>. The second arm <b>45</b>, the third driving module <b>46</b>, and the second assisting module <b>47</b> can assist an upper arm of the user.</p><p id="p-0033" num="0032">The second arm <b>45</b> is slidably disposed on an end of the first arm <b>42</b> away from the first driving module <b>41</b>. The third driving module <b>46</b> is disposed on the first arm <b>42</b> and the second arm <b>45</b>. The second assisting module <b>47</b> is disposed on an end of the second arm <b>45</b> away from the first arm <b>42</b>. The third driving module <b>46</b> drives the second assisting module <b>47</b> to cooperate with the first assisting module <b>44</b> for assisting the user to mime the rehabilitation actions. The structure of the third driving module <b>46</b> is similar to the structure of the second driving module <b>43</b>. The third driving module <b>46</b> can be an electromagnetic driving component. The structure of the second assisting module <b>47</b> is similar to the structure of the first assisting module <b>44</b>. The VR rehabilitation apparatus <b>100</b> can assist the forearm and the upper arm of the user to mime the rehabilitation actions by the first arm <b>42</b>, the second arm <b>45</b>, the corresponding driving modules, and the assisting modules.</p><p id="p-0034" num="0033">In one embodiment, the VR rehabilitation apparatus <b>100</b> further includes a second assisting mechanism <b>50</b>. The second assisting mechanism <b>50</b> assists legs of the user to mime the rehabilitation actions. The second assisting mechanism <b>50</b> is disposed at outer side of the frame <b>70</b>. The second assisting mechanism <b>50</b> supports the user and assists the supported user to mime the rehabilitation actions.</p><p id="p-0035" num="0034">In detail, the second assisting mechanism <b>50</b> is substantially in shape of a chair. The second assisting mechanism <b>50</b> can be a massage chair. The user can sit on the second assisting mechanism <b>50</b>. The second assisting mechanism <b>50</b> includes a pulling module <b>51</b>. The pulling module <b>51</b> corresponds to the leg of the user. The stretching and retracting pulling module <b>51</b> assists the legs of the user to mime the rehabilitation actions.</p><p id="p-0036" num="0035">In other embodiments, the first assisting mechanism <b>40</b> can also assist the arms and the legs. The first assisting mechanism <b>40</b> includes the function of the second assisting mechanism <b>50</b>, thus the second assisting mechanism <b>50</b> can be omitted.</p><p id="p-0037" num="0036">In one embodiment, the collecting mechanism <b>20</b> includes a first collecting module <b>22</b>, a second collecting module <b>24</b>, and a third collecting module <b>26</b>. The first collecting module <b>22</b> and the second collecting module <b>24</b> are disposed on the frame <b>70</b>, and the third collecting module <b>26</b> is disposed on the outside of the frame <b>70</b>. The third collecting module <b>26</b> can disposed on the second assisting mechanism <b>50</b>, the first assisting mechanism <b>40</b>, or the frame <b>70</b>.</p><p id="p-0038" num="0037">The first collecting module <b>22</b> includes an RGB color camera. The first collecting module <b>22</b> collects the mimicry actions of the user. The first collecting module <b>22</b> can capture videos, capture images, and collect sound around the user. When collecting the sound, the processor <b>10</b> can eliminate noise after comparing the sound for voice recognizing and locating a sound source. The videos captured by the first collecting module <b>22</b> can be stored, which is convenient to the remote doctors or physiotherapist for checking the rehabilitation state of the user and guiding the user to mime the rehabilitation actions. The second collecting module <b>24</b> includes an infrared emitter and an infrared 3D structure light range sensor, the second collecting module <b>24</b> collects the user appearance features and environment information. The environment information can include a distance between the user and the second collecting module <b>24</b> and a position of the user. The third collecting module <b>26</b> can be a body temperature sensor, a heart rate sensor, and the like, not being limited. The third collecting module <b>26</b> collects the physiological data of the user. The third collecting module <b>26</b> can be a wearable device, such as a bracelet, which is communicating with the processor <b>10</b> for collecting the physiological data of the user.</p><p id="p-0039" num="0038">In one embodiment, the VR rehabilitation apparatus <b>100</b> further includes a communication module <b>60</b>. The communication module <b>60</b> connects with the processor <b>10</b>. The communication module <b>60</b> establishes a communication with an assisting authority. The communication module <b>60</b> can connect with an electronic device through a wireless manner, a BLUETOOTH manner, or a wired manner. The electronic device can include a specified application to connect with the communication module <b>60</b>. The user communicates with the assisting authority through the communication module <b>60</b> and is able to make a video call or a voice call with the assisting authority.</p><p id="p-0040" num="0039">The processor further controls the displaying mechanism <b>30</b> to display the information of the assisting authority. The information of the assisting authority can include a video information, a sound information, an operation instruction information generated by the assisting authority, a rehabilitation project, a scene, and resistance parameters selected by the assisting authority, not being limited. The assisting authority can teach the user through the video for miming the rehabilitation actions. The rehabilitation project selected and transmitted by the assisting authority can be displayed in the displaying mechanism <b>30</b> for being viewed by the user. The assisting authority can be a doctor or a physiotherapist, who can help the user to mime the rehabilitation train.</p><p id="p-0041" num="0040">The processor <b>10</b> displays the video information and the sound information of the assisting authority on the displaying mechanism <b>30</b> for being viewed and learned by the user. The user can communicate with the assisting authority in real time. The assisting authority makes a video call with the user for watching the mimicry actions of the user. In one embodiment, the collecting mechanism <b>20</b> collects the mimicry actions of the user and transmits the mimicry actions to the assisting authority through the communication module <b>60</b>. Or, the mimicry actions is packed by the processor <b>10</b>, and the processor <b>10</b> transmits the packed mimicry actions to the assisting authority through the communication module <b>60</b> for watching and considering the mimicry actions of the user.</p><p id="p-0042" num="0041">The processor <b>10</b> further generates a first instruction based on the information of the assisting authority. The assisting authority determines whether the mimicry actions of the user meet a standard. When the mimicry actions meet the standard, the assisting authority can be silent, and the user continues to mime the rehabilitation actions. When the mimicry actions do not meet the standard despite the user re-miming for the specified number of times, and the assisting authority generates instruction information based on the mimicry actions, the processor <b>10</b> generates the first instruction based on the instruction information generated by the assisting authority.</p><p id="p-0043" num="0042">The processor <b>10</b> further controls the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> to assist the user to mime the rehabilitation actions based on the first instruction. In detail, the assisting authority transmits the instruction information when the watched mimicry actions do not meet the standard. The processor <b>10</b> generates the first instruction based on the instruction information and controls the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> to assist the user for miming the rehabilitation actions.</p><p id="p-0044" num="0043">The processor <b>10</b> further can only control the second assisting mechanism <b>50</b> to assist the user for miming the rehabilitation actions.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a VR rehabilitation system <b>200</b>. The VR rehabilitation system <b>100</b> can include one or more program instructions in form of applications stored in a storage medium, which can be executed by a processor to implement the functions of the present disclosure. In one embodiment, the VR rehabilitation system <b>200</b> includes a collecting unit <b>202</b>, a processing unit <b>204</b>, a displaying unit <b>206</b>, and an assisting unit <b>208</b>.</p><p id="p-0046" num="0045">The collecting unit <b>202</b> is configured to collect user information of the user.</p><p id="p-0047" num="0046">In detail, the collecting unit <b>202</b> can be the collecting mechanism <b>20</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The collecting mechanism <b>20</b> includes a first collecting module <b>22</b>, a second collecting module <b>24</b>, and a third collecting module <b>26</b>. The collecting mechanism <b>20</b> is configured to collect the user information and transmit the collected user information to the processing unit <b>204</b>. The user information can include video data, user appearance features, and physiological data, not being limited.</p><p id="p-0048" num="0047">The processing unit <b>204</b> is configured to create a virtual object based on the user information.</p><p id="p-0049" num="0048">In detail, the processing unit <b>204</b> can be the processor <b>10</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The processor <b>10</b> connects with the collecting mechanism <b>20</b>. The processor <b>10</b> creates the virtual object based on the corresponding user information. The virtual object can be a 3D human model or a VR model.</p><p id="p-0050" num="0049">The displaying unit <b>206</b> is configured to display a virtual object.</p><p id="p-0051" num="0050">In detail, the displaying unit <b>206</b> can be the displaying mechanism <b>30</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The displaying mechanism <b>30</b> connects with the processor <b>10</b>. The displaying mechanism <b>30</b> can be a display screen or a projector. The displaying mechanism <b>30</b> can display the virtual object and generate a prompt sound.</p><p id="p-0052" num="0051">The processor unit <b>204</b> is further configured to train the virtual object to move and perform rehabilitation actions.</p><p id="p-0053" num="0052">In detail, the processor <b>10</b> also can train the virtual object to move and perform rehabilitation actions. The processor <b>10</b> trains the virtual object, thus the virtual object can move and perform the rehabilitation actions to form a rehabilitation video. Thus, the users can exercise according to the rehabilitation actions in the rehabilitation video.</p><p id="p-0054" num="0053">The collecting unit <b>202</b> is further configured to collects mimicry actions acted by the users.</p><p id="p-0055" num="0054">In detail, the collecting mechanism <b>20</b> collects the mimicry actions acted by the users and transmits the collected mimicry actions to the processor <b>10</b>. The user exercises to mime the rehabilitation actions acted by the virtual object for forming the mimicry actions by watching the rehabilitation video. The collecting mechanism <b>20</b> collects the mimicry actions of the user in real time.</p><p id="p-0056" num="0055">The processing unit <b>204</b> is further configured to compare the mimicry actions with the rehabilitation actions to form a comparison result.</p><p id="p-0057" num="0056">In detail, the processor <b>10</b> compares the mimicry actions with the rehabilitation actions to form the comparison result. The processor <b>10</b> compares the mimicry actions collected by the collecting mechanism <b>20</b> with the rehabilitation actions, thus the comparison result is formed.</p><p id="p-0058" num="0057">The assisting unit <b>208</b> is configured to assist the user to mime the rehabilitation actions based on the comparison result.</p><p id="p-0059" num="0058">In detail, the assisting unit <b>208</b> can be the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> connect with the processor <b>10</b>. The processor <b>10</b> further controls the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> to assist the user to mime the rehabilitation actions based on the comparison result.</p><p id="p-0060" num="0059">In one embodiment, the VR rehabilitation system <b>200</b> further includes a communication unit <b>210</b>.</p><p id="p-0061" num="0060">The communication unit <b>210</b> is configured to establish a communication with an assisting authority.</p><p id="p-0062" num="0061">In detail, the communication unit <b>210</b> can be the communication module <b>60</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The communication module <b>60</b> establishes the communication with the assisting authority. The user communicates with the assisting authority through the communication module <b>60</b> and is able to make a video call or a voice call with the assisting authority.</p><p id="p-0063" num="0062">The displaying unit <b>206</b> is further configured to display information of the assisting authority.</p><p id="p-0064" num="0063">In detail, the processor <b>10</b> controls the displaying mechanism <b>30</b> to display the information of the assisting authority.</p><p id="p-0065" num="0064">The processing unit <b>204</b> is further configured to generate a first instruction based on the information of the assisting authority.</p><p id="p-0066" num="0065">In detail, the processor <b>10</b> generates the first instruction based on the information of the assisting authority.</p><p id="p-0067" num="0066">The assisting unit <b>208</b> is further configured to assist the user to mime the rehabilitation actions based on the first instruction.</p><p id="p-0068" num="0067">In detail, the processor <b>10</b> controls the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> to assist the user for miming the rehabilitation actions based on the first instruction. When the mimicry actions watched by the assisting authority through the communication module <b>60</b> do not meet the standard, the assisting authority generates instruction information based on the mimicry actions, the processor <b>10</b> generates the first instruction based on the instruction information generate by the assisting authority. The processor <b>10</b> controls the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> to assist the user for miming the rehabilitation actions based on the first instruction.</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a flowchart of a method for improving rehabilitation effect. Due to different requirements, a sequence of steps in the flowchart diagram can be changed, and some steps can be omitted. The method includes the following steps, these steps may be re-ordered:</p><p id="p-0070" num="0069">In block S<b>1</b>, user information is collected.</p><p id="p-0071" num="0070">In detail, the user information is collected by collecting unit <b>202</b>. The collecting unit <b>202</b> can be the collecting mechanism <b>20</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The collecting mechanism <b>20</b> is configured to collect the user information and transmit the collected user information to the processor <b>10</b>. The user information can include video data, user appearance features, and physiological data, not being limited.</p><p id="p-0072" num="0071">In block S<b>3</b>, a virtual object is created based on the user information.</p><p id="p-0073" num="0072">In detail, the processing unit <b>204</b> creates the virtual object based on the user information. The processing unit <b>204</b> can be the processor <b>10</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The processor <b>10</b> connects with the collecting mechanism <b>20</b>. The processor <b>10</b> creates the virtual object based on the corresponding user information.</p><p id="p-0074" num="0073">In block S<b>5</b>, the virtual object is displayed.</p><p id="p-0075" num="0074">In detail, the virtual object is displayed on the displaying unit <b>206</b>. The displaying unit <b>206</b> can be the displaying mechanism <b>30</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The displaying mechanism <b>30</b> connects with the processor <b>10</b>. The displaying mechanism <b>30</b> can be a display screen or a projector. The displaying mechanism <b>30</b> can display the virtual object and generate a prompt sound.</p><p id="p-0076" num="0075">In block S<b>7</b>, the virtual object is trained to move and perform rehabilitation actions.</p><p id="p-0077" num="0076">In detail, the virtual object is trained by the processing unit <b>204</b>. The processing unit <b>204</b> can be the processor <b>10</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The processor <b>10</b> trains the virtual object to move and perform the rehabilitation actions, thus the virtual object can move and perform the rehabilitation actions to form a rehabilitation video. Thus, the users can exercise according to the rehabilitation actions in the rehabilitation video</p><p id="p-0078" num="0077">In block S<b>9</b>, mimicry actions acted by the users are collected.</p><p id="p-0079" num="0078">In detail, the mimicry actions acted by the users are collected by the collecting unit <b>202</b>. The collecting unit <b>202</b> can be the collecting mechanism <b>20</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The collecting mechanism <b>20</b> collects the mimicry actions acted by the users and transmits the collected mimicry actions to the processor <b>10</b>. The user exercises to mime the rehabilitation actions acted by the virtual object for forming the mimicry actions by watching the rehabilitation video. The collecting mechanism <b>20</b> collects the mimicry actions of the user in real time.</p><p id="p-0080" num="0079">In block S<b>11</b>, the mimicry actions are compared with the rehabilitation actions to form a comparison result.</p><p id="p-0081" num="0080">In detail, the mimicry actions are compared with the rehabilitation actions to form the comparison result by the processing unit <b>204</b>. The processing unit <b>204</b> can be the processor <b>10</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The processor <b>10</b> compares the mimicry actions collected by the collecting mechanism <b>20</b> with the rehabilitation actions, thus the comparison result is formed. The comparison result can be displayed on the virtual object.</p><p id="p-0082" num="0081">In block S<b>13</b>, the user is assisted to mime the rehabilitation actions based on the comparison result.</p><p id="p-0083" num="0082">In detail, the user is assisted by the assisting unit <b>208</b> to mime the rehabilitation actions based on the comparison result. The assisting unit <b>208</b> can be the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> connect with the processor <b>10</b>. The processor <b>10</b> further controls the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> to assist the user to mime the rehabilitation actions based on the comparison result.</p><p id="p-0084" num="0083">In one embodiment, after the step of the block S<b>1</b>, the method further includes:</p><p id="p-0085" num="0084">In block S<b>2</b>, a communication with assisting authority is established.</p><p id="p-0086" num="0085">In detail, the communication with the assisting authority is established by the communication unit <b>210</b>. The communication unit <b>210</b> can be the communication module <b>60</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The communication module <b>60</b> establishes the communication with the assisting authority. The user communicates with the assisting authority through the communication module <b>60</b> and is able to make a video call or a voice call with the assisting authority.</p><p id="p-0087" num="0086">In block S<b>4</b>, information of the assisting authority is displayed.</p><p id="p-0088" num="0087">In detail, the information of the assisting authority is displayed by the displaying unit <b>206</b>. The processor <b>10</b> controls the displaying mechanism <b>30</b> to display the information of the assisting authority. The information of the assisting authority can include a video information of the assisting authority, a sound information of the assisting authority, an operation instruction information generated by the assisting authority, a rehabilitation project, a scene, and resistance parameters selected by the assisting authority, not being limited. The assisting authority can be a doctor or a physiotherapist, who can help the user to move and perform the rehabilitation train. The processor <b>10</b> displays the video information and the sound information of the assisting authority on the displaying mechanism <b>30</b> for being viewed and learned by the user. The user can communicate with the assisting authority in real time. The assisting authority makes a video call with the user for watching the mimicry actions of the user.</p><p id="p-0089" num="0088">In block S<b>6</b>, a first instruction is generated based on the information of the assisting authority.</p><p id="p-0090" num="0089">In detail, the first instruction is generated by the processing unit <b>204</b> based on the information of the assisting authority. The assisting authority determines whether the mimicry actions of the user meet a standard. When the mimicry actions meet the standard, the assisting authority can be silent, and the user continues to mime the rehabilitation actions. When the mimicry actions do not meet the standard, the user re-mimes for the specified number of times, and the assisting authority generates instruction information based on the mimicry actions, the processor <b>10</b> generates the first instruction based on the instruction information generate by the assisting authority.</p><p id="p-0091" num="0090">In block S<b>8</b>, the rehabilitation actions are mimed by the user based on the first instruction.</p><p id="p-0092" num="0091">In detail, the user mimes the rehabilitation actions being assisting by the assisting unit <b>208</b> based on the first instruction. The assisting authority transmits the instruction information when the watched mimicry actions do not meet the standard. The processor <b>10</b> generates the first instruction based on the instruction information and controls the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> to assist the user for miming the rehabilitation actions.</p><p id="p-0093" num="0092">A computer readable storage medium is provided in the present disclosure. The computer readable storage medium stores program codes, which can be executed by a processor to implement the above method for improving rehabilitation effect.</p><p id="p-0094" num="0093">Based on the VR rehabilitation apparatus <b>100</b>, the VR rehabilitation system <b>200</b>, and the method for improving rehabilitation effect, the processor <b>10</b>, the collecting mechanism <b>20</b>, the displaying mechanism <b>30</b>, the first assisting mechanism, the second assisting mechanism <b>50</b>, and the communication module <b>60</b> are set for assisting the user to mime the rehabilitation actions at home without going to the hospital or the rehabilitation place. The displaying mechanism <b>30</b> displays the virtual object. The user can watch the virtual object to directly confirm own gesture and the mimicry actions for improving rehabilitation effect while using the VR rehabilitation apparatus <b>100</b>. A psychological burden generated by the physical disabilities is decreased, and a confidence of the user can be improved. The collecting mechanism <b>20</b>, the processor <b>10</b>, the first assisting mechanism <b>40</b>, and the second assisting mechanism <b>50</b> cooperate with each other for ensuring the user to correctly mime the rehabilitation actions acted by the virtual object. The processor <b>10</b> compares the mimicry actions with the rehabilitation actions and controls the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b> to assist the user. Without the physiotherapist, the user also can correctly mime the rehabilitation actions by the assisted of the first assisting mechanism <b>40</b> and/or the second assisting mechanism <b>50</b>. A correction of the mimicry actions and an exercise time and an intensity are ensured for recovering a body function.</p><p id="p-0095" num="0094">The descriptions of the various embodiments of the present invention have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments. The terminology used herein was chosen to best explain the principles of the embodiments, the practical application or technical improvement over technologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A virtual reality (VR) rehabilitation apparatus comprises:<claim-text>a processor connected with a collecting mechanism, a displaying mechanism, and a first assisting mechanism; and</claim-text><claim-text>the connecting mechanism configured to collect user information of an user, wherein:</claim-text><claim-text>the processor creates a virtual object based on the user information, controls the displaying mechanism to display the virtual object, and trains the virtual object to move and perform rehabilitation actions,</claim-text><claim-text>the collecting mechanism further collects mimicry actions acted while the user mimes the rehabilitation actions,</claim-text><claim-text>the processor compares the mimicry actions with the rehabilitation actions to form a comparison result, and</claim-text><claim-text>the processor controls the first assisting mechanism to assist the user based on the comparison result for correctly acting the rehabilitation actions.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The VR rehabilitation apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a frame, wherein:</claim-text><claim-text>the processor is disposed in the frame;</claim-text><claim-text>the collecting mechanism is disposed inside or outside the frame;</claim-text><claim-text>the displaying mechanism is disposed in the frame;</claim-text><claim-text>the first assisting mechanism is slidably disposed on the frame; and</claim-text><claim-text>the user information comprises video data, user appearance features, and physiological data.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The VR rehabilitation apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein:<claim-text>two first assisting mechanisms are slidably disposed on the frame;</claim-text><claim-text>each of the two first assisting mechanisms comprises a first driving module, a first arm, a second driving module, and a first assisting module;</claim-text><claim-text>the first driving module is slidably disposed on one of the sliding rails;</claim-text><claim-text>the first arm connects with the first driving module;</claim-text><claim-text>the first driving module drives the first arm to move in a specified range;</claim-text><claim-text>the second driving module is disposed on the first arm;</claim-text><claim-text>the first assisting module is on an end of the first arm away from the first driving module; and</claim-text><claim-text>the second driving module drives the first assisting module to assist the user to mime the mimicry actions.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The VR rehabilitation apparatus of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein:<claim-text>the second driving module comprises an electromagnetic driving component;</claim-text><claim-text>the first assisting module comprises a rotating component, an adjusting component, and an assisting component;</claim-text><claim-text>the adjusting component rolls on the rotating component;</claim-text><claim-text>the assisting component is disposed on an end of the adjusting component away from the rotating component; and</claim-text><claim-text>the second driving module connects with the rotating component for driving the rotating component to rotate and driving the adjusting component to move along a specified direction to assist the user to mime the mimicry actions.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The VR rehabilitation apparatus of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein:<claim-text>the first assisting mechanism comprises a second arm, a third driving module, and a second assisting module;</claim-text><claim-text>the second arm is slidably disposed on an end of the first arm away from the first driving module;</claim-text><claim-text>the third driving module is disposed on the first arm and the second arm;</claim-text><claim-text>the second assisting module is disposed on an end of the second arm away from the first arm; and</claim-text><claim-text>the third driving module drives the second assisting module to cooperated with the first assisting module for assisting the user to mime the rehabilitation actions.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The VR rehabilitation apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:<claim-text>a second assisting mechanism, wherein:</claim-text><claim-text>the second assisting mechanism is disposed outside the frame; and</claim-text><claim-text>the second assisting mechanism loads the user and assists the user to mime the rehabilitation actions.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The VR rehabilitation apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:<claim-text>a first collecting module;</claim-text><claim-text>a second collecting module; and</claim-text><claim-text>a third collecting module, wherein:</claim-text><claim-text>the first collecting module, the second collecting module, and the third collecting module are disposed inside the frame or outside the frame,</claim-text><claim-text>the first collecting module collects the mimicry actions of the user,</claim-text><claim-text>the second collecting module collects user appearance features and environment information, and</claim-text><claim-text>the third collecting module collects the physiological data of the user.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The VR rehabilitation apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>a communication module connected with the processor;</claim-text><claim-text>the communication module establishes a communication with an assisting authority; and</claim-text><claim-text>the processor further controls the displaying mechanism to display information of the assisting authority, generates a first instruction based on the information of the assisting authority, and controls the first assisting mechanism to mime the rehabilitation actions based on the first instruction.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A virtual reality (VR) rehabilitation system comprises a non-transitory storage medium with program codes, which when being executed by a processor, cause the processor to:<claim-text>collect user information of an user;</claim-text><claim-text>create a virtual object based on the user information;</claim-text><claim-text>display the virtual object;</claim-text><claim-text>train the virtual object to move and perform rehabilitation actions;</claim-text><claim-text>collect mimicry actions acted by the user while miming the rehabilitation actions;</claim-text><claim-text>compare the mimicry actions with the rehabilitation actions to form a comparison result; and</claim-text><claim-text>assist the user to correctly mime the rehabilitation actions based on the comparison result.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The VR rehabilitation system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein, the processor further performs:<claim-text>establish a communication with an assisting authority;</claim-text><claim-text>display information of the assisting authority;</claim-text><claim-text>generate a first instruction based on the information of the assisting authority; and</claim-text><claim-text>assist the user to correctly mime the rehabilitation actions based on the first instruction.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The VR rehabilitation system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the user information comprises video data, user appearance features, and physiological data.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The VR rehabilitation system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the comparison result is displayed on the virtual object.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The VR rehabilitation system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein when the mimicry actions are similar or equal to the rehabilitation actions, the rehabilitation actions acted by the virtual object are displayed in green for indicating correctness of the mimicry actions.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The VR rehabilitation system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein when there is a difference between the mimicry actions and the rehabilitation actions, the rehabilitation actions acted by the virtual object are displayed in yellow for indicating incorrectness of the mimicry actions.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A method used in a VR rehabilitation apparatus; the VR rehabilitation comprises a storage medium with program codes, the program codes are executed by at least one processor to implement the following steps:<claim-text>collecting user information of an user;</claim-text><claim-text>creating a virtual object based on the user information;</claim-text><claim-text>displaying the virtual object;</claim-text><claim-text>training the virtual object to move and perform rehabilitation actions;</claim-text><claim-text>collecting mimicry actions acted by the user while miming the rehabilitation actions;</claim-text><claim-text>comparing the mimicry actions with the rehabilitation actions to form a comparison result; and</claim-text><claim-text>assisting the user to correctly mime the rehabilitation actions based on the comparison result.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the method further comprising:<claim-text>establishing a communication with an assisting authority;</claim-text><claim-text>displaying information of the assisting authority;</claim-text><claim-text>generating a first instruction based on the information of the assisting authority; and</claim-text><claim-text>assisting the user to correctly mime the rehabilitation actions based on the first instruction.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the user information comprises video data, user appearance features, and physiological data.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the comparison result is displayed on the virtual object.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein when the mimicry actions are similar or equal to the rehabilitation actions, the rehabilitation actions acted by the virtual object are displayed in green for indicating correctness of the mimicry actions.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein when there is a difference between the mimicry actions and the rehabilitation actions, the rehabilitation actions acted by the virtual object are displayed in yellow for indicating incorrectness of the mimicry actions.</claim-text></claim></claims></us-patent-application>
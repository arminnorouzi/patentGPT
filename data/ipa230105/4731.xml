<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004732A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004732</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17944956</doc-number><date>20220914</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20200101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>58</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20200101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>284</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20200101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>166</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20190101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>31</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20200101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>51</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20200101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>216</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20190101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>34</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20120101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>58</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>284</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>166</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>313</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>51</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>216</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>345</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>101</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>10</main-group><subgroup>103</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Systems and Methods for Intelligent Routing of Source Content for Translation Services</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17077994</doc-number><date>20201022</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11475227</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17944956</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16226419</doc-number><date>20181219</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>10817676</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17077994</doc-number></document-id></child-doc></relation></continuation><us-provisional-application><document-id><country>US</country><doc-number>62610591</doc-number><date>20171227</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SDL Inc.</orgname><address><city>Wakefield</city><state>MA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Vlad</last-name><first-name>Mihai</first-name><address><city>London</city><country>GB</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Echihabi</last-name><first-name>Abdessamad</first-name><address><city>Los Angeles</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A source content routing system is described for distributing source content received from clients such as documents, to translators for performing translation services on the source content. The routing system extracts source content features, which may be represented as vectors. The vectors may be assembled into an input matrix, which may be processed using an artificial neural network, classifier, perceptron, CRF model, and/or the like, to select a translator such as a machine translation system and/or human. The translator provides translation services translation from a source language to a target language, post translation editing, proof reading, quality analysis of a machine, quality analysis of human translation, and/or the like and returns the product to the content routing system or clients.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="87.97mm" wi="158.75mm" file="US20230004732A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="239.01mm" wi="164.17mm" file="US20230004732A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="135.97mm" wi="160.78mm" file="US20230004732A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="164.51mm" wi="114.55mm" file="US20230004732A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="222.08mm" wi="154.69mm" file="US20230004732A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a continuation of U.S. patent application Ser. No. 17/077,994, filed on Oct. 22, 2020 and titled &#x201c;Intelligent Routing Services and Systems,&#x201d; which is a continuation of U.S. patent application Ser. No. 16/226,419, filed on Dec. 19, 2018 and titled &#x201c;Intelligent Routing Services and Systems,&#x201d; which claims priority and benefit to U.S. provisional patent application Ser. No. 62/610,591 filed on Dec. 27, 2017 and titled &#x201c;Intelligent Routing Services and Systems,&#x201d; which are all incorporated by reference herein in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE PRESENT TECHNOLOGY</heading><p id="p-0003" num="0002">The present disclosure relates to the technical field of machine translation systems and methods. More particularly, the present invention is in the technical field of distribution of documents between machine translators, human translators, and post translation editors.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">The translation process in a typical language service provider is orchestrated by a human Project Manager who collects requests from customers or prospects. The project manager then analyzes content of the source documents to price the work. The project manage then makes a decision based on personal experience and knowledge of available translators on how best distribute the source documents to the translators. The project manager is also responsible for ensuring delivery of the completed work back to the customer. Currently, tools do not exist for equipping project managers to make fast and accurate decisions.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">Various embodiments of the present technology include a hardware solution for a way of improving the routing of source content such as documents to translators for translation services. The present technology improves on a human selection of a translator manually based personal experience with known translators and a cursory read of a source document to develop an impression of the content. Instead, the claimed technology provides a way of selecting of routing a document that includes performing a stochastic analysis of the source content to extract source content feature and generate vectors from the extracted features. These feature vectors may then be assembled into an input matrix representing source content features. A router may use an artificial neural network including hidden layers along with weight matrixes representing connections between layers and a target matrix representing translators for processing the input matrix to select a translator, and may transfer the document to the selected translator for translation services.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0006" num="0005">Certain embodiments of the present technology are illustrated by the accompanying figures. It will be understood that the figures are not necessarily to scale and that details not necessary for an understanding of the technology or that render other details difficult to perceive may be omitted. It will be understood that the technology is not necessarily limited to the particular embodiments illustrated herein.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an environment for routing documents to translators, in accordance with aspects of the technology.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a server for routing source content to translators, in accordance with aspects of the technology.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating exemplary details of the content analyzer of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an algorithm for summarizing source content.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an illustration of a multilayer perceptron.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram of an undirected probabilistic graphical CRF model for entity recognition using CFR.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagrammatic representation of an example machine in the form of a computer system, within which a set of instructions for causing the machine to perform any of one or more of the methodologies discussed herein may be executed.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0014" num="0013">The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the present technology. As used herein, the singular forms &#x201c;a&#x201d;, &#x201c;an&#x201d; and &#x201c;the&#x201d; are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms &#x201c;comprises&#x201d; and/or &#x201c;comprising,&#x201d; when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more of the same or other features, integers, steps, operations, elements, components, and/or groups thereof.</p><p id="p-0015" num="0014">It will be understood that like or analogous elements and/or components referred to herein may be identified throughout the drawings with like reference characters. It will be further understood that several of the figures are merely schematic representations and/or block diagrams of the present technology. As such, some of the components may have been distorted from their actual scale for pictorial clarity.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating an environment <b>100</b> for routing documents to translators. The environment <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> includes a network <b>110</b>, a content distribution server <b>112</b>, source content <b>102</b>, profiles of a plurality of translators (translators profiles <b>104</b>), a job profile <b>106</b>, and a plurality of translators 1-N, i.e., translators <b>116</b>. The content distribution server <b>112</b> is a special purpose computer system configured specifically to receive source content <b>102</b> and route the source content <b>102</b> to one or more of the plurality of translators <b>116</b>. In some embodiments, the content distribution server <b>112</b> is configured to receive source content <b>102</b> via a network <b>110</b>. The server may also receive translator profiles <b>104</b>, and a job profile <b>106</b> via the network <b>110</b>. The content distribution server <b>112</b> may route the source content <b>102</b> to one or more translators <b>116</b> via the network <b>110</b> based on an analysis of the source content <b>102</b>, the translator profiles <b>104</b>, and the job profile.</p><p id="p-0017" num="0016">In various embodiments, translation services include translation from a source language to a target language, post translation editing, proof reading, quality analysis of a machine, quality analysis of human translation, and/or the like. Translators <b>116</b> include machine translation systems, human translators using machine-assisted translation platforms, interactive adaptive machine translations systems, and/or the like.</p><p id="p-0018" num="0017">In various embodiments, the source content <b>102</b> includes text, a document, a batch of documents, or a portion of a document. Documents include various combinations of text, images, graphs, drawings, videos, audio, animation, media, web pages, links to web pages, web objects, and/or the like.</p><p id="p-0019" num="0018">The translator profiles include information about translators <b>116</b>, such as previous work content, quality, speed, schedule, time zone, target language skills (speed, quality, etc.) for one or more target languages, post editing skills (speed, quality, etc.), domain skills for one or more domains, source content in progress, and/or the like. Additional information about the translators <b>116</b> includes previous association of a translator with the type of document the job requires (e.g., familiarity with a document may enhance the speed of delivery and consistency); domain preference (e.g., efficiency within a domain); association with a document or similar document; translator native language. Translator quality features include overall quality/rating, translator quality/rating on a given domain/content type, translator experience/qualification, reliability and consistency, translator workload, translator availability, translator preference (comfortable with MT Post Editing). The translators profiles <b>104</b> may include information about all the translators <b>116</b> or some of the translators <b>116</b>. In some embodiment the translators profiles <b>104</b> include information about translators that are not included in the translators <b>116</b>.</p><p id="p-0020" num="0019">In various embodiments the job profile <b>106</b> includes information about how the job is to be processed, such as target language, cost, margin, time, deadlines, desired quality, translation, post translation editing, inspection, and/or the like.</p><p id="p-0021" num="0020">The content distribution server <b>112</b> may route the entire source content <b>102</b> to a single translator <b>116</b>, or a portion of the source content <b>102</b> may be routed to the single translator <b>116</b>. In some embodiments the source content <b>102</b> is separated into portions of the content are routed multiple translators <b>116</b>. For example, source content <b>102</b> may include a batch of documents, and the documents may be routed to translators <b>116</b> such that part of the documents are routed to a machine translation system, part of the documents are routed to a first human translator <b>116</b>, part to a second human translator <b>116</b>, and so on.</p><p id="p-0022" num="0021">It may be appreciated that one or more of the source content <b>102</b>, translators profiles <b>104</b>, and/or the job profile <b>106</b> may be communicated directly to the content distribution server <b>112</b> or may be generated at the content distribution server <b>112</b>. It may be further appreciated that one or more translators 1-N(translators <b>116</b>) may be in direct communication with the content distribution server <b>112</b>. In some embodiments, one or more translators <b>116</b> are a part of the content distribution server <b>112</b>, for example, in the case of a translator that includes machine translation services. The content distribution server <b>112</b> may route the source content <b>102</b> directly to one or more of the translators <b>116</b>.</p><p id="p-0023" num="0022">In some embodiments one or more of the network <b>110</b>, content distribution server <b>112</b>, source content <b>102</b>, translators profiles <b>104</b>, job profiles <b>106</b>, and a plurality of translators <b>116</b> (e.g., machine translator systems) <figref idref="DRAWINGS">FIG. <b>1</b></figref> are implemented within a cloud-based computing environment (not illustrated) In general, a cloud-based computing environment is a resource that typically combines the computational power of a large model of processors and/or that combines the storage capacity of a large model of computer memories or storage devices. For example, systems that provide a cloud resource may be utilized exclusively by their owners; or such systems may be accessible to outside users who deploy applications within the computing infrastructure to obtain the benefit of large computational or storage resources.</p><p id="p-0024" num="0023">A cloud based environment may be formed, for example, by a network of servers, with each server (or at least a plurality thereof) providing processor and/or storage resources. These servers may manage workloads provided by multiple users (e.g., cloud resource consumers or other users). Typically, each user places workload demands upon the cloud that vary in real-time, sometimes dramatically. The nature and extent of these variations typically depend on the type of business associated with the user.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating exemplary details of a content distribution server <b>112</b> for routing the source content <b>102</b> to the translators <b>116</b>. As discussed elsewhere herein, the content distribution server <b>112</b> is a special purpose computer system that includes specific components for accomplishing special tasks. The content distribution server <b>112</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes a content analyzer <b>200</b>, source content features <b>202</b>, translators features <b>204</b>, job features <b>206</b>, and a router <b>210</b>. The content analyzer <b>200</b> is configured to extract source content features <b>202</b> from the source content <b>102</b>. In various embodiments, the source content features <b>202</b> include a summary of the source content <b>102</b>, keywords in the source content <b>102</b>, key-phrases in the source content <b>102</b>, one or more domains identified as being related to the source content <b>102</b>, one or more entities being recognized as a source of the source content <b>102</b>, a complexity of the source content <b>102</b>, a suitability of the source content <b>102</b> for machine translation, and/or the like. Each of the source content features <b>202</b> may be represented as a vector of the features (content feature vector). In various embodiments, content feature vectors include a summary vector, keywords and key-phrases vector, domains vector, entities vector, complexity vector, and MT suitability vector. In some embodiments, the source content features <b>202</b> are represented as a matrix. Each of the content feature vectors (summary vector, keywords and key-phrases vector, domains vector, entities vector, complexity vector, and MT suitability vector) may be used as a column or row of the matrix.</p><p id="p-0026" num="0025">The translators features <b>204</b> may be extracted from the translators profiles <b>104</b> at the content distribution server <b>112</b>. In some embodiments, the translators features <b>204</b> are generated at the translators profiles <b>104</b> and then received from the translators profiles <b>104</b>. In various embodiments, the translators features <b>204</b> include previous work content, quality, speed, schedule, time zone, target language skills (speed, quality, etc.) for one or more target languages, post editing skills (speed, quality, etc.), domain skills for one or more domains, source content <b>102</b> in progress, and/or the like. The translators features <b>204</b> may be represented as a vector of the features (translator feature vector). In various embodiments, the translator feature vectors represent the previous work content, quality, speed, schedule, time zone, target language skills, post editing skills, domain skills, load, etc. Each of a plurality of translators may be represented by a translator feature vector. The translators features <b>204</b> may include a plurality of translator feature vectors, one for each of a plurality of translators. In some embodiments, the translators features <b>204</b> are represented as a matrix. Each of the translator feature vectors may be used as a column or row of the matrix.</p><p id="p-0027" num="0026">The job features <b>206</b> may be extracted from the job profile <b>106</b> at the content distribution server <b>112</b>. In some embodiments, the job features are generated at the job profile <b>106</b> and then received from the job profile <b>106</b>. In various embodiments, the job features <b>206</b> include job information, such as cost, margin, time, quality, target language, and/or the like. The job features <b>206</b> may be represented as a vector of the features such as the cost, margin, time, quality, target language, etc.</p><p id="p-0028" num="0027">The router <b>210</b> is configured to select translators and route content to the translators. The router <b>210</b> may receive the source content features <b>202</b>, the translators features <b>204</b>, and the job features <b>206</b> as input. The router may select one or more translators <b>116</b> based on the source content features <b>202</b>, translators features <b>204</b>, and job features <b>206</b>. The source content features <b>202</b> may be received as a matrix or as one or more vectors. Similarly, the translators features <b>204</b> and/or the job features <b>206</b> may be received as a matrix or one or more vectors. In some embodiments, the router <b>210</b> is a special purpose processor for using the source content features <b>202</b> in conjunction with translators features <b>204</b> and the job features <b>206</b> for selecting a translator <b>116</b> and routing the source content <b>102</b> to the selected translator <b>116</b>. The source content <b>102</b> may be divided into a plurality of portions. The router <b>210</b> may select a plurality of translators <b>116</b> and one or more portions of the source content <b>102</b> may be routed to each of the selected translators <b>116</b>.</p><p id="p-0029" num="0028">While the content analyzer <b>200</b>, source content features <b>202</b>, translators features <b>204</b>, job features <b>206</b>, and router <b>210</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> are illustrated as being components of a content distribution server <b>112</b>, any combination of one or more of these components may be disposed in a standalone computer system, a mobile device, a cloud-based computing environment, and/or the like. For example, the content analyzer <b>200</b> and source content features <b>202</b> may be components of the source content <b>102</b>. Similarly the translator features <b>204</b> may be component of the translators profiles <b>104</b> and/or a job features <b>206</b> may be a component of the job profile <b>106</b>. While the content distribution server <b>112</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> is illustrated as including the content analyzer <b>200</b>, source content features <b>202</b>, translators features <b>204</b>, job features <b>206</b>, and router <b>210</b>, more or fewer components may be included in the content distribution server <b>112</b>. For example, the content distribution server <b>112</b> may include a machine translation system.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating exemplary details of the content analyzer <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The content analyzer <b>200</b> includes means for extracting source content features <b>202</b> represented by vectors from the source content <b>102</b>. The content analyzer <b>200</b> is a special purpose computer system configured specifically to receive source content <b>102</b>, extract source content features <b>202</b> from the received source content <b>102</b>, and generate vectors representing the extracted source content features <b>202</b>. The content analyzer <b>200</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> includes a summarization module <b>302</b>, a keywords and key-phrases module <b>304</b>, a domains module <b>306</b>, an entities module <b>308</b>, a complexity module <b>310</b>, and a machine translation suitability module <b>312</b>. More or fewer modules may be included in the content analyzer <b>200</b>.</p><p id="p-0031" num="0030">The summarization module <b>302</b> includes a means for extracting sentences from the source content <b>102</b>. The extracted sentences may be represented in the form of vectors for use as source content features <b>202</b>. The summary features may comprise vector representations of sentences selected from the source content <b>102</b>. The summarization module <b>302</b> may use a centroid based approach that includes neural vector representations of text segments.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an algorithm for summarizing source content <b>102</b>. At <b>410</b> each sentence in the source text may be encoded into a vector representation. At step <b>420</b>, a centroid vector may be computed as a sum of the sentence vector representations encoded in step <b>410</b>. At step <b>430</b>, sentences with highest cosine similarity to the centroid vector may be selected for inclusion in summary. The summary features may comprise vector representations of the selected sentences. Persons having ordinary skill in the relevant arts would understand with the present application before them how to use a special purpose computer module to encode sentence text as vector representations, compute centroid vectors from sentence vector representations and determining cosine similarity between sentences, and centroid vectors for use as source content features <b>202</b>.</p><p id="p-0033" num="0032">The keywords and key-phrases module <b>304</b> includes means for extracting keywords and key-phrases from the source content <b>102</b>. The extracted keywords and key-phrases may be represented in the form of vectors for use as source content features <b>202</b>. An example of means for extracting keywords and/or key-phrases is nonparametric spherical topic modeling of the source content <b>102</b> with word embeddings for extracting keywords and/or key-phrases. Another example is non-parametric latent Dirichlet analysis of the source content <b>102</b>, for example a hierarchical Dirichlet process mixture model, which allows the number of keywords and/or key-phrases for topics to be unbounded and learned from data. Yet another example is classifying the source content <b>102</b> using numerical statistical analysis including term frequency&#x2014;inverse document frequency (Tf-Idf), for example, to calculate the importance of words and/or word phrases in the source content <b>102</b> and rank the words and phrases. The keyword and key-phrase features may comprise vector representations of key words and key-phrases. Persons having ordinary skill in the relevant arts would understand with the present application before them how to construct and use a special purpose computer module to extract keywords and key-phrases using techniques such as nonparametric spherical topic modeling with word embeddings, non-parametric latent Dirichlet analysis, and Tf-Idf technologies applied to source content <b>102</b>. Persons having ordinary skill in the relevant arts would understand with the present application before them how to generate a vector representation of a plurality of keywords and/or key-phrases for use as a source content feature <b>202</b>.</p><p id="p-0034" num="0033">The domain identification module <b>306</b> includes means for identifying one or more domain of source content <b>102</b>. The identified domains may be represented in the form of vectors for use as source content features <b>202</b>. In various embodiments the means includes a multilayer perceptron, a Term Frequency, an Inverse Document Frequency, and a weighted bag of words to generate a domain feature vector. The domain feature vector may include values representing one or more domains that the source content <b>102</b> is related to.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an illustration of a multilayer perceptron <b>500</b>. The multilayer perceptron <b>500</b> of <figref idref="DRAWINGS">FIG. <b>5</b></figref> includes as inputs the source content <b>102</b> and as output the domain feature vector <b>506</b>. The domain feature vector <b>506</b> may include an array of one or more values. Each value may represent a score or probability that the source content <b>102</b> is related to a specific domain. In various embodiments, the hidden layers <b>504</b> include a weighted bag of words layer, TF layer, IDF layer, and/or the like. Persons having ordinary skill in the relevant arts would understand with the present application before them how to use a special purpose computer module to identify one or more domains for the source content <b>102</b> using various combinations of multilayer perceptron <b>500</b> and hidden layers <b>504</b> including TF, layers, IDF layers, weighted bag of words layers, and/or like technologies, to generate domain feature vectors for use as source content features <b>202</b>.</p><p id="p-0036" num="0035">The entity recognition module <b>308</b> includes means for recognizing named entities in source content <b>102</b>. The named entities may be represented in the form of vectors for use as source content features <b>202</b>. In various embodiments the means includes Conditional Random Field model (CFR) and entity recognition technology. CRFs are a type of discriminative undirected probabilistic graphical model. CRF's may be used to encode known relationships between observations and construct consistent interpretations. CRF's are often used for labeling or parsing of sequential data, such as natural language processing. Specifically, CRFs find applications in named entity recognition. Entity recognition (also known as named entity recognition(NER), entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities occurring in unstructured text, into pre-defined categories such as the person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc. The entity feature vector includes values representing one or more categories of entities that occur in the source content <b>102</b>.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram <b>600</b> of an undirected probabilistic graphical CRF model for entity recognition using CFR. The diagram <b>600</b> includes as inputs the source content <b>102</b>, which may encode relationships between the source content <b>102</b> and sequential data including as observation data in the form of an entity feature vector <b>602</b>. The entity feature vector <b>602</b> may include an array of one or more values. Each value may represent a score or probability that an entity has been recognized or identified in the source content <b>102</b>. In some embodiments, encoding relationships between the source content <b>102</b> and the entity feature vector <b>602</b> includes hand crafting the relationships. Persons having ordinary skill in the relevant arts would understand with the present application before them how to use a special purpose computer module to recognize or identify one or more entities in the source content <b>102</b> using CFR applied to recognition technologies, to generate entity feature vectors for use as source content features <b>202</b>.</p><p id="p-0038" num="0037">The complexity module <b>310</b> includes means for calculating complexity of the source content <b>102</b>. The calculated complexity may be represented in the form of vectors for use as source content features <b>202</b>. In various embodiments the means for calculating complexity of the source content <b>102</b> include means for calculating syntactic complexity, lexical complexity, uber index complexity, Flesch Kincade complexity score, and overall complexity, of the source content <b>102</b>.</p><p id="p-0039" num="0038">Syntactic complexity may be calculated from various combinations of a part of speech ratio, constituency tree depth ration and constituent ratio.</p><p id="p-0040" num="0039">Lexical complexity (sometimes referred to as lexical richness) may be calculated for the source content <b>102</b>, for example using a Herdan ratio:</p><p id="p-0041" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mi>TTR</mi>  <mo>=</mo>  <mfrac>   <mi>V</mi>   <mi>N</mi>  </mfrac> </mrow></math></maths></p><p id="p-0042" num="0040">where TTR is a type-token ratio, V is vocabulary, and N is text length. A normalized Herdan Index H may also be calculated from:</p><p id="p-0043" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mrow>  <mi>H</mi>  <mo>=</mo>  <mfrac>   <mrow>    <mi>log</mi>    <mo>&#x2062;</mo>    <mi>V</mi>   </mrow>   <mrow>    <mi>log</mi>    <mo>&#x2062;</mo>    <mi>N</mi>   </mrow>  </mfrac> </mrow></math></maths></p><p id="p-0044" num="0041">Examples of modifications of a Herdan index include those proposed by:</p><p id="p-0045" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mi>Guiraud</mi>   </mtd>   <mtd>    <mrow>     <mi>G</mi>     <mo>=</mo>     <mfrac>      <mi>V</mi>      <msqrt>       <mi>N</mi>      </msqrt>     </mfrac>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00003-2" num="00003.2"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>Dugast</mi>     <mo>:</mo>    </mrow>   </mtd>   <mtd>    <mrow>     <mi>D</mi>     <mo>=</mo>     <mfrac>      <mrow>       <mi>log</mi>       <mo>&#x2062;</mo>       <mi>V</mi>      </mrow>      <mrow>       <mi>log</mi>       <mo>&#x2061;</mo>       <mo>(</mo>       <mrow>        <mi>log</mi>        <mo>&#x2062;</mo>        <mi>N</mi>       </mrow>       <mo>)</mo>      </mrow>     </mfrac>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00003-3" num="00003.3"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mi>Brunet</mi>     <mo>:</mo>    </mrow>   </mtd>   <mtd>    <mrow>     <mi>B</mi>     <mo>=</mo>     <msup>      <mi>N</mi>      <mrow>       <mi>V</mi>       <mo>-</mo>       <mi>k</mi>      </mrow>     </msup>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0046" num="0042">An Uber index may be calculated from:</p><p id="p-0047" num="0000"><maths id="MATH-US-00004" num="00004"><math overflow="scroll"> <mrow>  <mi>UberIndex</mi>  <mo>=</mo>  <mfrac>   <msup>    <mrow>     <mo>(</mo>     <mrow>      <mi>log</mi>      <mo>&#x2062;</mo>      <mtext>   </mtext>      <mi>tokens</mi>     </mrow>     <mo>)</mo>    </mrow>    <mn>2</mn>   </msup>   <mrow>    <mrow>     <mi>log</mi>     <mo>&#x2062;</mo>     <mtext>   </mtext>     <mi>tokens</mi>    </mrow>    <mo>-</mo>    <mrow>     <mi>log</mi>     <mo>&#x2062;</mo>     <mtext>   </mtext>     <mi>types</mi>    </mrow>   </mrow>  </mfrac> </mrow></math></maths></p><p id="p-0048" num="0043">A Flesch Kincaid score F (or Flesch reading-ease score) may be calculated from a formula:</p><p id="p-0049" num="0000"><maths id="MATH-US-00005" num="00005"><math overflow="scroll"> <mrow>  <mi>F</mi>  <mo>=</mo>  <mrow>   <mrow>    <mn>2</mn>    <mo>&#x2062;</mo>    <mn>0</mn>    <mo>&#x2062;</mo>    <mrow>     <mn>6</mn>     <mo>.</mo>     <mn>8</mn>    </mrow>    <mo>&#x2062;</mo>    <mn>3</mn>    <mo>&#x2062;</mo>    <mn>5</mn>   </mrow>   <mo>-</mo>   <mrow>    <mrow>     <mn>1</mn>     <mo>.</mo>     <mn>0</mn>    </mrow>    <mo>&#x2062;</mo>    <mn>1</mn>    <mo>&#x2062;</mo>    <mn>5</mn>    <mo>&#x2062;</mo>    <mfrac>     <msub>      <mi>T</mi>      <mi>words</mi>     </msub>     <msub>      <mi>T</mi>      <mi>sentences</mi>     </msub>    </mfrac>   </mrow>   <mo>-</mo>   <mrow>    <mn>8</mn>    <mo>&#x2062;</mo>    <mrow>     <mn>4</mn>     <mo>.</mo>     <mn>6</mn>    </mrow>    <mo>&#x2062;</mo>    <mfrac>     <msub>      <mi>T</mi>      <mi>syllables</mi>     </msub>     <msub>      <mi>T</mi>      <mi>words</mi>     </msub>    </mfrac>   </mrow>  </mrow> </mrow></math></maths></p><p id="p-0050" num="0044">Where &#x201c;T<sub>words</sub>&#x201d; is the total number of words, &#x201c;T<sub>sentencess</sub>&#x201d; is the total number of sentences and &#x201c;T<sub>syllables</sub>&#x201d; is the total number of syllables in the source content <b>102</b>. The meaning of the score F may be indicated by table <b>1</b> below.</p><p id="p-0051" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="49pt" align="center"/><colspec colname="2" colwidth="42pt" align="left"/><colspec colname="3" colwidth="126pt" align="left"/><thead><row><entry namest="1" nameend="3" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry>Score</entry><entry>School level</entry><entry>Notes</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry>100.0-90.0&#x2002;</entry><entry>5th grade</entry><entry>Very easy to read. Easily understood by</entry></row><row><entry/><entry/><entry>an average 11-year-old student.</entry></row><row><entry>90.0-80.0</entry><entry>6th grade</entry><entry>Easy to read. Conversational English</entry></row><row><entry/><entry/><entry>for consumers.</entry></row><row><entry>80.0-70.0</entry><entry>7th grade</entry><entry>Fairly easy to read.</entry></row><row><entry>70.0-60.0</entry><entry>8th &#x26; 9th</entry><entry>Plain English. Easily understood by 13-</entry></row><row><entry/><entry>grade</entry><entry>to 15-year-old students</entry></row><row><entry>60.0-50.0</entry><entry>10th to 12th</entry><entry>Fairly difficult to read.</entry></row><row><entry/><entry>grade</entry></row><row><entry>50.0-30.0</entry><entry>College</entry><entry>Difficult to read.</entry></row><row><entry>30.0-0.0&#x2002;</entry><entry>College</entry><entry>Very difficult to read. Best understood</entry></row><row><entry/><entry>graduate</entry><entry>by university graduates.</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0052" num="0045">The complexity features may comprise vector representations of complexity scores. Persons having ordinary skill in the relevant arts would understand with the present application before them how to construct and use a special purpose computer module to calculate complexity scores for syntactic complexity, lexical complexity, Uber index, FleschKincaid score, and overall complexity using information about the source content <b>102</b> and techniques including POS ratio, Constituency tree depth ration, constituent ratio, vocabulary size, text length, normalized Herdan Index log tokens, log types, total words, total sentences, total syllables applied to source content <b>102</b> to generate complexity vectors for use as source content features <b>202</b>.</p><p id="p-0053" num="0046">The machine translation (MT) suitability module <b>312</b> includes means for calculating machine translation suitability of the source content <b>102</b>. The calculated MT suitability may be represented in the form of vectors for use as source content features <b>202</b>. In various embodiments the means for calculating machine translatability include calculating a MT suitability score where:</p><p id="p-0054" num="0047">T<sub>words </sub>is the total number of words in source content <b>102</b></p><p id="p-0055" num="0048">P=probability of each sentence of source content <b>102</b></p><p id="p-0056" num="0049">Raw LM score per sentence is LM=&#x2212; log(P)</p><p id="p-0057" num="0050">The Document perplexity may be calculated from the relation:</p><p id="p-0058" num="0000"><maths id="MATH-US-00006" num="00006"><math overflow="scroll"> <mrow>  <mi>Perplexity</mi>  <mo>=</mo>  <msup>   <mi>e</mi>   <mfrac>    <mrow>     <munder>      <mo>&#x2211;</mo>      <mi>Sentences</mi>     </munder>     <mi>LM</mi>    </mrow>    <msub>     <mi>T</mi>     <mi>words</mi>    </msub>   </mfrac>  </msup> </mrow></math></maths></p><p id="p-0059" num="0000">The ME suitability score may be calculated as:</p><p id="p-0060" num="0000"><maths id="MATH-US-00007" num="00007"><math overflow="scroll"> <mrow>  <mrow>   <mi>M</mi>   <mo>&#x2062;</mo>   <msub>    <mi>T</mi>    <mi>suitability</mi>   </msub>  </mrow>  <mo>=</mo>  <mrow>   <mi>max</mi>   <mo>&#x2061;</mo>   <mo>(</mo>   <mrow>    <mn>5</mn>    <mo>,</mo>    <mrow>     <mi>min</mi>     <mo>&#x2061;</mo>     <mo>(</mo>     <mrow>      <mrow>       <mn>5</mn>       <mo>-</mo>       <mrow>        <mn>4</mn>        <mo>&#x2062;</mo>        <mfrac>         <mrow>          <mi>Perplexity</mi>          <mo>-</mo>          <mn>10</mn>         </mrow>         <mrow>          <mn>7</mn>          <mo>&#x2062;</mo>          <mn>0</mn>         </mrow>        </mfrac>       </mrow>      </mrow>      <mo>,</mo>      <mn>1</mn>     </mrow>     <mo>)</mo>    </mrow>   </mrow>   <mo>)</mo>  </mrow> </mrow></math></maths></p><p id="p-0061" num="0000">where the scaled document perplexity is calculated using a language model trained on NMT parallel data resources.</p><p id="p-0062" num="0051">The MT suitability features may comprise vector representations of the suitability of the source content <b>102</b> for translation using one or more machine translation technologies. Persons having ordinary skill in the relevant arts would understand with the present application before them how to construct and use a special purpose computer module to calculate a MT suitability score using techniques such as sentence probability, LM score, document Perplexity and the equation for MT suitability score applied to source content <b>102</b> to generate vector representations of MT suitability for use as source content features <b>202</b>. A different MT suitability score may be generated from the source content <b>102</b> for each of a plurality of types of machine translators. It is noteworthy that MT suitability is an important feature to use in determining where to route a document because machine translation is substantially faster and less expensive than human translation.</p><p id="p-0063" num="0052">In various embodiments, the router <b>210</b> is a neural network, a classifier, a matrix, a search engine, decision tree, a finite state acceptor, and/or the like. In the example of the router <b>210</b> being a neural network, the source content features <b>202</b> may be received by the router <b>210</b> from the content analyzer <b>200</b> as an input matrix representing the source content features <b>202</b>, or as a plurality of feature vectors representing the source content features <b>202</b>.</p><p id="p-0064" num="0053">For example, each of the source features generated by the content analyzer <b>200</b> using modules <b>302</b>-<b>312</b> may be represented as one or more feature vectors. The router <b>210</b> may receive the plurality of feature vectors from the content analyzer <b>200</b> and assemble the feature vectors into an input matrix including columns comprising the feature vectors. In some embodiments, the content analyzer <b>200</b> assembles the generated feature vectors into columns of the input matrix. Input matrix is then received from the content analyzer <b>200</b> by the router <b>210</b> as a representation of the source content features <b>202</b>. The router <b>210</b> may also assemble feature vectors for the translators features <b>204</b> and/or the job features <b>206</b> into additional columns of the input matrix.</p><p id="p-0065" num="0054">The router <b>210</b> may be an artificial neural network (e.g., a multi-layer perceptron) for processing complex inputs such as presented by the input matrix assembled from feature vectors generated by the content analyzer <b>200</b> and representing source content features <b>202</b>. Connections between one or more layers of the neural network may be represented by a weight matrix or more than one weight matrix. A target matrix may be formed, e.g., having columns for the translators <b>116</b>. The translator columns may be vectors that include weights representing delivery predictions for features such as cost, margin, time, quality. Persons having ordinary skill in the relevant arts would understand with the present application before them how to construct and use a special purpose computer router <b>210</b> using artificial neural network technology to train a weight matrix and process to process an input matrix and target matrix for selecting one or more translators <b>116</b> to provide translation services for source content <b>102</b>.</p><p id="p-0066" num="0055">In some embodiments, a router <b>210</b> is a classifier that ranks translators based on the source content <b>102</b> and/or the source content features <b>202</b>, translators features <b>204</b>, and job features <b>206</b>. The router <b>210</b> may output a delivery prediction score for each of various categories of delivery prediction for each translator. Delivery prediction categories for each translator <b>116</b> may include cost, margin, time, quality, and/or the like. The delivery prediction scores may be used for selecting a translator <b>116</b>.</p><p id="p-0067" num="0056"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagrammatic representation of an example machine in the form of a computer system <b>700</b>, within which a set of instructions for causing the machine to perform any of one or more of the methodologies discussed herein may be executed. In various example embodiments, the machine operates as a standalone device (e.g. content distribution server <b>112</b>, MT translator <b>116</b>, content analyzer <b>200</b>, router <b>210</b>, and/or other components described in the figures and specification) or may be connected (e.g., networked) to other machines. In a networked deployment, the machine may operate in the capacity of a server (e.g. content distribution server <b>112</b>) or a client machine, in a server-client network environment, or as a peer machine in a peer-to-peer (or distributed) network environment. The machine may be a personal computer (PC), a tablet PC, a set-top box (STB), a personal digital assistant (PDA), a cellular telephone, a portable music player (e.g., a portable hard drive audio device such as an Moving Picture Experts Group Audio Layer 3 (MP3) player), a web appliance, a network router, switch or bridge, or any machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine. Further, while only a single machine is illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the term &#x201c;machine&#x201d; shall also be taken to include any collection of machines that individually or jointly execute a set (or multiple sets) of instructions to perform any one or more of the methodologies discussed herein</p><p id="p-0068" num="0057">The example computer system <b>700</b> includes a processor or multiple processor(s) <b>702</b> (e.g., a central processing unit (CPU), a graphics processing unit (GPU), or both), and a main memory <b>706</b> and static memory <b>708</b>, which communicate with each other via a bus <b>722</b>. The computer system <b>700</b> may further include a video display <b>712</b> (e.g., a liquid crystal display (LCD)). The computer system <b>700</b> may also include an input/output device(s) <b>714</b> including alpha-numeric input devices (e.g., a keyboard), a cursor control device (e.g., a mouse, trackball, touchpad, touch screen, etc.), a voice recognition or biometric verification unit (not shown), a drive unit <b>716</b> (also referred to as disk drive unit). Input devices may include interfaces for receiving source content <b>102</b> via the network <b>110</b> and/or directly from clients, and output interfaces for routing source content <b>102</b> via the network <b>110</b> and/or directly to translators <b>116</b>. The computer system <b>700</b> may further include a signal generation device <b>720</b> (e.g., a speaker) and a network interface device <b>710</b>.</p><p id="p-0069" num="0058">The disk drive unit <b>716</b> includes a computer or machine-readable medium <b>718</b> on which is stored one or more sets of instructions and data structures (e.g., instructions <b>704</b>) embodying or utilizing any one or more of the methodologies or functions described herein. The instructions <b>704</b> may also reside, completely or at least partially, within the main memory <b>706</b> and/or within the processor(s) <b>702</b> during execution thereof by the computer system <b>700</b>. The main memory <b>706</b> and the processor(s) <b>702</b> may also constitute machine-readable media.</p><p id="p-0070" num="0059">The instructions <b>704</b> may further be transmitted or received over a network (e.g., network <b>110</b>, see <figref idref="DRAWINGS">FIG. <b>1</b></figref>) via the network interface device <b>710</b> utilizing any one of a number of well-known transfer protocols (e.g., Hyper Text Transfer Protocol (HTTP)). While the machine-readable medium <b>718</b> is shown in an example embodiment to be a single medium, the term &#x201c;computer-readable medium&#x201d; should be taken to include a single medium or multiple media (e.g., a centralized or distributed database and/or associated caches and servers) that store the one or more sets of instructions. The term &#x201c;computer-readable medium&#x201d; shall also be taken to include any medium that is capable of storing, encoding, or carrying a set of instructions for execution by the machine and that causes the machine to perform any one or more of the methodologies of the present application, or that is capable of storing, encoding, or carrying data structures utilized by or associated with such a set of instructions. The term &#x201c;computer-readable medium&#x201d; shall accordingly be taken to include, but not be limited to, solid-state memories, optical and magnetic media, and carrier wave signals. Such media may also include, without limitation, hard disks, floppy disks, flash memory cards, digital video disks, random access memory (RAM), read only memory (ROM), and/or the like. The example embodiments described herein may be implemented in an operating environment comprising software installed on a computer, in hardware, or in a combination of software and hardware.</p><p id="p-0071" num="0060">One skilled in the art will recognize that the Internet service may be configured to provide Internet access to one or more computing devices that are coupled to the Internet service, and that the computing devices may include one or more processors, buses, memory devices, display devices, input/output devices, and the like. Furthermore, those skilled in the art may appreciate that the Internet service may be coupled to one or more databases, repositories, servers, and the like, which may be utilized in order to implement any of the embodiments of the disclosure as described herein.</p><p id="p-0072" num="0061">The corresponding structures, materials, acts, and equivalents of all means or step plus function elements in the claims below are intended to include any structure, material, or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present technology has been presented for purposes of illustration and description, but is not intended to be exhaustive or limited to the present technology in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the present technology. Exemplary embodiments were chosen and described in order to best explain the principles of the present technology and its practical application, and to enable others of ordinary skill in the art to understand the present technology for various embodiments with various modifications as are suited to the particular use contemplated.</p><p id="p-0073" num="0062">Aspects of the present technology are described above with reference to flow diagram illustrations and/or block diagrams of methods, apparatus (systems) and computer program products according to embodiments of the present technology. It will be understood that each block of the flow diagram illustrations and/or block diagrams, and combinations of blocks in the flow diagram illustrations and/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flow diagram and/or block diagram block or blocks.</p><p id="p-0074" num="0063">These computer program instructions may also be stored in a computer readable medium that can direct a computer, other programmable data processing apparatus, or other devices to function in a particular manner, such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function/act specified in the flow diagram and/or block diagram block or blocks.</p><p id="p-0075" num="0064">The computer program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other devices to cause a series of operational steps to be performed on the computer, other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions/acts specified in the flow diagram and/or block diagram block or blocks.</p><p id="p-0076" num="0065">The flow diagram and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present technology. In this regard, each block in the flow diagram or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flow diagram illustration, and combinations of blocks in the block diagrams and/or flow diagram illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.</p><p id="p-0077" num="0066">In the following description, for purposes of explanation and not limitation, specific details are set forth, such as particular embodiments, procedures, techniques, etc. in order to provide a thorough understanding of the present invention. However, it will be apparent to one skilled in the art that the present invention may be practiced in other embodiments that depart from these specific details.</p><p id="p-0078" num="0067">Reference throughout this specification to &#x201c;one embodiment&#x201d; or &#x201c;an embodiment&#x201d; means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the appearances of the phrases &#x201c;in one embodiment&#x201d; or &#x201c;in an embodiment&#x201d; or &#x201c;according to one embodiment&#x201d; (or other phrases having similar import) at various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments. Furthermore, depending on the context of discussion herein, a singular term may include its plural forms and a plural term may include its singular form. Similarly, a hyphenated term (e.g., &#x201c;on-demand&#x201d;) may be occasionally interchangeably used with its non-hyphenated version (e.g., &#x201c;on demand&#x201d;), a capitalized entry (e.g., &#x201c;Software&#x201d;) may be interchangeably used with its non-capitalized version (e.g., &#x201c;software&#x201d;), a plural term may be indicated with or without an apostrophe (e.g., PE's or PEs), and an italicized term (e.g., &#x201c;N+1&#x201d;) may be interchangeably used with its non-italicized version (e.g., &#x201c;N+1&#x201d;). Such occasional interchangeable uses shall not be considered inconsistent with each other.</p><p id="p-0079" num="0068">The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used herein, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms &#x201c;comprises&#x201d; and/or &#x201c;comprising,&#x201d; when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and/or groups thereof.</p><p id="p-0080" num="0069">It is noted at the outset that the terms &#x201c;coupled,&#x201d; &#x201c;connected,&#x201d; &#x201c;connecting,&#x201d; &#x201c;electrically connected,&#x201d; etc., are used interchangeably herein to generally refer to the condition of being electrically/electronically connected. Similarly, a first entity is considered to be in &#x201c;communication&#x201d; with a second entity (or entities) when the first entity electrically sends and/or receives (whether through wireline or wireless means) information signals (whether containing data information or non-data/control information) to the second entity regardless of the type (analog or digital) of those signals. It is further noted that various figures (including component diagrams) shown and discussed herein are for illustrative purpose only, and are not drawn to scale.</p><p id="p-0081" num="0070">While specific embodiments of, and examples for, the system are described above for illustrative purposes, various equivalent modifications are possible within the scope of the system, as those skilled in the relevant art with the instant application before them will recognize. For example, while processes or steps are presented in a given order, alternative embodiments may perform routines having steps in a different order, and some processes or steps may be deleted, moved, added, subdivided, combined, and/or modified to provide alternative or sub-combinations. Each of these processes or steps may be implemented in a variety of different ways. Also, while processes or steps are at times shown as being performed in series, these processes or steps may instead be performed in parallel, or may be performed at different times.</p><p id="p-0082" num="0071">While various embodiments have been described above, it should be understood that they have been presented by way of example only, and not limitation. The descriptions are not intended to limit the scope of the invention to the particular forms set forth herein. To the contrary, the present descriptions are intended to cover such alternatives, modifications, and equivalents as may be included within the spirit and scope of the invention as defined by the appended claims and otherwise appreciated by one of ordinary skill in the art. Thus, the breadth and scope of a preferred embodiment should not be limited by any of the above-described exemplary embodiments.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230004732A1-20230105-M00001.NB"><img id="EMI-M00001" he="5.25mm" wi="76.20mm" file="US20230004732A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230004732A1-20230105-M00002.NB"><img id="EMI-M00002" he="6.01mm" wi="76.20mm" file="US20230004732A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003 MATH-US-00003-2 MATH-US-00003-3" nb-file="US20230004732A1-20230105-M00003.NB"><img id="EMI-M00003" he="18.37mm" wi="76.20mm" file="US20230004732A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00004" nb-file="US20230004732A1-20230105-M00004.NB"><img id="EMI-M00004" he="6.35mm" wi="76.20mm" file="US20230004732A1-20230105-M00004.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00005" nb-file="US20230004732A1-20230105-M00005.NB"><img id="EMI-M00005" he="6.01mm" wi="76.20mm" file="US20230004732A1-20230105-M00005.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00006" nb-file="US20230004732A1-20230105-M00006.NB"><img id="EMI-M00006" he="4.91mm" wi="76.20mm" file="US20230004732A1-20230105-M00006.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00007" nb-file="US20230004732A1-20230105-M00007.NB"><img id="EMI-M00007" he="5.67mm" wi="76.20mm" file="US20230004732A1-20230105-M00007.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for routing documents for translation services to translators, the method comprising:<claim-text>receiving a translator feature for each of a plurality of translators;</claim-text><claim-text>receiving a plurality of job features;</claim-text><claim-text>receiving a document for translation services;</claim-text><claim-text>extracting a plurality of document content features from content of the document;</claim-text><claim-text>generating an input matrix from the document content features, wherein at least one of the plurality of document content features includes a document summary feature comprising a vector representation of a plurality of sentences from the content of the document;</claim-text><claim-text>generating a target matrix for the plurality of translators from the plurality of translator features;</claim-text><claim-text>processing the input matrix using the target matrix for an artificial neural network to select a translator from the plurality of translators; and</claim-text><claim-text>routing the received document to the selected translator for performing the translation services.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a translator feature comprises one or more components of a translator profile associated with at least one of the plurality of translators.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising extracting the plurality of job features by a server from a job profile concerning the document for translation services, the job profile comprising information about how the job is to be processed for translation.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the plurality of job features comprises information regarding one or more of the following cost, margin, time, quality, and target language for the job.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising partitioning the content of the document into a plurality of portions that are to be routed to two or more of the plurality of translators for translation services.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the translator profile comprises information about the translator including at least one of the following: previous work content, quality, speed, schedule, time zone, target language skills for one or more target languages, post editing skills, and domain skills for one or more domains.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the input matrix comprises:<claim-text>generating a document feature vector for each of the plurality of document features, the document feature vector including one or more values representing the feature; and</claim-text><claim-text>assembling the input matrix using the plurality of vectors as columns of the input matrix.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the document content features include a summarization of the document, a plurality of keywords and key-phrases in the document, an identification of a domain of the document, a recognition of a plurality of named entities in the document, a calculation of complexity of the document, and a calculation of suitability of the document for machine translation.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the target matrix comprises:<claim-text>generating a translator feature vector for each of the plurality of translators, each translator feature vector including one or more values representing a feature of the translator; and</claim-text><claim-text>assembling the target matrix using the plurality of vectors as columns of the target matrix.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising generating the document content features that includes a plurality of summarization features of the document including selected sentences from the document.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the input matrix comprises:<claim-text>selecting a plurality of sentences representing the document summary feature for inclusion in a summary vector, the sentences selected by a method of:<claim-text>encoding each sentence of the document into a vector representation;</claim-text><claim-text>computing a &#x2018;centroid&#x2019; vector as the sum of these vector representations; and</claim-text><claim-text>selecting sentences having a highest cosine similarity to the centroid for inclusion in the summary vector; and</claim-text></claim-text><claim-text>assembling the input matrix using the summary vector as a column of the input matrix.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein document content features include a document keyword feature and generating the input matrix comprises:<claim-text>selecting a plurality of keywords and key-phrases;</claim-text><claim-text>generating a keyword vector representation of the plurality of keywords and key-phrases; and</claim-text><claim-text>assembling the input matrix using the keyword vector as a column of the matrix.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A system for routing source content to translators for translation services comprising:<claim-text>a processor; and</claim-text><claim-text>a memory communicatively coupled to the processor, the memory for storing instructions executable by the processor to perform a method, the method comprising:<claim-text>receiving a translator feature for each of a plurality of translators;</claim-text><claim-text>receiving a plurality of job features;</claim-text><claim-text>receiving a document for translation services;</claim-text><claim-text>extracting a plurality of document content features from content of the document;</claim-text><claim-text>generating an input matrix from the document content features, wherein at least one of the plurality of document content features includes a document summary feature comprising a vector representation of a plurality of sentences from the content of the document;</claim-text><claim-text>generating a target matrix for the plurality of translators from the plurality of translator features;</claim-text><claim-text>processing the input matrix using the target matrix for an artificial neural network to select a translator from the plurality of translators; and</claim-text><claim-text>routing the received document to the selected translator for performing the translation services.</claim-text></claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein a translator feature comprises one or more components of a translator profile associated with at least one of the plurality of translators.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the method further comprises extracting the plurality of job features by a server from a job profile concerning the document for translation services, the job profile comprising information about how the job is to be processed for translation.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the plurality of job features comprises information regarding one or more of the following cost, margin, time, quality, and target language for the job.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the method further comprises partitioning the content of the document into a plurality of portions that are routed to two or more of the plurality of translators for translation services.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the translator profile comprises information about the translator including at least one of the following: previous work content, quality, speed, schedule, time zone, target language skills for one or more target languages, post editing skills, and domain skills for one or more domains.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein generating the input matrix comprises:<claim-text>generating a document feature vector for each of the plurality of document features, the document feature vector including one or more values representing the feature; and</claim-text><claim-text>assembling the input matrix using the plurality of vectors as columns of the input matrix.</claim-text></claim-text></claim><claim id="CLM-00019-1" num="00019-1"><claim-text><b>19</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the document content features include a summarization of the document, a plurality of keywords and key-phrases in the document, an identification of a domain of the document, a recognition of a plurality of named entities in the document, a calculation of complexity of the document, and a calculation of suitability of the document for machine translation.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein generating the target matrix comprises:<claim-text>generating a translator feature vector for each of the plurality of translators, each translator feature vector including one or more values representing a feature of the translator; and</claim-text><claim-text>assembling the target matrix using the plurality of vectors as columns of the target matrix.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the method further comprises generating the document content features including a plurality of summarization features of the document including selected sentences from the document.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein generating the input matrix comprises:<claim-text>selecting a plurality of sentences representing the document summary feature for inclusion in a summary vector, the sentences selected by a method of:<claim-text>encoding each sentence of the document into a vector representation;</claim-text><claim-text>computing a &#x2018;centroid&#x2019; vector as the sum of these vector representations; and</claim-text><claim-text>selecting sentences having a highest cosine similarity to the centroid for inclusion in the summary vector; and</claim-text></claim-text><claim-text>assembling the input matrix using the summary vector as a column of the matrix.</claim-text></claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein document content features include a document keyword feature and generating the input matrix comprises:<claim-text>selecting a plurality of keywords and key-phrases;</claim-text><claim-text>generating a keyword vector representation of the plurality of keywords and key-phrases; and</claim-text><claim-text>assembling the input matrix using the keyword vector as a column of the matrix.</claim-text></claim-text></claim></claims></us-patent-application>
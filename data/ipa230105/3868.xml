<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003869A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003869</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17810122</doc-number><date>20220630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>21182868.6</doc-number><date>20210630</date></priority-claim><priority-claim sequence="02" kind="regional"><country>EP</country><doc-number>21182874.4</doc-number><date>20210630</date></priority-claim><priority-claim sequence="03" kind="regional"><country>EP</country><doc-number>22179201.3</doc-number><date>20220615</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>42</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>42</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>13</main-group><subgroup>931</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>2013</main-group><subgroup>932</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e98">Methods and Systems for Radar Data Processing</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Aptiv Technologies Limited</orgname><address><city>St. Michael</city><country>BB</country></address></addressbook><residence><country>BB</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Prediger</last-name><first-name>Christian</first-name><address><city>Lindlar</city><country>DE</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Meuter</last-name><first-name>Mirko</first-name><address><city>Erkrath</city><country>DE</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A computer implemented method for radar data processing includes the following steps carried out by computer hardware components: acquiring radar data from a radar sensor mounted on a vehicle; determining at least one of a speed of the vehicle or a steering wheel angle of the vehicle; and determining a subset of the radar data for processing based on the at least one of the speed of the vehicle or the steering wheel angle of the vehicle.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="131.57mm" wi="109.73mm" file="US20230003869A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="236.64mm" wi="136.65mm" file="US20230003869A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="236.64mm" wi="136.65mm" file="US20230003869A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="236.64mm" wi="136.65mm" file="US20230003869A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="236.64mm" wi="136.65mm" file="US20230003869A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="236.73mm" wi="158.41mm" file="US20230003869A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="239.01mm" wi="143.09mm" file="US20230003869A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="234.10mm" wi="175.77mm" orientation="landscape" file="US20230003869A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="148.17mm" wi="125.90mm" file="US20230003869A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">INCORPORATION BY REFERENCE</heading><p id="p-0002" num="0001">This application claims priority to European Patent Application Number EP22179201.3, filed on Jun. 15, 2022, which in turn claims priority to European Patent Application Number EP21182868.6, filed on Jun. 30, 2021, and to European Patent Application Number EP21182874.4, filed on Jun. 30, 2021, the disclosures of which are incorporated by reference in their entireties.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Processing radar data is an essential task for various applications, for example for (at least partially) autonomously driving vehicles. However, processing radar data is computationally expensive.</p><p id="p-0004" num="0003">Accordingly, there is a need to provide methods and systems for efficient processing of radar data.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0005" num="0004">The present disclosure relates to methods and systems for radar data processing, in particular adaptive radar sight.</p><p id="p-0006" num="0005">The present disclosure provides a computer implemented method, a computer system and a non-transitory computer readable medium according to the independent claims. Example implementations are given in the subclaims, the description and the drawings.</p><p id="p-0007" num="0006">In some example implementations, the present disclosure is directed to a computer implemented method for radar data processing, with the method comprising the following steps performed (in other words: carried out) by computer hardware components: acquiring radar data from a radar sensor mounted on a vehicle; determining at least one of a speed of the vehicle or a steering wheel angle of the vehicle; and determining a subset of the radar data for processing based on the at least one of the speed of the vehicle or the steering wheel angle of the vehicle.</p><p id="p-0008" num="0007">According to an implementation, the radar data comprises data with a range dimension and an angle dimension; and the subset comprises a subset along the range dimension and/or along the angle dimension.</p><p id="p-0009" num="0008">According to an implementation, the range dimension comprises a range up to 60 m, or up to 100 m, or up to 135 m, or up to 150 m, or up to 200 m, or up to 210 m, or up to 300 m; and/or the angle dimension comprises an angle range of 30&#xb0;, or 35&#xb0;, or 45&#xb0;, or 60&#xb0;, or 75&#xb0;, or 90&#xb0;.</p><p id="p-0010" num="0009">According to an implementation, the subset comprises a subset along the range dimension based on the speed of the vehicle.</p><p id="p-0011" num="0010">According to an implementation, for a speed below a first speed threshold, the range dimension is limited to a first range limit.</p><p id="p-0012" num="0011">According to an implementation, the subset comprises a subset along the angle dimension based on the speed of the vehicle.</p><p id="p-0013" num="0012">According to an implementation, for a speed below between the first speed threshold and a second speed threshold, the range dimension is limited to a second range limit and the angle dimension is limited between a first angle limit and a second angle limit.</p><p id="p-0014" num="0013">According to an implementation, for a speed higher than the second speed threshold, the angle dimension is limited between a third angle limit and a fourth angle limit.</p><p id="p-0015" num="0014">For example, ranges and speeds may be in the following range:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0015">1) 50 m range for a speed between 0 and 20 km/h (with a 10 km/h hysteresis);</li>        <li id="ul0002-0002" num="0016">2) 105 m range for a speed between 20 km/h and 70 km/h (with a 10 km/h hysteresis); and</li>        <li id="ul0002-0003" num="0017">3) 200 m range for a speed above 70 km/h (with a 10 km/h hysteresis) (for example corresponding to a highway/rural top speed in Germany), including a hysteresis overlap.</li>    </ul>    </li></ul></p><p id="p-0016" num="0018">According to an implementation, the subset comprises a subset along the angle dimension based on the steering wheel angle of the vehicle.</p><p id="p-0017" num="0019">According to an implementation, the subset along the range dimension is determined based on filtering out input beam vectors for angle finding.</p><p id="p-0018" num="0020">According to an implementation, the subset along the angle dimension is determined based on limiting an output of an angle finding method.</p><p id="p-0019" num="0021">According to an implementation, the speed of the vehicle and/or the steering wheel angle of the vehicle is determined from a bus system of the vehicle.</p><p id="p-0020" num="0022">In other example implementations, the present disclosure is directed at a computer system, with said computer system comprising a plurality of computer hardware components configured to carry out several or all operations of the computer implemented method described herein.</p><p id="p-0021" num="0023">The computer system may comprise a plurality of computer hardware components (for example a processor, for example processing unit or processing network, at least one memory, for example memory unit or memory network, and at least one non-transitory data storage). It will be understood that further computer hardware components may be provided and used for carrying out operations of the computer implemented method in the computer system. The non-transitory data storage and/or the memory unit may comprise a computer program for instructing the computer to perform several or all operations or aspects of the computer implemented method described herein, for example using the processing unit and the at least one memory unit.</p><p id="p-0022" num="0024">In still other example implementations, the present disclosure is directed at a vehicle comprising the computer system as described herein and the radar sensor.</p><p id="p-0023" num="0025">In yet still other example implementations, the present disclosure is directed at a non-transitory computer readable medium comprising instructions for carrying out several or all operations or aspects of the computer implemented method described herein. The computer readable medium may be configured as: an optical medium, such as a compact disc (CD) or a digital versatile disk (DVD); a magnetic medium, such as a hard disk drive (HDD); a solid state drive (SSD); a read only memory (ROM), such as a flash memory; or the like. Furthermore, the computer readable medium may be configured as a data storage that is accessible via a data connection, such as an internet connection. The computer readable medium may, for example, be an online data repository or a cloud storage.</p><p id="p-0024" num="0026">The present disclosure is also directed at a computer program for instructing a computer to perform several or all operations or aspects of the computer implemented method described herein.</p><p id="p-0025" num="0027">With the methods and systems as described herein, adapting the processing of signals within selected range/field-of-view of a vehicle radar system based on operative parameters of the vehicle and/or driving environment may be provided. Thus, the hardware requirements of the ML (machine learning) radar recognition may be decreased.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0026" num="0028">Example implementations and functions of the present disclosure are described herein in conjunction with the following drawings, showing schematically:</p><p id="p-0027" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> is an illustration of an example full radar range;</p><p id="p-0028" num="0030"><figref idref="DRAWINGS">FIG. <b>1</b>B</figref> depicts examples of a full range and full angle area;</p><p id="p-0029" num="0031"><figref idref="DRAWINGS">FIGS. <b>2</b>A and <b>2</b>B</figref> are illustrations of an example low-speed situation according to various implementations;</p><p id="p-0030" num="0032"><figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref> are illustrations of an example mid-speed situation according to various implementations;</p><p id="p-0031" num="0033"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> are illustrations of an example high-speed situation according to various implementations;</p><p id="p-0032" num="0034"><figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> are illustrations of an example adaption of the angular region of interest dependent on the steering wheel angle according to various implementations;</p><p id="p-0033" num="0035"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is an illustration of an example radar sensor on a vehicle;</p><p id="p-0034" num="0036"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is an illustration of example maximum curvatures on highways;</p><p id="p-0035" num="0037"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is an illustration of an example blocked view;</p><p id="p-0036" num="0038"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is an illustration of an example system according to various implementations; and</p><p id="p-0037" num="0039"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flow diagram illustrating an example method for radar data processing according to various implementations.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0038" num="0040">In various embedded systems, method for machine learning (ML) are used to solve perception tasks. The product which is performing these tasks may be deep neural networks (DNN).</p><p id="p-0039" num="0041">The ML technology may be superior in many fields, but it may lead to large computational requirements. As a large part of the technology was developed for server and web applications, embedded resource requirements are not always an initial requirement. Strategies for embedded deployment of DNNs are optimization techniques and special purpose hardware. Even though those technologies are a precondition to computing those methods, it may still be important to reduce the resource as it creates large systems cost.</p><p id="p-0040" num="0042">According to various aspects, in order to limit the computational requirements, the input data may be delimited, such that only relevant data is chosen. Regarding perception, this may mean to reduce the spatial area to one in which detected objects or obstacles are relevant for the vehicle.</p><p id="p-0041" num="0043">According to various aspects, by creation of a region of interest (ROI), the data according to areas which are irrelevant may be excluded from expensive computation.</p><p id="p-0042" num="0044">In case of a radar sensor, this may be non-trivial, since a spatial position of an input data is not defined. Furthermore, radars are already designed to fit to the expected requirements. According to various aspects, certain driving parameters may be taken into account for effectively solving this problem.</p><p id="p-0043" num="0045">In commonly used methods, the input data which is used is not limited by an effective input data reduction. Thereby, the computational complexity stays high and thereby the expected product cost stay high as well.</p><p id="p-0044" num="0046">In the following, creating an adaptive region of interest for front radar sensors according to various aspects will be described.</p><p id="p-0045" num="0047">Front radar sensors may be designed to reach a long range and in the same time create an aperture angle which enables overlooking driving situations in the front near to the car.</p><p id="p-0046" num="0048"><figref idref="DRAWINGS">FIG. <b>1</b>A</figref> shows an illustration <b>100</b> of a full radar range. The ego vehicle <b>104</b> is illustrated as a black rectangle surrounded by a near range field of view <b>106</b>, which may be used for 360 degree surround recognition. The field of view <b>102</b> is illustrated in an example of a front radar sensor. As the full area is covered, the ML radar recognition method may have to be applied on the full range and angle area <b>152</b> (as illustrated in illustration <b>150</b> of <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>), creating high computational requirements.</p><p id="p-0047" num="0049">According to various aspects, an adaptive region of interest may be provided using at least one of the following:</p><p id="p-0048" num="0050">1) Adapting the range region of interest dependent on ego vehicle speed; and/or</p><p id="p-0049" num="0051">2) Adapting the angular region of interest dependent on the steering wheel angle.</p><p id="p-0050" num="0052">Both values (the ego vehicle speed and the steering wheel angle) may be available in the vehicles (for example cars or trucks) and may be obtained from a bus system (for example CAN, LIN, or Ethernet) that is available.</p><p id="p-0051" num="0053">Further possibilities to limit the input data may be applied additionally or not, dependent on the full system requirements. Two examples of such further methods are:</p><p id="p-0052" num="0054">Inner region of interest for near range traffic recognition; and/or Static object filtering dependent on ego speed and thereby filtering for static doppler speed (which may provide a &#x201c;tailored datacube&#x201d;).</p><p id="p-0053" num="0055">Both further methods do not solve the case of a front radar intended to recognize moving objects.</p><p id="p-0054" num="0056">According to various aspects, the range region of interest may be adapted dependent on ego vehicle speed, as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>.</p><p id="p-0055" num="0057"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>2</b>B</figref> show illustrations <b>200</b> and <b>250</b> of a low-speed situation according to various implementations.</p><p id="p-0056" num="0058">In low-speed situations, it may be sufficient to limit the range of the front radar sensor to a certain range <b>202</b>, as objects in that area would have impact on the driving decisions, and objects further away may not yet be relevant. By this limitation, the range dimension of the input data can be reduced to area <b>252</b>, and the angle field of view may be kept wide.</p><p id="p-0057" num="0059"><figref idref="DRAWINGS">FIG. <b>3</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> show illustrations <b>300</b> and <b>350</b> of a mid-speed situation according to various implementations.</p><p id="p-0058" num="0060">In mid-speed situations, the area <b>302</b> needed from range dimension side may get bigger. But a limitation of the angular area may limit the input data effectively, leaving out the sides of the angular field in which the vehicle will not enter. The resulting area <b>352</b> is illustrated in the range vs. angle diagram of <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>.</p><p id="p-0059" num="0061"><figref idref="DRAWINGS">FIG. <b>4</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>4</b>B</figref> show illustrations <b>400</b> and <b>450</b> of a high-speed situation according to various implementations.</p><p id="p-0060" num="0062">In high-speed situations, it may be important to look far forward into the driving direction, as far as possible. In favor of this large range, the angular opening angle <b>402</b> may further be reduced. The resulting area <b>452</b> is illustrated in the range vs. angle diagram of <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>.</p><p id="p-0061" num="0063">In order to maximize the reduction of angular opening angle without missing relevant objects, the angular region of interest may be adapted dependent on the steering wheel angle, like will be described with reference to <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>.</p><p id="p-0062" num="0064"><figref idref="DRAWINGS">FIG. <b>5</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> show illustrations <b>500</b> and <b>550</b> of an adaption of the angular region of interest dependent on the steering wheel angle according to various implementations.</p><p id="p-0063" num="0065">According to the steering wheel angle, it may be possible to calculate the driving path of the ego vehicle. By this, the region of interest may be aimed into the direction of driving.</p><p id="p-0064" num="0066">Thus, the savings for excluded angular area may be maximized. According to regulatory rules the curvature which can be expected not to be exceeded is defined.</p><p id="p-0065" num="0067"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an illustration <b>600</b> of a radar sensor on a vehicle.</p><p id="p-0066" num="0068"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an illustration <b>700</b> of maximum curvatures on highways.</p><p id="p-0067" num="0069"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an illustration <b>800</b> of a blocked view.</p><p id="p-0068" num="0070">Use cases may include example calculation of road curvature and thereby resulting opening angle. These angles/curvatures and depending on that target speeds may depend on feature requirements and are thereby not explicitly defined.</p><p id="p-0069" num="0071">For example, a feature (e.g., Autonomous Emergency Braking (AEB)) which only considers in lane objects or neighboring lane potential candidates to lane change may have a requirement targeting that area plus a safety area at the sides. A feature depending on bridge recognition may have requirements also considering the road's side areas, where a bridges boundaries might be expected.</p><p id="p-0070" num="0072">Use cases (for example as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> to <figref idref="DRAWINGS">FIG. <b>8</b></figref>) may assure that also in quantitative measures, the methods and systems according to various implementations can lead to a significant reduction of hardware needs.</p><p id="p-0071" num="0073">In order to understand the quantitative impact of that method, a realistic use case is illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> to <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0072" num="0074">A front radar of a vehicle <b>602</b> may be mounted at a central position in the vehicle front and may have an opening angle of 60&#xb0; and a range of 210 m (outer circle). The inner circle <b>604</b> shows an example mid speed limit with a radius of 105 m (inner circle).</p><p id="p-0073" num="0075"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows the curvature limitation on a typical German inner city highway with 100 kph speed limitation. With dotted lines the example angular limitation for mid and high speed are shown. It may be seen that there is still a distance taking into account a reasonable driving path area. This distance may be objective to optimizations according to requirements and feature demands.</p><p id="p-0074" num="0076">The curvature <b>702</b>, <b>704</b> shows the respective limitation for highway (high speed) in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. Besides the limitation in curvature, it may also be seen that a part of the outer circle <b>706</b> may be realistically still blocked from direct perception due to near field barriers of the road (as for example illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>).</p><p id="p-0075" num="0077"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows an illustration <b>900</b> of a system according to various implementations.</p><p id="p-0076" num="0078">In the following, realization of adaptive computation will be described.</p><p id="p-0077" num="0079">In order to realize the computation steps within the architecture of the radar recognition network, it may be important to base on the given or at least possible architectures and modules influenced by the adaptive region of interest.</p><p id="p-0078" num="0080"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows a high level overview of the currently existing side radar signal processing on the left and an assumption of how the front radar signal processing will look like in the middle.</p><p id="p-0079" num="0081">Depending on the module impacted by the adaptive radar sight region of interest limitations, the strategy how to realize this may be different. The following may provide details and alternatives; however, it will be understood that other details and alternatives are possible.</p><p id="p-0080" num="0082">Range Dependent Adaptation:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0083">Filter out the input beam vectors for angle finding according to the range adaptation;</li>        <li id="ul0004-0002" num="0084">By this:</li>    </ul>    </li></ul></p><p id="p-0081" num="0085">1) strongly limit the number of beam vectors in the low-speed case;</p><p id="p-0082" num="0086">2) limit less but still impacting computational demand in the mid range; and</p><p id="p-0083" num="0087">3) do not filter in the long range case.</p><p id="p-0084" num="0088">Angle dependent adaptation:<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0089">in the front part compression step the angle of arrival is known from the module, so the angle adaptation can limit the output of angle finding already earlier, before this module starts to process the input;</li>        <li id="ul0006-0002" num="0090">By this:</li>    </ul>    </li></ul></p><p id="p-0085" num="0091">1) strongly limit the number of angle dimension of the output tensor in the high-speed case;</p><p id="p-0086" num="0092">2) limit less but still impacting computational demand in the mid range; and</p><p id="p-0087" num="0093">3) do not filter in the low speed case.</p><p id="p-0088" num="0094">ML (Machine Learning) Object Recognition:<ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0000">    <ul id="ul0008" list-style="none">        <li id="ul0008-0001" num="0095">the implementation of the detection and classification itself may be based on a grid structure;</li>        <li id="ul0008-0002" num="0096">that grid (for near range) may be spatially representing the vehicle coordinate system;</li>        <li id="ul0008-0003" num="0097">a possible alternative solution may be to stay in polar coordinate system;</li>        <li id="ul0008-0004" num="0098">in all cases the limitation of the angle and range may limit the grid and by this may achieve a massive reduction in computational needs because:</li>    </ul>    </li></ul></p><p id="p-0089" num="0099">1) regarding memory this part of the network is a bottle neck:</p><p id="p-0090" num="0100">2) in order to reach high distance with the front radar sensor the grid area would exceed even the demand seen from the near range area of interest.</p><p id="p-0091" num="0101">As described herein, a realization of three (3) fixed states of driving speed (low, mid and high) may be provided. An alternative may be to have a sliding adaptation of the region of interest, distorting the areas in a continuous manner. The realization of such a variant may imply:<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0000">    <ul id="ul0010" list-style="none">        <li id="ul0010-0001" num="0102">only a variable filtering limit for both initial steps: range and angle dependent adaptation;</li>        <li id="ul0010-0002" num="0103">a constant grid size but distorted input from different ranges/angles.</li>    </ul>    </li></ul></p><p id="p-0092" num="0104">A further alternative may be to implement a fixed grid:<ul id="ul0011" list-style="none">    <li id="ul0011-0001" num="0000">    <ul id="ul0012" list-style="none">        <li id="ul0012-0001" num="0105">A radar needs to balance long range and short range perception. At high speeds, one can expect the perception needs to be focused on high speed roads with limited curvature and curvature changes. Only roads with limited curvatures may truly provide a free field of view over several hundred meters. Due to this fact, a radar processing may process a short range perception over the full field of view, but to limit long range perception &#x3e;80 m to an area of +&#x2212;30&#xb0;-45 degree, which may cut required calculation effort by 25% to 50% for longer ranges while there should be no perceivable performance drop.</li>        <li id="ul0012-0002" num="0106">Fixed grid structures may ensure gradient propagation in E2E solutions and may create a trainable system with less need to structure training systematically into motion subclasses or to train the system as two stage approach.</li>    </ul>    </li></ul></p><p id="p-0093" num="0107"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows a flow diagram <b>1000</b> illustrating a method for radar data processing according to various implementations. At <b>1002</b>, radar data may be acquired from a radar sensor mounted on a vehicle. At <b>1004</b>, at least one of a speed of the vehicle or a steering wheel angle of the vehicle may be determined. At <b>1006</b>, a subset of the radar data for processing may be determined based on the at least one of the speed of the vehicle or the steering wheel angle of the vehicle.</p><p id="p-0094" num="0108">According to various aspects, the radar data may include or may be data with a range dimension and an angle dimension; and the subset may include or may be a subset along the range dimension and/or along the angle dimension.</p><p id="p-0095" num="0109">According to various aspects, the range dimension may include or may be a range up to 100 m, or up to 150 m, or up to 200 m, or up to 210 m, or up to 300 m; and/or the angle dimension may include or may be an angle range of 30&#xb0;, or 45&#xb0;, or 60&#xb0;, or 75&#xb0;, or 90&#xb0;. It will be understood that these range dimension and angle dimensions are merely examples, and that other values may be used for these dimensions; for example, the range dimension may be a range up to 135 m and the angle dimension may be 35&#xb0;, or the range dimension may be a range up to 60 m and the angle dimension may be 45&#xb0;.</p><p id="p-0096" num="0110">According to various aspects, the subset may include or may be a subset along the range dimension based on the speed of the vehicle.</p><p id="p-0097" num="0111">According to various aspects, for a speed below a first speed threshold, the range dimension may be limited to a first range limit.</p><p id="p-0098" num="0112">According to various aspects, the subset may include or may be a subset along the angle dimension based on the speed of the vehicle.</p><p id="p-0099" num="0113">According to various aspects, for a speed below between the first speed threshold and a second speed threshold, the range dimension may be limited to a second range limit and the angle dimension may be limited between a first angle limit and a second angle limit.</p><p id="p-0100" num="0114">According to various aspects, for a speed higher than the second speed threshold, the angle dimension may be limited between a third angle limit and a fourth angle limit.</p><p id="p-0101" num="0115">According to various aspects, the subset may include or may be a subset along the angle dimension based on the steering wheel angle of the vehicle.</p><p id="p-0102" num="0116">According to various aspects, the subset along the range dimension may be determined based on filtering out input beam vectors for angle finding.</p><p id="p-0103" num="0117">According to various aspects, the subset along the angle dimension may be determined based on limiting an output of an angle finding method.</p><p id="p-0104" num="0118">According to various aspects, the speed of the vehicle and/or the steering wheel angle of the vehicle may be determined from a bus system of the vehicle.</p><p id="p-0105" num="0119">Each of the steps <b>1002</b>, <b>1004</b>, <b>1006</b> and the further steps described above may be performed by computer hardware components.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>acquiring radar data from a radar sensor mounted on a vehicle;</claim-text><claim-text>determining at least one of a speed of the vehicle or a steering wheel angle of the vehicle; and</claim-text><claim-text>determining a subset of the radar data for processing based on the at least one of the speed of the vehicle or the steering wheel angle of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the radar data comprises data with a range dimension and an angle dimension; and</claim-text><claim-text>the subset comprises a subset along at least one of the range dimension or the angle dimension.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein at least one of:<claim-text>the range dimension comprises a range up to 60 m, 100 m, 135 m, 150 m, 200 m, 210 m, or 300 m; or</claim-text><claim-text>the angle dimension comprises an angle range of 30&#xb0;, 35&#xb0;, 45&#xb0;, 60&#xb0;, 75&#xb0;, or 90&#xb0;.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein:<claim-text>the subset comprises a subset along the range dimension based on the speed of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein:<claim-text>for a speed below a first speed threshold, the range dimension is limited to a first range limit.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein:<claim-text>the subset comprises a subset along the angle dimension based on the speed of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein:<claim-text>for a speed between the first speed threshold and a second speed threshold, the range dimension is limited to a second range limit, and the angle dimension is limited between a first angle limit and a second angle limit.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein:<claim-text>for a speed higher than the second speed threshold, the angle dimension is limited between a third angle limit and a fourth angle limit.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein:<claim-text>the subset comprises a subset along the angle dimension based on the steering wheel angle of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the determining the subset comprises:<claim-text>determining the subset along the range dimension based on filtering out input beam vectors for angle finding.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the determining the subset comprises:<claim-text>determining the subset along the angle dimension based on limiting an output of an angle finding method.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining of the at least one of the speed of the vehicle or the steering wheel angle of the vehicle comprises:<claim-text>determining the at least one of the speed of the vehicle or the steering wheel angle of the vehicle from a bus system of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A vehicle comprising:<claim-text>a computer system comprising a plurality of computer hardware components configured to:<claim-text>acquire radar data from a radar sensor mounted on the vehicle;</claim-text><claim-text>determine at least one of a speed of the vehicle or a steering wheel angle of the vehicle; and</claim-text><claim-text>determine a subset of the radar data for processing based on the at least one of the speed of the vehicle or the steering wheel angle of the vehicle.</claim-text></claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The vehicle of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising:<claim-text>the radar sensor.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The vehicle of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein:<claim-text>the radar data comprises data with a range dimension and an angle dimension; and</claim-text><claim-text>the subset comprises a subset along at least one of the range dimension or the angle dimension.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The vehicle of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein:<claim-text>the subset comprises a subset along the range dimension based on the speed of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The vehicle of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein:<claim-text>the subset comprises a subset along the angle dimension based on the speed of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The vehicle of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein:<claim-text>the subset comprises a subset along the angle dimension based on the steering wheel angle of the vehicle.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The vehicle of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising:<claim-text>a bus system,</claim-text><claim-text>wherein the at least one of the speed of the vehicle or the steering wheel angle of the vehicle is determined from the bus system.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. At least one non-transitory computer readable medium comprising instructions, which when executed by a processor, cause the processor to perform operations including:<claim-text>acquiring radar data from a radar sensor mounted on a vehicle;</claim-text><claim-text>determining at least one of a speed of the vehicle or a steering wheel angle of the vehicle; and</claim-text><claim-text>determining a subset of the radar data for processing based on the at least one of the speed of the vehicle or the steering wheel angle of the vehicle.</claim-text></claim-text></claim></claims></us-patent-application>
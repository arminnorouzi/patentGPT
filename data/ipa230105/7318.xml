<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007319A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007319</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17809682</doc-number><date>20220629</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>234</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2747</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>472</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>236</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>23418</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2747</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>47214</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>23605</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>6143</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">CONTENT BOUNDARY BASED RECORDINGS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17445894</doc-number><date>20210825</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11412273</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17809682</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15282038</doc-number><date>20160930</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11134278</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17445894</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Comcast Cable Communications, LLC</orgname><address><city>Philadelphia</city><state>PA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LINTZ</last-name><first-name>Christopher</first-name><address><city>Denver</city><state>CO</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>DAWSON</last-name><first-name>Tedd</first-name><address><city>Littleton</city><state>CO</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>BURGESS</last-name><first-name>Jason</first-name><address><city>Denver</city><state>CO</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Systems and methods for managing the storage of content are described. A video stream may include a content identifier and content information relating to a boundary that may be used to facilitate recording of at least a portion of the video stream.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="114.64mm" wi="158.75mm" file="US20230007319A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="255.95mm" wi="167.98mm" orientation="landscape" file="US20230007319A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="219.96mm" wi="175.26mm" file="US20230007319A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="163.41mm" wi="137.16mm" file="US20230007319A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="188.89mm" wi="142.16mm" file="US20230007319A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="181.36mm" wi="146.81mm" file="US20230007319A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="183.64mm" wi="144.10mm" file="US20230007319A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 17/445,894, filed Aug. 25, 2021, which is a continuation of U.S. patent application No. 15/282,038, filed Sep. 30, 2016, now U.S. Pat. No. 11,134,278, issued Sep. 28, 2021, which are hereby incorporated by reference in their entireties.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Content recording systems and devices, such as digital video recorders (DVRs), may facilitate the recording of various content assets. For example, a standard in-home DVR may record content locally. As another example, a cloud or network DVR service may allow an at-home user to request that a particular content asset be recorded. Instead of, or in addition to, the content being recorded on a device in the user's home, as with the standard DVR configuration, the cloud or network DVR service records and stores a copy of the requested content asset on the service provider's servers for the requesting user. When the user wishes to view the content asset, the cloud or network DVR service then delivers the copy of the recorded content to the user's cable box, mobile device, web browser, or the like for playback. Users implementing a record feature via a DVR may select a default recording schedule for the content. However, content that starts earlier or ends later than a scheduled display time (e.g., air time, program time, etc.) may result in the recording capturing only a portion of the intended content.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">Methods and systems for managing recorded content are described. Content boundary information may be included in a linear video stream to facilitate the alignment of downstream processes based on actual content (e.g., program, asset, etc.) start and end time. Content providers such as content creators, distributors, delivery services, and the like may insert content boundary information in a video stream. As an example, insertion of content boundary information may take the form of a SCTE-35 time signal mechanism comprising segmentation descriptors representing content boundaries and/or breaks in the content (e.g., programming). Other mechanisms may be used. The video stream (e.g., SCTE 35 stream) may also comprise a unique content identifier representing the underlying content. As such, a recipient device or downstream device, such as a linear transcoder, may receive the video stream and may condition the video stream based at least on the content identifier and the content boundary information to fragment the stream as necessary to align with one or more boundary points in the video stream. In turn, the linear packager may generate a manifest comprising at least the content identifier, the content boundary information, and information relating to the fragments that align with the content boundaries.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0005" num="0004">The following detailed description is better understood when read in conjunction with the appended drawings. For the purposes of illustration, examples are shown in the drawings; however, the subject matter is not limited to the specific elements and instrumentalities disclosed. In the drawings:</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a block diagram of an example of a system in accordance with aspects of the disclosure;</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a table of an example of data fields in accordance with aspects of the disclosure;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a flow chart of an exemplary method in accordance with aspects of the disclosure;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a flow chart of an exemplary method in accordance with aspects of the disclosure;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a flow chart of an exemplary method in accordance with aspects of the disclosure; and</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a block diagram of an exemplary computing device.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0012" num="0011">Methods and systems are described for managing recorded content in a system, such as a digital video recorder (DVR) or network digital video recorder (NDVR) system. Content boundary information may be included in a linear video stream to facilitate the alignment of downstream processes based on actual content (e.g., program, asset, item, etc.) start and end time, for example.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an exemplary system <b>100</b>, such as a cloud or network DVR system, by which a service provider, such as a cable television service provider, may receive a request to record content, store the requested content, and potentially fulfill a request to deliver the requested content for playback. Other systems such as local DVR system may implement the aspects of the present disclosure. Content may comprise a content asset or program, such as linear content, and may further comprise sequential content such as, for example, a television show, a movie, a sports event broadcast, or the like. As used herein, content may additionally include a portion of a program or content asset.</p><p id="p-0014" num="0013">The request to record content may be received from a device <b>132</b> and the requested content may be delivered to the device <b>132</b> for playback. As used herein, the device <b>132</b> may refer to a hardware element, such as a set-top cable box, a streaming-video player, or a quadrature amplitude modulation (QAM) client, or a software element, such as a web browser or other software adapted to playback video. It will be appreciated that the device <b>132</b> used to request that the content be recorded in the system <b>100</b> may be distinct from the device <b>132</b> used to receive the recorded content for playback. To illustrate, a user may use his or her local device (e.g., set-top cable box or other computing device) to request that a particular content be recorded in the system <b>100</b>, but may later request and playback the content with software running on his or her smart phone. The device <b>132</b> may be connected to the system <b>100</b> via any suitable network, which may comprise, for example, a cable network, satellite network, and/or the Internet.</p><p id="p-0015" num="0014">The system <b>100</b> may include a transcoder <b>114</b>. The transcoder <b>114</b> may receive content from a content source <b>112</b>. The content may be in any one of a variety of formats, such as, for example, H.264, MPEG-4 Part 2, or MPEG-2. The content may be transmitted using one or more standards such as SCTE 35 or other specifications. The transcoder <b>114</b> may convert the content from one video format to another video format, such as one amenable to the means by which the service provider's users view the content. The transcoder <b>114</b> may additionally segment the content into a plurality of segments. For example, content may be segmented into a series of 2-second segments, 10-second segments, or other fixed or variable time segments.</p><p id="p-0016" num="0015">Digital audio/video compression may be used, such as MPEG, or any other type of compression. Although reference may be made to example standards (e.g., MPEG) and formats, one of skill in the art will recognize that the systems and methods described herein are applicable to ant format or standard that support audio and/or video. As an example, the Moving Pictures Experts Group (MPEG) was established by the international Standards Organization (ISO) for the purpose of creating standards for digital audio/video compression. The combined MPEG-1, MPEG-2, and MPEG-4 standards are hereinafter referred to as MPEG. In an MPEG encoded transmission, content and other data are transmitted in packets, which collectively make up a transport stream. Additional information regarding transport stream packets, the composition of the transport stream, types of MPEG tables, and other aspects of the MPEG standards are described below. The present methods and systems may employ transmission of MPEG packets. However, the present methods and systems are not so limited, and may be implemented using other types of transmission and data.</p><p id="p-0017" num="0016">The output of a single MPEG audio and/or video coder may be referred to as a transport stream. The transport stream may comprise one or more elementary streams. An elementary stream may be or comprise an endless near real-time signal. For convenience, the elementary stream may be broken into data blocks of manageable size, forming a packetized elementary stream (PES). These data blocks need header information to identify the start of the packets and must include time stamps because packetizing disrupts the time axis. For transmission and digital broadcasting, for example, several programs (e.g., content assets) and their associated PESs may be multiplexed into a multi program transport stream. A multi program transport stream has a program clock reference (PCR) mechanism that allows transmission of multiple clocks, one of which may be selected and regenerated at the decoder.</p><p id="p-0018" num="0017">A multi program transport stream may comprise a multiplex of audio and video PESs. In addition to the compressed audio, video and data, a transport stream may comprise metadata describing the bit stream. Such metadata may comprise a program association table (PAT) that lists every content asset (e.g., program) in the multi program transport stream. Each entry in the PAT may point to a program map table (PMT) that lists the elementary streams making up each content asset. Some content may be unencrypted, but some content may be subject to conditional access (encryption) and this information is also carried in the metadata. The transport stream may be comprised of fixed-size data packets, for example, each containing <b>188</b> bytes. Each packet may carry a program identifier code (PID). Packets in the same elementary stream may all have the same PID, so that the decoder (or a demultiplexer) may select the elementary stream(s) it wants and reject the remainder. Packet continuity counts ensure that every packet that is needed to decode a stream is received. A synchronization system may be used so that decoders may correctly identify the beginning of each packet and deserialize the bit stream into words.</p><p id="p-0019" num="0018">A content asset, such as a program, may be a group of one or more PIDs that are related to each other. For instance, a multi program transport stream used in digital television might contain three programs, to represent three television channels. In some example, each channel may include one video stream, one or two audio streams, and any necessary metadata. A receiver wishing to tune to a particular &#x201c;channel&#x201d; merely has to decode the payload of the PIDs associated with its program. The receiver may discard the contents of all other PIDs.</p><p id="p-0020" num="0019">The multi program transport stream may carry many different programs and each may use a different compression factor and a bit rate that may change dynamically even though the overall bit rate stays constant. This behavior is called statistical multiplexing and it allows a program that is handling difficult material to borrow bandwidth from a program handling easy material. Each video PES may have a different number of audio and data PESs associated with it. Despite this flexibility, a decoder must be able to change from one program to the next and correctly select the appropriate audio and data channels. Some of the programs may be protected so that they may only be viewed by those who have paid a subscription or fee. The transport stream may comprise Conditional Access (CA) information to administer this protection. The transport stream may comprise Program Specific Information (PSI) to handle these tasks.</p><p id="p-0021" num="0020">To enable the splicing of compressed bit streams, certain specifications and/or standards such as SCTE 35 may define a splice event that indicates the opportunity to splice one or more elementary streams within a content asset (e.g., program). Each splice event may be uniquely identified with identifiers such as splice_event_id. Splice events may be communicated in various manners including, but not limited to: 1) scheduled ahead of time; 2) preroll warning may be given; or 3) a command may be given to execute the splice event at specified splice points. Data fields such as a command type field (e.g., splice_command_typefield) may be used to specify the type of message being sent. Depending on the value of this field, different constraints apply to the remaining syntax. For example, the following command types may be used with SCTE 35 based systems: splice_null( ) splice_schedule( ) splice_insert( ), time_signal( ) and bandwidth reservation( )</p><p id="p-0022" num="0021">In particular, a time signal mechanism such as the time_signal( )in SCTE 35 may be used to provide a time synchronized data delivery mechanism. The syntax of the time signal mechanism (e.g., time signal( ) allows for the synchronization of the information carried in this message with the System Time Clock (STC). The unique payload of the message is carried in the descriptor, however the syntax and transport capabilities may be afforded to message. Example syntax may include descriptor syntax such as a splice descriptor syntax.</p><p id="p-0023" num="0022">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, segmentation descriptor syntax (e.g., SCTE 35 or other standard or convention) may be used as an implementation of messaging syntax. Using SCTE 35 (2014), for example, the segmentation_descriptor( )<b>200</b> may be or comprise an implementation of a splice_descriptor( ) to provide an optional extension to the time_signal( ) and splice_insert( ) commands that allows for segmentation messages to be sent in a time/video accurate method. The various syntax, fields, and values of the same may be used to effect communication of information between devices and/or systems relating to the accurate recording of content such as programs. A such, content providers such as content creators, distributors, delivery services, and the like may insert content boundary information in a video stream using a SCTE-35 time signal mechanism comprising segmentation descriptors representing content boundaries and/or breaks in programming.</p><p id="p-0024" num="0023">In an aspect, a segmentation_upid( )<b>202</b> or similar context may be used to identify content or a content segment. The segmentation upid( )<b>202</b> or similar identifier may have a fixed or variable length. In a further aspect, the content segment may include a segmentation type identifier, such as segmentation_type_id <b>204</b> (SCTE 35). The segmentation type identifier (e.g., segmentation_type_id <b>204</b>) may indicate a message associated with an event (e.g., boundary point) in the segment of the underlying content. For example, the segmentation type identifier may indicate a content start, content end, content breakaway, content early termination, content resumption, content runover planned, content runover unplanned, content overlap start, content blackout override, advertisement start, advertisement end, etc. Other conventions and/or standards may be used to effect similar content identification and events in a video stream and/or audio stream. As such, recording decision by recipient devices may be based on the identified content and using the events (e.g., boundary points) to determine actual content start and end times.</p><p id="p-0025" num="0024">Returning to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the video stream (e.g., SCTE 35 stream) may comprise a unique content identifier representing the underlying content programing. As such, a recipient device or downstream device, such as the transcoder <b>114</b>, may receive the video stream and may condition the video stream based at least on the content identifier and the content boundary information to fragment the stream as necessary to align with one or more boundary points in the video stream. In turn, a linear packager <b>118</b> may generate a manifest comprising at least the content identifier, the content boundary information, and information relating to the fragments that align with the content boundaries.</p><p id="p-0026" num="0025">The transcoder <b>114</b> may be communicatively connected to a linear module <b>116</b>, which in turn may include the linear packager <b>118</b> and a linear storage <b>120</b>. The linear packager <b>118</b> and the linear storage <b>120</b> may be communicatively connected. It will be appreciated that the linear module <b>116</b> may refer generally to one or more interconnected servers, storage devices, logical elements, and the like.</p><p id="p-0027" num="0026">The linear packager <b>118</b> may receive the content from the transcoder <b>114</b> or the recording management system <b>124</b> (discussed further herein). The linear packager <b>118</b> may determine how the content is to be segmented and put together for delivery to and eventual playback by the device <b>132</b>. As part of this process, the linear packager <b>118</b> may segment the content (such as in the event that the content has not yet been segmented) or may re-segment the content (such as in the event that the content had been previously segmented). The linear packager <b>118</b> may additionally insert one or more cues or markers into the content segments at which one or more additional segments, such as segments comprising an advertisement, may be inserted by an upstream client, server, or logical module, such as the device <b>132</b> or the origin server <b>134</b>.</p><p id="p-0028" num="0027">The linear packager <b>118</b> may create a manifest file associated with the content. Generally, a manifest file may contain information describing various aspects of the associated content that may be useful for the device <b>132</b> to playback the content and/or for the recording management system <b>124</b> to store and retrieve the content. The manifest file may comprise at least the content identifier, the content boundary information, and information relating to the fragments that align with the content boundaries. The manifest file may indicate the segments comprising the content, the length of each segment, the number of segments, and/or the proper ordering of the segments necessary to effectuate a playback of the content. A manifest file may further include a network location (e.g., a hyper-text transfer protocol (HTTP) uniform resource locater (URL) link or other universal resource identifier (URI)) for each segment from which the segment may be downloaded, accessed, or retrieved. For example, the network location may indicate a location on the linear storage <b>120</b> or recording storage <b>128</b>. It will be appreciated that the network locations included within a manifest file may point to more than one different location or source.</p><p id="p-0029" num="0028">The network location for segments corresponding to the content may reference a location on the linear storage <b>120</b> while the network location for segments corresponding to an inserted advertisement may reference a location from outside the system <b>100</b>. In some instances, a manifest file may describe multiple versions (e.g., different quality levels) of the content, including corresponding information on those segments. A manifest file may be provided, such as by the origin server <b>134</b>, to the device <b>132</b> in response to a request to receive content recorded within the system <b>100</b>. The device <b>132</b> may use the manifest file to determine the segments required to play the content or a portion of the content and subsequently download the required segments using the network locations specified in the manifest file.</p><p id="p-0030" num="0029">The content or portions thereof may be stored in the linear storage <b>120</b>, which may be accessed by the device <b>132</b> directly or indirectly via the origin server <b>134</b> to deliver the content to the device <b>132</b>. The storage of the content or portions thereof may occur, in an aspect, after the linear packager <b>118</b> processes the content. The linear storage <b>120</b> may include one or more data storage devices, such as volatile memory (e.g., random access memory (RAM)), a hard disk drive, a network-attached storage (NAS), and/or a storage area network (SAN) upon which the content or portions thereof may be stored.</p><p id="p-0031" num="0030">A recording management system <b>124</b> may be communicatively connected to the linear module <b>116</b> and one or more devices <b>132</b>. The recording management system <b>124</b> may receive one or more requests from devices <b>132</b> to record content. The request to record content may include, for example, identifications of the user (e.g., an account identifier, a username, and/or a password), the device <b>132</b>, the content, the station, the stream, the start time of the content, and/or the end time of the content. Upon receiving a request to record content, the recording management system <b>124</b> may access the segmented content from the linear module <b>116</b> (e.g., the linear packager <b>118</b> and/or the linear storage <b>120</b>) and prepare to store a recording of the content in a communicatively connected recording storage <b>128</b>. The recording storage <b>128</b> may include one or more storage devices, such as a hard disk drive, a network-attached storage (NAS), and/or a storage area network (SAN).</p><p id="p-0032" num="0031">The recording management system <b>124</b> may include a recording scheduler <b>125</b>. The recording scheduler <b>125</b> may be configured to manage the requests to record that are received via the recording management system <b>124</b> or other component. The recording scheduler <b>125</b> or a component configured with similar operable capabilities may be stand-alone or may reside outside of the recording management system <b>124</b>, such as with the origin server <b>134</b>. The recording scheduler <b>125</b> may be configured to manage the transmission (e.g., assignment) of recording request to one or more recording agents <b>126</b><i>a</i>-<i>c</i>. Certain requests may be for an entire content asset (e.g., program) and may be marked appropriately as an entirety type recording, such as using the syntax &#x201c;RECORD ENTIRETY&#x201d; with a unique programming ID relating to the desired content for recording. Other syntax and requests may be processed via the recording scheduler <b>125</b> to effect recording of content.</p><p id="p-0033" num="0032">The recording management system <b>124</b> may include a plurality of the recording agents <b>126</b><i>a</i>-<i>c</i>, which may each represent a pool of resources available to independently perform a recording task, such as writing copies of a segment to the recording storage <b>128</b>. The recording management system <b>124</b> may track and maintain the status of each of the recording agents <b>126</b><i>a</i>-<i>c</i>. For example, the recording management system <b>124</b> may, at any given time, know which recording agents <b>126</b><i>a</i>-<i>c </i>are busy performing a recording task and which are available to be assigned a recording task to perform. As each of the recording agents <b>126</b><i>a</i>-<i>c </i>completes a recording task, the recording agent <b>126</b><i>a</i>-<i>c </i>may indicate to the recording management system <b>124</b> that the recording agent <b>126</b><i>a</i>-<i>c </i>is now available. In another aspect, each of the recording agents <b>126</b><i>a</i>-<i>c </i>may maintain each recording agents' <b>126</b><i>a</i>-<i>c </i>respective state (e.g., busy, available, etc.) instead of the recording management system <b>124</b> maintaining the state of each of the recording agents <b>126</b><i>a</i>-<i>c</i>. In such an aspect, a queue of available recording agents <b>126</b><i>a</i>-<i>c </i>may be maintained, such as by the recording management system <b>124</b>. When one of the recording agents <b>126</b><i>a</i>-<i>c</i>, such as recording agent <b>126</b><i>a</i>, becomes available, the recording agent <b>126</b><i>a </i>may insert itself into the queue. When the recording management system <b>124</b> has a task to be performed, the recording management system <b>124</b> may query the queue for the next available recording agent <b>126</b><i>a</i>-<i>c </i>and assign the task to that recording agent <b>126</b><i>a</i>-<i>c. </i></p><p id="p-0034" num="0033">The recording management system <b>124</b> may access, such as from the linear storage <b>120</b>, a segment of content that has been requested to be recorded. Based on this single access of the segment, the recording management system <b>124</b> may direct one of the available recording agents <b>126</b><i>a</i>-<i>c</i>, such as recording agent <b>126</b><i>a</i>, to write a copy of this segment to the recording storage <b>128</b> for each request for the content to be recorded. As an example, the recording agent <b>126</b><i>a </i>may provide an instruction, such as over a network socket, to the recording storage <b>128</b>, wherein the instruction specifies the file of the segment and the number of times that the file is to be copied to the recording storage <b>128</b>. The instruction may include an HTTP command, such as PUT, POST, or PATCH. In this manner, the segment is written multiple times to storage, but is accessed (i.e., read) only a single time. Thus, this may result in a performance increase of the recording management system <b>124</b> and the system <b>100</b> as a whole because the read operation of the segment from the linear storage <b>120</b> need only occur a single time for all the segment copies instead of once for each segment copy. When the recording agent <b>126</b><i>a </i>finishes writing the copies of the segment to the recording storage <b>128</b>, the recording agent <b>126</b><i>a </i>may indicate to the recording management system <b>124</b> that the recording agent <b>126</b><i>a </i>has successfully written the copies of the segment and that the recording agent <b>126</b><i>a </i>is available to perform another recording task. In the event that the recording agent <b>126</b><i>a </i>is unsuccessful in its task (e.g., the recording storage <b>128</b> indicates a disk error), the recording agent <b>126</b><i>a </i>may indicate so to the recording management system <b>124</b> and the recording management system <b>124</b> may direct the recording agent <b>126</b><i>a </i>to attempt to repeat the recording task or assign the recording task to another of the recording agents <b>126</b><i>a</i>-<i>c</i>, such as recording agent <b>126</b><i>b</i>. This process may be repeated until all of the segments of the content are copied to the recording storage <b>128</b> and there is a complete copy of the content in the recording storage <b>128</b> for each user request to record the content.</p><p id="p-0035" num="0034">The recording agents <b>126</b><i>a</i>-<i>c </i>may be configured to monitor the schedule of recordings (e.g., via the recording scheduler <b>125</b>) and may determine any changes with manifest via the linear packager <b>118</b>. The recording agents <b>126</b><i>a</i>-<i>c </i>may be configured to update scheduling information in a meta-data database <b>129</b>. The meta-data database <b>129</b> may be configured to store various forms of information including, but not limited to, scheduling information, recording and video playback data, and device, user, and/or content identifiers.</p><p id="p-0036" num="0035">In operation, the recording management system <b>124</b> may receive one or more linear video streams or fragments thereof. As the recording management system <b>124</b> receives request to record certain content, for example, based on a unique content identifier, the recording management system <b>124</b> may cause particular portions of the linear video stream to be recorded. For example, a user may request that content having a content identifier of &#x201c;Program One&#x201d; to be recording in its entirety. As such, the recording management system <b>124</b> may process the request and may schedule the recording. However, rather than simply recording a particular channel of content, the recording management system <b>124</b> may begin recording when a particular syntax or event code is detected in the linear video stream or fragments thereof. As a further example, the linear video stream may comprise of an SCTE-35 TimeSignal w/SegmentationDescriptor containing a segmentationTypeID of &#x201c;Content Start&#x201d; and the unique content identifier of &#x201c;Program One&#x201d; in the segmentationUpid field. As such, the unique content identifier is matched with the request to record and the recording will begin based on the fragment containing the marker that identifiers the &#x201c;Content Start.&#x201d; In this way, even if the content is delayed or is not aired on schedule, the recording management system <b>124</b> will cause the content to be recorded based on the boundary point information included in the video stream.</p><p id="p-0037" num="0036">It is possible for content programming to break and resume at a later time. For example, extreme weather conditions in sporting events may cause breaks in programming. In this case, the linear video stream may comprise a message (e.g., syntax) with marking that a break in programming is received (e.g., a SCTE 35 TimeSignal w/SegmentationDescriptor containing a &#x201c;Content Breakaway&#x201d; for the unique content identifier). As such, recordings may be paused and then started again once the break has ended and a message (e.g., SCTE-35 syntax) is received indicating that the continuation of the original programming (e.g., SCTE 35 TimeSignal w /SegmentationDescriptor containing a &#x201c;Content Resumption&#x201d; for the unique content identifier).</p><p id="p-0038" num="0037">Additional operations may be controlled using embedded syntax in the linear video stream, such as using SCTE-35 syntax. For example, a recording may be stopped for a request type &#x201c;RECORD_ENTIRETY&#x201d; when the unique programming associated with the scheduled recording changes on the linear stream. Such as change may occur when a new SCTE-35 embedded signal is received that marks the end of content boundary point for this unique content identifier. Other syntax may be used to indicate the end boundary point of a particular content associated with the unique content identifier.</p><p id="p-0039" num="0038">An archive storage <b>130</b> may be communicatively connected to the recording management system <b>124</b> and/or the recording storage <b>128</b>, and may include one or more storage devices, such as a hard disk drive, a network-attached storage (NAS), and/or a storage area network (SAN). The archive storage <b>130</b> may archive copies of content that have spent a certain amount of time in the recording storage <b>128</b>. That is, once a certain amount of time passes since content has been recorded and copies made in the recording storage <b>128</b>, the copies in the recording storage <b>128</b> may be deleted and a single copy may be made in the archive storage <b>130</b>. If the archived content is requested by a user to be delivered to the device <b>132</b> of the user for playback, the recording management system <b>124</b> may access the copy of the content in the archive storage <b>130</b> and make a new copy of the content in the recording storage <b>128</b>. The copy of the content in the recording storage <b>128</b> may then be delivered to the device <b>132</b> of the user, either directly or via the origin server <b>134</b>, which may be communicatively connected to the recording storage <b>128</b> directly or via the recording management system <b>124</b>.</p><p id="p-0040" num="0039">In an aspect, the segmented nature of the content may be leveraged to begin delivering the content from the recording storage <b>128</b> to the device <b>132</b> before the content is completely copied over from the archive storage <b>130</b>. In this instance, when a user requests delivery of content archived in the archive storage <b>130</b>, the recording management system <b>124</b> may begin by copying the first segment of the content to the recording storage <b>128</b>. The origin server <b>134</b> need not wait until all of the segments of the content are copied to the recording storage <b>128</b> before beginning to deliver the content to the device <b>132</b>, but may instead begin delivering the segments of the content when the first segment (or otherwise sufficient beginning subset of the segments) is copied to the recording storage <b>128</b>. The recording management system <b>124</b> may then continue copying subsequent segments (e.g., the second segment, the third segment, and so forth) of the content to the recording storage <b>128</b>, which may then be delivered to the device <b>132</b>. Preferably, the subsequent segments may be copied from the recording storage <b>128</b> to the archive storage <b>130</b> and delivered to the device <b>132</b> at a rate sufficient for the playback of the segments on the device <b>132</b> to be seamlessly maintained. If the playback on the device <b>132</b> is stopped or paused and no additional segments of the content are requested, a full duplicate copy may still be created. Thus in this instance, the recording management system <b>124</b> may determine the segments of the content that do not need to be delivered to the device <b>132</b> (e.g., segments preceding a mid-program playback start point, segments that are skipped during playback, such as those for a commercial, and segments subsequent to a playback stop point) and have not yet been copied to the recording storage <b>128</b>. Those segments may then be copied from the archive storage <b>130</b> to the recording storage <b>128</b> to reconstitute the entire unique copy of the content.</p><p id="p-0041" num="0040">The origin server <b>134</b> may receive and fulfill a request from the device <b>132</b> of a user to deliver a recorded content to the device <b>132</b> for playback. The request from the device <b>132</b> to deliver the recorded content may include identifications of the user (e.g., an account identifier, a username and/or a password), the device <b>132</b>, the requested content, and/or a playback time point or temporal location (e.g., the start of a asset or the 12:30 mark in a 30:00 asset). In certain aspects, the request to deliver the content may reflect a user skipping to a particular portion of content of which the initial segments of the content have already been delivered and are being played on the device <b>132</b>. For example, a user may have started viewing the first minute of a content asset and then decided to skip to a midway point of the content asset. In this case, the request to deliver the content asset would indicate that the device <b>132</b> required the segments of the content asset from that midway point and after. Upon receiving a request to deliver a recorded content to the device <b>132</b>, the origin server <b>134</b> may provide one or more manifest files (discussed further herein) to the device <b>132</b> that describe the content and segments thereof, including network locations from which each segment may be downloaded. Using the manifest file, the device <b>132</b> may iteratively download the segments comprising the content. As the device <b>132</b> downloads sufficient segments of the content, the device <b>132</b> may begin playback of the content.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example flow chart for a method <b>300</b>. At step <b>302</b>, a video (e.g., video stream) such as a linear video stream may be received or accessed. The video may comprise a content asset and content information. The video may be or comprise a MPEG transport stream. The video may comprise of a time signal mechanism in accordance with SCTE 35 and at least a portion of the content information is associated with the time signal mechanism. The video may comprise a segmentation descriptor mechanism in accordance with SCTE 35 and at least a portion of the content information is associated with the segmentation descriptor mechanism.</p><p id="p-0043" num="0042">At step <b>304</b>, a content identifier may be determined. The content identifier may be a unique identifier associated with the content. The content identifier may relate to the content and may be determined based on at least the content information. As an example, the content identifier may be embedded in the video (e.g., linear video stream), for example, using a data field such as &#x201c;segmentationUpid&#x201d; or other syntax receiving field. As such a device receiving the video may extract the information in a specific data field or in general metadata or headers in order to determine the content identifier.</p><p id="p-0044" num="0043">At step <b>306</b>, a boundary point of the content may be determined. As an example, the boundary point may be determined based on at least the content information. The boundary point may be or comprise a start point, an end point, a break point, or the like. As an example, the content information may embedded in the video as a SCTE-35 TimeSignal w/SegmentationDescriptor containing a segmentationTypeID that indicates a boundary (e.g., Content Start).</p><p id="p-0045" num="0044">At step <b>308</b>, the video (e.g., linear video stream) may be conditioned based on at least the content identifier and the boundary point. Conditioning the video may comprise fragmenting the video and generating a manifest relating to the fragmented video, wherein the manifest comprises at least a portion of the content information.</p><p id="p-0046" num="0045">The conditioning the video may facilitate the recording of the content based on at least the determined content identifier and the determined boundary point independent of a scheduled time of delivery of the content. For example, the content may be delivered to a recipient device based on a predefined schedule, such as a programming schedule associated with one or more programming channels. However, the actual transmittal of the content for display at the recipient device may be off the pre-defined schedule due to various reasons such as content over-run or delay. As such, a recording based on the predefined schedule may capture an unintended portion of content. Since, the content of the present disclosure is conditioned based on an actual boundary of the content, the recipient device may schedule a recording based on at least the content identifier and the determined content boundary. Accordingly, the recording may capture the start and end of the content (e.g., content asset) with accuracy regardless of the predetermined schedule of transmittal and/or any delays or extensions of programming.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example flow chart for a method <b>400</b>. At step <b>402</b>, a request to record content may be received or accessed. As an example, and with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the recording management system <b>124</b> may receive one or more requests from devices <b>132</b> to record content. The request to record content may include, for example, identifications of the user (e.g., an account identifier, a username, and/or a password), the device <b>132</b>, the content, the station, the stream, the start time of the content, and/or the end time of the content. Upon receiving a request to record content, the recording management system <b>124</b> may access the segmented content from the linear module <b>116</b> (e.g., the linear packager <b>118</b> and/or the linear storage <b>120</b>) and prepare to store a recording of the content in a communicatively connected recording storage <b>128</b>. The recording storage <b>128</b> may include one or more storage devices, such as a hard disk drive, a network-attached storage (NAS), and/or a storage area network (SAN).</p><p id="p-0048" num="0047">At step <b>404</b>, a video such as a linear video stream may be received or accessed. The linear video stream may comprise content (e.g., content assets) and content information. The linear video stream may be or comprise a MPEG transport stream. The linear video stream may comprise a time signal mechanism in accordance with SCTE <b>35</b> and at least a portion of the content information is associated with the time signal mechanism. The linear video stream may comprise a segmentation descriptor mechanism in accordance with SCTE <b>35</b> and at least a portion of the content information is associated with the segmentation descriptor mechanism.</p><p id="p-0049" num="0048">At step <b>406</b>, a content identifier may be determined. The content identifier may be a unique identifier associated with the content. The content identifier may relate to the content (e.g., content asset) and may be determined based on at least the content information. As an example, the content identifier may be embedded in the linear video stream, for example, using a data field such as &#x201c;segmentationUpid&#x201d; or other syntax receiving field.</p><p id="p-0050" num="0049">At step <b>408</b>, a boundary point of the content may be determined. As an example, the boundary point may be determined based on at least the content information. The boundary point may be or comprise a start point, an end point, a break point, or the like. As an example, the content information may embedded in the linear video stream as a SCTE-35 TimeSignal w/SegmentationDescriptor containing a segmentationTypeID that indicates a boundary (e.g., Content Start).</p><p id="p-0051" num="0050">At step <b>410</b>, at least a portion of the content may be caused to be recorded, for example, using the determined content identifier and the determined boundary point of the content. Causing at least a portion of the content to be recorded may comprise storing at least the portion of the content in memory. As an example, and with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the recording management system <b>124</b> may access, such as from the linear storage <b>120</b>, a segment of content that has been requested to be recorded. Based on this single access of the segment, the recording management system <b>124</b> may direct one of the available recording agents <b>126</b><i>a</i>-<i>c</i>, such as recording agent <b>126</b><i>a</i>, to write a copy of this segment to the recording storage <b>128</b> for each request for the content to be recorded. When the recording agent <b>126</b><i>a </i>finishes writing the copies of the segment to the recording storage <b>128</b>, the recording agent <b>126</b><i>a </i>may indicate to the recording management system <b>124</b> that the recording agent <b>126</b><i>a </i>has successfully written the copies of the segment and that the recording agent <b>126</b><i>a </i>is available to perform another recording task. In the event that the recording agent <b>126</b><i>a </i>is unsuccessful in its task (e.g., the recording storage <b>128</b> indicates a disk error), the recording agent <b>126</b><i>a </i>may indicate so to the recording management system <b>124</b> and the recording management system <b>124</b> may direct the recording agent <b>126</b><i>a </i>to attempt to repeat the recording task or assign the recording task to another of the recording agents <b>126</b><i>a</i>-<i>c</i>, such as recording agent <b>126</b><i>b</i>. This process may be repeated until all of the segments of the content are copied to the recording storage <b>128</b> and there is a complete copy of the content in the recording storage <b>128</b> for each user request to record the content.</p><p id="p-0052" num="0051">In certain aspects, the video stream including the content intended to be recorded may be delivered to a recipient device based on a predefined schedule, such as a programming schedule associated with one or more content channels. However, the actual transmittal of the content for display at the recipient device may be off the pre-defined schedule due to various reasons such as content over-run or delay. As such, a recording based on the predefined schedule may capture an unintended portion of content. Since, the video stream of the present disclosure is conditioned based on an actual boundary of the content, the recipient device may schedule a recording based on at least the content identifier and the determined content boundary. Accordingly, the recording may capture the start and end of the content with accuracy regardless of the predetermined schedule of transmittal and/or any delays or extensions.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example flow chart for a method <b>500</b>. At step <b>502</b>, information relating to one or more recording operations may be accessed or received. As an example, and with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the recording management system <b>124</b> may receive one or more requests from devices <b>132</b> to record content. The request to record content may include, for example, identifications of the user (e.g., an account identifier, a username, and/or a password), the device <b>132</b>, the content, the station, the stream, the start time of the content, and/or the end time of the content. Upon receiving a request to record content, the recording management system <b>124</b> may access the segmented content from the linear module <b>116</b> (e.g., the linear packager <b>118</b> and/or the linear storage <b>120</b>) and prepare to store a recording of the content in a communicatively connected recording storage <b>128</b>. The recording storage <b>128</b> may include one or more storage devices, such as a hard disk drive, a network-attached storage (NAS), and/or a storage area network (SAN).</p><p id="p-0054" num="0053">As a further example, the recording management system <b>124</b> may include a recording scheduler <b>125</b>. The recording scheduler <b>125</b> may be configured to manage the requests to record that are received via the recording management system <b>124</b> or other component. The recording scheduler <b>125</b> or a component configured with similar operable capabilities may be stand-alone or may reside outside of the recording management system <b>124</b>, such as with the origin server <b>134</b>. The recording scheduler <b>125</b> may be configured to manage the transmission (e.g., assignment) of recording request to one or more recording agents <b>126</b><i>a</i>-<i>c</i>. Certain requests may be for an entire content asset and may be marked appropriately as an entirety type recording, such as using the syntax &#x201c;RECORD_ENTIRETY&#x201d; with a unique content ID relating to the desired content for recording. Other syntax and requests may be processed via the recording scheduler <b>125</b> to effect recording of content.</p><p id="p-0055" num="0054">At step <b>504</b>, an indication that video (e.g., linear video stream) is being transmitted may be received or accessed. The video may comprise content and content information. The video may be or comprise a MPEG transport stream. The video may comprise a time signal mechanism in accordance with SCTE 35 and at least a portion of the content information is associated with the time signal mechanism. The video may comprise a segmentation descriptor mechanism in accordance with SCTE 35 and at least a portion of the content information is associated with the segmentation descriptor mechanism.</p><p id="p-0056" num="0055">At step <b>506</b>, a boundary point of the content may be determined. As an example, the boundary point may be determined based on at least the content information. The boundary point may be or comprise a start point, an end point, a break point, a resumption point, or the like. As an example, the content information may be embedded in the linear video stream as a SCTE-35 TimeSignal w/SegmentationDescriptor containing a segmentationTypeID that indicates a boundary (e.g., Content Start).</p><p id="p-0057" num="0056">At step <b>508</b>, at least a portion of the content may be caused to be recorded, for example, using the determined content identifier and the determined boundary point of the content. Causing at least a portion of the content to be recorded may comprise storing at least the portion of the content in memory. As an example, and with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the recording management system <b>124</b> may access, such as from the linear storage <b>120</b>, a segment of content that has been requested to be recorded. Based on this single access of the segment, the recording management system <b>124</b> may direct one of the available recording agents <b>126</b><i>a</i>-<i>c</i>, such as recording agent <b>126</b><i>a</i>, to write a copy of this segment to the recording storage <b>128</b> for each request for the content to be recorded. When the recording agent <b>126</b><i>a </i>finishes writing the copies of the segment to the recording storage <b>128</b>, the recording agent <b>126</b><i>a </i>may indicate to the recording management system <b>124</b> that the recording agent <b>126</b><i>a </i>has successfully written the copies of the segment and that the recording agent <b>126</b><i>a </i>is available to perform another recording task. In the event that the recording agent <b>126</b><i>a </i>is unsuccessful in its task (e.g., the recording storage <b>128</b> indicates a disk error), the recording agent <b>126</b><i>a </i>may indicate so to the recording management system <b>124</b> and the recording management system <b>124</b> may direct the recording agent <b>126</b><i>a </i>to attempt to repeat the recording task or assign the recording task to another of the recording agents <b>126</b><i>a</i>-<i>c</i>, such as recording agent <b>126</b><i>b</i>. This process may be repeated until all of the segments of the content are copied to the recording storage <b>128</b> and there is a complete copy of the content in the recording storage <b>128</b> for each user request to record the content.</p><p id="p-0058" num="0057">In certain aspects, since the video of the present disclosure is conditioned to include an identification of the content identifier and an actual boundary of the content, a recipient device may manage a recording based on at least the content identifier and the determined content boundary. Accordingly, the recording may capture the start and end of the content with accuracy regardless of the predetermined schedule of transmittal and/or any delays or extensions.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts a computing device that may be used in various aspects, such as the servers, modules, and/or devices depicted in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. With regard to the example architecture of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the transcoder <b>114</b>, the linear module <b>116</b>, the linear packager <b>118</b>, the linear storage <b>120</b>, the recording management system <b>124</b>, the recording agents <b>126</b><i>a</i>-<i>c</i>, the recording storage <b>128</b>, the archive storage <b>130</b>, the origin server <b>134</b>, and/or the device <b>132</b> may each be implemented in an instance of a computing device <b>600</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The computer architecture shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a conventional server computer, workstation, desktop computer, laptop, tablet, network appliance, PDA, e-reader, digital cellular phone, or other computing node, and may be utilized to execute any aspects of the computers described herein, such as to implement the methods described in relation to <figref idref="DRAWINGS">FIGS. <b>3</b>, <b>4</b>, and <b>5</b></figref>.</p><p id="p-0060" num="0059">The computing device <b>600</b> may include a baseboard, or &#x201c;motherboard,&#x201d; which is a printed circuit board to which a multitude of components or devices may be connected by way of a system bus or other electrical communication paths. One or more central processing units (CPUs) <b>604</b> may operate in conjunction with a chipset <b>606</b>. The CPU(s) <b>604</b> may be standard programmable processors that perform arithmetic and logical operations necessary for the operation of the computing device <b>600</b>.</p><p id="p-0061" num="0060">The CPU(s) <b>604</b> may perform the necessary operations by transitioning from one discrete physical state to the next through the manipulation of switching elements that differentiate between and change these states. Switching elements may generally include electronic circuits that maintain one of two binary states, such as flip-flops, and electronic circuits that provide an output state based on the logical combination of the states of one or more other switching elements, such as logic gates. These basic switching elements may be combined to create more complex logic circuits including registers, adders-subtractors, arithmetic logic units, floating-point units, and the like.</p><p id="p-0062" num="0061">The CPU(s) <b>604</b> may be augmented with or replaced by other processing units, such as GPU(s) <b>605</b>. The GPU(s) <b>605</b> may comprise processing units specialized for but not necessarily limited to highly parallel computations, such as graphics and other visualization-related processing.</p><p id="p-0063" num="0062">A chipset <b>606</b> may provide an interface between the CPU(s) <b>604</b> and the remainder of the components and devices on the baseboard. The chipset <b>606</b> may provide an interface to a random access memory (RAM) <b>608</b> used as the main memory in the computing device <b>600</b>. The chipset <b>606</b> may further provide an interface to a computer-readable storage medium, such as a read-only memory (ROM) <b>620</b> or non-volatile RAM (NVRAM) (not shown), for storing basic routines that may help to start up the computing device <b>600</b> and to transfer information between the various components and devices. ROM <b>620</b> or NVRAM may also store other software components necessary for the operation of the computing device <b>600</b> in accordance with the aspects described herein.</p><p id="p-0064" num="0063">The computing device <b>600</b> may operate in a networked environment using logical connections to remote computing nodes and computer systems through local area network (LAN) <b>616</b>. The chipset <b>606</b> may include functionality for providing network connectivity through a network interface controller (NIC) <b>622</b>, such as a gigabit Ethernet adapter. A NIC <b>622</b> may be capable of connecting the computing device <b>600</b> to other computing nodes over a network <b>616</b>. It should be appreciated that multiple NICs <b>622</b> may be present in the computing device <b>600</b>, connecting the computing device to other types of networks and remote computer systems.</p><p id="p-0065" num="0064">The computing device <b>600</b> may be connected to a mass storage device <b>628</b> that provides non-volatile storage for the computer. The mass storage device <b>628</b> may store system programs, application programs, other program modules, and data, which have been described in greater detail herein. The mass storage device <b>628</b> may be connected to the computing device <b>600</b> through a storage controller <b>624</b> connected to the chipset <b>606</b>. The mass storage device <b>628</b> may consist of one or more physical storage units. A storage controller <b>624</b> may interface with the physical storage units through a serial attached SCSI (SAS) interface, a serial advanced technology attachment (SATA) interface, a fiber channel (FC) interface, or other type of interface for physically connecting and transferring data between computers and physical storage units.</p><p id="p-0066" num="0065">The computing device <b>600</b> may store data on a mass storage device <b>628</b> by transforming the physical state of the physical storage units to reflect the information being stored. The specific transformation of a physical state may depend on various factors and on different implementations of this description. Examples of such factors may include, but are not limited to, the technology used to implement the physical storage units and whether the mass storage device <b>628</b> is characterized as primary or secondary storage and the like.</p><p id="p-0067" num="0066">For example, the computing device <b>600</b> may store information to the mass storage device <b>628</b> by issuing instructions through a storage controller <b>624</b> to alter the magnetic characteristics of a particular location within a magnetic disk drive unit, the reflective or refractive characteristics of a particular location in an optical storage unit, or the electrical characteristics of a particular capacitor, transistor, or other discrete component in a solid-state storage unit. Other transformations of physical media are possible without departing from the scope and spirit of the present description, with the foregoing examples provided only to facilitate this description. The computing device <b>600</b> may further read information from the mass storage device <b>628</b> by detecting the physical states or characteristics of one or more particular locations within the physical storage units.</p><p id="p-0068" num="0067">In addition to the mass storage device <b>628</b> described above, the computing device <b>600</b> may have access to other computer-readable storage media to store and retrieve information, such as program modules, data structures, or other data. It should be appreciated by those skilled in the art that computer-readable storage media may be any available media that provides for the storage of non-transitory data and that may be accessed by the computing device <b>600</b>.</p><p id="p-0069" num="0068">By way of example and not limitation, computer-readable storage media may include volatile and non-volatile, transitory computer-readable storage media and non-transitory computer-readable storage media, and removable and non-removable media implemented in any method or technology. Computer-readable storage media includes, but is not limited to, RAM, ROM, erasable programmable ROM (&#x201c;EPROM&#x201d;), electrically erasable programmable ROM (&#x201c;EEPROM&#x201d;), flash memory or other solid-state memory technology, compact disc ROM (&#x201c;CD-ROM&#x201d;), digital versatile disk (&#x201c;DVD&#x201d;), high definition DVD (&#x201c;HD-DVD&#x201d;), BLU-RAY, or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage, other magnetic storage devices, or any other medium that may be used to store the desired information in a non-transitory fashion.</p><p id="p-0070" num="0069">A mass storage device, such as the mass storage device <b>628</b> depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, may store an operating system utilized to control the operation of the computing device <b>600</b>. The operating system may comprise a version of the LINUX operating system. The operating system may comprise a version of the WINDOWS SERVER operating system from the MICROSOFT Corporation. According to further aspects, the operating system may comprise a version of the UNIX operating system. Various mobile phone operating systems, such as IOS and ANDROID, may also be utilized. It should be appreciated that other operating systems may also be utilized. The mass storage device <b>628</b> may store other system or application programs and data utilized by the computing device <b>600</b>.</p><p id="p-0071" num="0070">The mass storage device <b>628</b> or other computer-readable storage media may also be encoded with computer-executable instructions, which, when loaded into the computing device <b>600</b>, transforms the computing device from a general-purpose computing system into a special-purpose computer capable of implementing the aspects described herein. These computer-executable instructions transform the computing device <b>600</b> by specifying how the CPU(s) <b>604</b> transition between states, as described above. The computing device <b>600</b> may have access to computer-readable storage media storing computer-executable instructions, which, when executed by the computing device <b>600</b>, may perform the methods described in relation to <figref idref="DRAWINGS">FIGS. <b>3</b>-<b>5</b></figref>.</p><p id="p-0072" num="0071">A computing device, such as the computing device <b>600</b> depicted in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, may also include an input/output controller <b>632</b> for receiving and processing input from a number of input devices, such as a keyboard, a mouse, a touchpad, a touch screen, an electronic stylus, or other type of input device. Similarly, an input/output controller <b>632</b> may provide output to a display, such as a computer monitor, a flat-panel display, a digital projector, a printer, a plotter, or other type of output device. It will be appreciated that the computing device <b>600</b> may not include all of the components shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, may include other components that are not explicitly shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, or may utilize an architecture completely different than that shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p><p id="p-0073" num="0072">As described herein, a computing device may be a physical computing device, such as the computing device <b>600</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref>. A computing node may also include a virtual machine host process and one or more virtual machine instances. Computer-executable instructions may be executed by the physical hardware of a computing device indirectly through interpretation and/or execution of instructions stored and executed in the context of a virtual machine.</p><p id="p-0074" num="0073">It is to be understood that the methods and systems are not limited to specific methods, specific components, or to particular implementations. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting.</p><p id="p-0075" num="0074">As used in the specification and the appended claims, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; include plural referents unless the context clearly dictates otherwise. Ranges may be expressed herein as from &#x201c;about&#x201d; one particular value, and/or to &#x201c;about&#x201d; another particular value. When such a range is expressed, another embodiment includes from the one particular value and/or to the other particular value. Similarly, when values are expressed as approximations, by use of the antecedent &#x201c;about,&#x201d; it will be understood that the particular value forms another embodiment. It will be further understood that the endpoints of each of the ranges are significant both in relation to the other endpoint, and independently of the other endpoint.</p><p id="p-0076" num="0075">&#x201c;Optional&#x201d; or &#x201c;optionally&#x201d; means that the subsequently described event or circumstance may or may not occur, and that the description includes instances where said event or circumstance occurs and instances where it does not.</p><p id="p-0077" num="0076">Throughout the description and claims of this specification, the word &#x201c;comprise&#x201d; and variations of the word, such as &#x201c;comprising&#x201d; and &#x201c;comprises,&#x201d; means &#x201c;including but not limited to,&#x201d; and is not intended to exclude, for example, other components, integers or steps. &#x201c;Exemplary&#x201d; means &#x201c;an example of&#x201d; and is not intended to convey an indication of a preferred or ideal embodiment. &#x201c;Such as&#x201d; is not used in a restrictive sense, but for explanatory purposes.</p><p id="p-0078" num="0077">Components are described that may be used to perform the described methods and systems. When combinations, subsets, interactions, groups, etc., of these components are described, it is understood that while specific references to each of the various individual and collective combinations and permutations of these may not be explicitly described, each is specifically contemplated and described herein, for all methods and systems. This applies to all aspects of this application including, but not limited to, operations in described methods. Thus, if there are a variety of additional operations that may be performed it is understood that each of these additional operations may be performed with any specific embodiment or combination of embodiments of the described methods.</p><p id="p-0079" num="0078">The present methods and systems may be understood more readily by reference to the following detailed description of preferred embodiments and the examples included therein and to the Figures and their descriptions.</p><p id="p-0080" num="0079">As will be appreciated by one skilled in the art, the methods and systems may take the form of an entirely hardware embodiment, an entirely software embodiment, or an embodiment combining software and hardware aspects. Furthermore, the methods and systems may take the form of a computer program product on a computer-readable storage medium having computer-readable program instructions (e.g., computer software) embodied in the storage medium. More particularly, the present methods and systems may take the form of web-implemented computer software. Any suitable computer-readable storage medium may be utilized including hard disks, CD-ROMs, optical storage devices, or magnetic storage devices.</p><p id="p-0081" num="0080">Embodiments of the methods and systems are described below with reference to block diagrams and flowchart illustrations of methods, systems, apparatuses and computer program products. It will be understood that each block of the block diagrams and flowchart illustrations, and combinations of blocks in the block diagrams and flowchart illustrations, respectively, may be implemented by computer program instructions. These computer program instructions may be loaded on a general-purpose computer, special-purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions which execute on the computer or other programmable data processing apparatus create a means for implementing the functions specified in the flowchart block or blocks.</p><p id="p-0082" num="0081">These computer program instructions may also be stored in a computer-readable memory that may direct a computer or other programmable data processing apparatus to function in a particular manner, such that the instructions stored in the computer-readable memory produce an article of manufacture including computer-readable instructions for implementing the function specified in the flowchart block or blocks. The computer program instructions may also be loaded onto a computer or other programmable data processing apparatus to cause a series of operational steps to be performed on the computer or other programmable apparatus to produce a computer-implemented process such that the instructions that execute on the computer or other programmable apparatus provide steps for implementing the functions specified in the flowchart block or blocks.</p><p id="p-0083" num="0082">The various features and processes described above may be used independently of one another, or may be combined in various ways. All possible combinations and sub-combinations are intended to fall within the scope of this disclosure. In addition, certain methods or process blocks may be omitted in some implementations. The methods and processes described herein are also not limited to any particular sequence, and the blocks or states relating thereto may be performed in other sequences that are appropriate. For example, described blocks or states may be performed in an order other than that specifically described, or multiple blocks or states may be combined in a single block or state. The example blocks or states may be performed in serial, in parallel, or in some other manner. Blocks or states may be added to or removed from the described example embodiments. The example systems and components described herein may be configured differently than described. For example, elements may be added to, removed from, or rearranged compared to the described example embodiments.</p><p id="p-0084" num="0083">It will also be appreciated that various items are illustrated as being stored in memory or on storage while being used, and that these items or portions thereof may be transferred between memory and other storage devices for purposes of memory management and data integrity. Alternatively, in other embodiments, some or all of the software modules and/or systems may execute in memory on another device and communicate with the illustrated computing systems via inter-computer communication. Furthermore, in some embodiments, some or all of the systems and/or modules may be implemented or provided in other ways, such as at least partially in firmware and/or hardware, including, but not limited to, one or more application-specific integrated circuits (&#x201c;ASICs&#x201d;), standard integrated circuits, controllers (e.g., by executing appropriate instructions, and including microcontrollers and/or embedded controllers), field-programmable gate arrays (&#x201c;FPGAs&#x201d;), complex programmable logic devices (&#x201c;CPLDs&#x201d;), etc. Some or all of the modules, systems, and data structures may also be stored (e.g., as software instructions or structured data) on a computer-readable medium, such as a hard disk, a memory, a network, or a portable media article to be read by an appropriate device or via an appropriate connection. The systems, modules, and data structures may also be transmitted as generated data signals (e.g., as part of a carrier wave or other analog or digital propagated signal) on a variety of computer-readable transmission media, including wireless-based and wired/cable-based media, and may take a variety of forms (e.g., as part of a single or multiplexed analog signal, or as multiple discrete digital packets or frames). Such computer program products may also take other forms in other embodiments. Accordingly, the present invention may be practiced with other computer system configurations.</p><p id="p-0085" num="0084">While the methods and systems have been described in connection with preferred embodiments and specific examples, it is not intended that the scope be limited to the particular embodiments set forth, as the embodiments herein are intended in all respects to be illustrative rather than restrictive.</p><p id="p-0086" num="0085">Unless otherwise expressly stated, it is in no way intended that any method set forth herein be construed as requiring that its operations be performed in a specific order. Accordingly, where a method claim does not actually recite an order to be followed by its operations or it is not otherwise specifically stated in the claims or descriptions that the operations are to be limited to a specific order, it is no way intended that an order be inferred, in any respect. This holds for any possible non-express basis for interpretation, including: matters of logic with respect to arrangement of steps or operational flow; plain meaning derived from grammatical organization or punctuation; and the number or type of embodiments described in the specification.</p><p id="p-0087" num="0086">It will be apparent to those skilled in the art that various modifications and variations may be made without departing from the scope or spirit of the present disclosure. Other embodiments will be apparent to those skilled in the art from consideration of the specification and practices described herein. It is intended that the specification and example figures be considered as exemplary only, with a true scope and spirit being indicated by the following claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method comprising:<claim-text>receiving, at a computing device, a request to record a content asset;</claim-text><claim-text>receiving video content comprising the content asset and content information;</claim-text><claim-text>determining, based at least on the content information, a content identifier relating to the content asset;</claim-text><claim-text>determining, based at least on the content information, a boundary point of the content asset;</claim-text><claim-text>determining a first location of a stored portion of the content asset; and</claim-text><claim-text>causing, based on the content identifier and the boundary point of the content asset, at least the stored portion of the content asset to be stored at a second location.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein causing the at least the stored portion of the content asset to be stored at the second location comprises writing a copy of the at least the stored portion of the content asset:</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving an indication the at least the stored portion of the content asset is successfully stored at the second location.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving an indication the at least the stored portion of the content asset is failed to be stored at the second location; and</claim-text><claim-text>causing, based on the content identifier and the boundary point of the content asset, the at least the stored portion of the content asset to be stored at a third location.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the indication comprises a disk error indication.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the video stream comprises an MPEG transport stream.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the video stream comprises a time signal mechanism in accordance with SCTE <b>35</b> and wherein at least a portion of the content information is associated with the time signal mechanism.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. An apparatus comprising:<claim-text>one or more processors; and</claim-text><claim-text>memory storing computer executable instructions that, when executed, cause the apparatus to:<claim-text>receive a request to record a content asset;</claim-text><claim-text>receive video content comprising the content asset and content information;</claim-text><claim-text>determine, based at least on the content information, a content identifier relating to the content asset;</claim-text><claim-text>determine, based at least on the content information, a boundary point of the content asset;</claim-text><claim-text>determine a first location of a stored portion of the content asset; and</claim-text><claim-text>cause, based on the content identifier and the boundary point of the content asset, at least the stored portion of the content asset to be stored at a second location.</claim-text></claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein causing the at least the stored portion of the content asset to be stored at the second location comprises writing a copy of the at least the stored portion of the content asset:</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the computer executable instructions, when executed, further cause the apparatus to:<claim-text>receive an indication the at least the stored portion of the content asset is successfully stored at the second location.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the computer executable instructions, when executed, further cause the apparatus to:<claim-text>receive an indication the at least the stored portion of the content asset is failed to be stored at the second location; and</claim-text><claim-text>cause, based on the content identifier and the boundary point of the content asset, the at least the stored portion of the content asset to be stored at a third location.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The apparatus of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the indication comprises a disk error indication.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the video stream comprises an MPEG transport stream.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The apparatus of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the video stream comprises a time signal mechanism in accordance with SCTE <b>35</b> and wherein at least a portion of the content information is associated with the time signal mechanism.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A non-transitory computer-readable medium storing instructions that, when executed, cause:<claim-text>receiving, at a computing device, a request to record a content asset;</claim-text><claim-text>receiving video content comprising the content asset and content information;</claim-text><claim-text>determining, based at least on the content information, a content identifier relating to the content asset;</claim-text><claim-text>determining, based at least on the content information, a boundary point of the content asset;</claim-text><claim-text>determining a first location of a stored portion of the content asset; and</claim-text><claim-text>causing, based on the content identifier and the boundary point of the content asset, at least the stored portion of the content asset to be stored at a second location.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein causing the at least the stored portion of the content asset to be stored at the second location comprises writing a copy of the at least the stored portion of the content asset:</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the instructions, when executed, further cause:<claim-text>receiving an indication the at least the stored portion of the content asset is successfully stored at the second location.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the instructions, when executed, further cause:<claim-text>receiving an indication the at least the stored portion of the content asset is failed to be stored at the second location; and</claim-text><claim-text>causing, based on the content identifier and the boundary point of the content asset, the at least the stored portion of the content asset to be stored at a third location.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the indication comprises a disk error indication.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the video stream comprises an MPEG transport stream.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005457A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005457</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17778256</doc-number><date>20201119</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>FR</country><doc-number>FR1912935</doc-number><date>20191120</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>H</subclass><main-group>1</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>33</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>271</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>204</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>041</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>H</subclass><main-group>1</main-group><subgroup>055</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>045</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>1</main-group><subgroup>0008</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>33</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>271</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>13</main-group><subgroup>204</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0414</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>017</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>1</main-group><subgroup>0558</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>045</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>2220</main-group><subgroup>161</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>2220</main-group><subgroup>201</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>2220</main-group><subgroup>455</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>2220</main-group><subgroup>026</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>H</subclass><main-group>2210</main-group><subgroup>155</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">SYSTEM FOR GENERATING A SIGNAL BASED ON A TOUCH COMMAND AND ON AN OPTICAL COMMAND</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>EMBODME</orgname><address><city>PARIS</city><country>FR</country></address></addressbook><residence><country>FR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>HEMERY</last-name><first-name>Edgar</first-name><address><city>PARIS</city><country>FR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>FROHLICH</last-name><first-name>Mathieu</first-name><address><city>VANVES</city><country>FR</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2020/082767</doc-number><date>20201119</date></document-id><us-371c12-date><date>20220519</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system for generating a signal includes a touchpad including touch cells and a touch detection device for detecting the location and intensity of a pressure exerted on the touchpad; a first computer generating a first instruction based on the location and intensity of the pressure; an optical detection device for detecting a movement and/or a position, including optics for capturing images; a second computer for determining a motion parameter based on the captured images and for generating a second instruction based on the parameter; and a signal generator for producing a second signal based on the first instruction or on a first signal extracted from the first instruction, to which there is applied a special effect extracted from the second instruction; or on the second instruction or on a first signal extracted from the second instruction, to which there is applied a special effect extracted from the first instruction.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="76.71mm" wi="132.84mm" file="US20230005457A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="169.84mm" wi="145.54mm" file="US20230005457A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="166.54mm" wi="147.32mm" file="US20230005457A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="187.11mm" wi="152.06mm" file="US20230005457A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="206.84mm" wi="117.35mm" file="US20230005457A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="170.26mm" wi="151.13mm" file="US20230005457A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="156.89mm" wi="135.04mm" file="US20230005457A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="201.25mm" wi="131.91mm" file="US20230005457A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="141.65mm" wi="149.18mm" file="US20230005457A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD OF THE INVENTION</heading><p id="p-0002" num="0001">The invention relates to a system for generating a signal, in particular a sound signal. The invention also relates to a method for generating a signal, especially a sound signal. In particular, the field of the invention relates to musical instruments having a touchpad for generating a sound setpoint. The field of the invention especially relates to systems capable of being coupled to different control interfaces.</p><heading id="h-0002" level="1">STATE OF THE ART</heading><p id="p-0003" num="0002">Electronic musical instruments provide the possibility of producing a wide range of sound sequences, especially by combining sounds produced with different special effects or parameters aimed at modulating or modifying a sound or sounds. However, the musician's ability to control and adjust all of these sounds is limited by the performance of the instrument and by limitations of the instrument interface. There is a need to extend control capabilities and thus interface capabilities of a musical instrument to allow exploration and operation of the instrument sound production.</p><p id="p-0004" num="0003">A similar problem can be encountered in various fields when there is a need to generate a wide variety of signals and effects that can be applied to said signals from a human-controlled signal generator. This need results in the definition of a new control interface to control various parameters of said signal in real time by the user. For example, the field of lighting, the control of a robot or the control of an avatar in video games can be mentioned.</p><p id="p-0005" num="0004">There is thus a real need to increase the interface means in order to increase the possibilities for the user to generate a wide variety of effects on signals based on an instrument or a signal generator.</p><p id="p-0006" num="0005">Among the existing musical instruments providing enriched control devices, the solution described in document FR3008217 is especially known. This solution describes a detection module, such as a gyroscope, to modify the sounds produced by a musical instrument. The gyroscope is attached to the musical instrument or to the musician. However, one drawback of this system is that it involves attaching a detection module in addition to the musical instrument which is likely to introduce inaccuracy in the measurements or requires the equipment to be configured for each use. A second drawback is the compatibility of the musical instrument with the detection module. Indeed, it is necessary in this solution to pass through a computer and to use a software collecting the signals of the musical instrument on the one hand and the signals acquired by the detection module on the other hand in order to generate the output signal. The musician has to implement at least three elements: the instrument, the computer and the detection module and has to proceed to a configuration for each device.</p><p id="p-0007" num="0006">The invention aims at providing a system for generating a signal that allows a first signal to be modified without the drawbacks of prior art.</p><heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0008" num="0007">According to a first aspect, the invention relates to a system for generating a signal comprising:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0008">a touchpad comprising a plurality of touch cells and a touch detection device for detecting the location and intensity of at least one pressure exerted on said touchpad;</li>        <li id="ul0002-0002" num="0009">a first calculator generating at least one first setpoint based on the location and intensity of said at least one pressure; and</li>        <li id="ul0002-0003" num="0010">an optical detection device for detecting a motion and/or a position comprising at least one optics for capturing images;</li>        <li id="ul0002-0004" num="0011">a second calculator for determining at least one motion parameter based on the captured images and for generating a second setpoint based on said at least one motion parameter.</li>    </ul>    </li></ul></p><p id="p-0009" num="0012">One advantage is to allow two setpoints or signals to be combined to produce a single signal from two items of equipment providing different interaction modes with a user. Indeed, a first equipment makes it possible to take into account the touch and the press-in force of a finger within cells of a keyboard and the second equipment makes it possible to take into account an amplitude of gestures in space. An interest is that one of the generated setpoints is associated with a signal and the other generated setpoint allows effects to be produced for example to modulate the first signal. A single original signal can therefore be produced by means of the system of the invention. This combination of interactions makes it possible to provide a wide range of combinations of produced signals such as the production of sound signals. Finally, another advantage is to allow a significant freedom of uses of an instrument, such as a musical instrument, allowing each user to configure and appropriate this instrument.</p><p id="p-0010" num="0013">In a first alternative embodiment, each of the first setpoints is associated with the production of a first signal and the system comprises a signal generator for producing a second signal based on the first setpoint or the first signal to which a special effect extracted from the second setpoint is applied.</p><p id="p-0011" num="0014">In a second alternative embodiment, each of the second setpoints is associated with the production of a first signal and the system comprises a signal generator for producing a second signal based on the second setpoint or the first signal to which a special effect extracted from the first setpoint is applied.</p><p id="p-0012" num="0015">In one embodiment, the first signal and the second signal are sound signals.</p><p id="p-0013" num="0016">In one embodiment, each touch cell comprises a first layer comprising at least one force sensing resistor and comprises a second layer comprising a detection cell designed to detect a variation in the resistivity of the force sensing resistor.</p><p id="p-0014" num="0017">In one embodiment, each detection cell comprises a printed circuit comprising at least a first portion and a second portion connected to each other by the force sensing resistor of the first layer.</p><p id="p-0015" num="0018">In one embodiment, the motion parameter is determined based on the amplitude, speed and/or direction of the hand and/or a finger of the hand.</p><p id="p-0016" num="0019">In one embodiment, the optical detection device for detecting a motion and/or a position comprises a stereo camera, preferably an infrared stereo camera and/or a depth camera.</p><p id="p-0017" num="0020">One advantage is to enable a wide range of motions to be detected and gestures to be characterized finely to produce sound effects on a first generated signal.</p><p id="p-0018" num="0021">In one embodiment, the first signal corresponds to or comprises a musical note.</p><p id="p-0019" num="0022">In one embodiment, the system comprises a user interface for providing the second calculator with feedback data. The second calculator then includes a reinforcement learning algorithm configured to modify the mode of generation of the second setpoint based on the feedback data by iteration.</p><p id="p-0020" num="0023">In one embodiment, said system is a musical instrument and the touchpad and optical detection device are integrated into a single case.</p><p id="p-0021" num="0024">In one embodiment, the first calculator and the second calculator are integrated into said case.</p><p id="p-0022" num="0025">In one embodiment, each touch cell includes a lighting source for producing a light signal when a pressure is applied to said touch cell.</p><p id="p-0023" num="0026">In one embodiment, the signal generator is configured to produce the second signal as a third setpoint.</p><p id="p-0024" num="0027">According to a second aspect, the invention relates to a method for generating a signal comprising:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0028">acquiring the location and intensity of a pressure on a touchpad having a plurality of touch cells;</li>        <li id="ul0004-0002" num="0029">producing a first setpoint associated with the production of a first signal; and</li>        <li id="ul0004-0003" num="0030">acquiring at least one image by at least one optics; and</li>        <li id="ul0004-0004" num="0031">determining at least one motion parameter based on the acquired images;</li>        <li id="ul0004-0005" num="0032">generating a second setpoint based on the motion parameter.</li>    </ul>    </li></ul></p><p id="p-0025" num="0033">The method also includes a step of generating a second signal based on:<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0034">the first setpoint or a first signal associated with the first setpoint to which a special effect extracted from the second setpoint is applied; or</li>        <li id="ul0006-0002" num="0035">the second setpoint or a first signal associated with the second setpoint to which a special effect extracted from the first setpoint is applied.</li>    </ul>    </li></ul></p><p id="p-0026" num="0036">In one embodiment, the first signal and the second signal are sound signals.</p><p id="p-0027" num="0037">In one embodiment, the first setpoint or the second setpoint is associated with a first signal.</p><p id="p-0028" num="0038">In one embodiment, the motion parameter is also determined based on the amplitude, speed and/or direction of the hand and/or a finger of the hand.</p><p id="p-0029" num="0039">In one embodiment, the first sound signal corresponds to a musical note.</p><p id="p-0030" num="0040">In one embodiment, generating a second signal includes a step of generating a third setpoint associated with the second signal.</p><p id="p-0031" num="0041">In one embodiment, determining the at least one motion parameter comprises detecting points of interest such as the finger tips, the center of mass, and/or a deflection point.</p><p id="p-0032" num="0042">In one embodiment, the step of determining at least one motion parameter based on the acquired images comprises generating a depth map, said motion parameter also being determined depending on said depth map.</p><p id="p-0033" num="0043">In one embodiment, said special effect comprises one or more of the elements listed below:<ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0000">    <ul id="ul0008" list-style="none">        <li id="ul0008-0001" num="0044">a reverberation,</li>        <li id="ul0008-0002" num="0045">an echo,</li>        <li id="ul0008-0003" num="0046">a distortion,</li>        <li id="ul0008-0004" num="0047">a sustain,</li>        <li id="ul0008-0005" num="0048">a wha-wha,</li>        <li id="ul0008-0006" num="0049">a vibrato,</li>        <li id="ul0008-0007" num="0050">a phase shift.</li>    </ul>    </li></ul></p><p id="p-0034" num="0051">According to a third aspect, the invention relates to a system for generating a signal comprising hardware and/or software elements implementing the method according to the second aspect of the invention, especially hardware and/or software elements designed to implement the method according to the second aspect of the invention.</p><p id="p-0035" num="0052">In one embodiment, the hardware means comprise:<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0000">    <ul id="ul0010" list-style="none">        <li id="ul0010-0001" num="0053">a touchpad;</li>        <li id="ul0010-0002" num="0054">a touch detection device;</li>        <li id="ul0010-0003" num="0055">an optical detection device;</li>        <li id="ul0010-0004" num="0056">a first calculator;</li>        <li id="ul0010-0005" num="0057">a second calculator; and</li>        <li id="ul0010-0006" num="0058">a signal generator.</li>    </ul>    </li></ul></p><p id="p-0036" num="0059">According to a fourth aspect, the invention relates to a computer program product downloadable from a communication network and/or recorded on a computer-readable and/or computer-executable data storage medium, comprising computing program code instructions for implementing the method according to the second aspect of the invention.</p><p id="p-0037" num="0060">According to a fifth aspect, the invention relates to a computer-readable data storage medium, having recorded thereon a computer program comprising program code instructions for implementing the method according to the second aspect of the invention.</p><p id="p-0038" num="0061">According to a sixth aspect, the invention relates to a system for generating a signal comprising:<ul id="ul0011" list-style="none">    <li id="ul0011-0001" num="0000">    <ul id="ul0012" list-style="none">        <li id="ul0012-0001" num="0062">a touchpad comprising a plurality of touch cells and a touch detection device for detecting the location and intensity of at least one pressure exerted on said touchpad;</li>        <li id="ul0012-0002" num="0063">a first calculator generating at least one first setpoint based on the location and intensity of said at least one pressure, each of the first setpoints being associated with the production of a first signal;</li>        <li id="ul0012-0003" num="0064">an optical detection device for detecting a motion and/or a position comprising at least one optics for capturing images; and</li>        <li id="ul0012-0004" num="0065">a second calculator for determining at least one motion parameter based on the captured images and for generating a second setpoint based on the at least one motion parameter; and</li>        <li id="ul0012-0005" num="0066">a signal generator for producing a second signal based on the first setpoint or the first signal to which a special effect extracted from the second setpoint is applied.</li>    </ul>    </li></ul></p><p id="p-0039" num="0067">According to a sixth aspect, the invention relates to a system for generating a signal comprising:<ul id="ul0013" list-style="none">    <li id="ul0013-0001" num="0000">    <ul id="ul0014" list-style="none">        <li id="ul0014-0001" num="0068">a touchpad comprising a plurality of touch cells and a touch detection device for detecting the location and intensity of at least one pressure exerted on said touchpad;</li>        <li id="ul0014-0002" num="0069">an optical detection device for detecting a motion and/or a position comprising at least one optics for capturing images;</li>        <li id="ul0014-0003" num="0070">a first calculator generating a first setpoint based on the location and intensity of said at least one pressure;</li>        <li id="ul0014-0004" num="0071">a second calculator for determining at least one motion parameter based on the captured images and for generating at least one second setpoint based on said at least one motion parameter, each of the second setpoints being associated with the production of a first signal; and</li>        <li id="ul0014-0005" num="0072">a signal generator for producing a second signal based on the second setpoint or the first signal to which a special effect extracted from the first setpoint is applied.</li>    </ul>    </li></ul></p><p id="p-0040" num="0073">According to an eighth aspect, the invention relates to a method for generating a signal comprising:<ul id="ul0015" list-style="none">    <li id="ul0015-0001" num="0000">    <ul id="ul0016" list-style="none">        <li id="ul0016-0001" num="0074">acquiring the location and intensity of a pressure on a touchpad having a plurality of touch cells;</li>        <li id="ul0016-0002" num="0075">producing a first setpoint associated with the production of a first signal;</li>        <li id="ul0016-0003" num="0076">acquiring at least one image by at least one optics;</li>        <li id="ul0016-0004" num="0077">determining at least one motion parameter based on the acquired images;</li>        <li id="ul0016-0005" num="0078">generating a second setpoint based on the motion parameter; and</li>        <li id="ul0016-0006" num="0079">generating a second signal based on the first setpoint or the first signal to which a special effect extracted from the second setpoint is applied.</li>    </ul>    </li></ul></p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading><p id="p-0041" num="0080">Further characteristics and advantages of the invention will become apparent upon reading the following detailed description, with reference to the attached figures, which illustrate:</p><p id="p-0042" num="0081"><figref idref="DRAWINGS">FIG. <b>1</b></figref>: a schematic view of a system according to one embodiment of the invention;</p><p id="p-0043" num="0082"><figref idref="DRAWINGS">FIG. <b>2</b></figref>: a schematic view of a system according to one embodiment of the invention comprising a user interface for transmitting feedback data;</p><p id="p-0044" num="0083"><figref idref="DRAWINGS">FIG. <b>3</b></figref>: a cross-sectional view of the touchpad according to one embodiment;</p><p id="p-0045" num="0084"><figref idref="DRAWINGS">FIG. <b>4</b></figref>: a logic diagram of the method for generating a signal according to one embodiment of the invention;</p><p id="p-0046" num="0085"><figref idref="DRAWINGS">FIG. <b>5</b></figref>: a logic diagram of the method for generating a signal according to one embodiment of the invention further comprising a user feedback step;</p><p id="p-0047" num="0086"><figref idref="DRAWINGS">FIG. <b>6</b></figref>: a view of a case comprising the system according to one embodiment of the present invention;</p><p id="p-0048" num="0087"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref>: a schematic view of a detection cell according to one embodiment of the invention;</p><p id="p-0049" num="0088"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref>: a schematic view of a multiplexing circuit of the touch detection device according to one embodiment of the invention;</p><p id="p-0050" num="0089"><figref idref="DRAWINGS">FIG. <b>7</b>C</figref>: a schematic view of an electronic residual current reduction module according to one embodiment;</p><p id="p-0051" num="0090"><figref idref="DRAWINGS">FIG. <b>8</b></figref>: a schematic view of a first layer of the touchpad according to one embodiment of the invention;</p><p id="p-0052" num="0091"><figref idref="DRAWINGS">FIG. <b>9</b>A</figref> <figref idref="DRAWINGS">FIG. <b>9</b>B</figref> <figref idref="DRAWINGS">FIG. <b>9</b>C</figref> <figref idref="DRAWINGS">FIG. <b>9</b>D</figref> <figref idref="DRAWINGS">FIG. <b>9</b>E</figref> <figref idref="DRAWINGS">FIG. <b>9</b>F</figref> <figref idref="DRAWINGS">FIG. <b>9</b>G</figref> <figref idref="DRAWINGS">FIG. <b>9</b>H</figref> and <figref idref="DRAWINGS">FIG. <b>9</b>I</figref>: a graphical representation of types of gestures detectable by the optical detection device according to one embodiment;</p><p id="p-0053" num="0092"><figref idref="DRAWINGS">FIG. <b>10</b></figref>: a representation of an image of a hand in which each pixel is labeled so as to generate areas of interest of the hand;</p><p id="p-0054" num="0093"><figref idref="DRAWINGS">FIG. <b>11</b></figref>: the representation of the image of a hand comprising points of interest.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0055" num="0094">The technical problem is solved by the invention, especially by an optical detection device for detecting a motion and/or a position for generating a special effect depending on the user's gestures. The special effect is intended to be applied to a first signal determined based on a touchpad PT.</p><p id="p-0056" num="0095">The system is preferably a musical instrument. In the following, the system is especially described by the example of a musical instrument. The signal produced by the system is thus in this case a sound sequence. However, the present invention is not limited to a musical instrument. Indeed, the signal produced can be a light signal, a video signal or any other type of signal that can be produced by a signal generator and that can be modified by the application of a special effect such as a spatial or temporal filter, a predefined data processing, or any other digital or analog effect.</p><p id="p-0057" num="0096">The description of the system describes the main components of said system, each alternative of the components described can be combined with an embodiment described in this description.</p><p id="p-0058" num="0097">The system comprises, on the one hand, a touchpad PT for generating a first setpoint C<sub>1 </sub>associated with the production of a first signal, and on the other hand, an optical detection device OPT for determining a motion parameter D<sub>1 </sub>and generating a second setpoint C<sub>2 </sub>associated with a special effect to be applied to the first signal.</p><p id="p-0059" num="0098">Touchpad</p><p id="p-0060" num="0099">The touchpad PT comprises a plurality of touch cells CT. Advantageously, the touchpad PT makes it possible to detect a pressure exerted on one or more touch cells. For this purpose, the touchpad PT comprises a touch detection device DD. The touch detection device DD advantageously makes it possible to determine, on the one hand, the location of the touch cell CT on which a pressure has been exerted and, on the other hand, the intensity of said exerted pressure.</p><p id="p-0061" num="0100">The touchpad PT comprises a plurality of touch cells CT. Each touch cell CT comprises at least one force sensing resistor <b>31</b>. Preferably, the first layer <b>3</b> comprises a plurality of force sensing resistors FSR <b>31</b>. A force sensing resistor <b>31</b> is an electronic sensor whose resistance varies depending on the pressure applied to it.</p><p id="p-0062" num="0101">Each touch cell CT includes at least one detection cell <b>41</b>. The detection cell <b>41</b> is preferably arranged in contact with the force sensing resistor <b>31</b>. The detection cell <b>41</b> is configured to respond to a change in the resistivity of the force sensing resistor <b>31</b>.</p><p id="p-0063" num="0102">Each force sensing resistor <b>31</b> is associated with a detection cell <b>41</b>. In one embodiment, a force sensing resistor <b>31</b> may be included in multiple touch cells CT.</p><p id="p-0064" num="0103">Detection Cells</p><p id="p-0065" num="0104">The detection cell <b>41</b> preferably comprises a printed circuit <b>71</b>. The circuit of the detection cell comprises an electrical input <b>74</b> and an electrical output <b>75</b>.</p><p id="p-0066" num="0105">The printed circuit <b>71</b> comprises a first portion <b>73</b> connected to an electrical input <b>74</b> and a second portion <b>72</b> connected to the electrical output <b>75</b>. The first portion <b>73</b> and the second portion <b>72</b> of the printed circuit <b>71</b> are not in contact with each other: the printed circuit <b>71</b> is an open circuit.</p><p id="p-0067" num="0106">The printed circuit <b>71</b> is in contact with a layer of force sensing resistor <b>31</b> of the first layer <b>3</b>. The force sensing resistor <b>31</b> is in contact with the first portion <b>73</b> and with the second portion <b>72</b> of the printed circuit.</p><p id="p-0068" num="0107">When no pressure is exerted on the force sensing resistor <b>31</b>, the force sensing resistor is insulating between the first and second portions.</p><p id="p-0069" num="0108">When a pressure is exerted on the touchpad PT, the force sensing resistor <b>31</b> is subjected to the pressure. The resistivity of the force sensing resistor <b>31</b> decreases as the pressure is increased. At a certain pressure, the force sensing resistor <b>31</b> conducts electricity between the first portion <b>73</b> and the second portion <b>72</b> of the printed circuit <b>71</b>.</p><p id="p-0070" num="0109">In one embodiment illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> the first portion comprises a plurality of branched tracks <b>76</b>. Preferably, the plurality of branched tracks comprises a plurality of substantially parallel tracks <b>76</b> that extend from a first main track of the first portion. The first main track extends from the electrical input <b>74</b>. In this same embodiment, the second portion also comprises a second main track XX extending from the electrical output <b>75</b> and a plurality of branched tracks extending from said second main track.</p><p id="p-0071" num="0110">Preferably, the branched tracks <b>77</b>, <b>76</b> of the first and second portions alternately interlock with each other without contacting. The force sensing resistor <b>31</b> allows electrical contact to be made between each adjacent branched track when a pressure is exerted on said pressure sensor resistor.</p><p id="p-0072" num="0111">This embodiment advantageously improves conductivity between the electrical input <b>74</b> and the electrical output <b>75</b> of the detection cell <b>41</b> when a pressure is applied to the force sensing resistor <b>31</b>.</p><p id="p-0073" num="0112">The overall conductivity of the printed circuit of the detection cell <b>41</b> between the input <b>74</b> and the output <b>75</b> of the printed circuit <b>71</b> increases when a pressure is exerted on the force sensing resistor <b>31</b>.</p><p id="p-0074" num="0113">The more significant the intensity of pressure exerted on the force sensing resistor <b>31</b>, the more the resistivity of said force sensing resistor <b>31</b> decreases and thus the conductivity of the detection cell <b>41</b> increases. The conductivity of the detection cell <b>41</b> is therefore a function of the intensity of pressure exerted on the force sensing resistor <b>31</b>.</p><p id="p-0075" num="0114">In one embodiment, the length and/or width dimensions of the detection cell <b>41</b> are between 5 mm and 15 mm.</p><p id="p-0076" num="0115">In one embodiment, the first portion and/or the second portion comprise a number of interlocking branched tracks between 5 and 15. Each branched track may extend over a length between 5 mm and 15 mm and/or a width between 0.05 mm and 1 mm. The gap between a branched track of the first portion <b>73</b> and the branched track of the adjacent second portion <b>72</b> is between 0.05 mm and 1 mm.</p><p id="p-0077" num="0116">In one embodiment, the length of each branched track is between 3 mm and 20 mm. In one embodiment, the width of the overall shape of the circuit of the detection cell <b>41</b> is between 5 mm and 15 mm. The printed circuit is preferably made of copper, aluminum or most preferably gold.</p><p id="p-0078" num="0117">First Layer</p><p id="p-0079" num="0118">In one embodiment, the touchpad PT may comprise a first layer <b>3</b> intended to be superimposed on a second layer <b>4</b>. The first layer <b>3</b> comprises at least one force sensing resistor <b>31</b>. The force sensing resistor <b>31</b> preferably comprises a conductive material whose resistivity property varies depending on the pressure that is exerted on said material. Said material preferably comprises a mixture of conductive and insulating particles in a matrix. Said matrix is preferably a polymer matrix. When a pressure is exerted, the conductive fillers contact each other, modifying the resistivity properties of the material. In one embodiment not represented, the first layer <b>3</b> comprises a sheet of force sensing resistor <b>31</b>.</p><p id="p-0080" num="0119">According to one alternative embodiment illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the first layer <b>3</b> comprises a support sheet <b>32</b>. The support sheet <b>32</b> is preferably transparent. The support sheet <b>32</b> is preferably deformable. The force sensing resistor(s) are arranged on said support sheet <b>32</b>.</p><p id="p-0081" num="0120">Preferably, the force sensing resistor(s) <b>31</b> are printed on said support sheet <b>32</b> of the first layer <b>3</b>. The force sensing resistor <b>31</b> is thus obtained by printing an ink on the deformable sheet. Said ink comprises said material whose resistivity property varies depending on the pressure that is exerted on said material.</p><p id="p-0082" num="0121">The deformability of the support sheet <b>32</b> advantageously allows the pressure forces exerted on the touchpad PT to be transmitted. The deformability of the support sheet <b>32</b> advantageously also allows easier mounting of the touchpad PT. A transparent support sheet <b>32</b> advantageously allows display means visible to the user to be integrated below the touchpad PT through the first layer <b>3</b>.</p><p id="p-0083" num="0122">The support sheet <b>32</b> thus advantageously makes it possible to serve as a mechanical support for the ink FSR. It also reduces the amount of ink to be used compared to a sheet of force sensing resistor <b>31</b> by reducing the thickness required and by allowing regions of the first layer <b>3</b> comprising a force sensing resistor <b>31</b> to be selected.</p><p id="p-0084" num="0123">In a preferred embodiment illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the support sheet <b>32</b> comprises a force sensing resistor matrix. Most preferably, the force sensing resistor matrix is arranged on a first surface of the support sheet <b>32</b>.</p><p id="p-0085" num="0124">Press-in layer and contact layer.</p><p id="p-0086" num="0125">The touchpad PT may include a press-in layer <b>2</b>. The press-in layer <b>2</b> may be intended to receive pressure from the user. The press-in layer <b>2</b> allows the pressure exerted by the user to be transmitted to the force sensing resistor <b>31</b>. The press-in layer <b>2</b> is preferably made of a deformable material, most preferably a plastic material. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the press-in layer <b>2</b> may be divided into a plurality of keys <b>21</b>, preferably into a matrix of keys <b>21</b>.</p><p id="p-0087" num="0126">The first layer <b>3</b> and the press-in layer <b>2</b> are arranged such that each key <b>21</b> is located facing a force sensing resistor <b>31</b>.</p><p id="p-0088" num="0127">In one embodiment, the press-in layer <b>2</b> is superimposed on the first layer <b>3</b>. The press-in layer <b>2</b> is preferably arranged facing the second surface of the support sheet <b>32</b> of the first layer <b>3</b>. The second surface of the support sheet <b>32</b> is the face opposite the first surface on which the force sensing resistors are arranged.</p><p id="p-0089" num="0128">Advantageously, the press-in layer <b>2</b> serves as a protective layer for the first layer <b>3</b>. Advantageously, the press-in layer <b>2</b> makes it possible to create a first filter of the detection cell <b>41</b>. Below a certain pressure, the strains are damped by the press-in layer <b>2</b> and will not be transmitted to the first layer <b>3</b>. Advantageously, the press-in layer <b>2</b> reduces the risk of detecting an unintentional press on the touchpad PT.</p><p id="p-0090" num="0129">In one embodiment, the touchpad comprises a press-in layer and a contact layer <b>5</b>. The contact layer <b>5</b> is disposed above the press-in layer <b>2</b> and is intended to be touched by the user to exert a pressure on the press-in layer <b>2</b>.</p><p id="p-0091" num="0130">According to one example, the press-in layer is made of translucent plastic to allow an amount of light from the touchpad PT to pass through. A user may have the sensation of a key being lit when a pressure is exerted on the key.</p><p id="p-0092" num="0131">Second Layer</p><p id="p-0093" num="0132">The touchpad PT further comprises a touch detection device DD. The device comprises a second layer <b>4</b>. The second layer <b>4</b> is arranged in contact with the force sensing resistor <b>31</b> of the first layer <b>3</b>.</p><p id="p-0094" num="0133">The second layer <b>4</b> comprises a plurality of detection cells <b>41</b>. Each detection cell <b>41</b> is in contact with a force sensing resistor <b>31</b>. Each detection cell <b>41</b> is positioned in contact with a force sensing resistor <b>31</b>. Each detection cell <b>41</b> is designed to respond to a variation of the force sensing resistor <b>31</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, each touch cell CT thus comprises at least one detection cell <b>41</b> and one force sensing resistor <b>31</b>.</p><p id="p-0095" num="0134">Light Sources</p><p id="p-0096" num="0135">In one embodiment not represented, the system comprises a plurality of light sources. The light sources are designed to emit light when a pressure is exerted by the user on a touch cell CT adjacent to said light source. This way, the user advantageously receives, upon pressing a touch cell, a light response from said touch area being pressed.</p><p id="p-0097" num="0136">In one embodiment, each light source is arranged between two touch cells. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, each light source may be arranged on the second layer between at least two detection cells. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, the light sources <b>42</b> may be disposed between four detection cells <b>41</b> disposed in a square.</p><p id="p-0098" num="0137">As illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the first layer <b>3</b> may include bores <b>33</b>. The bores <b>33</b> are arranged facing the light source <b>42</b> so as to pass light from said light source <b>42</b> through said bore <b>33</b>.</p><p id="p-0099" num="0138">As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the press-in layer <b>2</b> comprises light wells <b>22</b>. The light wells <b>22</b> may comprise a hole that increases in cross-sectional area away from the light source <b>42</b>. The light wells <b>22</b> are arranged facing the light source and optionally facing the bores <b>33</b> of the first layer <b>3</b>.</p><p id="p-0100" num="0139">The light wells allow light to be diffused more evenly through the contact layer <b>5</b>.</p><p id="p-0101" num="0140">The touchpad is disposed to allow the light source to emit light outwardly from the touchpad PT through the second layer <b>4</b>, the first layer <b>3</b>, and the press-in layer <b>2</b>. The light source may comprise a light emitting diode.</p><p id="p-0102" num="0141">In one embodiment, the light source of the touch cell CT is designed to emit light when a pressure is exerted on the touchpad by the user. According to one example, a dimmer is associated with the light to generate an emitted power proportional to the pressure exerted. For this purpose, the dimmer can be driven by a setpoint generated based on the pressure exerted. The latter can be measured indirectly by the resistivity of the force sensor.</p><p id="p-0103" num="0142">Detection Device</p><p id="p-0104" num="0143">The touchpad PT includes a touch detection device DD.</p><p id="p-0105" num="0144">The touch detection device DD includes hardware and/or software means for detecting a variation in the resistivity of each detection cell <b>41</b>. The touch detection device DD generates information comprising the location of the detection cell <b>41</b> that has undergone a variation in resistivity and the intensity of said variation. The cell location may then be coupled to a sound library comprising predefined location information.</p><p id="p-0106" num="0145">In one embodiment, the touch detection device DD includes a multiplexing circuit. The multiplexing circuit is connected to the detection cells <b>41</b> by a matrix of rows and columns. The multiplexing circuit connects each detection cell <b>41</b> to a current source. Voltage, current, or resistivity can be measured on each circuit formed by a detection cell and a conductor organized in a row and column of the matrix.</p><p id="p-0107" num="0146">The multiplexing circuit is more particularly described below with reference to <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>.</p><p id="p-0108" num="0147">In one embodiment, the input <b>74</b> of the printed circuit <b>71</b> of each detection cell <b>41</b> is connected to a column of the multiplexing circuit and the output <b>75</b> of the printed circuit <b>71</b> of each detection cell <b>41</b> is connected to a row of the multiplexing circuit or vice versa.</p><p id="p-0109" num="0148">This embodiment advantageously allows, by scanning the rows and columns of the multiplexing circuit, the resistivity of each detection cell <b>41</b> to be measured one after the other. The scanning frequency can be configured so that the entirety of the columns and rows is probed when a key is being pressed.</p><p id="p-0110" num="0149">Preferably, the second layer <b>4</b> comprises a printed circuit comprising the detection cells <b>41</b> and/or the multiplexing circuit.</p><p id="p-0111" num="0150">The multiplexing circuit comprises a first switch INT<b>1</b>. The first switch INT<b>1</b> is connected in series with a current generator. The first switch INT<b>1</b> includes an input terminal. The input terminal of the first switch INT<b>1</b> is connected in series with a power supply. The first switch INT<b>1</b> comprises a plurality of output terminals. Each output terminal is connected in series with a column of the multiplexing circuit. The first switch INT<b>1</b> is designed to power each column of the multiplexing circuit by scanning.</p><p id="p-0112" num="0151">The multiplexing circuit comprises a second switch INT<b>2</b>. The second switch INT<b>2</b> comprises an output terminal connected to a voltage measuring instrument.</p><p id="p-0113" num="0152">The second switch INT<b>2</b> comprises a plurality of input terminals. Each input terminal is connected to a row of the multiplexing circuit. The second switch INT<b>2</b> is designed to connect each row of the multiplexing circuit to the voltage measuring instrument by scanning.</p><p id="p-0114" num="0153">The multiplexing circuit allows each row and each column to be powered independently one by one by scanning depending on the connection of the first and second switches INT<b>2</b>. The multiplexing circuit comprises means for measuring a voltage between the first switch INT<b>1</b> and the second switch INT<b>2</b>.</p><p id="p-0115" num="0154">The multiplexing circuit thus enables each detection cell <b>41</b> to be powered one by one depending on the connection of the first and second switches INT<b>2</b>. The voltage and/or resistivity of each detection cell <b>41</b> can thus be measured. A modification in voltage and/or resistivity then indicates the presence of a pressure exerted on said touch cell CT of said detection cell <b>41</b>.</p><p id="p-0116" num="0155">The touch detection device DD preferably comprises a memory. The memory records the position of the first switch INT<b>1</b> and the position of the second switch INT<b>2</b> when a variation in resistivity is detected. Preferably, the memory also records the intensity of the resistivity variation. A calculator associated with the memory is then configured to generate position information based on the position of the first and second switches INT<b>1</b>, INT<b>2</b>.</p><p id="p-0117" num="0156">The touch detection device DD is thus advantageously able to determine the location of a pressure exerted on the touchpad PT.</p><p id="p-0118" num="0157">Position information can thus be generated depending on the position of the two switches when a change in resistivity is detected. Pressure intensity information may also be generated depending on the measured or calculated resistivity value.</p><p id="p-0119" num="0158">In one embodiment, the multiplexing circuitry includes residual current reduction modules. The residual current could indeed increase the risk of false positive detection.</p><p id="p-0120" num="0159">The residual current reduction module may comprise a voltage divider bridge.</p><p id="p-0121" num="0160">In one embodiment, the residual current reduction module includes a first resistor <b>79</b>. The first resistor <b>79</b> is arranged to be connected to the electrical input <b>74</b> of each detection cell <b>41</b>. Preferably, the first resistor <b>79</b> is arranged upstream of the first switch INT<b>1</b> as shown in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>. In one embodiment, the first resistor <b>79</b> is connected in parallel to the first switch INT<b>1</b> and/or is connected in series to ground.</p><p id="p-0122" num="0161">In one embodiment illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>C</figref>, the residual current reduction module includes a feedback loop <b>76</b>. Advantageously, the feedback loop <b>76</b> allows the residual voltage that may be present in the circuit to be eliminated.</p><p id="p-0123" num="0162">According to one example, the feedback loop includes an operational amplifier <b>77</b>. The operational amplifier <b>77</b> is preferably connected in series with a row of the multiplexing circuit. In one embodiment, each row of the multiplexing circuit includes a feedback loop <b>76</b> in series.</p><p id="p-0124" num="0163">The feedback loop <b>76</b> includes a second resistor <b>78</b>. The second resistor <b>78</b> is shunt connected to the operational amplifier <b>76</b>. Said second resistor <b>78</b> is connected to the negative input terminal and the output terminal of the operational amplifier <b>77</b>. The positive input terminal of the operational amplifier is preferably connected to ground.</p><p id="p-0125" num="0164">Preferably, the impedance of the second resistor <b>78</b> is greater than the impedance of the first resistor <b>79</b>.</p><p id="p-0126" num="0165">Advantageously, the feedback loop allows the circuit impedance to be increased so as to make the circuit impedance caused by the first resistor <b>79</b> negligible.</p><p id="p-0127" num="0166">The current reduction module thus makes it possible to reduce the residual current without influencing the measured voltage values.</p><p id="p-0128" num="0167">This arrangement advantageously reduces the residual current present in the circuit which could lead to false positive detection.</p><p id="p-0129" num="0168">In one alternative embodiment, the feedback loops <b>76</b> may be included on each column of the multiplexing circuit.</p><p id="p-0130" num="0169">Alternatives to the Touchpad</p><p id="p-0131" num="0170">In one alternative embodiment, the touchpad PT may be replaced by an electronic control pad for generating a first setpoint C<sub>1 </sub>associated with the production of a first signal S<sub>1</sub>. The electronic control pad may comprise an electronic piano, a synthesizer or a synthesizer controller.</p><p id="p-0132" num="0171">Optical Detection Device</p><p id="p-0133" num="0172">The system according to the present invention comprises an optical detection device OPT for detecting a motion and/or a position. This device is compatible with all alternatives of the touch detection device previously disclosed.</p><p id="p-0134" num="0173">The optical detection device OPT is designed to capture images of a user, in particular of the hands, forearms and possibly upper arms, or even the torso. The optical detection device OPT allows the detection of a motion and/or the detection of a position of at least one part of the user's body. Preferably, the optical detection device OPT allows the detection of a motion or a position of at least one hand of a user.</p><p id="p-0135" num="0174">Advantageously, a user can thus use a first hand to exert one or more pressures on the touchpad PT and use the second hand with the optical detection device OPT.</p><p id="p-0136" num="0175">In one alternative embodiment, the optical detection device OPT allows images of a second user to be captured. Said second user is a person other than the person exerting a pressure on the touchpad PT. In this case, the system is then used simultaneously by two users, one for the touchpad PT and one for the optical detection device OPT.</p><p id="p-0137" num="0176">In another embodiment, the optical detection device OPT and the touchpad PT are separate and connected wirelessly, for example through the internet network.</p><p id="p-0138" num="0177">The optical detection device OPT comprises at least one optics CAM for capturing images of the user.</p><p id="p-0139" num="0178">In one embodiment illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the touchpad PT, the optical detection device OPT are included in a single case. According to one embodiment, the touchpad PT and the optics CAM are integrated on the same surface of the case <b>1</b>. In this case, the optics CAM is for example arranged to be adjacent to the touchpad PT. This arrangement advantageously makes it easier to sense images from a user's hand exerting a pressure on the touchpad PT with his other hand. The second hand of the user is then closer to the field of capture of the optics CAM.</p><p id="p-0140" num="0179">Optics</p><p id="p-0141" num="0180">The optics CAM may include a camera, a stereo camera system, and/or a depth camera. The stereo camera system generally comprises at least two cameras whose relative position is known. Together, the two acquisitions are used to determine a depth map. A depth camera is generally equipped with an emitter, for example a beam of light in the infrared range, and makes it possible to obtain time of flight information by measuring the reflected signal. The information is then used to determine a depth data.</p><p id="p-0142" num="0181">The optics CAM can be designed to capture images in the visible wavelengths. The optics CAM can be designed to capture images in the infrared wavelengths. Preferably, the optics CAM comprises an infrared camera or an infrared stereo camera system.</p><p id="p-0143" num="0182">In one alternative embodiment not represented, the optics CAM is not integrated into the case.</p><p id="p-0144" num="0183">In one embodiment, the system of the invention includes multiple optics CAM. A first optics CAM may be arranged to sense images of at least one first part of the user's body and a second optics CAM may be arranged to sense images of at least one second part of the user's body.</p><p id="p-0145" num="0184">In a first example, the first optics CAM is arranged to sense images of a hand of the user and the second optics CAM is arranged to sense images of the upper part of the user.</p><p id="p-0146" num="0185">In a second example, the second optics CAM may be arranged to sense images of a body part of a second user.</p><p id="p-0147" num="0186">Method for Generating a Signal</p><p id="p-0148" num="0187">In one embodiment, the present invention comprises hardware means and/or software means coupled to the touchpad PT for implementing a method for generating a signal S<sub>1</sub>.</p><p id="p-0149" num="0188">In one embodiment, the system according to the present invention comprises a first calculator K<sub>1</sub>. The first calculator K<sub>1 </sub>comprises software means for generating at least one first setpoint C<sub>1</sub>. The first setpoint C<sub>1 </sub>is associated with the production of a first signal S<sub>1</sub>. Each first setpoint C<sub>1 </sub>is generated based on the location and intensity of a pressure exerted on the touchpad PT. This setpoint can be used to generate said first signal S<sub>1</sub>. One advantage is that when the musical instrument is not integrated into the system of the invention, the setpoint can be transferred to the input of the musical instrument for the latter to generate a sound. When the instrument is integrated into the system, the setpoint can be directly operated by the system to produce the signal S<sub>1</sub>.</p><p id="p-0150" num="0189">Calculator K<sub>1 </sub></p><p id="p-0151" num="0190">The first calculator K<sub>1 </sub>is connected to the touch detection device DD of the touchpad PT. The first calculator K<sub>1 </sub>may be connected to the memory module of the touch detection device DD.</p><p id="p-0152" num="0191">In one embodiment, the first calculator K<sub>1 </sub>comprises software means for implementing the following steps of:<ul id="ul0017" list-style="none">    <li id="ul0017-0001" num="0000">    <ul id="ul0018" list-style="none">        <li id="ul0018-0001" num="0192">Receiving information comprising at least the location of a pressure exerted on the touchpad PT;</li>        <li id="ul0018-0002" num="0193">Associating said location with a first signal S<sub>1</sub>, for example from a library or a database storing prerecorded data; and</li>        <li id="ul0018-0003" num="0194">Generating a first setpoint C<sub>1 </sub>associated with the production of said first signal S<sub>1</sub>.</li>    </ul>    </li></ul></p><p id="p-0153" num="0195">If the instrument is not integrated into the system, one interest is to use libraries on demand, that is pre-established according to the instruments. The setpoint can be easily associated with a sound library of an instrument. Thus, making an instrument compatible with the touchpad can be easily performed.</p><p id="p-0154" num="0196">The information transmitted by the touch detection device DD may comprise the following information:<ul id="ul0019" list-style="none">    <li id="ul0019-0001" num="0000">    <ul id="ul0020" list-style="none">        <li id="ul0020-0001" num="0197">The location of the at least one pressure exerted on the touchpad PT;</li>        <li id="ul0020-0002" num="0198">The intensity of the at least one pressure exerted on the touchpad PT.</li>    </ul>    </li></ul></p><p id="p-0155" num="0199">The first setpoint C<sub>1 </sub>is generated based on the information received by the touch detection device DD. The first setpoint C<sub>1 </sub>is generated based on the location and/or intensity of the at least one pressure exerted on the touchpad PT.</p><p id="p-0156" num="0200">The touch detection device DD can detect at least two pressures exerted on the touchpad PT at two different locations. The touch detection device DD then generates information including the location of each pressure and the intensity associated with each pressure.</p><p id="p-0157" num="0201">In one embodiment, the first calculator K<sub>1 </sub>generates as many first setpoints C<sub>1 </sub>as there are pressures detected by the touch detection device DD. Each setpoint is associated with the production of a signal based on the location and intensity of a pressure.</p><p id="p-0158" num="0202">Preferably, the first signal S<sub>1 </sub>associated with the first setpoint C<sub>1 </sub>generated by the first calculator K<sub>1 </sub>is a sound signal. In this embodiment, each touch cell CT can be associated, for example, with a musical note. The frequency of the first sound signal S<sub>1 </sub>associated with the first setpoint C<sub>1 </sub>depends on the location of the pressure exerted on the touchpad PT. This can be configured in a prior step to prepare the touchpad for a specific use.</p><p id="p-0159" num="0203">In one embodiment, the frequency of a sound signal to be produced is associated with several simultaneous notes, for example when several simultaneous pressures are exerted on the touchpad PT.</p><p id="p-0160" num="0204">The first setpoint C<sub>1 </sub>preferably comprises a MIDI (Musical Instrument Digital Interface) control message. The MIDI protocol is a communication protocol and a file format dedicated to music. The MIDI control can comprise information about the frequency of a sound signal to be produced. The frequency corresponds to the note associated with the sound signal to be produced.</p><p id="p-0161" num="0205">Preferably, the information of the frequency of a sound signal to be produced is determined based on the at least one location of the pressure exerted on the touchpad PT.</p><p id="p-0162" num="0206">The MIDI control may include information on a particular timbre to be applied to the sound signal to be produced. The timbre makes it possible, for example, to reproduce the same note produced with two different instruments. The timbre may be determined depending on the location of the pressure exerted on the touchpad PT.</p><p id="p-0163" num="0207">The MIDI control may include information about the velocity associated with the note. Preferably, the velocity of the note is determined based on the intensity of the pressure exerted on the touchpad PT.</p><p id="p-0164" num="0208">The MIDI control of the first setpoint C<sub>1 </sub>may comprise information for triggering and/or stopping the production of the first sound signal S<sub>1</sub>.</p><p id="p-0165" num="0209">Preferably, the MIDI control message may be produced during the entire time that the at least one pressure is exerted on the touchpad PT.</p><p id="p-0166" num="0210">Calculator K<sub>2 </sub></p><p id="p-0167" num="0211">The system according to the present invention includes a second calculator K<sub>2</sub>. The second calculator K<sub>2 </sub>includes software means for generating a second setpoint C<sub>2</sub>. The second setpoint C<sub>2 </sub>is associated with the production of at least one special effect.</p><p id="p-0168" num="0212">The second calculator K<sub>2 </sub>comprises software means for implementing the following steps of:<ul id="ul0021" list-style="none">    <li id="ul0021-0001" num="0000">    <ul id="ul0022" list-style="none">        <li id="ul0022-0001" num="0213">Receiving images captured by the optical detection device OPT;</li>        <li id="ul0022-0002" num="0214">Determining at least one motion parameter D<b>1</b> based on the captured images; and</li>        <li id="ul0022-0003" num="0215">Generating a second setpoint C<sub>2 </sub>based on said motion parameter D<b>1</b>.</li>    </ul>    </li></ul></p><p id="p-0169" num="0216">In one embodiment, the second calculator K<sub>2 </sub>and the first calculator K<sub>1 </sub>are the same calculator.</p><p id="p-0170" num="0217">Learning-Based Artificial Intelligence Algorithm</p><p id="p-0171" num="0218">In one embodiment, the second calculator K<sub>2 </sub>comprises a supervised learning agent. The supervised learning agent may comprise a learning-based artificial intelligence algorithm.</p><p id="p-0172" num="0219">The supervised learning agent is trained on examples of gestures performed by different individuals. According to an example of embodiment, the artificial intelligence algorithm allows, from a trained neural network, a gesture to be classified according to a classifier. The detection of the gesture and its class then allows a special effect to be associated to it.</p><p id="p-0173" num="0220">In one embodiment, the system according to the invention comprises a display means. The display means makes it possible to represent data relating to the motion parameter D<b>1</b>.</p><p id="p-0174" num="0221">Reinforcement Learning Agent</p><p id="p-0175" num="0222">In one embodiment, the second calculator K<sub>2 </sub>comprises a reinforcement learning agent. Advantageously, the reinforcement agent allows a positive or negative feedback RET from the user to the agent regarding its current or past action to be performed iteratively.</p><p id="p-0176" num="0223">The user can thus, when generating the second signal S<b>2</b> by the signal generator, give a positive or negative comment on the special effect applied to the first signal S<sub>1</sub>. The reinforcement learning agent thus continues to associate a motion parameter D<b>1</b> with a special effect by discovering which associations are most positively or negatively rewarded. The reinforcement learning agent can thus modify the method for associating a motion parameter D<b>1</b> with a special effect to aim at a method whose associations are most rewarded.</p><p id="p-0177" num="0224">The step of generating GEN<sub>C2 </sub>a second setpoint C<sub>2 </sub>and/or the step of determining DET a motion parameter D<sub>1 </sub>may thus include a reinforcement learning agent.</p><p id="p-0178" num="0225">Advantageously, reinforcement learning agents allow progressive learning according to the user's feedback. The reinforcement learning agent thus allows the second calculator K<sub>2 </sub>to generate second setpoints comprising special effects that converge towards effects that are more liked by the user.</p><p id="p-0179" num="0226">In this embodiment, the system includes a user interface INU. The user interface INU enables the second calculator K<sub>2 </sub>to be provided with feedback data R<b>1</b>.</p><p id="p-0180" num="0227">The second calculator K<sub>2 </sub>is configured to modify the mode of generation of the second setpoint C<sub>2 </sub>based on the images received depending on the feedback data by iteration.</p><p id="p-0181" num="0228">Generation of a Setpoint C<sub>2 </sub></p><p id="p-0182" num="0229">The second calculator K<sub>2 </sub>comprises software means for implementing a step of generating a second setpoint C<sub>2 </sub>based on said motion parameter D<b>1</b>. Preferably, the second calculator K<sub>2 </sub>associates the motion parameter D<b>1</b> with a special effect.</p><p id="p-0183" num="0230">The second setpoint C<sub>2 </sub>is associated with a special effect. The special effect is intended to be applied to the first signal S<sub>1 </sub>generated by the first calculator</p><p id="p-0184" num="0231">In one embodiment, the special effect is selected from a library of special effects. The system may comprise a memory comprising a library of special effects. The second calculator K<sub>2</sub>, then selects a special effect from the library based on the motion parameter D<b>1</b>. The association between a given motion and a special effect can be preconfigured. According to one embodiment, this association is made free for the user from a configuration interface.</p><p id="p-0185" num="0232">In one embodiment, the special effect is selected from the library depending on the type of motion detected. The intensity value of the special effect to be applied can be determined depending on the intensity and/or amplitude of the recognized gesture.</p><p id="p-0186" num="0233">In one embodiment, the second setpoint C<sub>2 </sub>comprises several special effects that can be combined, especially when several gestures are recognized simultaneously.</p><p id="p-0187" num="0234">Signal Generator</p><p id="p-0188" num="0235">The system also comprises a signal generator GEN. The signal generator GEN is connected to the first calculator K<sub>1 </sub>and the second calculator K<sub>2</sub>. The signal generator receives the first setpoint C<sub>1 </sub>generated by the first calculator K<sub>1</sub>. The signal generator GEN receives the second setpoint C<sub>2 </sub>generated by the second calculator K<sub>2</sub>.</p><p id="p-0189" num="0236">The signal generator GEN generates a second signal S<sub>2</sub>. The second signal S<sub>2 </sub>is produced based on the first setpoint C<sub>1 </sub>and/or the first signal S<sub>1</sub>. The second signal S<sub>2 </sub>is also produced based on the second setpoint C<sub>2</sub>. Preferably, the second signal S<sub>2 </sub>comprises the first signal S<sub>1 </sub>to which a special effect extracted from the second setpoint C<sub>2 </sub>is applied.</p><p id="p-0190" num="0237">In one embodiment, the signal generator GEN produces a control signal comprising the second signal S<sub>2</sub>. Preferably, the signal generator GEN produces a control message, most preferably a MIDI control message. The MIDI control message includes the second sound signal S<sub>2</sub>.</p><p id="p-0191" num="0238">Single Case</p><p id="p-0192" num="0239">In one embodiment, the touchpad PT, the optical detection device OPT, the first calculator K<sub>1</sub>, the second calculator K<sub>2 </sub>and the signal generator are included in a single case.</p><p id="p-0193" num="0240">The single case preferably includes a means for transmitting the second signal S<sub>2</sub>. The single case advantageously allows the user to have only one item of equipment to carry. Preferably, the means for transmitting the second signal S<sub>2 </sub>is a speaker or an amplifier.</p><p id="p-0194" num="0241">In the latter case, the system of the invention is a musical instrument.</p><p id="p-0195" num="0242">In one embodiment, the single case comprises means for communicating with a second touchpad similar to the touchpad of the present invention. The invention then allows two musicians to play together remotely.</p><p id="p-0196" num="0243">In one embodiment not represented, the system comprises a first case comprising the touchpad PT and a second case comprising the optical detection device OPT and means for communicating between the two cases, for example via an internet network.</p><p id="p-0197" num="0244">The system can then be used by two remote users. When the two cases generate setpoints that can be received, for example, by a musical instrument, the latter can be associated locally with one of the cases or can also be accessible via a data network. Thus according to an example case, a first user manipulates the first case at a first position, the data whose setpoints are then transmitted to the musical instrument via a data network and a second user manipulates the second case at a second position, the data whose setpoints are sent via a data network to the musical instrument. The musical instrument is then capable of synthesizing a note that corresponds to the product of a first setpoint and a second setpoint. A use case can be the production of a sound sequence between different artists during a live event.</p><p id="p-0198" num="0245">Other Fields of Application of the Invention than the Field of Music</p><p id="p-0199" num="0246">The present invention may find application in other fields than the field of music.</p><p id="p-0200" num="0247">In a first alternative embodiment, the present invention is intended to be used in the field of lighting, especially stage lighting.</p><p id="p-0201" num="0248">For example, the system is intended to be connected to a lighting system comprising a plurality of light sources. The first signal S<sub>1 </sub>may comprise information of the light source to be activated.</p><p id="p-0202" num="0249">The special effect included in the second setpoint C<sub>2 </sub>may include a modulation of the intensity or wavelength emitted by the light source. The second setpoint C<sub>2 </sub>may also include a change in the orientation of the light source.</p><p id="p-0203" num="0250">Advantageously, the invention makes it possible to produce a second signal S<sub>2 </sub>for controlling a stage lighting device.</p><p id="p-0204" num="0251">In a second alternative embodiment, the present invention is intended to be used in the field of hologram control or the field of video games.</p><p id="p-0205" num="0252">For example, the system is intended to be connected to a device for generating a hologram. The first signal S<sub>1 </sub>may comprise information including a shape of a hologram.</p><p id="p-0206" num="0253">The special effect included in the second setpoint C<sub>2 </sub>may comprise position information. The second setpoint C<sub>2 </sub>then allows the hologram whose shape has been determined by the first signal to be set in motion.</p><p id="p-0207" num="0254">Method for generating a signal According to a second aspect, the invention relates to a method for generating a signal. An embodiment of said method is illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0208" num="0255">The method comprises a step of acquiring ACQ the location and intensity of a user's pressure on a touchpad PT comprising a plurality of touch cells.</p><p id="p-0209" num="0256">The method comprises a step of producing PROD the first setpoint C<sub>1 </sub>associated with the production of the first signal S<sub>1</sub>.</p><p id="p-0210" num="0257">The method includes a step of acquiring CAPT at least one image by the optics CAM.</p><p id="p-0211" num="0258">In one embodiment, the step of acquiring CAPT at least one image comprises acquiring at least one image comprising at least one part of a user, preferably a hand of the user.</p><p id="p-0212" num="0259">The method includes a step of determining DET at least one motion parameter D<b>1</b> based on the acquired images.</p><p id="p-0213" num="0260">Image Processing</p><p id="p-0214" num="0261">In one embodiment, the second calculator K<sub>2 </sub>comprises software means for implementing a step of processing the images acquired by the optics CAM.</p><p id="p-0215" num="0262">In one simplified embodiment of the invention, the second calculator K<sub>2 </sub>allows simple motions and/or simple positions and/or speeds of movement of the hand to be detected. This is the case for simple motions of, for example, an arm moving from left to right or up and down.</p><p id="p-0216" num="0263">In one enriched embodiment of the invention, the second calculator K<sub>2 </sub>is configured to detect hand postures, finger motions or complex gestures involving a sequence of linked motions. The enhanced embodiment may also comprise detection according to the simplified mode. The two embodiments may be combined.</p><p id="p-0217" num="0264">According to one embodiment, the image processing results in the generation of an image comprising at least points of interest of the user.</p><p id="p-0218" num="0265">In one embodiment, the optical detection device OPT or the first calculator K<sub>1 </sub>comprises a module for processing images IMG<sub>1</sub>. The image processing module generates at least one second image IMG<sub>2</sub>. The second image IMG<sub>2 </sub>includes a shape of at least the points of interest extracted from the first image IMG<sub>1</sub>. This can be for example tips of a limb such as the finger tips, joint points, shape contours, etc.</p><p id="p-0219" num="0266">Adaptive Threshold</p><p id="p-0220" num="0267">The generation of the second image IMG<sub>2 </sub>follows the step of receiving a captured image IMG<sub>1 </sub>by the optical detection device OPT.</p><p id="p-0221" num="0268">The generation of the second image IMG<sub>2 </sub>may include a thresholding step. The thresholding step comprises applying one or more filters to the captured image IMG<sub>1</sub>.</p><p id="p-0222" num="0269">The filter may include a Laplacian filter. The Laplacian filter is used to sharpen the contours of the user's shapes. The filter may include a filter to decrease the noise of the captured image.</p><p id="p-0223" num="0270">Generating the second image IMG<sub>2 </sub>may comprise a step of exploiting a depth map obtained based on the image captured by the optical detection device OPT. The depth map comprises a point cloud for identifying for each pixel, or for each group of pixels, a value associated with the depth. The second image IMG<sub>2 </sub>can then advantageously be a 3D image.</p><p id="p-0224" num="0271">Detection of Regions of Interest</p><p id="p-0225" num="0272">According to one embodiment, the generation of the second image IMG<sub>2 </sub>comprises an enhancement of the representation of regions of interest.</p><p id="p-0226" num="0273">The detection of regions of interest is performed based on the images captured by the optics CAM, possibly the images generated by the thresholding step and/or by the step of creating a depth map. The detection of regions of interest comprising labeling each pixel or group of pixels.</p><p id="p-0227" num="0274">In the example of the user's hand shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the regions of interest may include the palm <b>53</b>, the wrist <b>54</b>, the first phalanges of each finger <b>52</b> (thumb, index finger, middle finger, ring finger, little finger), and the tip and/or last phalange <b>51</b> of each finger. In one embodiment not represented, the regions of interest may include each phalange of the fingers of the hand.</p><p id="p-0228" num="0275">In one embodiment, the detection of the regions of interest is implemented by a classifier following the implementation of an artificial intelligence algorithm for example configured based on a neural network. The classifier is a classifier for example previously trained by means of a set of hand images. The image database may comprise a database of hand images on which regions of interest have been manually annotated.</p><p id="p-0229" num="0276">In one alternative embodiment, the image database is generated from a parametric model to generate a large number of hand images comprising different positions or poses. The parametric model generates images in which regions of interest are already labeled.</p><p id="p-0230" num="0277">The step of detecting regions of interest generates a labeled image of the user as output. Each pixel of the labeled image corresponding to the user is associated with a label corresponding to a region of interest.</p><p id="p-0231" num="0278">Generation of the Points of Interest</p><p id="p-0232" num="0279">Generating the second image IMG<sub>2 </sub>further comprises a step of generating points of interest. The points of interest may be generated based on the labeled image comprising the areas of interest.</p><p id="p-0233" num="0280">The points of interest may include centers of mass <b>103</b>. The centers of mass <b>103</b> may be generated at coordinates substantially corresponding to the center of an area of interest. For example, a point of interest may correspond to the center of mass of the palm of the hand.</p><p id="p-0234" num="0281">The points of interest may comprise deflection points <b>102</b>. Deflection points <b>102</b> are generated at the boundary between two adjacent areas of interest. For example, a point of interest may be generated between areas of interest corresponding to two adjacent phalanges of the same finger. The location of such a point of interest can then correspond to the location of a joint, for example between two phalanges. Preferably, generating a point of interest may comprise creating a point of interest substantially in the middle of a segment formed by the boundary between two adjacent areas of interest.</p><p id="p-0235" num="0282">Points of interest may include the tip or end of a finger <b>101</b>. Such a point of interest may be generated at the distal end of the region of interest corresponding to the last phalange of a finger, or corresponding to a center of mass of the region of interest corresponding to the last phalange of a finger.</p><p id="p-0236" num="0283">In one embodiment, the step of generating the points of interest <b>103</b>, <b>102</b>, <b>101</b> comprises generating at least one point of interest per region of interest.</p><p id="p-0237" num="0284">In one embodiment, the step of generating the points of interest comprises generating depth coordinates of each point of interest.</p><p id="p-0238" num="0285">The step of generating the points of interest outputs an image or depth map comprising the points of interest extracted from the image generated by the step of detecting areas of interest.</p><p id="p-0239" num="0286">Generation of a Skeleton</p><p id="p-0240" num="0287">In one embodiment, generating the second image IMG<b>2</b> may include a step of generating a skeleton. The skeleton is generated by connecting together points of interest in a predetermined manner.</p><p id="p-0241" num="0288"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a skeleton <b>104</b> obtained by connecting certain points of interest <b>102</b>, <b>101</b>. For example, the points of interest corresponding to the joints <b>102</b> of the same finger are connected together.</p><p id="p-0242" num="0289">The step of generating a skeleton outputs an image IMG<sub>2 </sub>or a depth map IMG<sub>2 </sub>comprising the points of interest and a skeleton connecting the points of interest together so as to reproduce the shape of the user.</p><p id="p-0243" num="0290">Advantageously, the step of generating a skeleton allows a hand model to be mapped onto the points of interest.</p><p id="p-0244" num="0291">The second image IMG<sub>2 </sub>may comprise the image and/or depth map generated by the step of generating the points of interest and/or the step of generating a skeleton.</p><p id="p-0245" num="0292">The skeleton may comprise segments connecting certain points of interest together.</p><p id="p-0246" num="0293">Motion Parameter</p><p id="p-0247" num="0294">In one embodiment, determining a motion parameter D<b>1</b> comprises detecting at least one type of motion of a user based on the captured images.</p><p id="p-0248" num="0295">Preferably, detecting a type of motion of a user comprises detecting a motion of a user's hand. Detecting a motion is performed based on the images captured by the optical detection device OPT.</p><p id="p-0249" num="0296">By &#x201c;based on the captured images&#x201d;, it is included herein the raw images as captured by the optics CAM as well as the images generated by the processing of these images, for example the images IMG<sub>2 </sub>generated from the generation of the point of interest. Also included are any two-dimensional images or any depth maps.</p><p id="p-0250" num="0297">Preferably, the different types of motion are listed in a library. The calculator can then perform a fitting operation or an analytical regression operation to determine a particular type of motion based on the captured images.</p><p id="p-0251" num="0298"><figref idref="DRAWINGS">FIGS. <b>9</b>A to <b>9</b>I</figref> illustrate examples of types of motions of the hand. These types of motions are recognizable by the second calculator K<sub>2</sub>. The second calculator K<sub>2 </sub>generates a motion parameter D<b>1</b> based on the detected type of motion.</p><p id="p-0252" num="0299">Examples of types of motion of the hand may comprise a rotational motion of the wrist with closed fist (<figref idref="DRAWINGS">FIG. <b>9</b>B</figref>), a rotation of the hand along a longitudinal axis of the forearm (<figref idref="DRAWINGS">FIG. <b>9</b>E</figref>), along an axis perpendicular to the longitudinal axis of the forearm (<figref idref="DRAWINGS">FIGS. <b>9</b>D and <b>9</b>F</figref>). Another example of a type of motion may comprise a transverse movement of the hand (<figref idref="DRAWINGS">FIGS. <b>9</b>I, <b>9</b>H, and <b>9</b>G</figref>).</p><p id="p-0253" num="0300">The type of motion may also depend on the position and/or motion of the finger joints. For example, the type of motion may be different if the wrist rotation gesture is performed with the hand open or closed. Certain types of motions may be associated with personalities' known gestures in the musical or audiovisual world. For example, a type of downward hand closing motion executed at a speed beyond a threshold while simultaneously tightening the fingers may be characteristic of a &#x201c;hand closing according to Ardisson&#x201d;. According to another example, a simultaneous closing of the hand and a transverse motion of the elbow may be characteristic of a hand closing motion according to the host Nagui. Another example of a type of motion illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref> may include a closing of the fingers of the hand with the fingers extended. Another example of the type of motion may include a wobble of the hand in a manner that mimics the motion of a wave, as represented in <figref idref="DRAWINGS">FIG. <b>9</b>C</figref>.</p><p id="p-0254" num="0301">The type of motion may also be a function of the direction of the gesture. For example, a translational hand movement gesture may be discriminated depending on the plane and/or direction of translation. For example, in <figref idref="DRAWINGS">FIG. <b>9</b>G</figref>, the translation is performed along the axis perpendicular to the palm of the hand. <figref idref="DRAWINGS">FIGS. <b>9</b>H and <b>9</b>G</figref> illustrate a translation motion of the hand in the same plane with one motion in the direction perpendicular to the longitudinal direction of the fingers (<figref idref="DRAWINGS">FIG. <b>9</b>H</figref>) and the other in a direction parallel to the longitudinal direction of the fingers (<figref idref="DRAWINGS">FIG. <b>9</b>I</figref>). In another example, a wrist rotation can be detected in the plane.</p><p id="p-0255" num="0302">Preferably, the motion parameter D<sub>1 </sub>also includes determining the speed and/or amplitude of the motion.</p><p id="p-0256" num="0303">Second Setpoint</p><p id="p-0257" num="0304">The method comprises a step of generating GEN<sub>C2 </sub>the second setpoint C<sub>2 </sub>based on the motion parameter D<b>1</b>. The second setpoint C<sub>2 </sub>is associated with a special effect.</p><p id="p-0258" num="0305">Special Sound Effects</p><p id="p-0259" num="0306">In the embodiment where the first signal S<sub>1 </sub>is a sound signal, the special effect is a special effect of altering the sound signal.</p><p id="p-0260" num="0307">The special effect can be selected from one or more of the following special effects:<ul id="ul0023" list-style="none">    <li id="ul0023-0001" num="0000">    <ul id="ul0024" list-style="none">        <li id="ul0024-0001" num="0308">&#x25aa;A signal reverberation: effect obtained by creating repeated sounds based on the first sound signal, with a delay not exceeding 60 ms, so that the brain cannot distinguish each sound separately.</li>        <li id="ul0024-0002" num="0309">An echo: effect achieved by repeating the first sound signal with a delay time long enough for the human brain to perceive the two sounds separately.</li>        <li id="ul0024-0003" num="0310">A distortion: effect achieved by amplifying the first sound signal strongly in order to clip it or flatten it.</li>        <li id="ul0024-0004" num="0311">Sustain: effect achieved by maintaining the first sound signal in time after having triggered it.</li>        <li id="ul0024-0005" num="0312">A wha-wha: effect achieved by passing the first sound signal through a bandpass filter.</li>        <li id="ul0024-0006" num="0313">A vibrato: effect achieved by modulating the frequency of the first sound signal around its original value.</li>        <li id="ul0024-0007" num="0314">&#x25aa;A tremolo: effect achieved by modulating the amplitude (and therefore the volume) of the first sound signal.</li>    </ul>    </li></ul></p><p id="p-0261" num="0315">The special effect can be selected from a library that can also include phase shifting of the sound signal, frequency transposition of the sound signal, modification of the timbre, filtering of the sound signal, stopping of the sound signal.</p><p id="p-0262" num="0316">In one embodiment, the special effect is selected from a modulation of the signal intensity. The intensity of the signal S<sub>2 </sub>can thus be controlled firstly by the intensity of the pressure exerted on the touchpad PT and/or by a gesture of the user sensed by the optical detection device OPT.</p><p id="p-0263" num="0317">Second Signal</p><p id="p-0264" num="0318">The method comprises a step of generating GEN<sub>S2 </sub>the second signal S<sub>2 </sub>based on the first setpoint C<sub>1 </sub>or the first signal S<sub>1 </sub>and based on the second setpoint C<sub>2</sub>.</p><p id="p-0265" num="0319">In one embodiment, the method comprises a step of applying the special effect to the first signal S<sub>1</sub>. The application consists, for example, in a modulation, a mix, or even more generally a combination of signals that can be of any type. According to one example, the effect is applied to a portion only of the first signal. According to another example, the effect is produced over a given period of time and is applied to all first signals produced in this period of time.</p><p id="p-0266" num="0320">Transmission of the Second Signal S<sub>2 </sub></p><p id="p-0267" num="0321">In one embodiment, the method comprises generating and transmitting the second signal S<sub>2</sub>. The second signal S<sub>2 </sub>is preferably transmitted to a device capable of applying the signal such as a control device or a sound device. This may be a speaker, a loudspeaker or more generally any type of membrane capable of making the second signal S<sub>2 </sub>audible.</p><p id="p-0268" num="0322">Preferably, generating the second signal is preceded by a step of generating a third setpoint, the third setpoint being associated with the second signal. The method and the system are then advantageously capable of transmitting the generated second signal, for example in the form of a MIDI message.</p><p id="p-0269" num="0323">Alternative</p><p id="p-0270" num="0324">Alternatively, the first setpoint generated based on the location and intensity of the pressure on the touchpad is associated with a special effect. The second setpoint generated based on the motion parameter is associated with the production of a first signal.</p><p id="p-0271" num="0325">The second signal is then generated based on the second setpoint (or the first signal) to which a special effect extracted from the first setpoint is applied.</p><p id="p-0272" num="0326">This alternative allows, for example, the user to generate a first signal associated with a note using the optical detection device and apply a special effect to said first signal, the special effect being selected based on the location and/or intensity of pressure on the touchpad.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system for generating a signal comprising:<claim-text>a touchpad comprising a plurality of touch cells and a touch detection device for detecting the location and intensity of at least one pressure exerted on said touchpad;</claim-text><claim-text>an optical detection device for detecting a motion of a hand a position comprising at least one optics for capturing images;</claim-text><claim-text>a first calculator configured to generate at least one first setpoint based on the location and the intensity of said at least one pressure,</claim-text><claim-text>a second calculator for determining at least one motion parameter based on the rotational motion of the wrist or of at least one finger and/or on the direction of translation of a translational hand or finger movement gesture based on the captured images by the optical detection device and for generating a second setpoint based on said at least one motion parameter; and</claim-text><claim-text>a signal generator for producing a second signal based on:<claim-text>the first setpoint or a first signal extracted from the first setpoint to which a special effect extracted from the second setpoint is applied; or</claim-text><claim-text>the second setpoint or a first signal extracted from the second setpoint to which a special effect extracted from the first setpoint is applied.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first signal and the second signal are sound signals.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the signal generator is configured to produce the second signal as a third setpoint.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each touch cell CT comprises:<claim-text>a first layer comprising at least one force sensing resistor; and</claim-text><claim-text>a second layer comprising a detection cell adapted to detect a variation in the resistivity of the force sensing resistor.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein each detection cell comprises a printed circuit comprising at least a first portion and a second portion connected to each other through the force sensing resistor of the first layer.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the motion parameter is determined based on an amplitude, speed of the hand and/or direction of a finger of the hand.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the optical detection device for detecting a motion of a hand comprises a stereo camera.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a user interface for providing the second calculator with a feedback data and wherein the second calculator comprises a reinforcement learning algorithm, configured to modify a mode of generation of the second setpoint depending on the feedback data by iteration.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said system is a musical instrument and wherein the touchpad and the optical detection device are integrated into a single case.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein each touch cell comprises a lighting source for producing a light signal when a pressure is exerted on said touch cell.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A method for generating a signal comprising:<claim-text>acquiring a location and intensity of a pressure on a touchpad having a plurality of touch cells;</claim-text><claim-text>producing a first setpoint EGO based on the acquired location and intensity;</claim-text><claim-text>acquiring at least one image by at least one optics;</claim-text><claim-text>determining at least one motion parameter comprising the detection of a rotational motion of the wrist or of at least one finger and/or on the direction of translation of a translational hand or finger movement gesture based on the acquired at least one image;</claim-text><claim-text>generating a second setpoint based on the motion parameter;</claim-text><claim-text>generating a second signal based on:<claim-text>the first setpoint or a first signal associated with the first setpoint to which a special effect extracted from the second setpoint is applied; or</claim-text><claim-text>the second setpoint or a first signal associated with the second setpoint to which a special effect extracted from the first setpoint is applied.</claim-text></claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the motion parameter is also determined based on an amplitude, speed and/or direction of a hand and/or a finger of the hand.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first sound signal corresponds to a musical note.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein determining at least one motion parameter EDI comprises detecting points of interest.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein determining at least one motion parameter based on the acquired images comprises generating a depth map, said motion parameter being determined also depending on said depth map.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein said special effect comprises one or more of the elements listed below:<claim-text>a reverberation,</claim-text><claim-text>an echo,</claim-text><claim-text>a distortion,</claim-text><claim-text>a sustain,</claim-text><claim-text>a wha-wha,</claim-text><claim-text>a vibrato,</claim-text><claim-text>a phase shift.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. (canceled)</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A non-transitory computer-readable data storage medium having recorded thereon a computer program comprising program code instructions for implementing the method of <claim-ref idref="CLM-00011">claim 11</claim-ref>.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The system according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the stereo camera is an infrared stereo camera.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the point of interests are finger tips, the center of mass and/or a deflection point.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005135A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005135</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17792526</doc-number><date>20210111</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>25</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>0012</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>25</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30204</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>20172</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10116</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">IMAGE ENHANCEMENT BASED ON FIBER OPTIC SHAPE-SENSING</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>62960964</doc-number><date>20200114</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>KONINKLIJKE PHILIPS N.V.</orgname><address><city>EINDHOVEN</city><country>NL</country></address></addressbook><residence><country>NL</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>BYDLON</last-name><first-name>Torre Michelle</first-name><address><city>MELROSE</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>FLEXMAN</last-name><first-name>Molly Lara</first-name><address><city>MELROSE</city><state>MA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>FLORENT</last-name><first-name>Raoul</first-name><address><city>VILLE D'AVRAY</city><country>FR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>BULLENS</last-name><first-name>Roland Wilhelmus Maria</first-name><address><city>MIERLO</city><country>NL</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2021/050399</doc-number><date>20210111</date></document-id><us-371c12-date><date>20220713</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present invention relates to an image processing system (<b>10</b>), comprising: a processor unit (<b>20</b>) arranged to receive imaging data associated with an imaging system (<b>40</b>) and optical shape sensing data associated with an optical shape sensing system (<b>50</b>) registered with the imaging system (<b>40</b>) such that the optical shape sensing data can be positioned in the imaging system; wherein the processor unit (<b>20</b>) is configured to define in the imaging data a region of interest based on the imaging data and/or the optical shape sensing data and further configured to use the optical shape sensing data as markers within the region of interest such that the processor unit applies image enhancement of imaging data on the region of interest based on received optical shape sensing data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="74.08mm" wi="95.08mm" file="US20230005135A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="146.30mm" wi="97.11mm" file="US20230005135A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="171.53mm" wi="123.36mm" file="US20230005135A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="167.89mm" wi="122.85mm" file="US20230005135A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="149.78mm" wi="130.39mm" file="US20230005135A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="146.22mm" wi="128.02mm" file="US20230005135A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD OF THE INVENTION</heading><p id="p-0002" num="0001">The present invention relates to systems and methods for enhancement of views during interventions for medical imaging system.</p><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0003" num="0002">Minimally invasive interventions can be performed under X-ray guidance. To minimize the amount of radiation, physicians compromise on image quality. Low signal to noise objects in X-ray images, like stent struts and calcifications can be enhanced using image integration, like StentBoost: the latter is about stent enhancement in the image by showing finer details of the stent struts, while background noise and anatomical structures are faded out. This only works if images can be correctly superimposed. This implies that markers are identifiable and that motion of the device is not overlay out-of-plane</p><heading id="h-0003" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0004" num="0003">It would be advantageous to have improved techniques for image enhancement during interventions.</p><p id="p-0005" num="0004">The object of the present invention is solved with the subject matter of the independent claims, wherein further embodiments are incorporated in the dependent claims.</p><p id="p-0006" num="0005">It should be noted that the following described aspects and examples of the invention apply also to the device, the method, as well as to the computer program element and a computer readable medium.</p><p id="p-0007" num="0006">In a first aspect, there is provided an image processing system, comprising: a processor unit arranged to receive imaging data associated with an imaging system and optical shape sensing data associated with an optical shape sensing system registered with the imaging system such that the optical shape sensing data can be positioned in the imaging system; wherein the processor unit is configured to define in the imaging data a region of interest based on the imaging data and/or the optical shape sensing data and further configured to use the optical shape sensing data as markers within the region of interest such that the processor unit applies image enhancement of imaging data on the region of interest based on received optical shape sensing data.</p><p id="p-0008" num="0007">In this manner, for example, StentBoost improved image quality by identifying markers in an image and using them to perform motion compensation across image frames to then improve image quality. The algorithm struggles when multiple markers are present, when no markers can be seen, or to extrapolate to a more generic marker that cannot be predefined. Combining FORS with StentBoost can address these challenges by limiting the search range in the image and providing 3D localization of devices.</p><p id="p-0009" num="0008">In other words, embedding optical shape sensing (&#x201c;OSS&#x201d;) fiber in the interventional instrument is provided according to an example of the present invention and using it as marker once co-registered with the imaging system, like for instance interventional X-ray imaging system, magnetic resonance systems or ultrasonic imaging systems.</p><p id="p-0010" num="0009">The present invention advantageously provides that during vascular procedures it can be difficult to obtain high quality images of therapy devices (stents, balloons, endografts, etc.) due to their small size, obstruction by other devices in the field of view, motion artefacts, or just from the anatomy itself. In addition, as devices become smaller and more tissue-like, they also lose some of the features that are visible via imaging.</p><p id="p-0011" num="0010">StentBoost was developed to overcome some of these challenges, however, knowing the exact location of the guidewires, catheters, stents or endografts may further improve the image quality of these types of devices. There are two specific cases that are particularly challenging:</p><p id="p-0012" num="0011">i. When there are multiple markers that are present in the image and it is difficult to identify which ones are associated with the device of interest.</p><p id="p-0013" num="0012">ii. When the markers are very difficult to visualize in X-ray (e.g. biodegradable stents)</p><p id="p-0014" num="0013">iii. When enhancing an object or structure that doesn't have known markers (e.g. an anatomical structure such as a cap or a vessel)</p><p id="p-0015" num="0014">iv. Correcting for motion that is out of plane.</p><p id="p-0016" num="0015">The present invention advantageously provides that the system or device as defined by claim <b>1</b> utilizes for instance a FORS device, FORS system, imaging system (e.g. X-ray or ultrasound) and controller, an image processing system, and a visualization system. This invention assumes that the FORS device and the imaging system are co-registered in spatial coordinates.</p><p id="p-0017" num="0016">One aspect of the present invention is for instance provided in how to use the FORS device positional information to enhance image quality in another imaging modality (e.g. X-ray or ultrasound).</p><p id="p-0018" num="0017">Aspects of the present inventions for instance are based on</p><p id="p-0019" num="0018">Providing i) representation of the reconstructed OSS fiber and ii) image of an object, registered one to the other</p><p id="p-0020" num="0019">Defining region of interest based on data from i)&#x2014;e.g. around the tip of a OSS guidewire, a balloon, a stent, endograft . . . &#x2014;automatically or via user interface</p><p id="p-0021" num="0020">Searching and identifying markers close to the FORS data in that region of interest (i.e. only the markers located on the pathway)&#x2014;this will discard non-viable markers</p><p id="p-0022" num="0021">Applying StentBoost on that region of interest (contrast injections from a series of X-Ray images of the same region of interest) based on the identified markers</p><p id="p-0023" num="0022">Displaying i), ii) superposed with higher contrast in region of interests as a result of StentBoost</p><p id="p-0024" num="0023">According to an exemplary embodiment of the present invention, FORS 3D data can be used to further filter-out frames that are out of plane.</p><p id="p-0025" num="0024">According to an exemplary embodiment of the present invention, FORS shape in between 2 markers can be used to evaluate when there are shape changes to the stent (as opposed to the current technique that accounts for translation). Those frames can be dropped, or the FORS can be used to morph the shape of the device to match the other frames.</p><p id="p-0026" num="0025">According to an exemplary embodiment of the present invention, FORS data per se can be used as markers. This will speed up the computation time for image integration and reduce the number of false positive markers and will thereby improve the image quality.</p><p id="p-0027" num="0026">According to an exemplary embodiment of the present invention, known markers (balloon, stent, curved line of the guidewire, endograft, clip or valve device, a vessel outline, vessel bifurcations . . . ) can be recognized in a series of images for StentBoost.</p><p id="p-0028" num="0027">According to an exemplary embodiment of the present invention, by this way calcifications along the vessel and cap morphology of chronic total occlusions may also be visualized.</p><p id="p-0029" num="0028">According to an exemplary embodiment of the present invention, the processor unit is configured to apply the image enhancement to a series of contrast-enhanced X-Ray images of the region of interest taken by the imaging system.</p><p id="p-0030" num="0029">According to an exemplary embodiment of the present invention, the processor unit is configured to search and identify the markers in terms of restricting the markers a subgroup of markers located on the pathway for an interventional instrument.</p><p id="p-0031" num="0030">According to an exemplary embodiment of the present invention, the processor unit is configured to define the region of interest based on a location of a balloon, a stent, an endograft or an interventional instrument.</p><p id="p-0032" num="0031">According to an exemplary embodiment of the present invention, the processor unit is configured to use the optical shape sensing data to filter-out frames of the imaging system that are out of plane.</p><p id="p-0033" num="0032">According to an exemplary embodiment of the present invention, the processor unit is configured to use the optical shape sensing data in between at least two markers to evaluate a shape change of a interventional instrument or the interventional instrument.</p><p id="p-0034" num="0033">According to an exemplary embodiment of the present invention, the processor unit is arranged to receive imaging data associated with the imaging system in terms of a computed tomography system or a magnetic resonance imaging system or an ultrasound or an optical imaging system or a X-ray imaging system or a medical imaging system or a diagnostic imaging system.</p><p id="p-0035" num="0034">According to an exemplary embodiment of the present invention, the processor unit is configured to identify markers in series of images taken by the imaging system.</p><p id="p-0036" num="0035">According to an exemplary embodiment of the present invention, the series of images taken by the imaging system is part of the applied image enhancement on the region of interest.</p><p id="p-0037" num="0036">In a second aspect, there is provided an imaging system configured to communicate with the device according to the first aspect or any implementation of the first aspect.</p><p id="p-0038" num="0037">In a third aspect, there is provided an optical shape sensing system configured to communicate with the device according to the first aspect or any implementation of the first aspect. The optical shape sensing system configured to be registered with the device according to the second aspect or any implementation of the second aspect.</p><p id="p-0039" num="0038">In a fourth aspect, there is provided a method for embedding fiber optic shape sensing in an medical imaging device, the method comprising the following steps of:</p><p id="p-0040" num="0039">As a first step, the following is performed: receiving imaging data associated with an imaging system and optical shape sensing data associated with an optical shape sensing system registered with the imaging system such that the optical shape sensing data can be positioned in the imaging system by means of a processor unit.</p><p id="p-0041" num="0040">As a second step, the following is performed: defining, in the imaging data, a region of interest based on the imaging data and/or the optical shape sensing data and further using the optical shape sensing data as markers within the region of interest such that the processor unit applies image enhancement of imaging data on the region of interest based on received optical shape sensing data by means of the processor unit.</p><p id="p-0042" num="0041">According to an exemplary embodiment of the present invention, the method further includes the step of applying the image enhancement to a series of contrast-enhanced X-Ray images of the region of interest taken by the imaging system.</p><p id="p-0043" num="0042">According to an exemplary embodiment of the present invention, the method further includes the step of applying searching and identifying the markers in terms of restricting the markers a subgroup of markers located on the pathway for an interventional instrument.</p><p id="p-0044" num="0043">According to an exemplary embodiment of the present invention, the method further includes the step of applying searching and identifying the markers in terms of restricting the markers a subgroup of markers located on the pathway for an interventional instrument.</p><p id="p-0045" num="0044">The above aspects and examples will become apparent from and be elucidated with reference to the embodiments described hereinafter.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0046" num="0045">Exemplary embodiments will be described in the following with reference to the following drawings:</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a schematic set up of an image processing system for embedding fiber optic shape sensing in a medical imaging device according to an exemplary embodiment of the present invention;</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a method for embedding fiber optic shape sensing in a medical imaging device according to an exemplary embodiment of the present invention;</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example an optical shape sensed devices overlaid upon a preoperative CT showing their position inside the vasculature according to an exemplary embodiment of the present invention;</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example of an image of StentBoost showing better image quality of the stent according to an exemplary embodiment of the present invention; and</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example of defining a local region for enhancement based on FORS device and therapy device positions according to an exemplary embodiment of the present invention;</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example of using the local region around the FORS device in combination with a therapy device to restrict region of x-ray image for image processing according to an exemplary embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION OF EMBODIMENTS</heading><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a schematic set up of an image processing system, for example for embedding fiber optic shape sensing in a medical imaging device, according to an exemplary embodiment of the present invention. The image processing system <b>10</b> comprises a processor unit <b>20</b>. The image processing system <b>10</b> is configured to be for example connected to a display unit <b>30</b>. The image processing system <b>10</b> is configured to be connected to an imaging system <b>40</b>.</p><p id="p-0054" num="0053">The image processing system <b>10</b> is configured to be connected to an optical shape sensing system <b>50</b> registered with the imaging system <b>40</b>.</p><p id="p-0055" num="0054">The processor unit <b>20</b> is arranged to receive imaging data associated with an imaging system <b>40</b> and optical shape sensing data associated with an optical shape sensing system <b>50</b> registered with the imaging system <b>40</b> such that the optical shape sensing data can be positioned in the imaging system;</p><p id="p-0056" num="0055">The processor unit <b>20</b> is configured to define in the imaging data a region of interest based on the imaging data and/or the optical shape sensing data and further configured to use the optical shape sensing data as markers within the region of interest such that the processor unit applies image enhancement of imaging data on the region of interest based on received optical shape sensing data.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a method for embedding fiber optic shape sensing in a medical imaging device according to an exemplary embodiment of the present invention. The method comprises:</p><p id="p-0058" num="0057">As a first step, the following is performed: receiving S1 imaging data associated with an imaging system and optical shape sensing data associated with an optical shape sensing system registered with the imaging system such that the optical shape sensing data can be positioned in the imaging system by means of a processor unit.</p><p id="p-0059" num="0058">As a second step, the following is performed: defining S2, in the imaging data, a region of interest based on the imaging data and/or the optical shape sensing data and further using the optical shape sensing data as markers within the region of interest such that the processor unit applies image enhancement of imaging data on the region of interest based on received optical shape sensing data by means of the processor unit.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example an optical shape sensed devices overlaid upon a preoperative CT showing their position inside the vasculature according to an exemplary embodiment of the present invention.</p><p id="p-0061" num="0060">According to an exemplary embodiment of the present invention, the Fiber Optical RealShape, FORS, uses light along a multicore optical fiber for device localization and navigation during surgical intervention.</p><p id="p-0062" num="0061">According to an exemplary embodiment of the present invention, the principle involved makes use of distributed strain measurements in the optical fiber using characteristic Rayleigh backscatter or controlled grating patterns.</p><p id="p-0063" num="0062">According to an exemplary embodiment of the present invention, the shape along the optical fiber begins at a specific point along the sensor, known as the launch or z=0, and the subsequent shape position and orientation are relative to that point.</p><p id="p-0064" num="0063">According to an exemplary embodiment of the present invention, the optical shape sensing fibers can be integrated into medical devices in order to provide live guidance of the devices during minimally invasive procedures.</p><p id="p-0065" num="0064">According to an exemplary embodiment of the present invention, the integrated fiber provides the position and orientation of the entire device.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a shape-sensed guidewire and shape-sensed catheter used for navigation to the left renal artery overlaid upon a pre-operative CT image.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example of an image of StentBoost showing better image quality of the stent according to an exemplary embodiment of the present invention; and</p><p id="p-0068" num="0067">According to an exemplary embodiment of the present invention, the enhancement is provided by StentBoost which as such is a tool that enhances stent visualization in relation to the vessel walls.</p><p id="p-0069" num="0068">According to an exemplary embodiment of the present invention, the stent is enhanced in the image by showing finer details of the stent struts, while background noise and anatomical structures are faded out. This enables more precise positioning of the stent and the ability to correct for under-deployment immediately.</p><p id="p-0070" num="0069">According to an exemplary embodiment of the present invention, the StentBoost is used in terms of the product that improves the image quality of stents. It localizes the marker bands of the stent in each image frame, compensates for any motion, and then averages across the image frames to improve the contrast of the image. StentBoost is described in U.S. Pat. No. 728,962 B2: Medical Viewing System and Method for Detecting and Enhancing Structures in Noisy Images.</p><p id="p-0071" num="0070">According to an exemplary embodiment of the present invention, the enhancement or StentBoost takes a series of X-ray images and localizes a known marker (e.g. balloon/stent markers) to use for co-registration of a series of images. This technique fails when there are multiple markers present in the image. In this case, the FORS-enabled guidewire can be used to limit the search range for markers, as those markers will lie along the path of the guidewire. The search range can be determined around the FORS wire based on:</p><p id="p-0072" num="0071">Device type, e.g. narrow search for a stent/balloon, wider search for an endograft;</p><p id="p-0073" num="0072">Estimated FORS error, e.g. as a function of curvature, twist, length along the device;</p><p id="p-0074" num="0073">User-defined search region</p><p id="p-0075" num="0074">Imaging system settings, e.g. pixel resolution, type of imaging protocol;</p><p id="p-0076" num="0075">This technique still uses the markers in the, for example X-ray or ultrasound, image for motion compensation and reduces the accuracy requirements on the FORS device. The FORS device and x-ray system must be co-registered so that the coordinate systems are aligned.</p><p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example of defining a local region for enhancement based on FORS device and therapy device positions according to an exemplary embodiment of the present invention.</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example of FORS GW that can be used to localize the stent markers in the X-ray image. The FORS device is a guidewire used in combination with a UniCath hub to define the location of the stent. The region of the stent is used to define the search range for the stent markers.</p><p id="p-0079" num="0078">In the case where motion compensation is performed using the markers in the image, it is still challenging to account for out-of-plane motion. According to an exemplary embodiment of the present invention, the FORS 3D position can be used to filter out frames that are out of plane and to not include them in the averaging, or, to correct for the scaling that the out-of-plane motion will impact.</p><p id="p-0080" num="0079">According to an exemplary embodiment of the present invention, the FORS shape in between the two markers can be used to evaluate when there are shape changes to the stent (as opposed to the current technique that accounts for translation). Those frames can be dropped, or the FORS can be used to morph the shape of the device to match the other frames.</p><p id="p-0081" num="0080">According to an exemplary embodiment of the present invention, there are limited markers in the image that capture the device (e.g. bio-degradable stents). In this case the FORS position and shape of one or more nodes can be used directly as a localizer for motion compensation.</p><p id="p-0082" num="0081">According to an exemplary embodiment of the present invention, the FORS device and imaging system are co-registered so that the coordinate systems are aligned.</p><p id="p-0083" num="0082">According to an exemplary embodiment of the present invention, the FORS accuracy will be a limiting factor in the performance of this strategy. There are some additional approaches that can be used to improve accuracy specifically for the purpose of improving performance during the StentBoost.</p><p id="p-0084" num="0083">According to an exemplary embodiment of the present invention, the FORS accuracy is high immediately following registration, so this method could include an automatic registration step (including multiple image projections if necessary) in order to correct for FORS error prior to the StentBoost algorithm.</p><p id="p-0085" num="0084">According to an exemplary embodiment of the present invention, the FORS relative accuracy is also high in comparison to absolute accuracy. So the relative FORS motion can be used to correct for the device movement as opposed to the absolute FORS position.</p><p id="p-0086" num="0085">According to an exemplary embodiment of the present invention, the enhancement or StentBoost takes a series of X-ray images and localizes a known marker (e.g. balloon/stent markers) to use for co-registration of a series of images. This technique can be generalized to auto-identify suitable localizers in the image to be used as markers for motion compensation provided that the region for stabilization is restricted to relevant parts of the image. In this case, the FORS-enabled device can be used to establish a search region for localizers along the path of the guidewire. This technique then uses those auto-generated localizers in the (e.g. x-ray or ultrasound) image for motion compensation and reduces the accuracy requirements on the FORS device.</p><p id="p-0087" num="0086">According to an exemplary embodiment of the present invention, the FORS device and imaging system must be co-registered so that the coordinate systems are aligned.</p><p id="p-0088" num="0087">Localizers can be both anatomical or device based, such as:</p><p id="p-0089" num="0088">A curved line of the guidewire</p><p id="p-0090" num="0089">Markers on an endograft</p><p id="p-0091" num="0090">A clip or valve device</p><p id="p-0092" num="0091">A vessel outline in a DSA (at the tip of a FORS catheter) or vessel bifurcations</p><p id="p-0093" num="0092">The system can also have a library of pre-defined localizers to search for in the vicinity of the device, such as radio-opaque marker bands, fenestrations, mitraclip, etc. Alternatively the system can have a pre-defined set of typical features (e.g. edges, lines, dots, that it then automatically finds and identifies within the vicinity of the device).</p><p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example of using the local region around the FORS device in combination with a therapy device to restrict region of x-ray image for image processing according to an exemplary embodiment of the present invention.</p><p id="p-0095" num="0094"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example of FORS GW that can be used to identify a search range and then identify localizers in the vicinity of the wire on the endograft for use in stabilizing the image.</p><p id="p-0096" num="0095">The present invention can be applied to many applications such as vascular (guidewire, catheters, stent sheaths, deployment systems, etc.), endoluminal (endoscopes or bronchoscopes), orthopedic (k-wires &#x26; screwdrivers) as well as non-medical applications.</p><p id="p-0097" num="0096">In another exemplary embodiment, the present invention can apply to both Rayleigh (enhanced and regular) as well as Fiber Bragg implementations of shape sensing fiber. It also applies to both manual and robotic manipulation of such devices.</p><p id="p-0098" num="0097">In another exemplary embodiment, the present invention can apply to any imaging system used in conjunction with FORS including X-ray, ultrasound, MRI, CT, OCT, IVUS, endoscopy, etc.</p><p id="p-0099" num="0098">In another exemplary embodiment, a computer program or computer program element is provided that is characterized by being configured to execute the method steps of the method according to one of the preceding embodiments, on an appropriate system.</p><p id="p-0100" num="0099">The computer program element might therefore be stored on a computer unit, which might also be part of an embodiment. This computing unit may be configured to perform or induce performing of the steps of the method described above.</p><p id="p-0101" num="0100">Moreover, it may be configured to operate the components of the above described apparatus and/or system. The computing unit can be configured to operate automatically and/or to execute the orders of a user. A computer program may be loaded into a working memory of a data processor. The data processor may thus be equipped to carry out the method according to one of the preceding embodiments.</p><p id="p-0102" num="0101">This exemplary embodiment of the invention covers both, a computer program that right from the beginning uses the invention and computer program that by means of an update turns an existing program into a program that uses the invention.</p><p id="p-0103" num="0102">Further on, the computer program element might be able to provide all necessary steps to fulfill the procedure of an exemplary embodiment of the method as described above.</p><p id="p-0104" num="0103">According to a further exemplary embodiment of the present invention, a computer readable medium, such as a CD-ROM, USB stick or the like, is presented wherein the computer readable medium has a computer program element stored on it which computer program element is described by the preceding section.</p><p id="p-0105" num="0104">A computer program may be stored and/or distributed on a suitable medium, such as an optical storage medium or a solid state medium supplied together with or as part of other hardware, but may also be distributed in other forms, such as via the internet or other wired or wireless telecommunication systems.</p><p id="p-0106" num="0105">However, the computer program may also be presented over a network like the World Wide Web and can be downloaded into the working memory of a data processor from such a network. According to a further exemplary embodiment of the present invention, a medium for making a computer program element available for downloading is provided, which computer program element is arranged to perform a method according to one of the previously described embodiments of the invention.</p><p id="p-0107" num="0106">It has to be noted that embodiments of the invention are described with reference to different subject matters. In particular, some embodiments are described with reference to method type claims whereas other embodiments are described with reference to the device type claims. However, a person skilled in the art will gather from the above and the following description that, unless otherwise notified, in addition to any combination of features belonging to one type of subject matter also any combination between features relating to different subject matters is considered to be disclosed with this application. However, all features can be combined providing synergetic effects that are more than the simple summation of the features.</p><p id="p-0108" num="0107">While the invention has been illustrated and described in detail in the drawings and foregoing description, such illustration and description are to be considered illustrative or exemplary and not restrictive. The invention is not limited to the disclosed embodiments. Other variations to the disclosed embodiments can be understood and effected by those skilled in the art in practicing a claimed invention, from a study of the drawings, the disclosure, and the dependent claims.</p><p id="p-0109" num="0108">In the claims, the word &#x201c;comprising&#x201d; does not exclude other elements or steps, and the indefinite article &#x201c;a&#x201d; or &#x201c;an&#x201d; does not exclude a plurality. A single processor or other unit may fulfill the functions of several items re-cited in the claims. The mere fact that certain measures are re-cited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage. Any reference signs in the claims should not be construed as limiting the scope.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image processing system, comprising:<claim-text>a processor unit arranged to receive imaging data associated with an imaging system and optical shape sensing data associated with an optical shape sensing system registered with the imaging system, such that the optical shape sensing data can be positioned in the imaging system; and</claim-text><claim-text>wherein the processor unit is configured to define in the imaging data a region of interest based on the imaging data and/or the optical shape sensing data and further configured to use the optical shape sensing data as markers within the region of interest such that the processor unit applies image enhancement of imaging data on the region of interest based on received optical shape sensing data.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor unit is configured to apply the image enhancement to a series of contrast-enhanced X-Ray images of the region of interest taken by the imaging system.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor unit is configured to search and identify the markers in terms of restricting the markers a subgroup of markers located on the pathway for an interventional instrument.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor unit is configured to define the region of interest based on a location of a balloon, a stent, an endograft or an interventional instrument.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor unit is configured to use the optical shape sensing data to filter-out frames of the imaging system that are out of plane.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor unit is configured to use the optical shape sensing data in between at least two markers to evaluate a shape change of a or the interventional instrument.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor unit is arranged to receive imaging data associated with the imaging system in terms of a computed tomography system or a magnetic resonance imaging system or an ultrasound or an optical imaging system or a X-ray imaging system or a medical imaging system or a diagnostic imaging system.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image processing system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor unit is configured to identify markers in series of images taken by the imaging system.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The image processing system according <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the series of images taken by the imaging system is part of the applied image enhancement on the region of interest.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. An imaging system configured to communicate with the image processing system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An optical shape sensing system configured to communicate with the image processing system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A method for embedding fiber optic shape sensing in a medical imaging device, the method comprising the following steps of:<claim-text>receiving (S1) imaging data associated with an imaging system and optical shape sensing data associated with an optical shape sensing system registered with the imaging system such that the optical shape sensing data can be positioned in the imaging system by means of a processor unit;</claim-text><claim-text>defining (S2), in the imaging data, a region of interest based on the imaging data and/or the optical shape sensing data and further using the optical shape sensing data as markers within the region of interest such that the processor unit applies image enhancement of imaging data on the region of interest based on received optical shape sensing data by means of the processor unit.</claim-text><claim-text>receiving (S4) FORS data of the optical shape sensing fiber by means of the processor unit; and</claim-text><claim-text>applying (S5) image enhancement on the region of interest based on the received receive FORS data by means of the processor unit.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the method further includes the step of applying the image enhancement to a series of contrast-enhanced X-Ray images of the region of interest taken by the imaging system.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the method further includes the step of applying searching and identifying the markers in terms of restricting the markers a subgroup of markers located on the pathway for an interventional instrument.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A computer program element for controlling a device, which when executed by a processor is configured to carry out the method <claim-ref idref="CLM-00012">claim 12</claim-ref>.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A computer-readable storage medium comprising instructions which, when executed by a computer, cause the computer to carry out the method of claim according to <claim-ref idref="CLM-00012">claim 12</claim-ref>.</claim-text></claim></claims></us-patent-application>
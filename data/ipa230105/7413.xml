<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007414A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007414</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931747</doc-number><date>20220913</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>R</subclass><main-group>25</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>25</main-group><subgroup>554</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>25</main-group><subgroup>604</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>B</subclass><main-group>5</main-group><subgroup>0025</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>25</main-group><subgroup>552</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>R</subclass><main-group>25</main-group><subgroup>407</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">LOW-LATENCY COMMUNICATION PROTOCOL FOR BINAURAL APPLICATIONS</invention-title><us-related-documents><division><relation><parent-doc><document-id><country>US</country><doc-number>17143324</doc-number><date>20210107</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11503416</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17931747</doc-number></document-id></child-doc></relation></division></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SEMICONDUCTOR COMPONENTS INDUSTRIES, LLC</orgname><address><city>Phoenix</city><state>AZ</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>COENEN</last-name><first-name>Ivo Leonardus</first-name><address><city>Coffrane</city><country>CH</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>MITCHLER</last-name><first-name>Dennis Wayne</first-name><address><city>Gloucester</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>SEMICONDUCTOR COMPONENTS INDUSTRIES, LLC</orgname><role>02</role><address><city>Phoenix</city><state>AZ</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Hearing instruments, such as hearing aids, may improve a quality of presented audio through the use of a binaural application, such as beamforming. The binaural application may require communication between the hearing instruments so that audio from a left hearing instrument may be combined with audio from a right hearing instrument. The combining at a hearing instrument can require synchronizing audio sampled locally with sampled audio received from wireless communication. This synchronization may cause a noticeable delay of an output of the binaural application if the latency of the wireless communication is not low (e.g., a few samples of delay). Presented herein is a low-latency communication protocol that communicates packets on a sample-by-sample basis and that compensates for delays caused by overhead protocol data transmitted with the audio data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="67.48mm" wi="137.92mm" file="US20230007414A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="139.95mm" wi="93.47mm" orientation="landscape" file="US20230007414A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="167.13mm" wi="83.57mm" orientation="landscape" file="US20230007414A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="219.20mm" wi="132.50mm" orientation="landscape" file="US20230007414A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="221.66mm" wi="191.43mm" orientation="landscape" file="US20230007414A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="263.40mm" wi="141.22mm" orientation="landscape" file="US20230007414A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="195.33mm" wi="184.91mm" orientation="landscape" file="US20230007414A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="264.24mm" wi="210.06mm" orientation="landscape" file="US20230007414A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is a divisional application of U.S. patent application Ser. No. 17/143,324, filed Jan. 7, 2021, which is incorporated by reference herein in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE DISCLOSURE</heading><p id="p-0003" num="0002">The present disclosure relates to point-to-point wireless communication and more specifically to a digital wireless communication protocol having low latency to facilitate binaural applications for hearing instruments.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Hearing instruments, such as hearing aids or ear-worn speakers (i.e. ear buds), can be worn in/on each ear of a user to provide sound to a user. Additionally, the hearing instruments may include one or more microphones to receive audio signals from an environment of the user. For example, audio from the environment may be received and converted (i.e., sampled) into a first digital signal (i.e., left channel) by a left-worn hearing instrument, and audio from the environment may be received and converted into a second digital signal (i.e., right channel) by a right-worn hearing instrument. Processing to improve a listening/hearing experience for the user is possible if the left channel and the right channel can be processed together (i.e., binaural processing). This binaural processing can require digital communication between the hearing instruments and the synchronization of the left and right channels.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">In at least one aspect, the present disclosure generally describes a method for wireless communication between two devices. The method includes designating a first device as a master and a second device as a slave. The master and the slave communicate data over a frame by transmitting protocol packets from the master to the slave at regular intervals in a first half of the frame and from the slave to the master at regular intervals in a second half of the frame. Each protocol packet transmitted add a latency to the wireless communication. Accordingly, the method further includes transmitting data packets during the regular intervals between the protocol packets. The data packets are transmitted between the master and the slave in an alternating fashion. The data packets have a number of bits that is smaller than a number of bits of the protocol packets so that the latency added by each protocol packet is compensated for by the data packets transmitted between the protocol packets.</p><p id="p-0006" num="0005">In another aspect, the present disclosure generally describes a hearing instrument system. The hearing instrument system includes a first hearing instrument that is designated as master and that is configured to be worn at a first ear of a user. The first hearing instrument includes a first microphone, a first speaker, a first transceiver configured for wireless communication, and a first processor configured to execute software instructions stored in a first memory. When executed, the software instructions cause the first processor to transmit a first channel of audio samples collected at the first microphone in packets that each contain one audio sample so that the packets are transmitted as each audio sample is collected. The hearing instrument system further includes a second hearing instrument that is designated as slave and that is configured to be worn at a second ear of the user. The second hearing instrument includes a second microphone, a second speaker, a second transceiver configured for wireless communication, and a second processor configured to execute software instructions stored in a second memory. When executed, the software instructions cause the second processor to transmit a second channel of audio samples collected at the second microphone in packets that each contain one audio sample so that the packets are transmitted as each audio sample is collected. The second processor is further caused to receive the first channel of audio samples collected at the first microphone, combine the first channel and the second channel for a binaural application, and couple an output of the binaural application to the second speaker.</p><p id="p-0007" num="0006">In another aspect, the present disclosure generally describes a non-transitory computer-readable medium that includes instructions stored thereon that when executed by a processor of the first hearing instrument, cause the first hearing instrument to perform operations. The operations include transmitting a preamble packet to a second hearing instrument, where the transmission of the preamble packet causes a first delay corresponding to a time taken to transmit preamble data of the preamble packet. The operations further includes transmitting, after the preamble packet, a number of data packets at a rate that compensates for the first delay. The operations further include transmitting a message packet to the second hearing instrument, wherein the transmission of the message packet causes a second delay corresponding to a time taken to transmit message data of the message packet. The operations further include transmitting, after the message packet, a number of data packets at a rate that compensates for the second delay. The operations further include transmitting a cyclic redundancy check (CRC) packet to the second hearing instrument, where the transmission of the CRC packet causes a third delay corresponding to a time taken to transmit CRC data of the CRC packet. The operations further include transmitting, after the CRC packet, a number of data packets at a rate that compensates for the third delay.</p><p id="p-0008" num="0007">The foregoing illustrative summary, as well as other exemplary objectives and/or advantages of the disclosure, and the manner in which the same are accomplished, are further explained within the following detailed description and its accompanying drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic block diagram illustrating a beam forming process according to an implementation of the present disclosure.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a block diagram of a binaural sound system including hearing instruments communicating via near field magnetic induction (NFMI) according to a possible implementation of the present disclosure.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a block diagram of a hearing instrument according to a possible implementation of the present disclosure.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates timing diagrams of a low-latency communication protocol according to a possible implementation of the present disclosure.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a frame of uplink and downlink data streams according to a possible implementation of a low-latency communication protocol according to an implementation of the present disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow chart of a method for wireless communication according to a possible implementation of the present disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a frame of packet transmissions from a master and a slave for various phases of the wireless communication protocol according to a possible implementation of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0016" num="0015">The components in the drawings are not necessarily to scale relative to each other. Like reference numerals designate corresponding parts throughout the several views.</p><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0017" num="0016">Binaural processing can improve a listening/hearing experience for a user by processing audio received at different hearing instruments (e.g., worn at each ear of the user) For example, a user that is deaf in one ear may hear a combined left/right audio channel in the hearing ear so that sounds on the side of the user's deaf ear may be heard more easily. In another example, a user may receive audio with reduced noise, using a binaural processing technique known as beamforming. Binaural processing may require wireless digital communication of sound data between a left hearing instrument and a right hearing instrument and the synchronization of the sound data prior to processing. Conventional radio frequency (RF) digital communication protocols (e.g., Bluetooth, WiFi) can introduce a communication delay (i.e. transport delay, latency) that can negatively affect the binaural processing. Disclosed herein are circuits and methods to improve the wireless digital communication and synchronization of audio data to facilitate binaural processing, such as beamforming.</p><p id="p-0018" num="0017">Beamforming may be performed on audio from two spatially separated microphones on a single hearing instrument (i.e., monaural beamforming); however, beamforming performed on audio from microphones on a left hearing instrument at a left ear of the user and a right hearing instrument at a right ear of the user (i.e., binaural beamforming) may offer some advantages. For example, the audio from the left and right hearing instruments may have an interaural delay and amplitude difference resulting from the separation between the left/right ears and a direction of the sound, which can improve a quality the beamforming.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic block diagram illustrating an example beam forming process. The example beamforming process is simplified for understanding. Variations to the example beamforming process are possible and within the scope of the present disclosure. For example, a number, an arrangement (e.g., spatial separation), and a response (e.g., amplitude) of the microphones may be adjusted to suit a particular application/environment.</p><p id="p-0020" num="0019">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a first microphone (M<b>1</b>) and a second microphone (M<b>2</b>) are spatially separated by a distance (d). The spatial separation distance (d) and the direction of the sound introduce an interaural delay <b>105</b> between a first time at which a sound arrives at the first microphone (M<b>1</b>) and a second time at which the sound arrives at the second microphone (M<b>2</b>). The beamforming processing <b>100</b> includes a buffering delay <b>110</b> applied to one of the audio streams (e.g., the audio from the first microphone (M<b>1</b>)). The buffering delay <b>110</b> can be used to synchronize the audio streams and/or create a delay between the audio streams for beamforming. The beamforming processing further includes a combiner <b>120</b> that is configured to combine (e.g., sum) the audio streams into a beamformed audio stream <b>130</b>. By adjusting the buffering delay <b>110</b> (e.g., with respect to the interaural delay <b>105</b>), audio from a particular direction may be adjusted (e.g., cancelled, attenuated, enhanced) by the beamforming process. For example, a pure sine wave received by M<b>1</b> and M<b>2</b> can be canceled completely for a particular direction if, after the interaural delay <b>105</b> and the buffering delay <b>110</b>, the versions of the sine wave at the combiner 120 are 180 degrees out of phase.</p><p id="p-0021" num="0020">A quality of an audio adjustment (i.e., cancellation, attenuation, enhancement) resulting from beamforming can depend on the matching performance of the first microphone (M<b>1</b>) and the second microphone (M<b>2</b>). Additionally, a spatial profile (i.e., directivity) of the beamforming may be affected by the spatial separation (d) of the first microphone (M<b>1</b>) and the second microphone (M<b>2</b>). A small spatial separation (d) can produce an interaural delay <b>105</b> that changes little (if at all) with a direction of the sound. As the spatial separation (d) of the microphones is made larger, a spatial filtering that is possible from the beamforming may be increased. Accordingly, it may be desirable to position the first microphone (M<b>1</b>) at a left ear of a user and the second microphone (M<b>2</b>) at a right ear of the user (or vice versa). This positioning may also add realism to the beamforming by preserving the amplitudes and phases of audio streams as they normally appear at each ear of the user.</p><p id="p-0022" num="0021">A relatively large spatial separation (d) can require sound data from one of the microphones to be transmitted to the other. Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, if the beamforming processing <b>100</b> is local to the first microphone (M<b>1</b>) (e.g., included in a left hearing instrument), then sound data from the second microphone (M<b>2</b>) (e.g., from a right hearing instrument) can be transmitted to the beamforming processing <b>100</b>. Wireless communication of the sound data may be desirable in many applications (e.g., in hearing instruments) but can introduce a communication delay <b>140</b> (i.e., latency) to the beamforming shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0023" num="0022">As mentioned, a conventional wireless communication protocol may result in a communication delay <b>140</b> that is relatively large. Increasing the buffering delay <b>110</b> to compensate for the communication delay <b>140</b>, however, may reduce a quality of the beamforming (i.e., may reduce a listening/hearing experience for a user). For example, a communication delay can result in a beamformed audio stream <b>130</b> that is visually out of sync with a sound source (especially for high frequency sounds) due to a buffering delay necessary to compensate for the communication delay <b>140</b>.</p><p id="p-0024" num="0023">The disclosed circuits and methods describe a wireless communication system that includes a communication protocol that minimizes a communication delay (i.e., provides an ultra-low latency) to allow for improved performance in binaural applications, such as beamforming. Additionally, the communication protocol can utilize wireless communication technology that is well suited for body-worn hearing instruments.</p><p id="p-0025" num="0024">Conventional digital wireless communication can include transmitting propagating radio frequency (RF) signals (e.g., 2.4 gigahertz (GHz)) between a transmitter antenna and a receiver antenna. For conventional digital wireless communication, such as Bluetooth and WiFi, the RF signals are intended to propagate according to far-field transmission principles. Communicating between hearing instruments worn in opposite ears using these forms of digital wireless communication could result in (at least) poor efficiency and interference with other devices. To avoid these problems, the disclosed circuits and methods can use a near field magnetic induction (NFMI) communication technology, which is better suited for wireless communication between body worn devices, such as hearing instruments.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a block diagram of a binaural sound system including hearing instruments communicating via NFMI according to a possible implementation of the present disclosure. The binaural sound system <b>200</b> includes two hearing instruments. Each hearing instrument <b>300</b> can be configured to be worn near or touching an ear of a user. For example, in a possible implementation, the hearing instruments are a left hearing instrument and a right hearing instrument worn (at least partially) in an ear canal of the user. Each hearing instrument <b>300</b> can include one or more speakers for projecting transmitted sounds <b>210</b> (e.g., beamformed audio stream) from the hearing instrument. Each hearing instrument <b>300</b> can also include one or more microphones for receiving received sounds <b>220</b> from an environment. Each hearing instrument <b>300</b> may also include a transmitter and/or a receiver. For example, each hearing instrument <b>300</b> may include a transmitter/receiver (T/R) configured to transmit and receive digital data over a wireless communication link <b>230</b> (e.g., a bidirectional wireless communication link). As mentioned previously, the wireless communication link <b>230</b> may include NFMI.</p><p id="p-0027" num="0026">NFMI facilitates digital communication over a short range (e.g., &#x3c;1 meter(m)). For NFMI communication, each hearing instrument <b>300</b> can include a coil <b>240</b> that is coupled to a transmitter/receiver of the hearing instrument <b>300</b>. The transmitter of a first hearing instrument can be configured to excite a current in a coil <b>240</b> of the transmitter to produce a magnetic field <b>250</b> that is inductively coupled to a coil <b>240</b> of a receiver of a second hearing instrument. The magnetic field <b>250</b> may be modulated (e.g., frequency shift key (FSK)) for communicating digital information between the hearing instruments. The coils may be substantially similar (e.g., identical) and can be arranged to increase a magnetic coupling so that the efficiency of NFMI can be high. Further, magnetic field <b>250</b> can be tightly coupled and has an amplitude that drops quickly with range because it does not propagate (i.e., near field transmission). Accordingly, NFMI communication can minimize interference with other devices. For digital communication, the magnetic field <b>250</b> may be modulated in a high-frequency (HF) band (e.g., 10-14 megahertz (MHz)). HF band signals may experience less distortion/absorption from the human body than higher frequency signals (e.g., 2.4 GHz).</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a block diagram of a hearing instrument <b>300</b> that can be used in the binaural sound system of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As mentioned previously, the hearing instrument can include a transmitter/receiver coupled to a wireless transducer, such as an antenna or a coil. The transmitter/receiver may be implemented as a discrete transmitter and receiver or may be implemented as a transmitter/receiver device that includes a transmitter portion and receiver portion. For the hearing instrument implementation shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a transmitter/receiver <b>310</b> (i.e., transceiver) may transmit and receive digital data (e.g., an audio data stream) over a wireless communication link <b>230</b> via a coil <b>240</b> configured for NFMI.</p><p id="p-0029" num="0028">The hearing instrument <b>300</b> includes at least one microphone <b>320</b> (i.e., mic) configured to convert received sounds <b>220</b> into an analog mic signal <b>321</b>. The analog mic signal <b>321</b> is coupled to an analog-to-digital converter (i.e., A/D <b>330</b>) that is configured to periodically sample (i.e., samples spaced by a sampling period) the analog mic signal <b>321</b> at a sample rate (e.g., 24 kilohertz (kHz)), generate digital samples having a amplitude resolution corresponding to a binary representation (e.g., 16 bits), and output the digital samples in sequence as a digital data stream <b>331</b>. The digital data stream <b>331</b> may be transmitted to a processor (e.g., a digital signal processor (i.e., DSP <b>340</b>), which can be configured to use the digital data stream <b>331</b> as a channel in a binaural application, such as beamforming. In a possible implementation, the hearing instrument can include a delay <b>335</b> (e.g., buffering delay <b>110</b>) that is configured to generate a buffered digital data stream <b>332</b>, which is buffered for a period before being provided to the DSP <b>340</b>. The delay <b>335</b> may be used to synchronize data streams (e.g., local and received) at the DSP <b>340</b> and may also be used for binaural applications (e.g., beamforming). The digital data stream <b>331</b> may also be provided to an encoder <b>344</b> that is configured to encode (e.g., compress) the digital data stream in order to reduce a number of bits (i.e., bandwidth) communicated over the wireless communication link <b>230</b>. The encoder <b>344</b> may be a portion of an audio codec <b>350</b> that includes (at least) an encoder <b>344</b> and a decoder <b>345</b>. The audio codec <b>350</b> may be one of a plurality of possible types, including (but not limited to) an adaptive differential pulse-code modulation (ADPCM) codec. The encoder <b>344</b> may output an encoded data stream <b>341</b> for transmission to a transmitter portion of the transmitter/receiver <b>310</b> for transmission to another hearing instrument (not shown).</p><p id="p-0030" num="0029">The transmitter/receiver <b>310</b> may further include a receiver portion that is configured to receive an encoded data stream from another hearing instrument (not shown) over the wireless communication link <b>230</b> via the coil <b>240</b>. The receiver portion may couple the received encoded data stream <b>342</b> to the decoder <b>345</b>. The decoder <b>345</b> can be configured to decode (e.g., decompress) the received encoded data stream and output a received digital data stream <b>346</b> to the DSP <b>340</b>.</p><p id="p-0031" num="0030">The DSP <b>340</b> may be configured to receive/process the buffered digital data stream <b>332</b> (i.e., first channel, local channel) and the received digital data stream <b>346</b> (i.e., second channel, remote channel, received channel) for a binaural application and to output a processed digital data stream <b>351</b>. The processed digital data stream <b>351</b> can be a combination of the buffered digital data stream <b>332</b> and the received digital data stream <b>346</b>. In a possible implementation, the DSP <b>340</b> is configured (e.g., by software) to perform beamforming processing on the first channel and the second channel. In this case, the processed digital data stream <b>351</b> is the beamformed audio stream <b>130</b>.</p><p id="p-0032" num="0031">The hearing instrument <b>300</b> may further include a non-transitory computer readable medium (i.e., memory <b>360</b>). The memory <b>360</b> may be configured to store a computer program product (i.e., software) including instructions that, when executed by a processor, can configure the processor to perform operations to enable functionality of the hearing instrument. For example, the memory <b>360</b> may include stored instructions that can configured the DSP <b>340</b> to perform a beamforming process (i.e., method). Additionally, or alternatively, the memory may include stored instructions that can configure a processor (e.g., the DSP <b>340</b>) to perform a method associated with an ultra-low latency NFMI communication protocol.</p><p id="p-0033" num="0032">The hearing instrument <b>300</b> may further include a digital-to-analog converter (i.e., D/A <b>355</b>) that is configured to parse the digital samples of the processed digital data stream <b>351</b> and to generate an analog speaker signal <b>324</b> based on the digital samples. The analog speaker signal <b>324</b> can be amplified (not shown) and coupled to at least one speaker <b>325</b> of the hearing instrument <b>300</b> to produce transmitted sounds <b>210</b>. The transmitted sounds <b>210</b> may provide an improved listening/hearing experience for a user because of the binaural application. For example, the transmitted sounds may include less noise than transmitted sounds without the processing provided by the binaural application.</p><p id="p-0034" num="0033">As mentioned, the hearing instrument <b>300</b> shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref> can be one of two hearing instruments worn in the ears of a user. In this case, the hearing instrument worn in the left ear can be the same as the hearing aid worn in the right ear. In other words, processing may be performed at each hearing instrument. Alternatively, a first hearing instrument in a pair can include a subset of the circuits/subsystems as a second hearing instrument in the pair. In other words, processing for a binaural application may be performed at one hearing instrument in the pair. In either case, a wireless communication link <b>230</b> between the hearing instrument may be required. The wireless communication link <b>230</b> may include a low-latency communication protocol in order to prevent problems in the processing for the binaural application.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates timing diagrams of a low-latency communication protocol according to a possible implementation of the present disclosure. In a forward direction (i.e., right HI to left HI), the microphone A/D samples are processed immediately by a codec and channel encoder on a per sample basis. The encoded data is then formatted into small packets representing one sample each and transmitted over the air at a high data rate. Next, the left HI receives the transmitted signal and decodes the demodulated packet. The demodulated data is decoded sample-by-sample to generate the D/A samples. The D/A samples are converted to analog audio for the left's speaker. The communication delay in the example is 3 sample periods, which is 125 microseconds for 24 kHz sample rate. In other words, the latency of the communication is only a few sample periods and is mostly due to the encoding/decoding.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>4</b></figref> includes a plurality of graphs of signals plotted versus the same time axis. The plurality of graphs may be grouped by hearing instrument. The graphs include graphs for a first hearing instrument (e.g., a right hearing instrument <b>401</b>). The graphs also include graphs for a second hearing instrument (e.g., a left hearing instrument <b>402</b>). The graphs illustrate the timing associated with bidirectional communication of audio between the left hearing instrument (left HI) and the right hearing instrument (right HI) to provide a visual understanding of a communication delay (i.e. latency). The timing can be expressed in terms of a sampling time (i.e., sampling period) (e.g., 41.67 microseconds (p)/sample) for the audio signals, which is typically the same for each hearing instrument.</p><p id="p-0037" num="0036">At the right hearing instrument, microphone audio is sampled to create a right audio data stream that includes a plurality of audio samples. In a conventional communication protocol (e.g., Bluetooth, WiFi), a number of samples are collected to form a block that can be encoded and transmitted in a packet. When an amount of overhead data is required for each packet (e.g., as in Bluetooth, WiFi), an efficiency of the packet communication can be increased by increasing a size of the block. Additionally, an encoder may work better for large blocks of data. In other words, an amount of compression of a block of data may increase as a size (i.e., length) of the block of data is increased.</p><p id="p-0038" num="0037">While larger blocks may be desirable for conventional communication, they can lead to larger communication delays (i.e., transport delays, latencies). For example, transmitting a block of data from a first device to a second device results in a communication delay that includes a transmission delay and a reception delay. The transmission delay can include a first delay associated with collecting the data samples for a block of data at the first device, a second delay associated with encoding the block of data, and a third delay associated with transmitting the encoded block of data wirelessly. Receiving the block of data can result in a reception delay that includes a fourth delay associated with receiving the encoded block of data, a fifth delay associated with decoding the block of data, and a sixth delay associated with presenting audio from the block of data at the second device.</p><p id="p-0039" num="0038">When the block of data is large, a communication delay, resulting from a conventional protocol, can be too large for a binaural application. A binaural application using a first stream of audio data collected locally and a second stream of audio data received from a remote device may require the synchronization of the streams of audio data. Buffering the stream of audio data collected locally during the communication delay in order to synchronize it with the audio data collected remotely may result in a delayed output of the processed digital data stream (i.e., the transmitted sound). This delay may be made even more severe if a packet is damaged or lost. In hearing instruments (e.g., hearing aids), large delays (e.g., &#x2265;10 milliseconds(msec)) may be unacceptable because sounds may become noticeably out of sync with their visually observable sources (i.e., counterparts). Accordingly, the disclosed communication protocol can minimize a block size (e.g., &#x2264;2 samples). For example, as shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> the block size is one sample. To prevent the loss of efficiency associated with a small block, the disclosed communication protocol eliminates the overhead data transmitted with each block. Instead, the disclosed communication protocol distributes the overhead data (e.g., messaging, error correction, synchronization, etc.) throughout a frame of samples to manage the communication and eliminate errors.</p><p id="p-0040" num="0039">As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, microphone audio <b>405</b> collected from a microphone at a right HI may be sampled to produce a sequence of A/D samples. Each A/D sample may be represented by a number of bits (e.g., 16 bits). The bits for each sample may be encoded by an encoder <b>409</b> to produce an encoded block for a packet. The packet may be transmitted using a wireless technology (e.g., NFMI) to a left HI <b>402</b>. At the left HI, the packet is decoded by a decoder <b>413</b> and converted into D/A samples <b>415</b> so that received audio <b>417</b> from the right HI <b>401</b> is reconstructed at the left HI <b>402</b>. Because the block of data in the packet is limited to a sample, a delay <b>420</b> between a time at which audio was sampled by the right HI <b>401</b> and a time at which the sample becomes available at the left HI <b>402</b> is small (e.g., about 3 samples). Accordingly, synchronizing audio captured at the left HI <b>402</b> (i.e., left microphone audio <b>419</b>) with audio received from the right HI (i.e., left speaker audio <b>417</b>) requires a short delay (e.g., &#x2dc;125 &#x3bc;s). The left HI <b>402</b> may also collect and transmit audio to the right HI as described above.</p><p id="p-0041" num="0040">The left HI <b>402</b> and the right HI <b>401</b> can transmit packets at the same rate but at different times so that packets <b>411</b> transmitted by the right HI <b>401</b> (i.e., downlink packets) do not overlap with packets <b>412</b> transmitted by the left HI <b>402</b> (i.e., uplink packets). To achieve non-overlapping packets, the right HI and the left HI can synchronize using communicated messages that includes predetermined data (e.g., sync word). For example, prior to data transmission a master device (e.g., the right HI) may repeatedly transmit a short (e.g., 16 bit) sync word to a slave device (e.g., the left HI). Because the sync word is known to the slave device, adjustments may be made to the sync device until the sync word is recognized at the slave device.</p><p id="p-0042" num="0041">The left HI <b>402</b> may not always receive packets from the right HI <b>401</b> correctly (and vice versa). To correct for communication errors, each packet may include parity bits that can help the receiving device to determine if the data in a packet is correct or incorrect. The parity bit analysis may determine if correction is possible. If correction is possible, then the data bits in the packet can be changed to correct the errors. If correction is not possible, the code may apply an algorithm (e.g., packet loss concealment) to mitigate the information lost by the error.</p><p id="p-0043" num="0042">For at least synchronization and error correction some overhead information may be communicated in addition to the audio data. An advantage of the low-latency communication protocol disclosed is that this overhead information may be transmitted without significantly affecting the packet-to-packet delay. For example, messages regarding the communication may be transmitted on a frame-by-frame basis where a frame includes a number (e.g., 128) of packets. Delays (i.e. latencies) caused by the messages may be counter balanced by an increased packet transmission rate so that a latency caused by the overhead information is insignificant (e.g., zero). The protocol and its features may be best understood by considering an example frame.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a frame <b>500</b> including an uplink data stream <b>501</b> (e.g., transmitted by a device designated slave) and downlink data stream <b>502</b> (e.g., transmitted by a device designated master) according to a possible implementation of a low-latency communication protocol. The low-latency communication protocol (i.e., protocol) includes a plurality of frames transmitted in sequence. Each frame can be identical and arranged as the frame <b>500</b> shown. Accordingly, the frame <b>500</b> may include an identically arranged frame just prior to the frame shown and immediately after the frame shown. The frame includes a plurality of packets. In each frame, the uplink data stream <b>501</b> and the downlink data stream <b>502</b> can alternate transmitting packets. A number of packets transmitted in the uplink data stream <b>501</b> during the frame <b>500</b> may equal a number of packets transmitted in the downlink data stream <b>502</b> during the frame <b>500</b>. Each packet in data stream may include a block of audio data <b>512</b> (i.e., DATA). As mentioned, the audio data in each packet may correspond to bits of one sample of an analog audio signal. Each packet may further include parity bits <b>516</b> (i.e., PARITY) added by an encoder <b>344</b> to help diagnose and correct for bit errors in audio data resulting from the wireless communication. Accordingly, data packets (D) can be arranged so that the parity bits are transmitted after the audio bits. In other words, a data packet <b>511</b> (i.e., D) can include (in sequence) payload (e.g., audio data (i.e., DATA)) and parity data (i.e., PARITY). In a frame <b>500</b>, the downlink transmitter and the uplink transmitter take turns transmitting data packets. For the uplink and downlink transmission to use the same frequency band, time synchronization between the data streams may be necessary. This initial time synchronization may happen at the beginning of communication, during a synchronization period (i.e., start-up mode). The frame of <figref idref="DRAWINGS">FIG. <b>5</b></figref> shows the relative timing of packet transmission after synchronization (i.e., after a start-up mode of communication)</p><p id="p-0045" num="0044">A data packet <b>511</b> may be a sample of audio data (e.g., 16 bits) that has been compressed by a codec (e.g., ADPCM) to a short data length (e.g., 8 bits). The parity may be shorter than the compressed audio sample (e.g., 4 bits). The parity may be used to detect, and in some cases, correct for errors. The disclosed low-latency communication protocol utilizes parity with each audio data in a packet so that there is no time necessary for the resending of packets with errors. Each packet is short so even if an error cannot be corrected or a packet is lost the effect on the overall data stream may not be significant.</p><p id="p-0046" num="0045">Some packets in the uplink data stream <b>501</b> and the downlink data stream <b>502</b> can further include overhead data (i.e., protocol data) added to the data packet (D) (i.e., added to the audio data and the parity data). For example, a sync packet <b>513</b> (i.e., S+D) can include (in sequence) synchronization data <b>514</b> (i.e., SYNC), audio data (i.e., DATA), and parity data (i.e., PARITY). A message packet <b>515</b> (i.e., M+D) can include (in sequence) message data (i.e., MESSAGE), audio data (i.e., DATA) and parity data (i.e., PARITY).</p><p id="p-0047" num="0046">The synchronization data <b>514</b> may be short (e.g., 16 bits) to prevent the synchronization data (S) added to the data packet (D) from significantly delaying the data stream. The synchronization data <b>514</b> may include a sync word that a receiver can use for synchronization. In other words, during a synchronization period a receiver may expect to receive a sync word. A transmitter may repeatedly transmit the sync word and the receiver may adjust itself until the repeated sync word is received properly, at which point the transmitter and the receiver are synchronized. The sync word can be relatively short, which can increase a risk that random data is recognized as the sync word. To mitigate this risk, the receiver may be configured to detect correct reception of the sync word for multiple frames.</p><p id="p-0048" num="0047">The message data <b>517</b> may be short (e.g., 16 bits) to prevent the message data (M) added to the data packet (D) from significantly delaying the data stream. The message data <b>517</b> may include information regarding the communication, such as number of packets, packet number, length of message, and acknowledgment of last message received.</p><p id="p-0049" num="0048">In some cases, the message data is cyclic redundancy check data (i.e., CRC data). In this case, a message packet (M+D) can include (in sequence) CRC data <b>519</b> (CRC), audio data (i.e., DATA), and parity data (i.e., PARITY). The CRC data <b>519</b> may be short (e.g., 16 bits) to prevent the CRC data (CRC) added to the data packet (D) from significantly delaying the data stream. The CRC data <b>519</b> may include information to help detect errors in a previously sent message data (M). When the message packet includes CRC data it may be referred to as a CRC packet.</p><p id="p-0050" num="0049">The message packets (M+D) and the sync packets (S+D) may be referred to collectively as protocol packets. The protocol packets may be the same size or different sizes and may be generally larger than the data packet <b>511</b> by a number of bits for the overhead data (i.e., protocol data). The protocol packets can be transmitted at intervals (i.e., regular intervals) in a frame (i.e., can be distributed in the frame). In other words, the protocol packets can be spaced apart by a plurality of data packets (D), such as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0051" num="0050">Data packets may be transmitted at a data packet rate when not otherwise delayed by a protocol packet. In other words, most data packets in the frame may be separated by a data packet period <b>523</b>. When a protocol packet <b>525</b> is transmitted, data packets around the protocol packet may be separated by a delayed packet period <b>522</b>. In other words, each delayed packet period in a frame can contribute to a communication delay of the frame. The low-latency communication protocol disclosed can reduce (e.g., eliminate) the communication delay by adjusting the data packet period <b>523</b> to compensate for the delayed packet period <b>522</b>.</p><p id="p-0052" num="0051">As mentioned, each data packet may include one sample of audio data. In this case, a communication delay <b>140</b> may be minimized when the samples of audio data are transmitted, on average, at the sampling rate of the audio data. The disclosed low-latency communication protocol maintains an average transmission rate by transmitting data packets at data packet period <b>523</b> that is faster than an audio sampling period <b>421</b> (i.e., sample period) so that after a delayed packet period <b>522</b> the average packet period is the sampling period <b>421</b>. In other words, the data packet rate (i.e., data packet period) can compensate for a delay caused by a protocol packet (i.e., delayed packet period). Proper spacing of the protocol packets in the frame may be necessary to keep the average communication delay at its minimum.</p><p id="p-0053" num="0052">The transmitters of the uplink data stream <b>501</b> and the downlink data stream <b>502</b> may each transmit protocol packets. For example, the downlink data stream <b>502</b> may include a preamble packet, a message packet, and a message packet containing CRC in each frame <b>500</b>. Likewise, the uplink data stream <b>501</b> may include a preamble packet, a message packet, and a message packet containing CRC in each frame <b>500</b>. The frame <b>500</b> may be divided into a first portion <b>520</b> (e.g., first half) and a second portion <b>521</b> (e.g., second half) at a 50% offset point from the frame start. In a possible implementation, half (50%) of the data packets for the frame are transmitted in the first portion and half (50%) of the data packets for the frame are transmitted in the second portion. The transmitter of the downlink data stream <b>502</b> may transmit all of its protocol packets in the first portion <b>520</b> of the frame <b>500</b>, while the transmitter of the uplink data stream <b>501</b> may transmit all of its protocol packets in the second portion <b>521</b> of the frame <b>500</b>.</p><p id="p-0054" num="0053">The protocol packets are distributed (e.g., equally) within the frame. For example, as shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the downlink data stream and the uplink data stream may together include six protocol packets (i.e., three in uplink data stream <b>501</b> and three in downlink data stream <b>502</b>). In one possible implementation, the downlink data stream <b>502</b> (e.g., transmitted by a master HI) can include a sync packet (S+D) at the start of the frame (i.e., 0% offset from the start), a first message packet (M+D) at a 16.7% offset from the start, and a second message packet (M+D) (i.e., CRC packet) at a 33.3% offset from the start. The uplink data stream <b>501</b> (e.g., transmitted by a slave HI) can include a sync packet (S+D) at 50% offset from the start, a first message packet (M+D) at a 66.7% offset from the start, and a second message packet (M+D) (i.e., CRC packet) at 83.3% offset from the start. In other words, after the message packet (M+D) at 33.3% offset from the start, the downlink data stream <b>502</b> includes only data packets, while before the sync packet (S+D) at 50% offset from the start, the uplink data stream includes only data packets. At 100% offset from the start the sync packet (i.e., preamble packet, header) packet) can be sent in the downlink data stream <b>502</b> for the next frame. In other words, a preamble packet may be sent by the master transmitter once every N samples, where N is a number of data packets in a frame. It should be noted that the sync packet and the message packets (i.e., the protocol packets) transmitted in the downlink data stream <b>502</b> (e.g., by the master) may not be the same as the sync packet and the message packets transmitted in the uplink data steam <b>501</b> (e.g., by the slave).</p><p id="p-0055" num="0054">The protocol packets are spread in the frame to minimize a communication delay. For example, the sync packet <b>510</b> at 0% offset introduces a delay (i.e., latency) relative to a sample rate. The subsequent message packet <b>515</b> may not transmitted until the delay can be compensated for by data packets transmitted after the sync packet. For example, the data packets can be transmitted at a packet transmission rate that is higher than the sample rate. In other words, the delay compensation can be divided over a plurality of data packets <b>524</b> between the sync packet <b>510</b> and the message packet <b>515</b>. Accordingly, the rate of data packet transmission may need to be only a fraction higher than the sampling rate of the audio signal.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow chart of a method for low-latency wireless communication between two devices (e.g., hearing instruments). According to a possible implementation, the method <b>600</b> includes designating <b>610</b> a first device (e.g., left hearing instrument) as a master device (i.e., master) and designating a second device (e.g., right hearing instrument) as a slave device (i.e., slave). In other words, a frame can include a number (N) of data packets (e.g., audio samples) transmitted by the master and/or slave. The devices may be designated master or slave by a factory setting. For example, hearing instruments grouped (e.g., sold) in pairs may include settings so that one hearing instrument always begins communication as the master.</p><p id="p-0057" num="0056">The method further includes transmitting <b>620</b> a protocol packet (e.g., preamble packet, sync packet, message packet, CRC packet) from the master to the slave. For example, the left hearing instrument may be designated as the master and can begin a frame by transmitting a sync packet to the right hearing instrument. The sync packet can include synchronization data and a payload (e.g., audio sample). The data stream may be delayed according to the time taken to transmit the synchronization data. The delay may be relative to a desired transmission rate of data packets, which in turn, may be related to a sample rate of the audio data at the hearing aid.</p><p id="p-0058" num="0057">The method further includes transmitting <b>630</b> a number of data packets between the master and slave in alternating fashion. In other words, the master and slave may alternate transmitting data packets for a pre-determined number of data packets. The data packets may be smaller (e.g., have a smaller number of bits) than the protocol packet. A transmission rate of the data packets may be made slightly higher than the desired transmission rate so that the delay created by the preamble packet can be compensated for by the data packets. In other words, a latency added by the protocol packet can be compensated for by the data packets transmitted after the protocol packet. In other words, the transmission rate of the data packets may deviate from the desired transmission rate during the frame, slower for protocol packets and faster for data packets, but on average is approximately (i.e., within a percent) of the desired transmission rate of data packets for each frame. Accordingly, the number of data packets may be based on a size of the preamble data.</p><p id="p-0059" num="0058">The transmission of the protocol packets may occur at intervals (i.e., regular intervals) for a first portion (e.g., first half) of the frame. Accordingly, the process of transmitting protocol packets followed by transmitting data packets may repeat until all protocol packets for the master have been transmitted (i.e., until the first portion of the frame is complete <b>640</b>).</p><p id="p-0060" num="0059">The shorter data packets transmitted between the master and slave can each partially compensate for the delay caused by the longer protocol packet. Distributing the protocol packets between periods of transmitting data packets helps to minimize the latency of the communication because the average transmission of the payload data is always kept close to a desired transmission rate (e.g., close to the sample rate). The number of data packets transmitted between each protocol packet in a frame may be the same or may vary. If each protocol packet (i.e., preamble packet, message packet) is the same size, then the number of data packets transmitted in the intervals between protocol packets may be the same.</p><p id="p-0061" num="0060">When transmission of the first portion of the frame is complete, then the method <b>600</b> includes transmitting a protocol packets form the slave to the master at regular intervals in a second portion (e.g., second half) of the frame. During the second portion, the method further includes transmitting <b>660</b> data packets between the master and the slave in alternating fashion in the (regular) intervals between the protocol packets. This process can continue until the second portion of the frame is complete <b>620</b>.</p><p id="p-0062" num="0061">When the second portion of the frame is complete <b>620</b>, the method includes beginning <b>690</b> a new frame and repeating the process described above for the next frame. The frame length can be made longer or shorter as needed for different applications. For example, because the protocol operates on a sample-by-sample basis, the frame length is not determined by a minimum payload size.</p><p id="p-0063" num="0062">The method shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> assumes the devices are synchronized. For synchronization between two devices, a first device may repeatedly transmit a sync word to a second device. The second device is expecting the sync word and can adjust its receiver until the sync word is properly received. After the adjustments are made, the second device may transmit an acknowledgment to the first device that communication, such as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, can begin. Details of a possible synchronization phase (i.e., start-up mode) to start the communication are described below.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a frame of uplink and downlink data streams for various phases of the low-latency wireless communication protocol according to a possible implementation of the present disclosure. As mentioned, the communication between two devices can be synchronized prior to communication. Accordingly, the communication protocol may include a start-up mode for synchronization and a run mode for communication. The start-up mode may include a first phase and a second phase, while the run mode may include a bidirectional mode or a unidirectional mode.</p><p id="p-0065" num="0064">The details of these modes can be described with reference to <figref idref="DRAWINGS">FIG. <b>7</b></figref>. <figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a frame <b>700</b> of a downlink data stream of packets transmitted by a first hearing instrument designated as a master (i.e., master device <b>701</b>) and an uplink data stream of packets transmitted by a second hearing instrument designated as a slave (i.e., slave device <b>702</b>) and for a first phase of a start-up mode (i.e., first phase <b>711</b>), for a second phase of a start-up mode (i.e., second phase <b>712</b>), and for a run mode <b>713</b>.</p><p id="p-0066" num="0065">In the first phase <b>711</b> of the start-up mode, the master device <b>701</b> is configured to transmit packets while the slave device <b>702</b> is configured to not transmit (i.e., listen). The transmitted packets include protocol packets (i.e., S+D, M+D) that protocol information (e.g., sync word, messages, CRC data, etc.) and a payload of audio data (e.g., one or more audio samples). The transmitted packets further include (shorter) data packets (i.e., D) that only include audio data. In a first portion (e.g., first half) of the frame <b>700</b>, the protocol packets are spaced at intervals (e.g., regular intervals) with the data packets in between. The communication is similar to that shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, however, timeslots provide for the slave device <b>702</b> are filled instead with repeating-pattern data <b>720</b> (i.e., repetitive-pattern data). For example, the repeating-pattern data packets (i.e., R) can include a binary pattern. The binary pattern can contain 50% zeros and 50% ones. The ones and zeros can be in any sequence, such as a repeating one-zero-one binary pattern (i.e., . . . 1010 . . . ). The slave device can acquire a phase and frequency lock (i.e., synchronize) on the transmitted data. The frame of the first phase <b>711</b> may be repeatedly transmitted to allow the slave to synchronize. In a second portion (e.g., second half) of the frame <b>700</b>, the master <b>701</b> stops transmitting for one or more listening periods. For example, the second portion of the frame <b>700</b> may include a first listening period <b>731</b>, a second listening period <b>732</b>, and a third listening period <b>733</b>. The listening periods provide times for the slave to respond with its own protocol packets. The slave device may response after it has synchronized.</p><p id="p-0067" num="0066">In the second phase <b>712</b> of the start-up mode, the slave has synchronized and transmits protocol packets during the listening periods. For example the slave may transmit its sync packet (S+D) during the first listening period <b>731</b>, a first message packet (M+D) during the second listening period <b>732</b>, and a second message packet (e.g., a CRC packet (C+D)) during the third listening period <b>733</b>. These protocol packets sent by the slave inform the master that it has synchronized. As a result, the master synchronizes with the slave by using the slave's sync packet (S+D). After the master synchronizes (e.g., receives the sync word correctly), the master may communicate its sync status to the slave via message packets.</p><p id="p-0068" num="0067">After both the master and the slave synchronize, the communication may enter a run mode <b>713</b>. The run mode <b>713</b> may be bidirectional or unidirectional. For example, a bidirectional run mode is shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. In this mode, the master <b>701</b> and the slave <b>702</b> communicate protocol packets (S+D, M+D, C+D) and data packets (D) as described for <figref idref="DRAWINGS">FIG. <b>5</b></figref>. In a unidirectional run mode (not shown), the master can transmit exclusively while the slave receives. Alternatively, the slave <b>702</b> can transmit exclusively while the master <b>701</b> receives.</p><p id="p-0069" num="0068">The latency of the wireless communication protocol is low because a payload of the data packets (D) can be small. Each packet can include one sample of audio so that each sample is transmitted individually on a sample-by-sample bases to reduce a latency in the communication of the samples. For example, packets can be created on a sample-by-sample basis at a hearing instrument. The latency (i.e., communication delay) of the wireless communication protocol is also low (e.g., &#x2264;3 sample periods, &#x3c;125 &#x3bc;sec) because delays caused by transmitting protocol data (e.g., preamble data, synchronization data, messages, CRC data, etc.) can be compensated for by increasing a packet-transmission rate of data packets so that the latency caused by the protocol data is low (e.g., zero). The latency of the wireless communication protocol is also low because there is no resending of packets. Parity bits are included with each data packet so if a data packet is corrupted it can be repaired. If it is lost, then its loss is not significant to the entire data stream. The latency of the wireless communication protocol is also low because the protocol data can be kept small (e.g., 16 bits) because a binaural application may reduce the scope of the information necessary to carry out communication. For at least these reasons the latency may be referred to as low compared to other wireless protocols (e.g., Bluetooth, WiFi, UWB, etc.). For example, the latency of the protocol described here may be on the order of microseconds (e.g., 125 &#x3bc;s (3 samples) for a 24 kHz sampling rate) rather than milliseconds.</p><p id="p-0070" num="0069">In the specification and/or figures, typical embodiments have been disclosed. The present disclosure is not limited to such exemplary embodiments. For example, while NFMI has been described it is possible that the low-latency protocol described herein could be used with other wireless technologies, such as those that require propagating RF signals.</p><p id="p-0071" num="0070">Unless defined otherwise, all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art. Methods and materials similar or equivalent to those described herein can be used in the practice or testing of the present disclosure. As used in the specification, and in the appended claims, the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; &#x201c;the&#x201d; include plural referents unless the context clearly dictates otherwise. The term &#x201c;comprising&#x201d; and variations thereof as used herein is used synonymously with the term &#x201c;including&#x201d; and variations thereof and are open, non-limiting terms. The terms &#x201c;optional&#x201d; or &#x201c;optionally&#x201d; used herein mean that the subsequently described feature, event or circumstance may or may not occur, and that the description includes instances where said feature, event or circumstance occurs and instances where it does not. Ranges may be expressed herein as from &#x201c;about&#x201d; one particular value, and/or to &#x201c;about&#x201d; another particular value. When such a range is expressed, an aspect includes from the one particular value and/or to the other particular value. Similarly, when values are expressed as approximations, by use of the antecedent &#x201c;about,&#x201d; it will be understood that the particular value forms another aspect. It will be further understood that the endpoints of each of the ranges are significant both in relation to the other endpoint, and independently of the other endpoint.</p><p id="p-0072" num="0071">While certain features of the described implementations have been illustrated as described herein, many modifications, substitutions, changes and equivalents will now occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the scope of the implementations. It should be understood that they have been presented by way of example only, not limitation, and various changes in form and details may be made. Any portion of the apparatus and/or methods described herein may be combined in any combination, except mutually exclusive combinations. The implementations described herein can include various combinations and/or sub-combinations of the functions, components and/or features of the different implementations described.</p><p id="p-0073" num="0072">It will be understood that, in the foregoing description, when an element is referred to as being on, connected to, electrically connected to, coupled to, or electrically coupled to another element, it may be directly on, connected or coupled to the other element, or one or more intervening elements may be present. In contrast, when an element is referred to as being directly on, directly connected to or directly coupled to another element, there are no intervening elements present. Although the terms directly on, directly connected to, or directly coupled to may not be used throughout the detailed description, elements that are shown as being directly on, directly connected or directly coupled can be referred to as such. The claims of the application, if any, may be amended to recite exemplary relationships described in the specification or shown in the figures.</p><p id="p-0074" num="0073">As used in this specification, a singular form may, unless definitely indicating a particular case in terms of the context, include a plural form. Spatially relative terms (e.g., over, above, upper, under, beneath, below, lower, and so forth) are intended to encompass different orientations of the device in use or operation in addition to the orientation depicted in the figures. In some implementations, the relative terms above and below can, respectively, include vertically above and vertically below. In some implementations, the term adjacent can include laterally adjacent to or horizontally adjacent to.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A hearing instrument system, comprising:<claim-text>a first hearing instrument designated as master and configured to be worn at a first ear of a user, the first hearing instrument including:<claim-text>a first microphone;</claim-text><claim-text>a first speaker;</claim-text><claim-text>a first transceiver configured for wireless communication; and</claim-text><claim-text>a first processor configured to execute software instructions stored in a first memory, the software instructions, when executed, causing the first processor to:<claim-text>transmit a first channel of audio samples collected at the first microphone in packets that each contain one audio sample, the packets being transmitted as each audio sample is collected;</claim-text></claim-text></claim-text><claim-text>a second hearing instrument designated as slave and configured to be worn at a second ear of the user, the second hearing instrument including:<claim-text>a second microphone;</claim-text><claim-text>a second speaker;</claim-text><claim-text>a second transceiver configured for wireless communication; and</claim-text><claim-text>a second processor configured to execute software instructions stored in a second memory, the software instructions causing the second processor to:<claim-text>transmit a second channel of audio samples collected at the second microphone in packets that each contain one audio sample, the packets being transmitted as each audio sample is collected;</claim-text><claim-text>receive the first channel of audio samples collected at the first microphone;</claim-text><claim-text>combine the first channel and the second channel for a binaural application; and</claim-text><claim-text>couple an output of the binaural application to the second speaker.</claim-text></claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The hearing instrument system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the packets are transmitted as each audio sample is collected so that a latency in the wireless communication within an order of magnitude of a sample period of the audio samples.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The hearing instrument system according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the order of magnitude of the sample period is microseconds.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The hearing instrument system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the wireless communication includes near field magnetic induction (NFMI).</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The hearing instrument system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the binaural application is beamforming.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The hearing instrument system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the combining includes synchronizing the first channel and the second channel.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The hearing instrument system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the packets that each contain one audio sample includes protocol packets and data packets.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The hearing instrument system according to <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the protocol packets and the data packets are transmitted in a frame, the protocol packets separated by a plurality of data packets.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A hearing instrument system, comprising:<claim-text>a hearing instrument including:<claim-text>a microphone;</claim-text><claim-text>a transceiver configured for wireless communication; and</claim-text><claim-text>a processor configured to execute software instructions stored in a memory, the software instructions, when executed, configuring the processor to:<claim-text>transmit protocol packets at regular intervals, each protocol packet adding a latency; and</claim-text><claim-text>transmit audio samples of audio collected at the microphone in data packets, the data packets being transmitted between protocol packets and having a number of bits smaller than a number of bits of the protocol packets so that the latency added by each protocol packet is compensated for by the data packets transmitted between the protocol packets.</claim-text></claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The hearing instrument system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the hearing instrument is a first hearing instrument, the microphone is a first microphone, the transceiver is a first transceiver, the processor is a first processor, and the memory is a first memory, the hearing instrument system further including:<claim-text>a second hearing instrument including:</claim-text><claim-text>a second microphone;</claim-text><claim-text>a second transceiver configured for wireless communication with the first transceiver; and</claim-text><claim-text>a second processor configured to execute software instructions stored in a second memory, the software instructions, when executed, configuring the processor to:<claim-text>receive the audio samples transmitted by the first transceiver as a first channel;</claim-text><claim-text>receive audio samples of audio collected at the second microphone as a second channel; and</claim-text><claim-text>combine the first channel and the second channel.</claim-text></claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The hearing instrument system according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the first channel and the second channel are combined as part of beamforming for the first microphone and the second microphone.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The hearing instrument system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein:<claim-text>each data packet includes audio data; and</claim-text><claim-text>each protocol packet includes protocol data and audio data.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The hearing instrument system according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein:<claim-text>the protocol data is preamble data.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The hearing instrument system according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein:<claim-text>the protocol data is synchronization data.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The hearing instrument system according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein:<claim-text>the protocol data is cyclic redundancy check (CRC) data.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The hearing instrument system according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein:<claim-text>the protocol data is 16 bits; and</claim-text><claim-text>the latency added by each protocol packet corresponds to a time necessary to transmit the 16 bits of protocol data.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The hearing instrument system according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the latency corresponding to the time necessary to transmit the 16 bits of protocol data is less than 200 microseconds.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The hearing instrument system according to <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein:<claim-text>the audio data included in each protocol packet and data packet is one audio sample.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The hearing instrument system according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:<claim-text>the one audio sample is represented by 16 bits that are encoded.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The hearing instrument system according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the wireless communication includes near-filed magnetic induction (NFMI).</claim-text></claim></claims></us-patent-application>
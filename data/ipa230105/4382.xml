<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004383A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004383</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17363853</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>77</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>36</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>8</main-group><subgroup>77</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>11</main-group><subgroup>3668</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">ANOMALY IDENTIFICATION WITHIN SOFTWARE PROJECT UNDER DEVELOPMENT</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>MICRO FOCUS LLC</orgname><address><city>Santa Clara</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Shufer</last-name><first-name>Ilan</first-name><address><city>Yehud</city><country>IL</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Vaingart</last-name><first-name>Tom</first-name><address><city>Yehud</city><country>IL</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Ishay</last-name><first-name>Sigal</first-name><address><city>Yehud</city><country>IL</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Quality indicators regarding a software project under development that has a plurality of functional areas are collected. Each quality indicator is normalized to a coverage of the functional area of the software project to which the quality indicator corresponds. The normalized quality indicators are correlated to previously identified anomalies of the software project, yielding an anomaly indicative value for each normalized quality indicator corresponding to a probability that the normalized quality indicator is revelatory of unidentified anomalies of the software project. A normal behavior for each normalized quality indicator is estimated. For each functional area of the software project, an anomaly score indicative of a likelihood of an unidentified anomaly within the functional area is calculated. The anomaly score is based on, for each normalized quality indicator corresponding to the functional area, how the normalized quality indicator departs from its estimated normal behavior as weighted by its anomaly indicative value.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="213.61mm" wi="154.77mm" file="US20230004383A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="215.65mm" wi="156.80mm" file="US20230004383A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="208.96mm" wi="156.80mm" file="US20230004383A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="188.81mm" wi="125.05mm" file="US20230004383A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="212.43mm" wi="156.80mm" file="US20230004383A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="159.43mm" wi="148.42mm" file="US20230004383A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="212.43mm" wi="144.02mm" file="US20230004383A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Computing systems made up of one or multiple computing devices, including server, desktop, laptop, and notebook computers, mobile computing devices such as smartphones and tablet computing devices, and other types of computing devices, run software, or computer programs, to perform intended functionality. As computing systems have increased in computing power and connectivity, the complexity of such software projects has greatly increased as well. Developing software projects has become an increasingly evolved process, involving large numbers of developers, testers, and other users to quickly roll out sophisticated software as defect-free as possible.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0003" num="0002"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of an example process for identifying anomalies within a software project under development.</p><p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram depicting how different example quality indicators can have different coverages of respective functional areas of a software project under development.</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram depicting how example normalized quality indicators can be supplemented with combined normalized quality indicators.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram depicting an example distribution of values of a normalized quality indicator.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref> are diagram depicting example pruning of normalized quality indicators.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram depicting how an example weighted departure value for a normalized quality indicator can be calculated.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram depicting how an example anomaly score for a functional area of a software project can be calculated.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram of an example computing device for identifying anomalies within a software project under development.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0003" level="1">DETAILED DESCRIPTION</heading><p id="p-0011" num="0010">Development of a software project can be a complex process involving many developers working on different functional areas of the software project and many testers testing the functional areas individually as well as the interoperability of the functional areas. Software project development has increasingly occurred at faster speed, with smaller, more frequent releases of software projects. Software development methodologies such as agile development, which focuses on discovering requirements and developing solutions through collaborative effort and continual improvement, as well DevOps, which combines software development (&#x201c;Dev&#x201d;) and information technology operations (&#x201c;Ops&#x201d;), have further shortened software project development lifecycles.</p><p id="p-0012" num="0011">Such accelerated software project development has shortened the time available to detect and address software project defects. Therefore, quality assurance personnel have to identify which functional areas in an application are at high risk for potential defects so that testing activities are focused on such areas. Identifying functional areas of a software project that are at risk, however, is difficult, typically involving subjectivity in the face of large amounts of data. Inaccuracy in identifying areas of a software project that are at high risk for defects can mean that actual defects remain undetected and are present when the software project is released, affecting the ability of the software to operate for its intended purpose.</p><p id="p-0013" num="0012">Risk estimation has traditionally focused on two ways for identifying functional areas of a software project that are at high risk for potential defects. First, a quality assurance expert may manually inspect various quality indicators collected during the software development process, and attempt to discern which functional areas are at risk for defects. However, such an approach relies upon the skill of the expert, whose knowledge may be uneven across different types of software projects and even different types of types of indicators. This approach therefore introduces subjectivity into the risk estimation process that may not provide a sound manner for high risk functional areas across different software project domains.</p><p id="p-0014" num="0013">Second, a supervised technique relying on an algorithm or model, such as linear regression, a deep neural network, and so on, can be used that has to be initially trained before deployment for actual estimation of high risk functional areas within a software project. Such a supervised technique can require elaborate and laborious construction. Experts have to painstakingly tag quality indicators collected during the development process of many software projects to specify whether the indicators correspond to functional areas at high risk of defects or not. Such tagged, or supervised, training data is then used to train the algorithm or model. Failure to collect sufficient training data, or failure to collect accurate training data, can result in this approach not accurately identifying high risk functional areas of different software projects.</p><p id="p-0015" num="0014">Techniques described herein ameliorate these and other issues. The described techniques provide a way to identify anomalies within a software project under development, such a defects and other anomalies, based on quality indicators regarding the software project that are collected during the development process. Specifically, the techniques calculate anomaly scores that are indicative of the likelihood of unidentified anomalies within functional areas of the software project. The functional areas having higher anomaly scores are more likely to be anomalous (i.e., contain anomalies in how the functional areas operate or perform, and therefore are at higher risk of having quality issues), and thus are at higher risk for containing defects. The techniques do not rely on subjective manual risk assessment by quality assurance or other experts, and further are unsupervised in that no algorithm or model has to be trained a priori on the basis of laboriously tagged training data.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an example process <b>100</b> (e.g., a method) for identifying anomalies within a software project <b>102</b> under development. The software project <b>102</b> may be composed of one or multiple computer programs, software code modules, and so on, that are interoperable to provide or perform intended functionality. The software project <b>102</b> can thus be considered as having a number of functional areas <b>104</b> that each correspond to a different function that assists in providing the overall intended functionality of the software project <b>102</b> as a whole. Different program code of the software project <b>102</b> may correspond to different functional areas <b>104</b>, and the size of a functional area <b>104</b> may correspond to the size of the program code of the software project <b>102</b> for that functional area <b>104</b>.</p><p id="p-0017" num="0016">Quality indicators <b>106</b> regarding the software project <b>102</b> are collected (<b>108</b>) during the development of the software project <b>102</b>. Quality indicators <b>106</b> can include values of different types of data that can be collected during testing of the software project <b>102</b> under development. Such quality indicators <b>106</b> can include automated test data that is regularly and frequently collected during a continuous improvement or continuous development process. Such test data can include the results of test runs, including the number of successful test runs and the number of failures. The test data can include automation coverage, as to how much each functional area <b>104</b> is covered by the automation tests in question. The test data can include how stable or instable the tests are. For instance, unstable tests and build processes generate more noisy data, which can heighten risk of anomalies in the software development process.</p><p id="p-0018" num="0017">The quality indicators <b>106</b> can include manual test data as well. Because the program code that is tested can be traced to functional areas <b>104</b> of the software project <b>102</b> under development, the output of the tests can be related to which functional areas <b>104</b> the tests correspond. Therefore, the status of each test can be collected, as well as the overall coverage of each test. Continuous improvement or continuous development process build data can also be collected as quality indicators <b>106</b>, such as the stability of test jobs performed during these processes, as well as data indicative of environmental and other types of issues.</p><p id="p-0019" num="0018">Code changes in the software project <b>102</b> may be mapped to functional areas <b>104</b> as part of the quality indicators <b>106</b>. For each code change, the data collected as part of the quality indicators <b>106</b> can include the number of commits made during development, and the committed number of program code lines. The quality indicators <b>106</b> can include scores for individual program code files reflecting the sensitivity of the files to such code changes. The quality indicators <b>106</b> can include backlog data, in that the estimated development effort of different functional areas <b>104</b> can be tracked during the development process of the software project <b>102</b>. Highly sensitive files and functional areas <b>104</b> having high development effort may be more at risk for potential defects within the software project <b>102</b>.</p><p id="p-0020" num="0019">During the development process, quality issues and other anomalies, such as defects, bugs, and so on, are likely to be discovered, and can be considered in this respect as previously identified anomalies <b>132</b> within the software project <b>102</b>. Such identified anomalies <b>132</b> can be used when assessing the likelihood of other, unidentified anomalies within the functional areas <b>104</b> of the software project <b>102</b>, on the basis of the quality indicators <b>106</b>. The foregoing examples of quality indicators <b>106</b> are not exhaustive, and other types of quality indicators <b>106</b> may also be collected during the development of the software project <b>102</b>.</p><p id="p-0021" num="0020">The collected quality indicators <b>106</b> are normalized (<b>110</b>) to yield normalized quality indicators <b>112</b>. Each quality indicator <b>106</b> is normalized to the coverage of the functional area <b>104</b> of the software project <b>102</b> to which the quality indicator <b>106</b> in question corresponds. Large functional areas <b>104</b> can have more tests run, and therefore more quality indicators <b>106</b> indicative of anomalies, than smaller functional areas <b>104</b>. Similarly, a quality indicator <b>106</b> more substantially covering a given functional area <b>104</b> than another quality indicator <b>106</b> is more likely to indicate anomalies than a quality indicator <b>106</b> that less substantially covers the functional area <b>104</b> in question. Normalizing each quality indicator <b>106</b> to the coverage of its corresponding functional area <b>104</b> ensures that anomaly identification is not biased towards quality indicators <b>106</b> covering larger functional areas <b>104</b> and/or that more completely cover their corresponding functional areas <b>104</b>.</p><p id="p-0022" num="0021">A quality indicator <b>106</b> can be normalized to the coverage of the functional area <b>104</b> of the software project <b>102</b> to which the quality indicator <b>106</b> corresponds based on the size of the program code to which the quality indicator <b>106</b> relates. A quality indicator <b>106</b> relating to a larger amount of program code will therefore be scaled more than a quality indicator <b>106</b> relating to a smaller amount of program code. The program code to which a corresponding functional area <b>104</b> for a quality indicator <b>106</b> pertains is thus used to normalize the quality indicator <b>106</b>, in consideration of the amount of this program code and the extent to which the quality indicator <b>106</b> covers the program code. The values of the quality indicators <b>106</b> are thus adjusted so that they are more consistently considered when identifying anomalies within the software project <b>102</b>.</p><p id="p-0023" num="0022">As a concrete example, a first quality indicator <b>106</b> may be indicative of the number of program code commits to a first functional area <b>104</b>, whereas a second quality indicator <b>106</b> may be indicative of the number of program code commits to a second functional area <b>104</b>. The first functional area <b>104</b> may have more lines of program code than the second functional area <b>104</b>, and therefore is larger in size than the second functional area <b>104</b>. To normalize the quality indicators <b>106</b> to coverages of their respective functional areas <b>104</b>, the number of program code commits of each quality indicator <b>106</b> may be divided by the number of program code lines of its respective functional area <b>104</b>. Therefore, the first quality indicator <b>106</b> is adjusted more than the second quality indicator <b>106</b>, because the first functional area <b>104</b> that the first quality indicator <b>106</b> covers has more program code lines than the second functional area <b>104</b> that the second quality indicator <b>106</b> covers. The number of program code lines in this respect is considered a normalization weight by which a quality indicator <b>106</b> is weighted for normalization purposes.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustratively depicts example quality indicator normalization as to a software project <b>102</b> having three functional areas <b>104</b>A, <b>104</b>B, and <b>104</b>C, which are collectively referred to as the functional areas <b>104</b>. The functional area <b>104</b>A is larger in size than the functional areas <b>104</b>B and <b>104</b>C, in that the software project <b>102</b> may have more lines of program code to realize the functional area <b>104</b>A than either functional area <b>104</b>B or <b>104</b>C. Quality indicators <b>202</b>A, <b>202</b>B, and <b>202</b>C, collectively referred to as the quality indicators <b>202</b>, have coverages of the functional area <b>104</b>A as depicted in the figure, with the quality indicator <b>202</b>A having greater coverage of the functional area <b>104</b>A than the quality indicator <b>202</b>B, and the quality indicator <b>202</b>B having greater coverage than the quality indicator <b>202</b>C. Further, the quality indicator <b>202</b>A overlaps the quality indicators <b>202</b>B and <b>202</b>C in coverage of the functional area <b>104</b>A. The quality indicators <b>202</b> are normalized based on their respective coverages of the functional area <b>104</b>A, such that the quality indicator <b>202</b>A is adjusted more than the quality indicator <b>202</b>B, which is adjusted more than the quality indicator <b>202</b>C.</p><p id="p-0025" num="0024">Quality indicators <b>204</b>A and <b>204</b>B, collectively referred to as the quality indicators <b>204</b>, have coverages of the functional area <b>104</b>B as depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The quality indicator <b>204</b>A has greater coverage of the functional area <b>104</b>B than the quality indicator <b>204</b>B, and completely overlaps the quality indicator <b>204</b>B in coverage. The quality indicators <b>204</b> are also normalized based on their respective coverages of the functional area <b>104</b>B, such that the quality indicator <b>204</b>A is adjusted more than the quality indicator <b>204</b>B. Note, too, that quality indicator normalization is based in this respect on the overall functional area size as well. For example, even though the coverage of the functional area <b>104</b>A by the quality indicator <b>202</b>A is less than the coverage of the functional area <b>104</b>B by the quality indicator <b>204</b>A, because the functional area <b>104</b>A is larger the functional area <b>104</b>B, the quality indicator <b>202</b>A may be adjusted more during normalization than the quality indicator <b>204</b>A.</p><p id="p-0026" num="0025">Quality indicators <b>206</b>A and <b>206</b>B, collectively referred to as the quality indicators <b>206</b>, have coverages of the functional area <b>104</b>C as depicted in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The extent to which the quality indicator <b>206</b>A covers the functional area <b>104</b>C is equal to the extent to which the quality indicator <b>206</b>B covers the functional area <b>104</b>C. That is, although the quality indicators <b>206</b> cover different portions of the functional area <b>104</b>C except for an overlapping part of the functional area <b>104</b>C, the percentage of the functional area <b>104</b>C covered by the quality indicator <b>206</b>A is equal to the percentage covered by the quality indicator <b>206</b>B. As noted above, quality indicator normalization is based on overall functional area size as well, meaning, for example, that though each quality indicator <b>206</b> covers more of the functional area <b>104</b>C than the quality indicator <b>202</b>B does the functional area <b>104</b>A, the quality indicator <b>202</b>B may be adjusted more during normalization than either quality indicator <b>206</b>.</p><p id="p-0027" num="0026">Referring back to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, once the collected quality indicators <b>106</b> have been normalized (<b>110</b>) as the normalized quality indicators <b>112</b>, the normalized quality indicators <b>112</b> may be combined (<b>114</b>) in various ways to yield combined normalized quality indicators <b>116</b>, which are additional normalized quality indicators. For example, different pairs or other sets of test normalized quality indicators <b>112</b> may be multiplied, divided, added, subtracted, and so on, in different ways. Such combined normalized quality indicators <b>116</b> may provide for anomaly identification where the individual normalized quality indicators <b>112</b> do not. The combined normalized quality indicators <b>116</b> are thus included (<b>118</b>) with the normalized quality indicators <b>112</b> to yield the normalized quality indicators <b>120</b> on which basis anomaly identification can subsequently be performed.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustratively depicts the normalized quality indicators <b>120</b> in this respect. The normalized quality indicators <b>120</b> include both the collected (individual) normalized quality indicators <b>112</b> and the combined normalized quality indicators <b>116</b> that are generated by combining the normalized quality indicators <b>112</b> in various ways. In the example, the normalized quality indicators <b>112</b> make up more of the normalized quality indicators <b>120</b> than the combined normalized quality indicators <b>116</b> do. However, in other implementations, there may be more combined normalized quality indicators <b>116</b> than normalized quality indicators <b>112</b>. The sets of normalized quality indicators <b>112</b> and combined normalized quality indicators <b>116</b> are thus joined together to make up the set of normalized quality indicators <b>120</b>.</p><p id="p-0029" num="0028">Referring back to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, distributions of values <b>122</b> are calculated (<b>124</b>) for the normalized quality indicators <b>120</b>. Each normalized quality indicator <b>120</b> has a distribution of values <b>122</b>. The distribution of values <b>122</b> for a normalized quality indicator <b>120</b> includes the values that have been collected for that normalized quality indicator <b>120</b> during development of the software project <b>102</b>. For a given software project <b>102</b>, some normalized quality indicators <b>120</b> may have values that change little if any, resulting in much narrower distributions of values <b>122</b> than other normalized quality indicators <b>120</b>. Normalized quality indicators <b>120</b> having little variation in their distributions of values <b>122</b> are unlikely to have predictive value in anomaly identification, since the introduction of an anomaly may not result in the values of such quality indicators <b>120</b> changing. Therefore, the normalized quality indicators <b>120</b> can be pruned (<b>126</b>) based on their distributions of values <b>122</b>, yielding normalized quality indicators <b>128</b> from which those normalized quality indicators <b>120</b> unlikely to have predictive value in anomaly identification have been removed.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustratively depicts an example range <b>400</b> of values for a normalized quality indicator <b>120</b> that can serve as the distribution of values <b>122</b> of that quality indicator <b>120</b>. The normalized quality indicator <b>120</b> has collected (and normalized) values that span from a minimum value <b>402</b> at one end of the range <b>400</b> to a maximum value <b>404</b> at the other end of the range <b>400</b>. In one implementation, any normalized quality indicator <b>120</b> for which the range <b>400</b> of values is less than a threshold may be removed as unlikely to have predictive value in anomaly identification. That is, if the maximum value <b>404</b> minus the minimum value <b>402</b> for a given normalized quality indicator <b>120</b> is less than this threshold, then the normalized quality indicator <b>120</b> in question is removed and not included within the normalized quality indicators <b>128</b>.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustratively depicts example pruning of the normalized quality indicators <b>120</b> on the basis of their distributions of values <b>122</b> to yield the normalized quality indicators <b>128</b>. Not all of the normalized quality indicators <b>120</b> are expected to have distributions of values <b>122</b> that have predictive value in anomaly identification. Therefore, to the extent that some of the normalized quality indicators <b>120</b> are removed, the resulting normalized quality indicators <b>128</b> are a subset of all the normalized quality indicators <b>120</b>, as depicted in the figure.</p><p id="p-0032" num="0031">Referring back to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the normalized quality indicators <b>128</b> can be correlated (<b>130</b>) with previously identified anomalies <b>132</b> within the software project <b>102</b> to yield anomaly indicative values <b>134</b>. The anomaly indicative value <b>134</b> for a normalized quality indicator <b>128</b> corresponds to the probability that the normalized quality indicator <b>128</b> is revelatory of unidentified anomalies of the software project <b>102</b>. For example, the values of a normalized quality indicator <b>128</b> can be correlated with the identification of anomalies <b>132</b> within the functional area <b>104</b> to which the normalized quality indicator <b>128</b> pertains, as covered by the quality indicator <b>128</b>. If identification of such anomalies <b>132</b> results in changes in the normalized quality indicator <b>128</b> in question, the normalized quality indicator <b>128</b> will have greater correlation (and thus a higher anomaly indicative value <b>134</b>) than a normalized quality indicator <b>128</b> that does not change with identification of the anomalies <b>132</b>.</p><p id="p-0033" num="0032">The normalized quality indicators <b>128</b> can also be self-correlated (<b>136</b>)&#x2014;i.e., correlated with one other&#x2014;to yield correlation values <b>138</b>. For example, each unique pair of normalized quality indicators <b>128</b> may be correlated with one another to determine a corresponding correlation value <b>138</b> for that pair. More generally, unique sets of two or more normalized quality indicators <b>128</b> may each be correlated with one another to determine a corresponding correlation value <b>138</b> for that set. Normalized quality indicators <b>128</b> that are correlated with one another in this respect are unlikely to independently have predictive value in anomaly identification. For example, if a first normalized quality indicator <b>128</b> has high correlation with a second normalized quality indicator <b>128</b>, then if the first quality indicator <b>128</b> is indicative of an anomaly, the second test will be in the same way, too, and vice-versa. Therefore, both normalized quality indicators <b>128</b> do not have to be considered when subsequently identifying anomalies within the software project <b>102</b> under development.</p><p id="p-0034" num="0033">The normalized quality indicators <b>128</b> can thus be pruned (<b>140</b>) based on their anomaly indicative values <b>134</b> and/or based on the correlation values <b>138</b> to yield normalized quality indicators <b>142</b>. In one implementation, normalized quality indicators <b>128</b> having anomaly indicative values <b>134</b> less than a first threshold may be removed and not remain part of the normalized quality indicators <b>142</b>. Additionally or instead, in another implementation, for each set of normalized quality indicators <b>128</b> having a correlation value <b>138</b> greater than a (different) second threshold, all but one of the quality indicators <b>128</b> of the set in question may be removed and not remain part of the normalized quality indicators <b>142</b>. For example, for each unique pair of normalized quality indicators <b>128</b> having a correlation value <b>138</b> greater than the second threshold, one of the two quality indicators <b>128</b> of that pair may be removed. That is, one of the two indicators <b>128</b> is selected to retain, with the other indicator <b>128</b> being removed. Which normalized quality indicator <b>128</b> is selected for retention may be achieved randomly, or in a different manner.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustratively shows the pruning of the normalized quality indicators <b>128</b> on the basis of their anomaly indicative values <b>134</b> and on the basis of the correlation values <b>138</b> to yield the normalized quality indicators <b>142</b>. The normalized quality indicators <b>128</b> include anomaly-indicative normalized quality indicators <b>602</b> that have anomaly indicative values <b>134</b> greater than the first threshold. The normalized quality indicators <b>602</b> are thus the normalized quality indicators <b>128</b> that remain after pruning on the basis of the anomaly indicative values <b>134</b>.</p><p id="p-0036" num="0035">The normalized quality indicators <b>128</b> further include uncorrelated normalized quality indicators <b>604</b>. The uncorrelated normalized quality indicators <b>604</b> are those normalized quality indicators <b>128</b> that remain after pruning to remove all but one normalized quality indicator <b>128</b> from each unique set of normalized quality indicators <b>128</b> having a correlation value <b>138</b> greater than the second threshold. In one implementation, the normalized quality indicators <b>128</b> that remain after pruning on the basis of both the anomaly indicative values <b>134</b> and the correlation values <b>138</b> are the normalized indicators <b>142</b> that are each an anomaly-indicative normalized quality indicator <b>602</b> and an uncorrelated normalized quality indicator <b>604</b>.</p><p id="p-0037" num="0036">Referring back to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the normal behavior of each normalized quality indicator <b>142</b> is estimated (<b>144</b>), yielding normal values <b>146</b> for the normalized quality indicators <b>142</b>. The normal value <b>146</b> of a normalized quality indicator <b>142</b> may be the typical value of the normalized quality indicator <b>142</b> when there are no anomalies within the functional area <b>104</b> covered by that normalized quality indicator <b>142</b>. The normal value <b>146</b> of a normalized quality indicator <b>142</b> can be determined from historical values of the normalized quality indicator <b>142</b>, as collected during the development of the software project <b>102</b>. For example, the normal value <b>146</b> of a normalized quality indicator <b>142</b> may be calculated as the mean or median of the historical values of the normalized quality indicator <b>142</b> in question.</p><p id="p-0038" num="0037">Departure values <b>148</b> are then calculated (<b>150</b>) for the normalized quality indicators <b>142</b> based on the normal values <b>146</b> of the normalized quality indicators <b>142</b>. For each normalized quality indicator <b>142</b>, the departure value <b>148</b> is calculated as indicative of the extent to which a current value of the normalized quality indicator <b>142</b>, as most recently collected during development of the software project <b>102</b>, departs from the normal value <b>146</b> of that normalized quality indicator <b>142</b>. The departure value <b>148</b> for a normalized quality indicator <b>142</b> may be calculated in a number of different ways. The departure value <b>148</b> may be calculated as the absolute difference between the current value of the normalized quality indicator <b>142</b> and the normal value <b>146</b> of that normalized quality indicator <b>142</b>. The departure value <b>148</b> may instead be calculated as the standard deviation of the normalized quality indicator <b>142</b>, a calculation that considers and thus is based on both the current value and the normal value <b>146</b> of that normalized quality indicator <b>142</b>.</p><p id="p-0039" num="0038">The departure values <b>148</b> for the normalized quality indicators <b>142</b> can be weighted (<b>152</b>) by their anomaly indicative values <b>134</b> to yield weighted departure values <b>154</b>. The weighted departure value <b>154</b> for a normalized quality indicator <b>142</b> can be calculated as the departure value <b>148</b> for the normalized quality indicator <b>142</b> multiplied by the anomaly indicative value <b>134</b> for that normalized quality indicator <b>142</b>. A normalized quality indicator <b>142</b> having a greater departure value <b>148</b> than another normalized quality indicator <b>142</b> means that the former normalized quality indicator <b>142</b> varies more from its normal behavior than the latter normalized quality indicator <b>142</b> does. While such departure from normal behavior may be indicative of an anomaly within the software project <b>102</b>, to the extent that a normalized quality indicator <b>142</b> has a higher anomaly indicative value <b>134</b>, the greater the likelihood that such departure from normal behavior is anomaly-indicative. Therefore, weighting the departure values <b>148</b> for the normalized quality indicators <b>142</b> by their respective anomaly indicative values <b>134</b> provides weighted departure values <b>154</b> that are more revelatory of unidentified anomalies of the software project <b>102</b>.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustratively shows calculation of the weighted departure value <b>154</b> for a normalized quality indicator <b>142</b>. The departure value <b>148</b> for the normalized quality indicator <b>142</b> is calculated based on the normal value <b>146</b> of the normalized quality indicator <b>142</b> and (at least) the current value <b>702</b> of the normalized quality indicator <b>142</b>. As noted, the normal value <b>146</b> is an estimation of the normal behavior of the normalized quality indicator <b>142</b>, and the departure value <b>148</b> indicates the extent to which (the current value <b>702</b> of) the normalized quality indicator <b>142</b> departs from such estimated normal behavior. The departure value <b>148</b> can then be weighted by the anomaly indicative value <b>134</b> for the normalized quality indicator <b>142</b> to yield the weighted departure value <b>154</b>. As also noted, the anomaly indicative value <b>134</b> correspond to the probability that the normalized quality indicator <b>142</b> is revelatory of unidentified anomalies of the software project <b>102</b>.</p><p id="p-0041" num="0040">Referring back to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, anomaly scores <b>156</b> for the functional areas <b>104</b> of the software project <b>102</b> are calculated (<b>158</b>) based on the weighted departure values <b>154</b> of their corresponding normalized quality indicators <b>142</b>. That is, for each functional area <b>104</b>, an anomaly score <b>156</b> is calculated from the weighted departure values <b>154</b> for those normalized quality indicators <b>142</b> that correspond to (i.e., cover) the functional area <b>104</b> in question. For example, the average of the weighted departure values <b>154</b> for the normalized quality indicators <b>142</b> corresponding to a functional area <b>104</b> may be calculated as the anomaly score <b>156</b> for that functional area <b>104</b>. The anomaly score <b>156</b> for a functional area <b>104</b> of the software project <b>102</b> is indicative of the likelihood of an unidentified anomaly within the functional area <b>104</b> in question. The higher the anomaly score <b>156</b>, the more likely the functional area <b>104</b> having that anomaly score <b>156</b> may have an unidentified anomaly. Therefore, the program code functional areas <b>104</b> having the highest anomaly scores <b>156</b>, or the functional areas <b>104</b> for which the anomaly scores <b>156</b> are greater than a threshold, may be subjected to heightened inspection to determine whether they have defects causing the anomalous behavior.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustratively shows example calculation of an anomaly score <b>156</b> for a functional area <b>104</b> of the software project <b>102</b>. There are normalized quality indicators <b>142</b>A, <b>142</b>B, . . . , <b>142</b>N, collectively referred to as the normalized quality indicators <b>142</b>, which correspond to the functional area <b>104</b> in question, in that the normalized quality indicators <b>142</b> cover this functional area <b>104</b>. The normalized quality indicators <b>142</b>, <b>142</b>B, . . . , <b>142</b>N respectively have weighted departure values <b>154</b>A, <b>154</b>B, . . . , <b>154</b>N, which are collectively referred to as the weighted departure values <b>154</b>. The anomaly score <b>156</b> for the functional area <b>104</b> is thus calculated based on the weighted departure values <b>154</b> for the normalized quality indicators <b>142</b> corresponding to the functional area <b>104</b>, such as the average of these weighted departure values <b>154</b>.</p><p id="p-0043" num="0042">Referring back to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a remedial action may be performed (<b>160</b>) regarding the functional areas <b>104</b> of the software project <b>102</b> based on their anomaly scores <b>156</b>. For instance, a remedial action may be performed regarding each functional area <b>104</b> having an anomaly score <b>156</b> greater than a threshold. The program code of the software project <b>102</b> causing the unidentified anomaly within the functional area <b>104</b> may be identified. For example, to the extent that the anomaly score <b>156</b> for a functional area <b>104</b> is based on the weighted departure values <b>154</b> of normalized quality indicators <b>142</b> corresponding to that functional area <b>104</b>, which of these quality indicators <b>142</b> have the highest weighted departure value <b>154</b> may be identified as contributing to the anomaly score <b>156</b>. The program code of the software project <b>102</b> that these identified normalized quality indicators <b>142</b> cover can then be identified as that which is likely causing the unidentified anomaly within the functional area <b>104</b> in question.</p><p id="p-0044" num="0043">Performing the remedial action can include resolving the unidentified anomaly within the identified program code. For example, the program code may be subjected to error analysis and correction to identify and correct any specified errors in an automated manner. An error analysis and correction program may be able to automatically identify and correct certain types of program code errors, for instance, without developer assistance or interaction. Performing the remedial action can additionally or instead include automatically performing additional tests on the identified program code or the functional area <b>104</b> in question to acquire and thus provide further information regarding the unidentified anomaly. For example, more thorough but time consuming tests may be run just for those functional areas <b>104</b> having anomaly scores <b>156</b> greater than the threshold. Overall development of the software project <b>102</b> is thus not unnecessarily slowed down by running these tests on all the functional areas <b>104</b>, including those that are not likely to include unidentified anomalies.</p><p id="p-0045" num="0044">The process <b>100</b> that has been described as to generation of the anomaly scores <b>156</b> for the functional areas <b>104</b> of the software project <b>102</b> under development considers quality indicators <b>106</b> collected for the software project <b>102</b> that are subjected to normalization. As described, the normalization of the quality indicators <b>106</b> results in normalized quality indicators <b>112</b> that are then used for the remaining parts of the process <b>100</b>. However, the quality indicators <b>106</b> can be normalized in the generation of the anomaly scores <b>156</b> for the functional areas <b>104</b> in different ways as well. For example, a normalization weight may be calculated or otherwise generated for each quality indicator <b>106</b> that is indicative of the extent to which the quality indicator <b>106</b> in question covers its corresponding functional area <b>104</b>. Rather than multiplying the quality indicator <b>106</b> by the normalization weight to yield a corresponding normalized quality indicator <b>112</b>, the normalization weight may be used later in the process <b>100</b>, however. For instance, how a quality indicator <b>142</b> departs from its normal behavior can be weighted by both this normalization weight and the anomaly indicative value <b>134</b> for the quality indicator <b>142</b>. That is, the departure value <b>148</b> for the quality indicator <b>142</b> may be weighted by both its normalization weight and anomaly indicative value <b>134</b> to yield the weighted departure value <b>154</b> for the quality indicator <b>142</b>.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows an example computing device <b>900</b> for identifying anomalies within a software project <b>102</b> under development. The computing device <b>900</b> may be a server, desktop, laptop, or notebook computer, for instance. The computing device <b>900</b> may be one of the computing devices on which the software project <b>102</b> is being tested and/or developed, or may be another computing device. The computing device <b>900</b> can include a processor <b>902</b> and a non-transitory computer-readable data storage medium <b>904</b>, such as a memory. The computer-readable data storage medium <b>904</b> stores program code <b>906</b> that is executable by the processor <b>902</b> to perform processing (e.g., a method).</p><p id="p-0047" num="0046">The processing includes collecting quality indicators <b>106</b> regarding the software project <b>102</b> under development that has the functional areas <b>104</b> (<b>908</b>). The processing includes normalizing each quality indicator <b>106</b> to a coverage of the functional area <b>104</b> of the software project <b>102</b> to which the quality indicator <b>106</b> corresponds (<b>910</b>), yielding a normalized quality indicator <b>112</b>. The processing can include generating additional normalized quality indicators <b>116</b> (<b>912</b>) that each combine a number of the normalized quality indicators <b>112</b> that have been collected. The additional (i.e., combined) normalized quality indicators <b>116</b> are included with the normalized quality indicators <b>112</b> to yield the normalized quality indicators <b>120</b>. The processing includes calculating a distribution of values <b>122</b> of each normalized quality indicator <b>120</b>, and removing each normalized quality indicator <b>120</b> for which the distribution of values <b>122</b> is unlikely to have predictive value in anomaly identification (<b>914</b>). The result of such pruning is a set of normalized quality indicators <b>128</b>.</p><p id="p-0048" num="0047">The processing includes correlating the normalized quality indicators <b>128</b> (<b>916</b>), on which basis the normalized quality indicators <b>128</b> can be pruned to yield the normalized quality indicators <b>142</b>. The normalized quality indicators <b>128</b> are correlated to previously identified anomalies <b>132</b> of the software project <b>102</b>, yielding an anomaly indicative value <b>134</b> for each normalized quality indicator <b>128</b> corresponding to a probability that the normalized quality indicator <b>128</b> is revelatory of unidentified anomalies of the software project <b>102</b>. The normalized quality indicators <b>128</b> can also be correlated to one another, yielding correlation values <b>138</b> for unique sets of normalized quality indicators <b>128</b>. The normalized quality indicators <b>128</b> can be pruned on the basis of the anomaly indicative values <b>134</b> and/or the correlation values <b>138</b> to yield the normalized quality indicators <b>142</b>.</p><p id="p-0049" num="0048">The processing includes estimating a normal behavior for each normalized quality indicator <b>142</b> (<b>918</b>). For each functional area <b>104</b> of the software project <b>102</b>, the processing includes calculating an anomaly score <b>156</b> indicative of a likelihood of an unidentified anomaly within the functional area <b>104</b> (<b>920</b>). The calculation of the anomaly score <b>156</b> is based on, for each normalized quality indicator <b>142</b> corresponding to the functional area <b>104</b> in question, how the normalized quality indicator <b>142</b> departs from the estimated normal behavior for the normalized quality indicator <b>142</b> as weighted by the anomaly indicative value <b>134</b> for the normalized quality indicator <b>142</b>. The processing can include performing remedial actions regarding each functional area <b>104</b> of the software project <b>102</b> for which the anomaly score <b>156</b> is greater than a threshold (<b>922</b>).</p><p id="p-0050" num="0049">Techniques have been described for identifying anomalies within a software project under development. Specifically, the techniques identify the likelihood that each functional area includes an unidentified anomaly. The described techniques in this respect calculate an anomaly score for each functional area of the software project. The anomaly score is calculated in a way that does not require manual and subjective inspection by a quality assurance expert or other user. The anomaly score is further calculated in a way that does not require a supervised algorithm or model, and thus does not require laborious collection of training data that may be incomplete or prone to error. The techniques therefore improve the technology of software development, by permitting software projects to be developed more quickly in a defect-free manner.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>We claim:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A non-transitory computer-readable data storage medium storing program code executable by a processor to perform processing comprising:<claim-text>collecting a plurality of quality indicators regarding a software project under development that has a plurality of functional areas;</claim-text><claim-text>normalizing each quality indicator to a coverage of the functional area of the software project to which the quality indicator corresponds;</claim-text><claim-text>correlating the normalized quality indicators to previously identified anomalies of the software project, yielding an anomaly indicative value for each normalized quality indicator corresponding to a probability that the normalized quality indicator is revelatory of unidentified anomalies of the software project;</claim-text><claim-text>estimating a normal behavior for each normalized quality indicator; and</claim-text><claim-text>for each functional area of the software project, calculating an anomaly score indicative of a likelihood of an unidentified anomaly within the functional area, based on, for each normalized quality indicator corresponding to the functional area, how the normalized quality indicator departs from the estimated normal behavior for the normalized quality indicator as weighted by the anomaly indicative value for the normalized quality indicator.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing further comprises:<claim-text>performing a remedial action regarding each functionality area of the software project for which the anomaly score is greater than a threshold.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein performing the remedial action comprises:<claim-text>identifying code of the software project causing the unidentified anomaly.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein performing the remedial action comprises:<claim-text>resolving the unidentified anomaly within code of the software project.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein performing the remedial action comprises:<claim-text>identifying the normalized quality indicators contributing to the anomaly score.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein performing the remedial action comprises:<claim-text>performing additional tests to provide further information regarding the unidentified anomaly.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein normalizing each quality indicator to the coverage of the functional area of the software project to which the quality indicator corresponds comprises:<claim-text>generating a normalization weight for each quality indicator that is indicative of an extent to which the quality indicator covers the functional area to which the quality indicator corresponds,</claim-text><claim-text>wherein how each normalized quality indicator departs from the estimated normal behavior for the normalized quality indicator is weighted by the normalization weight in addition to the anomaly indicative value when calculating the anomaly score indicative of the likelihood of the unidentified anomaly within the functional area to which the quality indicator corresponds.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing further comprises:<claim-text>generating a plurality of additional normalized quality indicators, each additional normalized quality indicator combining a number of the normalized quality indicators that have been collected,</claim-text><claim-text>wherein the additional normalized quality indicators are included within the normalized quality indicators that are subsequently correlated and that the normal behavior of each of which is subsequently estimated for calculation of the anomaly score for each functional area of the software project.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing further comprises:<claim-text>calculating a distribution of values of each normalized quality indicator; and</claim-text><claim-text>removing each normalized quality indicator for which the distribution of values is unlikely to have predictive value in anomaly identification.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein removing each normalized quality indicator for which the distribution of values is unlikely to have predictive value in anomaly detection comprises:<claim-text>removing each normalized quality indicator for which a range between a maximum value of the distribution of values and a minimum value of the distribution of values is less than a threshold.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing further comprises:<claim-text>correlating the normalized quality indicators to one another; and</claim-text><claim-text>for each set of the normalized quality indicators that are correlated to one another by more than a threshold, removing the normalized quality indicators of the set other than a selected normalized quality indicator of the set to retain just the selected normalized quality indicator of the set.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing further comprises:<claim-text>calculating a correlation between each of a plurality of unique pairs of the normalized quality indicators; and</claim-text><claim-text>for each unique pair of the normalized quality indicators between which the correlation is greater than a threshold, removing one of the normalized quality indicators of the unique pair.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein estimating the normal behavior of each normalized quality indicator comprises:<claim-text>determining a normal value of the normalized quality indicator from historical values of the normalized quality indicator.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the normal value is a mean or a median of historical values of the normalized quality indicator.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein, for each functional area of the software project, calculating the anomaly score indicative of the likelihood of the unidentified anomaly within the functional area comprises:<claim-text>for each normalized quality indicator corresponding to the functional area, calculating a departure value indicative of an extent to which a current value of the normalized quality indicator departs from the normal value of the normalized quality indicator;</claim-text><claim-text>for each normalized quality indicator corresponding to the functional area, multiplying the departure value for the normalized quality indicator by the anomaly indicative value for the normalized quality indicator, yielding a weighted departure value for the normalized quality indicator; and</claim-text><claim-text>calculating the anomaly score based on the weighted departure value for each normalized quality indicator corresponding to the functional area.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein calculating the departure value indicative of the extent to which a current value of the normalized quality indicator departs from the normal value of the normalized quality indicator comprises:<claim-text>calculating an absolute difference between the current value of the normalized quality indicator and the normal value of the normalized quality indicator, as the departure value.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable data storage medium of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein calculating the anomaly score based on the weighted departure value for each normalized quality indicator corresponding to the functional area comprises:<claim-text>calculating an average of the weighted departure value for each normalized quality indicator corresponding to the functional value, as the anomaly score.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A computing device comprising:<claim-text>a processor; and</claim-text><claim-text>a non-transitory computer-readable data storage medium storing program code executable by the processor to:<claim-text>collect a plurality of quality indicators regarding a software project under development that has a plurality of functional areas;</claim-text><claim-text>normalize each quality indicator to a coverage of the functional area of the software project to which the quality indicator corresponds;</claim-text><claim-text>calculate a distribution of values of each normalized quality indicator;</claim-text><claim-text>remove each normalized quality indicator for which the distribution of values is unlikely to have predictive value in anomaly identification;</claim-text><claim-text>correlate the normalized quality indicators to one another; and</claim-text><claim-text>for each set of the normalized quality indicators that are correlated to one another by more than a threshold, remove the normalized quality indicators of the set other than a selected normalized quality indicator of the set to retain just the selected normalized quality indicator of the set;</claim-text><claim-text>correlate the normalized quality indicators to previously identified anomalies of the software project, yielding an anomaly indicative value for each normalized quality indicator corresponding to a probability that the normalized quality indicator is revelatory of unidentified anomalies of the software project;</claim-text><claim-text>estimate a normal behavior for each normalized quality indicator; and</claim-text><claim-text>for each functional area of the software project, calculate an anomaly score indicative of a likelihood of an unidentified anomaly within the functional area, based on, for each normalized quality indicator corresponding to the functional area, how the normalized quality indicator departs from the estimated normal behavior for the normalized quality indicator as weighted by the anomaly indicative value for the normalized quality indicator.</claim-text></claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computing device of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the program code is executable by the processor to further:<claim-text>perform a remedial action regarding each functionality area of the software project for which the anomaly score is greater than an anomaly threshold.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A method comprising:<claim-text>collecting, by a processor, a plurality of quality indicators regarding a software project under development that has a plurality of functional areas;</claim-text><claim-text>normalizing, by the processor, each quality indicator to a coverage of the functional area of the software project to which the quality indicator corresponds;</claim-text><claim-text>calculating, by the processor, a distribution of values of each normalized quality indicator;</claim-text><claim-text>generating, by the processor, a plurality of additional normalized quality indicators, each additional normalized quality indicator combining a number of the normalized quality indicators that have been collected;</claim-text><claim-text>removing, by the processor, each normalized quality indicator for which the distribution of values is unlikely to have predictive value in anomaly identification;</claim-text><claim-text>correlating, by the processor, the normalized quality indicators to one another; and</claim-text><claim-text>for each set of the normalized quality indicators that are correlated to one another by more than a threshold, removing, by the processor, the normalized quality indicators of the set other than a selected normalized quality indicator of the set to retain just the selected normalized quality indicator of the set;</claim-text><claim-text>correlating, by the processor, the normalized quality indicators to previously identified anomalies of the software project, yielding an anomaly indicative value for each normalized quality indicator corresponding to a probability that the normalized quality indicator is revelatory of unidentified anomalies of the software project;</claim-text><claim-text>estimating, by the processor, a normal behavior for each normalized quality indicator;</claim-text><claim-text>for each functional area of the software project, calculating, by the processor, an anomaly score indicative of a likelihood of an unidentified anomaly within the functional area, based on, for each normalized quality indicator corresponding to the functional area, how the normalized quality indicator departs from the estimated normal behavior for the normalized quality indicator as weighted by the anomaly indicative value for the normalized quality indicator; and</claim-text><claim-text>performing a remedial action regarding each functionality area of the software project for which the anomaly score is greater than an anomaly threshold.</claim-text></claim-text></claim></claims></us-patent-application>
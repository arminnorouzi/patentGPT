<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007178A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007178</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17932658</doc-number><date>20220915</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-079514</doc-number><date>20200428</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23287</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23216</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>23229</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180801</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>232945</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">PROCESSOR OF IMAGING APPARATUS, IMAGING APPARATUS, CONTROL METHOD OF IMAGING APPARATUS, AND CONTROL PROGRAM OF IMAGING APPARATUS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/008082</doc-number><date>20210303</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17932658</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>FUJIFILM Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TANAKA</last-name><first-name>Koichi</first-name><address><city>Saitama-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KURIBAYASHI</last-name><first-name>Kosuke</first-name><address><city>Saitama-shi</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>FUJIFILM Corporation</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A processor of an imaging apparatus including an imaging element that images a subject through an imaging optical system is configured to: perform a recording control of performing one of: first processing as defined herein; and second processing as defined herein; perform an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system; perform image processing of generating a live view image for displaying a subject image formed in the second region on a display unit; and perform a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element and the lens in the image shake correction control to be larger than in a case of performing the second processing.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="99.06mm" wi="158.75mm" file="US20230007178A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="175.43mm" wi="135.81mm" orientation="landscape" file="US20230007178A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="180.85mm" wi="135.72mm" file="US20230007178A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="185.84mm" wi="146.81mm" file="US20230007178A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="190.58mm" wi="137.67mm" file="US20230007178A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="181.69mm" wi="145.80mm" file="US20230007178A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="179.15mm" wi="144.19mm" file="US20230007178A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="235.80mm" wi="148.00mm" file="US20230007178A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="186.69mm" wi="154.35mm" file="US20230007178A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="164.42mm" wi="110.41mm" file="US20230007178A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="211.50mm" wi="154.43mm" file="US20230007178A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="158.16mm" wi="149.10mm" file="US20230007178A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="175.51mm" wi="128.95mm" orientation="landscape" file="US20230007178A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="168.15mm" wi="148.59mm" file="US20230007178A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="163.49mm" wi="99.91mm" file="US20230007178A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="184.40mm" wi="149.61mm" file="US20230007178A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This is a continuation of International Application No. PCT/JP2021/008082 filed on Mar. 3, 2021, and claims priority from Japanese Patent Application No. 2020-079514 filed on Apr. 28, 2020, the entire disclosures of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><heading id="h-0003" level="1">1. Field of the Invention</heading><p id="p-0003" num="0002">The present invention relates to a processor of an imaging apparatus, an imaging apparatus, a control method of an imaging apparatus, and a computer readable medium storing a control program of an imaging apparatus.</p><heading id="h-0004" level="1">2. Description of the Related Art</heading><p id="p-0004" num="0003">JP2007-114311A discloses an apparatus comprising an imaging optical system including an imaging sensor, an electronic zooming unit that changes a subject region by trimming a part of an image formed on the imaging sensor, an image shake correction unit that operates a shake correction optical element constituting a part of the imaging optical system in a plane orthogonal to an optical axis in accordance with a magnitude and a direction of a shake exerted on the imaging optical system, a section in which area data indicating a change in size of an effective imaging region corresponding to the subject region in a case where the subject region is changed by the electronic zooming unit is recorded in advance, and a movable range control unit that changes a movable range of the shake correction optical element corresponding to the change of the subject region based on the area data of the recording section.</p><p id="p-0005" num="0004">JP1992-319923A (JP-H4-319923A) discloses a camera comprising a setting unit that sets any mode of a normal imaging mode in which the entire imaging screen is printed or a trimming imaging mode in which a pseudo zoomed-in photo is obtained by trimming a part of the imaging screen. In a case where the trimming imaging mode is set, the camera operates a shake detection unit that detects a shake of an image in the imaging screen.</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0006" num="0005">An object of the present invention is to provide a processor of an imaging apparatus, an imaging apparatus, a control method of an imaging apparatus, and a computer readable medium storing a control program of an imaging apparatus that improve image shake correction performance.</p><p id="p-0007" num="0006">A processor of an imaging apparatus according to an aspect of the present invention is a processor of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the processor being configured to perform a recording control of performing any of first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region, perform an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system, perform image processing of generating a live view image for displaying a subject image formed in the second region on a display unit, and perform a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element or the lens in the image shake correction control to be larger than in a case of performing the second processing.</p><p id="p-0008" num="0007">An imaging apparatus according to another aspect of the present invention comprises the processor, and the imaging element.</p><p id="p-0009" num="0008">A control method of an imaging apparatus according to still another aspect of the present invention is a control method of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the method comprising performing a recording control of performing any of first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region, performing an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system, performing image processing of generating a live view image for displaying a subject image formed in the second region on a display unit, and performing a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element or the lens in the image shake correction control to be larger than in a case of performing the second processing.</p><p id="p-0010" num="0009">A control program included in a computer readable medium according to still another aspect of the present invention is a control program of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the control program causing a processor to execute a recording control of performing any of first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region, an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system, image processing of generating a live view image for displaying a captured image output from the second region on a display unit, and a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element or the lens in the image shake correction control to be larger than in a case of performing the second processing.</p><p id="p-0011" num="0010">According to the present invention, image shake correction performance can be improved.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating a schematic configuration of a digital camera <b>1</b> that is one embodiment of an imaging apparatus according to the present invention.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic plan view of a light-receiving region of an imaging element <b>12</b> seen in a direction of an optical axis K.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram schematically illustrating a live view image and a normal recording image in a normal recording mode.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically illustrating the live view image and a crop recording image in a crop recording mode.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic diagram for describing a movable range of the imaging element <b>12</b> in the normal recording mode.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic diagram for describing the movable range of the imaging element <b>12</b> in the crop recording mode.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating a state where the imaging element <b>12</b> is moved to an end of the movable range in the crop recording mode.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic diagram illustrating an example of a brightness gain used for brightness shading correction.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart for describing an operation of the digital camera <b>1</b>.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram schematically illustrating the live view image after semi-transparent processing.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart for describing the operation of the digital camera <b>1</b> in a case of decreasing edge part image quality of the live view image by performing the semi-transparent processing.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart for describing an operation of a digital camera of a fifth modification example.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a schematic diagram illustrating a sixth modification example of the digital camera <b>1</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart for describing an operation of the digital camera of the sixth modification example in the crop recording mode.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates an exterior of a smartphone <b>200</b> that is one embodiment of the imaging apparatus according to the present invention.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a block diagram illustrating a configuration of the smartphone <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating a schematic configuration of a digital camera <b>1</b> that is one embodiment of an imaging apparatus according to the present invention.</p><p id="p-0029" num="0028">The digital camera <b>1</b> comprises a camera body <b>10</b> and a lens device <b>20</b>. The lens device <b>20</b> is attachably and detachably, in other words, interchangeably, configured with respect to the camera body <b>10</b>. The lens device <b>20</b> may be integrated with the camera body <b>10</b>.</p><p id="p-0030" num="0029">The lens device <b>20</b> includes an imaging optical system <b>30</b> and a lens control unit <b>40</b>. The imaging optical system <b>30</b> comprises an imaging lens <b>31</b> and a stop mechanism and the like, not illustrated. For example, the imaging lens <b>31</b> is composed of a single lens or a plurality of lenses including a lens for adjusting a focal point of the imaging optical system <b>30</b>. The lens control unit <b>40</b> is mainly configured with a processor and controls driving of the imaging optical system <b>30</b> under control of a system control unit <b>18</b>, described later.</p><p id="p-0031" num="0030">The camera body <b>10</b> comprises an imaging element <b>12</b>, an imaging element shift mechanism <b>13</b>, an imaging element drive unit <b>14</b>, a display unit <b>15</b> that is a display device such as a liquid crystal display or an organic electro luminescence (EL) display, a memory <b>16</b> including a random access memory (RAM) as a volatile memory in which information is temporarily recorded, a read only memory (ROM) as a non-volatile memory in which a program and various information necessary for an operation of the program are recorded in advance, and the like, a motion detection sensor <b>17</b>, the system control unit <b>18</b>, and a recording medium <b>19</b> such as a memory card configured with a non-volatile memory.</p><p id="p-0032" num="0031">The imaging element <b>12</b> images a subject through the imaging optical system <b>30</b>. The imaging element <b>12</b> is configured with a charge coupled device (CCD) image sensor, a complementary metal oxide semiconductor (CMOS) image sensor, or the like. The imaging element <b>12</b> includes a light-receiving region in which a plurality of pixels are two-dimensionally arranged. In a case where the imaging element <b>12</b> is a CMOS image sensor, the imaging element drive unit <b>14</b> may be integrated with the CMOS image sensor.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic plan view of the light-receiving region of the imaging element <b>12</b> seen in a direction of an optical axis K. In a rectangular light-receiving region <b>120</b> of the imaging element <b>12</b>, the plurality of pixels are two-dimensionally arranged in a row direction X and a column direction Y orthogonal to the row direction X. In the light-receiving region <b>120</b>, a rectangular crop region <b>121</b> that is a region of a part of the light-receiving region <b>120</b> and an edge part region <b>122</b> that is a region excluding the crop region <b>121</b> are set. The crop region <b>121</b> constitutes a first region. The light-receiving region <b>120</b> constitutes a second region. The edge part region <b>122</b> constitutes a third region. A set of pixel signals output from all pixels of the light-receiving region <b>120</b> or a part (for example, pixels of only odd-numbered rows) of all pixels will be referred to as a captured image signal. A crop ratio &#x3b2; is defined as a value obtained by dividing a size (defined as a length of a diagonal line) of the light-receiving region <b>120</b> by a size (defined as a length of a diagonal line) of the crop region <b>121</b>.</p><p id="p-0034" num="0033">The imaging element shift mechanism <b>13</b> is a mechanism for preventing a shake of a subject image formed in the light-receiving region <b>120</b> of the imaging element <b>12</b> by moving the imaging element <b>12</b> in a plane perpendicular to the optical axis K of the imaging optical system <b>30</b>.</p><p id="p-0035" num="0034">The motion detection sensor <b>17</b> is a sensor for detecting a motion of the digital camera <b>1</b>. The motion detection sensor <b>17</b> is configured with, for example, an acceleration sensor or an angular velocity sensor or both thereof. The motion detection sensor <b>17</b> may be disposed in the lens device <b>20</b>.</p><p id="p-0036" num="0035">The system control unit <b>18</b> manages and controls the entire digital camera <b>1</b>. A hardware structure of the system control unit <b>18</b> corresponds to various processors that perform processing by executing programs including a control program of the imaging apparatus.</p><p id="p-0037" num="0036">The various processors include a central processing unit (CPU) that is a general-purpose processor performing various types of processing by executing a program, a programmable logic device (PLD) that is a processor of which a circuit configuration can be changed after manufacturing like a field programmable gate array (FPGA), or a dedicated electric circuit or the like that is a processor having a circuit configuration dedicatedly designed to execute a specific type of processing like an application specific integrated circuit (ASIC). More specifically, a structure of the various processors is an electric circuit in which circuit elements such as semiconductor elements are combined.</p><p id="p-0038" num="0037">The system control unit <b>18</b> may be configured with one of the various processors or may be configured with a combination of two or more processors of the same type or different types (for example, a combination of a plurality of FPGAs or a combination of a CPU and an FPGA).</p><p id="p-0039" num="0038">The system control unit <b>18</b> causes the imaging element <b>12</b> to image the subject by controlling the imaging element drive unit <b>14</b> and outputs a captured image signal corresponding to the subject image formed in the light-receiving region <b>120</b> of the imaging element <b>12</b> from the imaging element <b>12</b>. The system control unit <b>18</b> generates an image of a format such as Joint Photographic Experts Group (JPEG) format reproducible by the digital camera <b>1</b> or another apparatus by performing image processing on the captured image signal (RAW data) output from the light-receiving region <b>120</b> of the imaging element <b>12</b>.</p><p id="p-0040" num="0039">Hereinafter, the image obtained by performing image processing on the captured image signal output from the light-receiving region <b>120</b> of the imaging element <b>12</b> will be referred to as a captured image output from the light-receiving region <b>120</b> of the imaging element <b>12</b>. The captured image includes a live view image that is an image for displaying the subject image formed in the light-receiving region <b>120</b> on the display unit <b>15</b>, and a normal recording image that is an image for recording the subject image formed in the light-receiving region <b>120</b> on the recording medium <b>19</b>. The normal recording image constitutes a second captured image. While the subject included in each of the live view image and the normal recording image is the same, sizes (the number of vertical and horizontal pixels) of the images are different. An image obtained by performing image processing on a captured image output from the crop region <b>121</b> in the captured image signal output from the light-receiving region <b>120</b> will be referred to as a crop recording image. The crop recording image constitutes a first captured image.</p><p id="p-0041" num="0040">An imaging mode of the digital camera <b>1</b> includes a normal recording mode in which second processing of imaging the subject by the imaging element <b>12</b> at a timing corresponding to an imaging instruction and recording the normal recording image (captured image output from the light-receiving region <b>120</b>) obtained by the imaging on the recording medium <b>19</b> is performed, and a crop recording mode in which first processing of imaging the subject by the imaging element <b>12</b> at the timing corresponding to the imaging instruction and recording the crop recording image (captured image output from the crop region <b>121</b>) obtained by the imaging on the recording medium <b>19</b> is performed. Each of the normal recording image and the crop recording image may be set to be recorded on the recording medium <b>19</b> in the form of RAW data before image processing.</p><p id="p-0042" num="0041">In both of the normal recording mode and the crop recording mode, the system control unit <b>18</b> performs a control of imaging the subject by the imaging element <b>12</b>, generating the live view image by performing image processing on the captured image signal output from the light-receiving region <b>120</b> of the imaging element <b>12</b> by the imaging, and displaying the live view image on the display unit <b>15</b>.</p><p id="p-0043" num="0042">Image processing performed on the captured image signal in generating the live view image includes correction processing for correcting a decrease in image quality that may occur depending on optical characteristics of the imaging optical system <b>30</b>, a pixel structure of the imaging element <b>12</b>, or the like. The correction processing includes brightness shading correction of correcting a decrease in brightness depending on an image height, noise correction of reducing a noise increased by the brightness shading correction, outline highlight processing of correcting a decrease in sharpness (blurriness) depending on the image height, distortion correction of correcting a distortion occurring in an edge part of the image, lateral chromatic aberration correction of correcting a chromatic aberration in the edge part, fringe correction, and the like. Image processing in generating each of the normal recording image and the crop recording image also includes the same correction processing.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram schematically illustrating the live view image and the normal recording image in the normal recording mode. In the normal recording mode, a live view image LV is generated from a captured image signal D<b>2</b> output from the light-receiving region <b>120</b> of the imaging element <b>12</b> and is displayed on a display surface <b>150</b> of the display unit <b>15</b>. In a case where the imaging instruction is provided in the normal recording mode, a normal recording image P<b>2</b> is generated from the captured image signal D<b>2</b> and is recorded on the recording medium <b>19</b>.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram schematically illustrating the live view image and the crop recording image in the crop recording mode. In the crop recording mode, the live view image LV is generated from the captured image signal D<b>2</b> output from the light-receiving region <b>120</b> of the imaging element <b>12</b> and is displayed on the display surface <b>150</b> of the display unit <b>15</b>.</p><p id="p-0046" num="0045">The captured image signal D<b>2</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is configured with an image signal D<b>1</b> output from the crop region <b>121</b> and an image signal D<b>3</b> output from the edge part region <b>122</b>. The live view image LV is configured with an image L<b>1</b> (image generated from the image signal D<b>1</b>) corresponding to the crop region <b>121</b> and an image L<b>3</b> (image generated from the image signal D<b>3</b>) corresponding to the edge part region <b>122</b>. In a case where the imaging instruction is provided in the crop recording mode, a crop recording image P<b>1</b> is generated from the image signal D<b>1</b> of the captured image signal D<b>2</b> and is recorded on the recording medium <b>19</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in the crop recording mode, a range that is not recorded on the recording medium <b>19</b> in the subject image formed in the light-receiving region <b>120</b> can also be checked on the display unit <b>15</b> as the image L<b>3</b>.</p><p id="p-0047" num="0046">In imaging the subject by the imaging element <b>12</b>, the system control unit <b>18</b> corrects a shake (image shake) of the captured image output from the imaging element <b>12</b> by controlling the imaging element shift mechanism <b>13</b> based on motion information of the digital camera <b>1</b> detected by the motion detection sensor <b>17</b>.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a schematic diagram for describing a movable range of the imaging element <b>12</b> in the normal recording mode. <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates the light-receiving region <b>120</b> seen in the direction of the optical axis K and an image circle <b>30</b>A of the imaging optical system <b>30</b>. The image circle <b>30</b>A illustrates an allowable range of image quality of the subject image formed in the light-receiving region <b>120</b> of the imaging element <b>12</b>. In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the image circle <b>30</b>A is a perfect circle centered at the optical axis K.</p><p id="p-0049" num="0048">In a state where the digital camera <b>1</b> stands still, the system control unit <b>18</b> matches a center of the light-receiving region <b>120</b> to the optical axis K as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> by controlling a position of the imaging element <b>12</b> through the imaging element shift mechanism <b>13</b>. In <figref idref="DRAWINGS">FIG. <b>5</b></figref>, an axis Jx and an axis Jy that are orthogonal to each other at the optical axis K as an origin are illustrated. The axis Jx is an axis that extends in a direction (row direction X) in which a long side of the light-receiving region <b>120</b> extends. The axis Jy is an axis that extends in a direction (column direction Y) in which a short side of the light-receiving region <b>120</b> extends. The imaging element <b>12</b> is moved in an extending direction of the axis Jx and an extending direction of the axis Jy by the imaging element shift mechanism <b>13</b>.</p><p id="p-0050" num="0049">In the normal recording mode, the system control unit <b>18</b> performs image shake correction by moving the imaging element <b>12</b> so that the light-receiving region <b>120</b> does not stay outside the image circle <b>30</b>A. Accordingly, image quality of the normal recording image can be set to an allowable level. That is, the system control unit <b>18</b> controls the movable range (movable range of the center of the light-receiving region <b>120</b>) of the imaging element <b>12</b> in the normal recording mode within a range of a circle C<b>1</b> of which a radius is a difference r<b>1</b> between a radius CR of the image circle <b>30</b>A and a diagonal length l<b>1</b> (length of a half of a diagonal line) of the light-receiving region <b>120</b>.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic diagram for describing the movable range of the imaging element <b>12</b> in the crop recording mode. In the crop recording mode, the system control unit <b>18</b> performs image shake correction by moving the imaging element <b>12</b> so that the crop region <b>121</b> of the light-receiving region <b>120</b> does not stay outside the image circle <b>30</b>A. Accordingly, image quality of the crop recording image can be set to an allowable level. That is, the system control unit <b>18</b> controls the movable range of the imaging element <b>12</b> in the crop recording mode within a range of a circle C<b>2</b> of which a radius is a difference r<b>2</b> between the radius CR of the image circle <b>30</b>A and a diagonal length l<b>2</b> (length of a half of a diagonal line) of the crop region <b>121</b>. The diagonal length l<b>2</b> of the crop region <b>121</b> is a value obtained by dividing the diagonal length l<b>1</b> of the light-receiving region <b>120</b> by the crop ratio &#x3b2;. That is, the circle C<b>2</b> having the radius of the difference r<b>2</b> is larger than the circle C<b>1</b> having the radius of the difference r<b>1</b>.</p><p id="p-0052" num="0051">The system control unit <b>18</b> performs a control of setting the movable range of the imaging element <b>12</b> in the normal recording mode based on sizes of the image circle <b>30</b>A and the light-receiving region <b>120</b> and setting the movable range of the imaging element <b>12</b> to be greater than in the normal recording mode based on the crop ratio &#x3b2; in the crop recording mode. The crop ratio &#x3b2; may be set to a plurality of values.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram illustrating a state where the imaging element <b>12</b> is moved to an end of the movable range in the crop recording mode. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, in a state where a center <b>120</b>A of the light-receiving region <b>120</b> is on a circumference of the circle C<b>2</b>, a part of the edge part region <b>122</b> of the imaging element <b>12</b> stays outside the image circle <b>30</b>A. Accordingly, there is a possibility that the image L<b>3</b> (refer to <figref idref="DRAWINGS">FIG. <b>5</b></figref>) that is a part corresponding to the edge part region <b>122</b> in the live view image LV displayed in the crop recording mode has an unallowable level of image quality. On the other hand, in the normal recording mode, the light-receiving region <b>120</b> does not stay outside the image circle <b>30</b>A. Thus, the image L<b>3</b> that is a part corresponding to the edge part region <b>122</b> in the live view image LV has an allowable level of image quality.</p><p id="p-0054" num="0053">In order to improve the image quality (visibility) of the image L<b>3</b> of the live view image LV in the crop recording mode, the system control unit <b>18</b> performs a control of setting an image processing parameter related to the visibility of the image L<b>3</b>, in other words, a parameter used for image processing performed on the image signal D<b>3</b> output from the edge part region <b>122</b> in the captured image signal D<b>2</b>, differently from the image processing parameter of the image L<b>3</b> in the normal recording mode. The visibility of the image is decided by brightness, sharpness, distortion, color, or the like.</p><p id="p-0055" num="0054">The image processing parameter includes a brightness gain by which a pixel signal of each pixel is multiplied in order to perform brightness shading correction, an outline highlight gain by which the pixel signal of each pixel is multiplied in order to perform outline highlighting, intensity of the noise correction of each pixel, intensity of the distortion correction of each pixel, correction intensity of the lateral chromatic aberration of each pixel, intensity of the fringe correction of each pixel, and the like.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic diagram illustrating an example of the brightness gain used for the brightness shading correction. Data G<b>1</b> illustrates the brightness gain used in generating the live view image in the normal recording mode. Data G<b>2</b> illustrates the brightness gain used in generating the live view image in the crop recording mode. An image height m<b>1</b> denotes a position of a pixel on an edge of the light-receiving region <b>120</b>. An image height m<b>2</b> denotes a position of a pixel on an edge of the crop region <b>121</b>.</p><p id="p-0057" num="0056">As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, in the crop recording mode, ranges of the image height m<b>1</b> and the image height m<b>2</b> in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, that is, a degree of each of a decrease in brightness, a decrease in sharpness, an increase in distortion, and an increase in color shift of the subject image formed in the edge part region <b>122</b> with respect to the subject image formed at the center of the light-receiving region <b>120</b>, may be greater than in the normal recording mode. Accordingly, as illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in the crop recording mode, the brightness gain by which each pixel of the image signal D<b>3</b> output from the edge part region <b>122</b> is multiplied is set to a greater value than in the normal recording mode. In addition, in the crop recording mode, the system control unit <b>18</b> sets the outline highlight gain by which each pixel of the image signal D<b>3</b> output from the edge part region <b>122</b> is multiplied to a greater value than in the normal recording mode. In addition, in the crop recording mode, the system control unit <b>18</b> sets the intensity of each of the noise correction, the distortion correction, the lateral chromatic aberration correction, and the fringe correction of the image signal D<b>3</b> output from the edge part region <b>122</b> to be higher than in the normal recording mode. Accordingly, occurrence of a change in the visibility of the image L<b>3</b> of the live view image LV between the normal recording mode and the crop recording mode can be prevented.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart for describing an operation of the digital camera <b>1</b>. In a case where the digital camera <b>1</b> is powered on, the system control unit <b>18</b> attempts to communicate with the lens control unit <b>40</b> of the lens device <b>20</b>. In a case where communication with the lens device <b>20</b> is not available (step S<b>1</b>: NO), the system control unit <b>18</b> performs setting of omitting the correction processing as image processing in generating the live view image (step S<b>2</b>).</p><p id="p-0059" num="0058">In a case where communication with the lens device <b>20</b> is available (step S<b>1</b>: YES), the system control unit <b>18</b> acquires lens information of the lens device <b>20</b> from the lens control unit <b>40</b> (step S<b>3</b>). The lens information is information necessary for determining the image circle <b>30</b>A of the imaging optical system <b>30</b>.</p><p id="p-0060" num="0059">After the lens information is acquired, the system control unit <b>18</b> determines whether the imaging mode is the normal recording mode or the crop recording mode (step S<b>4</b>). In a case where the imaging mode is the normal recording mode (step S<b>4</b>: NO), the system control unit <b>18</b> reads out the image processing parameter for the normal recording mode from the ROM of the memory <b>16</b> and sets the image processing parameter as a parameter used in generating the normal recording image and the live view image (step S<b>5</b>).</p><p id="p-0061" num="0060">In a case where the imaging mode is the crop recording mode (step S<b>4</b>: YES), the system control unit <b>18</b> reads out the image processing parameter for the crop recording mode from the ROM of the memory <b>16</b> and sets the image processing parameter as a parameter used in generating the crop recording image and the live view image (step S<b>6</b>).</p><p id="p-0062" num="0061">After processing in any of step S<b>2</b>, step S<b>5</b>, and step S<b>6</b>, the system control unit <b>18</b> sets the movable range of the imaging element <b>12</b> for performing image shake correction (step S<b>7</b>). After processing in step S<b>5</b>, the system control unit <b>18</b> sets a first movable range as the movable range of the imaging element <b>12</b>. After processing in step S<b>6</b>, the system control unit <b>18</b> sets a second movable range larger than the first movable range as the movable range of the imaging element <b>12</b>. After processing in step S<b>2</b>, for example, the system control unit <b>18</b> sets any value such as a maximum value or a minimum value that can be set as the movable range of the imaging element <b>12</b>.</p><p id="p-0063" num="0062">As described above, according to the digital camera <b>1</b>, in the crop recording mode, since the movable range of the imaging element <b>12</b> for image shake correction can be set to be larger than in the normal recording mode, a larger image shake can be corrected. In addition, since visibility of an edge part of the live view image displayed in the crop recording mode can be set to be the same as in the normal recording mode, the subject can be favorably checked.</p><p id="p-0064" num="0063">The movable range of the imaging element <b>12</b> in the normal recording mode can also be set to a circle larger than the circle C<b>1</b> as long as image quality of an edge part of the normal recording image in a case where an edge part of the light-receiving region <b>120</b> stays outside the image circle <b>30</b>A falls within an allowable range (the image quality can be set to fall within the allowable range by image processing). That is, the movable range of the imaging element <b>12</b> in the normal recording mode can be decided in accordance with an allowable degree of image quality of the normal recording image. By increasing the movable range of the imaging element <b>12</b>, stronger shake correction can be performed.</p><p id="p-0065" num="0064">(First Modification Example of Digital Camera <b>1</b>)</p><p id="p-0066" num="0065">As described so far, quality of the live view image LV is improved by preventing a decrease in edge part image quality of the live view image LV in the crop recording mode. Conversely, the quality of the live view image LV may be improved by causing a decrease in edge part image quality of the live view image LV to not stand out in the crop recording mode.</p><p id="p-0067" num="0066">That is, the system control unit <b>18</b> may perform a control of setting the visibility of the part corresponding to the edge part region <b>122</b> in the live view image LV generated in the crop recording mode to be lower than in the normal recording mode. Specifically, in the crop recording mode, the system control unit <b>18</b> controls the parameter of image processing performed on the image signal D<b>3</b> in the captured image signal D<b>2</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> to a state where the visibility is set to be lower than in the normal recording mode. That is, in the crop recording mode, the system control unit <b>18</b> sets at least one of brightness (brightness gain) or sharpness (outline highlight gain) of the image L<b>3</b> of the live view image LV to be lower than in the normal recording mode.</p><p id="p-0068" num="0067">More specifically, in the crop recording mode, the system control unit <b>18</b> may decrease the visibility of the image L<b>3</b> by generating the live view image LV using the same image processing parameter as in the normal recording mode and then, performing semi-transparent processing on the image L<b>3</b>. <figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram schematically illustrating the live view image after the semi-transparent processing. The live view image LV illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref> is configured with the image L<b>1</b> and an image L<b>3</b><i>a </i>after the semi-transparent processing on the image L<b>3</b>.</p><p id="p-0069" num="0068">The semi-transparent processing corresponds to processing of setting the brightness or the sharpness of the image L<b>3</b> to be lower than in the normal recording mode. The semi-transparent processing may be performed in the system control unit <b>18</b> but is preferably performed in a driver included in the display unit <b>15</b>. By performing the semi-transparent processing in the display unit <b>15</b>, a load of the system control unit <b>18</b> can be decreased.</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart for describing the operation of the digital camera <b>1</b> in a case of decreasing the edge part image quality of the live view image by performing the semi-transparent processing. In a case where the digital camera <b>1</b> is powered on, the system control unit <b>18</b> attempts to communicate with the lens control unit <b>40</b> of the lens device <b>20</b>. In a case where communication with the lens device <b>20</b> is not available (step S<b>11</b>: NO), the system control unit <b>18</b> performs setting of omitting the correction processing as image processing in generating the live view image (step S<b>12</b>).</p><p id="p-0071" num="0070">In a case where communication with the lens device <b>20</b> is available (step S<b>11</b>: YES), the system control unit <b>18</b> acquires the lens information of the lens device <b>20</b> from the lens control unit <b>40</b> (step S<b>13</b>).</p><p id="p-0072" num="0071">After the lens information is acquired, the system control unit <b>18</b> reads out the image processing parameter for the normal recording mode from the ROM of the memory <b>16</b> and sets the image processing parameter as a parameter used in generating each of the normal recording image, the crop recording image, and the live view image (step S<b>14</b>).</p><p id="p-0073" num="0072">Next, the system control unit <b>18</b> sets the movable range of the imaging element <b>12</b> in performing image shake correction in the normal recording mode and sets the movable range of the imaging element <b>12</b> in performing image shake correction in the crop recording mode based on the lens information and the crop ratio &#x3b2; (step S<b>15</b>).</p><p id="p-0074" num="0073">Next, in a case where the imaging mode is the normal recording mode (step S<b>16</b>: NO), the system control unit <b>18</b> generates the live view image by processing the captured image signal output from the light-receiving region <b>120</b> of the imaging element <b>12</b> using the image processing parameter set in step S<b>14</b> and displays the live view image on the display unit <b>15</b> (step S<b>17</b>).</p><p id="p-0075" num="0074">In a case where the imaging mode is the crop recording mode (step S<b>16</b>: YES), the system control unit <b>18</b> generates the live view image by processing the captured image signal output from the light-receiving region <b>120</b> of the imaging element <b>12</b> using the image processing parameter set in step S<b>14</b> (step S<b>18</b>). The system control unit <b>18</b> performs the semi-transparent processing on the image of the part corresponding to the edge part region <b>122</b> in the live view image and displays the live view image after the semi-transparent processing on the display unit <b>15</b> (step S<b>19</b>).</p><p id="p-0076" num="0075">According to the operation illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the image processing parameter can be used in common between the normal recording mode and the crop recording mode. Thus, reduction of a memory capacity, efficient image processing, and the like can be achieved.</p><p id="p-0077" num="0076">(Second Modification Example of Digital Camera <b>1</b>)</p><p id="p-0078" num="0077">In a case where communication with the lens device <b>20</b> is not available, the system control unit <b>18</b> may set the movable range of the imaging element <b>12</b> in image shake correction in accordance with a focal length set value set from a user regardless of whether the imaging mode is the normal recording mode or the crop recording mode. Specifically, the system control unit <b>18</b> increases the movable range as the focal length set value is increased. Accordingly, image shake correction performance suitable for an imaging condition is obtained.</p><p id="p-0079" num="0078">(Third Modification Example of Digital Camera <b>1</b>)</p><p id="p-0080" num="0079">Even in a case where the crop ratio &#x3b2; can be set to a plurality of values, it is preferable that the system control unit <b>18</b> fixes the crop ratio &#x3b2; to a predetermined value in a case where communication with the lens device <b>20</b> is not available. In addition, in a case where communication with the lens device <b>20</b> is not available, it is preferable that the system control unit <b>18</b> fixes the movable range of the imaging element <b>12</b> to a predetermined range regardless of whether the imaging mode is the normal recording mode or the crop recording mode. Accordingly, a decrease in captured image quality can be prevented.</p><p id="p-0081" num="0080">(Fourth Modification Example of Digital Camera <b>1</b>)</p><p id="p-0082" num="0081">Even in the crop recording mode, the system control unit <b>18</b> may control the movable range of the imaging element <b>12</b> to the same range as in the normal recording mode during a period (period in which imaging for generating the live view image is performed) in which the imaging instruction is not provided, and control the movable range of the imaging element <b>12</b> to a wide range for the crop recording mode in a case where the imaging instruction is provided to set a state for performing imaging for recording. By doing so, image quality can be guaranteed over the entire range of the live view image in the crop recording mode.</p><p id="p-0083" num="0082">In a case where imaging for recording is finished and returns to imaging for generating the live view image, it is preferable that the display of the live view image is resumed after moving the imaging element <b>12</b> so that the light-receiving region <b>120</b> falls within the movable range of the imaging element <b>12</b> in the normal recording mode. By doing so, it is possible that the motion of the imaging element <b>12</b> caused by rapidly changing the movable range is not recognized by the user.</p><p id="p-0084" num="0083">(Fifth Modification Example of Digital Camera <b>1</b>)</p><p id="p-0085" num="0084">As described so far, the camera body <b>10</b> of the digital camera <b>1</b> has an in-body vibration-proof function of performing image shake correction by moving the imaging element <b>12</b>. The digital camera <b>1</b> of a fifth modification example has an optical vibration-proof function of performing image shake correction by moving a vibration-proof lens included in the imaging optical system <b>30</b> of the lens device <b>20</b> instead of moving the imaging element <b>12</b>. In the digital camera <b>1</b> having the optical vibration-proof function instead of the in-body vibration-proof function, the movable range of the imaging element <b>12</b> described above is replaced with a movable range of the vibration-proof lens. That is, the system control unit <b>18</b> sets the movable range of the vibration-proof lens to, for example, the range of the circle C<b>1</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref> in the normal recording mode, and sets the movable range of the vibration-proof lens to, for example, the range of the circle C<b>2</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref> in the crop recording mode.</p><p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart for describing an operation of the digital camera of the fifth modification example. In a case where the digital camera <b>1</b> is powered on, the system control unit <b>18</b> communicates with the lens device <b>20</b> and determines whether or not the lens device <b>20</b> is equipped with the optical vibration-proof function (step S<b>21</b>). In a case where the lens device <b>20</b> is not equipped with the optical vibration-proof function (step S<b>21</b>: NO), the system control unit <b>18</b> disables an image shake correction function (step S<b>24</b>).</p><p id="p-0087" num="0086">In a case where the lens device <b>20</b> is equipped with the optical vibration-proof function (step S<b>21</b>: YES), the system control unit <b>18</b> determines whether or not the lens device <b>20</b> supports setting (change) of the movable range of the vibration-proof lens from an outside (step S<b>22</b>). In a case where the determination in step S<b>22</b> results in NO, the system control unit <b>18</b> disables the image shake correction function (step S<b>24</b>).</p><p id="p-0088" num="0087">In a case where the determination in step S<b>22</b> results in YES, the system control unit <b>18</b> sets the movable range of the vibration-proof lens in performing image shake correction in the normal recording mode and sets the movable range of the vibration-proof lens in performing image shake correction in the crop recording mode based on the lens information of the lens device <b>20</b> and the crop ratio &#x3b2; (step S<b>23</b>).</p><p id="p-0089" num="0088">Even in the digital camera having only the optical vibration-proof function, it is possible to improve the image shake correction performance and improve the quality of the live view image.</p><p id="p-0090" num="0089">(Sixth Modification Example of Digital Camera <b>1</b>)</p><p id="p-0091" num="0090">The digital camera <b>1</b> may have the optical vibration-proof function in addition to the in-body vibration-proof function. <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a schematic diagram illustrating a sixth modification example of the digital camera <b>1</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. A hardware configuration of a digital camera <b>1</b>A illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref> is the same as the digital camera <b>1</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref> except that the lens device <b>20</b> is changed to a lens device <b>20</b>A. In the digital camera <b>1</b>A, the lens device <b>20</b>A can also be interchanged with the lens device <b>20</b> not having the optical vibration-proof function.</p><p id="p-0092" num="0091">The lens device <b>20</b>A has the same configuration as the lens device <b>20</b> except that a vibration-proof lens <b>32</b> and a vibration-proof lens drive mechanism <b>33</b> that drives the vibration-proof lens <b>32</b> are added to the imaging optical system <b>30</b>.</p><p id="p-0093" num="0092">The vibration-proof lens <b>32</b> is a lens for correcting an image shake. The vibration-proof lens drive mechanism <b>33</b> moves the vibration-proof lens <b>32</b> in a direction orthogonal to the optical axis K of the imaging optical system <b>30</b> based on an instruction from the lens control unit <b>40</b>. The image shake is optically corrected by moving the vibration-proof lens <b>32</b> in the direction orthogonal to the optical axis K.</p><p id="p-0094" num="0093">In the digital camera <b>1</b>A, the image shake is corrected by moving the vibration-proof lens <b>32</b> by the lens control unit <b>40</b> and moving the imaging element <b>12</b> by the system control unit <b>18</b> based on the motion information of the digital camera <b>1</b>A detected by the motion detection sensor <b>17</b>.</p><p id="p-0095" num="0094">In a case of correcting the image shake using both of the optical vibration-proof function and the in-body vibration-proof function, the system control unit <b>18</b> corrects the image shake by offsetting a part of the motion of the digital camera <b>1</b>A by the vibration-proof lens <b>32</b> and offsetting the rest of the motion by the imaging element <b>12</b>.</p><p id="p-0096" num="0095">In the normal recording mode, for example, the system control unit <b>18</b> allocates the circle C<b>1</b> having the radius of the difference r<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref> at an equal ratio between the vibration-proof lens <b>32</b> and the imaging element <b>12</b>. The system control unit <b>18</b> sets the movable range of the imaging element <b>12</b> to a range of a circle having a radius of 0.5 times the difference r<b>1</b> and sets the movable range of the vibration-proof lens <b>32</b> to a range of a circle having a radius of 0.5 times the difference r<b>1</b>. This allocation ratio is decided based on a mechanical upper limit to which the vibration-proof lens <b>32</b> in the lens device mounted in the camera body <b>10</b> of the digital camera <b>1</b>A can be moved and a mechanical upper limit to which the imaging element <b>12</b> can be moved.</p><p id="p-0097" num="0096">In the crop recording mode, for example, the system control unit <b>18</b> allocates the circle C<b>2</b> having the radius of the difference r<b>2</b> illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> at a ratio between the vibration-proof lens <b>32</b> and the imaging element <b>12</b> based on the crop ratio &#x3b2;. Specifically, in a case of crop ratio &#x3b2;=1.2, &#x3b2;1 and &#x3b2;2 of an allocation ratio 131:132 between the vibration-proof lens <b>32</b> and the imaging element <b>12</b> are set such that &#x3b2;1&#xd7;&#x3b2;2=1.2 is satisfied. A range of a circle having a radius of {&#x3b2;1/(&#x3b2;1+&#x3b2;2)} times the difference r<b>2</b> is set as the movable range of the vibration-proof lens <b>32</b>. A range of a circle having a radius of {&#x3b2;2/(&#x3b2;1+&#x3b2;2)} times the difference r<b>2</b> is set as the movable range of the imaging element <b>12</b>. Based on the allocation ratio depending on the crop ratio &#x3b2;, the system control unit <b>18</b> sets at least one of the movable range of the vibration-proof lens <b>32</b> or the movable range of the imaging element <b>12</b> to be larger than in the normal recording mode so that the crop region <b>121</b> does not stay outside the image circle <b>30</b>A.</p><p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a flowchart for describing an operation of the digital camera of the sixth modification example in the crop recording mode. In a case where the digital camera <b>1</b>A is powered on, the system control unit <b>18</b> communicates with a mounted lens device and determines whether or not the lens device is equipped with the optical vibration-proof function (step S<b>31</b>). In a case where the lens device is not equipped with the optical vibration-proof function (step S<b>31</b>: NO), the system control unit <b>18</b> sets the movable range of the imaging element <b>12</b> based on the crop ratio &#x3b2; (step S<b>34</b>).</p><p id="p-0099" num="0098">In a case where the lens device is equipped with the optical vibration-proof function (step S<b>31</b>: YES), that is, in a case where the lens device <b>20</b>A is mounted, the system control unit <b>18</b> determines whether or not the lens device <b>20</b>A supports setting (change) of the movable range of the vibration-proof lens <b>32</b> from the outside (step S<b>32</b>). In a case where the determination in step S<b>32</b> results in NO, the system control unit <b>18</b> disables the optical vibration-proof function and processes step S<b>34</b>. For example, the determination in step S<b>32</b> results in NO in a case where firmware of the lens device <b>20</b>A is not updated.</p><p id="p-0100" num="0099">In a case where the determination in step S<b>32</b> results in YES, the system control unit <b>18</b> sets the movable range of each of the imaging element <b>12</b> and the vibration-proof lens <b>32</b> based on the lens information of the lens device <b>20</b>A and the crop ratio &#x3b2; (step S<b>33</b>).</p><p id="p-0101" num="0100">Even in the digital camera using the optical vibration-proof function and the in-body vibration-proof function together, it is possible to improve the image shake correction performance and improve the quality of the live view image.</p><p id="p-0102" num="0101">Next, a configuration of a smartphone will be described as the imaging apparatus according to the embodiment of the present invention.</p><p id="p-0103" num="0102"><figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates an exterior of a smartphone <b>200</b> that is one embodiment of the imaging apparatus according to the present invention.</p><p id="p-0104" num="0103">The smartphone <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref> includes a casing <b>201</b> having a flat plate shape and comprises a display and input unit <b>204</b> in which a display panel <b>202</b> as a display unit and an operation panel <b>203</b> as an input unit are integrated on one surface of the casing <b>201</b>.</p><p id="p-0105" num="0104">The casing <b>201</b> comprises a speaker <b>205</b>, a microphone <b>206</b>, an operation unit <b>207</b>, and a camera unit <b>208</b>. The configuration of the casing <b>201</b> is not limited thereto and can employ, for example, a configuration in which the display unit and the input unit are independently disposed, or a configuration that has a folded structure or a sliding mechanism.</p><p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a block diagram illustrating a configuration of the smartphone <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>.</p><p id="p-0107" num="0106">As illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, a wireless communication unit <b>210</b>, the display and input unit <b>204</b>, a call unit <b>211</b>, the operation unit <b>207</b>, the camera unit <b>208</b>, a recording unit <b>212</b>, an external input-output unit <b>213</b>, a global navigation satellite system (GNSS) (in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, referred to as a global positioning system (GPS) as an example) reception unit <b>214</b>, a motion sensor unit <b>215</b>, a power supply unit <b>216</b>, and a main control unit <b>220</b> are comprised as main constituents of the smartphone.</p><p id="p-0108" num="0107">In addition, a wireless communication function of performing mobile wireless communication with a base station apparatus BS, not illustrated, through a mobile communication network NW, not illustrated, is provided as a main function of the smartphone <b>200</b>.</p><p id="p-0109" num="0108">The wireless communication unit <b>210</b> performs wireless communication with the base station apparatus accommodated in the mobile communication network in accordance with an instruction from the main control unit <b>220</b>. By using the wireless communication, transmission and reception of various file data such as voice data and image data, electronic mail data, or the like and reception of web data, streaming data, or the like are performed.</p><p id="p-0110" num="0109">The display and input unit <b>204</b> is a so-called touch panel that visually delivers information to the user by displaying images (still images and motion images), text information, or the like and detects a user operation with respect to the displayed information under control of the main control unit <b>220</b>. The display and input unit <b>204</b> comprises the display panel <b>202</b> and the operation panel <b>203</b>.</p><p id="p-0111" num="0110">The display panel <b>202</b> uses a liquid crystal display (LCD), an organic electro-luminescence display (OELD), or the like as a display device.</p><p id="p-0112" num="0111">The operation panel <b>203</b> is a device that is placed such that an image displayed on the display surface of the display panel <b>202</b> can be visually recognized, is operated by a finger of the user or a stylus, and detects one or a plurality of coordinates. In a case where the device is operated by the finger of the user or the stylus, a detection signal generated by the operation is output to the main control unit <b>220</b>. Next, the main control unit <b>220</b> detects an operation position (coordinates) on the display panel <b>202</b> based on the received detection signal.</p><p id="p-0113" num="0112">As illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, the display panel <b>202</b> and the operation panel <b>203</b> of the smartphone <b>200</b> illustrated as the imaging apparatus according to one embodiment of the present invention are integrated and constitute the display and input unit <b>204</b>. The operation panel <b>203</b> is arranged to completely cover the display panel <b>202</b>.</p><p id="p-0114" num="0113">In a case where such arrangement is employed, the operation panel <b>203</b> may have a function of detecting the user operation even in a region outside the display panel <b>202</b>. In other words, the operation panel <b>203</b> may comprise a detection region (hereinafter, referred to as a display region) for an overlapping part overlapping with the display panel <b>202</b> and a detection region (hereinafter, referred to as a non-display region) for an outer edge portion other than the overlapping part that does not overlap with the display panel <b>202</b>.</p><p id="p-0115" num="0114">A size of the display region and a size of the display panel <b>202</b> may completely match, but both sizes do not need to match. In addition, the operation panel <b>203</b> may comprise two sensitive regions of the outer edge portion and an inner part other than the outer edge portion. Furthermore, a width of the outer edge portion is appropriately designed depending on a size and the like of the casing <b>201</b>.</p><p id="p-0116" num="0115">Furthermore, as a position detection type employed in the operation panel <b>203</b>, a matrix switch type, a resistive film type, a surface acoustic wave type, an infrared type, an electromagnetic induction type, a capacitance type, and the like are exemplified, and any of the types can be employed.</p><p id="p-0117" num="0116">The call unit <b>211</b> comprises the speaker <b>205</b> or the microphone <b>206</b> and converts voice of the user input through the microphone <b>206</b> into voice data processable in the main control unit <b>220</b> and outputs the voice data to the main control unit <b>220</b>, or decodes voice data received by the wireless communication unit <b>210</b> or the external input-output unit <b>213</b> and outputs the decoded voice data from the speaker <b>205</b>.</p><p id="p-0118" num="0117">In addition, as illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, for example, the speaker <b>205</b> can be mounted on the same surface as a surface on which the display and input unit <b>204</b> is disposed, and the microphone <b>206</b> can be mounted on a side surface of the casing <b>201</b>.</p><p id="p-0119" num="0118">The operation unit <b>207</b> is a hardware key that uses a key switch or the like, and receives an instruction from the user. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, the operation unit <b>207</b> is a push-button type switch that is mounted on a side surface of the casing <b>201</b> of the smartphone <b>200</b> and is set to an ON state in a case where the switch is pressed by the finger or the like, and set to an OFF state by restoring force of a spring or the like in a case where the finger is released.</p><p id="p-0120" num="0119">In the recording unit <b>212</b>, a control program and control data of the main control unit <b>220</b>, application software, address data in which a name, a telephone number, or the like of a communication counterpart is associated, transmitted and received electronic mail data, web data downloaded by web browsing, and downloaded contents data are recorded, and streaming data or the like is temporarily recorded. In addition, the recording unit <b>212</b> is configured with an internal recording unit <b>217</b> incorporated in the smartphone and an external recording unit <b>218</b> that includes a slot for an attachable and detachable external memory.</p><p id="p-0121" num="0120">Each of the internal recording unit <b>217</b> and the external recording unit <b>218</b> constituting the recording unit <b>212</b> is implemented using a storage medium such as a memory (for example, a MicroSD (registered trademark) memory) of a flash memory type, a hard disk type, a multimedia card micro type, or a card type, a random access memory (RAM), or a read only memory (ROM).</p><p id="p-0122" num="0121">The external input-output unit <b>213</b> is an interface with all external apparatuses connected to the smartphone <b>200</b> and is directly or indirectly connected to other external apparatuses by communication (for example, a universal serial bus (USB) or IEEE1394) or through a network (for example, the Internet, a wireless LAN, Bluetooth (registered trademark), radio frequency identification (RFID), infrared communication (Infrared Data Association (IrDA) (registered trademark)), Ultra Wideband (UWB) (registered trademark), or ZigBee (registered trademark)).</p><p id="p-0123" num="0122">For example, the external apparatuses connected to the smartphone <b>200</b> include a wired/wireless headset, a wired/wireless external charger, a wired/wireless data port, a memory card and a subscriber identity module (SIM)/user identity module (UIM) card connected through a card socket, an external audio and video apparatus connected through an audio and video input/output (I/O) terminal, a wirelessly connected external audio and video apparatus, a smartphone connected in a wired/wireless manner, a personal computer connected in a wired/wireless manner, and an earphone.</p><p id="p-0124" num="0123">The external input-output unit <b>213</b> can deliver data transferred from the external apparatuses to each constituent in the smartphone <b>200</b> or transfer data in the smartphone <b>200</b> to the external apparatuses.</p><p id="p-0125" num="0124">The GPS reception unit <b>214</b> receives GPS signals transmitted from GPS satellites ST<b>1</b> to STn, executes position measurement calculation processing based on the received plurality of GPS signals, and detects a position that includes a latitude, a longitude, and an altitude of the smartphone <b>200</b> in accordance with an instruction from the main control unit <b>220</b>. In a case where positional information can be acquired from the wireless communication unit <b>210</b> or the external input-output unit <b>213</b> (for example, a wireless LAN), the GPS reception unit <b>214</b> can detect the position using the positional information.</p><p id="p-0126" num="0125">The motion sensor unit <b>215</b> comprises, for example, a three-axis acceleration sensor and detects a physical motion of the smartphone <b>200</b> in accordance with an instruction from the main control unit <b>220</b>. By detecting the physical motion of the smartphone <b>200</b>, a movement direction or an acceleration of the smartphone <b>200</b> is detected. A detection result is output to the main control unit <b>220</b>.</p><p id="p-0127" num="0126">The power supply unit <b>216</b> supplies power stored in a battery (not illustrated) to each unit of the smartphone <b>200</b> in accordance with an instruction from the main control unit <b>220</b>.</p><p id="p-0128" num="0127">The main control unit <b>220</b> comprises a microprocessor, operates in accordance with the control program and the control data recorded in the recording unit <b>212</b>, and manages and controls each unit of the smartphone <b>200</b>. In addition, the main control unit <b>220</b> has a mobile communication control function of controlling each unit of a communication system and an application processing function for performing voice communication or data communication through the wireless communication unit <b>210</b>.</p><p id="p-0129" num="0128">The application processing function is implemented by operating the main control unit <b>220</b> in accordance with the application software recorded in the recording unit <b>212</b>. For example, the application processing function is an infrared communication function of performing data communication with counter equipment by controlling the external input-output unit <b>213</b>, an electronic mail function of transmitting and receiving electronic mails, or a web browsing function of browsing a web page.</p><p id="p-0130" num="0129">In addition, the main control unit <b>220</b> has an image processing function such as displaying an image on the display and input unit <b>204</b> based on image data (data of a still image or a motion image) such as reception data or downloaded streaming data.</p><p id="p-0131" num="0130">The image processing function refers to a function of causing the main control unit <b>220</b> to decode the image data, perform image processing on the decoding result, and display an image on the display and input unit <b>204</b>.</p><p id="p-0132" num="0131">Furthermore, the main control unit <b>220</b> executes a display control for the display panel <b>202</b> and an operation detection control for detecting the user operation through the operation unit <b>207</b> and the operation panel <b>203</b>.</p><p id="p-0133" num="0132">By executing the display control, the main control unit <b>220</b> displays an icon for starting the application software or a software key such as a scroll bar or displays a window for creating an electronic mail.</p><p id="p-0134" num="0133">The scroll bar refers to a software key for receiving an instruction to move a display part of a large image or the like that does not fit in the display region of the display panel <b>202</b>.</p><p id="p-0135" num="0134">In addition, by executing the operation detection control, the main control unit <b>220</b> detects the user operation through the operation unit <b>207</b>, receives an operation with respect to the icon and an input of a text string in an input field of the window through the operation panel <b>203</b>, or receives a request for scrolling the display image through the scroll bar.</p><p id="p-0136" num="0135">Furthermore, by executing the operation detection control, the main control unit <b>220</b> is provided with a touch panel control function of determining whether the operation position on the operation panel <b>203</b> is in the overlapping part (display region) overlapping with the display panel <b>202</b> or the other outer edge portion (non-display region) not overlapping with the display panel <b>202</b> and controlling the sensitive region of the operation panel <b>203</b> or a display position of the software key.</p><p id="p-0137" num="0136">In addition, the main control unit <b>220</b> can detect a gesture operation with respect to the operation panel <b>203</b> and execute a preset function depending on the detected gesture operation.</p><p id="p-0138" num="0137">The gesture operation is not a simple touch operation in the related art and means an operation of drawing a trajectory by the finger or the like, designating a plurality of positions at the same time, or drawing a trajectory for at least one of the plurality of positions as a combination thereof.</p><p id="p-0139" num="0138">The camera unit <b>208</b> includes the configurations other than the memory <b>16</b> and the system control unit <b>18</b> in the digital camera <b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In a case where the smartphone <b>200</b> functions as the digital camera <b>1</b>, the recording unit <b>212</b> and the recording medium <b>19</b> function as the memory <b>16</b>, and the main control unit <b>220</b> functions as the system control unit <b>18</b>.</p><p id="p-0140" num="0139">Captured image data generated by the camera unit <b>208</b> can be recorded in the recording unit <b>212</b> or be output through the external input-output unit <b>213</b> or the wireless communication unit <b>210</b>.</p><p id="p-0141" num="0140">In the smartphone <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the camera unit <b>208</b> is mounted on the same surface as the display and input unit <b>204</b>. However, a mount position of the camera unit <b>208</b> is not limited thereto. The camera unit <b>208</b> may be mounted on a rear surface of the display and input unit <b>204</b>.</p><p id="p-0142" num="0141">In addition, the camera unit <b>208</b> can be used in various functions of the smartphone <b>200</b>. For example, an image acquired by the camera unit <b>208</b> can be displayed on the display panel <b>202</b>, or the image of the camera unit <b>208</b> can be used as one of operation inputs of the operation panel <b>203</b>.</p><p id="p-0143" num="0142">In addition, in a case where the GPS reception unit <b>214</b> detects the position, the position can be detected by referring to the image from the camera unit <b>208</b>. Furthermore, by referring to the image from the camera unit <b>208</b>, an optical axis direction of the camera unit <b>208</b> of the smartphone <b>200</b> can be determined, or the current usage environment can be determined without using the three-axis acceleration sensor or by using the three-axis acceleration sensor together. The image from the camera unit <b>208</b> can also be used in the application software.</p><p id="p-0144" num="0143">Besides, image data of a still image or a motion image to which the positional information acquired by the GPS reception unit <b>214</b>, voice information (may be text information acquired by performing voice to text conversion by the main control unit or the like) acquired by the microphone <b>206</b>, attitude information acquired by the motion sensor unit <b>215</b>, or the like is added can be recorded in the recording unit <b>212</b> or be output through the external input-output unit <b>213</b> or the wireless communication unit <b>210</b>.</p><p id="p-0145" num="0144">At least the following matters are disclosed in the present specification.</p><p id="p-0146" num="0145">(1) A processor of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the processor being configured to perform a recording control of performing any of first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region, perform an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system, perform image processing of generating a live view image for displaying a subject image formed in the second region on a display unit, and perform a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element or the lens in the image shake correction control to be larger than in a case of performing the second processing.</p><p id="p-0147" num="0146">(2) The processor of an imaging apparatus according to (1), in which the processor is configured to change an image processing parameter of a part corresponding to a third region that is a region excluding the first region in the second region of the live view image, between a case of performing the first processing and a case of performing the second processing.</p><p id="p-0148" num="0147">(3) The processor of an imaging apparatus according to (2), in which the image processing parameter is a parameter related to visibility of an image.</p><p id="p-0149" num="0148">(4) The processor of an imaging apparatus according to (3), in which the parameter is a parameter for deciding brightness or sharpness.</p><p id="p-0150" num="0149">(5) The processor of an imaging apparatus according to (4), in which the processor is configured to, in a case of performing the first processing, set the part to be brighter or set sharpness of the part to be higher than in a case of performing the second processing.</p><p id="p-0151" num="0150">(6) The processor of an imaging apparatus according to (4), in which the processor is configured to, in a case of performing the first processing, set the part to be darker or set sharpness of the part to be lower than in a case of performing the second processing.</p><p id="p-0152" num="0151">(7) The processor of an imaging apparatus according to any one of (1) to (6), in which the processor is configured to decide the movable range in a case of performing the first processing based on a ratio of sizes of the first region and the second region.</p><p id="p-0153" num="0152">(8) The processor of an imaging apparatus according to (7), in which the processor is configured to, in a case of correcting the image shake by moving both of the imaging element and the lens, decide the movable range of the imaging element based on a first allocation ratio allocated to the imaging element in the ratio and decide the movable range of the lens based on a second allocation ratio allocated to the lens in the ratio.</p><p id="p-0154" num="0153">(9) An imaging apparatus comprising the processor according to any one of (1) to (8), and the imaging element.</p><p id="p-0155" num="0154">(10) A control method of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the method comprising performing a recording control of performing any of first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region, performing an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system, performing image processing of generating a live view image for displaying a subject image formed in the second region on a display unit, and performing a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element or the lens in the image shake correction control to be larger than in a case of performing the second processing.</p><p id="p-0156" num="0155">(11) The control method of an imaging apparatus according to (10), in which an image processing parameter of a part corresponding to a third region that is a region excluding the first region in the second region of the live view image is changed between a case of performing the first processing and a case of performing the second processing.</p><p id="p-0157" num="0156">(12) The control method of an imaging apparatus according to (11), in which the image processing parameter is a parameter related to visibility of an image.</p><p id="p-0158" num="0157">(13) The control method of an imaging apparatus according to (12), in which the visibility includes brightness or sharpness.</p><p id="p-0159" num="0158">(14) The control method of an imaging apparatus according to (13), in which in a case of performing the first processing, the part is set to be brighter or sharpness of the part is set to be higher than in a case of performing the second processing.</p><p id="p-0160" num="0159">(15) The control method of an imaging apparatus according to (13), in which in a case of performing the first processing, the part is set to be darker or sharpness of the part is set to be lower than in a case of performing the second processing.</p><p id="p-0161" num="0160">(16) The control method of an imaging apparatus according to any one of (10) to (15), in which the movable range in a case of performing the first processing is decided based on a ratio of sizes of the first region and the second region.</p><p id="p-0162" num="0161">(17) The control method of an imaging apparatus according to (16), in which in a case of correcting the image shake by moving both of the imaging element and the lens, the movable range of the imaging element is decided based on a first allocation ratio allocated to the imaging element in the ratio, and the movable range of the lens is decided based on a second allocation ratio allocated to the lens in the ratio.</p><p id="p-0163" num="0162">(18) A control program of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the control program causing a processor to execute a recording control of performing any of first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region, an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system, image processing of generating a live view image for displaying a captured image output from the second region on a display unit, and a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element or the lens in the image shake correction control to be larger than in a case of performing the second processing.</p><p id="p-0164" num="0163">While various embodiments are described above with reference to the drawings, the present invention is not limited to such examples. It is apparent that those skilled in the art may perceive various modification examples or correction examples within the scope disclosed in the claims, and those examples are also understood as falling within the technical scope of the present invention. In addition, any combination of each constituent in the embodiment may be used without departing from the gist of the invention.</p><p id="p-0165" num="0164">The present application is based on Japanese Patent Application (JP2020-079514) filed on Apr. 28, 2020, the content of which is incorporated in the present application by reference.</p><heading id="h-0008" level="1">EXPLANATION OF REFERENCES</heading><p id="p-0166" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0165"><b>1</b>A, <b>1</b>: digital camera</li>        <li id="ul0002-0002" num="0166">D<b>1</b>, D<b>3</b>: image signal</li>        <li id="ul0002-0003" num="0167">L<b>1</b>, L<b>3</b><i>a</i>, L<b>3</b>: image</li>        <li id="ul0002-0004" num="0168">P<b>1</b>: crop recording image</li>        <li id="ul0002-0005" num="0169">l<b>1</b>, l<b>2</b>: diagonal length</li>        <li id="ul0002-0006" num="0170">r<b>1</b>, r<b>2</b>: difference</li>        <li id="ul0002-0007" num="0171">C<b>1</b>, C<b>2</b>: circle</li>        <li id="ul0002-0008" num="0172">G<b>1</b>, G<b>2</b>: data</li>        <li id="ul0002-0009" num="0173">D<b>2</b>: captured image signal</li>        <li id="ul0002-0010" num="0174">P<b>2</b>: normal recording image</li>        <li id="ul0002-0011" num="0175"><b>10</b>: camera body</li>        <li id="ul0002-0012" num="0176"><b>12</b>: imaging element</li>        <li id="ul0002-0013" num="0177"><b>13</b>: imaging element shift mechanism</li>        <li id="ul0002-0014" num="0178"><b>14</b>: imaging element drive unit</li>        <li id="ul0002-0015" num="0179"><b>15</b>: display unit</li>        <li id="ul0002-0016" num="0180"><b>16</b>: memory</li>        <li id="ul0002-0017" num="0181"><b>17</b>: motion detection sensor</li>        <li id="ul0002-0018" num="0182"><b>18</b>: system control unit</li>        <li id="ul0002-0019" num="0183"><b>19</b>: recording medium</li>        <li id="ul0002-0020" num="0184"><b>20</b>A, <b>20</b>: lens device</li>        <li id="ul0002-0021" num="0185"><b>30</b>A: image circle</li>        <li id="ul0002-0022" num="0186"><b>30</b>: imaging optical system</li>        <li id="ul0002-0023" num="0187"><b>31</b>: imaging lens</li>        <li id="ul0002-0024" num="0188"><b>32</b>: vibration-proof lens</li>        <li id="ul0002-0025" num="0189"><b>33</b>: vibration-proof lens drive mechanism</li>        <li id="ul0002-0026" num="0190"><b>40</b>: lens control unit</li>        <li id="ul0002-0027" num="0191"><b>120</b>A: center</li>        <li id="ul0002-0028" num="0192"><b>120</b>: light-receiving region</li>        <li id="ul0002-0029" num="0193"><b>121</b>: crop region</li>        <li id="ul0002-0030" num="0194"><b>122</b>: edge part region</li>        <li id="ul0002-0031" num="0195"><b>150</b>: display surface</li>        <li id="ul0002-0032" num="0196"><b>200</b>: smartphone</li>        <li id="ul0002-0033" num="0197"><b>201</b>: casing</li>        <li id="ul0002-0034" num="0198"><b>202</b>: display panel</li>        <li id="ul0002-0035" num="0199"><b>203</b>: operation panel</li>        <li id="ul0002-0036" num="0200"><b>204</b>: display and input unit</li>        <li id="ul0002-0037" num="0201"><b>205</b>: speaker</li>        <li id="ul0002-0038" num="0202"><b>206</b>: microphone</li>        <li id="ul0002-0039" num="0203"><b>207</b>: operation unit</li>        <li id="ul0002-0040" num="0204"><b>208</b>: camera unit</li>        <li id="ul0002-0041" num="0205"><b>210</b>: wireless communication unit</li>        <li id="ul0002-0042" num="0206"><b>211</b>: call unit</li>        <li id="ul0002-0043" num="0207"><b>212</b>: recording unit</li>        <li id="ul0002-0044" num="0208"><b>213</b>: external input-output unit</li>        <li id="ul0002-0045" num="0209"><b>214</b>: GPS reception unit</li>        <li id="ul0002-0046" num="0210"><b>215</b>: motion sensor unit</li>        <li id="ul0002-0047" num="0211"><b>216</b>: power supply unit</li>        <li id="ul0002-0048" num="0212"><b>217</b>: internal recording unit</li>        <li id="ul0002-0049" num="0213"><b>218</b>: external recording unit</li>        <li id="ul0002-0050" num="0214"><b>220</b>: main control unit</li>    </ul>    </li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A processor of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the processor being configured to:<claim-text>perform a recording control of performing one of: first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element; and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region;</claim-text><claim-text>perform an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system;</claim-text><claim-text>perform image processing of generating a live view image for displaying a subject image formed in the second region on a display unit; and</claim-text><claim-text>perform a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element and the lens in the image shake correction control to be larger than in a case of performing the second processing.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The processor of an imaging apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the processor is configured to change an image processing parameter of a part corresponding to a third region that is a region excluding the first region in the second region of the live view image, between a case of performing the first processing and a case of performing the second processing.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The processor of an imaging apparatus according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,<claim-text>wherein the image processing parameter is a parameter related to visibility of an image.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The processor of an imaging apparatus according to <claim-ref idref="CLM-00003">claim 3</claim-ref>,<claim-text>wherein the parameter is a parameter for deciding brightness or sharpness.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The processor of an imaging apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>,<claim-text>wherein the processor is configured to, in a case of performing the first processing, set the part to be brighter or set sharpness of the part to be higher than in a case of performing the second processing.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The processor of an imaging apparatus according to <claim-ref idref="CLM-00004">claim 4</claim-ref>,<claim-text>wherein the processor is configured to, in a case of performing the first processing, set the part to be darker or set sharpness of the part to be lower than in a case of performing the second processing.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The processor of an imaging apparatus according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the processor is configured to decide the movable range in a case of performing the first processing based on a ratio of sizes of the first region and the second region.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The processor of an imaging apparatus according to <claim-ref idref="CLM-00007">claim 7</claim-ref>,<claim-text>wherein the processor is configured to, in a case of correcting the image shake by moving both of the imaging element and the lens, decide the movable range of the imaging element based on a first allocation ratio allocated to the imaging element in the ratio and decide the movable range of the lens based on a second allocation ratio allocated to the lens in the ratio.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. An imaging apparatus comprising:<claim-text>the processor according to <claim-ref idref="CLM-00001">claim 1</claim-ref>; and</claim-text><claim-text>the imaging element.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A control method of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the method comprising:<claim-text>performing a recording control of performing any of first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region;</claim-text><claim-text>performing an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system;</claim-text><claim-text>performing image processing of generating a live view image for displaying a subject image formed in the second region on a display unit; and</claim-text><claim-text>performing a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element and the lens in the image shake correction control to be larger than in a case of performing the second processing.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The control method of an imaging apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>,<claim-text>wherein an image processing parameter of a part corresponding to a third region that is a region excluding the first region in the second region of the live view image is changed between a case of performing the first processing and a case of performing the second processing.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The control method of an imaging apparatus according to <claim-ref idref="CLM-00011">claim 11</claim-ref>,<claim-text>wherein the image processing parameter is a parameter related to visibility of an image.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The control method of an imaging apparatus according to <claim-ref idref="CLM-00012">claim 12</claim-ref>,<claim-text>wherein the visibility includes brightness or sharpness.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The control method of an imaging apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>,<claim-text>wherein in a case of performing the first processing, the part is set to be brighter or sharpness of the part is set to be higher than in a case of performing the second processing.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The control method of an imaging apparatus according to <claim-ref idref="CLM-00013">claim 13</claim-ref>,<claim-text>wherein in a case of performing the first processing, the part is set to be darker or sharpness of the part is set to be lower than in a case of performing the second processing.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The control method of an imaging apparatus according to <claim-ref idref="CLM-00010">claim 10</claim-ref>,<claim-text>wherein the movable range in a case of performing the first processing is decided based on a ratio of sizes of the first region and the second region.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The control method of an imaging apparatus according to <claim-ref idref="CLM-00016">claim 16</claim-ref>,<claim-text>wherein in a case of correcting the image shake by moving both of the imaging element and the lens, the movable range of the imaging element is decided based on a first allocation ratio allocated to the imaging element in the ratio, and the movable range of the lens is decided based on a second allocation ratio allocated to the lens in the ratio.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. A non-transitory computer readable medium storing a control program of an imaging apparatus including an imaging element that images a subject through an imaging optical system, the control program causing a processor to execute:<claim-text>a recording control of performing any of first processing of recording a first captured image output from a first region of a light-receiving region of the imaging element and second processing of recording a second captured image output from a second region, which is larger than the first region, of the light-receiving region;</claim-text><claim-text>an image shake correction control of correcting an image shake of a captured image output from the imaging element by moving one or both of the imaging element and a lens included in the imaging optical system;</claim-text><claim-text>image processing of generating a live view image for displaying a captured image output from the second region on a display unit; and</claim-text><claim-text>a control of setting, in a case of performing the first processing, a movable range of at least one of the imaging element and the lens in the image shake correction control to be larger than in a case of performing the second processing.</claim-text></claim-text></claim></claims></us-patent-application>
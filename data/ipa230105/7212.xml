<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007213A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007213</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17940079</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>91</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>774</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>765</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>91</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>774</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>765</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>2201</main-group><subgroup>034</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30004</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10068</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">IMAGE RECORDING SYSTEM, IMAGE RECORDING METHOD, AND RECORDING MEDIUM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2020/009910</doc-number><date>20200309</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17940079</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>OLYMPUS CORPORATION</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TANAKA</last-name><first-name>Hiroshi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KANDA</last-name><first-name>Yamato</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>KITAMURA</last-name><first-name>Makoto</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>KUBOTA</last-name><first-name>Akihiro</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>TSURUOKA</last-name><first-name>Takao</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>OLYMPUS CORPORATION</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An image recording system includes a processor. The processor acquires a time series RAW image group including a plurality of time series RAW images in a first time section. The processor extracts, from the time series RAW image group, a recording candidate RAW image group included in a second time section as a part of the first time section. The processor records at least one RAW image included in the recording candidate RAW image group as a recording target RAW image which is a RAW image to be recorded. The processor selects the recording target RAW image from the recording candidate RAW image group. The processor converts the RAW image which is not selected as the recording target RAW image from the recording candidate RAW image group or the time series RAW image group to compressed data, and records the compressed data.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="96.94mm" wi="158.75mm" file="US20230007213A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="188.98mm" wi="142.83mm" file="US20230007213A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="236.05mm" wi="148.08mm" orientation="landscape" file="US20230007213A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="200.32mm" wi="108.12mm" orientation="landscape" file="US20230007213A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="203.20mm" wi="78.74mm" file="US20230007213A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="231.65mm" wi="155.53mm" orientation="landscape" file="US20230007213A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="203.20mm" wi="78.40mm" file="US20230007213A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="203.03mm" wi="125.56mm" orientation="landscape" file="US20230007213A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="233.17mm" wi="157.82mm" orientation="landscape" file="US20230007213A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="236.81mm" wi="158.07mm" orientation="landscape" file="US20230007213A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application is a continuation of International Patent Application No. PCT/JP2020/009910, having an international filing date of Mar. 9, 2020, which designated the United States, the entirety of which is incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Known is a technique of detecting a lesion from a medical image by image recognition with machine learning. PCT international publication No. WO2018/008593 discloses a technique of generating a neural network for identification of an abnormal region in an endoscopic image by machine learning using an image for learning in which a diagnosis subject is photographed and information indicating abnormality of the diagnosis subject and given to the image for learning in advance.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0004" num="0003">In accordance with one of some aspect, there is provided an image recording system comprising a processor, the processor being configured to implement:</p><p id="p-0005" num="0004">acquiring a time series RAW image group including a plurality of time series RAW images in a first time section;</p><p id="p-0006" num="0005">extracting, from the time series RAW image group, a recording candidate RAW image group included in a second time section as a part of the first time section;</p><p id="p-0007" num="0006">recording at least one RAW image included in the recording candidate RAW image group as a recording target RAW image which is a RAW image to be recorded, whereby selecting the recording target RAW image from the recording candidate RAW image group; and</p><p id="p-0008" num="0007">converting the RAW image which is not selected as the recording target RAW image from the recording candidate RAW image group or the time series RAW image group to compressed data, and recording the compressed data.</p><p id="p-0009" num="0008">In accordance with one of some aspect, there is provided an image recording method comprising:</p><p id="p-0010" num="0009">acquiring a time series RAW image group including a plurality of time series RAW images in a first time section;</p><p id="p-0011" num="0010">extracting, from the time series RAW image group, a recording candidate RAW image group included in a second time section as a part of the first time section;</p><p id="p-0012" num="0011">selecting, from the recording candidate RAW image group, a recording target RAW image to be recorded;</p><p id="p-0013" num="0012">recording at least one RAW image included in the recording candidate RAW image group as the recording target RAW image; and</p><p id="p-0014" num="0013">converting the RAW image which is not selected as the recording target RAW image from the recording candidate RAW image group or the time series RAW image group to compressed data, and recording the compressed data.</p><p id="p-0015" num="0014">In accordance with one of some aspect, there is provided a non-transitory computer-readable storage medium storing a program for causing a computer to execute:</p><p id="p-0016" num="0015">acquiring a time series RAW image group including a plurality of time series RAW images in a first time section;</p><p id="p-0017" num="0016">extracting, from the time series RAW image group, a recording candidate RAW image group included in a second time section as a part of the first time section;</p><p id="p-0018" num="0017">selecting, from the recording candidate RAW image group, a recording target RAW image to be recorded;</p><p id="p-0019" num="0018">recording at least one RAW image included in the recording candidate RAW image group as the recording target RAW image; and</p><p id="p-0020" num="0019">converting the RAW image which is not selected as the recording target RAW image from the recording candidate RAW image group or the time series RAW image group to compressed data, and recording the compressed data.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example configuration of an image capturing system.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a first example configuration of an image recording system.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating processing performed by a processing section in the first example configuration.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating processing performed by the processing section in the first example configuration.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating processing performed by the processing section in the first example configuration.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating processing performed by a processing section in a second example configuration.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a third example configuration of the image recording system.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a fourth example configuration of the image recording system.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram illustrating processing performed by a processing section in the fourth example configuration.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DESCRIPTION OF EXEMPLARY EMBODIMENTS</heading><p id="p-0030" num="0029">The following disclosure provides many different embodiments, or examples, for implementing different features of the provided subject matter. These are, of course, merely examples and are not intended to be limiting. In addition, the disclosure may repeat reference numerals and/or letters in the various examples. This repetition is for the purpose of simplicity and clarity and does not in itself dictate a relationship between the various embodiments and/or configurations discussed. Further, when a first element is described as being &#x201c;connected&#x201d; or &#x201c;coupled&#x201d; to a second element, such description includes embodiments in which the first and second elements are directly connected or coupled to each other, and also includes embodiments in which the first and second elements are indirectly connected or coupled to each other with one or more other intervening elements in between.</p><heading id="h-0006" level="1">1. Image Capturing System</heading><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example configuration of an image capturing system <b>10</b> which photographs and records a medical image. The image capturing system <b>10</b> includes an endoscope system <b>5</b> and an image recording system <b>1</b>.</p><p id="p-0032" num="0031">The endoscope system <b>5</b> is a system that photographs a medical image. The medical image is an inside body image photographed by a medical endoscope. The medical endoscope is a videoscope such as a digestive tract endoscope or the like, or a rigid scope for surgical procedures or the like. <figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a videoscope as an example. The endoscope system <b>5</b> includes a scope <b>2</b>, a control device <b>3</b>, and a monitor <b>4</b>.</p><p id="p-0033" num="0032">The scope <b>2</b> photographs an inside of a subject body by inserting an elongated insertion section <b>201</b> to a body cavity of the subject, and outputs an image signal of the medical image that is an inside body image thereof. The scope <b>2</b> includes the insertion section <b>201</b>, a grip section <b>204</b> disposed on a base end side of the insertion section <b>201</b>, and a universal code <b>203</b> extending from the grip section <b>204</b>. A connector is provided on a base end side of the universal code <b>203</b> and connected to the control device <b>3</b>. An imaging module <b>202</b> is provided in a distal end section of the insertion section <b>201</b> and outputs an image signal of a RAW image as the image signal of the medical image. The imaging module <b>202</b> photographs a plurality of time series medical images by moving image photography or the like. In a case of moving image photography, each frame image of the moving image corresponds to each medical image.</p><p id="p-0034" num="0033">The control device <b>3</b> controls the entire endoscope system <b>5</b>, as well as performing signal processing on an image signal output from the imaging module <b>202</b>, and outputs a processing result. Specifically, the control device <b>3</b> develops the RAW image to generate a color image, and displays the color image on the monitor <b>4</b>. Further, the control device <b>3</b> outputs a plurality of RAW images photographed in time series to the image recording system <b>1</b>. The image recording system <b>1</b> records some of a plurality of RAW images transmitted from the endoscope system <b>5</b> as an image for learning. Details of the image recording system <b>1</b> is described later. Note that while in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the image recording system <b>1</b> is an external system of the control device <b>3</b>, the image recording system <b>1</b> may be integrated with the control device <b>3</b>.</p><p id="p-0035" num="0034">The RAW image is an image before being developed to be a color image, having a pixel value corresponding to each pixel of an image sensor recorded as it is. For example, if the image sensor is a primary color Bayer-type sensor, R, G, and B pixels are arranged in the image sensor and the RAW image has one pixel value per pixel recorded as it is regardless of a pixel color thereof. The color image is an image obtained by interpolation and compression of the RAW image according to a Bayer-type layout, and has RGB pixel values per pixel. Since the RAW image is unprocessed and uncompressed data, data amount per image is larger than the color image.</p><p id="p-0036" num="0035">Image processing has been applied to the medical image according to a default setting or a user setting of a medical equipment. Therefore, a trained model obtained by machine learning is affected by the setting contents of the medical equipment at the time of generating the medical image to be used as the image for learning. Thus, considered is a method of acquiring the RAW image as the image for learning, which is an unprocessed original signal from the image sensor. However, when using the RAW image as the image for learning, there is a problem that the data amount of the accumulated RAW images becomes extremely large.</p><p id="p-0037" num="0036">More specifically, image processing suitable for endoscopic observation has been applied to the color image. Since this image processing is not necessarily suitable for machine learning, when using the color image as the image for learning, machine learning will be affected by the image processing already applied to the color image. On the other hand, the RAW image is an undeveloped image and thus characterized by high flexibility for image processing. Therefore, by accumulating the RAW images as the image for learning, it is possible to use the RAW images in machine learning after processing them to the ones suitable for machine learning. This is expected to improve the accuracy of image recognition. For the above reasons, there is a strong need to acquire the RAW images as learning data for image recognition with machine learning, but there is a problem that the data amount of the RAW images is extremely large.</p><heading id="h-0007" level="1">2. First Example Configuration of Image Recording System</heading><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a first example configuration of the image recording system <b>1</b>. While <figref idref="DRAWINGS">FIG. <b>2</b></figref> also illustrates a training data generation system <b>400</b> and a learning device <b>500</b>, the training data generation system <b>400</b> and the learning device <b>500</b> are not necessarily connected to the image recording system <b>1</b> when the image recording system <b>1</b> records an image.</p><p id="p-0039" num="0038">The image recording system <b>1</b> includes an acquisition section <b>110</b>, a recording candidate RAW image group extraction section <b>120</b>, and a RAW image recording section <b>130</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the acquisition section <b>110</b> acquires a time series RAW image group GIM<b>1</b> including a plurality of time series RAW images in a first time section TP<b>1</b>. The recording candidate RAW image group extraction section <b>120</b> extracts, from the time series RAW image group GIM<b>1</b>, a recording candidate RAW image group GIM<b>2</b> included in a second time section TP<b>2</b> as a part of the first time section TP<b>1</b>. The RAW image recording section <b>130</b> records at least one RAW image included in the recording candidate RAW image group GIM<b>2</b> as a recording target RAW image which is a RAW image to be recorded.</p><p id="p-0040" num="0039">As a result, in some embodiments, only a part of the RAW images in the time series RAW image group GIM<b>1</b> acquired by the acquisition section <b>110</b> are recorded, and thus it is possible to reduce the recording data amount compared to a case of recording the entire time series RAW image group GIM<b>1</b>. Thereby, it is possible to achieve both reduction of the recording data amount of the image for learning and acquisition of the RAW image as the image for learning. Furthermore, as a result, in some embodiments, the recording candidate RAW image group GIM<b>2</b> included in the second time section TP<b>2</b> is extracted. Thereby, a plurality of RAW images in a certain time span becomes a recording candidate such that the RAW image suitable for machine learning can be recorded, compared to a method of recording only one RAW image at a prescribed timing.</p><p id="p-0041" num="0040">A detailed description of the first example configuration will be given below. The image recording system <b>1</b> includes a processing section <b>100</b> and a storage section <b>200</b>. The processing section <b>100</b> includes the acquisition section <b>110</b>, the recording candidate RAW image group extraction section <b>120</b>, the RAW image recording section <b>130</b>, and a RAW image recording importance determination section <b>140</b>.</p><p id="p-0042" num="0041">The image recording system <b>1</b> is, for example, an information processing device such as a personal computer (PC). Alternatively, the image recording system <b>1</b> may be a system in which a terminal device and an information processing device are connected through network. For example, the terminal device may include the storage section <b>200</b> and the information processing device may include the processing section <b>100</b>. Alternatively, the image recording system <b>1</b> may be a cloud system in which a plurality of information processing devices is connected through network.</p><p id="p-0043" num="0042">The storage section <b>200</b> stores the time series RAW image group GIM<b>1</b> acquired by the acquisition section <b>110</b>. The storage section <b>200</b> is a storage device such as a semiconductor memory or a hard disk drive. The semiconductor memory is, for example, a volatile memory such as RAM or a non-volatile memory such as EEPROM.</p><p id="p-0044" num="0043">The processing section <b>100</b> is a processor. The processor may be an integrated circuit device such as a CPU, a microcomputer, a DSP, an application specific integrated circuit (ASIC), or a field programmable gate array (FPGA). The processing section <b>100</b> may include one or more processors. Further, the processing section <b>100</b> that is a processor may be, for example, a processing circuit or a processing device including one or more circuit components, or may be a circuit device with one or more circuit components mounted on a board.</p><p id="p-0045" num="0044">Operation of the processing section <b>100</b> may be realized by software processing. That is, a program is stored in the storage section <b>200</b>, the program describing all or part of the operation of the acquisition section <b>110</b>, the recording candidate RAW image group extraction section <b>120</b>, the RAW image recording section <b>130</b>, and the RAW image recording importance determination section <b>140</b> which are included in the processing section <b>100</b>. The processor executes the program stored in the storage section <b>200</b> to realize the operation of the processing section <b>100</b>. The program may be stored in a computer readable information storage medium. The information storage medium can be implemented by, for example, an optical disk, a memory card, an HDD, or a semiconductor memory. The computer is a device equipped with an input device, a processing section, a storage section, and an output section.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating processing performed by the processing section <b>100</b> in the first example configuration. In a step S<b>1</b>, the acquisition section <b>110</b> acquires the RAW images. Specifically, the acquisition section <b>110</b> is a data interface of the processing section <b>100</b> and receives the time series RAW image group GIM<b>1</b> transferred from the endoscope system <b>5</b> and temporarily stores the time series RAW image group GIM<b>1</b> in the storage section <b>200</b>. Alternatively, the time series RAW image group GIM<b>1</b> transferred from the endoscope system <b>5</b> may be temporarily stored in the storage section <b>200</b> and read out from the storage section <b>200</b> by the acquisition section <b>110</b>.</p><p id="p-0047" num="0046">As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the time series RAW image group GIM<b>1</b> is a plurality of RAW images captured in time series in the first time section TP<b>1</b>. The first time section TP<b>1</b> may be an arbitrary time section. For example, in a case where the endoscope system <b>5</b> photographs a moving image and the acquisition section <b>110</b> acquires the moving image to store it in the storage section <b>200</b>, photographing time of one moving image corresponds to the first time section TP<b>1</b>. Alternatively, when the recording candidate RAW image group extraction section <b>120</b> extracts the recording candidate RAW image group GIM<b>2</b>, a time section processed by single extraction processing corresponds to the first time section TP<b>1</b>.</p><p id="p-0048" num="0047">In a step S<b>2</b>, the recording candidate RAW image group extraction section <b>120</b> determines the second time section TP<b>2</b>. Specifically, the recording candidate RAW image group extraction section <b>120</b> analyzes the RAW images included in the time series RAW image group GIM<b>1</b> in a step S<b>3</b>, and determines the second time section TP<b>2</b> in the step <b>2</b> based on the analysis result.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating processing performed by the processing section <b>100</b>. <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example in which the recording candidate RAW image group extraction section <b>120</b> detects a lesion from the RAW images. The &#x201c;extracted time section&#x201d; in <figref idref="DRAWINGS">FIG. <b>5</b></figref> corresponds to the second time section TP<b>2</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and a section from a time t<b>1</b> at which the lesion appears to a time t<b>2</b> at which the lesion disappears is the second time section TP<b>2</b>. That is, the time section in which the lesion is captured in the RAW images is the second time section.</p><p id="p-0050" num="0049">For example, the recording candidate RAW image group extraction section <b>120</b> detects appearance and disappearance of a lesion by analyzing the time series RAW images. In this case, the time t<b>1</b> as a start point and the time t<b>2</b> as an end point are decided, and the interval therebetween becomes the second time section TP<b>2</b>. Alternatively, the recording candidate RAW image group extraction section <b>120</b> determines whether or not the lesion is captured in each RAW image by analyzing the RAW images included in the time series RAW image group GIM<b>1</b> one by one. In this case, a time section corresponding to the RAW images, which are determined that the lesion is captured therein, results in the second time section TP<b>2</b>.</p><p id="p-0051" num="0050">While the description has been given of the example in which analysis of the RAW images corresponds to lesion detection, the analysis method is not limited thereto. Other examples of the analysis method are described later. Further, the second time section TP<b>2</b> may be determined based on system information of the endoscope system <b>5</b>. A description of this example will be given with regard to the second example configuration.</p><p id="p-0052" num="0051">In a step S<b>4</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the RAW image recording importance determination section <b>140</b> determines importance of the RAW image. The importance is, for example, importance in machine learning using the RAW image. The importance indicates, for example, whether a target for image recognition with machine learning is captured or not, or whether a target for image recognition is captured in a manner contributing to highly accurate learning.</p><p id="p-0053" num="0052">As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the RAW images included in the recording candidate RAW image group GIM<b>2</b> are designated as IM<b>1</b> to IMn. n is an integer greater than or equal to 2. The RAW image recording importance determination section <b>140</b> determines each importance of IM<b>1</b> to IMn RAW images. In the example of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the importance has two levels of &#x201c;high&#x201d; and &#x201c;low&#x201d;, and each RAW image is determined to have either &#x201c;high&#x201d; or &#x201c;low&#x201d; importance. The RAW image recording importance determination section <b>140</b> determines the importance based on, for example, whether an entire lesion is captured in the RAW image or not, or the ratio of the lesion region to the RAW image. Note that the importance determination method is not limited to the above. Other determination methods are described later.</p><p id="p-0054" num="0053">The RAW image recording importance determination section <b>140</b> outputs the recording target RAW image, which is the RAW image determined to be of high importance, i.e. importance &#x201c;high&#x201d;. <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example in which IM<b>1</b>, IM<b>5</b>, IM<b>6</b>, . . . , are determined to be recording target RAW images. The importance may be classified in three or more levels, or may be continuous values. In this case, the RAW image recording importance determination section <b>140</b> outputs the RAW image with importance higher than a threshold value as the recording target RAW image.</p><p id="p-0055" num="0054">In a step S<b>5</b> in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the RAW image recording section <b>130</b> determines whether recording of the RAW image is required or not. That is, the RAW image recording section <b>130</b> determines that recording of the RAW image is not required when there are no RAW images determined to be the recording target RAW image in the step S<b>4</b>, and ends the processing in the flowchart. The RAW image recording section <b>130</b> determines that recording of the RAW image is required when there is the RAW image determined to be the recording target RAW image in the step S<b>4</b>, and records the recording target RAW image in the storage section <b>200</b>.</p><p id="p-0056" num="0055">For example, the RAW image recording section <b>130</b> deletes the RAW image other than the recording target RAW image among the time series RAW image group GIM<b>1</b> temporarily stored in the storage section <b>200</b>, thereby recording the recording target RAW image in the storage section <b>200</b>. Alternatively, the RAW image recording section <b>130</b> may delete the time series RAW image group GIM<b>1</b> temporarily stored in the storage section <b>200</b>, and newly store the recording target RAW image in the storage section <b>200</b>.</p><p id="p-0057" num="0056">The training data generation system <b>400</b> includes a processor <b>410</b>, a storage section <b>420</b>, a display section <b>430</b>, and an operation section <b>440</b>. The RAW image recorded in the storage section <b>200</b> of the image recording system <b>1</b> is transmitted to the training data generation system <b>400</b> and stored in the storage section <b>420</b>.</p><p id="p-0058" num="0057">The processor <b>410</b> reads out the RAW image from the storage section <b>420</b>, develops the RAW image to generate a display image, and displays the display image on the display section <b>430</b>. The processor <b>410</b> includes a training label acquisition section and a training label recording section. A user inputs the training label corresponding to the display image by using the operation section <b>440</b>. The training label acquisition section acquires the input training label. The training label recording section associates the training label with the RAW image so as to be a training image, and records the training image in the storage section <b>420</b>.</p><p id="p-0059" num="0058">The learning device <b>500</b> includes a storage section <b>520</b> and a processor <b>510</b>. The training image stored in the storage section <b>420</b> of the training data generation system <b>400</b> is transmitted to the learning device <b>500</b> and stored in the storage section <b>520</b> as training data <b>521</b>.</p><p id="p-0060" num="0059">The storage section <b>520</b> stores a learning model <b>522</b> for machine learning. The processor <b>510</b> performs machine learning for the learning model <b>522</b> using the training data <b>521</b>. The learning model <b>522</b> subjected to machine learning is transferred to the endoscope system as a trained model and used for image recognition in the endoscope system.</p><p id="p-0061" num="0060">In the above embodiments, the recording target RAW image is to be used in machine learning together with the training label which is associated with the recording target RAW image so as to be the training image.</p><p id="p-0062" num="0061">As a result, in some embodiments, the image recording system <b>1</b> records the RAW image which is then used in machine learning, such that the accuracy of machine learning can be improved. The image recording system <b>1</b> selects the RAW image to be recorded, such that both reduction of the data amount of the training image and improvement of accuracy of machine learning can be achieved.</p><p id="p-0063" num="0062">As a method for reducing data amount of the RAW image to be recorded, for example, a method is also considered in which the RAW image only at a scene switching timing or at a shutter operation timing is recorded. However, by such method, the RAW image only at a certain timing is to be recorded. Therefore, there may be a case where no RAW images suitable for machine learning are recorded, or there is a problem that the RAW image before or after the timing is not recorded.</p><p id="p-0064" num="0063">In the present embodiment, the image recording system <b>1</b> has the RAW image recording importance determination section <b>140</b> that selects the recording target RAW image from the recording candidate RAW image group GIM<b>2</b>. The RAW image recording section <b>130</b> records the recording target RAW image selected by the RAW image recording importance determination section <b>140</b>. Specifically, the RAW image recording importance determination section <b>140</b> determines each RAW image in the recording candidate RAW image group GIM<b>2</b> based on the importance, whereby selecting the recording target RAW image.</p><p id="p-0065" num="0064">The recording candidate RAW image group GIM<b>2</b> is thus extracted and among them, the RAW image with high importance is recorded such that the RAW image appropriate for machine learning is recorded. Furthermore, the recording candidate RAW image group GIM<b>2</b> included in the second time section TP<b>2</b> is extracted, whereby allowing to record a plurality of RAW images containing information on time series changes. This makes it possible to generate, for example, an image recognition system that even takes into consideration the time series changes in images, by machine learning.</p><p id="p-0066" num="0065">Further in the present embodiment, the processing time for one RAW image performed by the RAW image recording importance determination section <b>140</b> is longer than the processing time for one RAW image performed by the recording candidate RAW image group extraction section <b>120</b>. Specifically, the processing time for determining importance of one RAW image by the RAW image recording importance determination section <b>140</b> is longer than the processing time for determining whether one RAW image is to be the recording candidate or not by the recording candidate RAW image group extraction section <b>120</b>.</p><p id="p-0067" num="0066">In this way, since the recording candidate RAW image group GIM<b>2</b> is extracted from the time series RAW image group GIM<b>1</b> by processing with a small processing load, importance determination targets requiring a large processing load are reduced. Accordingly, a processing load in the entire process of selecting the recording target RAW image can be reduced.</p><p id="p-0068" num="0067">The processing with a small processing load to be performed by the recording candidate RAW image group extraction section <b>120</b> is assumed to be determination based on a recognition result input by an external image recognition system, for example. The image recognition includes, for example, detection of a lesion, abnormal mucosa, or an organ. Alternatively, the processing with a small processing load is assumed to be determination based on parameters such as brightness of an image calculated with a relatively small load. Alternatively, the processing with a small processing load is assumed to be determination based on the system information input from the endoscope system <b>5</b>, as described with regard to the second example configuration. The system information includes a type of illumination light, treatment information, information on user operation, or the like.</p><p id="p-0069" num="0068">The processing with a large processing load to be performed by the RAW image recording importance determination section <b>140</b> is assumed to be the importance determination based on image recognition performed by the RAW image recording importance determination section <b>140</b> itself, for example. The image recognition includes, for example, analysis of a type or size of a lesion and a treatment condition.</p><p id="p-0070" num="0069">Further in the present embodiment, the acquisition section <b>110</b> acquires, as a plurality of RAW images, a plurality of medical images photographed in time series by the endoscope system <b>5</b>.</p><p id="p-0071" num="0070">In machine learning using medical images, it is assumed that a variety of image extension would be applied to the medical images depending on the image recognition target. That is, there are various image recognition targets such as targets characterized by uneven structures, blood running, color, or texture, and image extension is applied depending on such characteristics. To allow such a variety of image extension, it is preferable to accumulate RAW images flexibly enduring image processing. As a result, in some embodiments, it is possible to accumulate the RAW images while reducing the amount of recording data, and use them in machine learning of the medical images.</p><heading id="h-0008" level="1">3. Various Embodiments of First Example Configuration</heading><p id="p-0072" num="0071">A description will be given of a specific example of a method in which the recording candidate RAW image group extraction section <b>120</b> extracts the recording candidate RAW image group GIM<b>2</b>. Any one of the following methods may be adopted, or two or more methods may be combined.</p><p id="p-0073" num="0072">In a first method, the recording candidate RAW image group extraction section <b>120</b> detects a state of an image capturing target in the RAW image included in the time series RAW image group GIM<b>1</b>, and based on the state of the image capturing target, extracts the recording candidate RAW image group GIM<b>2</b>. For example, the following first to third examples can be assumed.</p><p id="p-0074" num="0073">In the first example, the recording candidate RAW image group extraction section <b>120</b> detects a lesion from appearance to disappearance thereof in the time series RAW image group GIM<b>1</b>, and sets the section from appearance to disappearance thereof to the second time section TP<b>2</b>. The appearance and disappearance of the lesion is, for example, detected by image recognition processing such as AI processing. The lesion is a pathologically changed tissue, such as, for example, a polyp or cancer.</p><p id="p-0075" num="0074">In the second example, the recording candidate RAW image group extraction section <b>120</b> detects abnormal mucosa from its appearance to disappearance in the time series RAW image group GIM<b>1</b>, and sets the section from appearance to disappearance thereof to the second time section TP<b>2</b>. The appearance and disappearance of the abnormal mucosa is, for example, detected by image recognition processing such as AI processing. The abnormal mucosa is mucosa that is not normal, for example, mucosa with inflammation, bleeding, or atrophy.</p><p id="p-0076" num="0075">In the third example, the recording candidate RAW image group extraction section <b>120</b> determines an organ captured in the time series RAW image group GIM<b>1</b>, and set the time section in which the organ to be subjected to machine learning is captured to the second time section TP<b>2</b>. The organ is, for example, detected by image recognition processing such as AI processing.</p><p id="p-0077" num="0076">As a result, in some embodiments, it is possible to roughly extract the candidate RAW image according to the state of the image capturing target before selecting the RAW image based on the importance. That is, it is possible to exclude the RAW image in which no image recognition target for machine learning is captured or the RAW image in which the image capturing target is captured in a state unsuitable for machine learning, and record the other RAW image as a candidate.</p><p id="p-0078" num="0077">In a second method, the recording candidate RAW image group extraction section <b>120</b> detects directly or indirectly brightness of the RAW image included in the time series RAW image group GIM<b>1</b>, and extracts the recording candidate RAW image group GIM<b>2</b> based on the brightness of the RAW image.</p><p id="p-0079" num="0078">Specifically, the recording candidate RAW image group extraction section <b>120</b> detects lightness of the RAW image and sets the time section including a brightly photographed RAW image to the second time section TP<b>2</b>. The lightless is an index value indicating brightness of an image, for example, an average luminance value of the entire image. Directly detecting brightness is to calculate the lightness from the RAW image. Indirectly detecting brightness is to calculate the lightness based on information other than the RAW image. For example, the lightness may be calculated based on the amount of illumination light of the endoscope system <b>5</b>. This example also serves as an example of the system information of the second example configuration.</p><p id="p-0080" num="0079">As a result, in some embodiments, it is possible to roughly extract the candidate RAW image according to the brightness of the RAW image before selecting the RAW image based on the importance. That is, it is possible to exclude the RAW image unsuitable for machine learning, such as too dark or too bright images, and record the other RAW image as a candidate.</p><p id="p-0081" num="0080">In a third method, the recording candidate RAW image group extraction section <b>120</b> detects treatment operation of the endoscope system <b>5</b> and extracts the recording candidate RAW image group GIM<b>2</b> based on the treatment operation of the endoscope system <b>5</b>.</p><p id="p-0082" num="0081">Specifically, the recording candidate RAW image group extraction section <b>120</b> detects a treatment tool from its appearance to disappearance in the RAW images, and sets the time section from appearance to disappearance thereof to the second time section TP<b>2</b>. The section from appearance to disappearance of the treatment tool is detected by image recognition processing. The image recognition processing includes, for example, contour detection of the treatment tool, detection of high-luminance regions, and detection of specific color regions.</p><p id="p-0083" num="0082">As a result, in some embodiments, it is possible to roughly extract the candidate RAW image according to the treatment operation before selecting the RAW image based on the importance. That is, since it is highly probable that a learning target for machine learning is photographed in the time section in which the treatment operation is being performed, the recording target RAW image can be extracted by extracting the RAW image in the time section.</p><p id="p-0084" num="0083">In a fourth method, the recording candidate RAW image group extraction section <b>120</b> detects movement of the insertion section <b>201</b> of the endoscope system <b>5</b>, and extracts the recording candidate RAW image group GIM<b>2</b> based on the movement of the insertion section <b>201</b>. For example, the following first and second examples can be assumed.</p><p id="p-0085" num="0084">In the first example, the recording candidate RAW image group extraction section <b>120</b> detects the section in which the distal end of the scope stands still, and sets the section to the second time section TP<b>2</b>. The stillness of the distal end of the scope is detected by performing motion detection on the RAW image. That is, if a degree of motion detected from the RAW image is a predetermined value or smaller, it is detected that the distal end of the scope stands still.</p><p id="p-0086" num="0085">In the second example, the recording candidate RAW image group extraction section <b>120</b> detects an insertion/withdrawal direction of the insertion section <b>201</b> and sets the time section in which appropriate withdrawal is performed to the second time section TP<b>2</b>. The insertion/withdrawal direction is detected by performing motion detection on the RAW image. That is, if a motion converging to a vanishing point is detected from the RAW image, it is determined that the insertion section <b>201</b> is being withdrawn. Since examination of the large intestine or the like is performed during withdrawal, the RAW image in the time section in which withdrawal is performed is to be a recording candidate.</p><p id="p-0087" num="0086">As a result, in some embodiments, it is possible to roughly extract the candidate RAW image according to a degree of motion of the insertion section <b>201</b> before selecting the RAW image based on the importance. That is, since it is highly probable that the learning target for machine learning is photographed during a specific motion of the insertion section <b>201</b>, the recording target RAW image can be extracted by extracting the RAW image in the time section in which the insertion section <b>201</b> moves in the specific motion.</p><p id="p-0088" num="0087">Next, a description will be given of a specific example of a method in which the RAW image recording importance determination section <b>140</b> selects the recording target RAW image. Any one of the following methods may be adopted, or two or more methods may be combined.</p><p id="p-0089" num="0088">In a first method, the RAW image recording importance determination section <b>140</b> analyzes characteristics of a lesion in the RAW image, and sets the importance according to the characteristics of the lesion. The characteristics of the lesion is, for example, detected by image recognition processing such as AI processing. For example, the following first and second examples are assumed.</p><p id="p-0090" num="0089">In the first example, the RAW image recording importance determination section <b>140</b> sets the importance according to a type of a lesion. For example, the RAW image recording importance determination section <b>140</b> sets the importance of the RAW image high when a rare case is detected.</p><p id="p-0091" num="0090">In the second example, the RAW image recording importance determination section <b>140</b> analyzes size of a lesion and sets the importance according to the size. For example, when a small lesion to be easily missed is detected, the RAW image recording importance determination section <b>140</b> sets the importance of the RAW image high.</p><p id="p-0092" num="0091">In a second method, the RAW image recording importance determination section <b>140</b> analyzes a treatment condition of the endoscope system <b>5</b> and sets the importance according to the treatment condition. The treatment condition is detected by image recognition processing. The image recognition processing includes, for example, contour detection of a treatment tool, detection of high luminance regions, and detection of specific color regions. Further, the treatment condition may be detected based on the system information from the endoscope system <b>5</b>. For example, the treatment condition may be detected based on information of switch operation of an electric knife or the like. This example also serves as an example of the system information of the second example configuration. The following first and second examples are assumed as the example of the second method.</p><p id="p-0093" num="0092">In the first example, the RAW image recording importance determination section <b>140</b> determines whether the RAW image was photographed before, during, or after the treatment, and sets the importance of the RAW image based on the determination result.</p><p id="p-0094" num="0093">In the second example, the RAW image recording importance determination section <b>140</b> determines a type of a treatment tool captured in the RAW image, and sets the importance of the RAW image based on the type of the treatment tool.</p><p id="p-0095" num="0094">In a third method, the RAW image recording importance determination section <b>140</b> determines whether the RAW image is an image of an already photographed site or not, and in a case where the RAW image is an image of a newly photographed site, sets the importance of the RAW image high. For example, a site captured in the RAW image is detected by image recognition processing such as AI processing and compared with the determination result of the already photographed image, thereby determining whether the site is already photographed or not.</p><p id="p-0096" num="0095">Next, a description will be given of a specific example of a method in which the RAW image recording section <b>130</b> records the recording target RAW image.</p><p id="p-0097" num="0096">The RAW image recording section <b>130</b> records the RAW image determined to be highly important, but does not record the other RAW image. Note that the RAW image not determined as highly important may be recorded as compressed data. The method thereof is described later.</p><heading id="h-0009" level="1">4. Second Example Configuration</heading><p id="p-0098" num="0097">In the second example configuration, the recording candidate RAW image group extraction section <b>120</b> extracts the recording candidate RAW image group GIM<b>2</b> based on the system information of the endoscope system <b>5</b>. Note that the first and second example configurations can be combined. That is, the recording candidate RAW image group extraction section <b>120</b> may extract the recording candidate RAW image group GIM<b>2</b> based on both of the analysis result of the RAW image and the analysis result of the system information.</p><p id="p-0099" num="0098">The hardware configuration of the second example configuration is same as the one of the first example configuration illustrated in <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flowchart illustrating processing performed by the processing section <b>100</b> in the second example configuration. Steps S<b>14</b> to S<b>16</b> are same as the steps S<b>4</b> to S<b>6</b> in the first example configuration illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref> and thus a description thereof is omitted.</p><p id="p-0100" num="0099">In a step S<b>11</b>, the acquisition section <b>110</b> acquires the RAW images and the system information of the endoscope system. Specifically, the acquisition section <b>110</b> is a data interface of the processing section <b>100</b>, receiving the time series RAW image group GIM<b>1</b> and the system information transferred from the endoscope system <b>5</b>, temporarily storing the time series RAW image group GIM<b>1</b> in the storage section <b>200</b>, and outputting the system information to the recording candidate RAW image group extraction section <b>120</b>. The system information is information about control, operation, or a state of the endoscope system <b>5</b>, and transmitted as signals or data. The system information is, for example, time series information, likewise the RAW images. The system information at the time of photographing each RAW image is associated with the RAW image and input to the acquisition section <b>110</b>.</p><p id="p-0101" num="0100">In a step S<b>12</b>, the recording candidate RAW image group extraction section <b>120</b> determines the second time section TP<b>2</b>. Specifically, the recording candidate RAW image group extraction section <b>120</b> analyzes the system information of the endoscope system <b>5</b> at the time of photographing the time series RAW image group GIM<b>1</b> in a step S<b>13</b>; determines the second time section TP<b>2</b> based on the analysis result in the step S<b>12</b>; and extracts the recording candidate RAW image group GIM<b>2</b>. The specific example of the system information is described later.</p><p id="p-0102" num="0101">As a result, in some embodiments, it is possible to roughly extract the candidate RAW image based on the system information of the endoscope system <b>5</b> before selecting the RAW image based on the importance. That is, since it is highly probable that the learning target for machine learning is photographed by specific control, operation, or a state of the endoscope system <b>5</b>, it is possible to extracts the recording target RAW image by extracting the RAW image in the time section in which the specific control, operation or state of the endoscope system is performed.</p><p id="p-0103" num="0102">A description will be given of a specific example of a method in which the recording candidate RAW image group extraction section <b>120</b> extracts the recording candidate RAW image group GIM<b>2</b>. Any one of the following methods may be adopted, or two or more methods may be combined.</p><p id="p-0104" num="0103">In a first method, the recording candidate RAW image group extraction section <b>120</b> detects a type of a light source at the time when the time series RAW image group GIM<b>1</b> was photographed, and sets a time section photographed by a desired type of the light source to the second time section TP<b>2</b>. The type of the light source is a spectral-based type such as white light and special light, or a type of a light emitting element such as a xenon lump, LED, or a laser diode. The system information indicating the type of the light source includes, for example, a control signal of an illumination light mode.</p><p id="p-0105" num="0104">In a second method, the recording candidate RAW image group extraction section <b>120</b> detects imaging magnification of the scope and set the time section photographed at the desired magnification to the second time section TP<b>2</b>. The system information indicating the imaging magnification includes, for example, a control signal for zoom operation.</p><p id="p-0106" num="0105">In a third method, the recording candidate RAW image group extraction section <b>120</b> detects release operation or freeze operation, and sets the time section including before and after the timing when the release operation or the freeze operation is performed to the second time section TP<b>2</b>. The release operation or the freeze operation is, for example, performed by a button provided in the grip section <b>204</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and a signal of the button operation corresponds to the system information.</p><p id="p-0107" num="0106">In a fourth method, a user provides input to the endoscope system <b>5</b>, the input indicating determination that the RAW image should be recorded, and the recording candidate RAW image group extraction section <b>120</b> sets the second time section TP<b>2</b> based on the input information. The input mentioned above is, for example, provided through an operation section provided in the grip section <b>204</b>, the control device <b>3</b> or the monitor <b>4</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, or provided by voice input or the like.</p><heading id="h-0010" level="1">5. Third Example Configuration</heading><p id="p-0108" num="0107"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a third example configuration of the image recording system <b>1</b>. In <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the acquisition section <b>110</b> includes an image conversion section <b>112</b>. Note that a description of a component described with regard to the first and second example configurations is omitted as appropriate.</p><p id="p-0109" num="0108">The image conversion section <b>112</b> performs conversion processing on the RAW image included in the time series RAW image group GIM<b>1</b>, and generates a converted image. The recording candidate RAW image group extraction section <b>120</b> extracts the recording candidate RAW image group GIM<b>2</b> based on the converted image.</p><p id="p-0110" num="0109">The conversion processing is a process of converting the RAW image to a color image, that is development processing. The conversion processing may also include white balance processing, noise processing, tone conversion processing, color conversion processing, enhancement processing, or the like.</p><p id="p-0111" num="0110">As a result, in some embodiments, it is possible to convert the RAW image to an image suitable for extraction processing of the recording candidate RAW image group GIM<b>2</b>, and then extract the recording candidate RAW image group GIM<b>2</b> based on the converted image.</p><heading id="h-0011" level="1">6. Fourth Example Configuration</heading><p id="p-0112" num="0111">In a fourth example configuration, the RAW image that is not selected as the recording target is recorded as compressed data. <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates the fourth example configuration of the image recording system <b>1</b>. In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the RAW image recording section <b>130</b> includes a compression section <b>114</b>. Further, the processor <b>510</b> of the learning device <b>500</b> includes an image extension section <b>512</b>. Note that a description of a component described with regard to the first and second example configurations is omitted as appropriate.</p><p id="p-0113" num="0112">As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the compression section <b>114</b> converts the RAW image among the recording candidate RAW image group GIM<b>2</b>, which is not selected by the RAW image recording importance determination section <b>140</b>, to compressed data. That is, the RAW image that is determined to be of &#x201c;low&#x201d; importance by the RAW image recording importance determination section <b>140</b> is converted to the compressed data. The RAW image recording section <b>130</b> records the compressed data and the RAW image selected by the RAW image recording importance determination section <b>140</b> in the storage section <b>200</b>. <figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example where IM<b>1</b>, IMn, etc. are recorded in a RAW format, and IM<b>2</b>, etc. are recorded in a compressed format.</p><p id="p-0114" num="0113">Note that the compression section <b>114</b> may convert the RAW image among the time series RAW image group GIM<b>1</b>, which is not selected by the RAW image recording importance determination section <b>140</b>, to compressed data, and then the RAW image recording section <b>130</b> records the compressed data in the storage section <b>200</b>. That is, the compression section <b>114</b> converts not only the RAW image among the recording candidate RAW image group GIM<b>2</b>, which is not selected by the RAW image recording importance determination section <b>140</b>, but also the RAW image not extracted as the recording candidate RAW image group GIM<b>2</b> to the compressed data.</p><p id="p-0115" num="0114">The compressed data is data of the RAW image that has been subjected to development processing or compression processing, and corresponds to compressed data of the color image. The data amount of the compressed data generated by one RAW image is smaller than the data amount of the original one RAW image.</p><p id="p-0116" num="0115">As a result, in some embodiments, the RAW image with high importance as well as the compressed data of the other compressed RAW image are recorded. This enables machine learning using the RAW images and the compressed data. Machine learning requires a lot of images; hence, by adding the compressed data to secure a lot of images as well as using the RAW images for a part of those images, highly accurate learning becomes possible.</p><p id="p-0117" num="0116">The recording target RAW image is an image to be used in machine learning after being converted to an extended image by image processing. The recording target RAW image is highly flexible for image processing, and thus easily converted to the desired extended image. The compressed data is an image to be used in machine learning without being converted to the extended image. That is, the image extension section <b>512</b> of the learning device <b>500</b> converts the recording target RAW image to the extended image by image extension processing. The image extension section <b>512</b> does not perform image extension processing on the compressed data. The image extension processing includes development processing, white balance processing, noise processing, tone conversion processing, color conversion processing, enhancement processing, or the like. The processor <b>510</b> performs machine learning for the learning model <b>522</b> using the extended image and the compressed data as the image for learning.</p><p id="p-0118" num="0117">Although the embodiments to which the present disclosure is applied and the modifications thereof have been described in detail above, the present disclosure is not limited to the embodiments and the modifications thereof, and various modifications and variations in components may be made in implementation without departing from the spirit and scope of the present disclosure. The plurality of elements disclosed in the embodiments and the modifications described above may be combined as appropriate to implement the present disclosure in various ways. For example, some of all the elements described in the embodiments and the modifications may be deleted. Furthermore, elements in different embodiments and modifications may be combined as appropriate. Thus, various modifications and applications can be made without departing from the spirit and scope of the present disclosure. Any term cited with a different term having a broader meaning or the same meaning at least once in the specification and the drawings can be replaced by the different term in any place in the specification and the drawings.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image recording system comprising a processor, the processor being configured to implement:<claim-text>acquiring a time series RAW image group including a plurality of time series RAW images in a first time section;</claim-text><claim-text>extracting, from the time series RAW image group, a recording candidate RAW image group included in a second time section as a part of the first time section;</claim-text><claim-text>recording at least one RAW image included in the recording candidate RAW image group as a recording target RAW image which is a RAW image to be recorded, whereby selecting the recording target RAW image from the recording candidate RAW image group; and</claim-text><claim-text>converting the RAW image which is not selected as the recording target RAW image from the recording candidate RAW image group or the time series RAW image group to compressed data, and recording the compressed data.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the recording target RAW image is to be used in machine learning together with a training label which is associated with the recording target RAW image so as to be a training image.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor records the selected recording target RAW image.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image recording system as defined in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein processing time for one RAW image performed by the processor when the processor selects the recording target RAW image from the recording candidate RAW image group is longer than the processing time for one RAW image performed by the processor when the processor extracts the recording candidate RAW image group from the time series RAW image group.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image recording system as defined in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the processor determines each RAW image of the recoding candidate RAW image group based on importance to select the recording target RAW image.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor<claim-text>converts the RAW image included in the time series RAW image group to generate a converted image, and</claim-text><claim-text>extracts the recording candidate RAW image group based on the converted image.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor detects a state of an image capturing target in the RAW image included in the time series RAW image group, and extracts the recording candidate RAW image group based on the state of the image capturing target.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor detects directly or indirectly brightness of the RAW image included in the time series RAW image group, and extracts the recording candidate RAW image group based on the brightness of the RAW image.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor acquires, as the plurality of RAW images, a plurality of medical images photographed in time series by an endoscope system.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor<claim-text>acquires the time series RAW image group captured by an endoscope system,</claim-text><claim-text>detects treatment operation of the endoscope system and extracts the recording candidate RAW image group based on the treatment operation.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor<claim-text>acquires the time series RAW image group captured by an endoscope system, and</claim-text><claim-text>detects movement of an insertion section of the endoscope system and extracts the recording candidate RAW image group based on the movement of the insertion section.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The image recording system as defined in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor<claim-text>acquires the time series RAW image group captured by an endoscope system and system information of the endoscope system, and</claim-text><claim-text>extracts the recording candidate RAW image group based on the system information.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. An image recording method comprising:<claim-text>acquiring a time series RAW image group including a plurality of time series RAW images in a first time section;</claim-text><claim-text>extracting, from the time series RAW image group, a recording candidate RAW image group included in a second time section as a part of the first time section;</claim-text><claim-text>selecting, from the recording candidate RAW image group, a recording target RAW image to be recorded;</claim-text><claim-text>recording at least one RAW image included in the recording candidate RAW image group as the recording target RAW image; and</claim-text><claim-text>converting the RAW image which is not selected as the recording target RAW image from the recording candidate RAW image group or the time series RAW image group to compressed data, and recording the compressed data.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The image recording method as defined in <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the recording target RAW image is a RAW image to be used in machine learning together with a training label which is associated with the recording target RAW image so as to be a training image.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The image recording method as defined in <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein<claim-text>the recording target RAW image is an image to be used in machine learning after being converted to an extended image by image extension processing; and</claim-text><claim-text>the compressed data is an image to be used in machine learning without being converted to the extended image.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A non-transitory computer-readable storage medium storing a program for causing a computer to execute:<claim-text>acquiring a time series RAW image group including a plurality of time series RAW images in a first time section;</claim-text><claim-text>extracting, from the time series RAW image group, a recording candidate RAW image group included in a second time section as a part of the first time section;</claim-text><claim-text>selecting, from the recording candidate RAW image group, a recording target RAW image to be recorded;</claim-text><claim-text>recording at least one RAW image included in the recording candidate RAW image group as the recording target RAW image; and</claim-text><claim-text>converting the RAW image which is not selected as the recording target RAW image from the recording candidate RAW image group or the time series RAW image group to compressed data, and recording the compressed data.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007265A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007265</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17778002</doc-number><date>20201127</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-223601</doc-number><date>20191211</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>132</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>46</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>103</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>124</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>176</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>132</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>46</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>103</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>18</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>124</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20141101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>176</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">IMAGE PROCESSING DEVICE, BIT STREAM GENERATION METHOD, COEFFICIENT DATA GENERATION METHOD, AND QUANTIZATION COEFFICIENT GENERATION METHOD</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Sony Group Corporation</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TSUKUBA</last-name><first-name>Takeshi</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Sony Group Corporation</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/044151</doc-number><date>20201127</date></document-id><us-371c12-date><date>20220519</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">In encoding an image, a transform skip flag that is flag information indicating, for each component, whether or not to skip transform processing of transforming a residual between an image and a predicted image of the image into coefficient data is generated, the transform skip flag generated is encoded, coded data of the transform skip flag is generated, and a bit stream including the generated coded data of the transform skip flag is generated. The present encoding/decoding can be applied to, for example, an image processing device, an image encoding device, an image decoding device, a transmission device, a reception device, a transmission-reception device, an information processing device, an imaging device, a reproduction device, a bit stream generation method, a coefficient data generation method, a quantization coefficient generation method, or the like.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="100.92mm" wi="158.75mm" file="US20230007265A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="204.22mm" wi="155.70mm" file="US20230007265A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="151.05mm" wi="155.70mm" file="US20230007265A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="196.51mm" wi="92.12mm" file="US20230007265A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="151.05mm" wi="155.70mm" file="US20230007265A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="235.80mm" wi="157.65mm" orientation="landscape" file="US20230007265A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="215.73mm" wi="113.54mm" orientation="landscape" file="US20230007265A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="222.93mm" wi="74.34mm" orientation="landscape" file="US20230007265A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="235.71mm" wi="156.97mm" orientation="landscape" file="US20230007265A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="217.85mm" wi="69.17mm" orientation="landscape" file="US20230007265A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="237.32mm" wi="156.89mm" orientation="landscape" file="US20230007265A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="217.85mm" wi="69.00mm" orientation="landscape" file="US20230007265A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="235.63mm" wi="157.99mm" orientation="landscape" file="US20230007265A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="123.36mm" wi="145.80mm" file="US20230007265A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="127.08mm" wi="143.34mm" file="US20230007265A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00026" num="00026"><img id="EMI-D00026" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00026.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00027" num="00027"><img id="EMI-D00027" he="235.97mm" wi="159.51mm" orientation="landscape" file="US20230007265A1-20230105-D00027.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00028" num="00028"><img id="EMI-D00028" he="231.99mm" wi="98.81mm" orientation="landscape" file="US20230007265A1-20230105-D00028.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00029" num="00029"><img id="EMI-D00029" he="158.33mm" wi="131.49mm" orientation="landscape" file="US20230007265A1-20230105-D00029.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present disclosure relates to an image processing device, a bit stream generation method, a coefficient data generation method, and a quantization coefficient generation method, and particularly relates to an image processing device, a bit stream generation method, a coefficient data generation method, and a quantization coefficient generation method capable of suppressing reduction in encoding efficiency.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">Conventionally, there has been proposed, in image encoding, a method of performing encoding by skipping (omitting) transform processing of transforming a residual between an image and a predicted image thereof into coefficient data (for example, Non-Patent Document 1).</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Non-Patent Document</heading><p id="p-0004" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0003">Non-Patent Document 1: Benjamin Bross, Jianle Chen, Shan Liu, &#x201c;Versatile Video Coding (Draft 5)&#x201d;, JVET-N1001-v10, Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 14th Meeting: Geneva, CH, 19-27 Mar. 2019</li></ul></p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><heading id="h-0006" level="1">Problems to be Solved by the Invention</heading><p id="p-0005" num="0004">However, in the case of the method described in Non-Patent Document 1, this mode of transform skip is applied only to luminance components (luminance transform skip). That is, this transform skip mode cannot be applied to chrominance components. Therefore, there has been a possibility of reduction in encoding efficiency.</p><p id="p-0006" num="0005">The present disclosure has been made in view of such a situation, and an object thereof is to make it possible to suppress reduction in encoding efficiency.</p><heading id="h-0007" level="1">Solutions to Problems</heading><p id="p-0007" num="0006">An image processing device according to one aspect of the present technology is an image processing device including a flag generation unit that generates a transform skip flag that is flag information indicating, for each component, whether or not to skip transform processing of transforming a residual between an image and a predicted image of the image into coefficient data in encoding of the image, a flag encoding unit that encodes the transform skip flag generated by the flag generation unit and generates coded data of the transform skip flag, and a bit stream generation unit that generates a bit stream including the coded data of the transform skip flag generated by the flag encoding unit.</p><p id="p-0008" num="0007">A bit stream generation method according to one aspect of the present technology is a bit stream generation method including generating a transform skip flag that is flag information indicating, for each component, whether or not to skip transform processing of transforming a residual between an image and a predicted image of the image into coefficient data in encoding of the image, encoding the transform skip flag generated and generating coded data of the transform skip flag, and generating a bit stream including the coded data of the transform skip flag generated.</p><p id="p-0009" num="0008">An image processing device according to another aspect of the present technology is an image processing device including a quantization parameter correction unit that, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping transform processing for transforming a residual between an image and a predicted image of the image into a transform coefficient in encoding the image, corrects a quantization parameter to be applied to a processing target transform block corresponding to the component identifier, and a quantization unit that performs quantization of the processing target transform block corresponding to the component identifier by using the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0010" num="0009">A quantization coefficient generation method according to another aspect of the present technology is an image processing device including correcting, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping transform processing for transforming a residual between an image and a predicted image of the image into a transform coefficient in encoding the image, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier, and performing quantization of the processing target transform block corresponding to the component identifier by using the quantization parameter corrected, and generating a quantization coefficient corresponding to the component identifier.</p><p id="p-0011" num="0010">An image processing device according to still another aspect of the present technology is an image processing device including a flag decoding unit that decodes coded data of a transform skip flag corresponding to a component identifier and obtains the transform skip flag corresponding to the component identifier, a mode control unit that controls, on the basis of the transform skip flag corresponding to the component identifier obtained by the flag decoding unit, whether a decoding mode of coded data of coefficient data corresponding to the component identifier is set to a TS residual decoding mode that is a mode for a case of skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, or set to a non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform process, and a coefficient data decoding unit that decodes the coded data of the coefficient data corresponding to the component identifier according to the decoding mode set by the mode control unit, and generates the coefficient data corresponding to the component identifier.</p><p id="p-0012" num="0011">A coefficient data generation method according to still another aspect of the present technology is a coefficient data generation method including decoding coded data of a transform skip flag corresponding to a component identifier and obtaining the transform skip flag corresponding to the component identifier, controlling, on the basis of the transform skip flag corresponding to the component identifier obtained, whether a decoding mode of coded data of coefficient data corresponding to the component identifier is set to a TS residual decoding mode that is a mode for a case of skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, or set to a non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform process, and decoding the coded data of the coefficient data corresponding to the component identifier according to the decoding mode set, and generating the coefficient data corresponding to the component identifier.</p><p id="p-0013" num="0012">An image processing device according to still another aspect of the present technology is an image processing device including a quantization parameter correction unit that, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, corrects a quantization parameter to be applied to a processing target transform block corresponding to the component identifier, and an inverse quantization unit that performs inverse quantization of a processing target transform block corresponding to the component identifier by using the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0014" num="0013">A coefficient data generation method according to still another aspect of the present technology is a coefficient data generation method including correcting, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier, and performing inverse quantization of a processing target transform block corresponding to the component identifier by using the quantization parameter corrected, and generates the coefficient data corresponding to the component identifier.</p><p id="p-0015" num="0014">In the image processing device and the bit stream generation method according to one aspect of the present technology, a transform skip flag that is flag information indicating, for each component, whether or not to skip transform processing of transforming a residual between an image and a predicted image of the image into coefficient data in encoding of the image is generated, the transform skip flag generated is encoded, coded data of the transform skip flag is generated, and a bit stream including the coded data of the transform skip flag generated is generated.</p><p id="p-0016" num="0015">In the image processing device and the quantization coefficient generation method according to another aspect of the present technology, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping transform processing for transforming a residual between an image and a predicted image of the image into a transform coefficient in encoding the image, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier is corrected, and quantization of the processing target transform block corresponding to the component identifier is performed by using the quantization parameter corrected, and a quantization coefficient corresponding to the component identifier is generated.</p><p id="p-0017" num="0016">In the image processing device and the coefficient data generation method according to still another aspect of the present technology, coded data of a transform skip flag corresponding to a component identifier is decoded, the transform skip flag corresponding to the component identifier is obtained, whether a decoding mode of coded data of coefficient data corresponding to the component identifier is set to a TS residual decoding mode that is a mode for a case of skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, or set to a non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform process, is controlled on the basis of the transform skip flag corresponding to the component identifier obtained, the coded data of the coefficient data corresponding to the component identifier is decoded according to the set decoding mode, and the coefficient data corresponding to the component identifier is generated.</p><p id="p-0018" num="0017">In the image processing device and the coefficient data generation method according to still another aspect of the present technology, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier is corrected, inverse quantization of a processing target transform block corresponding to the component identifier is performed by using the quantization parameter corrected, and the coefficient data corresponding to the component identifier is generated.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0008" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram describing extension of transform skip.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a main configuration example of an image encoding device.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a main configuration example of an encoding unit.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating an example of a flow of image encoding processing.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart describing an example of a flow of encoding processing.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating a main configuration example of an image decoding device.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating a main configuration example of a decoding unit.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example of a flow of image decoding processing.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating an example of a flow of decoding processing.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating an example of syntax of a TU.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram illustrating an example of syntax of transform mode information.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating an example of syntax of a TS residual encoding mode.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram illustrating an example of semantics of transform mode information.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating another example of syntax of transform mode information.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a diagram illustrating an example of syntax of a sequence parameter set.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram illustrating an example of syntax of the TU.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a diagram illustrating an example of semantics of a sequence parameter set.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a diagram illustrating an example of syntax of the sequence parameter set.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a diagram illustrating an example of syntax of the TU.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a diagram illustrating an example of semantics of the sequence parameter set.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a block diagram illustrating a main configuration example of a quantization unit.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>22</b></figref> is a flowchart illustrating an example of a flow of quantization processing.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a block diagram illustrating a main configuration example of an inverse quantization unit.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a flowchart illustrating an example of a flow of inverse quantization processing.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>25</b></figref> is a diagram illustrating an example of syntax of a quantization parameter.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a diagram illustrating an example of syntax of a context variable.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a diagram illustrating an example of syntax of the context variable.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>28</b></figref> is a diagram describing switching of a sign coding mode.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>29</b></figref> is a block diagram illustrating a main configuration example of a computer.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0009" level="1">MODE FOR CARRYING OUT THE INVENTION</heading><p id="p-0048" num="0047">Hereinafter, modes for carrying out the present disclosure (hereinafter referred to as embodiments) will be described. Note that the description will be made in the following order.</p><p id="p-0049" num="0048">1. Documents and the like supporting technical contents and technical terms</p><p id="p-0050" num="0049">2. Transform skip</p><p id="p-0051" num="0050">3. First embodiment (extension of transform skip)</p><p id="p-0052" num="0051">4. Second embodiment (correction of quantization parameter)</p><p id="p-0053" num="0052">5. Third embodiment (sharing of context variable)</p><p id="p-0054" num="0053">6. Fourth embodiment (control of encoding-decoding mode of sign code)</p><p id="p-0055" num="0054">7. Appendix</p><heading id="h-0010" level="1">1. DOCUMENTS AND THE LIKE SUPPORTING TECHNICAL CONTENTS AND TECHNICAL TERMS</heading><p id="p-0056" num="0055">The scope disclosed in the present technology includes not only the contents described in the embodiments but also the contents described in the following non-patent documents known at the time of filing.<ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0056">Non-Patent Document 1: (described above)</li>    <li id="ul0002-0002" num="0057">Non-Patent Document 2: Takeshi Tsukuba, Masaru Ikeda, Yoichi Yagasaki, Teruhiko Suzuki, &#x201c;CE8: Chroma Transform Skip (CE8-3.2)&#x201d;, JVET-O0081-v2, Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 15th Meeting: Gothenburg, SE, 3-12 Jul. 2019</li>    <li id="ul0002-0003" num="0058">Non-Patent Document 3: Tung Nguyen, Benjamin Bross, Heiko Schwarz, Detlev Marpe, Thomas Wiegand, &#x201c;Non-CE8: Minimum Allowed QP for Transform Skip Mode&#x201d;, JVET-O0405-v1, Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 15th Meeting: Gothenburg, SE, 3-12 Jul. 2019</li>    <li id="ul0002-0004" num="0059">Non-Patent Document 4: Jianle Chen, Yan Ye, Seung Hwan Kim, &#x201c;Algorithm description for Versatile Video Coding and Test Model 6 (VTM 6)&#x201d;, JVET-O2002-v2, Joint Video Experts Team (JVET), of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 15th Meeting: Gothenburg, SE, 3-12 Jul. 2019</li>    <li id="ul0002-0005" num="0060">Non-Patent Document 5: Takeshi Tsukuba, Masaru Ikeda, Yoichi Yagasaki, Teruhiko Suzuki, &#x201c;CE8-2.1: Transform Skip for Chroma with limiting maximum number of context-coded bin in TS residual coding&#x201d;, JVET-P0058-v1, Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 16th Meeting: Geneva, CH, 1-11 Oct. 2019</li>    <li id="ul0002-0006" num="0061">Non-Patent Document 6: Gordon Clare, Felix Henry, Takeshi Tsukuba, Masaru Ikeda, Yoich Yagasaki, Teruhiko Suzuki, &#x201c;CE8-4.1: BDPCM and Transform skip for Chroma&#x201d;, JVET-P0059-v1, Joint Video Experts Team (JVET) of ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11 16th Meeting: Geneva, CH, 1-11 Oct. 2019</li>    <li id="ul0002-0007" num="0062">Non-Patent Document 7: TELECOMMUNICATION STANDARDIZATION SECTOR OF ITU (International Telecommunication Union), &#x201c;Advanced video coding for generic audiovisual services&#x201d;, H.264, April 2017</li>    <li id="ul0002-0008" num="0063">Non-Patent Document 8: TELECOMMUNICATION STANDARDIZATION SECTOR OF ITU (International Telecommunication Union), &#x201c;High efficiency video coding&#x201d;, H.265, December 2016</li></ul></p><p id="p-0057" num="0064">That is, the contents described in the above-mentioned non-patent documents are also the basis for determining the support requirements. For example, even in a case where the quad-tree block structure and the quad tree plus binary tree (QTBT) block structure described in the above-described non-patent documents are not directly described in the embodiments, they are within the scope of disclosure of the present technology and are assumed to satisfy the support requirements of the claims. Furthermore, for example, technical terms such as parsing, syntax, and semantics are also within the scope of disclosure of the present technology even in a case where there is no direct description in the embodiments, and are assumed to meet the support requirements of the claims.</p><p id="p-0058" num="0065">Furthermore, in the present description, a &#x201c;block&#x201d; (not a block indicating a processing unit) used in the description as a partial area of an image (picture) or a processing unit indicates any partial area in the picture unless otherwise specified, and does not limit its size, shape, characteristics, and the like. For example, the &#x201c;block&#x201d; includes any partial region (processing unit) such as a transform block (TB), a transform unit (TU), a prediction block (PB), a prediction unit (PU), a smallest coding unit (SCU), a coding unit (CU), a largest coding unit (LCU), a coding tree block (CTB), a coding tree unit (CTU), a transform block, a sub-block, a macroblock, a tile, or a slice described in the above-described non-patent document.</p><p id="p-0059" num="0066">Furthermore, upon specifying the size of such a block, not only the block size may be directly specified, but also the block size may be indirectly specified. For example, the block size may be specified using identification information that identifies the size. Furthermore, for example, the block size may be specified by a ratio or difference with the size of the reference block (for example, LCU, SCU, or the like). For example, in a case of transmitting information for specifying the block size as a syntax element or the like, information for indirectly specifying the size as described above may be used as this information. In this manner, the amount of information of the information can be reduced, and encoding efficiency may be improved. Furthermore, the specification of the block size also includes a specification of the range of the block size (for example, the specification of the range of an allowable block size, or the like).</p><p id="p-0060" num="0067">Furthermore, in the present description, encoding includes not only the entire process of transforming an image into a bit stream but also a part of the process. For example, the encoding includes not only processing including prediction processing, orthogonal transform, quantization, arithmetic coding, and the like, but also processing collectively including the quantization and the arithmetic coding, processing including the prediction processing, the quantization, and the arithmetic coding, and the like. Similarly, the decoding includes not only the entire process of transforming a bit stream into an image but also a part of the process. For example, the processing includes not only processing including inverse arithmetic decoding, inverse quantization, inverse orthogonal transform, prediction processing, and the like, but also processing including the inverse arithmetic decoding and the inverse quantization, processing including the inverse arithmetic decoding, the inverse quantization, and the prediction processing, and the like.</p><heading id="h-0011" level="1">2. TRANSFORM SKIP</heading><p id="p-0061" num="0068">&#x3c;Transform Skip of Luminance Component&#x3e;</p><p id="p-0062" num="0069">Conventionally, in encoding a still image and a moving image, an image input to an encoding device is generally a color image having a luminance component and a color component (which may include a chrominance component). In such image encoding, for example, as described in Non-Patent Document 1, a method of performing encoding by skipping (omitting) transform processing of transforming a residual between an image and a predicted image thereof into coefficient data for a luminance component has been considered.</p><p id="p-0063" num="0070">However, this transform skip mode cannot be applied to the color component. Accordingly, in screen content or the like in which transform skip is effective, encoding efficiency of color components may be reduced.</p><p id="p-0064" num="0071">&#x3c;Extension of Transform Skip Flag&#x3e;</p><p id="p-0065" num="0072">Accordingly, the transform skip is extended so that the transform skip can be set for each component (each luminance component and each color component), and the transform skip can be performed not only for the luminance component but also for the color component. For example, in a case of an image encoding and decoding method described in non-patent document described above, setting of skip can be indicated by a transform skip flag (transform_skip_flag). Furthermore, the component can be indicated by a component identifier (cIdx). Thus, for example, as in method 1 described in the top row of a table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the value of the transform skip flag is set in association with the value of the component identifier.</p><p id="p-0066" num="0073">For example, an image processing device includes a flag generation unit that generates a transform skip flag that is flag information indicating, for each component, whether or not to skip transform processing of transforming a residual between an image and a predicted image of the image into coefficient data in encoding of the image, a flag encoding unit that encodes the transform skip flag generated by the flag generation unit and generates coded data of the transform skip flag, and a bit stream generation unit that generates a bit stream including the coded data of the transform skip flag generated by the flag encoding unit.</p><p id="p-0067" num="0074">Furthermore, for example, at the time of generating a bit stream, a transform skip flag that is flag information indicating, for each component, whether or not to skip transform processing of transforming a residual between an image and a predicted image of the image into coefficient data in encoding of the image is generated, the generated transform skip flag is encoded, coded data of the transform skip flag is generated, and a bit stream including the coded data of the generated transform skip flag is generated.</p><p id="p-0068" num="0075">In this manner, the setting of the transform skip for each component can be provided to the decoding side. Therefore, in a case where the transform skip is applied to the color components, the decoding side can correctly decode the bit stream. Therefore, reduction in encoding efficiency can be suppressed as compared with a case where the transform skip can be applied only to the luminance components.</p><p id="p-0069" num="0076">Then, the transform skip flag may be acquired on the decoding side.</p><p id="p-0070" num="0077">For example, the image processing device may include a flag decoding unit that decodes coded data of a transform skip flag corresponding to a component identifier and obtains the transform skip flag corresponding to the component identifier.</p><p id="p-0071" num="0078">Furthermore, for example, when the coefficient data is generated, the coded data of the transform skip flag corresponding to the component identifier may be decoded to obtain the transform skip flag corresponding to the component identifier.</p><p id="p-0072" num="0079">In this manner, when decoding, the setting of the transform skip for each component indicated by the transform skip flag can be applied. Therefore, the bit stream of the color components to which the transform skip is applied can be correctly decoded. Therefore, reduction in encoding efficiency can be suppressed as compared with a case where the transform skip can be applied only to the luminance components.</p><p id="p-0073" num="0080">Furthermore, when encoding the image, transform processing of the color components may be controlled on the basis of the setting of the transform skip for each component by the above-described transform skip flag. That is, the transform skip may be applied to the transform processing of the color components. In this manner, reduction in encoding efficiency can be suppressed as compared with a case where the transform skip can be applied only to the luminance components.</p><p id="p-0074" num="0081">Similarly, at the time of decoding the coded data of the image, inverse transform processing of transforming the coefficient data of the color component into the residual between the image and the predicted image may be controlled on the basis of the setting of the transform skip for each component by the above-described transform skip flag. That is, the transform skip may be applied to the inverse transform processing of the color components. In this manner, the bit stream of the color components to which the transform skip is applied can be correctly decoded. Therefore, reduction in encoding efficiency can be suppressed as compared with a case where the transform skip can be applied only to the luminance components.</p><p id="p-0075" num="0082">Note that, as described above, by setting the transform skip for each component, it is possible to set the transform skip for the color components independently of the luminance components. Therefore, it is possible to set the transform skip for the color components according to whether or not the transform skip is valid for the color components. In this manner, reduction in encoding efficiency can be suppressed as compared with a case where setting of the transform skip for the luminance components is applied to the color components.</p><p id="p-0076" num="0083">&#x3c;Control of Encoding Mode&#x3e;</p><p id="p-0077" num="0084">Furthermore, in the case of the method described in Non-Patent Document 1, an encoding mode (decoding mode) of the coefficient data of the luminance components is controlled according to the presence or absence of the transform skip. For example, in a case where the transform skip is performed, the coefficient data of the luminance components is encoded in the TS residual encoding mode optimized for the coefficient data for which the transform skip has been performed (the coded data of the coefficient data of the luminance components is decoded in the TS residual decoding mode optimized to transform-skipped coefficient data). On the other hand, in a case where the transform skip is not performed, the coefficient data of the luminance components is encoded in the non-TS residual encoding mode optimized for the coefficient data on which the transform processing has been performed (the coded data of the coefficient data of the luminance components is decoded in the non-TS residual decoding mode optimized to the coefficient data on which the transform processing has been performed).</p><p id="p-0078" num="0085">However, since the transform skip is not applied to the chrominance components, such control of the encoding mode (decoding mode) has not been performed. Thus, in a case where the transform skip is applied to the color components as described above, the encoding efficiency may be reduced as compared with a case where such control of the encoding mode (decoding mode) is performed.</p><p id="p-0079" num="0086">Accordingly, in a case where the transform skip is applied to the color components as in the above-described method 1, such control of the encoding mode (decoding mode) may also be applied. For example, as in method 1-1 described in the second row from the top of the table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in a case where the transform skip is applied to each value of the identifier of the component, the TS residual encoding mode (TS residual decoding mode) may be applied as the encoding mode (decoding mode), and in a case where the transform skip is not applied (in a case of the non-transform skip), the non-TS residual encoding mode (non-TS residual decoding mode) may be applied as the encoding mode (decoding mode).</p><p id="p-0080" num="0087">For example, on the basis of the transform skip flag corresponding to a component identifier, whether an encoding mode of coefficient data corresponding to the component identifier is set to a TS residual encoding mode that is a mode for a case of skipping the transform processing or a non-TS residual encoding mode that is a mode for a case of not skipping the transform processing may be controlled, and coefficient data corresponding to the component identifier may be encoded by the encoding mode set as described above and generates coded data of the coefficient data.</p><p id="p-0081" num="0088">Furthermore, for example, on the basis of the transform skip flag corresponding to the component identifier, whether the decoding mode of the coded data of the coefficient data corresponding to the component identifier is set to the TS residual decoding mode that is a mode for a case of skipping the inverse transform processing of transforming the coefficient data into residuals between the image and the predicted image, or to the non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform processing may be controlled to decode the coded data of the coefficient data corresponding to the component identifier by the decoding mode set as described above, and to generate the coefficient data corresponding to the component identifier.</p><p id="p-0082" num="0089">In this manner, since the encoding mode (decoding mode) according to the setting of the transform skip can be applied, reduction in encoding efficiency can be suppressed as compared with a case where encoding (decoding) is performed in a single encoding mode (decoding mode).</p><p id="p-0083" num="0090">&#x3c;Transform Skip Residual Encoding Use Flag&#x3e;</p><p id="p-0084" num="0091">A flag indicating selection between the TS residual encoding mode (TS residual decoding mode) and the non-TS residual encoding mode (non-TS residual decoding mode) may be applied. For example, a residual encoding mode selection flag (also referred to as a transform skip residual encoding use flag) indicating selection setting of the encoding mode may be applied as in method 1-1-1 described in the third row from the top of the table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0085" num="0092">For example, when encoding, the transform skip residual encoding use flag that is flag information indicating whether to apply the TS residual encoding mode or the non-TS residual encoding mode may be generated, the transform skip residual encoding use flag may be encoded, and a bit stream including coded data of the transform skip residual encoding use flag may be generated.</p><p id="p-0086" num="0093">Furthermore, when decoding, the coded data of the transform skip residual encoding use flag may be decoded to generate the transform skip residual encoding use flag corresponding to the component identifier, and whether the decoding mode of the coded data of the coefficient data corresponding to the component identifier is set to the TS residual decoding mode or the non-TS residual decoding mode may be controlled on the basis of the transform skip residual encoding use flag corresponding to the component identifier.</p><p id="p-0087" num="0094">For example, such a transform skip residual encoding use flag may be set at a high level of a sequence parameter or the like. In this manner, even an encoder or a decoder that does not support the transform skip can correctly perform encoding and decoding on the basis of this flag. Therefore, reduction in encoding efficiency can be suppressed. In other words, implementation of the TS residual encoding mode (TS residual decoding mode) in the encoder and the decoder can be omitted, and increase in the circuit scale can be suppressed.</p><p id="p-0088" num="0095">&#x3c;Transform Skip Residual Encoding Use Specifying Mode Flag&#x3e;</p><p id="p-0089" num="0096">A flag indicating whether to apply the TS residual encoding mode (TS residual decoding mode) or to apply the non-TS residual encoding mode (non-TS residual decoding mode) in a specific mode may be applied. For example, as in method 1-1-2 described in the fourth row from the top of the table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a flag (also referred to as a transform skip residual encoding use specifying mode flag) that enables selection of the encoding mode in the specific mode may be applied.</p><p id="p-0090" num="0097">For example, when encoding, a transform skip residual encoding use specifying mode flag that is flag information indicating whether to apply the TS residual encoding mode or the non-TS residual encoding mode in a specific mode may be generated, the transform skip residual encoding use specifying mode flag may be encoded, and a bit stream including coded data of the transform skip residual encoding use specifying mode flag may be generated.</p><p id="p-0091" num="0098">Furthermore, when decoding, the coded data of the transform skip residual encoding use specifying mode flag may be decoded, the transform skip residual encoding use specifying mode flag corresponding to the component identifier may be generated, and whether the decoding mode of the coded data of the coefficient data corresponding to the component identifier is set to the TS residual decoding mode or the non-TS residual decoding mode may be controlled on the basis of the transform skip residual encoding use specifying mode flag corresponding to the component identifier.</p><p id="p-0092" num="0099">For example, such a transform skip residual encoding use specifying mode flag may be set at a high level such as a sequence parameter. This enables switching between the TS residual decoding mode and the non-TS residual decoding mode in a specific mode.</p><p id="p-0093" num="0100">Note that the foregoing method 1, method 1-1, method 1-1-1, and method 1-1-2 will be described later in the first embodiment.</p><p id="p-0094" num="0101">&#x3c;Correction of Quantization Parameter&#x3e;</p><p id="p-0095" num="0102">Non-Patent Document 3 proposes a method for clipping a quantization parameter QP applied to a luminance transform block to QP=4 or QP=QpPrimeTsMin (minimum TSQP) in a case of luminance transform skip, as a countermeasure against a possibility that a peak signal-to-noise ratio (PSNR) decreases when the quantization parameter QP&#x3c;4 in the luminance transform block to which the luminance transform skip is applied.</p><p id="p-0096" num="0103">In a case where the transform skip is applied to the color components, although there is similarly a possibility that the PSNR is reduced, conventionally the transform skip is not applied to the color components, and naturally such a point has not been considered.</p><p id="p-0097" num="0104">Accordingly, for example, as in method 1-2 described in the fifth row from the top of the table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the quantization parameter may be corrected in a case of the transform skip in each value of the component identifier. That is, in a case where the transform skip is applied, the quantization parameter may be corrected. Then, such control may be performed for each component.</p><p id="p-0098" num="0105">For example, the image processing device may include a quantization parameter correction unit that, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip in encoding an image, corrects a quantization parameter to be applied to a processing target transform block corresponding to the component identifier, and a quantization unit that performs quantization of the processing target transform block corresponding to the component identifier by using the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0099" num="0106">For example, in the quantization coefficient generation method, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip in encoding an image, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier may be corrected, quantization of the processing target transform block corresponding to the component identifier may be performed by using the quantization parameter corrected, and a quantization coefficient corresponding to the component identifier may be generated.</p><p id="p-0100" num="0107">For example, the image processing device may include a quantization parameter correction unit that, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip, corrects a quantization parameter to be applied to a processing target transform block corresponding to the component identifier, and an inverse quantization unit that performs inverse quantization of a processing target transform block corresponding to the component identifier by using the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0101" num="0108">For example, in a coefficient data generation method, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier may be corrected, and inverse quantization of a processing target transform block corresponding to the component identifier may be performed by using the corrected quantization parameter, and generates the coefficient data corresponding to the component identifier.</p><p id="p-0102" num="0109">In this manner, decrease in PSNR can be suppressed in the encoder or the decoder, or in both.</p><p id="p-0103" num="0110">Note that, for example, in encoding, in a case where the transform skip flag corresponding to the component identifier indicates the transform skip, one having a larger value of a minimum quantization parameter for the transform skip and a quantization parameter corresponding to the component identifier may be set as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier, and in a case where the transform skip flag corresponding to the component identifier indicates non-transform skip in which the transform skip is not performed, the quantization parameter corresponding to the component identifier may be set as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier.</p><p id="p-0104" num="0111">Furthermore, for example, in decoding, in a case where the transform skip flag corresponding to the component identifier indicates the transform skip, one having a larger value of a minimum quantization parameter for the transform skip and a quantization parameter corresponding to the component identifier may be set as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier, and in a case where the transform skip flag corresponding to the component identifier indicates non-transform skip in which the transform skip is not performed, the quantization parameter corresponding to the component identifier may be set as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier.</p><p id="p-0105" num="0112">In this manner, decrease in PSNR can be suppressed in the encoder or the decoder, or in both.</p><p id="p-0106" num="0113">Note that, for example, in decoding, coded data of the transform skip flag corresponding to the component identifier may be decoded, and in a case where the transform skip flag corresponding to the component identifier indicates the transform skip, the quantization parameter to be applied to the processing target transform block corresponding to the component identifier may be corrected.</p><p id="p-0107" num="0114">In this manner, the correction of the quantization parameter can be controlled on the basis of the transform skip flag corresponding to the encoded component identifier.</p><p id="p-0108" num="0115">The above method 1-2 will be described later in the second embodiment.</p><p id="p-0109" num="0116">&#x3c;Sharing of Context Variable&#x3e;</p><p id="p-0110" num="0117">Furthermore, as described above, in a case where the transform skip is introduced for the color components and the transform block of the color components to which the transform skip is applied is encoded by the TS residual encoding mode, if context variables independent of each other are used for the luminance components and the color components, it is necessary to newly add a context variable for the color components, and there is a possibility that the a memory capacity for holding the context variable increases and the cost of hardware increases.</p><p id="p-0111" num="0118">Accordingly, for example, as in method 1-3 described in the sixth row from the top of the table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in a case of the transform skip, the context variable corresponding to each binIdx in the bin row of each syntax may be shared between the luminance component and the color component.</p><p id="p-0112" num="0119">For example, in a case where the transform processing is skipped in encoding, a context variable may be shared between encoding of a luminance component of the coefficient data and encoding of a chrominance component.</p><p id="p-0113" num="0120">Furthermore, for example, in a case where the inverse transform processing is skipped in decoding, the context variable may be shared between decoding of coded data of the luminance component of the coefficient data and decoding of coded data of the chrominance component.</p><p id="p-0114" num="0121">In this manner, it is possible to suppress increase in memory size for holding the context variable. Therefore, it is possible to suppress increase in hardware cost.</p><p id="p-0115" num="0122">The above method 1-3 will be described later in the third embodiment.</p><p id="p-0116" num="0123">&#x3c;Control of Encoding-Decoding Mode of Sign Code&#x3e;</p><p id="p-0117" num="0124">Furthermore, for example, as in method 1-4 described in the seventh row from the top of the table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, an encoding and decoding method of a sign code may be switched according to the transform skip flag corresponding to the component identifier.</p><p id="p-0118" num="0125">For example, as in method 1-4-1 described in the eighth stage from the top of the table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in a case where the transform skip is not performed, bypass encoding-decoding may be applied to encoding-decoding of the sign code.</p><p id="p-0119" num="0126">Furthermore, for example, as in method 1-4-2 described in the ninth row from the top of the table in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in the case of transform skip, if the number of remaining context encoding bins is equal to or larger than a threshold, context encoding-decoding may be applied to encoding-decoding of the sign code, or otherwise, bypass encoding-decoding may be applied to encoding-decoding of the sign code.</p><p id="p-0120" num="0127">In this manner, reduction in encoding efficiency can be suppressed.</p><p id="p-0121" num="0128">The foregoing method 1-4, method 1-4-1, and method 1-4-2 will be described later in the fourth embodiment.</p><heading id="h-0012" level="1">3. FIRST EMBODIMENT</heading><p id="p-0122" num="0129">&#x3c;3-1. Image Encoding Device&#x3e;</p><p id="p-0123" num="0130">The present technology described above can be applied to arbitrary devices, devices, systems, and the like. For example, the above-described present technology can be applied to an image encoding device that encodes image data.</p><p id="p-0124" num="0131"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating an example of a configuration of an image encoding device that is one aspect of an image processing device to which the present technology is applied. The image encoding device <b>100</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a device that encodes image data of a moving image. For example, the image encoding device <b>100</b> implements the technology described in at least one of the above-described non-patent documents, and encodes the image data of the moving image by a method conforming to the standard described in any of the documents.</p><p id="p-0125" num="0132">Note that while <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates main elements such as processing units and data flows, the elements illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> do not necessarily include all elements. That is, in the image encoding device <b>100</b>, a processing unit not illustrated as a block in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may exist, and a process or data flow not illustrated as an arrow or the like in <figref idref="DRAWINGS">FIG. <b>2</b></figref> may exist. This similarly applies to other drawings describing a processing unit and the like in the image encoding device <b>100</b>.</p><p id="p-0126" num="0133">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the image encoding device <b>100</b> includes a control unit <b>101</b>, a rearrangement buffer <b>111</b>, an operation unit <b>112</b>, an orthogonal transform unit <b>113</b>, a quantization unit <b>114</b>, an encoding unit <b>115</b>, and an accumulation buffer <b>116</b>. Furthermore, the image encoding device <b>100</b> includes an inverse quantization unit <b>117</b>, an inverse orthogonal transform unit <b>118</b>, an operation unit <b>119</b>, an in-loop filter unit <b>120</b>, a frame memory <b>121</b>, a prediction unit <b>122</b>, and a rate control unit <b>123</b>.</p><p id="p-0127" num="0134">&#x3c;Control Unit&#x3e;</p><p id="p-0128" num="0135">The control unit <b>101</b> divides moving image data held by the rearrangement buffer <b>111</b> into blocks (CU, PU, transform block, and the like) in units of processing on the basis of a block size in units of processing specified outside or in advance. Furthermore, the control unit <b>101</b> determines encoding parameters (header information Hinfo, prediction mode information Pinfo, transform information Tinfo, filter information Finfo, and the like) to be supplied to each block on the basis of, for example, rate-distortion optimization (RDO). For example, the control unit <b>101</b> can set a transform skip flag or the like.</p><p id="p-0129" num="0136">Details of these encoding parameters will be described later. When determining the encoding parameters as described above, the control unit <b>101</b> supplies the encoding parameters to each block. Specifically, it is as follows.</p><p id="p-0130" num="0137">The header information Hinfo is supplied to each block. The prediction mode information Pinfo is supplied to the encoding unit <b>115</b> and the prediction unit <b>122</b>. The transform information Tinfo is supplied to the encoding unit <b>115</b>, the orthogonal transform unit <b>113</b>, the quantization unit <b>114</b>, the inverse quantization unit <b>117</b>, and the inverse orthogonal transform unit <b>118</b>. The filter information Finfo is supplied to the in-loop filter unit <b>120</b>.</p><p id="p-0131" num="0138">&#x3c;Rearrangement Buffer&#x3e;</p><p id="p-0132" num="0139">Each field (input image) of the moving image data is input to the image encoding device <b>100</b> in the reproduction order (display order). The rearrangement buffer <b>111</b> acquires and holds (stores) each input image in its reproduction order (display order). The rearrangement buffer <b>111</b> rearranges the input image in encoding order (decoding order) or divides the input image into blocks in units of processing on the basis of control of the control unit <b>101</b>. The rearrangement buffer <b>111</b> supplies each processed input image to the operation unit <b>112</b>.</p><p id="p-0133" num="0140">&#x3c;Operation Unit&#x3e;</p><p id="p-0134" num="0141">The operation unit <b>112</b> subtracts a predicted image P supplied from the prediction unit <b>122</b> from an image corresponding to the block of the processing unit supplied from the rearrangement buffer <b>111</b> to derive a predicted residual D, and supplies the predicted residual D to the orthogonal transform unit <b>113</b>.</p><p id="p-0135" num="0142">&#x3c;Orthogonal Transform Unit&#x3e;</p><p id="p-0136" num="0143">The orthogonal transform unit <b>113</b> uses the predicted residual supplied from the operation unit <b>112</b> and the transform information Tinfo supplied from the control unit <b>101</b> as inputs, and performs orthogonal transform on the predicted residual on the basis of the transform information Tinfo to derive a transform coefficient Coeff. The orthogonal transform unit <b>113</b> supplies the obtained transform coefficient to the quantization unit <b>114</b>.</p><p id="p-0137" num="0144">&#x3c;Quantization Unit&#x3e;</p><p id="p-0138" num="0145">The quantization unit <b>114</b> uses the transform coefficient supplied from the orthogonal transform unit <b>113</b> and the transform information Tinfo supplied from the control unit <b>101</b> as inputs, and scales (quantizes) the transform coefficient on the basis of the transform information Tinfo. Note that the quantization rate is controlled by the rate control unit <b>123</b>. The quantization unit <b>114</b> supplies a quantized transform coefficient (also referred to as a quantized transform coefficient level) level obtained by such quantization to the encoding unit <b>115</b> and the inverse quantization unit <b>117</b>.</p><p id="p-0139" num="0146">&#x3c;Encoding Unit&#x3e;</p><p id="p-0140" num="0147">The encoding unit <b>115</b> uses the quantized transform coefficient level supplied from the quantization unit <b>114</b>, various encoding parameters (the header information Hinfo, the prediction mode information Pinfo, the transform information Tinfo, the filter information Finfo, and the like) supplied from the control unit <b>101</b>, information regarding a filter such as a filter coefficient supplied from the in-loop filter unit <b>120</b>, and information regarding an optimum prediction mode supplied from the prediction unit <b>122</b> as inputs.</p><p id="p-0141" num="0148">The encoding unit <b>115</b> performs, for example, entropy encoding (lossless encoding) such as context-based adaptive binary arithmetic code (CABAC) or context-based adaptive variable length code (CAVLC) on the quantized transform coefficient level to generate a bit string (coded data).</p><p id="p-0142" num="0149">Furthermore, the encoding unit <b>115</b> derives residual information Rinfo from the quantized transform coefficient level, encodes the residual information Rinfo, and generates a bit string.</p><p id="p-0143" num="0150">Moreover, the encoding unit <b>115</b> includes information regarding the filter supplied from the in-loop filter unit <b>120</b> in the filter information Finfo, and includes information regarding the optimum prediction mode supplied from the prediction unit <b>122</b> in the prediction mode information Pinfo. Then, the encoding unit <b>115</b> encodes the above-described various encoding parameters (the header information Hinfo, the prediction mode information Pinfo, the transform information Tinfo, the filter information Finfo, and the like) to generate a bit string.</p><p id="p-0144" num="0151">Furthermore, the encoding unit <b>115</b> multiplexes the bit strings of various types of information generated as described above to generate coded data. The encoding unit <b>115</b> supplies the coded data to the accumulation buffer <b>116</b>.</p><p id="p-0145" num="0152">&#x3c;Accumulation Buffer&#x3e;</p><p id="p-0146" num="0153">The accumulation buffer <b>116</b> temporarily holds the coded data obtained by the encoding unit <b>115</b>. The accumulation buffer <b>116</b> outputs the held coded data to the outside of the image encoding device <b>100</b> as, for example, a bit stream or the like at a predetermined timing. For example, the coded data is transmitted to a decoding side via an arbitrary recording medium, an arbitrary transmission medium, an arbitrary information processing device, or the like. That is, the accumulation buffer <b>116</b> is also a transmission unit that transmits coded data (bit stream).</p><p id="p-0147" num="0154">&#x3c;Inverse quantization unit&#x3e;</p><p id="p-0148" num="0155">The inverse quantization unit <b>117</b> performs processing related to inverse quantization. For example, the inverse quantization unit <b>117</b> uses the quantized transform coefficient level level supplied from the quantization unit <b>114</b> and the transform information Tinfo supplied from the control unit <b>101</b> as inputs, and scales (inversely quantizes) the value of the quantized transform coefficient level on the basis of the transform information Tinfo. Note that this inverse quantization is inverse processing of the quantization performed in the quantization unit <b>114</b>. The inverse quantization unit <b>117</b> supplies a transform coefficient Coeff_IQ obtained by such inverse quantization to the inverse orthogonal transform unit <b>118</b>. Note that since the inverse quantization unit <b>117</b> is similar to the inverse quantization unit on the decoding side (described later), the description (described later) to be given for the decoding side can be applied to the inverse quantization unit <b>117</b>.</p><p id="p-0149" num="0156">&#x3c;Inverse Orthogonal Transform Unit&#x3e;</p><p id="p-0150" num="0157">The inverse orthogonal transform unit <b>118</b> performs processing related to inverse orthogonal transform. For example, the inverse orthogonal transform unit <b>118</b> uses the transform coefficient supplied from the inverse quantization unit <b>117</b> and the transform information Tinfo supplied from the control unit <b>101</b> as inputs, and performs inverse orthogonal transform on the transform coefficient on the basis of the transform information Tinfo to derive a predicted residual D&#x2032;. Note that this inverse orthogonal transform is inverse processing of the orthogonal transform performed by the orthogonal transform unit <b>113</b>. The inverse orthogonal transform unit <b>118</b> supplies the predicted residual obtained by such inverse orthogonal transform to the operation unit <b>119</b>. Note that since the inverse orthogonal transform unit <b>118</b> is similar to an inverse orthogonal transform unit on the decoding side (described later), a description (described later) to be given for the decoding side can be applied to the inverse orthogonal transform unit <b>118</b>.</p><p id="p-0151" num="0158">&#x3c;Operation Unit&#x3e;</p><p id="p-0152" num="0159">The operation unit <b>119</b> uses the predicted residual D&#x2032; supplied from the inverse orthogonal transform unit <b>118</b> and the predicted image P supplied from the prediction unit <b>122</b> as inputs. The operation unit <b>119</b> adds the predicted residual and the predicted image corresponding to the predicted residual to derive a locally decoded image. The operation unit <b>119</b> supplies the derived locally decoded image to the in-loop filter unit <b>120</b> and the frame memory <b>121</b>.</p><p id="p-0153" num="0160">&#x3c;In-Loop Filter Unit&#x3e;</p><p id="p-0154" num="0161">The in-loop filter unit <b>120</b> performs processing related to an in-loop filter process. For example, the in-loop filter unit <b>120</b> uses the locally decoded image supplied from the operation unit <b>119</b>, the filter information Finfo supplied from the control unit <b>101</b>, and the input image (original image) supplied from the rearrangement buffer <b>111</b> as inputs. Note that the information input to the in-loop filter unit <b>120</b> is arbitrary, and information other than these pieces of information may be input. For example, a prediction mode, motion information, a code amount target value, a quantization parameter QP, a picture type, information of a block (CU, CTU, and the like), and the like may be input to the in-loop filter unit <b>120</b> as necessary.</p><p id="p-0155" num="0162">The in-loop filter unit <b>120</b> appropriately performs the filter process on the locally decoded image on the basis of the filter information Finfo. The in-loop filter unit <b>120</b> also takes the input image (original image) and other input information for the filter process as necessary.</p><p id="p-0156" num="0163">For example, as described in Non-Patent Document 1, the in-loop filter unit <b>120</b> can apply four in-loop filters of a bilateral filter, a deblocking filter (DBF), an adaptive offset filter (sample adaptive offset (SAO)), and an adaptive loop filter (ALF) in this order. Note that which filter is applied and in which order the filter is applied are arbitrary and can be selected as appropriate.</p><p id="p-0157" num="0164">Of course, the filter process performed by the in-loop filter unit <b>120</b> is arbitrary and is not limited to the above example. For example, the in-loop filter unit <b>120</b> may apply a Wiener filter or the like.</p><p id="p-0158" num="0165">The in-loop filter unit <b>120</b> supplies the locally decoded image subjected to the filter process to the frame memory <b>121</b>. Note that, for example, in a case where information regarding the filter, such as the filter coefficient, is transmitted to the decoding side, the in-loop filter unit <b>120</b> supplies the information regarding the filter to the encoding unit <b>115</b>.</p><p id="p-0159" num="0166">&#x3c;Frame Memory&#x3e;</p><p id="p-0160" num="0167">The frame memory <b>121</b> performs processing related to storage of data related to an image. For example, the frame memory <b>121</b> takes the locally decoded image supplied from the operation unit <b>119</b> or the locally decoded image subjected to the filter process supplied from the in-loop filter unit <b>120</b> as an input, and holds (stores) the locally decoded image. Furthermore, the frame memory <b>121</b> reconstructs and holds a decoded image in each picture unit using the locally decoded image (stores the decoded image in a buffer in the frame memory <b>121</b>). The frame memory <b>121</b> supplies the decoded image (or a part thereof) to the prediction unit <b>122</b> in response to a request from the prediction unit <b>122</b>.</p><p id="p-0161" num="0168">&#x3c;Prediction Unit&#x3e;</p><p id="p-0162" num="0169">The prediction unit <b>122</b> performs processing related to generation of a predicted image. For example, the prediction unit <b>122</b> uses the prediction mode information Pinfo supplied from the control unit <b>101</b>, the input image (original image) supplied from the rearrangement buffer <b>111</b>, and the decoded image (or a part thereof) read from the frame memory <b>121</b> as inputs. The prediction unit <b>122</b> performs prediction processing such as inter prediction or intra prediction using the prediction mode information Pinfo and the input image (original image), performs prediction with reference to the decoded image as a reference image, performs motion compensation processing on the basis of the prediction result, and generates a predicted image. The prediction unit <b>122</b> supplies the generated predicted image to the operation unit <b>112</b> and the operation unit <b>119</b>. Furthermore, the prediction unit <b>122</b> supplies information regarding the prediction mode selected by the above processing, that is, the optimum prediction mode, to the encoding unit <b>115</b> as necessary.</p><p id="p-0163" num="0170">&#x3c;Rate Control Unit&#x3e;</p><p id="p-0164" num="0171">The rate control unit <b>123</b> performs processing related to rate control. For example, the rate control unit <b>123</b> controls the rate of the quantization operation of the quantization unit <b>114</b> so that overflow or underflow does not occur on the basis of the code amount of the coded data accumulated in the accumulation buffer <b>116</b>.</p><p id="p-0165" num="0172">&#x3c;Encoding Unit&#x3e;</p><p id="p-0166" num="0173"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating a main configuration example of the encoding unit <b>115</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the encoding unit <b>115</b> includes a transform mode information encoding unit <b>150</b>, a control unit <b>151</b>, a selection unit <b>152</b>, a TS residual encoding unit <b>153</b>, a non-TS residual encoding unit <b>154</b>, and a selection unit <b>155</b>.</p><p id="p-0167" num="0174">The transform mode information encoding unit <b>150</b> performs processing related to encoding of the transform mode information (transform_mode). This transform mode information is information regarding a mode of transform processing by the orthogonal transform unit <b>113</b>. For example, the transform mode information may include a transform skip flag (transform_skip_flag[xTbY][yTbY][cIdx]), an identifier related to primary transform (mts_idx[xTbY][yTbY][cIdx]), and the like.</p><p id="p-0168" num="0175">For example, the transform mode information encoding unit <b>150</b> can acquire the transform mode information supplied from the control unit <b>101</b>. Furthermore, the transform mode information encoding unit <b>150</b> can encode the acquired transform mode information and generate coded data of the transform mode information. Moreover, the transform mode information encoding unit <b>150</b> can supply the coded data of the generated transform mode information to the accumulation buffer <b>116</b> (that is, can provide the coded data to the decoding side).</p><p id="p-0169" num="0176">The control unit <b>151</b> performs processing related to control of the encoding mode. For example, the control unit <b>151</b> can acquire the transform mode information ((transform_skip_flag[xTbY][yTbY][cIdx]), mts_idx[xTbY][yTbY][cIdx], and the like) and the component identifier (cIdx) supplied from the control unit <b>101</b>. Furthermore, the control unit <b>151</b> can switch between the TS residual encoding mode and the non-TS residual encoding mode as the encoding mode of the coefficient data (quantization coefficient) by controlling selection of the selection unit <b>152</b> or the selection unit <b>155</b> on the basis of the transform skip flag corresponding to the component identifier. For example, in a case where the transform skip is applied, the control unit <b>151</b> connects the selection unit <b>152</b> and the selection unit <b>155</b> to the TS residual encoding unit <b>153</b>. Furthermore, for example, in a case where the transform skip is not applied (in a case where the transform processing is performed), the control unit <b>151</b> connects the selection unit <b>152</b> and the selection unit <b>155</b> to the non-TS residual encoding unit <b>154</b>.</p><p id="p-0170" num="0177">The selection unit <b>152</b> performs processing related to selection of a supply destination of the coefficient data (quantization coefficient). For example, the selection unit <b>152</b> can acquire the quantization coefficient supplied from the quantization unit <b>114</b>. Furthermore, under control of the control unit <b>151</b>, the selection unit <b>152</b> can supply the acquired quantization coefficient to the TS residual encoding unit <b>153</b> or the non-TS residual encoding unit <b>154</b> (the one designated by the control unit <b>151</b>). For example, in a case where the transform skip is applied, the selection unit <b>152</b> supplies the quantization coefficient to the TS residual encoding unit <b>153</b>. Furthermore, for example, in a case where the transform skip is not applied (in a case where the transform processing is performed), the selection unit <b>152</b> supplies the quantization coefficient to the non-TS residual encoding unit <b>154</b>.</p><p id="p-0171" num="0178">The TS residual encoding unit <b>153</b> performs processing related to a TS residual encoding mode. For example, the TS residual encoding unit <b>153</b> can acquire the quantization coefficient supplied from the selection unit <b>152</b>. Furthermore, the TS residual encoding unit <b>153</b> can encode the acquired quantization coefficient in the TS residual encoding mode. The TS residual encoding mode is an encoding mode for a case of skipping the transform processing. For example, encoding in the TS residual encoding mode is optimized for the coefficient data from which the transform processing is skipped, for example, scanning is performed from the DC component of the coefficient data toward a high frequency component, or position information of a last coefficient is not transmitted to the decoding side. A more specific technique of the TS residual encoding mode is described in Non-Patent Document 4 and the like. The TS residual encoding unit <b>153</b> can encode the quantization coefficient in this manner and generate coded data of the quantization coefficient. The TS residual encoding unit <b>153</b> can supply the coded data generated in this manner to the selection unit <b>155</b>.</p><p id="p-0172" num="0179">The non-TS residual encoding unit <b>154</b> performs processing related to the non-TS residual encoding mode. For example, the non-TS residual encoding unit <b>154</b> can acquire the quantization coefficient supplied from the selection unit <b>152</b>. Furthermore, the non-TS residual encoding unit <b>154</b> can encode the acquired quantization coefficient in the non-TS residual encoding mode. The non-TS residual encoding mode is an encoding mode for a case of performing transform processing. For example, the encoding in the non-TS residual encoding mode is optimized for the coefficient data on which the transform processing has been performed such that scanning is performed from the last coefficient of the coefficient data toward the DC component, or the position information of the last coefficient is transmitted to the decoding side. A more specific technique of the non-TS residual encoding mode is described in Non-Patent Document 4 and the like. The non-TS residual encoding unit <b>154</b> can encode the quantization coefficient in this manner and generate coded data of the quantization coefficient. The non-TS residual encoding unit <b>154</b> can supply the coded data generated in this manner to the selection unit <b>155</b>.</p><p id="p-0173" num="0180">The selection unit <b>155</b> performs processing related to selection of a supply source of coded data. For example, the selection unit <b>155</b> can acquire the coded data supplied from the TS residual encoding unit <b>153</b> or the non-TS residual encoding unit <b>154</b> (the one designated by the control unit <b>151</b>). For example, in a case where the transform skip is applied, the selection unit <b>155</b> acquires the coded data supplied from the TS residual encoding unit <b>153</b>. Furthermore, for example, in a case where the transform skip is not applied (in a case where the transform processing is performed), the selection unit <b>155</b> acquires the coded data supplied from the non-TS residual encoding unit <b>154</b>. The selection unit <b>155</b> can supply the coded data acquired in this manner to the accumulation buffer <b>116</b> (that is, can provide the coded data to the decoding side).</p><p id="p-0174" num="0181">&#x3c;Transform Skip of Respective Components&#x3e;</p><p id="p-0175" num="0182">The image encoding device <b>100</b> can encode a color image having luminance components and color components. Then, the image encoding device <b>100</b> can perform the encoding by skipping (omitting) the transform processing of transforming the residual between the image and the predicted image thereof into coefficient data not only for the luminance components but also for the color components.</p><p id="p-0176" num="0183">For example, the control unit <b>101</b> can set the transform skip flag (transform_skip_flag) indicating whether or not to apply the transform skip for each component. The component can be indicated by a component identifier (cIdx). That is, the control unit <b>101</b> can set the value of the transform skip flag in association with the value of the component identifier.</p><p id="p-0177" num="0184">That is, the control unit <b>101</b> can generate the transform skip flag (transform_skip_flag[xTbY][yTbY][cIdx]) indicating, for each component (cIdx), whether or not to skip the transform processing of transforming the residual between the image to be encoded and the predicted image thereof into coefficient data. Furthermore, the transform mode information encoding unit <b>150</b> of the encoding unit <b>115</b> can encode the transform skip flag generated by the control unit <b>101</b> and generate the coded data of the transform skip flag. Moreover, the accumulation buffer <b>116</b> can generate a bit stream including the coded data of the transform skip flag generated by the transform mode information encoding unit <b>150</b> and output the bit stream to the outside of the image encoding device <b>100</b>.</p><p id="p-0178" num="0185">In this manner, for example, the control unit <b>101</b> can set the transform skip flag for the color components, and can also apply the transform skip to the color components. Furthermore, the image encoding device <b>100</b> can provide the generated transform skip flag (that is, setting of the transform skip for each component) to the decoding side. Therefore, in a case where the transform skip is applied to the color components, the decoding side can correctly decode the bit stream. Therefore, reduction in encoding efficiency can be suppressed as compared with a case where the transform skip can be applied only to the luminance components.</p><p id="p-0179" num="0186">Furthermore, the image encoding device <b>100</b> may control the transform processing of the color components on the basis of the setting of the transform skip for each component by the above-described transform skip flag. For example, the orthogonal transform unit <b>113</b> may control the transform skip for each component on the basis of the transform skip flag generated by the control unit <b>101</b>. In this manner, the orthogonal transform unit <b>113</b> can apply the transform skip to the transform processing of the color components, for example.</p><p id="p-0180" num="0187">Note that, as described above, by setting the transform skip for each component, the control unit <b>101</b> can set the transform skip for each of the color components independently of the luminance components. Therefore, the control unit <b>101</b> can set the transform skip for the color components according to whether or not the transform skip for the color components is valid. Thus, the orthogonal transform unit <b>113</b> can perform the transform skip on the color components independently of the luminance components. In this manner, reduction in encoding efficiency can be suppressed as compared with a case where setting of the transform skip for the luminance components is applied to the color components.</p><p id="p-0181" num="0188">&#x3c;Control of Encoding Mode&#x3e;</p><p id="p-0182" num="0189">Furthermore, the encoding unit <b>115</b> may control the encoding mode of the coefficient data corresponding to the component identifiers on the basis of the transform skip flag corresponding to the component identifiers. For example, the control unit <b>151</b>, the selection unit <b>152</b>, and the selection unit <b>155</b> of the encoding unit <b>115</b> may control whether to set the TS residual encoding mode or the non-TS residual encoding mode on the basis of the transform skip flag. For example, the TS residual encoding unit <b>153</b> and the non-TS residual encoding unit <b>154</b> may encode the coefficient data corresponding to the component identifiers by the encoding mode set as described above, and generate the coded data of the coefficient data.</p><p id="p-0183" num="0190">That is, a plurality of encoding modes having different characteristics is prepared as candidates, and the encoding unit <b>115</b> selects and applies an encoding mode from the plurality of prepared candidates on the basis of the transform skip flag corresponding to the component identifiers. That is, the encoding unit <b>115</b> encodes the coefficient data in the selected encoding mode. In this manner, the encoding unit <b>115</b> can apply the encoding mode having characteristics more suitable for the setting of the transform skip among the encoding modes having different characteristics from each other, and thus it is possible to suppress reduction in encoding efficiency as compared with the case of performing encoding in a single encoding mode.</p><p id="p-0184" num="0191">&#x3c;Flow of Image Encoding Processing&#x3e;</p><p id="p-0185" num="0192">Next, a flow of each processing executed by the image encoding device <b>100</b> as described above will be described. First, an example of a flow of image encoding processing will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0186" num="0193">When the image encoding processing is started, in step S<b>101</b>, the rearrangement buffer <b>111</b> is controlled by the control unit <b>101</b> to rearrange the order of the frames of the input moving image data from the display order to the encoding order.</p><p id="p-0187" num="0194">In step S<b>102</b>, the control unit <b>101</b> sets a processing unit (performs block division) for the input image held by the rearrangement buffer <b>111</b>.</p><p id="p-0188" num="0195">In step S<b>103</b>, the control unit <b>101</b> determines (sets) the encoding parameters for the input image held by the rearrangement buffer <b>111</b>.</p><p id="p-0189" num="0196">In step S<b>104</b>, the control unit <b>101</b> generates the transform mode information (transform_mode) of the transform block corresponding to the component identifier (cIdx).</p><p id="p-0190" num="0197">In step S<b>105</b>, the prediction unit <b>122</b> performs the prediction processing and generates a predicted image or the like in an optimum prediction mode. For example, in the prediction processing, the prediction unit <b>122</b> performs intra prediction to generate a predicted image or the like in an optimum intra prediction mode, performs inter prediction to generate a predicted image or the like in an optimum inter prediction mode, and selects the optimum prediction mode from the predicted images on the basis of a cost function value or the like.</p><p id="p-0191" num="0198">In step S<b>106</b>, the operation unit <b>112</b> calculates a difference between the input image and the predicted image in the optimum mode selected by the prediction processing in step S<b>105</b>. That is, the operation unit <b>112</b> generates the predicted residual D between the input image and the predicted image. The predicted residual D obtained in this manner has a smaller data amount than the original image data. Therefore, the amount of data can be compressed as compared with a case where an image is encoded as it is.</p><p id="p-0192" num="0199">In step S<b>107</b>, the orthogonal transform unit <b>113</b> performs orthogonal transform processing on the predicted residual D generated by the processing of step S<b>106</b> according to the transform mode information generated in step S<b>104</b>, and derives the transform coefficient Coeff.</p><p id="p-0193" num="0200">In step S<b>108</b>, the quantization unit <b>114</b> quantizes the transform coefficient Coeff obtained by the processing of step S<b>107</b> by using the quantization parameter calculated by the control unit <b>101</b>, or the like, and derives the quantized transform coefficient level level.</p><p id="p-0194" num="0201">In step S<b>109</b>, the inverse quantization unit <b>117</b> inversely quantizes the quantized transform coefficient level level generated by the processing of step S<b>108</b> with a characteristic corresponding to the quantization characteristic in step S<b>108</b> to derive the transform coefficient Coeff_IQ.</p><p id="p-0195" num="0202">In step S<b>110</b>, the inverse orthogonal transform unit <b>118</b> inversely orthogonally transforms the transform coefficient Coeff_IQ obtained by the processing of S<b>109</b> according to the transform mode information generated in step S<b>104</b> by a method corresponding to the orthogonal transform processing of step S<b>107</b>, and derives the predicted residual D&#x2032;. Note that since the inverse orthogonal transform processing is similar to the inverse orthogonal transform processing (described later) performed on the decoding side, the description (described later) performed on the decoding side can be applied to the inverse orthogonal transform processing in step S<b>110</b>.</p><p id="p-0196" num="0203">In step S<b>111</b>, the operation unit <b>119</b> adds the predicted image obtained by the prediction processing of step S<b>105</b> to the predicted residual D&#x2032; derived by the processing of step S<b>110</b>, thereby generating a decoded image that is locally decoded.</p><p id="p-0197" num="0204">In step S<b>112</b>, the in-loop filter unit <b>120</b> performs the in-loop filter process on the decoded image that is locally decoded and derived by the processing of step S<b>111</b>.</p><p id="p-0198" num="0205">In step S<b>113</b>, the frame memory <b>121</b> stores the decoded image that is locally decoded and derived by the processing of step S<b>111</b> and the decoded image that is locally decoded and subjected to the filter process in step S<b>112</b>.</p><p id="p-0199" num="0206">In step S<b>114</b>, the encoding unit <b>115</b> encodes the quantized transform coefficient level level obtained by the processing of step S<b>108</b> and the transform mode information generated in step S<b>104</b>. For example, the encoding unit <b>115</b> encodes the quantized transform coefficient level level, which is information regarding the image, by arithmetic coding or the like to generate coded data. Furthermore, at this time, the encoding unit <b>115</b> encodes various encoding parameters (the header information Hinfo, the prediction mode information Pinfo, and the transform information Tinfo). Moreover, the encoding unit <b>115</b> derives the residual information RInfo from the quantized transform coefficient level level, and encodes the residual information RInfo.</p><p id="p-0200" num="0207">In step S<b>115</b>, the accumulation buffer <b>116</b> accumulates the coded data obtained in this manner, and outputs the coded data to the outside of the image encoding device <b>100</b> as, for example, a bit stream. This bit stream is transmitted to the decoding side via a transmission path or a recording medium, for example.</p><p id="p-0201" num="0208">In step S<b>116</b>, the rate control unit <b>123</b> performs rate control as necessary.</p><p id="p-0202" num="0209">When the processing of step S<b>116</b> ends, the image encoding processing ends.</p><p id="p-0203" num="0210">&#x3c;Flow of Encoding Processing&#x3e;</p><p id="p-0204" num="0211">Next, an example of a flow of encoding processing executed in step S<b>114</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p><p id="p-0205" num="0212">When the encoding processing is started, the transform mode information encoding unit <b>150</b> of the encoding unit <b>115</b> encodes the transform mode information (transform_mode) of the transform block corresponding to the component identifier cIdx in step S<b>151</b>.</p><p id="p-0206" num="0213">In step S<b>152</b>, the control unit <b>151</b> derives Condition1 by the following Expression (1). That is, the control unit <b>151</b> generates Condition1 by using the transform skip flag (transform_skip_flag[cIdx]) corresponding to the components. Note that, in the transform skip flag (transform_skip_flag[cIdx]), there is a case where the coordinates (xTbY, yTbY) of a processing target block are also written (for example, transform_skip_flag[xTbY][yTbY][cIdx]), but description thereof is omitted here for convenience. Hereinafter, description will be appropriately omitted.</p><p id="p-0207" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Condition1=(transform_skip_flag[cId<i>x</i>]==&#x201c;IS_SKIP&#x201d;)&#x2003;&#x2003; (1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0208" num="0214">In step S<b>153</b>, the control unit <b>151</b> determines whether or not this Condition1 is true. In a case where Condition1 is true, the transform skip flag (transform_skip_flag[cIdx]) corresponding to the component is true (IS_SKIP). Thus, the selection unit <b>152</b> and the selection unit <b>155</b> are connected to the TS residual encoding unit <b>153</b> under control of the control unit <b>151</b>. Consequently, the process proceeds to step S<b>154</b>.</p><p id="p-0209" num="0215">In step S<b>154</b>, the TS residual encoding unit <b>153</b> encodes the quantization coefficient in the TS residual encoding mode to generate coded data. When the coded data is generated, the encoding processing ends.</p><p id="p-0210" num="0216">Furthermore, in step S<b>153</b>, in a case where Condition1 is false, the transform skip flag (transform_skip_flag[cIdx]) corresponding to the component is false. Therefore, the selection unit <b>152</b> and the selection unit <b>155</b> are connected to the non-TS residual encoding unit <b>154</b> under control of the control unit <b>151</b>. Thus, the processing proceeds to step S<b>155</b>.</p><p id="p-0211" num="0217">In step S<b>155</b>, the non-TS residual encoding unit <b>154</b> encodes the quantization coefficient in the non-TS residual encoding mode to generate coded data. When the coded data is generated, the encoding processing ends.</p><p id="p-0212" num="0218">By performing each processing as described above, the image encoding device <b>100</b> can apply the TS residual encoding mode also to the color components, and reduction in encoding efficiency can be suppressed.</p><p id="p-0213" num="0219">Note that, in the above description, it has been described that notification of whether or not the transform skip is performed is provided by the transform skip flag (transform_skip_flag) but it is not limited to this, and notification of the mode may be provided as one mode of the identifier mts_idx related to the primary transform. The identifier mts_idx is an identifier indicating transform types in the horizontal direction and the vertical direction of the primary transform. In this case, the control unit <b>151</b> can derive Condition1 as in the following Expression (2).</p><p id="p-0214" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Condition1=(<i>mts</i>_<i>idx</i>[cId<i>x</i>]=&#x201c;IS_SKIP&#x201d;)&#x2003;&#x2003; (2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0215" num="0220">&#x3c;3-2. Image Decoding Device&#x3e;</p><p id="p-0216" num="0221"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating an example of a configuration of an image decoding device that is one aspect of the image processing device to which the present technology is applied. The image decoding device <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a device that decodes coded data in which a predicted residual between an image and a predicted image thereof is encoded, such as AVC or HEVC. For example, the image decoding device <b>200</b> implements the technology described in the above-described non-patent documents, and can decode coded data obtained by encoding image data of a moving image by a method conforming to a standard described in any of these non-patent documents. For example, the image decoding device <b>200</b> can decode the coded data (bit stream) generated by the above-described image encoding device <b>100</b>.</p><p id="p-0217" num="0222">Note that while <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates main elements such as a processing unit and a flow of data, the elements illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> do not necessarily include all elements. That is, in the image decoding device <b>200</b>, there may be a processing unit not illustrated as a block in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, or there may be processing or a data flow not illustrated as an arrow or the like in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. This similarly applies to other drawings describing a processing unit and the like in the image decoding device <b>200</b>.</p><p id="p-0218" num="0223">In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the image decoding device <b>200</b> includes an accumulation buffer <b>211</b>, a decoding unit <b>212</b>, an inverse quantization unit <b>213</b>, an inverse orthogonal transform unit <b>214</b>, an operation unit <b>215</b>, an in-loop filter unit <b>216</b>, a rearrangement buffer <b>217</b>, a frame memory <b>218</b>, and a prediction unit <b>219</b>. Note that the prediction unit <b>219</b> includes an intra prediction unit and an inter prediction unit (not illustrated).</p><p id="p-0219" num="0224">&#x3c;Accumulation Buffer&#x3e;</p><p id="p-0220" num="0225">The accumulation buffer <b>211</b> acquires and holds (stores) the bit stream input to the image decoding device <b>200</b>. The accumulation buffer <b>211</b> extracts coded data included in the accumulated bit stream at a predetermined timing or in a case where a predetermined condition is satisfied, or the like, and supplies the coded data to the decoding unit <b>212</b>.</p><p id="p-0221" num="0226">&#x3c;Decoding Unit&#x3e;</p><p id="p-0222" num="0227">The decoding unit <b>212</b> performs processing related to image decoding. For example, the decoding unit <b>212</b> uses the coded data supplied from the accumulation buffer <b>211</b> as an input, performs entropy decoding (lossless decoding) on a syntax value of each syntax element from the bit string according to the definition of the syntax table to derive parameters.</p><p id="p-0223" num="0228">The syntax element and the parameters derived from the syntax value of the syntax element include, for example, the header information Hinfo, the prediction mode information Pinfo, the transform information Tinfo, the residual information Rinfo, the filter information Finfo, and the like. That is, the decoding unit <b>212</b> parses (analyzes and acquires) these pieces of information from the bit stream. These pieces of information will be described below.</p><p id="p-0224" num="0229">&#x3c;Header information Hinfo&#x3e;</p><p id="p-0225" num="0230">The header information Hinfo includes, for example, header information such as video parameter set (VPS)/sequence parameter set (SPS)/picture parameter set (PPS)/picture header (PH)/slice header (SH). The header information Hinfo includes, for example, information defining an image size (horizontal width PicWidth and vertical width PicHeight), a bit depth (luminance bitDepthY and chrominance bitDepthC), a chrominance array type ChromaArrayType, a maximum value MaxCUSize and a minimum value MinCUSize of a CU size, a maximum depth MaxQTDepth and a minimum depth MinQTDepth of quad-tree separation (also referred to as quad-tree division), a maximum depth MaxBTDepth and a minimum depth MinBTDepth of binary-tree division (binary-tree division), a maximum value MaxTSSize of a transform skip block (also referred to as a maximum transform skip block size), an on-off flag (also referred to as a valid flag) of each encoding tool, and the like.</p><p id="p-0226" num="0231">For example, as the on-off flag of the encoding tool included in the header information Hinfo, there is an on-off flag related to the following transform and quantization processing. Note that the on-off flag of the encoding tool can also be interpreted as a flag indicating whether or not syntax related to the encoding tool exists in the coded data. Furthermore, in a case where the value of the on-off flag is one (true), it is indicated that the encoding tool can be used, and in a case where the value of the on-off flag is zero (false), it is indicated that the encoding tool cannot be used. Note that the interpretation of the flag value may be reversed.</p><p id="p-0227" num="0232">An inter-component prediction enabled flag (ccp_enabled_flag): is flag information indicating whether or not inter-component prediction (cross-component prediction (CCP), also referred to as CC prediction) can be used. For example, in a case where the flag information is &#x201c;1&#x201d; (true), it is indicated that the flag information can be used, and in a case where the flag information is &#x201c;0&#x201d; (false), it is indicated that the flag information cannot be used.</p><p id="p-0228" num="0233">Note that this CCP is also referred to as inter-component linear prediction (CCLM or CCLMP).</p><p id="p-0229" num="0234">&#x3c;Prediction Mode Information Pinfo&#x3e;</p><p id="p-0230" num="0235">The prediction mode information Pinfo includes, for example, information such as size information PBSize (predicted block size) of the processing target PB (predicted block), intra prediction mode information IPinfo, and motion prediction information MVinfo.</p><p id="p-0231" num="0236">The intra prediction mode information IPinfo includes, for example, prev_intra_luma_pred_flag, mpm_idx, and rem_intra_pred_mode in JCTVC-W1005, 7.3.8.5 Coding Unit syntax, a luminance intra prediction mode IntraPredModeY derived from the syntax, and the like.</p><p id="p-0232" num="0237">Furthermore, the intra prediction mode information IPinfo includes, for example, an inter-component prediction flag (ccp_flag(cclmp_flag)), a multi-class linear prediction mode flag (mclm_flag), a chrominance sample position type identifier (chroma_sample_loc_type_idx), a chrominance MPM identifier (chroma_mpm_idx), a luminance intra prediction mode (IntraPredModeC) derived from these syntaxes, and the like.</p><p id="p-0233" num="0238">The inter-component prediction flag (ccp_flag(cclmp_flag)) is flag information indicating whether or not to apply the inter-component linear prediction. For example, when ccp_flag==1, it is indicated that the inter-component prediction is applied, and when ccp_flag==0, it is indicated that the inter-component prediction is not applied.</p><p id="p-0234" num="0239">The multi-class linear prediction mode flag (mclm_flag) is information (linear prediction mode information) regarding a mode of linear prediction. More specifically, the multi-class linear prediction mode flag (mclm_flag) is flag information indicating whether or not to set the multi-class linear prediction mode. For example, in a case of &#x201c;0&#x201d;, a one-class mode (single-class mode) (for example, CCLMP) is indicated, and in a case of &#x201c;1&#x201d;, a two-class mode (multi-class mode) (for example, MCLMP) is indicated.</p><p id="p-0235" num="0240">The chrominance sample position type identifier (chroma_sample_loc_type_idx) is an identifier that identifies a type (also referred to as a chrominance sample position type) of a pixel position of the chrominance component.</p><p id="p-0236" num="0241">Note that this chrominance sample position type identifier (chroma_sample_loc_type_idx) is transmitted as (stored in) information regarding the pixel position of the chrominance component (chroma_sample_loc_info( )).</p><p id="p-0237" num="0242">The chrominance MPM identifier (chroma_mpm_idx) is an identifier indicating which prediction mode candidate in the chrominance intra prediction mode candidate list (intraPredModeCandListC) is designated as the chrominance intra prediction mode.</p><p id="p-0238" num="0243">The motion prediction information MVinfo includes, for example, information such as merge_idx, merge_flag, inter_pred_idc, ref_idx_LX,_mvp_1X_flag, X={0, 1}, and mvd (see, for example, JCTVC-W1005, 7.3.8.6 Prediction Unit Syntax).</p><p id="p-0239" num="0244">Of course, the information included in the prediction mode information Pinfo is arbitrary, and information other than these pieces of information may be included.</p><p id="p-0240" num="0245">&#x3c;Transform Information Tinfo&#x3e;</p><p id="p-0241" num="0246">The transform information Tinfo includes, for example, the following information. Of course, the information included in the transform information Tinfo is arbitrary, and information other than these pieces of information may be included.</p><p id="p-0242" num="0247">The horizontal width size TBWSize and the vertical width TBHSize (or a logarithmic value log 2TBWSize, log 2TBHSize of each TBWSize with a base of 2, TBHSize) of the processing target transform block. The transform skip flag (ts_flag): is a flag indicating whether or not to skip (inverse) primary transform and (inverse) secondary transform.</p><p id="p-0243" num="0248">Scan Identifier (scanIdx)</p><p id="p-0244" num="0249">Quantization parameter (qp)</p><p id="p-0245" num="0250">Quantization matrix (scaling_matrix (for example, JCTVC-W1005, 7.3.4 Scaling list data syntax))</p><p id="p-0246" num="0251">&#x3c;Residual Information Rinfo&#x3e;</p><p id="p-0247" num="0252">The residual information Rinfo (see, for example, 7.3.8.11 Residual Coding syntax of JCTVC-W1005) includes, for example, the following syntax.</p><p id="p-0248" num="0253">cbf (coded_block_flag): residual data presence-absence flag</p><p id="p-0249" num="0254">last_sig_coeff_x_pos: last non-zero coefficient X coordinate</p><p id="p-0250" num="0255">last_sig_coeff_y_pos: last non-zero coefficient Y-coordinate</p><p id="p-0251" num="0256">coded_sub_block_flag: sub-block non-zero coefficient presence-absence flag</p><p id="p-0252" num="0257">sig_coeff_flag: non-zero coefficient presence-absence flag</p><p id="p-0253" num="0258">gr1_flag: a flag indicating whether the level of the non-zero coefficient is greater than one (also referred to as a GR1 flag)</p><p id="p-0254" num="0259">gr2_flag: a flag indicating whether the level of the non-zero coefficient is greater than two (also referred to as a GR2 flag)</p><p id="p-0255" num="0260">sign_flag: a sign indicating positive or negative of a non-zero coefficient (also referred to as a sign code)</p><p id="p-0256" num="0261">coeff_abs_level_remaining: residual level of non-zero coefficient (also referred to as non-zero coefficient residual level)</p><p id="p-0257" num="0262">or the like.</p><p id="p-0258" num="0263">Of course, the information included in the residual information Rinfo is arbitrary, and information other than these pieces of information may be included.</p><p id="p-0259" num="0264">&#x3c;Filter Information Finfo&#x3e;</p><p id="p-0260" num="0265">The filter information Finfo includes, for example, control information related to each filter process described below.</p><p id="p-0261" num="0266">Control information regarding the deblocking filter (DBF)</p><p id="p-0262" num="0267">Control information regarding pixel adaptive offset (SAO)</p><p id="p-0263" num="0268">Control Information regarding adaptive loop filter (ALF)</p><p id="p-0264" num="0269">Control information on other linear and nonlinear filters</p><p id="p-0265" num="0270">More specifically, for example, information for specifying a picture to which each filter is applied and a region in the picture, filter on-off control information in units of CUs, filter on-off control information regarding boundaries of slices and tiles, and the like are included. Of course, the information included in the filter information Finfo is arbitrary, and information other than these pieces of information may be included.</p><p id="p-0266" num="0271">Returning to the description of the decoding unit <b>212</b>, the decoding unit <b>212</b> derives the quantized transform coefficient level level at each coefficient position in each transform block with reference to the residual information Rinfo. The decoding unit <b>212</b> supplies the quantized transform coefficient level to the inverse quantization unit <b>213</b>.</p><p id="p-0267" num="0272">Furthermore, the decoding unit <b>212</b> supplies the parsed header information Hinfo, the prediction mode information Pinfo, the transform information Tinfo, and the filter information Finfo to each block. Specifically, it is as follows.</p><p id="p-0268" num="0273">The header information Hinfo is supplied to the inverse quantization unit <b>213</b>, the inverse orthogonal transform unit <b>214</b>, the prediction unit <b>219</b>, and the in-loop filter unit <b>216</b>. The prediction mode information Pinfo is supplied to the inverse quantization unit <b>213</b> and the prediction unit <b>219</b>. The transform information Tinfo is supplied to the inverse quantization unit <b>213</b> and the inverse orthogonal transform unit <b>214</b>. The filter information Finfo is supplied to the in-loop filter unit <b>216</b>.</p><p id="p-0269" num="0274">Of course, the above example is one example, and the present technology is not limited to this example. For example, each encoding parameter may be supplied to an arbitrary processing unit. Furthermore, other information may be supplied to an arbitrary processing unit.</p><p id="p-0270" num="0275">&#x3c;Inverse Quantization Unit&#x3e;</p><p id="p-0271" num="0276">The inverse quantization unit <b>213</b> performs processing related to inverse quantization. For example, the inverse quantization unit <b>213</b> uses the transform information Tinfo and the quantized transform coefficient level level supplied from the decoding unit <b>212</b> as inputs, scales (inversely quantizes) the value of the quantized transform coefficient level on the basis of the transform information Tinfo, and derives the transform coefficient Coeff_IQ after inverse quantization.</p><p id="p-0272" num="0277">Note that this inverse quantization is performed as inverse processing of quantization by the quantization unit <b>114</b>. Furthermore, this inverse quantization is processing similar to the inverse quantization by the inverse quantization unit <b>117</b>. That is, the inverse quantization unit <b>117</b> performs processing (inverse quantization) similar to that of the inverse quantization unit <b>213</b>.</p><p id="p-0273" num="0278">The inverse quantization unit <b>213</b> supplies the derived transform coefficient Coeff_IQ to the inverse orthogonal transform unit <b>214</b>.</p><p id="p-0274" num="0279">&#x3c;Inverse Orthogonal Transform Unit&#x3e;</p><p id="p-0275" num="0280">The inverse orthogonal transform unit <b>214</b> performs processing related to inverse orthogonal transform. For example, the inverse orthogonal transform unit <b>214</b> uses the transform coefficient Coeff_IQ supplied from the inverse quantization unit <b>213</b> and the transform information Tinfo supplied from the decoding unit <b>212</b> as inputs, and performs inverse orthogonal transform processing (inverse transform processing) on the transform coefficient on the basis of the transform information Tinfo to derive the predicted residual D&#x2032;.</p><p id="p-0276" num="0281">Note that this inverse orthogonal transform is performed as inverse processing of the orthogonal transform by the orthogonal transform unit <b>113</b>. Furthermore, this inverse orthogonal transform is processing similar to the inverse orthogonal transform by the inverse orthogonal transform unit <b>118</b>. That is, the inverse orthogonal transform unit <b>118</b> performs processing (inverse orthogonal transform) similar to that of the inverse orthogonal transform unit <b>214</b>.</p><p id="p-0277" num="0282">The inverse orthogonal transform unit <b>214</b> supplies the derived predicted residual D&#x2032; to the operation unit <b>215</b>.</p><p id="p-0278" num="0283">&#x3c;Operation Unit&#x3e;</p><p id="p-0279" num="0284">The operation unit <b>215</b> performs processing related to addition of information regarding an image. For example, the operation unit <b>215</b> uses the predicted residual supplied from the inverse orthogonal transform unit <b>214</b> and the predicted image supplied from the prediction unit <b>219</b> as inputs. The operation unit <b>215</b> adds the predicted residual and the predicted image (prediction signal) corresponding to the predicted residual to derive the locally decoded image.</p><p id="p-0280" num="0285">The operation unit <b>215</b> supplies the derived locally decoded image to the in-loop filter unit <b>216</b> and the frame memory <b>218</b>.</p><p id="p-0281" num="0286">&#x3c;In-Loop Filter Unit&#x3e;</p><p id="p-0282" num="0287">The in-loop filter unit <b>216</b> performs a process related to the in-loop filter process. For example, the in-loop filter unit <b>216</b> uses the locally decoded image supplied from the operation unit <b>215</b> and the filter information Finfo supplied from the decoding unit <b>212</b> as inputs. Note that the information input to the in-loop filter unit <b>216</b> is arbitrary, and information other than these pieces of information may be input.</p><p id="p-0283" num="0288">The in-loop filter unit <b>216</b> appropriately performs a filter process on the locally decoded image on the basis of the filter information Finfo.</p><p id="p-0284" num="0289">For example, the in-loop filter unit <b>216</b> applies four in-loop filters of a bilateral filter, a deblocking filter (DBF), an adaptive offset filter (sample adaptive offset (SAO)), and an adaptive loop filter (ALF) in this order. Note that which filter is applied and in which order the filter is applied are arbitrary and can be selected as appropriate.</p><p id="p-0285" num="0290">The in-loop filter unit <b>216</b> performs a filter process corresponding to the filter process performed by the encoding side (for example, the in-loop filter unit <b>120</b> of the image encoding device <b>100</b>). Of course, the filter process performed by the in-loop filter unit <b>216</b> is arbitrary and is not limited to the above example. For example, the in-loop filter unit <b>216</b> may apply a Wiener filter or the like.</p><p id="p-0286" num="0291">The in-loop filter unit <b>216</b> supplies the locally decoded image subjected to the filter process to the rearrangement buffer <b>217</b> and the frame memory <b>218</b>.</p><p id="p-0287" num="0292">&#x3c;Rearrangement Buffer&#x3e;</p><p id="p-0288" num="0293">The rearrangement buffer <b>217</b> receives the locally decoded image supplied from the in-loop filter unit <b>216</b> as an input, and holds (stores) the locally decoded image. The rearrangement buffer <b>217</b> reconstructs the decoded image in each picture unit using the locally decoded image, and holds (stores in the buffer) the decoded image. The rearrangement buffer <b>217</b> rearranges the obtained decoded images from the decoding order to the reproduction order. The rearrangement buffer <b>217</b> outputs a group of rearranged decoded images to the outside of the image decoding device <b>200</b> as moving image data.</p><p id="p-0289" num="0294">&#x3c;Frame Memory&#x3e;</p><p id="p-0290" num="0295">The frame memory <b>218</b> performs processing related to storage of data related to an image. For example, the frame memory <b>218</b> uses the locally decoded image supplied from the operation unit <b>215</b> as an input, reconstructs the decoded image in each picture unit, and stores the decoded image in the buffer in the frame memory <b>218</b>.</p><p id="p-0291" num="0296">Furthermore, the frame memory <b>218</b> uses the locally decoded image subjected to the in-loop filter process supplied from the in-loop filter unit <b>216</b> as an input, reconstructs the decoded image in each picture unit, and stores the decoded image in the buffer in the frame memory <b>218</b>. The frame memory <b>218</b> appropriately supplies the stored decoded image (or a part thereof) to the prediction unit <b>219</b> as a reference image.</p><p id="p-0292" num="0297">Note that the frame memory <b>218</b> may store the header information Hinfo, the prediction mode information Pinfo, the transform information Tinfo, the filter information Finfo, and the like related to generation of the decoded image.</p><p id="p-0293" num="0298">&#x3c;Encoding Unit&#x3e;</p><p id="p-0294" num="0299"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating a main configuration example of the decoding unit <b>212</b> in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the decoding unit <b>212</b> includes a transform mode information decoding unit <b>250</b>, a control unit <b>251</b>, a selection unit <b>252</b>, a TS residual decoding unit <b>253</b>, a non-TS residual decoding unit <b>254</b>, and a selection unit <b>255</b>.</p><p id="p-0295" num="0300">The transform mode information decoding unit <b>250</b> performs processing related to decoding of the coded data of the transform mode information (transform_mode). This transform mode information is information regarding the mode of the inverse transform processing by the inverse orthogonal transform unit <b>214</b>. For example, the transform mode information may include a transform skip flag (transform_skip_flag[xTbY][yTbY][cIdx]), an identifier related to primary transform (mts_idx[xTbY][yTbY][cIdx]), and the like.</p><p id="p-0296" num="0301">For example, the transform mode information decoding unit <b>250</b> can acquire the coded data supplied from the accumulation buffer <b>211</b>. Furthermore, the transform mode information decoding unit <b>250</b> can decode the acquired coded data and generate transform mode information and a component identifier (cIdx). Moreover, the transform mode information encoding unit <b>150</b> can supply the generated transform mode information and the like to the control unit <b>251</b>.</p><p id="p-0297" num="0302">The control unit <b>251</b> performs processing related to control of the decoding mode. For example, the control unit <b>251</b> can acquire the transform mode information ((transform_skip_flag[xTbY][yTbY][cIdx]), mts_idx[xTbY][yTbY][cIdx], and the like) and the component identifier (cIdx) supplied from the transform mode information decoding unit <b>250</b>. Furthermore, the control unit <b>251</b> can switch between the TS residual decoding mode and the non-TS residual decoding mode as the decoding mode of the coded data of the coefficient data by controlling selection of the selection unit <b>252</b> or the selection unit <b>255</b> on the basis of the transform skip flag corresponding to the component identifier. For example, in a case where the transform skip is applied, the control unit <b>251</b> connects the selection unit <b>252</b> and the selection unit <b>255</b> to the TS residual decoding unit <b>253</b>. Furthermore, for example, in a case where the transform skip is not applied (in a case where the transform processing is performed), the control unit <b>251</b> connects the selection unit <b>252</b> and the selection unit <b>255</b> to the non-TS residual decoding unit <b>254</b>.</p><p id="p-0298" num="0303">The selection unit <b>252</b> performs processing related to selection of a supply destination of the coded data of the coefficient data (quantization coefficient). For example, the selection unit <b>252</b> can acquire the coded data supplied from the accumulation buffer <b>211</b>. Furthermore, under control of the control unit <b>251</b>, the selection unit <b>252</b> can supply the acquired coded data to the TS residual decoding unit <b>253</b> or the non-TS residual decoding unit <b>254</b> (the one designated by the control unit <b>251</b>). For example, in a case where the transform skip is applied, the selection unit <b>252</b> supplies the coded data to the TS residual decoding unit <b>253</b>. Furthermore, for example, in a case where the transform skip is not applied (in a case where the transform processing is performed), the selection unit <b>252</b> supplies the coded data to the non-TS residual decoding unit <b>254</b>.</p><p id="p-0299" num="0304">The TS residual decoding unit <b>253</b> performs processing related to the TS residual decoding mode. For example, the TS residual decoding unit <b>253</b> can acquire the coded data supplied from the selection unit <b>252</b>. Furthermore, the TS residual decoding unit <b>253</b> can decode the acquired coded data in the TS residual decoding mode. The TS residual decoding mode is a decoding mode for a case of skipping the transform processing. For example, decoding in the TS residual decoding mode corresponds to encoding in the TS residual encoding mode, and is optimized for the coded data of the coefficient data from which the transform processing is skipped. A more specific method of the TS residual decoding mode is described in Non-Patent Document 4 and the like. The TS residual decoding unit <b>253</b> can decode the coded data in this manner and generate a quantization coefficient. The TS residual decoding unit <b>253</b> can supply the quantization coefficient generated in this manner to the selection unit <b>255</b>.</p><p id="p-0300" num="0305">The non-TS residual decoding unit <b>254</b> performs processing related to the non-TS residual decoding mode. For example, the non-TS residual decoding unit <b>254</b> can acquire the coded data supplied from the selection unit <b>252</b>. Furthermore, the non-TS residual decoding unit <b>254</b> can decode the acquired coded data in the non-TS residual decoding mode. The non-TS residual decoding mode is a decoding mode for a case of performing the transform processing. For example, the decoding in the non-TS residual decoding mode corresponds to the encoding in the non-TS residual encoding mode, and is optimized for the coded data of the coefficient data on which the transform processing has been performed. A more specific method of the non-TS residual decoding mode is described in Non-Patent Document 4 and the like. The non-TS residual decoding unit <b>254</b> can decode the coded data in this manner and generate the quantization coefficient. The non-TS residual decoding unit <b>254</b> can supply the quantization coefficient generated in this manner to the selection unit <b>255</b>.</p><p id="p-0301" num="0306">The selection unit <b>255</b> performs processing related to selection of a supply source of the quantization coefficient. For example, the selection unit <b>255</b> can acquire the quantization coefficient supplied from the TS residual decoding unit <b>253</b> or the non-TS residual decoding unit <b>254</b> (the one designated by the control unit <b>251</b>). For example, in a case where the transform skip is applied, the selection unit <b>255</b> acquires the quantization coefficient supplied from the TS residual decoding unit <b>253</b>. Furthermore, for example, in a case where the transform skip is not applied (in a case where the transform processing is performed), the selection unit <b>255</b> acquires the coded data supplied from the non-TS residual decoding unit <b>254</b>. The selection unit <b>255</b> can supply the acquired quantization coefficient to the inverse quantization unit <b>213</b>.</p><p id="p-0302" num="0307">&#x3c;Transform Skip of Respective Components&#x3e;</p><p id="p-0303" num="0308">The image decoding device <b>200</b> can decode coded data of a color image having luminance components and color components. Then, the image decoding device <b>200</b> can skip (omit) the inverse transform processing of transforming coefficient data generated by decoding the coded data into the residual between the image and the predicted image thereof for not only the luminance components but also the color components.</p><p id="p-0304" num="0309">For example, the transform mode information decoding unit <b>250</b> can decode the coded data of the transform skip flag corresponding to the component identifier to obtain the transform skip flag corresponding to the component identifier.</p><p id="p-0305" num="0310">In this manner, when decoding, the setting of the transform skip for each component indicated by the transform skip flag can be applied. Therefore, the bit stream of the color components to which the transform skip is applied can be correctly decoded. Therefore, reduction in encoding efficiency can be suppressed as compared with a case where the transform skip can be applied only to the luminance components.</p><p id="p-0306" num="0311">Furthermore, when decoding the coded data of the image, the inverse transform processing of the color components may be controlled on the basis of the setting of the transform skip for each component by the above-described transform skip flag. That is, the transform skip may be applied to the inverse transform processing of the color components. In this manner, the bit stream of the color components to which the transform skip is applied can be correctly decoded. Therefore, reduction in encoding efficiency can be suppressed as compared with a case where the transform skip can be applied only to the luminance components.</p><p id="p-0307" num="0312">Note that, as described above, by setting the transform skip for each component, it is possible to set the transform skip for the color components independently of the luminance components. Therefore, it is possible to set the transform skip for the color components according to whether or not the transform skip is valid for the color components. In this manner, reduction in encoding efficiency can be suppressed as compared with a case where setting of the transform skip for the luminance components is applied to the color components.</p><p id="p-0308" num="0313">&#x3c;Control of Encoding Mode&#x3e;</p><p id="p-0309" num="0314">Furthermore, in a case where the transform skip is applied to the color components as in the above-described method 1, such control of the decoding mode may also be applied. For example, the TS residual decoding mode may be applied as the decoding mode in a case where the transform skip is applied to each value of the identifier of the component, and the non-TS residual decoding mode may be applied as the decoding mode in a case where the transform skip is not applied.</p><p id="p-0310" num="0315">For example, on the basis of the transform skip flag corresponding to the component identifier, it may be controlled whether the decoding mode of the coded data of the coefficient data corresponding to the component identifier is set to the TS residual decoding mode that is a mode for a case of skipping the inverse transform processing of transforming the coefficient data into the residual between the image and the predicted image, or to the non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform processing, and the coded data of the coefficient data corresponding to the component identifier may be decoded by the decoding mode set as described above to generate the coefficient data corresponding to the component identifier.</p><p id="p-0311" num="0316">In this manner, since the decoding mode according to the setting of the transform skip can be applied, reduction in encoding efficiency can be suppressed as compared with a case where decoding is performed in a single decoding mode.</p><p id="p-0312" num="0317">&#x3c;Flow of Image Decoding Processing&#x3e;</p><p id="p-0313" num="0318">Next, a flow of each processing executed by the image decoding device <b>200</b> having the configuration as described above will be described. First, an example of a flow of image decoding processing will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0314" num="0319">When the image decoding processing is started, in step S<b>401</b>, the accumulation buffer <b>211</b> acquires and holds (accumulates) a bit stream supplied from the outside of the image decoding device <b>200</b>.</p><p id="p-0315" num="0320">In step S<b>202</b>, the decoding unit <b>212</b> extracts and decodes coded data from the bit stream to obtain the quantized transform coefficient level level. Furthermore, the decoding unit <b>212</b> parses (analyzes and acquires) various encoding parameters from the bit stream by this decoding.</p><p id="p-0316" num="0321">In step S<b>203</b>, the inverse quantization unit <b>213</b> performs inverse quantization, which is inverse processing of the quantization performed on the encoding side, on the quantized transform coefficient level level obtained by the processing of step S<b>202</b> to obtain the transform coefficient Coeff_IQ.</p><p id="p-0317" num="0322">In step S<b>204</b>, under control of step S<b>203</b>, the inverse orthogonal transform unit <b>214</b> performs inverse orthogonal transform processing, which is inverse processing of the orthogonal transform processing performed on the encoding side, on the transform coefficient Coeff_IQ obtained in step S<b>203</b> to obtain the predicted residual D&#x2032;.</p><p id="p-0318" num="0323">In step S<b>205</b>, the prediction unit <b>219</b> executes prediction processing by a prediction method designated by the encoding side on the basis of the information parsed in step S<b>202</b>, and generates the predicted image P by referring to the reference image stored in the frame memory <b>218</b>, or the like.</p><p id="p-0319" num="0324">In step S<b>206</b>, the operation unit <b>215</b> adds the predicted residual D&#x2032; obtained in step S<b>204</b> and the predicted image P obtained in step S<b>205</b> to derive a locally decoded image R<sub>local</sub>.</p><p id="p-0320" num="0325">In step S<b>207</b>, the in-loop filter unit <b>216</b> performs the in-loop filter process on the locally decoded image R<sub>local </sub>obtained by the processing of step S<b>206</b>.</p><p id="p-0321" num="0326">In step S<b>208</b>, the rearrangement buffer <b>217</b> derives a decoded image R using the locally decoded image R<sub>local </sub>subjected to the filter process obtained by the processing of step S<b>207</b>, and rearranges the order of a group of decoded images R from the decoding order to the reproduction order. The group of the decoded images R rearranged in the reproduction order is output as a moving image to the outside of the image decoding device <b>200</b>.</p><p id="p-0322" num="0327">Furthermore, in step S<b>209</b>, the frame memory <b>218</b> stores at least one of the locally decoded image Rio-Ai obtained by the processing of step S<b>206</b> or the locally decoded image R<sub>local </sub>after the filter process obtained by the processing of step S<b>207</b>.</p><p id="p-0323" num="0328">When the processing of step S<b>209</b> ends, the image decoding processing ends.</p><p id="p-0324" num="0329">&#x3c;Flow of Decoding Processing&#x3e;</p><p id="p-0325" num="0330">Next, an example of a flow of decoding processing executed in step S<b>202</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref> will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>9</b></figref>.</p><p id="p-0326" num="0331">When the decoding processing is started, in step S<b>251</b>, the transform mode information decoding unit <b>250</b> of the decoding unit <b>212</b> decodes the transform mode information (transform_mode) of the transform block corresponding to the component identifier cIdx.</p><p id="p-0327" num="0332">In step S<b>252</b>, the control unit <b>251</b> derives Condition1 by the above-described Expression (1). That is, the control unit <b>251</b> generates Condition1 by using the transform skip flag (transform_skip_flag[cIdx]) corresponding to the component.</p><p id="p-0328" num="0333">In step S<b>253</b>, the control unit <b>251</b> determines whether or not this Condition1 is true. In a case where Condition1 is true, the transform skip flag (transform_skip_flag[cIdx]) corresponding to the component is true (IS_SKIP). Therefore, the selection unit <b>252</b> and the selection unit <b>255</b> are connected to the TS residual decoding unit <b>253</b> under control of the control unit <b>251</b>. Thus, the processing proceeds to step S<b>254</b>.</p><p id="p-0329" num="0334">In step S<b>254</b>, the TS residual decoding unit <b>253</b> decodes the coded data in the TS residual decoding mode to generate a quantization coefficient. When the quantization coefficient is generated, the decoding processing ends.</p><p id="p-0330" num="0335">Furthermore, in step S<b>253</b>, in a case where Condition1 is false, the transform skip flag (transform_skip_flag [cIdx]) corresponding to the component is false. Thus, the selection unit <b>252</b> and the selection unit <b>255</b> are connected to the non-TS residual decoding unit <b>254</b> under control of the control unit <b>251</b>. Consequently, the processing proceeds to step S<b>255</b>.</p><p id="p-0331" num="0336">In step S<b>255</b>, the non-TS residual decoding unit <b>254</b> encodes the coded data in the non-TS residual decoding mode to generate a quantization coefficient. When the quantization coefficient is generated, the decoding processing ends.</p><p id="p-0332" num="0337">By performing each processing as described above, the image decoding device <b>200</b> can apply the TS residual decoding mode also to the color components, and can suppress reduction in encoding efficiency.</p><p id="p-0333" num="0338">Note that, in the above description, it has been described that notification of whether or not the transform skip is performed is provided by the transform skip flag (transform_skip_flag) but it is not limited to this, and notification of the mode may be provided as one mode of the identifier mts_idx related to the primary transform. The identifier mts_idx is an identifier indicating transform types in the horizontal direction and the vertical direction of the primary transform. In this case, the control unit <b>251</b> can derive Condition1 as in the above-described Expression (2).</p><p id="p-0334" num="0339">&#x3c;3-3. Syntax Semantics&#x3e;</p><p id="p-0335" num="0340"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an example of syntax of a tranmform-unit (TU) in this case. In a case of the example of <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the transform mode information (transform_mode ( . . . , 0), transform_mode ( . . . , 0), transform_mode ( . . . , 2),) corresponding to respective components is derived, and whether or not to apply the transform skip (residual_comding ( . . . , cIdx) or residual_ts_coding ( . . . , cIdx)) is determined for each component (tu_cbf_luma, tu_cbf_cb, tu_cbf_cr).</p><p id="p-0336" num="0341">An example of syntax of the transform mode information is illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. In a case of the example in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the transform skip flag (transform_skip_flag[x0][y0][cIdx]) for each component and an identifier (mts_idx[x0][y0][cIdx]) of a transform type of primary transform for each component are set as the transform mode information (transform_mode ( . . . , cIdx)) for each component. In this case, conditions of the respective components for generating these pieces of information are the same. The contents of the conditions are arbitrary. For example, an enable flag of the transform skip (sps_transform_skip_enabled_flag) or the like set in a sequence parameter set (SPS) is used for the conditions.</p><p id="p-0337" num="0342">An example of syntax of the transform skip (residual_ts_coding ( . . . , cIdx)) is illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the setting of the transform skip is performed for each component (cIdx). Furthermore, A in <figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example of semantics of the transform skip flag (transform_skip_flag[x0][y0][cIdx]) of the transform mode information. Moreover, B in <figref idref="DRAWINGS">FIG. <b>13</b></figref> illustrates an example of semantics of the identifier (mts_idx[x0][y0][cIdx]) of the transform type of the primary transform. In this manner, the information regarding the transform skip is set for each component. Therefore, as described above, the transform skip can be applied to the color components, and reduction in encoding efficiency can be suppressed.</p><p id="p-0338" num="0343">Note that in the syntax of the transform mode information, the conditions of the respective components for generating the transform skip flag (transform_skip_flag[x0][y0][cIdx]) for each component and the identifier (mts_idx[x0][y0][cIdx]) of the transform type of the primary transform for each component may be different from each other as in the example in <figref idref="DRAWINGS">FIG. <b>14</b></figref>. By preparing the condition for each component in this manner, redundancy of the determination condition can be suppressed, and an increase in processing load can be suppressed.</p><p id="p-0339" num="0344">&#x3c;3-4. Transform Skip Residual Encoding Use Flag&#x3e;</p><p id="p-0340" num="0345">Note that a transform skip residual encoding use flag indicating selection between the TS residual encoding mode (TS residual decoding mode) and the non-TS residual encoding mode (non-TS residual decoding mode) may be applied.</p><p id="p-0341" num="0346">An example of syntax of the sequence parameter set (SPS) is illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>. For example, the control unit <b>101</b> may set the transform skip residual encoding use flag sps_ts_residual_coding_use_flag in this sequence parameter set.</p><p id="p-0342" num="0347">The sps_ts_residual_coding_use_flag is the transform skip residual encoding use flag notification of which is provided at the sequence parameter set level. In a case where the value of this flag is &#x201c;1&#x201d;, it is indicated that the TS residual encoding mode is applied at the time of transform skip. Furthermore, in a case where the value of this flag is &#x201c;0&#x201d;, it is indicated that the non-TS residual encoding mode is applied at the time of transform skip.</p><p id="p-0343" num="0348"><figref idref="DRAWINGS">FIG. <b>16</b></figref> illustrates an example of syntax of a TU in this case. In the case of the example of <figref idref="DRAWINGS">FIG. <b>16</b></figref>, this transform skip residual encoding use flag is used as a condition for determining whether or not to apply transform skip. <figref idref="DRAWINGS">FIG. <b>17</b></figref> illustrates semantics of sps_ts_residual_coding_use_flag. Furthermore, Condition1 in this case is derived using, for example, the following Expression (3).</p><p id="p-0344" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Condition1=(transform_skip_flag[cId<i>x</i>]==&#x201c;IS_SKIP&#x201d;&#x26; &#x26; <i>sps</i>_<i>ts</i>_residual_coding_use_flag==1)&#x2003;&#x2003; (3)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0345" num="0349">Note that in a case where the identifier of the transform type of the primary transform is used, the transform type is derived as in the following (4).</p><p id="p-0346" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Condition1=(<i>mts</i>_<i>idx</i>[cId<i>x</i>]=&#x201c;IS_SKIP&#x201d;&#x26; &#x26; <i>sps</i>_<i>ts</i>_residual_coding_use_flag==1)&#x2003;&#x2003; (4)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0347" num="0350">By using such a high-level flag, even an encoder or a decoder that does not support transform skipping can correctly perform encoding and decoding on the basis of this flag. Therefore, reduction in encoding efficiency can be suppressed. In other words, implementation of the TS residual encoding mode (TS residual decoding mode) in the encoder and the decoder can be omitted, and increase in the circuit scale can be suppressed.</p><p id="p-0348" num="0351">Note that a data unit for setting the transform skip residual encoding use flag is arbitrary, and may be other than the sequence parameter set. For example, notification of the transform skip residual encoding use flag may be provided at a CU level, a slice level, a picture level, or the like. As granularity of the data unit is made finer, the degree of freedom of mode switching increases, and the room for improving encoding efficiency is improved.</p><p id="p-0349" num="0352">&#x3c;3-5. Transform Skip Residual Encoding Use Specifying Mode Flag&#x3e;</p><p id="p-0350" num="0353">Furthermore, a flag indicating whether to apply the TS residual encoding mode (TS residual decoding mode) or to apply the non-TS residual encoding mode (non-TS residual decoding mode) in a specific mode may be applied.</p><p id="p-0351" num="0354">An example of syntax of the sequence parameter set (SPS) is illustrated in <figref idref="DRAWINGS">FIG. <b>18</b></figref>. For example, the control unit <b>101</b> may set the transform skip residual encoding use specifying mode flag sps_ts_residual_coding_use_for_bdpcm_flag in this sequence parameter set.</p><p id="p-0352" num="0355">This sps_ts_residual_coding_use_for_bdpcm_flag is a flag notification of which is provided at the sequence parameter set level, and is flag information indicating that selection of the encoding mode is enabled in block_based differential pulse code modulation (BDPCM). In a case where the value of this flag is &#x201c;1&#x201d;, it is indicated that the TS residual encoding mode is applied in a case of the BDPCM. Furthermore, in a case where the value of this flag is &#x201c;0&#x201d;, it is indicated that the non-TS residual encoding mode is applied in the case of the BDPCM.</p><p id="p-0353" num="0356"><figref idref="DRAWINGS">FIG. <b>19</b></figref> illustrates an example of syntax of the TU in this case. In the case of the example of <figref idref="DRAWINGS">FIG. <b>19</b></figref>, this transform skip residual encoding use specifying mode flag is used as a condition for determining whether or not to apply the transform skip. <figref idref="DRAWINGS">FIG. <b>20</b></figref> illustrates semantics of sps_ts_residual_coding_use_for_bdpcm_flag. Furthermore, Condition1 in this case is derived using, for example, the following Expression (5).</p><p id="p-0354" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Condition1(transform_skip_flag[cIdx]==&#x201c;IS_SKIP&#x201d;&#x26;&#x26;!(int <i>ra</i>_<i>bdpcm</i>_flag &#x26;&#x26; <i>sps</i>_<i>ts</i>_residual_coding_use_for_bdpcm_flag==0))&#x2003;&#x2003; (5)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0355" num="0357">Note that, in a case where the identifier of the transform type of the primary transform is used, the transform type is derived as in the following (6).</p><p id="p-0356" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Condition1=(<i>mts</i>_<i>idx</i>[cId<i>x</i>]==&#x201c;IS_SKIP&#x201d;&#x26;&#x26;!(int <i>ra</i>_<i>bdpcm</i>_flag &#x26; &#x26; <i>sps</i>_<i>ts</i>_residual_coding_use_for_bdpcm_flag==0))&#x2003;&#x2003; (6)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0357" num="0358">By using such a high-level flag, the TS residual encoding mode and the non-TS residual encoding mode can be switched in the BDPCM.</p><p id="p-0358" num="0359">Note that the data unit for setting the transform skip residual encoding use specifying mode flag is arbitrary, and may be other than the sequence parameter set. For example, notification of the transform skip residual encoding use specifying mode flag may be provided at the CU level, the slice level, the picture level, or the like. As granularity of the data unit is made finer, the degree of freedom of mode switching increases, and the room for improving encoding efficiency is improved.</p><heading id="h-0013" level="1">4. SECOND EMBODIMENT</heading><p id="p-0359" num="0360">&#x3c;4-1. Correction of Quantization Parameter in Quantization&#x3e;</p><p id="p-0360" num="0361">In each value of the component identifier, the quantization parameter may be corrected in a case of the transform skip. That is, in a case where the transform skip is applied, the quantization parameter may be corrected. Then, such control may be performed for each component.</p><p id="p-0361" num="0362">&#x3c;Quantization Unit&#x3e;</p><p id="p-0362" num="0363">Also in this case, the image encoding device <b>100</b> is similar to the example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. <figref idref="DRAWINGS">FIG. <b>21</b></figref> is a block diagram illustrating a main configuration example of the quantization unit <b>114</b> in this case. As illustrated in <figref idref="DRAWINGS">FIG. <b>21</b></figref>, the quantization unit <b>114</b> in this case includes a QP correction unit <b>311</b> and a quantization processing unit <b>312</b>.</p><p id="p-0363" num="0364">The QP correction unit <b>311</b> performs processing related to correction of the quantization parameter. For example, the QP correction unit <b>311</b> refers to the transform skip flag corresponding to the component identifier cIdx, a joint chrominance encoding mode information TuResMode, a QP(Op&#x2032;) at the CU-level corresponding to the component identifier cIdx, and the minimum QP(QpPrimeTsMin) of the transform skip to derive the quantization parameter Qp to be applied to the processing target transform block corresponding to the component identifier cIdx. Types of the quantization parameters include Qp&#x2032;y, Qp&#x2032;cb, Qp&#x2032;cr, and Qp&#x2032;cbcr. Furthermore, notification of the minimum quantization parameter QpPrimeTsMin for transform skip is provided by a parameter set.</p><p id="p-0364" num="0365">Note that the joint chrominance encoding mode is a mode in which only one of the chrominance components (Cb, Cr) is transmitted, and the other is derived from the one and is not transmitted. For example, only the residual of Cr is encoded and transmitted, and the residual of Cb is derived from the residual of Cr and is not transmitted. The joint chrominance encoding mode information TuResMode is information related to such a joint chrominance encoding mode.</p><p id="p-0365" num="0366">The QP correction unit <b>311</b> supplies a quantization parameter (corrected QP(qP)) after correction to the quantization processing unit <b>312</b>.</p><p id="p-0366" num="0367">The quantization processing unit <b>312</b> quantizes the coefficient data (transform coefficient) using the quantization parameter (correction QP(qP)) supplied from the QP correction unit <b>311</b> to generate a quantization coefficient. The quantization processing unit <b>312</b> supplies the generated quantization coefficient to the encoding unit <b>115</b> and the inverse quantization unit <b>117</b>.</p><p id="p-0367" num="0368">&#x3c;Flow of Quantization Processing&#x3e;</p><p id="p-0368" num="0369">An example of a flow of the quantization processing in this case executed in step S<b>108</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>22</b></figref>. When the quantization processing is started, the QP correction unit <b>311</b> of the quantization unit <b>114</b> derives Condition2 by the following Expression (7) in step S<b>301</b>. That is, the QP correction unit <b>311</b> generates Condition2 using the transform skip flag (transform_skip_flag[cIdx]) corresponding to the component.</p><p id="p-0369" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Condition2=(transform_skip_flag[cId<i>x</i>]==&#x201c;IS_SKIP&#x201d;)&#x2003;&#x2003;(7)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0370" num="0370">Note that in a case where the identifier of the transform type of the primary transform is used, the transform type is derived as in the following (8).</p><p id="p-0371" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>Condition2(<i>mts</i>_<i>idx</i>[cId<i>x</i>]=&#x201c;IS_SKIP&#x201d;)&#x2003;&#x2003; (8)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0372" num="0371">In step S<b>302</b>, the QP correction unit <b>311</b> determines whether or not Condition2 is true. In a case where Condition2 is true, that is, in a case where the transform skip flag (transform_skip_flag[cIdx]) corresponding to the component is true (IS_SKIP), the processing proceeds to step S<b>303</b>.</p><p id="p-0373" num="0372">In step S<b>303</b>, the QP correction unit <b>311</b> corrects the quantization parameter QP. In this case, for example, the QP correction unit <b>311</b> sets one having a larger value of the minimum quantization parameter (QpPrimeTsMin) for the transform skip and the quantization parameter QP&#x2032;x at the CU level as the quantization parameter (correction QP(qP)) to be applied to the processing target transform block corresponding to the component identifier. When the processing of step S<b>303</b> ends, the processing proceeds to step S<b>305</b>.</p><p id="p-0374" num="0373">Furthermore, in a case where Condition2 is determined to be false, the processing proceeds to step S<b>304</b>. In this case, for example, the QP correction unit <b>311</b> sets the CU-level quantization parameter QP&#x2032;x as the quantization parameter (correction QP(qP)) to be applied to the processing target transform block corresponding to the component identifier. When the processing of step S<b>304</b> ends, the processing proceeds to step S<b>305</b>.</p><p id="p-0375" num="0374">In step S<b>305</b>, the quantization processing unit <b>312</b> quantizes the transform coefficient by using the quantization parameter updated in step S<b>303</b> or step S<b>304</b>. When the processing of step S<b>305</b> ends, the quantization processing ends, and the processing returns to <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0376" num="0375">This makes it possible to suppress decrease in PSNR.</p><p id="p-0377" num="0376">&#x3c;4-2. Correction of Quantization Parameter in Inverse Quantization&#x3e;</p><p id="p-0378" num="0377">In the inverse quantization, similarly, the quantization parameter may be corrected in a case of the transform skip in each value of the component identifier. That is, in a case where the transform skip is applied, the quantization parameter may be corrected. Then, such control may be performed for each component.</p><p id="p-0379" num="0378">&#x3c;Inverse Quantization Unit&#x3e;</p><p id="p-0380" num="0379">Also in this case, the image decoding device <b>200</b> is similar to the example of <figref idref="DRAWINGS">FIG. <b>6</b></figref>. <figref idref="DRAWINGS">FIG. <b>23</b></figref> is a block diagram illustrating a main configuration example of the inverse quantization unit <b>213</b> in this case. As illustrated in <figref idref="DRAWINGS">FIG. <b>23</b></figref>, the inverse quantization unit <b>213</b> in this case includes a QP correction unit <b>411</b> and an inverse quantization processing unit <b>412</b>.</p><p id="p-0381" num="0380">The QP correction unit <b>411</b> performs processing related to correction of the quantization parameter. For example, the QP correction unit <b>411</b> refers to the transform skip flag corresponding to the component identifier cIdx, the joint chrominance encoding mode information TuResMode, the QP(Qp&#x2032;) at the CU-level corresponding to the component identifier cIdx, and the minimum QP(QpPrimeTsMin) of the transform skip to derive the quantization parameter Qp to be applied to the processing target transform block corresponding to the component identifier cIdx. Types of the quantization parameters include Qp&#x2032;y, Qp&#x2032;cb, Qp&#x2032;cr, and Qp&#x2032;cbcr. Furthermore, notification of the minimum quantization parameter QpPrimeTsMin for transform skip is provided by a parameter set.</p><p id="p-0382" num="0381">The QP correction unit <b>411</b> supplies the quantization parameter (corrected QP(qP)) after correction to the inverse quantization processing unit <b>412</b>.</p><p id="p-0383" num="0382">The inverse quantization processing unit <b>412</b> performs the inverse quantization of the quantization coefficient using the quantization parameter (correction QP(qP)) supplied from the QP correction unit <b>411</b> to generate coefficient data (transform coefficient). The inverse quantization processing unit <b>412</b> supplies the generated coefficient data to the inverse orthogonal transform unit <b>214</b>.</p><p id="p-0384" num="0383">&#x3c;Flow of Inverse Quantization Processing&#x3e;</p><p id="p-0385" num="0384">An example of a flow of the inverse quantization processing in this case executed in step S<b>203</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref> will be described with reference to a flowchart of <figref idref="DRAWINGS">FIG. <b>24</b></figref>. When the inverse quantization processing is started, the QP correction unit <b>411</b> of the inverse quantization unit <b>213</b> derives Condition2 by the above-described Expression (7) in step S<b>401</b>. That is, the QP correction unit <b>411</b> generates Condition2 using the transform skip flag (transform_skip_flag [cIdx]) corresponding to the component. As described in the first embodiment, the transform skip flag is obtained by being decoded by the transform mode information decoding unit <b>250</b>.</p><p id="p-0386" num="0385">In step S<b>402</b>, the QP correction unit <b>411</b> determines whether or not Condition2 is true. In a case where Condition2 is true, that is, in a case where the transform skip flag (transform_skip_flag[cIdx]) corresponding to the component is true (IS_SKIP), the processing proceeds to step S<b>403</b>.</p><p id="p-0387" num="0386">In step S<b>403</b>, the QP correction unit <b>411</b> corrects the quantization parameter QP. In this case, for example, the QP correction unit <b>411</b> sets one having a larger value of the minimum quantization parameter (QpPrimeTsMin) for the transform skip and the quantization parameter QP&#x2032;x at the CU level as the quantization parameter (correction QP(qP)) to be applied to the processing target transform block corresponding to the component identifier. When the processing of step S<b>403</b> ends, the processing proceeds to step S<b>405</b>.</p><p id="p-0388" num="0387">Furthermore, in a case where Condition2 is determined to be false, the processing proceeds to step S<b>404</b>. In this case, for example, the QP correction unit <b>411</b> sets the CU-level quantization parameter QP&#x2032;x as the quantization parameter (correction QP(qP)) to be applied to the processing target transform block corresponding to the component identifier. When the processing of step S<b>404</b> ends, the processing proceeds to step S<b>405</b>.</p><p id="p-0389" num="0388">In step S<b>405</b>, the inverse quantization processing unit <b>412</b> inversely quantizes the quantization coefficient by using the quantization parameter updated in step S<b>403</b> or step S<b>404</b>. When the processing of step S<b>405</b> ends, the inverse quantization processing ends, and the processing returns to <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><p id="p-0390" num="0389">This makes it possible to suppress decrease in PSNR.</p><p id="p-0391" num="0390">&#x3c;4-3. Syntax&#x3e;</p><p id="p-0392" num="0391"><figref idref="DRAWINGS">FIG. <b>25</b></figref> illustrates an example of the syntax of the quantization parameter in this case. As described above, the quantization parameter qP is corrected for each component by using the transform skip flag transform_skip_flag.</p><heading id="h-0014" level="1">5. THIRD EMBODIMENT</heading><p id="p-0393" num="0392">&#x3c;Sharing of Context Variable&#x3e;</p><p id="p-0394" num="0393">In a case where the transform skip is applied as described above, the context variable corresponding to each binIdx in the bin column of each syntax may be shared between the luminance components and the color components.</p><p id="p-0395" num="0394">For example, in a case where the transform processing is skipped in encoding, the context variable may be shared between encoding of the luminance component of the coefficient data and encoding of the chrominance component.</p><p id="p-0396" num="0395">Furthermore, for example, in a case where the inverse transform processing is skipped in decoding, the context variable may be shared between decoding of the coded data of the luminance component of the coefficient data and decoding of the coded data of the chrominance component.</p><p id="p-0397" num="0396">An example of syntax regarding the context variable in this case is illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref>. As in the example of <figref idref="DRAWINGS">FIG. <b>26</b></figref>, in a case where the transform skip is applied, the context variable may be derived by a common method for the luminance component and the color component.</p><p id="p-0398" num="0397">Furthermore, another example of syntax regarding the context variable is illustrated in <figref idref="DRAWINGS">FIG. <b>27</b></figref>. As in the example of <figref idref="DRAWINGS">FIG. <b>27</b></figref>, in a case where the transform skip is applied, context variables may be derived by methods independent of each other for the luminance component and the color component.</p><p id="p-0399" num="0398">As described above, by sharing the context variable corresponding to each binIdx in the bin row of each syntax between the luminance components and the color components, it is possible to suppress an increase in memory size for holding the context variable. Therefore, it is possible to suppress increase in hardware cost.</p><heading id="h-0015" level="1">6. FOURTH EMBODIMENT</heading><p id="p-0400" num="0399">&#x3c;Control of Encoding-Decoding Mode of Sign Code&#x3e;</p><p id="p-0401" num="0400">Furthermore, the encoding and decoding method of the sign code may be switched according to the transform skip flag corresponding to the component identifier. <figref idref="DRAWINGS">FIG. <b>28</b></figref> illustrates an example of syntax in this case.</p><p id="p-0402" num="0401">As in the column of binIdx=0 in the table illustrated in <figref idref="DRAWINGS">FIG. <b>28</b></figref>, for example, in a case where the transform skip is not performed, bypass encoding-decoding may be applied to encoding and decoding of the sign code. Furthermore, for example, in the case of transform skip, if the number of remaining context encoding bins is equal to or larger than a threshold, the context encoding and decoding may be applied to encoding and decoding of the sign code, and if not, bypass encoding-decoding may be applied to encoding and decoding of the sign code ((MaxCcbs&#x3e;0)? (0 . . . 5): bypass).</p><p id="p-0403" num="0402">In this manner, reduction in encoding efficiency can be suppressed.</p><heading id="h-0016" level="1">7. APPENDIX</heading><p id="p-0404" num="0403">&#x3c;Computer&#x3e;</p><p id="p-0405" num="0404">The series of processes described above can be executed by hardware or can be executed by software. In a case where the series of processes is executed by software, a program constituting the software is installed in a computer. Here, the computer includes a computer incorporated in dedicated hardware, a general-purpose personal computer for example that can execute various functions by installing various programs, and the like.</p><p id="p-0406" num="0405"><figref idref="DRAWINGS">FIG. <b>29</b></figref> is a block diagram illustrating a configuration example of hardware of a computer that executes the above-described series of processes by a program.</p><p id="p-0407" num="0406">In a computer <b>900</b> illustrated in <figref idref="DRAWINGS">FIG. <b>29</b></figref>, a central processing unit (CPU) <b>901</b>, a read only memory (ROM) <b>902</b>, and a random access memory (RAM) <b>903</b> are interconnected via a bus <b>904</b>.</p><p id="p-0408" num="0407">An input-output interface <b>910</b> is also connected to the bus <b>904</b>. An input unit <b>911</b>, an output unit <b>912</b>, a storage unit <b>913</b>, a communication unit <b>914</b>, and a drive <b>915</b> are connected to the input-output interface <b>910</b>.</p><p id="p-0409" num="0408">The input unit <b>911</b> includes, for example, a keyboard, a mouse, a microphone, a touch panel, an input terminal, and the like. The output unit <b>912</b> includes, for example, a display, a speaker, an output terminal, and the like. The storage unit <b>913</b> includes, for example, a hard disk, a RAM disk, a nonvolatile memory, and the like. The communication unit <b>914</b> includes, for example, a network interface. The drive <b>915</b> drives a removable medium <b>921</b> such as a magnetic disk, an optical disk, a magneto-optical disk, or a semiconductor memory.</p><p id="p-0410" num="0409">In the computer configured as described above, the CPU <b>901</b> loads, for example, a program stored in the storage unit <b>913</b> into the RAM <b>903</b> via the input-output interface <b>910</b> and the bus <b>904</b> and executes the program, so as to perform the above-described series of processing. The RAM <b>903</b> also appropriately stores data necessary for the CPU <b>901</b> to execute various processes, and the like.</p><p id="p-0411" num="0410">The program executed by the computer can be applied by being recorded in the removable medium <b>921</b> as a package medium or the like, for example. In this case, the program can be installed in the storage unit <b>913</b> via the input-output interface <b>910</b> by attaching the removable medium <b>921</b> to the drive <b>915</b>.</p><p id="p-0412" num="0411">Furthermore, this program can be provided via a wired or wireless transmission medium such as a local area network, the Internet, or digital satellite broadcasting. In this case, the program can be received by the communication unit <b>914</b> and installed in the storage unit <b>913</b>.</p><p id="p-0413" num="0412">In addition, this program can be installed in the ROM <b>902</b> or the storage unit <b>913</b> in advance.</p><p id="p-0414" num="0413">&#x3c;Unit of Information and Processing&#x3e;</p><p id="p-0415" num="0414">The data units in which the various information described above is set and the data units targeted by the various processes are arbitrary and are not limited to the above-described examples. For example, these information and processes may be set in every transform unit (TU), transform block (TB), prediction unit (PU), prediction block (PB), coding unit (CU), largest coding unit (LCU), sub-block, block, tile, slice, picture, sequence, or component, or data in those data units may be targeted. Of course, this data unit can be set for every pieces of information or process, and it is not necessary that the data units of all the pieces of information or processes are unified. Note that the storage location of these information is arbitrary, and may be stored in a header, parameter set, or the like of the above-described data units. Furthermore, it may be stored in a plurality of places.</p><p id="p-0416" num="0415">&#x3c;Control Information&#x3e;</p><p id="p-0417" num="0416">The control information related to the present technology described in each of the above embodiments may be transmitted from the encoding side to the decoding side. For example, control information (for example, enabled_flag) that controls whether or not the application of the present technology described above is permitted (or prohibited) may be transmitted. Furthermore, for example, control information (for example, present_flag) indicating an object to which the above-described present technology is applied (or an object to which the present technology is not applied) may be transmitted. For example, the control information may be transmitted that specifies a block size (upper or lower limits, or both) by which the present technology is applied (or application thereof is allowed or prohibited), frame, component, layer, or the like.</p><p id="p-0418" num="0417">&#x3c;Applicable Target of the Present Technology&#x3e;</p><p id="p-0419" num="0418">The present technology can be applied to any image encoding and decoding method. That is, as long as it does not contradict the present technology described above, the specifications of various processes related to the image encoding and decoding, such as transform (inverse transform), quantization (inverse quantization), encoding (decoding), and prediction are arbitrary, and are not limited to the above-described examples. Furthermore, some of these processes may be omitted as long as they do not contradict the present technology described above.</p><p id="p-0420" num="0419">Furthermore, the present technology can be applied to a multi-view image encoding-decoding system that encodes and decodes a multi-view image including images of a plurality of viewpoints (views). In this case, the present technology is only required to be applied to encoding and decoding of each viewpoint (view).</p><p id="p-0421" num="0420">Furthermore, the present technology can be applied to a hierarchical image encoding (scalable encoding) and decoding system that encodes and decodes a hierarchical image layered (hierarchized) so as to have a scalability function for a predetermined parameter. In this case, the present technology is only required to be applied to encoding and decoding of each hierarchy (layer).</p><p id="p-0422" num="0421">Furthermore, in the above description, the image encoding device <b>100</b> and the image decoding device <b>200</b> have been described as application examples of the present technology, but the present technology can be applied to any configuration.</p><p id="p-0423" num="0422">For example, the present technology can be applied to various electronic devices such as a transmitter and a receiver (for example, a television receiver and a mobile phone) in satellite broadcasting, cable broadcasting such as cable TV, distribution on the Internet, and distribution to a terminal by cellular communication, or a device (for example, a hard disk recorder and a camera) that records an image on a medium such as an optical disk, a magnetic disk, and a flash memory, or reproduces an image from the storage medium.</p><p id="p-0424" num="0423">Furthermore, for example, the present technology can also be implemented as a partial configuration of a device, such as a processor (for example, a video processor) as a system large scale integration (LSI) or the like, a module (for example, a video module) using a plurality of processors or the like, a unit (for example, a video unit) using a plurality of modules or the like, or a set (for example, a video set) obtained by further adding other functions to a unit.</p><p id="p-0425" num="0424">Furthermore, for example, the present technology can also be applied to a network system including a plurality of devices. For example, the present technology may be implemented as cloud computing shared and processed in cooperation by a plurality of devices via a network. For example, the present technology may be implemented in a cloud service that provides a service related to an image (moving image) to an arbitrary terminal such as a computer, an audio visual (AV) device, a portable information processing terminal, or an Internet of Things (IoT) device.</p><p id="p-0426" num="0425">Note that in the present description, the system means a set of a plurality of components (devices, modules (parts), and the like), and it does not matter whether or not all the components are in the same housing. Therefore, a plurality of devices housed in separate housings and connected via a network, and one device in which a plurality of modules is housed in one housing are all systems.</p><p id="p-0427" num="0426">&#x3c;Field and Application to which Present Technology is Applicable&#x3e;</p><p id="p-0428" num="0427">Note that the system, device, processing unit, and the like to which the present technology is applied can be used in any fields, for example, traffic, medical care, crime prevention, agriculture, livestock industry, mining, beauty, factory, household appliance, weather, nature monitoring, and the like. Furthermore, its use is arbitrary.</p><p id="p-0429" num="0428">For example, the present technology can be applied to systems and devices used for providing contents for appreciation and the like. Furthermore, for example, the present technology can also be applied to systems and devices used for traffic, such as traffic condition management and autonomous driving control. Moreover, for example, the present technology can also be applied to systems and devices used for security. Furthermore, for example, the present technology can be applied to systems and devices used for automatic control of a machine or the like. Moreover, for example, the present technology can also be applied to systems and devices provided for use in agriculture and livestock industry. Furthermore, the present technology can also be applied to systems and devices that monitor, for example, a state of natural such as a volcano, a forest, and the ocean, wildlife, and the like. Moreover, for example, the present technology can also be applied to systems and devices used for sports.</p><p id="p-0430" num="0429">&#x3c;Others&#x3e;</p><p id="p-0431" num="0430">Note that in the present description, the &#x201c;flag&#x201d; is information for identifying a plurality of states, and includes not only information used for identifying two states of true (1) or false (0), but also information that can identify three or more states. Therefore, the value that this &#x201c;flag&#x201d; can take may be, for example, two values of 1 and 0, or 3 or more values. That is, the number of bits constituting this &#x201c;flag&#x201d; is arbitrary, and may be 1 bit or a plurality of bits. Furthermore, identification information (including the flag) is assumed to include not only identification information thereof in a bit stream but also difference information of the identification information with respect to a certain reference information in the bitstream, and thus, in the present description, the &#x201c;flag&#x201d; and &#x201c;identification information&#x201d; include not only the information thereof but also the difference information with respect to the reference information.</p><p id="p-0432" num="0431">Furthermore, various types of information (metadata and the like) related to the coded data (bit stream) may be transmitted or recorded in any form as long as the information is associated with the coded data. Here, the term &#x201c;associate&#x201d; means, for example, that one data can be used (linked) when the other data is processed. That is, the data associated with each other may be collected as one data or may be individual data. For example, information associated with coded data (image) may be transmitted on a transmission path different from that of the coded data (image). Furthermore, for example, the information associated with the coded data (image) may be recorded in a recording medium (or another recording area of the same recording medium) different from the coded data (image). Note that this &#x201c;association&#x201d; may be a part of data instead of the entire data. For example, an image and information corresponding to the image may be associated with each other in an arbitrary unit such as a plurality of frames, one frame, or a part of the frame.</p><p id="p-0433" num="0432">Note that, in the present description, terms such as &#x201c;combine&#x201d;, &#x201c;multiplex&#x201d;, &#x201c;add&#x201d;, &#x201c;integrate&#x201d;, &#x201c;include&#x201d;, &#x201c;store&#x201d;, &#x201c;insert&#x201d;, and &#x201c;insert&#x201d; mean to combine a plurality of items into one, for example, to combine coded data and metadata into one data, and mean one method of the above-described &#x201c;associate&#x201d;.</p><p id="p-0434" num="0433">Furthermore, the embodiments of the present technology are not limited to the above-described embodiments, and various modifications are possible without departing from the scope of the present technology.</p><p id="p-0435" num="0434">For example, a configuration described as one device (or processing unit) may be divided and configured as a plurality of devices (or processing units). Conversely, configurations described above as a plurality of devices (or processing units) may be combined and configured as one device (or processing unit). Furthermore, a configuration other than those described above may of course be added to the configuration of each device (or each processing unit). Moreover, if the configuration and operation of the entire system are substantially the same, a part of the configuration of a certain device (or processing unit) may be included in the configuration of another device (or another processing unit).</p><p id="p-0436" num="0435">Furthermore, for example, the above-described program may be executed in an arbitrary device. In this case, it is sufficient if the device has necessary functions (functional blocks and the like) and can acquire necessary information.</p><p id="p-0437" num="0436">Furthermore, for example, each step of one flowchart may be executed by one device, or may be shared and executed by a plurality of devices. Moreover, in a case where a plurality of processes is included in one step, the plurality of processes may be executed by one device, or may be shared and executed by a plurality of devices. In other words, a plurality of processes included in one step can be executed as processes of a plurality of steps. Conversely, a process described as a plurality of steps can be collectively executed as one step.</p><p id="p-0438" num="0437">Furthermore, for example, in the program executed by the computer, processing of steps describing the program may be executed in time series in the order described in the present description, or may be executed in parallel or individually at necessary timing such as when a call is made. That is, as long as no contradiction occurs, the processes in the respective steps may be executed in an order different from the above-described orders. Moreover, the processes in steps for describing this program may be executed in parallel with processes in another program, or may be executed in combination with processes in another program.</p><p id="p-0439" num="0438">Furthermore, for example, a plurality of techniques related to the present technology can be implemented independently as a single body as long as there is no contradiction. Of course, any plurality of the present technologies can also be used and implemented in combination. For example, part or all of the present technologies described in any of the embodiments can be implemented in combination with part or all of the present technologies described in other embodiments. Furthermore, part or all of any of the above-described present technologies can be implemented by using together with another technology that is not described above.</p><p id="p-0440" num="0439">Note that the present technology can have configurations as follows.</p><p id="p-0441" num="0440">(1) An image processing device including:</p><p id="p-0442" num="0441">a flag generation unit that generates a transform skip flag that is flag information indicating, for each component, whether or not to skip transform processing of transforming a residual between an image and a predicted image of the image into coefficient data in encoding of the image;</p><p id="p-0443" num="0442">a flag encoding unit that encodes the transform skip flag generated by the flag generation unit and generates coded data of the transform skip flag; and</p><p id="p-0444" num="0443">a bit stream generation unit that generates a bit stream including the coded data of the transform skip flag generated by the flag encoding unit.</p><p id="p-0445" num="0444">(2) The image processing device according to (1), further including:</p><p id="p-0446" num="0445">a mode control unit that controls, on the basis of the transform skip flag corresponding to a component identifier generated by the flag generation unit, whether an encoding mode of coefficient data corresponding to the component identifier is set to a TS residual encoding mode that is a mode for a case of skipping the transform processing or a non-TS residual encoding mode that is a mode for a case of not skipping the transform processing; and</p><p id="p-0447" num="0446">a coefficient data encoding unit that encodes coefficient data corresponding to the component identifier by the encoding mode set by the mode control unit and generates coded data of the coefficient data,</p><p id="p-0448" num="0447">in which the bit stream generation unit generates a bit stream including coded data of the transform skip flag generated by the flag encoding unit and the coded data of the coefficient data generated by the coefficient data encoding unit.</p><p id="p-0449" num="0448">(3) The image processing device according to (2), in which</p><p id="p-0450" num="0449">in a case where the transform processing is skipped, the coefficient data encoding unit shares a context variable between encoding of a luminance component of the coefficient data and encoding of a chrominance component.</p><p id="p-0451" num="0450">(4) The image processing device according to (2) or (3), in which</p><p id="p-0452" num="0451">the coefficient data encoding unit applies an encoding method of a sign code according to the transform skip flag generated by the flag generation unit.</p><p id="p-0453" num="0452">(5) The image processing device according to any one of (1) to (4), in which</p><p id="p-0454" num="0453">the flag generation unit further generates a transform skip residual encoding use flag that is flag information indicating whether to apply a TS residual encoding mode that is a mode for a case of skipping the transform processing or to apply a non-TS residual encoding mode that is a mode for a case of not skipping the transform processing,</p><p id="p-0455" num="0454">the flag encoding unit further encodes the transform skip residual encoding use flag generated by the flag generation unit, and generates coded data of the transform skip residual encoding use flag, and</p><p id="p-0456" num="0455">the bit stream generation unit generates the bit stream further including the coded data of the transform skip residual encoding use flag generated by the flag encoding unit.</p><p id="p-0457" num="0456">(6) The image processing device according to any one of (1) to (5), in which</p><p id="p-0458" num="0457">the flag generation unit further generates a transform skip residual encoding use specifying mode flag that is flag information indicating whether to apply a TS residual encoding mode that is a mode for a case of skipping the transform processing or to apply a non-TS residual encoding mode that is a mode for a case of not skipping the transform processing in a specific mode,</p><p id="p-0459" num="0458">the flag encoding unit further encodes the transform skip residual encoding use specifying mode flag generated by the flag generation unit, and generates coded data of the transform skip residual encoding use specifying mode flag, and</p><p id="p-0460" num="0459">the bit stream generation unit generates the bit stream further including coded data of the transform skip residual encoding use specifying mode flag generated by the flag encoding unit.</p><p id="p-0461" num="0460">(7) A bit stream generation method including:</p><p id="p-0462" num="0461">generating a transform skip flag that is flag information indicating, for each component, whether or not to skip transform processing of transforming a residual between an image and a predicted image of the image into coefficient data in encoding of the image;</p><p id="p-0463" num="0462">encoding the transform skip flag generated and generating coded data of the transform skip flag; and</p><p id="p-0464" num="0463">generating a bit stream including the coded data of the transform skip flag generated.</p><p id="p-0465" num="0464">(8) An image processing device including:</p><p id="p-0466" num="0465">a quantization parameter correction unit that, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping transform processing for transforming a residual between an image and a predicted image of the image into a transform coefficient in encoding the image, corrects a quantization parameter to be applied to a processing target transform block corresponding to the component identifier; and</p><p id="p-0467" num="0466">a quantization unit that performs quantization of the processing target transform block corresponding to the component identifier by using the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0468" num="0467">(9) The image processing device according to (8), in which</p><p id="p-0469" num="0468">the quantization parameter correction unit<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0469">sets, in a case where the transform skip flag corresponding to the component identifier indicates the transform skip, one having a larger value of a minimum quantization parameter for the transform skip and a quantization parameter corresponding to the component identifiers as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier, and</li>        <li id="ul0004-0002" num="0470">sets, in a case where the transform skip flag corresponding to the component identifier indicates non-transform skip in which the transform skip is not performed, the quantization parameter corresponding to the component identifier as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier.</li>    </ul>    </li></ul></p><p id="p-0470" num="0471">(10) A quantization coefficient generation method including:</p><p id="p-0471" num="0472">correcting, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping transform processing for transforming a residual between an image and a predicted image of the image into a transform coefficient in encoding the image, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier; and</p><p id="p-0472" num="0473">performing quantization of the processing target transform block corresponding to the component identifier by using the quantization parameter corrected, and generating a quantization coefficient corresponding to the component identifier.</p><p id="p-0473" num="0474">(11) An image processing device including:</p><p id="p-0474" num="0475">a flag decoding unit that decodes coded data of a transform skip flag corresponding to a component identifier and obtains the transform skip flag corresponding to the component identifier;</p><p id="p-0475" num="0476">a mode control unit that controls, on the basis of the transform skip flag corresponding to the component identifier obtained by the flag decoding unit, whether a decoding mode of coded data of coefficient data corresponding to the component identifier is set to a TS residual decoding mode that is a mode for a case of skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, or set to a non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform processing; and</p><p id="p-0476" num="0477">a coefficient data decoding unit that decodes the coded data of the coefficient data corresponding to the component identifier according to the decoding mode set by the mode control unit, and generates the coefficient data corresponding to the component identifier.</p><p id="p-0477" num="0478">(12) The image processing device according to (11), in which</p><p id="p-0478" num="0479">in a case where the inverse transform processing is skipped, the coefficient data decoding unit shares a context variable between decoding of coded data of a luminance component of the coefficient data and decoding of coded data of a chrominance component.</p><p id="p-0479" num="0480">(13) The image processing device according to (11) or (12), in which</p><p id="p-0480" num="0481">the coefficient data decoding unit applies a sign code decoding method according to the transform skip flag corresponding to the component identifier obtained by the flag decoding unit.</p><p id="p-0481" num="0482">(14) The image processing device according to any one of (11) to (13), in which</p><p id="p-0482" num="0483">the flag decoding unit further decodes coded data of a transform skip residual encoding use flag that is flag information indicating whether to apply the TS residual decoding mode or the non-TS residual decoding mode, and obtains the transform skip residual encoding use flag corresponding to the component identifier in a case where the inverse transform processing is skipped, and</p><p id="p-0483" num="0484">the mode control unit further controls whether a decoding mode of the coded data of the coefficient data corresponding to the component identifier is set to the TS residual decoding mode or the non-TS residual decoding mode on the basis of the transform skip residual encoding use flag corresponding to the component identifier generated by the flag decoding unit.</p><p id="p-0484" num="0485">(15) The image processing device according to any one of (11) to (14), in which</p><p id="p-0485" num="0486">the flag decoding unit further decodes coded data of a transform skip residual encoding use specifying mode flag that is flag information indicating whether to apply the TS residual decoding mode or the non-TS residual decoding mode in a specific mode, and obtains the transform skip residual encoding use specifying mode flag corresponding to the component identifier, and</p><p id="p-0486" num="0487">the mode control unit further controls whether a decoding mode of the coded data of the coefficient data corresponding to the component identifier is set to the TS residual decoding mode or the non-TS residual decoding mode on the basis of the transform skip residual encoding use specifying mode flag corresponding to the component identifier generated by the flag decoding unit.</p><p id="p-0487" num="0488">(16) A coefficient data generation method including:</p><p id="p-0488" num="0489">decoding coded data of a transform skip flag corresponding to a component identifier and obtaining the transform skip flag corresponding to the component identifier;</p><p id="p-0489" num="0490">controlling, on the basis of the transform skip flag corresponding to the component identifier obtained, whether a decoding mode of coded data of coefficient data corresponding to the component identifier is set to a TS residual decoding mode that is a mode for a case of skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, or set to a non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform processing; and</p><p id="p-0490" num="0491">decoding the coded data of the coefficient data corresponding to the component identifier according to the decoding mode set, and generating the coefficient data corresponding to the component identifier.</p><p id="p-0491" num="0492">(17) An image processing device including:</p><p id="p-0492" num="0493">a quantization parameter correction unit that, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, corrects a quantization parameter to be applied to a processing target transform block corresponding to the component identifier; and</p><p id="p-0493" num="0494">an inverse quantization unit that performs inverse quantization of a processing target transform block corresponding to the component identifier by using the quantization parameter corrected by the quantization parameter correction unit.</p><p id="p-0494" num="0495">(18) An image processing device according to (17), in which</p><p id="p-0495" num="0496">the quantization parameter correction unit<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0497">sets, in a case where the transform skip flag corresponding to the component identifier indicates the transform skip, one having a larger value of a minimum quantization parameter for the transform skip and a quantization parameter corresponding to the component identifier as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier, and</li>        <li id="ul0006-0002" num="0498">sets, in a case where the transform skip flag corresponding to the component identifier indicates non-transform skip in which the transform skip is not performed, the quantization parameter corresponding to the component identifier as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier.</li>    </ul>    </li></ul></p><p id="p-0496" num="0499">(19) The image processing device according to (17) or (18), further including:</p><p id="p-0497" num="0500">a flag decoding unit that decodes coded data of the transform skip flag corresponding to the component identifier and obtains the transform skip flag corresponding to the component identifier,</p><p id="p-0498" num="0501">in which in a case where the transform skip flag corresponding to the component identifier obtained by the flag decoding unit indicates the transform skip, the quantization parameter correction unit corrects the quantization parameter to be applied to the processing target transform block corresponding to the component identifier.</p><p id="p-0499" num="0502">(20) A coefficient data generation method including:</p><p id="p-0500" num="0503">correcting, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier; and</p><p id="p-0501" num="0504">performing inverse quantization of a processing target transform block corresponding to the component identifier by using the quantization parameter corrected, and generates the coefficient data corresponding to the component identifier.</p><heading id="h-0017" level="1">REFERENCE SIGNS LIST</heading><p id="p-0502" num="0000"><ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0505"><b>100</b> Image encoding device</li>    <li id="ul0007-0002" num="0506"><b>101</b> Control unit</li>    <li id="ul0007-0003" num="0507"><b>114</b> Quantization unit</li>    <li id="ul0007-0004" num="0508"><b>115</b> Encoding unit</li>    <li id="ul0007-0005" num="0509"><b>150</b> Transform mode information encoding unit</li>    <li id="ul0007-0006" num="0510"><b>151</b> Control unit</li>    <li id="ul0007-0007" num="0511"><b>152</b> Selection unit</li>    <li id="ul0007-0008" num="0512"><b>153</b> TS residual encoding unit</li>    <li id="ul0007-0009" num="0513"><b>154</b> Non-TS residual encoding unit</li>    <li id="ul0007-0010" num="0514"><b>155</b> Selection unit</li>    <li id="ul0007-0011" num="0515"><b>200</b> Image decoding device</li>    <li id="ul0007-0012" num="0516"><b>212</b> Decoding unit</li>    <li id="ul0007-0013" num="0517"><b>213</b> Inverse quantization unit</li>    <li id="ul0007-0014" num="0518"><b>250</b> Transform mode information decoding unit</li>    <li id="ul0007-0015" num="0519"><b>251</b> Control unit</li>    <li id="ul0007-0016" num="0520"><b>252</b> Selection unit</li>    <li id="ul0007-0017" num="0521"><b>253</b> TS residual decoding unit</li>    <li id="ul0007-0018" num="0522"><b>254</b> Non-TS residual decoding unit</li>    <li id="ul0007-0019" num="0523"><b>255</b> Selection unit</li>    <li id="ul0007-0020" num="0524"><b>311</b> QP correction unit</li>    <li id="ul0007-0021" num="0525"><b>312</b> Quantization processing unit</li>    <li id="ul0007-0022" num="0526"><b>411</b> QP correction unit</li>    <li id="ul0007-0023" num="0527"><b>412</b> Inverse quantization processing unit</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-01-10" num="01-10"><claim-text><b>1</b>.-<b>10</b>. (canceled)</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. An image processing device comprising:<claim-text>a flag decoding unit that decodes coded data of a transform skip flag corresponding to a component identifier and obtains the transform skip flag corresponding to the component identifier;</claim-text><claim-text>a mode control unit that controls, on a basis of the transform skip flag corresponding to the component identifier obtained by the flag decoding unit, whether a decoding mode of coded data of coefficient data corresponding to the component identifier is set to a TS residual decoding mode that is a mode for a case of skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, or set to a non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform processing; and</claim-text><claim-text>a coefficient data decoding unit that decodes the coded data of the coefficient data corresponding to the component identifier according to the decoding mode set by the mode control unit, and generates the coefficient data corresponding to the component identifier.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The image processing device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein<claim-text>in a case where the inverse transform processing is skipped, the coefficient data decoding unit shares a context variable between decoding of coded data of a luminance component of the coefficient data and decoding of coded data of a chrominance component.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The image processing device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein<claim-text>the coefficient data decoding unit applies a sign code decoding method according to the transform skip flag corresponding to the component identifier obtained by the flag decoding unit.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The image processing device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein<claim-text>the flag decoding unit further decodes coded data of a transform skip residual encoding use flag that is flag information indicating whether to apply the TS residual decoding mode or the non-TS residual decoding mode, and obtains the transform skip residual encoding use flag corresponding to the component identifier in a case where the inverse transform processing is skipped, and</claim-text><claim-text>the mode control unit further controls whether a decoding mode of the coded data of the coefficient data corresponding to the component identifier is set to the TS residual decoding mode or the non-TS residual decoding mode on a basis of the transform skip residual encoding use flag corresponding to the component identifier generated by the flag decoding unit.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The image processing device according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein<claim-text>the flag decoding unit further decodes coded data of a transform skip residual encoding use specifying mode flag that is flag information indicating whether to apply the TS residual decoding mode or the non-TS residual decoding mode in a specific mode, and obtains the transform skip residual encoding use specifying mode flag corresponding to the component identifier, and</claim-text><claim-text>the mode control unit further controls whether a decoding mode of the coded data of the coefficient data corresponding to the component identifier is set to the TS residual decoding mode or the non-TS residual decoding mode on a basis of the transform skip residual encoding use specifying mode flag corresponding to the component identifier generated by the flag decoding unit.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A coefficient data generation method comprising:<claim-text>decoding coded data of a transform skip flag corresponding to a component identifier and obtaining the transform skip flag corresponding to the component identifier;</claim-text><claim-text>controlling, on a basis of the transform skip flag corresponding to the component identifier obtained, whether a decoding mode of coded data of coefficient data corresponding to the component identifier is set to a TS residual decoding mode that is a mode for a case of skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, or set to a non-TS residual decoding mode that is a mode for a case of not skipping the inverse transform processing; and</claim-text><claim-text>decoding the coded data of the coefficient data corresponding to the component identifier according to the decoding mode set, and generating the coefficient data corresponding to the component identifier.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. An image processing device comprising:<claim-text>a quantization parameter correction unit that, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, corrects a quantization parameter to be applied to a processing target transform block corresponding to the component identifier; and</claim-text><claim-text>an inverse quantization unit that performs inverse quantization of a processing target transform block corresponding to the component identifier by using the quantization parameter corrected by the quantization parameter correction unit.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The image processing device according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein<claim-text>the quantization parameter correction unit<claim-text>sets, in a case where the transform skip flag corresponding to the component identifier indicates the transform skip, one having a larger value of a minimum quantization parameter for the transform skip and a quantization parameter corresponding to the component identifier as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier, and</claim-text><claim-text>sets, in a case where the transform skip flag corresponding to the component identifier indicates non-transform skip in which the transform skip is not performed, the quantization parameter corresponding to the component identifier as the quantization parameter to be applied to the processing target transform block corresponding to the component identifier.</claim-text></claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The image processing device according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising<claim-text>a flag decoding unit that decodes coded data of the transform skip flag corresponding to the component identifier and obtains the transform skip flag corresponding to the component identifier,</claim-text><claim-text>wherein in a case where the transform skip flag corresponding to the component identifier obtained by the flag decoding unit indicates the transform skip, the quantization parameter correction unit corrects the quantization parameter to be applied to the processing target transform block corresponding to the component identifier.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A coefficient data generation method comprising:<claim-text>correcting, in a case where a transform skip flag corresponding to a component identifier indicates a transform skip for skipping inverse transform processing of transforming coefficient data into a residual between an image and a predicted image, a quantization parameter to be applied to a processing target transform block corresponding to the component identifier; and</claim-text><claim-text>performing inverse quantization of a processing target transform block corresponding to the component identifier by using the quantization parameter corrected, and generates the coefficient data corresponding to the component identifier.</claim-text></claim-text></claim></claims></us-patent-application>
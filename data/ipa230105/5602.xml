<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005603A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005603</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17366647</doc-number><date>20210702</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>10</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>07</class><subclass>C</subclass><main-group>9</main-group><subgroup>37</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>07</class><subclass>C</subclass><main-group>9</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>35</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>205</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>0205</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>021</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>145</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>024</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>20</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>10</main-group><subgroup>60</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>C</subclass><main-group>9</main-group><subgroup>37</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>C</subclass><main-group>9</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>50</main-group><subgroup>20</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>35</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>40</main-group><subgroup>205</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>00288</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>02055</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>021</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>0816</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>14542</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>4824</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>5</main-group><subgroup>024</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">INTELLIGENT EMERGENCY TRIAGE SYSTEM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>CERNER INNOVATION, INC.</orgname><address><city>KANSAS CITY</city><state>KS</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Rahman</last-name><first-name>Huma</first-name><address><city>Bengaluru</city><country>IN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Prashant</last-name><first-name>Pagi</first-name><address><city>Bengaluru</city><country>IN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Shukla</last-name><first-name>Medha</first-name><address><city>Agra</city><country>IN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Systems and methods for intelligently and accurately triaging a patient are provided. The systems and methods access an electronic health record of the patient based on a detection of an event, such as entering an emergency department. Additionally, the systems and methods collect triage vitals of the patient. Further, free-text within the electronic health record is mapped and binned. In response to the mapping and the binning, the systems and methods input features into an acuity level predictor. Based on inputting the features into the acuity level predictor, the systems and methods output an acuity level of the patient for triaging the patient.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="132.16mm" wi="124.54mm" file="US20230005603A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="243.33mm" wi="154.35mm" orientation="landscape" file="US20230005603A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="235.46mm" wi="135.55mm" orientation="landscape" file="US20230005603A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="242.32mm" wi="152.40mm" orientation="landscape" file="US20230005603A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="215.56mm" wi="157.56mm" orientation="landscape" file="US20230005603A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="251.04mm" wi="161.71mm" orientation="landscape" file="US20230005603A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="244.69mm" wi="148.76mm" orientation="landscape" file="US20230005603A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="244.26mm" wi="143.93mm" orientation="landscape" file="US20230005603A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="230.04mm" wi="162.48mm" file="US20230005603A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="217.17mm" wi="126.58mm" file="US20230005603A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="217.85mm" wi="146.47mm" file="US20230005603A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><p id="p-0002" num="0001">Triage is the process of determining a priority of a patient to be treated based on a condition of the patient and a likelihood of recovery with and without treatment. Triage committees and ad hoc consultative bodies make decisions on how to triage incoming patients. A goal of triaging is to save as many lives as possible, while factoring in resources and personnel. For example, clinicians may determine that resources required for a patient with a low likelihood of survival be diverted to others with higher likelihoods of survival to increase their chances of surviving.</p><p id="p-0003" num="0002">Triage is the first clinical process performed on the patient upon arrival. Typically, patients are first categorized by acuity to prioritize individuals who require urgent medical care. Subsequently, a clinician will attend to the patient. The clinician will create an initial care plan and recommend an approach. Quickly and effectively triaging patients allows for prompt clinical intervention.</p><heading id="h-0002" level="1">SUMMARY</heading><p id="p-0004" num="0003">At a high level, aspects described herein relate to intelligently and accurately triaging a patient. In aspects, based on the detection of an event, a computerized method accesses an electronic health record of the patient and collects triage vitals of the patient. The computerized method maps and bins free-text from the electronic health record and the triage vitals into categorical features using natural language processing. Further, the computerized method transforms numerical features from the electronic health record and the triage vitals using a statistical imputation. Additionally, the computerized method inputs the categorical features that were binned and the numerical features that were transformed into an acuity level predictor. Based on inputting the features into the acuity level predictor, the computerized method outputs an acuity level of the patient for triaging the patient.</p><p id="p-0005" num="0004">In another aspect, non-transitory computer storage media cause a processor to perform operations for intelligently and accurately triaging a patient. The operations comprise accessing an electronic health record of the patient and collecting triage vitals of the patient based on a detection of an event. The operations also comprise mapping and binning free-text from the electronic health record and the triage vitals into categorical features using natural language processing for input into an acuity level predictor. Additionally, the operations comprise inputting the categorical features into the acuity level predictor that uses a machine learning algorithm for recalculating thresholds at each level of a decision tree. Each level of the decision tree corresponds to one of the categorical features. Based on inputting the categorical features into the acuity level predictor, the operations additionally comprise outputting an acuity level of the patient for triaging the patient.</p><p id="p-0006" num="0005">In yet another aspect, an intelligent triage system triages a patient. The intelligent triage system comprises a processor and one or more computer storage media storing computer-executable instructions embodied thereon that when executed by the on processor, cause the processor to perform operations. For example, the intelligent triage system retrieves an electronic health record of the patient and collects triage vitals based on a detection of an event. Additionally, the intelligent triage system maps and bins free-text from the electronic health record and the triage vitals into categorical features using natural language processing for input into an acuity level predictor. Further, the intelligent triage system inputs the categorical features into the acuity level predictor that recalculates a threshold at each level of a decision tree. Each level of the decision tree corresponds to one of the categorical features. Based on inputting the categorical features into the acuity level predictor, the intelligent triage system outputs an acuity level of the patient for triaging the patient.</p><p id="p-0007" num="0006">This summary is intended to introduce a selection of concepts in a simplified form that is further described in the Detailed Description section of this disclosure. The Summary is not intended to identify key or essential features of the claimed subject matter, nor is it intended to aid in determining the scope of the claimed subject matter. Additional objects, advantages, and novel features of the technology are included in the Detailed Description, and in part, will become apparent to those skilled in the art upon examination of the disclosure or learned through practice of the technology.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0008" num="0007">The present technology is described in detail below with reference to the attached drawing figures, wherein:</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is an example flowchart for determining an acuity level, in accordance with an aspect described herein;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>B</figref> provide example tables comprising data for preparation to input features from the data into an acuity level predictor, in accordance with an aspect described herein;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example computational decision tree for determining an acuity level of a patient being triaged, in accordance with an aspect described herein;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example flowchart for determining treatment based on an acuity level, in accordance with an aspect described herein;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an electronic triage powerform chart, in accordance with an aspect described herein;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example emergency room launchpoint, in accordance with an aspect described herein;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an example emergency department tracking board, in accordance with an aspect described herein;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates a schematic diagram for automated triaging, in accordance with an aspect described herein;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>9</b></figref> includes a flowchart for intelligently and accurately triaging a patient via an automated process, in accordance with an aspect described herein; and</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is an example computing environment suitable for implementing aspects of the disclosed technology, in accordance with an aspect described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0019" num="0018">The subject matter of the present technology is described with specificity herein to meet statutory requirements. However, the description itself is not intended to limit the scope of this disclosure. Rather, the inventors have contemplated that the claimed or disclosed subject matter might also be embodied in other ways, to include different steps or combinations of steps similar to the ones described in this document, in conjunction with other present or future technologies. Moreover, although the terms &#x201c;step&#x201d; or &#x201c;block&#x201d; might be used herein to connote different elements of methods employed, the terms should not be interpreted as implying any particular order among or between various steps herein disclosed unless and except when the order of individual steps is explicitly stated.</p><p id="p-0020" num="0019">For purposes of this disclosure, the word &#x201c;including&#x201d; has the same broad meaning as the word &#x201c;comprising,&#x201d; and the word &#x201c;accessing&#x201d; comprises &#x201c;receiving,&#x201d; &#x201c;referencing,&#x201d; or &#x201c;retrieving.&#x201d; Further the word &#x201c;communicating&#x201d; has the same broad meaning as the word &#x201c;receiving,&#x201d; or &#x201c;transmitting&#x201d; facilitated by software or hardware-based buses, receivers, or transmitters&#x201d; using communication media described herein. Also, the word &#x201c;initiating&#x201d; has the same broad meaning as the word &#x201c;executing or &#x201c;instructing&#x201d; where the corresponding action can be performed to completion or interrupted based on an occurrence of another action.</p><p id="p-0021" num="0020">In addition, words such as &#x201c;a&#x201d; and &#x201c;an,&#x201d; unless otherwise indicated to the contrary, include the plural as well as the singular. Thus, for example, the constraint of &#x201c;a feature&#x201d; is satisfied where one or more features are present. Also, the term &#x201c;or&#x201d; includes the conjunctive, the disjunctive, and both (a or b thus includes either a or b, as well as a and b).</p><p id="p-0022" num="0021">For purposes of a detailed discussion above, embodiments of the present technology described with reference to a distributed computing environment; however, the distributed computing environment depicted herein is merely an example. Components can be configured for performing novel aspects of embodiments, where the term &#x201c;configured for&#x201d; or &#x201c;configured to&#x201d; can refer to &#x201c;programmed to&#x201d; perform particular tasks or implement particular abstract data types using code.</p><p id="p-0023" num="0022">As will be described, one or more methods, computer storage media, and systems for intelligently triaging a patient are provided. In the clinical setting, it is difficult to quickly and accurately triage a patient. For example, conventional systems and methods inaccurately triage patients due to an under-evaluation of a high acuity and/or an overestimation of urgency without any severe illness. The overestimation and under-evaluation can result from unaccounted for information, such as particular patient vitals taken during triage and previous clinical data pertaining to the triaged patient stored in an electronic health record. High volumes of patients entering an emergency department for triage may also contribute to the overestimation and under-evaluation of urgency.</p><p id="p-0024" num="0023">Additionally, the conventional systems and methods are slow and have latency issues due to the high volumes and due to reliance on clinicians making decisions for acuity determinations. The acuity determinations made by the conventional methods and systems fail to account for hidden patterns within large volumes of historical clinical data stored, which would enhance accuracy. Further, the acuity determinations of the conventional methods and systems do not analyze and transform input variables, which would enhance the speed and inhibit the latency issues. The conventional systems and methods fail to utilize the decisions for acuity determinations for forecasting patient dispositions and estimating resource utilization for critical care, radiology and laboratory services, intensive care unit admission, and the like.</p><p id="p-0025" num="0024">To solve these problems with the conventional systems and methods, the present aspects described herein provide for improved patient triaging. In aspects, based on the detection of an event, a computerized method accesses an electronic health record of the patient and collects triage vitals of the patient. The computerized method maps and bins free-text from the electronic health record and the triage vitals into categorical features using natural language processing. Further, the computerized method transforms numerical features from the electronic health record and the triage vitals using a statistical imputation. Additionally, the computerized method inputs the categorical features that were binned and the numerical features that were transformed into an acuity level predictor. Based on inputting the features into the acuity level predictor, the computerized method outputs an acuity level of the patient for triaging the patient.</p><p id="p-0026" num="0025">In an embodiment, non-transitory computer storage media cause a processor to perform operations for intelligently and accurately triaging a patient. The operations comprise accessing an electronic health record of the patient and collecting triage vitals of the patient based on a detection of an event. The operations also comprise mapping and binning free-text from the electronic health record and the triage vitals into categorical features using natural language processing for input into an acuity level predictor. Additionally, the operations comprise inputting the categorical features into the acuity level predictor that uses a machine learning algorithm for recalculating thresholds at each level of a decision tree. Each level of the decision tree corresponds to one of the categorical features. Based on inputting the categorical features into the acuity level predictor, the operations additionally comprise outputting an acuity level of the patient for triaging the patient.</p><p id="p-0027" num="0026">In yet another embodiment, an intelligent triage system triages a patient. The intelligent triage system comprises a processor and one or more computer storage media storing computer-executable instructions embodied thereon that when executed by the on processor, cause the processor to perform operations. For example, the intelligent triage system retrieves an electronic health record of the patient and collects triage vitals based on a detection of an event. Additionally, the intelligent triage system maps and bins free-text from the electronic health record and the triage vitals into categorical features using natural language processing for input into an acuity level predictor. Further, the intelligent triage system inputs the categorical features into the acuity level predictor that recalculates a threshold at each level of a decision tree. Each level of the decision tree corresponds to one of the categorical features. Based on inputting the categorical features into the acuity level predictor, the intelligent triage system outputs an acuity level of the patient for triaging the patient.</p><p id="p-0028" num="0027">Implementation of the embodiments above provides for faster and more accurate patient triaging without having to rely upon human subjective determinations. Additionally, implementation of the embodiments result in more accurate determinations of acuity with less under-evaluations and overestimations of urgency without any severe illness. Further, these implementations result in reduced wait time for patient treatment, improved queuing of patients, improved qualities of emergency department services, decreased morbidity, improved emergency department throughput, improved boarding, decreased errors in patient treatment, and overall improved qualities of care.</p><p id="p-0029" num="0028">Referring now to the drawings, <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example emergency department workflow <b>100</b> based on acuity level. An acuity level predictor <b>114</b> determines an acuity level by using a machine learning algorithm and patient data comprising historical clinical data stored in an electronic health record and vitals that are collected and measured during triage of the patient. The acuity level predictor <b>114</b> provides decision support by predicting acuity and the likelihood of radiology services, intensive care unit admissions, and inpatient hospitalizations. The electronic health record may include data from various electronic health record systems that are communicatively coupled to a network. For example, the electronic health record systems may comprise electronic health records from a hospital, a health information exchange, and an ambulatory clinic. Additionally, other electronic health records may include records from a mental health facility and a behavioral health facility.</p><p id="p-0030" num="0029">Referring back to the acuity level, a five-level triage algorithm may include the following example acuity levels:</p><p id="p-0031" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="217pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 1</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Acuity Levels</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="offset" colwidth="35pt" align="left"/><colspec colname="1" colwidth="84pt" align="left"/><colspec colname="2" colwidth="98pt" align="left"/><tbody valign="top"><row><entry/><entry>Acuity Level</entry><entry>Health Deterioration</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row><row><entry/><entry>Level 1</entry><entry>Resuscitation</entry></row><row><entry/><entry>Level 2</entry><entry>Emergent</entry></row><row><entry/><entry>Level 3</entry><entry>Urgent</entry></row><row><entry/><entry>Level 4</entry><entry>Less Urgent</entry></row><row><entry/><entry>Level 5</entry><entry>Non-Urgent</entry></row><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0032" num="0030">Referring to Table 1, a patient who has an acuity level 1 would have a higher need for particular resources than a patient who has an acuity level of 3-5. For example, a patient having acuity level 1 may require immediate intervention to save her life or to save her limb. As another example, a patient having acuity level 2 may have a high risk for requiring a treatment sensitive to time. Further, patients who are not assigned to the first two levels are assigned to levels 3-5. Resource availability has an impact on which level a patient is assigned. In some embodiments, a patient at level 3 requires two or more resources, at level 4 requires one resource, and at level 5 requires no resources.</p><p id="p-0033" num="0031">Conventional systems have nurses or other humans determining acuity levels for patients. For example, nurses would determine which facilities are required for the patient and determine an acuity level based on the facilities required. By contrast, the acuity level predictor <b>114</b> provides for more accurate acuity levels based on hidden patterns in large volumes of historical clinical data that conventional systems failed to detect and utilize. As a result, the acuity level predictor <b>114</b> improves resource distribution (e.g. in the emergency department), more effectively ques patients, and decreases morbidity by providing rapid and informed decisions that enhance resource planning.</p><p id="p-0034" num="0032">As such, example emergency department workflow <b>100</b> provides for an example triaging scheme based on acuity level. Example emergency department workflow <b>100</b> comprises an emergency department <b>102</b>, triage area <b>110</b>, boarding in the emergency department <b>140</b>, and inpatient (IP) treatment area <b>150</b>. Upon patient arrival <b>104</b> at the emergency department <b>102</b>, a triage nurse <b>112</b> attends to the patient within the triage area <b>110</b>. The triage nurse <b>112</b> may enter the name of the patient and/or other identification information into a computing device that is in communication with one or more electronic health record systems comprising one or more electronic health records.</p><p id="p-0035" num="0033">Additionally, the triage nurse <b>112</b> may take the patient's vitals. For example, vitals may include temperature, oxygen saturation, blood pressure, respiratory rate, heart rate, and so forth. In some embodiments, the nurse acquires the vitals via one or more devices. In some embodiments, vitals are captured via a video device, an audio device, heat sensors, facial imaging devices, and/or other detection devices. In some embodiments, vitals may be captured via an x-ray radiology device that collects information audibly, visually, and/or electronically available within a range of the x-ray radiology device. Continuing the example, a communication interface (e.g., Wi-Fi, near field communication, universal serial bus, Ethernet, open natural interaction, natural user interface, etc.) is included in or with the x-ray radiology device for capturing environmental data and other patient information in addition to image data captured via the x-ray radiology device.</p><p id="p-0036" num="0034">Using the electronic health records corresponding to the patient and the vitals, the acuity level predictor <b>114</b> determines an acuity level. In some embodiments, the acuity level scale ranges from 1-5, such as the Emergency Severity Index (ESI). For acuity levels 3-5, those patients enter the waiting room <b>116</b>. In some embodiments, 72.9% of all patients who enter the emergency department <b>102</b> receive an acuity level of 3, 4, or 5. For the patients with an acuity level of 3, 4, or 5, those patients have a lower risk of health deterioration while waiting for emergency department services than patients with an acuity level of 1 or 2. By improving inaccurate triaging based on human error that leads to adverse events, acuity level predictor <b>114</b> improves patient safety and care quality at least in part by reducing this error.</p><p id="p-0037" num="0035">Further, conventional systems that introduce more error result in patients leaving without being seen (LWBS) <b>118</b>. For example, studies suggest that patients that nurses incorrectly triaged as an ESI level 3, but should have been triaged as an ESI level 2, will LWBS <b>118</b>. Continuing the example, some studies suggest that up to 80% of patients who enter an emergency department and sit in the waiting room will LWBS <b>118</b>. As such, acuity level predictor <b>114</b> provides for improved allocation of services by more accurately triaging patients.</p><p id="p-0038" num="0036">In some embodiments within the triage area <b>110</b>, patients assigned an acuity level of 4 or 5 via the acuity level predictor at step <b>120</b> are further assessed at <b>122</b> by registered nurses (RNs) and/or mid-level practitioners (MLPs) who have a defined scope of practice. Continuing the example, in some embodiments, 25% of the 72.9% of patients (having an acuity level 3-5) have an acuity level of 4 and 5. Based on the assessment at <b>122</b> by the MLP and/or the RN, the patients having the acuity level of 4 and 5 are either sent to a clinic or a pharmacy at <b>124</b> or receive treatment at <b>128</b>. Those who receive treatment at <b>128</b> are subsequently discharged at <b>130</b>. Patients who were under-triaged as 4 and 5, but should have been triaged as a lower acuity level, increase the crowding in the waiting room <b>116</b> and increase the wait time for services. For example, patients who were under-triaged by a conventional system would have needed treatment from the emergency department treatment room <b>142</b> or would have needed an inpatient bed <b>152</b>, but instead were sitting in the waiting room <b>142</b>.</p><p id="p-0039" num="0037">In some embodiments within the triage area <b>110</b>, patients assigned an acuity level of 3 via the acuity level predictor at step <b>120</b> are further assessed at <b>126</b> by an MLP and/or an RN. Continuing the example, in some embodiments, 75% of the 72.9% of patients (having an acuity level 3-5) have an acuity level of 3. Upon assessment at <b>126</b>, the patients having the acuity level of 3 are either sent to the emergency department treatment room at <b>142</b> within boarding in the emergency department <b>140</b>, or are sent to the inpatient bed at <b>152</b> within the IP treatment area <b>150</b>. In some embodiments, the patient moves from the emergency department treatment room at <b>142</b> to the critical care unit <b>154</b>. Continuing the example, after the critical care unit <b>154</b>, the patient may move to the inpatient bed at <b>152</b> and thereafter be discharged <b>160</b>.</p><p id="p-0040" num="0038">For a conventional system that over-triages patients, the result of this over-triage includes increased crowding at the emergency department room <b>142</b>. For example, patients who were over-triaged as 3, but should have been triaged as a 4 or a 5, increase crowding during boarding in the emergency department <b>140</b> and increase the wait time for emergency department services for patients actually having a greater need for those services. As such, acuity level predictor <b>114</b> provides for improved allocation of services by improving boarding in the emergency department <b>140</b> and by making boarding in the emergency department <b>140</b> more efficient due to more accurately triaging patients.</p><p id="p-0041" num="0039">Returning to acuity level predictor <b>114</b>, in some embodiments, the acuity level predictor <b>114</b> assigns 26.3% of the patients who enter the emergency department <b>102</b> an acuity level 2. As illustrated in workflow <b>100</b>, the patients who are assigned an acuity level 2 receive boarding in the emergency department <b>140</b> for the emergency department treatment room <b>142</b>. Thereafter, the patient is processed in the IP treatment area <b>150</b> for an inpatient bed <b>152</b> or a critical care unit <b>154</b>. If assigned to the critical care unit <b>154</b>, the patient may then be assigned to the inpatient bed <b>152</b>. After the inpatient bed <b>152</b>, the patient may be discharged <b>160</b>.</p><p id="p-0042" num="0040">Further, in some embodiments, the acuity level predictor <b>114</b> assigns 0.8% of the patients who enter the emergency department <b>102</b> an acuity level 1. These patients assigned acuity level 1 are sent to a cardiopulmonary resuscitation (CPR) room <b>132</b>. From there, the patients either die <b>134</b> or are then sent to the emergency department treatment room <b>142</b>. Thereafter, the patient is processed in the IP treatment area <b>150</b> for an inpatient bed <b>152</b> or a critical care unit <b>154</b>. If assigned to the critical care unit <b>154</b>, the patient may then be assigned to the inpatient bed <b>152</b>. After the inpatient bed <b>152</b>, the patient may be discharged <b>160</b>.</p><p id="p-0043" num="0041">Turning now to <figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>B</figref>, <figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>B</figref> provide example tables comprising data prepared as input features into an acuity level predictor. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, the data for preparation may comprise a response variable <b>202</b>, demographics <b>204</b>, triage vitals <b>206</b>, hospital usage <b>208</b>, chief complaints <b>200</b>, imaging <b>212</b>, past medical history <b>214</b>, and home medication <b>216</b>. The data for preparation may be stored in the electronic health record. Beginning with response variable <b>202</b>, include predicted acuity levels by the acuity level predictor for a particular patient or for a sample population of patients.</p><p id="p-0044" num="0042">Turning now to demographics <b>204</b>, demographics <b>204</b> may include an insurance provider, an insurance card grouping number, provider information for specialists, primary care provider information, date of birth, age, gender, ethnicity, country of origin, first name, family name, middle name(s), home address, work address, etc. Additionally, triage vitals <b>206</b> may include body temperature, blood pressure, heart rate, respiratory rate, blood oxygen level, a pain score (e.g., a numerical rating scale, a visual analog scale, a categorical scale), etc. In addition, hospital usage <b>208</b> may include a number of emergency department visits within a period of time (e.g., a year or a lifetime), a number of admissions into a particular hospital, a number and types of surgeries performed on the patient within a period of time (e.g., a year or a decade), and a number and types of procedures performed on the patient within a period of time.</p><p id="p-0045" num="0043">Turning to chief complaints <b>210</b>, chief complaints <b>210</b> may include a problem on admission, an initial comment to a clinician, an observed or detected degree of severity, and observed or detected symptoms. Further, examples of imaging <b>212</b> include a number of chest x-rays, an echocardiogram, a computerized tomography scan, magnetic resonance imaging, and medical ultrasound. In some embodiments, the imaging <b>212</b> may only include imaging <b>212</b> within the past year. Additionally, examples of past medical history <b>214</b> include information related to diet and exercise, allergy information, immunization history, family medical history, social history, relevant chronic illnesses, prior diseases, etc. Turning to home medications <b>216</b>, home medications <b>216</b> may include active home medications, an amount of a strength of the medication taken within a period of time, a method of administration of the medication, etc.</p><p id="p-0046" num="0044">Preparation of the data (e.g., the response variable <b>202</b>, the demographics <b>204</b>, the triage vitals <b>206</b>, the hospital usage <b>208</b>, the chief complaints <b>200</b>, the imaging <b>212</b>, the past medical history <b>214</b>, and the home medication <b>216</b>) may include mapping and binning. For example, data from the chief complaints <b>210</b> stored in the electronic health record are extracted and binned into the &#x201c;chief complaints&#x201d; <b>210</b> category. Additionally, data within the chief complaints <b>210</b> category are further mapped and binned into a plurality of categorical features. For example, the chief complaints having an observed or detected degree of severity of 8-10 are mapped and binned into one category feature, and the chief complaints having the observed or detected degree of severity of 4-6 are mapped and binned into a second category feature.</p><p id="p-0047" num="0045">Further, the data (e.g., the free-text) from the chief complaints <b>210</b> category may be reduced to binary variables (e.g., a high detected degree of severity 1, a low detected degree of severity 0; admitted patient was unconscious 1 (yes), admitted patient was not unconscious (0)) by binning frequent data in a plurality of categories. As another example, ICD-9 codes corresponding to the past medical histories <b>214</b> may be mapped to <b>281</b> categories by binning to a binary variable. In yet another example, features of the active home medications <b>216</b> may be binned into 48 therapeutic subgroups (e.g., analgesics) based on values that are most frequent. Each category may comprise a number of variables.</p><p id="p-0048" num="0046">In some embodiments, a pattern classifier may determine one or more patterns of the mapped and binned information. Further, the classifier may also determine one or more patterns corresponding to the binary variables. The classifier may include a plurality of classifiers. Further, a single software module may implement the classifier or the plurality of classifiers. Patterns in both numerical values and free-text may be determined. In some embodiments, a change to a knowledge representation caused by training may only require duplication of one model. Pattern(s) determined may be used for further determinations of an feature importance corresponding to a respective category.</p><p id="p-0049" num="0047">In some embodiments, for example, numerical features (e.g., temperature, blood pressure, respiratory rate, pain score, heart rate, age, number of hospital visits in the past 1 year, number of surgeries/procedures in past 1 year, etc.) are transformed by null handling using median and mean imputation. For example, median and mean imputation may be determined from electronic health record data corresponding to a plurality of patients having predetermined similarities (e.g., data from patients within a particular age range having a similar number of the same procedure, a similar body weight, a similar height, and a similar city of origin may be used for missing value imputations). In some embodiments, the median and mean imputation may be determined from historical electronic health record data corresponding to the patient being triaged. The median and mean imputation(s) may be used for further determinations of the feature importance corresponding to the respective category.</p><p id="p-0050" num="0048">In some embodiments, natural language processing (NLP) software maps and bins free-text from the electronic health record and the triage vitals into categories and categorical features. Machine learning algorithms may include supervised learning based on mapping variables, from information for a plurality of patients having a known ESI, to a fixed set of labels based on the known ESI. For example, the NLP software extracts the information for the plurality of patients having the known ESI from an open-source website having a plurality of emergency department electronic health records. In another embodiment, the NLP software extracts the information for the plurality of patients having the known ESI from a plurality of hospital electronic health records. In some embodiments, the information is extracted from one system corresponding to an emergency department.</p><p id="p-0051" num="0049">Turning to <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, the left column includes a feature importance and the right column corresponds to the variable. For example, the triage vital heart rate <b>220</b> has a feature importance of 0.705, the triage vital systolic blood pressure <b>222</b> has a feature importance of 0.441, the triage vital diastolic blood pressure <b>224</b> has a feature importance of 0.161, the triage vital respiratory rate <b>226</b> has a feature importance of 0.056, the triage vital oxygen saturation <b>228</b> has a feature importance of 0.050, the triage vital oxygen saturation via pulse oximetry <b>230</b> has a feature importance of 0.039, the triage vital temperature <b>232</b> has a feature importance of 0.029, the triage vital corresponding to a previous disposition of the patient <b>234</b> has a feature importance of 0.006, the triage vital number of emergency department visits <b>236</b> has a feature importance of 0.006, the triage vital number of admissions <b>238</b> has a feature importance of 0.006, and the triage vital number of surgeries <b>240</b> has a feature importance of 0.005.</p><p id="p-0052" num="0050">One or more processors may determine the feature importance using a decision tree. For example, the feature importance may be determined using a Gini index (an impurity measure for determining the split at an internal node of a decision tree, such as a random forest) and an entropy gain. For example, higher feature importance scores indicate that the corresponding feature is more predictive than the lower feature importance scores. The feature importance of each feature may be determined based on a total decrease in node purity averaged over each tree in the forest. By using the categories from the mapping and the binning for the decision tree, the decision tree is better able to perform classification or regression tasks without undue increase in computational load.</p><p id="p-0053" num="0051">Turning to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example decision tree <b>300</b> for a computing system that determines an acuity level of a patient being automatically and intelligently triaged. The size and shape of the decision tree depends on various factors, such as the number of independent variables that are found to be significant for predictions based on the feature importance scores. Further, mapping and binning of categories and determinations of the feature importance scores dictate the order in which a tree-generation algorithm analyzes the category features, numerical features, and so on. In some embodiments, the decision tree <b>300</b> may require or rely on ensembles or collections of many different trees (e.g., respective trees obtained using respective subsets of training data sets).</p><p id="p-0054" num="0052">At decision node <b>302</b>, if the patient being triaged includes an accident/burn calamity case, then the acuity level predictor gives the patient an acuity level of 1 at <b>304</b>. If the patient is not an accident/burn calamity case, then decision node <b>306</b> determines whether the patient has an age that is above a threshold (e.g., a patient who is 80 or older). If the patient is at an age over the threshold, then decision node <b>308</b> determines whether the patient has a particular active home medication (e.g., a medication with a particular active ingredient). If the patient has the particular active home medication, then decision node <b>310</b> determines whether the patient has had a particular number of emergency department visits in the past year. If the number of emergency department visits exceeds a threshold, then the acuity level predictor gives the patient an acuity level of 1 at <b>312</b>. If the number of emergency department visits does not exceed the threshold, then the acuity level predictor gives the patient an acuity level of 3 at <b>316</b>.</p><p id="p-0055" num="0053">Turning back to <b>308</b>, if the decision node determines that the patient does not have the particular active home medication, then decision node <b>320</b> determines whether the patient has a particular chief complaint or a particular feature of the particular chief complaint. If the patient has the particular chief complaint or the particular feature, then the acuity level predictor gives the patient an acuity level of 4 at <b>322</b>. If the patient does not have the particular chief complaint or the particular feature, then the acuity level predictor gives the patient an acuity level of 4 at <b>322</b>. Continuing the example, the particular chief complaint or the particular feature of the particular chief complaint may have a feature importance score of 0.005, which is lower than the other feature importance scores.</p><p id="p-0056" num="0054">Turning back to <b>306</b>, if the patient is at an age that is not over the threshold, then if the patient has other triage vitals that the acuity level predictor determines are at level 1, then the patient receives an acuity level of 1 at <b>332</b>. If the patient does not have the other triage vitals, then the decision node <b>334</b> determines whether the patient has a triage vital that the acuity level predictor determines is level 2. If the patient has these level 2 triage vitals, then the patient receives an acuity level of 2 at <b>336</b>. If the patient does not have these level 2 triage vitals, then the patient receives an acuity level of 3 at <b>338</b>.</p><p id="p-0057" num="0055">Turning to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example flowchart <b>400</b> for patient interaction with a predetermined solution within the emergency department. At the emergency department, a patient <b>404</b> enters the emergency room and data is immediately reflected within a launchpoint dashboard <b>402</b>. At <b>406</b>, the patient <b>404</b> is automatically or manually registered with a computing system in communication with at least one electronic medical record of the patient <b>404</b>. If the patient <b>404</b> is not automatically registered at <b>408</b>, the system may require manual entry of the patient <b>404</b>. launch point <b>402</b> displays the data captured during the registration. Upon registration, triage powerform <b>410</b> is charted by a triage nurse. After the triage powerform <b>410</b> is signed and submitted, the system initiates a launchpoint <b>412</b>. The data is then reflected on launchpoint <b>412</b>, triage documentation <b>414</b>, and an emergency department tracking board <b>416</b>. Launchpoint <b>412</b> initiates the emergency department workflow from triage through discharge. The triage documentation <b>414</b> automatically provides templates for documentation based on symptoms upon entry and/or age and gender. The documentation may be stored in a database associated with the electronic health record system. The emergency department tracking board <b>416</b> provides for tracking a status of the patient and monitoring resource availability.</p><p id="p-0058" num="0056">The triage powerform <b>410</b> may receive manual information including an oral temperature, heart rate, respiratory rate, and blood pressure. In some embodiments, triage powerform <b>410</b> may automatically populate an onset date and time, a mode of arrival, and a reason for visit. In some embodiments, triage powerform <b>410</b> automatically populates vitals using sensors (e.g., a thermal imaging camera or infrared pyrometer). In some embodiments, triage powerform <b>410</b> automatically populates a weight and height of the patient by extracting the information from an electronic medical record of the patient.</p><p id="p-0059" num="0057">As an example, a clinician may enter into a chief complaint or mechanism of injury entry area that that patient has severe abdominal pain, is vomiting, and has nausea. Continuing the example, another entry area may include a reason for not obtaining current visit information, which may include a list for selection of the following: none, clinical condition, cognitive impairment, intubated, language barrier, physical impairment, sedated, and other. Additionally, another entry area may include demonstrating signs and symptoms of the following condition, which may include a list for selection of the following: acute coronary syndrome, asthma, heart failure, pneumonia, stroke, and venous thromboembolism. In some embodiments, triage powerform <b>410</b> automatically populates allergy information of the patient by extracting the information from the electronic medical record of the patient.</p><p id="p-0060" num="0058">Based on categorical features and numerical features corresponding to data received by the triage powerform <b>410</b> and data extracted by the triage powerform <b>410</b> from the electronic health record, an acuity level of the patient for triaging is determined. Based on the acuity level, a treatment decision <b>418</b> is provided. For example, treatment decision <b>418</b> may present for display a tracking group that the patient was grouped into (e.g., grouping based on a level of cognition when entering an ambulatory vehicle or the emergency department). As another example, the treatment decision <b>418</b> may present for display the acuity level (e.g., emergent).</p><p id="p-0061" num="0059">Examples of an acuity level 1 may include immediate life-saving intervention needed, including airway medications, other hemodynamic interventions, and any of the following clinical conditions: intubated, apneic, pulseless, severe respiratory distress, SpO<sub>2 </sub>less than 90%, acute mental status changes, unresponsiveness (e.g., nonverbal or requires noxious stimulus). An example of an acuity level 2 may include high risk situations wherein a patient is in severe pain or distress and has a pain score of 7 or higher on a pain scale of 0-10. Further, an example of an acuity level 3 may include a need for electrolytes/coagulations and a chest x-ray. An example of an acuity level 4 may include a need for electrolytes/coagulations (i.e., one resource). Additionally, an example of an acuity level 5 may include a patient who does not need any resources.</p><p id="p-0062" num="0060">The treatment decision <b>418</b> may provide an acuity level and a recommended treatment procedure based on whether the patient needs an immediate life-saving intervention; whether the patient is confused, lethargic, disoriented, in severe pain, and/or in severe distress; the number of resources the patient needs; and/or vital signs that the patient has or is exhibiting. The recommended treatment procedure may include ICU admission <b>420</b>, inpatient admission <b>422</b>, lab/radiology testing <b>424</b>, and discharge <b>426</b>. For example, the launchpoint <b>412</b> may display an outcome predictor that provides a predicted probability that the patient will need the ICU admission <b>420</b>, the inpatient admission <b>422</b>, and/or the lab/radiology testing <b>424</b>. In some embodiments, in response to providing the acuity level and/or the recommended treatment(s), the system provides a selection to accept the acuity level predicted. Upon providing the selection, a user may select to accept or override (e.g., upon the entry of improper data) the acuity level predicted.</p><p id="p-0063" num="0061">Turning <figref idref="DRAWINGS">FIG. <b>5</b></figref>, an example selectable, editable electronic triage powerform chart <b>500</b> is illustrated. Powerform chart <b>500</b> comprises editable sections including a chief complaint or mechanism of injury, a reason that the system was unable to obtain current visit information, signs and symptoms of various conditions, an onset date and time, a mode of arrival, a level of consciousness, and an orientation. The editable selections may be automatically populated by the electronic system in some embodiments. For example, a device comprising video and audio sensors may detect and determine that the patient is vomiting in the ambulance or the emergency room. Further, other editable selections may include vital signs, weight and height, a pregnancy status, allergy information, past medical history, a reason for visit, and problems being addressed during the visit. An acuity level may be predicted upon selection of an acuity button. Further, a selection to accept or not to accept the acuity prediction may be received.</p><p id="p-0064" num="0062">Turning to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, example emergency room launchpoint <b>600</b> comprises tabs for patients corresponding to a particular provider of care in the emergency department, bed availability, patients on a fast track to discharge, and a check-out list. Each tab may provide a list of &#x201c;my patients,&#x201d; &#x201c;unassigned patients,&#x201d; &#x201c;empty beds,&#x201d; &#x201c;patients in the waiting room,&#x201d; and &#x201c;department information.&#x201d; Further, the emergency room launchpoint <b>600</b> also includes patient information, information about the nurses and doctors attending to the patient, and outcome predictors. Outcome predictors use the proposed acuity level from the acuity level predictor and to estimate, for example, whether the patient will need imaging, advanced diagnostic imaging, an ICU bed, inpatient admission, other critical care resources, and so forth.</p><p id="p-0065" num="0063">In embodiments, a learning classification/regression model capable of improving accuracy of the classifications via labeling categorical features without increasing computational overhead for learning and classifying. For example, the classification regression model may be trained using training data and labeling pairs for predicting an outcome. Labeling may correspond to categories (e.g., chief complaints and active home medications), subcategories (e.g., 48 therapeutic subgroups of the active home medications), and one or more corresponding acuity levels. Training data may correspond to acuity levels correctly determined for a plurality of patients from one or more electronic health records. In embodiments, during the learning process, a computing system lists combinations of labels appearing together in one or more training data to obtain a combination of labels expected to appear together for an input.</p><p id="p-0066" num="0064">Turning now to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, example emergency department tracking board <b>700</b> comprises patient information including name, bed location, age, a predicted acuity level, outcome predictions, a chief complaint, attending clinician information, and a medical identification. Further, example emergency department tracking board <b>700</b> provides warning icons for patients who need immediate assistance. Additionally, a number of patients in the waiting room is provided. Further, other icons for radiology and medications are illustrated on the emergency department tracking board <b>700</b>. The radiology predictor icon provides for rapid identification of patients who require radiology imaging during their emergency department visit. The predictor icons assist clinicians in identifying those with a higher risk of ICU admission. Further, the predictor icons help reduce emergency department ICU wait time. Furthermore, the emergency department tracking board <b>700</b> helps clinicians to manage resources more efficiently to reduce boarding errors and delays.</p><p id="p-0067" num="0065">Turning to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic diagram <b>800</b> for automated triaging. Triaging begins upon the occurrence of a trigger event <b>802</b>, such as a patient entering an emergency department or an ambulatory vehicle. In some embodiments, the triggering event is a video call from a patient to an emergency department. In some embodiments, the triggering event includes a facial recognition system detecting an identity of the patient upon the video call, entrance into the emergency department, or entrance into the ambulatory vehicle using an image sensor. Upon detection of the identity, the facial recognition system associates the patient with one or more electronic health records of the patient (from one or more electronic health record systems) using the image sensor and images stored in a database.</p><p id="p-0068" num="0066">Upon occurrence of the triggering event <b>802</b>, one or more electronic health records <b>804</b> of the patient are retrieved and data is extracted. For example, the extracted data may comprise demographics <b>804</b>A, past medical history <b>804</b>B, medications <b>804</b>C, prior emergency visits <b>804</b>D, and imaging and lab data <b>804</b>E. Further, triage vitals <b>806</b> are collected for data preparation. Triage vitals <b>806</b>, for example, include a pain score <b>806</b>A, a temperature <b>806</b>B, a blood pressure <b>806</b>C, a respiratory rate <b>806</b>D, an oxygen saturation level <b>806</b>E, and a heart rate <b>806</b>F. The one or more electronic health records <b>804</b> and the triage vitals <b>806</b> are further prepared for data processing <b>808</b>.</p><p id="p-0069" num="0067">Data processing <b>808</b> may include using natural language processing to map and bin the data to categories (e.g., chief complaints and medications) and subcategories (e.g., active ingredients in the medications having a known particular side effect). For example, an associative rule-based learning technique may be used in conjunction with an NLP technique to parse a set of textual data associated with a particular category and/or subcategory. In some embodiments, binning the categorical and sub-categorical data may include generating a series of data entries (e.g., within a database corresponding to an electronic health record system) for one or more particular categories and mapping one or more language attributes of the series subcategories based on common attributes. An associative rule-based learning technique may be used in conjunction with the NLP technique to ascertain a lexical context in which the data entries are used to identify attributes, meanings, and/or context.</p><p id="p-0070" num="0068">Data processing <b>808</b> may also include transforming numerical features from the electronic health record and the triage vitals using a statistical imputation. For example, missing values in a column may be identified and replaced by calculating a statistical value for each column and replacing the missing value with the statistic (e.g., the mean). Values in a column may include values from one or more electronic medical records corresponding to the particular patient or a plurality of patients that have at least one similarity with respect to a category and/or subcategory (e.g., the plurality of patients and the particular patient are within the same age range and each have had at least one stroke).</p><p id="p-0071" num="0069">Further, acuity level predictor <b>810</b> uses a machine learning algorithm to determine an acuity level for a patient based on inputting features into the acuity level predictor <b>810</b>. For example, the algorithm may calculate an importance feature at each level of a decision tree. Each level may have a different threshold based on the particular features of each patient and based on the prior importance feature determination. Further, each tree in the forest may be trained with a splitting criterion ensuring division of training data such that the instances in each child node, maximally agree on a solver of preference. In embodiments, partitioning stops when an amount of data in the child node is too small. In some embodiments, each tree is trained on a random subset of 70% of the data and a random subset of 30% considered features to ensure variation and to validate findings. Further, upon presentation of a new instance, each tree may vote for the best solver based on its data.</p><p id="p-0072" num="0070">In embodiments, the tree-based approach is suitable for classification problem(s) with multi-class classification. For example, the decision tree model works wherein the root node is the condition(feature) on which split is decided using the Gini index method. This tree-based approach is computationally fast and highly scalable. In practice, an application of the tree-based approach was compared to prior predictions by a trained human. The comparison showed that the tree-based approach was 89% accurate compared to the 68% accuracy of the predictions by the trained human. As such, turning to accuracy and verification <b>812</b>, the accuracy of the model may be calculated using a Confusion matrix and further validated using a statistical test Area under the Curve (AUC). In practice, an AUC of 0.91 was achieved with using the full list of variables: patients' age, gender, arrival time, arrival mode, triage vital signs, chief complaint, prior hospital, and emergency department admissions, number of procedures and surgeries listed in the patient's record, medical history, medications, and number of orders for imaging. For example, an example calculation of the metrics required to measure algorithm performance is reproduced below:</p><p id="p-0073" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="217pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 2</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>AUC Calculation</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="offset" colwidth="14pt" align="left"/><colspec colname="1" colwidth="56pt" align="left"/><colspec colname="2" colwidth="70pt" align="char" char="."/><colspec colname="3" colwidth="77pt" align="left"/><tbody valign="top"><row><entry/><entry>AUC</entry><entry>0.864733</entry><entry/></row><row><entry/><entry>Cutoff</entry><entry>0.343</entry><entry>Optimal</entry></row><row><entry/><entry>Train_test split</entry><entry>70:30:00</entry><entry>Random method</entry></row><row><entry/><entry namest="offset" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="5"><colspec colname="1" colwidth="63pt" align="center"/><colspec colname="2" colwidth="35pt" align="center"/><colspec colname="3" colwidth="42pt" align="center"/><colspec colname="4" colwidth="28pt" align="center"/><colspec colname="5" colwidth="49pt" align="center"/><tbody valign="top"><row><entry/><entry>precision</entry><entry>recall</entry><entry>f1-score</entry><entry>support</entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row><row><entry>0</entry><entry>0.87</entry><entry>0.86</entry><entry>0.87</entry><entry>7526</entry></row><row><entry>1</entry><entry>0.86</entry><entry>0.86</entry><entry>0.86</entry><entry>7474</entry></row><row><entry>accuracy</entry><entry/><entry/><entry>0.86</entry><entry>15000</entry></row><row><entry>macro avg</entry><entry>0.86</entry><entry>0.86</entry><entry>0.86</entry><entry>15000</entry></row><row><entry>weighted avg</entry><entry>0.86</entry><entry>0.86</entry><entry>0.86</entry><entry>15000</entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0074" num="0071">Lastly, output <b>814</b> includes outputting an acuity level upon inputting features into the acuity level predictor <b>810</b>. Output may include an alert or a value. The output may be transmitted to a clinician device. In some embodiments, an alert is transmitted to a device of an emergency contact. In some embodiments, the output includes an indication that the patient is emergent. In some embodiments, the output includes an indication that there is availability for a resource for a patient who was determined to have an acuity level of 3-5. In some embodiments, the alert indicates that a resource is unavailable or close to being unavailable. For example, the indication and/or alert may include a notification that beds are almost unavailable.</p><p id="p-0075" num="0072">Turning to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart <b>900</b> for intelligently and accurately triaging a patient via an automated process. At <b>902</b>, a computing system extracts data from one or more electronic health records that correspond to one or more electronic health systems upon detection of an event (e.g., a triggering event, described above in <figref idref="DRAWINGS">FIG. <b>8</b></figref>). The electronic health record may comprise a demographic, past medical history information, active medications, previous emergency department visits, and imaging data. The electronic health record may comprise numerical values and free-text.</p><p id="p-0076" num="0073">At <b>904</b>, the computing system collects triage vitals upon detection of the event. The triage vitals may comprise a pain score, a temperature, a respiratory rate, an oxygen saturation level, a heart rate, and a blood pressure. The triage vitals may comprise numerical values and free-text. The triage vitals may be collected automatically or by receiving input of the triage vitals. In embodiments, collecting the triage vitals includes a combination of received and automatically collected (e.g., via a temperature sensor) triage vitals.</p><p id="p-0077" num="0074">At <b>906</b>, features from the triage vitals and the data from the electronic health record are input into an acuity level predictor. Prior to input, free-text from the data and the triage vitals are mapped and binned into categorical features using natural language processing. The categorical features may include a gender, a mode of arrival, a level of consciousness, and a reason for visit. In some embodiments, the acuity level predictor uses a decision tree and a Gini index. For example, a feature importance for one or more categories is determined at each level of the decision tree. Continuing the example, each feature importance is determined using the Gini index. In some embodiments, the acuity level predictor uses a machine learning algorithm for recalculating thresholds at each level of the decision tree, and each level corresponds to one of the categorical features.</p><p id="p-0078" num="0075">At <b>908</b>, an acuity level is output by the acuity level predictor based on the input. In some embodiments, a first availability level of radiology imaging and a second availability level of hospital beds is determined for input into the acuity level predictor. In some embodiments, a probability that the patient will need a radiology service, an intensive care unit admission, and an inpatient hospitalization is determined. In some embodiments, an accuracy of the acuity level of the patient is determined using a Confusion matrix. Continuing the example, an accuracy of the probability that the patient will need the radiology service, the intensive care unit admission, and the inpatient hospitalization is determined using the Confusion matrix. Further, in some embodiments, these accuracies are validated using a statistical area under the curve. In some embodiments, a selection accepting the determined acuity level is received.</p><p id="p-0079" num="0076">Turning now to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, example computing environment <b>1000</b> is suitable for use in implementing embodiments of the present invention. Example computing environment <b>1000</b> is merely an example of one suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing environment <b>1000</b> be interpreted as having any dependency or requirement relating to any single component or combination of components illustrated therein.</p><p id="p-0080" num="0077">The present invention may be operational with numerous other computing system environments or configurations. Examples of computing environments or configurations may include personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above-mentioned systems or devices, and the like.</p><p id="p-0081" num="0078">Embodiments of the present invention may be described in the general context of computer-executable instructions, such as program circuitry, being executed by a computer. Example circuitry (e.g., program circuitry or any other suitable circuitry) comprise circuits (e.g., circuits that include resistors, transistors, capacitors, inductors, diodes, and/or any suitable component whether hardware and/or programmatic code), routines, programs, objects, components, and/or data structures that perform particular tasks or implement particular abstract data types. The present invention may be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network <b>1006</b>. In a distributed computing environment, program circuitry might be located in association with local and/or remote computer storage media (e.g., memory storage devices).</p><p id="p-0082" num="0079">With continued reference to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the computing environment <b>1000</b> comprises a computing device in the form of a control server <b>1002</b>. Exemplary components of the control server <b>1002</b> comprise a processing unit, internal system memory, and a suitable system bus for coupling various system components, including data store <b>1004</b>, with the control server <b>1002</b>. The system bus might be any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, and a local bus, using any of a variety of bus architectures. Exemplary architectures comprise Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronic Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus, also known as Mezzanine bus.</p><p id="p-0083" num="0080">The control server <b>1002</b> typically includes therein, or has access to, a variety of computer-readable media. Computer-readable media can be any available media that may be accessed by control server <b>1002</b>, and includes volatile and nonvolatile media, as well as, removable and nonremovable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program circuitry or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by control server <b>1002</b>.</p><p id="p-0084" num="0081">Communication media typically embodies computer-readable instructions, data structures, program circuitry or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term &#x201c;modulated data signal&#x201d; means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer-readable media.</p><p id="p-0085" num="0082">The control server <b>1002</b> might operate in a computer network <b>1006</b> using logical connections to one or more remote computers <b>1008</b>. Remote computers <b>1008</b> might be located at a variety of locations in a medical or research environment, including clinical laboratories (e.g., molecular diagnostic laboratories), hospitals and other inpatient settings, ambulatory settings, medical billing and financial offices, hospital administration settings, home healthcare environments, clinicians' offices, Center for Disease Control, Centers for Medicare &#x26; Medicaid Services, World Health Organization, any governing body either foreign or domestic, Health Information Exchange, and any healthcare/government regulatory bodies not otherwise mentioned. Clinicians may comprise a treating physician or physicians, specialists such as intensivists, surgeons, radiologists, cardiologists, and oncologists, emergency medical technicians, physicians' assistants, nurse practitioners, nurses, nurses' aides, pharmacists, dieticians, microbiologists, laboratory experts, laboratory technologists, genetic counselors, researchers, students, and the like.</p><p id="p-0086" num="0083">The remote computers <b>1008</b> might also be physically located in nontraditional medical care environments so that the entire healthcare community might be capable of integration on the network. The remote computers <b>1008</b> might be personal computers, servers, routers, network PCs, peer devices, other common network nodes, or the like and might comprise some or all of the elements described above in relation to the control server <b>1002</b>. The devices can be personal digital assistants or other like devices.</p><p id="p-0087" num="0084">Computer networks <b>1006</b> comprise local area networks (LANs) and/or wide area networks (WANs). Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet. When utilized in a WAN networking environment, the control server <b>1002</b> might comprise a modem or other means for establishing communications over the WAN, such as the Internet. In a networking environment, program circuitry or portions thereof might be stored in association with the control server <b>1002</b>, the data store <b>1004</b>, or any of the remote computers <b>1008</b>. For example, various application programs may reside on the memory associated with any one or more of the remote computers <b>1008</b>. It will be appreciated by those of ordinary skill in the art that the network connections shown are exemplary and other means of establishing a communications link between the computers (e.g., control server <b>1002</b> and remote computers <b>1008</b>) might be utilized.</p><p id="p-0088" num="0085">In operation, an organization might enter commands and information into the control server <b>1002</b> or convey the commands and information to the control server <b>1002</b> via one or more of the remote computers <b>1008</b> through input devices, such as a keyboard, a pointing device (commonly referred to as a mouse), a trackball, a touch display, or a touch pad. Other input devices include microphones, satellite dishes, scanners, or the like. Commands and information might also be sent directly from a remote healthcare device to the control server <b>1002</b>. In addition to a monitor, the control server <b>1002</b> and/or remote computers <b>1008</b> might comprise other peripheral output devices, such as speakers and a printer.</p><p id="p-0089" num="0086">From the foregoing, it will be seen that this technology is one well adapted to attain all the ends and objects described above, including other advantages that are obvious or inherent to the structure. It will be understood that certain features and subcombinations are of utility and may be employed without reference to other features and subcombinations. This is contemplated by and is within the scope of the claims. Since many possible embodiments of the described technology may be made without departing from the scope, it is to be understood that all matter described herein or illustrated the accompanying drawings is to be interpreted as illustrative and not in a limiting sense.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computerized method for intelligently and accurately triaging a patient, the method comprising:<claim-text>accessing an electronic health record of the patient based on a detection of an event;</claim-text><claim-text>collecting triage vitals of the patient upon the detection of the event;</claim-text><claim-text>mapping and binning free-text from the electronic health record and the triage vitals into categorical features using natural language processing;</claim-text><claim-text>transforming numerical features from the electronic health record and the triage vitals using a statistical imputation;</claim-text><claim-text>in response to mapping, binning, and transforming, inputting the categorical features and the numerical features into an acuity level predictor; and</claim-text><claim-text>based on inputting the categorical features and the numerical features into the acuity level predictor, outputting an acuity level of the patient for triaging the patient.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the acuity level of the patient comprises one of the following: resuscitation, emergent, urgent, less urgent, and non-urgent.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the electronic health record comprises a demographic, past medical history information, active medications, previous emergency department visits, and imaging data, and wherein the electronic health record was previously stored in a database.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the event comprises the patient entering an emergency department and a facial recognition system associating the patient with the electronic health record of the patient using an image sensor and images stored in the database.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the triage vitals comprise a pain score, a temperature, a respiratory rate, an oxygen saturation level, a heart rate, and a blood pressure.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the categorical features include a gender, a mode of arrival, a level of consciousness, and a reason for a visit.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the numerical features include an age, a number of hospital visits during a period of time, and a blood pressure.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining a first availability level of radiology imaging;</claim-text><claim-text>determining a second availability level of hospital beds; and</claim-text><claim-text>outputting the acuity level of the patient upon inputting the first availability level and the second availability level into the acuity level predictor.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising:<claim-text>determining, using the acuity level, a probability that the patient will need a radiology service, an intensive care unit admission, and an inpatient hospitalization.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the acuity level predictor uses a decision tree and Gini index for outputting the acuity level based on inputting the categorical features and the numerical features.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining an accuracy of the acuity level of the patient using a Confusion matrix.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising validating the accuracy of the acuity level using a statistical area under the curve.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. One or more non-transitory computer storage media storing computer-readable instructions that, when executed by a processor, cause the processor to perform operations for intelligently and accurately triaging a patient, the operations comprising:<claim-text>accessing an electronic health record of the patient based on a detection of an event;</claim-text><claim-text>collecting triage vitals of the patient upon the detection of the event;</claim-text><claim-text>mapping and binning free-text from the electronic health record and the triage vitals into categorical features using natural language processing for input into an acuity level predictor;</claim-text><claim-text>inputting the categorical features into the acuity level predictor that uses a machine learning algorithm for recalculating thresholds at each level of a decision tree, each level corresponding to one of the categorical features; and</claim-text><claim-text>based on inputting the categorical features into the acuity level predictor, outputting an acuity level of the patient for triaging the patient.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The media of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising inputting numerical features from the electronic health record and the triage vitals, the numerical features comprising a blood pressure, a pain score, a heart rate, a temperature, a number of procedures performed by a clinician during a time range, and an age.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The media of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the acuity level of the patient comprises one of the following: resuscitation, emergent, urgent, less urgent, and non-urgent.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising determining a probability that the patient will need a radiology service, an intensive care unit admission, and an inpatient hospitalization based on the acuity level.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The media of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising determining an accuracy of the acuity level, the probability that the patient will need the radiology service, the probability that the patient will need the intensive care unit admission, and the probability that the patient will need the inpatient hospitalization using a Confusion matrix.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising validating the accuracy of the acuity level, the probability that the patient will need the radiology service, the probability that the patient will need the intensive care unit admission, and the probability that the patient will need the inpatient hospitalization using a statistical area under the curve.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. An intelligent triage system for triaging a patient, the system comprising:<claim-text>at least one processor; and</claim-text><claim-text>one or more computer storage media storing computer-executable instructions embodied thereon that when executed by the at least on processor, cause the at least one processor to perform operations comprising:<claim-text>retrieve an electronic health record of the patient based on a detection of an event;</claim-text><claim-text>collect triage vitals of the patient upon the detection of the event;</claim-text><claim-text>map and bin free-text from the electronic health record and the triage vitals into categorical features using natural language processing for input into an acuity level predictor;</claim-text><claim-text>input the categorical features into the acuity level predictor that recalculates a threshold at each level of a decision tree, each level corresponding to one of the categorical features; and</claim-text><claim-text>based on inputting the categorical features into the acuity level predictor, output an acuity level of the patient for triaging the patient.</claim-text></claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising receiving a selection accepting the acuity level.</claim-text></claim></claims></us-patent-application>
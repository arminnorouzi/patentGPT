<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007021A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007021</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17901162</doc-number><date>20220901</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>63</main-group><subgroup>1416</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20180101</date></cpc-version-indicator><section>G</section><class>16</class><subclass>H</subclass><main-group>40</main-group><subgroup>67</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">Indicators Of Compromise In Healthcare/Medical Products/Objects By Analyzing Data Based On Rolling Baseline</invention-title><us-related-documents><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>17880898</doc-number><date>20220804</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17901162</doc-number></document-id></child-doc></relation></continuation-in-part><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>17154915</doc-number><date>20210121</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11445340</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17880898</doc-number></document-id></child-doc></relation></continuation-in-part></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Flying Cloud Technologies, Inc.</orgname><address><city>Polson</city><state>MT</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Christian</last-name><first-name>Brian P.</first-name><address><city>Sioux Falls</city><state>SD</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Techniques are disclosed for identifying indicators of compromise in a variety of medical/healthcare objects. The objects may be finished products or components of medical/healthcare objects/devices. The indicators of compromise in the objects are determined/detected by analyzing their data residing in a cloud. The analysis is performed by an instant baseline engine that first establishes a rolling baseline with a centroid of a conceptual hypercube. The centroid represents the normal population of data packets. Data packets far enough away from the centroid indicate an anomaly that may be an indicator of a compromise of/in the respective object. An early detection of such indicators of compromise in the objects can prevent catastrophic downstream consequences with the potential of saving lives and/or protecting them from harm.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="167.47mm" wi="156.89mm" file="US20230007021A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="172.55mm" wi="158.75mm" file="US20230007021A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="212.68mm" wi="163.58mm" file="US20230007021A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="212.68mm" wi="163.58mm" file="US20230007021A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="212.68mm" wi="163.58mm" file="US20230007021A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="212.68mm" wi="163.58mm" file="US20230007021A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="212.68mm" wi="163.58mm" file="US20230007021A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="212.68mm" wi="163.58mm" file="US20230007021A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="212.68mm" wi="163.58mm" file="US20230007021A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="212.68mm" wi="163.58mm" file="US20230007021A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="198.12mm" wi="158.92mm" file="US20230007021A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="166.79mm" wi="149.27mm" file="US20230007021A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="166.79mm" wi="149.27mm" file="US20230007021A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="166.79mm" wi="149.27mm" file="US20230007021A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="166.79mm" wi="149.27mm" file="US20230007021A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation-in-part (CIP) of U.S. patent application Ser. No. 17/880,898 filed on Aug. 4, 2022, which is a continuation-in-part (CIP) of U.S. patent application Ser. No. 17/154,915 filed on Jan. 21, 2021 to be issued as U.S. Pat. No. 11,445,340 on Sep. 13, 2022. This application is also related to U.S. patent application Ser. No. 16/219,931, now U.S. Pat. No. 10,516,689 B2 issued on Dec. 24, 2019. This application is also related to U.S. patent application Ser. No. 16/058,145, issued on Dec. 31, 2019. This application is further related to U.S. patent application Ser. No. 16/120,704, now U.S. Pat. No. 10,542,026 B2 issued on Jan. 21, 2020. This application is also related to U.S. patent application Ser. No. 16/700,554, now U.S. Pat. No. 10,848,514 B2 issued on Nov. 24, 2020. This application is also related to U.S. patent application Ser. No. 16/804,351, now U.S. Pat. No. 10,887,330 B2 issued on Jan. 5, 2021. All the above numbered U.S. patent applications and U.S. patents are incorporated by reference herein for all purposes in their entireties.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE INVENTION</heading><p id="p-0003" num="0002">This invention relates to the field of data analyses for the purposes of identifying indicators of compromise in various healthcare/medical objects/devices.</p><heading id="h-0003" level="1">BACKGROUND ART</heading><p id="p-0004" num="0003">Surveillance of sites and properties for the purposes of proactively identifying threats and malicious actors is an active area of pursuit. The importance of early detection of health scares and other security threats in the age of global pandemics cannot be overstated. As a result, there is lot of active research on trying to identify health, security and other threats in crowded spaces, sites and various facilities.</p><p id="p-0005" num="0004">Much of the focus has unsurprisingly been on information or information security thus far. U.S. Pat. No. 10,594,714 B2 to Crabtree describes a cybersecurity system that protects against cyberattacks by performing user and device behavioral analysis using an advanced cyber decision platform which creates a map of users and devices attached to a network. It then develops a baseline of expected interactions and behaviors for each user and device in the map, and monitors deviations from the expected interactions and behaviors.</p><p id="p-0006" num="0005">U.S. Pat. No. 10,542,027 B2 to Wittenschlaeger discloses a hybrid-fabric apparatus that comprises a black box memory configured to store a plurality of behavior metrics and an anomaly agent coupled to the black box. The anomaly agent determines a baseline vector corresponding to nominal behavior of the fabric, wherein the baseline vector comprises at least two different behavior metrics that are correlated with each other. The anomaly agent disaggregates anomaly detection criteria into a plurality of anomaly criterion to be distributed among network nodes in the fabric.</p><p id="p-0007" num="0006">U.S. Pat. No. 10,542,026 B2 to Christian teaches a data surveillance system for the detection of security issues, especially of the kind where privileged data may be stolen by steganographic, data manipulation or any form of exfiltration attempts. Such attempts may be made by rogue users or admins from the inside of a network, or from outside hackers who are able to intrude into the network and impersonate themselves as legitimate users. The system and methods use a triangulation process whereby analytical results pertaining to data protocol, user-behavior and packet content are combined to establish a baseline for the data. Subsequent incoming data is then scored and compared against the baseline to detect any security anomalies. A centroid representing the normal population of the data packets is identified. The design allows establishing the context of various events of interest in the organization, thus enabling dynamic management of security policies.</p><p id="p-0008" num="0007">In the area of detecting the presence of humans or bodies in a network, U.S. Pat. No. 10,142,785 B2 to Wootton teaches systems and methods for detecting the presence of a body in a network without fiducial elements. It does so using signal absorption, and signal forward and reflected backscatter of radio frequency (RF) waves caused by the presence of a biological mass in a communications network.</p><p id="p-0009" num="0008">In the area of surveillance monitoring, the product of iCetana&#x2122; proclaims a set of advanced, automated, video analysis tools that provide for the immediate detection and extraction of events and valuable data from surveillance footage. It is purported to increase the return on investment (ROI) of a surveillance system, and overall security, safety and business operations. The integration capabilities allow it operate on every camera connected to the surveillance system. The product claims to detect anomalies, enabling full event management through the client. This includes event notification with graphic overlay for both live and recorded (playback) video, simplified configuration, triggered recording, activation of outputs and more. Video search and business intelligence capabilities are embedded in the client, enabling retrieval of stored video and display of analytics results.</p><p id="p-0010" num="0009">The product of FLIR&#x2122; proclaims a desktop software offering an efficient, accurate way to perform elevated skin temperature screenings at ports of entry, checkpoints, building entrances, and other high-traffic areas. When connected to a thermal camera, the software activates as an individual enters the camera's field of view and provides guidance to correctly position them. The software places a hot spot on the individual's face and takes a skin temperature measurement within seconds. If the measured temperature exceeds a threshold set above the rolling baseline average, the system will notify the operator and present an alarm on the subject's viewing monitor. The individual can then be directed to a secondary screening with a medical device. This rapid, non-contact measurement system sets up in minutes, and helps organizations reduce the risk of work and production interruptions due to illness.</p><p id="p-0011" num="0010">One of the shortcomings of the prior art is that it fails to teach techniques that allow identifying of anomalous subjects and devices based on a rolling baseline in a crowded site containing a variety of sensors. Such a design absent from the art would gather data from all the sensors and analyze them by first establishing a rolling baseline by clustering of data packets and then scoring each incoming packet against a centroid of the baseline. As a result, the system absent from the art would allow the identification of anomalous subjects and devices at a site/environment such as health and security threats, training issues, espionage, etc.</p><p id="p-0012" num="0011">The prior art is also silent about teaching the above techniques where the sensors would be installed on computing devices. The prevailing art is also silent about detecting various health, security or other scenarios when there are personal-devices carried by the subjects at a given site. The art is also silent about applying these techniques to monitoring valuable assets at a manufacturing site or facility.</p><p id="p-0013" num="0012">The prior art is further silent about detecting indicators of compromise by analyzing data from various types of objects. Such objects may be healthcare or medical objects. An early detection of such indicators of compromise could save serious downstream consequences including harm to or loss of lives. However, no techniques in the prior art allow one to achieve the above objectives.</p><heading id="h-0004" level="1">OBJECTS OF THE INVENTION</heading><p id="p-0014" num="0013">In view of the shortcomings and unfulfilled needs of the prior art, it is an object of the present invention to provide a set of techniques for identifying anomalous subjects and devices at a site of interest.</p><p id="p-0015" num="0014">It is also an object of the invention to achieve the above objectives by establishing a rolling baseline for data streams based on clustering of data packets and then scoring each incoming packet against a centroid of the rolling baseline.</p><p id="p-0016" num="0015">It is also an object of the invention to gather data from a variety of sensors present at the site in order to achieve its objectives of anomalous subject and device identification.</p><p id="p-0017" num="0016">It is also an object of the invention to allow the above sensors to be embodied in various types of computing devices so ubiquitously present in today's environments.</p><p id="p-0018" num="0017">It is also an object of the invention to apply the above techniques for monitoring valuable assets at a site such as a manufacturing or fabrication facility.</p><p id="p-0019" num="0018">It is also an object of the invention to attain greater fidelity in achieving its objectives by deploying antennas installed at the facility.</p><p id="p-0020" num="0019">It is also an object of the invention to detect indicators of compromise by analyzing data from various types of objects, including medical and healthcare objects.</p><p id="p-0021" num="0020">It is also an object of the invention to detect such indicators of compromise by analyzing object data residing in the cloud.</p><p id="p-0022" num="0021">It is further an object of the invention to detect such indicators of compromise where they may signify a pattern failure of semiconductor components.</p><p id="p-0023" num="0022">These as well as other objects of the invention will be evident in the forthcoming summary and detailed description sections of this disclosure.</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0024" num="0023">The objects and advantages of the invention are secured by systems and methods for anomalous subject and device identification based on a rolling baseline. This is accomplished by deploying one or more sensors at a site at which anomalous subject and device identification is required. The sensors may be based on any suitable wired or wireless technology including video, audio, cellular, blue-tooth, radio frequency identification (RFID), Zigbee and thermal sensor technologies. Subjects or targets at the site may also be carrying communication devices of their own or personal-devices.</p><p id="p-0025" num="0024">Data streams originating from the above subjects and personal-devices is gathered by the above sensors and analyzed by a rolling baseline engine taught in herein incorporated references cited above in the Related applications section, including U.S. Pat. No. 10,542,026 issued on 21 Jan. 2020 to Christian. The baseline engine establishes a rolling baseline of data received from the sensors, preferably after processing by a data processing module. The rolling baseline is established by assignment of each incoming packet to a cluster of packets amongst clusters of packets of data. Preferably, the clustering is performed using k-means clustering.</p><p id="p-0026" num="0025">The baseline thus established is characterized by a conceptual hypercube with any number and types of dimensions on which the data is desired to be analyzed. The hypercube has a centroid that represents the &#x201c;normal&#x201d; population of packets. Then, as subsequent packets arrive, they are scored against the baseline by computing their distance from the centroid of the hypercube. Any packets that are far away enough from the centroid on a dimension of interest to be not normal are then identified as anomalous along with the subject and/or device associated with that data packet. In this manner, the anomalous subject and device identification system of the present design is able to analyze data from a variety of different sensors deployed at a given on a variety of dimensions of interest and identify anomalous subjects and devices at the site.</p><p id="p-0027" num="0026">In various preferred embodiments, the sensors are located on various computing devices including personal computing devices such as cellular phones such as smartphones, tablets, wearable devices such as smartwatches, laptops, even desktops, etc. The data analyzed by the baseline engine may be related to the subjects and/or devices carried by the subjects termed as personal-devices. The devices carried by the subjects may be cellular phones such as smartphones, tablets, wearable devices such as smartwatches, laptops, even desktops, etc.</p><p id="p-0028" num="0027">In another set of embodiments, there are wireless antennas installed at the site. The antennas may act as personal-device sensors or they may boost the signal for other personal-device sensors present at the site. The antennas add fidelity to the system by allowing better location determination of devices at the site. For location determination, any network algorithm techniques such as triangulation, trilateration, etc. may be utilized by the data processing module, which then furnishes its output with subject, device and location data to the rolling baseline engine.</p><p id="p-0029" num="0028">In various embodiments the baseline engine is used to perform analysis for a variety of aspects about the subjects/devices. Consequently, the distance of data packets associated with the subjects/devices at the site is determinative of a number of useful situations about anomalous subjects and devices at the site. These include knowing that the device has been beaconing in the unused media access control (MAC) address space for too long.</p><p id="p-0030" num="0029">These situations/scenarios further include knowing movement patterns of the subject, temperature reading of the subject, police record of the subject, the lack of a personal-device carried by the subject, the transfer of a personal-device from one subject to another, a weapon carried by the subject, among others. The system is also able to identify scenarios with an anomalous device alone, such as an unattended device at the site that may or may not have been previously associated with a subject.</p><p id="p-0031" num="0030">Preferably the data streams from the sensors are stored in a data file as separate data-tracks. For this purpose, data streams from multiple sensors of the same type may first be combined by the data processing module before storing them in the data file as data stream of a given type. Exemplary data-tracks include video data, audio data, radio frequency (RF) data, blue-tooth data, etc. Preferably, there is also an underlying data track containing information about the subjects associated with the data-tracks.</p><p id="p-0032" num="0031">In another set of embodiments, the sensors are embodied in a computing device at a kiosk present at the site. Such embodiments are useful in presenting the capabilities of the system to the subjects and/or getting them familiarized with it. In other embodiments, the subjects are items or apparatus of value whose monitoring is required. For this purpose, asset sensors are utilized, which are typically wireless sensors that communicate with xmitters installed in or around the valuable assets. Exemplary implementations of such embodiments may be found at manufacturing/fabrication facilities where monitoring of expensive or sensitive manufacturing/fabrication equipment is required.</p><p id="p-0033" num="0032">The present technology may be deployed at sites/locations including airports, train stations, subways, central bus stations, embassies and consulates, government buildings, stadiums, arenas, venues, convention centers, Fortune 500 companies' headquarters or key offices, hospitals, universities/colleges, schools, restaurants and hospitality centers, office buildings, etc. The scenarios including the involved subjects and devices proactively identified by the present anomalous subject and device identification technology include health threats, security threats, espionage, training issues, distressed individuals, etc. The findings of the baseline engine are archived in an on-premise database or in the cloud for performing downstream forensic or other analytics as needed.</p><p id="p-0034" num="0033">In a highly preferred set of embodiments, the present technology analyzes data from a variety of medical or healthcare objects in order to determine indicators of compromise in these medical/healthcare objects using rolling baseline. The objects in the present embodiments may be finished medical/healthcare products, including consumer or industrial products or components that may be used in medical/healthcare objects or devices. The data analyzed by the present embodiments may be pre-production design/manufacturing data or post-production operational data, or any conceivable type of data produced by the objects.</p><p id="p-0035" num="0034">These medical/healthcare embodiments of the present technology apply to any medical/healthcare objects or devices including wearable or implantable or industrial objects/devices. Exemplary objects that benefit from the present technology include but are not limited to pacemakers, insulin pumps, electrocardiogram (ECG/EKG) monitors, health alert bracelets, fitness trackers, smart health watches, blood pressure monitors, any type of biosensors, body temperature sensors, heartbeat monitors, kidney and/or dialysis monitors and sleep monitors.</p><p id="p-0036" num="0035">The systems and methods of the present technology are performed by one or more microprocessors or processors that are operably coupled or simply coupled to one or more memory storage media or simply storage media. The storage media stores computer-readable instructions that are then executed by the one or more processors for performing the various functions of the instant rolling baseline engine.</p><p id="p-0037" num="0036">In the present embodiments, the rolling baseline engine analyzes data packets generated by the one or more medical/healthcare objects mentioned above. Per prior teachings, the rolling baseline engine establishes a rolling baseline by assigning each packet of data to a cluster of packets of data. There are a plurality of clusters of packets of data from the objects. Preferably, the clustering is performed using k-means clustering.</p><p id="p-0038" num="0037">The rolling baseline engine then scores each packet of data based on its distance from the centroid of the rolling baseline. The distance may be along one or more dimensions of a conceptual hypercube. Then based on this distance, the rolling baseline line engine detects anomalous data packets. Such anomalies or anomalous data packets are then used to signify indicator(s) of compromise of/in respective objects.</p><p id="p-0039" num="0038">The indicators of compromise thus detected may manifest themselves in a variety of manners. In various embodiments, such manifestation may occur as unintelligible or obfuscated data, unintentionally encrypted data, misreported data. The data thus misreported may be underreported or overreported depending on the variation. Exemplarily, the underreporting may occur if the object(s) have been intruded by a malware or a hacker who is now executing unauthorized remote commands on the object(s) and/or is sending/receiving unauthorized messages to/from them on the network. This overuse of resources may cause the medical/healthcare object(s)/device(s) to underreport their data. The manifestation may also occur as overuse/overage or underuse/underage of a variety of metrics and resources of the objects. These include CPU usage, memory usage, disk storage usage, network usage, thermal output, etc.</p><p id="p-0040" num="0039">The data from these medical/healthcare objects is preferably sent to a cloud where it is analyzed by the instant baseline engine resides. Depending on the variations, there are many different types of such clouds possible. These include generic automation testing clouds, device specific clouds, vendor specific clouds, component clouds, etc. A single cloud may encompass more than one type of above clouds and the clouds may be tiered.</p><p id="p-0041" num="0040">In one variation, the object data in the cloud is used as a training dataset for modeling the optimal behavior of respective objects using artificial intelligence (AI) techniques. This model of optimal behavior then helps/facilitates establishing the rolling baseline with its centroid of normal population of data packets that are now correlated to the above optimal model.</p><p id="p-0042" num="0041">In another advantageous variation, the cloud is a component cloud used for electronic design automation (EDA), also sometimes referred to as electronic computer-aided design (ECAD), of one or more components. The instant baseline engine analyzes data in such a component cloud and detects indicators of compromise that may signify a pattern of failure of the components.</p><p id="p-0043" num="0042">An early knowledge of the indicators of compromise in the present embodiments allows a concerned party to take immediate remedial actions, so that much more devastating downstream consequences can be effectively avoided. Such remedial actions have the potential of saving human lives from harm or loss.</p><p id="p-0044" num="0043">In a useful variation of the present embodiments, a correlation logic or module in or operably connected with the baseline engine is also employed. This correlation logic/module produces correlation data showing any correlations between or more medical records of the users/patients of the medical/healthcare objects/devices with the version of software/hardware operating in/on the objects.</p><p id="p-0045" num="0044">Instead of or in addition, the correlation logic further correlates the medical record data or the correlation data obtained above with the type of compromise affecting the objects/devices. The resultant correlation data is employed by concerned party/parties in protecting these objects/devices from future compromises/vulnerabilities and exploits.</p><p id="p-0046" num="0045">Clearly, the system and methods of the invention find many advantageous embodiments. The details of the invention, including its preferred embodiments, are presented in the below detailed description with reference to the appended drawing figures.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWING FIGURES</heading><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a conceptual diagram illustrating the anomalous subject and device identification system of the present design.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a detailed diagram illustrating various embodiments with various types of sensors used in the anomalous subject and device identification system of the present technology.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram emphasizing the embodiments utilizing one or more cameras according to the instant principles.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram emphasizing the embodiments utilizing one or more assets sensors and xmitters at a manufacturing or fabrication site according to the instant principles.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>4</b></figref> also incorporating cameras and other subjects.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram emphasizing the embodiments utilizing personal-device sensors at a site.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>6</b></figref> also incorporating cameras and unattended devices at the site.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>7</b></figref> also incorporating wireless antennas installed at the site.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram emphasizing embodiments where sensors of the present design are embodied in various computing devices.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates some of the many types of objects by analyzing whose data the instant baseline engine detects indicators of compromise in them in a highly preferred set of embodiments.</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows a preferred variation of the embodiments of <figref idref="DRAWINGS">FIG. <b>10</b></figref> where the instant baseline engine analyzes smart TV data residing in a cloud in order to detect indicators of compromise in the TVs.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows a preferred variation of the embodiments of <figref idref="DRAWINGS">FIG. <b>10</b></figref> where the instant baseline engine analyzes component data residing in a component cloud in order to detect indicators of compromise in the components.</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows a variation of the embodiments of <figref idref="DRAWINGS">FIG. <b>11</b></figref> applied to the healthcare/medical vertical. Specifically, <figref idref="DRAWINGS">FIG. <b>13</b></figref> shows the instant baseline engine analyzing data residing in a cloud containing data from pacemakers in order to detect indicators of compromise in the pacemakers.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>13</b></figref> showing the instant baseline engine analyzing data in cloud for detecting indicators of compromise in health monitoring or health alert bracelets. Also shown explicitly is a correlation logic/module for identifying correlations between medical records and other relevant data related to the healthcare/medical products and their indicators of compromise.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0061" num="0060">The figures and the following description relate to preferred embodiments of the present invention by way of illustration only. It should be noted that from the following discussion, alternative embodiments of the structures and methods disclosed herein will be readily recognized as viable alternatives that may be employed without departing from the principles of the claimed invention.</p><p id="p-0062" num="0061">Reference will now be made in detail to several embodiments of the present invention(s), examples of which are illustrated in the accompanying figures. It is noted that wherever practicable, similar or like reference numbers may be used in the figures and may indicate similar or like functionality. The figures depict embodiments of the present invention for purposes of illustration only. One skilled in the art will readily recognize from the following description that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles of the invention described herein.</p><p id="p-0063" num="0062">The techniques described herein may employ computer code that may be implemented purely in software, hardware, firmware or a combination thereof as required for a given implementation. The system and methods of the present technology will be best understood by first reviewing an anomalous subject and device identification system <b>100</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. System <b>100</b> is a surveillance system comprising any number of sensors <b>104</b>A, <b>104</b>B, . . . <b>104</b>N connected via a communication network (not shown) to a rolling baseline computation engine <b>110</b> at a site or an organization or an establishment or facility or property or environment <b>102</b>.</p><p id="p-0064" num="0063">Reference numerals <b>104</b>A . . . <b>104</b>N may represent anywhere from a single sensor up to hundreds or thousands or even more sensors as depicted by the dotted line, that may generate data for rolling baseline engine or for short baseline engine <b>110</b>. Furthermore, non-limiting examples of these sensors are shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. These include as one or more sensors <b>104</b>A termed as asset sensors installed on or near or in vicinity or in proximity of valuable or sensitive assets, such as a manufacturing equipment or tools at a manufacturing or chip fabrication facility.</p><p id="p-0065" num="0064">The sensors in <figref idref="DRAWINGS">FIG. <b>1</b></figref> also include one or more sensors <b>104</b>B that are picture or video cameras and one or more sensors <b>104</b>C that are audio sensors such as microphones. These further include one or more sensors <b>104</b>D that are wireless sensors such as wifi or bluetooth or Zigbee sensors and the like&#x2014;these are termed as personal-device sensors because they are responsible for sensing/communicating with devices carried by subjects <b>206</b>. <figref idref="DRAWINGS">FIG. <b>1</b></figref> also shows one or more such sensors operating at a kiosk <b>105</b>.</p><p id="p-0066" num="0065">Any number and type of sensors <b>104</b>A-N may be installed on one or more computing devices, such as mobile devices including cellular phones including smartphones. Sensors <b>104</b>A-N may also be on tablets, and wearable devices such as smartwatches, even desktops, etc. It should further be noted that sensor(s) <b>104</b>A may be one or more asset sensors, sensor(s) <b>104</b>B may be one or more cameras, sensor(s) <b>104</b>C may be one or more microphones that may or may not be integrated with camera(s) <b>104</b>B, sensor(s) <b>104</b>D may be one or more wireless personal-device sensors, examples of which were noted above, etc.</p><p id="p-0067" num="0066">In this disclosure, unless otherwise explicitly noted, we may use reference numerals, for example reference numeral <b>104</b>B to refer to a single sensor or multiple sensors of a given type, in this case camera or cameras. Any of sensors <b>104</b> may be operating in one or more kiosks, such as kiosk <b>105</b> at site <b>102</b>. These sensors may be installed on one or more computing devices, fixed or mobile, enterprise or personal.</p><p id="p-0068" num="0067">According to the present technology, sensors <b>104</b>A . . . <b>104</b>N gather data that is related to various subjects or targets <b>106</b>. Subjects may be sentient beings, such as any sentient life forms or beings including animals or human beings shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Subjects also include non-living or non-sentient beings such as robots, automatons, cyborgs, as well as objects or assets of interest or value at site <b>101</b>. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, sensors <b>104</b> are monitoring/surveilling human subjects <b>106</b> at site <b>102</b> and providing that data to baseline engine <b>110</b> for analysis, in order to accrue the benefits of the instant anomalous subject and device identification system <b>100</b> of the present design. Baseline engine <b>110</b> used by the present technology is the rolling baseline data surveillance system taught in detail in above-incorporated references including U.S. Pat. No. 10,542,026 issued on 21 Jan. 2020 to Christian.</p><p id="p-0069" num="0068">Explained further, baseline engine <b>110</b> analyzes each packet of data gathered by sensors <b>104</b>. As a part of this analysis, it assigns each packet of data to a cluster of packets amongst clusters of packets of data. The clustering is done preferably by utilizing k-means clustering, specifically by utilizing Eq. (1) of the above-incorporated references and teachings. As a result, baseline engine <b>110</b> establishes a rolling or evolving baseline <b>120</b> for the data that signifies the mean or normal behavior of the packets.</p><p id="p-0070" num="0069">Baseline <b>120</b> is based on a conceptual hypercube <b>180</b> with a centroid <b>182</b> as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> representing the normal population of packets. For brevity, we may just refer to centroid <b>182</b> to be the centroid of baseline <b>120</b>, rather than spelling out fully that centroid <b>182</b> is the centroid of hypercube <b>180</b> of baseline <b>120</b>. Thus, as data packets from sensors <b>104</b>A-N arrive via a communication network (not shown) at baseline engine <b>110</b>, it scores these brackets based on their distance from centroid <b>182</b> of baseline <b>120</b>.</p><p id="p-0071" num="0070">Since baseline <b>120</b> with centroid <b>182</b> signifies the &#x201c;normal&#x201d; behavior of packets, packets that are very far away from centroid <b>182</b> represent an anomaly. In this way, anomalous subject and device identification system <b>100</b> identifies anomalous subjects among subjects <b>106</b> that are associated with anomalous packets of data. Once again, for even a more detailed explanation of the workings of baseline engine <b>110</b> of anomalous subject and device identification system <b>100</b>, that is responsible for establishing a rolling baseline <b>120</b> and then identifying anomalous data packets, the reader is referred to the above-incorporated references including U.S. Pat. No. 10,542,026 issued on 21 Jan. 2020 to Christian.</p><p id="p-0072" num="0071">Now let us take a more detailed look at the present technology by reviewing its various embodiments and by taking advantage of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. <figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an anomalous subject and device identification system <b>200</b> of the present design operating at a site <b>202</b>. Site <b>202</b> has a number of subjects <b>206</b> per above explanation. In the example shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, these subjects or targets are humans or people marked by reference numerals <b>206</b>A, <b>206</b>B, . . . . Also shown are a number of sensors of various types <b>204</b>A, <b>204</b>B, <b>204</b>C, <b>204</b>D, . . . per above discussion. Any number and types of such sensors <b>204</b>A-N or simply sensors <b>204</b> may be present at site <b>202</b>. All these sensors are connected to a network backbone <b>208</b> that is in turn connected to baseline engine <b>110</b> of the above teachings. Network backbone <b>208</b> is an electronic communications network based on techniques known in the art.</p><p id="p-0073" num="0072">Furthermore, sensors <b>204</b> are collecting data about people <b>206</b>A, <b>206</b>B, . . . or simply people <b>206</b> at site <b>202</b> and supplying it to baseline engine <b>110</b> for analysis such that any malicious or anomalous subjects/actors/people/beings amongst people/beings <b>206</b> or any anomalous devices at site <b>202</b> can be identified. This process depends upon the type of sensor(s) involved. The results of analysis performed by baseline engine <b>110</b> and any other related data is stored in an appropriate data storage mechanism for archival and analytics. Such a storage mechanism may be a database on premises at site <b>202</b> or in cloud <b>230</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> or a combination thereof.</p><p id="p-0074" num="0073">Let us now study the various embodiments utilizing the different types of sensors at a given site based on the present principles while referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0075" num="0074">Camera(s): Camera(s) or simply camera <b>204</b>A visually monitors people <b>206</b>. In various embodiments, camera <b>204</b>A may be a standard video camera such as a closed-circuit television (CCTV) camera, or a more specialized camera such as a stereoscopic video camera or a thermal camera. Regardless, camera <b>204</b>A supplies its data as video packets via network backbone <b>208</b> to baseline engine <b>110</b> of the above discussion.</p><p id="p-0076" num="0075">Baseline engine <b>110</b> then establishes a rolling baseline <b>120</b>A with conceptual hypercube <b>180</b>A and centroid <b>182</b>A for these video packets. It then identifies anomalous video packets as compared to baseline <b>120</b>A per above-incorporated references and teachings. Anomalous video packets are associated with a specific subject/person, exemplarily person <b>206</b>C amongst subjects/person <b>206</b> at site <b>202</b>. Based on the analysis performed by baseline engine <b>110</b> and identification of anomalous video packet(s) by engine <b>110</b>, anomalous subject and device identification system <b>200</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> identifies person <b>206</b>C as an anomalous subject or a malicious actor. Its findings can then be accessed directly via an appropriate user interface (not shown) and/or stored in cloud <b>230</b> for archival and analytics.</p><p id="p-0077" num="0076">Note that in the present and other embodiments discussed in this disclosure, the correspondence of the reference numeral of the baseline to the type of sensor <b>204</b> must not be taken too strictly. For example, any number of baselines may be established by baseline engine <b>110</b> based on the video stream from a single camera depending on the analysis performed by the baseline engine for a given implementation. There may be one baseline geared towards security aspects, another baseline geared towards training aspects, another towards behavioral aspects, etc. Conversely, data streams from multiple sensors may be combined into a single baseline also, as per the requirements of a given implementation.</p><p id="p-0078" num="0077">As already mentioned, camera <b>204</b>A may be a standard video camera such as the one typically integrated with today's cellular phones or smartphones or a more specialized camera or a CCTV camera. The analysis performed by baseline engine <b>110</b> for its rolling baseline <b>120</b>A calculation may then be based on facial recognition and motion tracking of subjects/people/beings <b>206</b>. Facial recognition and object tracking or simply tracking of people <b>206</b> in the video data from camera <b>204</b>A are performed based on techniques known in the art by data processing module <b>220</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Preferably, for this purpose data processing module <b>220</b> performs form or skeletal motion analysis on the video stream(s).</p><p id="p-0079" num="0078">Data processing module <b>220</b> is also responsible for performing any other data preprocessing tasks before supplying its output as data packets to baseline engine <b>110</b> for analysis. In various embodiments, data processing module <b>220</b> may be implemented as a single module or it may be comprised of various submodules per the needs of an implementation and based on techniques known in the art. In a preferred embodiment, it is implemented as a shim compatibility layer to baseline engine <b>110</b>.</p><p id="p-0080" num="0079">Each subject or person <b>206</b>A, <b>206</b>B, . . . at site <b>202</b> is identified by a hash signature or an alternate identifying signature/marker/information or simply an identifier for object tracking performed by data processing module <b>220</b>. The movement data of each signature is then fed to baseline engine <b>110</b>. Preferably, the movement data comprises (x, y, z) coordinates or other equivalent location information of the respective individual/subject/being at site <b>202</b> at various points in time. Alternately or in addition, the movement data comprises his/her speed and direction of movement at the given location and the given point in time.</p><p id="p-0081" num="0080">As that person moves in a building or site, object tracking function of module <b>220</b> tracks the movements of the person in the building having the assigned identifier. If there are more than one cameras <b>204</b>A, object/facial recognition and tracking is performed on video data streams of all such cameras by module <b>220</b>. The movement data of tracked people <b>206</b> with their respective identifiers is then fed to baseline engine <b>110</b> for analysis per above. There are a number of useful scenarios or situations that can be captured by the embodiments. A non-exhaustive list of these includes:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0081">1. Erratic/distressed movement pattern: In one embodiment, rolling baseline <b>120</b>A signifies the average or mean behavior of crowd <b>206</b> by a given set of movements or movement pattern/patterns of people <b>206</b> that is considered &#x201c;normal&#x201d;. An individual or person, such as person <b>206</b>C with an exemplary hash signature or simply hash or identifier C1369F4789DA, exhibiting an erratic or stressful or distressed movement pattern or patterns may signify an anomaly. In this case, baseline engine <b>110</b> will determine the distance of video packets associated with person <b>206</b>C to be far enough away from centroid <b>182</b>A of baseline <b>120</b>A to signal an anomaly. This anomaly is then reported by engine <b>110</b> per prior teachings. Anomalous subject and device identification system <b>200</b> can then take appropriate actions based on the anomalies reported by baseline engine <b>110</b>.</li>        <li id="ul0002-0002" num="0082">2. Audio signatures: In a related variation, camera <b>204</b>A may be integrated with microphone <b>204</b>B in a single product/device. In such a variation, audio packets of data or audio data stream from microphone <b>204</b>B are combined with video packets or video data stream from camera <b>204</b>A to advantageously enhance facial recognition and object tracking of people <b>206</b> at site <b>202</b>. For example, if site <b>202</b> is a theatre or studio or the like where the audio signature of each tracked individual may be distinguishable enough, such an audio signature may further help data processing module <b>220</b> to recognize and locate each individual with his/her identifier at site <b>202</b>. Additional embodiments benefiting from audio or microphone sensors <b>204</b>B are discussed further below.</li>    </ul>    </li></ul></p><p id="p-0082" num="0083">As already mentioned, camera <b>204</b>A may be a stereoscopic camera. Such a stereo camera has the advantage of providing depth information or size information of the object, thus better aiding facial recognition and object tracking of subjects <b>206</b> discussed above. In still other variations, camera <b>204</b>A may be a thermal-video camera, that may or may not also be a stereo camera. Let us study this variation now in greater detail.</p><p id="p-0083" num="0084">Thermal camera(s): In such a variation, a given site <b>202</b>, such as a building or an arena or a school or any other site shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, is fitted with one or more thermal cameras <b>204</b>A. As per above, for brevity, we may refer to thermal camera(s) <b>204</b>A in the singular with the knowledge that data streams from multiple cameras <b>204</b>A will be combined by anomalous subject and device identification system <b>200</b> for analysis. Camera <b>204</b>A may just be a pure thermal camera and capture the infrared spectrum of the electromagnetic radiation only. In such an implementation, data processing module <b>220</b> recognizes and tracks objects or people <b>206</b> based on just their temperature readings or thermal signature alone.</p><p id="p-0084" num="0085">However, in other variations, camera <b>204</b>A is a bi-spectrum camera because it captures both visible and infrared spectrums of the electromagnetic radiation. Preferably, thermal camera <b>204</b>A is also a stereoscopic or stereo camera because then it can capture depth/size information. Regardless, thermal camera <b>204</b>A working in conjunction with data processing module <b>220</b>, identifies and tracks each individual person amongst persons/people <b>206</b> at site <b>202</b> and further, reads their body temperatures. Thus, each individual/person along with his/her identifier per above, is also associated with a body temperature reading that is taken in real-time or near real-time. The temperature readings of each tracked/identified person are then provided to baseline engine <b>110</b> for analysis.</p><p id="p-0085" num="0086">Such an embodiment is shown in greater detail in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>2</b></figref> showing our site <b>202</b> now configured with an entrance <b>212</b> denoted by a dotted and dashed line. People <b>206</b>A, <b>206</b>B, . . . or simply people <b>206</b> are shown entering site/building <b>202</b> through entrance <b>212</b>. People <b>206</b> may be a few, or in dozens, or in thousands or even more in number at crowded site <b>202</b>. There are one or more thermal cameras <b>204</b>A, which we will simply refer to as camera <b>204</b>A per above, targeted or aimed at entrance <b>212</b>. As people <b>206</b> enter the building, camera <b>204</b>A captures their visible and infrared video streams. More specifically, person <b>206</b>A has a temperature reading of <b>210</b>A, person <b>206</b>B has a temperature reading of <b>210</b>B, and so on as shown.</p><p id="p-0086" num="0087">These visible and infrared video data streams or simply data streams are communicated to data processing module <b>220</b> via network backbone <b>208</b>. Data processing module <b>220</b> identifies and tracks each subject <b>206</b>A, <b>206</b>B, . . . amongst subjects <b>206</b> per above, and associates a temperature reading with them. It then communicates this information to baseline engine <b>110</b> for analysis.</p><p id="p-0087" num="0088">Preferably, module <b>220</b> communicates data packets containing the following information to engine <b>110</b>:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0089">1. A timestamp at which the observation is made by camera <b>204</b>A.</li>        <li id="ul0004-0002" num="0090">2. An object identifier assigned to each subject/person <b>206</b>A, <b>206</b>B, . . . per above.</li>        <li id="ul0004-0003" num="0091">3. (x, y, z) coordinates or location information of each identified subject/person at site <b>202</b>.</li>        <li id="ul0004-0004" num="0092">4. A temperature reading of the identified subject/person at timestamp in (1) above.</li>    </ul>    </li></ul></p><p id="p-0088" num="0093">These data packets are then parsed by baseline engine <b>110</b> which then establishes a baseline <b>120</b>A for the normal temperature readings for the individuals and identifies anomalous individuals per prior teachings. Preferably, an anomalous threshold value is provided as an input to baseline engine <b>110</b>. For example, a normal threshold value of 38&#xb0; C. or 100.4&#xb0; F. is provided to baseline engine <b>110</b> that incorporates this value into baseline <b>120</b>A with centroid <b>182</b>A. It then identifies as anomalous any subjects with body temperatures above the normal threshold value.</p><p id="p-0089" num="0094">A number of very useful scenarios are discovered/caught by the present embodiments of the anomalous subject and device identification system of the present design. The present technology allows an early detection of potential health and security threats in a reliable and flexible manner. A non-exhaustive list of useful scenarios identified/caught by the present design includes:<ul id="ul0005" list-style="none">    <li id="ul0005-0001" num="0000">    <ul id="ul0006" list-style="none">        <li id="ul0006-0001" num="0095">1. Elevated body temperature: Continuing with the above discussion, any individuals, such as person <b>206</b>C, showing a temperature reading equal to or greater than this normal threshold value are then identified as anomalous by baseline engine <b>110</b>. If there are multiple thermal cameras <b>204</b>A, then video data streams from these cameras is processed by combining them at or by data processing module <b>220</b> that then tracks objects/people across the various data streams of different cameras and identifies anomalous subjects with elevated body temperatures per above teachings. Preferably, the temperature reading performed by thermal camera(s) <b>204</b>A is accurate within an error tolerance of less than or equal to 0.3&#xb0; F.</li>        <li id="ul0006-0002" num="0096">2. Mask detection and/or enforcing mask wearing: The facial recognition capabilities of module <b>220</b> also allow detection of facial masks worn by individuals/personals. Preferably, the facial recognition capabilities are not degraded as a result of subjects wearing masks. Therefore, anomalous subject and device identification system <b>200</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref> is able to detect which subjects amongst subjects <b>206</b>A-E are wearing facial masks. Baseline engine can then establish baseline <b>120</b>B based on wearing of masks by the subjects as the normal behavior, and any subjects not wearing a mask can be signaled as an anomaly. Hence, mask wearing can be appropriately enforced upon those individuals/subjects who are not wearing masks.</li>        <li id="ul0006-0003" num="0000">&#x2003;Furthermore, while an anomalous subject with elevated body temperature per above, signifies a problem/anomaly, but if that individual is also not even wearing a mask, then that is even a greater anomaly or problem or threat, and baseline engine <b>110</b> can identify him/her as such.</li>        <li id="ul0006-0004" num="0097">3. Enforcing social distancing: Based on the capabilities of the present design and specifically the present embodiments, system <b>200</b> is able to enforce social distancing amongst subjects, such as that needed during the Covid-19 pandemic. Because the subjects are assigned an identifier and their location, speed and movements are known/tracked, the system can determine which subjects are not following social distancing guidelines. In the present case, proximity to other subjects may be a dimension on the hypercube of the respective baseline established by engine <b>110</b>. A proximal distance, for example 6 feet, can be provided as an input to baseline engine <b>110</b> representing the minimum threshold value. If a given subject is in repeated violation of the minimum threshold value/distance, then this situation and the subject can be conveniently identified and flagged by baseline engine <b>110</b>.</li>        <li id="ul0006-0005" num="0098">4. Weapons detection: Depending on the image/object recognition capabilities of data processing module <b>220</b>, data streams captured by cameras <b>204</b>A can be used to determine if a subject is carrying a weapon at site <b>202</b>. Of course, the present technology can support additional specialized sensors for weapons detection, such as metal or ballistic detectors at the site, instead of or in addition to sensors <b>204</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Such sensors allow system <b>200</b> to specifically detect guns, knives and other prohibited articles. As a result, system <b>200</b> in conjunction with baseline engine <b>110</b> can identify any anomalous individuals that may be carrying a prohibited weapon at site <b>202</b> per prior teachings.</li>        <li id="ul0006-0006" num="0099">5. Thermal signatures: The above capabilities utilizing thermal cameras of the present technology also allow system <b>200</b> to harvest thermal signatures of subjects at site <b>202</b>. For instance, each subject may have a slightly different normal body temperature that can be captured and cataloged by the system in an appropriate database. Similarly, an overall infrared signature of the bodies or forms of each subject may also be captured and cataloged in the database.</li>    </ul>    </li></ul></p><p id="p-0090" num="0100">Microphone(s): While referring back to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a given site <b>202</b>, such as a building or an arena or any other location, is fitted with one or more microphones <b>204</b>B. As per above, for brevity, we may refer to microphones <b>204</b>B in the singular with the knowledge that data streams from multiple microphones will be processed by anomalous subject and device identification system <b>200</b> for analysis per above.</p><p id="p-0091" num="0101">While typically microphones will come integrated with cameras <b>204</b>A, this is not necessarily the case. It is conceivable to have a site where audio signatures of subjects alone are used for identification and tracking and for determination of anomalous subjects. Examples of such audio sensitive sites include theaters, studios, etc. Moreover, the audio signatures may be combined with video signatures for better tracking of objects.</p><p id="p-0092" num="0102">Data processing module <b>220</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> may correlate an audio signature or identifier of a subject amongst subjects <b>206</b> based on audio stream from microphone <b>204</b>B, with a video signature or identifier of the subject based on video stream from camera <b>204</b>A to pinpoint the location of the subject with greater fidelity. It can then better provide the movement patterns or temperature readings of these subjects to baseline engine <b>110</b> for analysis per above teachings.</p><p id="p-0093" num="0103">Asset sensor(s): While still referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a given site <b>202</b>, such as a manufacturing or a chip fabrication facility or any other location containing important or valuable assets, is fitted with one or more asset sensors <b>204</b>C. For the purposes of present discussion an asset is a subject that is not a sentient being but still a valuable and/or sensitive item or thing whose monitoring is required. Examples include manufacturing equipment, apparatus, vaults/safes, valuable paraphernalia, or any other item of value at site <b>202</b> whose monitoring is justified. As per above, for brevity, we may refer to asset sensors <b>204</b>C in the singular with the knowledge that data streams from multiple asset sensors will be processed by anomalous subject and device identification system <b>200</b> for analysis per above.</p><p id="p-0094" num="0104">Asset sensor <b>204</b>C captures data from one or more xmitters installed in or near or around assets present at the site. In the embodiments where site <b>202</b> is a manufacturing or chip fabrication facility, an xmitter can be any sensor installed in or near a manufacturing equipment or asset that senses/monitors the asset and transmits the sensed/monitored data to asset sensor <b>204</b>C. An xmitter at a manufacturing or any other site can be based on any suitable wired or wireless technology including blue-tooth, cellular network, radio frequency identification (RFID), Zigbee, etc.</p><p id="p-0095" num="0105">Exemplarily, such an xmitter monitors the asset to ensure that it stays at a given location. Alternatively or in addition, such an xmitter may perform measurements of one or more manufacturing parameters for and/or in conjunction with the asset/equipment/tool, such as, reading the value of a voltage, a current, a pH, etc. It then transmits this reading or sensed data, either by a wired connection or wirelessly to an asset sensor of the present design, such as asset sensor <b>204</b>C.</p><p id="p-0096" num="0106"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows such an embodiment in greater detail. More specifically, <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>2</b></figref> where site <b>202</b> is a manufacturing facility, for example, a chip fabrication facility or fab. Facility <b>202</b> has a manufacturing line <b>214</b> that has various manufacturing assets or tools <b>216</b>A, <b>216</b>B, <b>216</b>C and <b>216</b>D as shown. These assets are being monitored by various xmitters of the present principles. Specifically, xmitter <b>218</b>A is in charge of monitoring asset/equipment <b>216</b>A and <b>216</b>B, xmitter <b>218</b>B is monitoring asset <b>216</b>C and xmitter <b>218</b>C is monitoring asset/equipment <b>216</b>D.</p><p id="p-0097" num="0107">Data surveilled or monitored by xmitters <b>218</b>A-C is then transmitted, by wire or wirelessly, on-demand or at regular intervals or on realtime or near-realtime basis, to asset sensor(s) <b>204</b>C. Asset sensor <b>204</b>C may be any wireless sensor receiving data packets from xmitters <b>218</b>A-C based on techniques known in the art. For instance, asset sensor(s) <b>204</b>C may communicate with xmitters <b>218</b>A-C using one or more of blue-tooth, cellular network, radio frequency identification (RFID), a Zigbee or any other suitable wireless technologies required for a given implementation.</p><p id="p-0098" num="0108">Asset sensor <b>204</b>C then communicates this data to data processing module <b>220</b> as shown. In the present embodiment, data processing module <b>220</b> performs any necessary processing of data received from xmitters <b>218</b>A-C before providing it to baseline engine <b>110</b> for analysis. In an exemplary embodiment, data processing module <b>220</b> normalizes data between one or more assets. In the same or another variation, module <b>220</b> correlates data between assets of the same type or of different types. In any event, the processed data is provided to baseline engine <b>110</b> for analysis. Baseline engine now establishes a rolling baseline for assets <b>216</b>A-D based on data received from xmitters <b>218</b>A-C and identifies any assets or subjects that may be anomalous.</p><p id="p-0099" num="0109">In the preferred embodiment, baseline engine <b>110</b> establishes a rolling baseline for each different type of asset or manufacturing tool/equipment. For example, if site <b>202</b> is a fab then baseline engine <b>110</b> may establish a rolling baseline <b>120</b>B with centroid <b>182</b>B for chemical vapor deposition tools, and another baseline for metrology tools, etc. as shown. Note that in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, to avoid clutter, only one such baseline with its centroid are shown marked by reference numerals <b>120</b>B and <b>182</b>B respectively.</p><p id="p-0100" num="0110"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a variation of <figref idref="DRAWINGS">FIG. <b>4</b></figref> containing a camera(s) <b>204</b>A from the embodiments of <figref idref="DRAWINGS">FIG. <b>3</b></figref> explained earlier. Also shown are human subjects <b>206</b>F, <b>206</b>G and <b>206</b>H. Camera <b>204</b>A is in charge of monitoring/surveilling people <b>206</b>F-H present at site <b>202</b> per earlier explanation. There is also a data processing module <b>220</b> in <figref idref="DRAWINGS">FIG. <b>5</b></figref> of above discussion. In the present embodiments, in addition to its functions already described above, data processing module <b>220</b> also correlates data between human subjects <b>206</b>F-H and manufacturing subjects or assets <b>216</b>A-D. If camera or cameras <b>204</b>A are also thermal cameras, then temperature readings <b>210</b>F-H of subjects <b>206</b>F-H respectively are also available as shown.</p><p id="p-0101" num="0111">There are a number of useful scenarios that are identifiable by the variations shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> and <figref idref="DRAWINGS">FIG. <b>5</b></figref>. A non-exhaustive list of these scenarios includes:<ul id="ul0007" list-style="none">    <li id="ul0007-0001" num="0000">    <ul id="ul0008" list-style="none">        <li id="ul0008-0001" num="0112">1. Dwell times: Examples of useful correlations between data from asset sensor(s) <b>204</b>C and camera(s) <b>204</b>A include which human subjects <b>206</b>F-H have been in the vicinity or proximity of manufacturing subjects/assets <b>216</b>A-D during a given time window, the dwell times of subjects <b>206</b>F-H around subjects <b>216</b>A-D in a given time window, the temperature readings of these subjects, where else in facility <b>202</b> have subjects <b>206</b>F-H been, their past security profile/performance, etc. This correlated data is then provided to baseline engine <b>110</b> which analyzes it and identifies anomalous subjects or assets at site <b>202</b> per prior explanation.</li>        <li id="ul0008-0002" num="0113">2. Training or other security issues/threats: If a subject/human <b>206</b>B has shown a greater than normal dwell time around a malfunctioning asset <b>216</b>D, then this may signify a training problem. If asset <b>216</b>D has been involved in security incidents in the past, then this may signal a security issue or threat associated with subject/human <b>206</b>B.</li>        <li id="ul0008-0003" num="0114">3. Espionage: If an unauthorized universal serial bus (USB) device with malware is inserted into subject/asset <b>216</b>C that is exfiltrating data, then baseline engine <b>110</b> will catch this incident. More specifically, data transmission/download patterns of subject/asset <b>216</b>C as compared to its baseline will signify a greater than &#x201c;normal&#x201d; activity. Such an anomalous activity will be identified based on the distance of the number of transmitted/downloaded data packets from the centroid of the hypercube of the baseline per prior teachings. This is one form of espionage that is identifiable by the present technology.</li>        <li id="ul0008-0004" num="0000">&#x2003;As another example, if an unauthorized subject/human has excessive dwell time around a sensitive asset, then this might signify another form of espionage.</li>    </ul>    </li></ul></p><p id="p-0102" num="0115">Similarly, a variety of other useful scenarios that are based on correlating data related to subjects <b>206</b>F-H and captured by camera(s) <b>204</b>A with the data related to subjects <b>216</b>A-D captured by asset sensor(s) <b>204</b>C, are conceivably caught and are identifiable by the embodiments explained in relation to <figref idref="DRAWINGS">FIG. <b>4</b>-<b>5</b></figref>.</p><p id="p-0103" num="0116">Personal-device sensor(s): In a highly preferred set of embodiments, a given site <b>202</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, such as a building or an arena or any other site, is fitted with one or more personal-device sensor(s) <b>204</b>D. Personal-device sensors <b>204</b>D are wireless sensors based on one or more of a blue-tooth sensor, a cellular signal sensor, a radio frequency identification (RFID) sensor/reader, a Zigbee sensor or any other suitable wireless technology sensor required for a given implementation. Personal-device sensors <b>204</b>D are in charge of communicating with the devices carried by various subjects at site <b>202</b>.</p><p id="p-0104" num="0117">If a personal-device sensor is a blue-tooth sensor, it is responsible for communicating with blue-tooth personal-devices, if it is a cellular signal sensor, it is responsible for communicating with cellular personal-devices such as cellular phones, if it is an RFID reader, it is responsible for communicating with RFID personal devices such as RFID tags, which may be active, passive or semi-active tags. If the personal device sensor is a Zigbee sensor, it is responsible for communicating with Zigbee personal-devices such a Zigbee end-devices.</p><p id="p-0105" num="0118">Depending on the requirements of an implementation and the capabilities of a particular wireless technology, any of the communication above may be bi-directional or uni-directional i.e. only from the personal-devices to the personal-device sensor. Moreover, more than one sensors of the same or different type may be integrated into a single composite sensor/device in the present or any other embodiments of this disclosure.</p><p id="p-0106" num="0119">A personal-device carried by a subject may or may not actually be owned by him/her or be his/her &#x201c;personal&#x201d; device in a manner of ownership. However, for the purposes of this disclosure any device carried by the subject is termed as a personal-device. Such subjects are typically human beings and the devices carried by them may be cellular phones including smartphones, tablets, wearable devices such as smartwatches, laptop computers, etc. Note however that there are situations that a personal-device is unattended or not carried by any subject. Such a situation is discussed in detail in the embodiments explained below.</p><p id="p-0107" num="0120"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the present embodiments in greater detail. Specifically, <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>2</b></figref> emphasizing the wireless sensor capabilities based on the instant principles. Site <b>202</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a number of human subjects carrying devices. Specifically, <figref idref="DRAWINGS">FIG. <b>6</b></figref> shows subject <b>206</b>I carrying a device <b>222</b>I, <b>206</b>J carrying a device <b>222</b>J, <b>206</b>L carrying devices <b>222</b>L and <b>224</b>L, <b>206</b>M carrying device <b>222</b>M and subject <b>206</b>N carrying devices <b>222</b>N, <b>224</b>N and <b>226</b>N at site <b>202</b>. Note that subject <b>206</b>K is not carrying any device while subject <b>206</b>L is carrying two devices <b>222</b>L and <b>224</b>L, and subject <b>206</b>N is carrying three devices <b>222</b>N, <b>224</b>N and <b>226</b>N. While the present design supports only having one personal-device sensor, the embodiment of <figref idref="DRAWINGS">FIG. <b>6</b></figref> explicitly shows two personal-device or wireless sensors <b>204</b>D<b>1</b> and <b>204</b>D<b>2</b> which may be based on any number of available wireless technologies, some examples of which were listed above.</p><p id="p-0108" num="0121">Now, based on triangulation and trilateration techniques known in the art and the availability of sufficient number of sensors <b>204</b>D, the present design is able to determine where each device carrying subject is on the premises of site <b>202</b>. For this purpose, our data processing module <b>220</b> may again be utilized with the necessary algorithms for locating devices <b>222</b>, <b>224</b> and <b>226</b> with their respective subjects <b>206</b> at site <b>202</b>. As noted, two such exemplary algorithmic techniques include triangulation and trilateration.</p><p id="p-0109" num="0122">As a consequence, module <b>220</b> may determine that individual/subject <b>206</b>I is in region R<b>1</b> of site <b>202</b>, individuals/subjects <b>206</b>J and <b>206</b>L are in region R<b>2</b> and subjects <b>206</b>M and <b>206</b>N are in region R<b>3</b>. Furthermore, data processing module <b>220</b> of the present design also assigns an identifier to each device that it detects at site <b>202</b>. Note that subject <b>206</b>K who is not carrying any device will not be detected by sensors <b>204</b>D<b>1</b> and <b>204</b>D<b>2</b> alone. For this purpose, we will defer to embodiments discussed further below.</p><p id="p-0110" num="0123">Now, given the above setup, the wireless embodiments of <figref idref="DRAWINGS">FIG. <b>6</b></figref> are able to provide a number of important capabilities for identifying anomalous situations. A non-exhaustive list of such capabilities and situations/scenarios is provided below:<ul id="ul0009" list-style="none">    <li id="ul0009-0001" num="0000">    <ul id="ul0010" list-style="none">        <li id="ul0010-0001" num="0124">1. Location detection: As noted above, with two or more personal-device sensors <b>204</b>D<b>1</b>-<b>2</b>, the system is able to determine the location of each device carrying subject at site <b>202</b> using techniques including triangulation and trilateration.</li>        <li id="ul0010-0002" num="0125">2. Anomalous movement patterns: Based on location detection, the system is further able to determine movement patterns or speed and direction at a given point in time of subjects <b>206</b>I, <b>206</b>J, <b>206</b>L, <b>206</b>M, <b>206</b>N. If any subjects exhibit erratic or distressed movements, they can be identified by baseline engine <b>110</b> per above teachings.</li>        <li id="ul0010-0003" num="0126">3. Anomalous dwell patterns: In a similar manner, system <b>200</b> is able to identify different from normal dwell times of any subjects <b>206</b>I, <b>206</b>J, <b>206</b>L, <b>206</b>M, <b>206</b>N at sensitive locations at site <b>202</b> based on their authorization level. Similarly, the proximity of one subject to other subjects that is not regarded normal for a given implementation, etc. can also be identified and an anomalous subject identified per above.</li>        <li id="ul0010-0004" num="0127">4. Excessive beaconing in unused media access control (MAC) address space: Let us consider the scenario where site <b>202</b> of <figref idref="DRAWINGS">FIG. <b>6</b></figref> is an office building with a local area network (LAN) powered by one or more personal-device or wireless sensors or antennas <b>204</b>D<b>1</b>-<b>2</b> and subjects <b>206</b>I-N are expected to be employees. Prior to joining the LAN, a device beacons in an unused MAC address space, that is, by not using its real or correct MAC address. However, this beaconing is still detected by sensors <b>204</b>D<b>1</b>-<b>2</b> and data processing module <b>220</b> assigns it an identifier.</li>        <li id="ul0010-0005" num="0000">&#x2003;Only after a device joins the LAN, it beacons with its correct MAC address and at which point system <b>200</b> can use its real MAC address as the device identifier. If it is expected that employees <b>206</b>I-N will be connected to the LAN, then a device that continues to beacon in the unused MAC address space for a greater than normal period of time, will be identified as a suspect device by baseline engine <b>110</b>.</li>        <li id="ul0010-0006" num="0000">&#x2003;More specifically, baseline engine <b>110</b> will establish rolling baseline <b>120</b>D with a normal behavior of data streams from sensors <b>204</b>D<b>1</b>-<b>2</b> indicating that devices at site <b>202</b> start communicating with their real MAC address within a &#x201c;normal&#x201d; time window. This time will be a dimension in the conceptual hypercube with centroid <b>182</b>D of baseline <b>120</b>D. If a device such as device <b>222</b>J carried by employee <b>206</b>J beacons in the unused MAC address space for greater than normal time, then it will be far away enough from centroid <b>182</b>D along this dimension to signify an anomaly. Such an anomaly may indicate a breach or security incident or a threat, or a technical issue. As a result, employee <b>206</b>J with device <b>222</b>J will be flagged/signaled as an anomaly by engine <b>110</b>. These and other useful scenarios are easily identifiable and caught by anomalous subject and device identification system <b>200</b> of the personal-device sensor embodiment shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</li>    </ul>    </li></ul></p><p id="p-0111" num="0128">Personal-device sensor(s) together with camera(s): In a highly useful set of embodiments personal-device sensors <b>204</b>D of <figref idref="DRAWINGS">FIG. <b>2</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref> work together with cameras <b>204</b>A of <figref idref="DRAWINGS">FIG. <b>2</b></figref> to provide additional fidelity to our anomalous subject and device identification system. Such an embodiment is shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. Just like the embodiments of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, cameras for the present embodiments are a desirable but not necessary type of sensor to accrue the benefits of the present technology.</p><p id="p-0112" num="0129"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>6</b></figref> but also with cameras <b>204</b>A of the prior teachings. <figref idref="DRAWINGS">FIG. <b>7</b></figref> also shows a device <b>222</b>M in region R<b>2</b> of site <b>202</b> that is not carried by any subject. In the example of <figref idref="DRAWINGS">FIG. <b>6</b></figref>, two cameras <b>204</b>A<b>1</b> and <b>204</b>A<b>2</b> are explicitly shown as well as data processing module <b>220</b> that amongst other things, performs object tracking and facial/image/object recognition. In a manner analogous to the embodiments of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, cameras in <figref idref="DRAWINGS">FIG. <b>7</b></figref> add fidelity to the embodiments of <figref idref="DRAWINGS">FIG. <b>6</b></figref> while also providing additional capabilities as discussed further below. For example, cameras <b>204</b>A<b>1</b> and <b>204</b>A<b>2</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> are able to detect and track subject <b>206</b>K who is not carrying any wireless device detectable by personal-device sensors <b>204</b>D. Of course, camera(s) <b>204</b>A<b>1</b>-<b>2</b> are able to afford all the capabilities to the embodiment of <figref idref="DRAWINGS">FIG. <b>7</b></figref> as already explained in reference to the embodiments of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0113" num="0130">Moreover and very importantly, system <b>200</b> with cameras <b>204</b>A<b>1</b>-<b>2</b> working in conjunction with data processing module <b>220</b> as well as personal-device sensors <b>204</b>D<b>1</b>-<b>2</b> is now able to associate a specific subject with each device. Anomalous subject and device identification system <b>200</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> assigns an identifier to each subject as well his/her associated device(s) per above. As the subject moves around the building/site <b>202</b>, the system is able to ascertain the physical proximity or correlation between the subject and his/her devices.</p><p id="p-0114" num="0131">Data streams from sensors <b>204</b>A<b>1</b>-<b>2</b> and <b>204</b>D<b>1</b>-<b>2</b> processed by module <b>220</b> are then provided to baseline engine <b>110</b>. Based on data streams from cameras <b>204</b>A<b>1</b>-<b>2</b>, baseline engine establishes one or more baselines <b>120</b>A<b>1</b>, <b>120</b>A<b>2</b>, <b>120</b>A<b>3</b>, . . . <b>120</b>AN for the dimensions of conceptual hypercube of interest with correspondent centroids <b>182</b>A<b>1</b>, <b>182</b>A<b>2</b>, <b>182</b>A<b>3</b>, . . . <b>182</b>AN. Similarly, based on data streams from wireless sensors <b>204</b>D<b>1</b>-<b>2</b>, baseline engine establishes one or more baselines <b>120</b>D<b>1</b>, <b>120</b>D<b>2</b>, <b>120</b>D<b>3</b>, . . . <b>120</b>DN for the dimensions of conceptual hypercube of interest with correspondent centroids <b>182</b>D<b>1</b>, <b>182</b>D<b>2</b>, <b>182</b>D<b>3</b>, . . . <b>182</b>DN. It then scores each incoming packet from these data streams against the above baselines by computing the distance of the packet from the respective centroids on a certain dimension of interest. If the distance is far enough or greater than what is normal for the respective baseline, it identifies that packet as an anomalous packet and signals an anomaly identifying the associated subject and/or device per prior teachings.</p><p id="p-0115" num="0132">Such a capability allows a number of important scenarios to be discovered/caught by anomalous subject and device identification system <b>200</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref> based on the present technology. A non-exhaustive list of these include:<ul id="ul0011" list-style="none">    <li id="ul0011-0001" num="0000">    <ul id="ul0012" list-style="none">        <li id="ul0012-0001" num="0133">1. Lack of a device carried by a subject: A subject, such as subject <b>206</b>K detected and tracked by cameras <b>204</b>A who is not carrying any device may indicate a suspect situation for site <b>202</b>. In this case, one dimension of the conceptual hypercube will exemplarily be the number of devices carried by a subject. If the number is 0 or too high above the normal, then this indicates an anomaly for site <b>202</b>. Such a scenario along with the anomalous subject is identified by the present technology per above teachings.</li>        <li id="ul0012-0002" num="0134">2. Unattended device: Device <b>222</b>M that is not carried by any subject may also be a suspect situation. Such a device <b>222</b>M can be detected by one or more of various types of appropriate sensors supported by the present design, including cameras <b>204</b>A<b>1</b>-<b>2</b> and personal-device sensors <b>204</b>D<b>1</b>-<b>2</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>. Device <b>222</b>M will have an assigned identifier by data processing module <b>220</b> per above. If there has been no subject associated with this device identifier, then the device itself and alone is identified by the system as an anomalous device. On the other hand, if the device identifier has been associated with subject <b>206</b>M with his/her own identifier, then system <b>200</b> is able to ascertain that subject/human <b>206</b>M was previously associated with or carrying device <b>222</b>M. Subject <b>206</b>M may or may not be on site <b>202</b> at that point in time.</li>        <li id="ul0012-0003" num="0000">&#x2003;Any of the above scenarios may simply signify an innocuous situation, such as a lost device. On the other hand, these may also indicate a more serious security incident/threat associated with device <b>222</b>M and subject <b>206</b>M. Regardless, the above scenarios along with the subject and/or device in question are signaled by baseline engine <b>110</b> as anomalies and identified.</li>        <li id="ul0012-0004" num="0000">&#x2003;More specifically, in these scenarios, one dimension of the conceptual hypercube will exemplarily be the number of subjects associated with a device. If the number is 0 or greater than 1, then this indicates an anomaly for site <b>202</b>. Per above, if there is a prior association of an anomalous device with a subject then that subject is also identified, otherwise just the device itself is identified as anomalous by the anomalous subject and device identification system <b>200</b> of the present design.</li>        <li id="ul0012-0005" num="0135">3. Transfer of a device: In an analogous manner, if a device that was once associated with one subject is now associated with another subject, such a situation also rises to a level of concern or anomaly. Again, such an anomaly caught by the present design may be innocuous or a more serious security exposure or threat. In this case also, one dimension of the conceptual hypercube will be the number of subjects associated with a device. If the number is 0 or greater than 1, then this indicates an anomaly for site <b>202</b>.</li>    </ul>    </li></ul></p><p id="p-0116" num="0136">Wireless sensors with site instrumentation: In addition to or alternatively of cameras, in some embodiments the wireless sensors of the present design are augmented by wireless antennas instrumented/installed at the site. Like cameras, these local antennas and instrumentation provide additional fidelity to the anomalous subject and device identification system of the present design.</p><p id="p-0117" num="0137"><figref idref="DRAWINGS">FIG. <b>8</b></figref> assists us in explaining these embodiments in greater detail. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>7</b></figref> but with an RF infrastructure containing two additional radio antennas <b>232</b>A and <b>232</b>B installed in regions R<b>2</b> and R<b>3</b> of site <b>202</b>. Preferably, these antennas are wifi antennas or access points operating in a radio frequency range of 2.5 to 5 GHz. Preferably still, the antennas are cellular antennas. Such antennas may be used in conjunction with a spectrum analyzer (not shown specifically) in order to read and analyze the cellular signals from the devices. Based on the signal strength and/or other network techniques in the art, these antennas assist in knowing whether a device is close to an antenna or not. This knowledge further supplements the object tracking by data processing module <b>220</b> enabled by cameras <b>204</b>A.</p><p id="p-0118" num="0138">Any number of antennas <b>232</b>A, <b>232</b>B or more, installed in the local infrastructure at site <b>202</b> can operate in one or more of at least two configurations: (i) the antennas act as a booster for wireless sensors <b>204</b>D<b>1</b>-<b>2</b> by collecting data on the ground close to the devices at site <b>202</b> and then communicating it to sensors <b>204</b>D<b>1</b>-<b>2</b> either by wire or wirelessly, (ii) the antennas themselves operate as sensors <b>204</b>D installed at optimal locations at site <b>202</b> for maximum signal coverage/strength. In other words, they may supplement existing wireless sensors <b>204</b>D, but instead of or in addition to, may also act themselves as wireless sensors <b>204</b>D.</p><p id="p-0119" num="0139">In the absence of cameras <b>204</b>A, antennas <b>232</b>A and <b>232</b>B assist in the determination of the location of a device with respect to the antennas in conjunction with wireless sensors <b>204</b>D. As explained earlier in reference to the embodiments of <figref idref="DRAWINGS">FIG. <b>6</b>-<b>7</b></figref>, this is accomplished by using network algorithmic techniques including triangulation and trilateration, etc. preferably performed by data processing module <b>220</b>. Any number and type of such antennas based on various available wireless technologies may be installed at site <b>202</b> depending on the requirements of an implementation. The various antennas at the site may all be based on the same or different wireless technologies depending on the types of wireless devices they need to communicate with.</p><p id="p-0120" num="0140">Using sensors on computing devices: In a highly useful set of embodiments, sensors available on computing devices are used to accrue the benefits of the anomalous subject and device identification system of the present design. The benefit of these embodiments is that instead of requiring separate sensors, sensors that are already ubiquitously present in today's computing devices are utilized. Exemplary computing devices include laptops, tablets, cellular phones including smartphones, wearable devices (including smartwatches and medical devices), security devices, etc.</p><p id="p-0121" num="0141">Let us take advantage of <figref idref="DRAWINGS">FIG. <b>9</b></figref> to discuss these embodiments in greater detail. <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a variation of <figref idref="DRAWINGS">FIG. <b>2</b></figref> showing an anomalous subject and device identification system <b>300</b> of the present design operating at a site <b>302</b>. Camera and microphone sensors <b>204</b>A and <b>204</b>B respectively of the prior discussion are now embodied in a tablet <b>234</b>, wireless asset sensor <b>204</b>C is now embodied in cellular phone or smartphone <b>236</b> and wireless personal-device sensor <b>204</b>D is now embodied in cellular phone or smartphone <b>238</b>. By being embodied here we mean that the sensor in question may be integrated with the device or operably connected to it, such as via a USB port.</p><p id="p-0122" num="0142">Kiosk <b>205</b> discussed further below has a computing device <b>240</b> installed in it. Device <b>240</b> may be a tablet or a cellular phone/smartphone or even a laptop or the like. Not all of sensors <b>204</b>A-D above need to be embodied in computing devices. In other words, any subset of the sensors may be separately installed as in the embodiments of <figref idref="DRAWINGS">FIG. <b>2</b>-<b>8</b></figref>. Also shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref> is data processing module <b>220</b> that works in conjunction with the sensors per prior discussion.</p><p id="p-0123" num="0143">All the relevant teachings of the prior embodiments apply to the present embodiments also, except that the sensors are now on economically and ubiquitously available on (personal) computing devices. One of the advantages of the present embodiments is that a given site, such as site <b>302</b> can be quickly provisioned with the instant anomalous subject and device identification system <b>300</b>. This is because the computing devices housing the sensors of interest, such as devices <b>234</b>, <b>236</b>, <b>238</b> and <b>240</b> are cheaply and readily available. Moreover, they have a small form factor, such that they can be easily and flexibly deployed at site <b>302</b> for optimal results. In an interesting application of the present embodiments, mobile devices with police officers containing cameras, microphones and/or other sensors are used to surveil a location on a short notice per above teachings.</p><p id="p-0124" num="0144">Kiosks: Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the present technology lends itself well to showcasing its capabilities at a kiosk <b>205</b> at site <b>202</b>. Kiosk <b>205</b> may be instrumented with one or more sensors <b>204</b>. These sensors may further be embodied in a computing device installed or operating in the kiosk.</p><p id="p-0125" num="0145">Referring now to the embodiment of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, kiosk <b>205</b> shows a computing device <b>240</b> that may be a tablet operating in it. Exemplarily, tablet <b>240</b> may be instrumented with a camera, such as camera <b>204</b>A and a microphone, such as microphone <b>204</b>C along with a data processing module <b>220</b> of the present design. Then, guests/subjects <b>206</b> at site <b>306</b> may use the kiosk to take their temperature reading or to ensure that their mask is detectable or to get familiarized with the capabilities of anomalous subject detection system <b>300</b> at site <b>302</b>.</p><p id="p-0126" num="0146">Data layering: In the preferred embodiment, the present technology is implemented by storing the data streams from various sensors, such as sensors <b>204</b> at site <b>202</b>/<b>302</b> as separate data-tracks or layers in a file. Each data layer or track in the data file corresponds to a data stream from a sensor. For example, there may be a radio frequency (RF) data layer, a cellular layer, a blue-tooth layer, a video layer, an audio layer, etc. This layering may be performed by data processing module <b>220</b>.</p><p id="p-0127" num="0147">Additionally, as object recognition is performed, an underlying subject/device data layer containing characteristics of the objects being recognized and to whom an identifier is assigned per above, is also created. For instance, if the object recognition function recognizes two persons amongst persons <b>206</b> with identifiers <b>78</b>X<b>67</b> and Y<b>6790</b> with heights 6 foot, 3 inches and 5 feet, 6 inches respectively, then this data is stored in the underlying subject/device data layer in the data file.</p><p id="p-0128" num="0148">Where there are multiple sensors of the same type, such as cameras <b>204</b>A<b>1</b> and <b>204</b>A<b>2</b> in <figref idref="DRAWINGS">FIG. <b>7</b>-<b>8</b></figref>, the data streams from these sensors can be stored as separate data layers. Alternatively, the data streams may first be combined into a composite data layer of video type by data processing module <b>220</b> and then stored in the data file. The present design thus affords the above multilayer approach to data streams obtained from various sensors.</p><p id="p-0129" num="0149">Forensic analysis: As already mentioned, the embodiments of <figref idref="DRAWINGS">FIG. <b>2</b>-<b>9</b></figref> utilize cloud <b>230</b> for archiving the findings of baseline engine <b>110</b> and for performing analytics on the archived data. Such analytics or forensic analysis, that preferably utilizes machine learning (ML) and artificial intelligence (AI) techniques, can be extremely useful. This is because it can allow answering hard questions for establishments and allow them to limit liability and/or manage risk.</p><p id="p-0130" num="0150">For example, let us consider that a site, such as site <b>202</b>/<b>302</b> of the of the prior discussion is a restaurant/school. Then a claim by a patron/student <b>206</b> that he/she got infected with Covid-19 virus while at the restaurant/school on a given date may be challenged by uncovering evidence in the archive that the patron/student was not wearing a mask on that date at the restaurant/school. In another interesting application of the above embodiments for performing mask wearing enforcement/detection, a local government may audit a chain of hotels or restaurant based on the above-discussed instant archived data in cloud <b>230</b> to determine if they have been allowing patrons without masks.</p><p id="p-0131" num="0151">Furthermore, as the data streams from sensors <b>204</b> about subjects at site <b>202</b>/<b>302</b> is stored in a database, whether the database is on-premise at site <b>202</b>/<b>302</b> or in cloud <b>230</b>, this allows the creation of profiles for individual subjects. This capability is also very useful because any analytics performed on the output of baseline engine <b>110</b> can then be matched against the profile of the subject in question to determine whether a specific behavior matches his/her profile. If it does not, then system <b>200</b>/<b>300</b> updates the subject or target profile accordingly. The profiling capability further allows system <b>200</b>/<b>300</b> to blacklist or whitelist subjects as needed.</p><p id="p-0132" num="0152">In yet another variation, the anomalous subject and device identification system of the present design further analyzes data from subjects based on their police record. For example, one dimension of the hypercube of the baseline established by baseline engine <b>110</b> may be the number of arrests or warrant or charges, etc. for the subjects. This information may then be utilized to determine if a given subject scored on that dimension is likely to be associated with an anomalous situation based on above teachings.</p><p id="p-0133" num="0153">Overall: Any of the embodiments taught above may utilize a wired or a wireless connection as appropriate to facilitate communication between sensors, devices and ground infrastructure. Furthermore, backbone <b>208</b> discussed in various embodiments above may also be wired or wireless. Furthermore, various capabilities of the above embodiments may be combined (mixed and matched) depending on the number and types of various sensors and/or devices involved in an implementation.</p><p id="p-0134" num="0154">Furthermore, exemplary sites/locations that may benefit from the anomalous subject and device identification system with its above-taught embodiments include airports, train stations, subways, central bus stations, embassies and consulates, government buildings, stadiums, arenas, venues, convention centers, Fortune 500 companies' headquarters or key offices, hospitals, universities/colleges, schools, restaurants and hospitality centers, office buildings, etc.</p><p id="p-0135" num="0155">Indicators of Compromise by Analyzing Data Based on Rolling Baseline:</p><p id="p-0136" num="0156">In a highly preferred set of embodiments, the data from a variety of objects is analyzed by the rolling baseline engine of the prior teachings to determine whether any of those objects may be compromised. The term object in these embodiments is used to refer either to a finished product or simply put, a product, or a component assembly or simply put, a component, that may be assembled into or integrated into or to produce a product.</p><p id="p-0137" num="0157">Exemplarily, a product may be consumer product or device or an end-user device, such as a smart television, a smartphone, a tablet, a thermostat, a smart fridge, a security camera, a microphone, a measuring device, any other internet of things (IoT) devices, or any other consumer product/device. The product may also be an industrial product/device, or any other conceivable finished product. A component may be any conceivable component or assembly that is used in the assembly or manufacturing of a finished product, including the ones listed above. A component may also be a semi-conductor component, a chip or a circuit board or circuitry that may eventually be used in a product including the ones listed above.</p><p id="p-0138" num="0158">A few examples of objects covered by the present embodiments are shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. More specifically, <figref idref="DRAWINGS">FIG. <b>10</b></figref> shows one or more smart meters <b>400</b>A sending their operational data, such as their measurements or meter readings at defined intervals or on-demand to our rolling baseline engine <b>110</b> via network backbone <b>208</b>. <figref idref="DRAWINGS">FIG. <b>10</b></figref> also shows one or more circuit boards <b>400</b>B that send their prediction, simulation, test, verification, performance, etc. data during their manufacturing to baseline engine <b>110</b> via network backbone <b>208</b>. Network backbone <b>208</b> may be connected to other systems and Information Technology infrastructure not explicitly shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, and which is responsible for consuming and processing data generated by objects <b>400</b>. Depending on the embodiment network backbone <b>208</b> may be a secure or private network or the internet or any combination thereof.</p><p id="p-0139" num="0159"><figref idref="DRAWINGS">FIG. <b>10</b></figref> also shows one or more digital cameras <b>400</b>C that may include security cameras, sending camera footage, such as a surveillance footage, to baseline engine <b>110</b>. <figref idref="DRAWINGS">FIG. <b>10</b></figref> further shows one or more microphones <b>400</b>D that send their operational data such as audio recordings to baseline engine <b>110</b>. Also shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref> are one or more semi-conductor components or chips <b>400</b>E that send their manufacturing data, such as prediction, simulation, test, verification, performance, etc. data to baseline engine <b>110</b> via network backbone <b>208</b>. There are also one or more smart computing devices <b>400</b>F, which may include a smart phone, a tablet, or any other mobile computing device that send data to baseline engine <b>110</b>.</p><p id="p-0140" num="0160">Also shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref> are one or more smart home devices <b>400</b>G, including Google Nest&#x2122; and Amazon Echo&#x2122; devices, such as temperature or atmospheric sensors, that send their data, such as temperature readings, carbon monoxide readings, etc. to baseline engine <b>110</b> via network backbone <b>208</b>. <figref idref="DRAWINGS">FIG. <b>10</b></figref> also shows one or more smart TVs <b>400</b>H that sends their data, such as performance data or playtime, or any other statistics to baseline engine <b>110</b>. Further, the dotted line <b>4001</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref> indicates that any number and types of such objects/devices may benefit from the present technology not explicitly shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, that send their manufacturing and/or operational or any other kind of data to baseline engine <b>110</b> for analysis.</p><p id="p-0141" num="0161">As noted above, data in the present embodiments refers to any data that any of the above objects generates during its course of manufacturing/construction/assembly or operation thereafter. Exemplarily, if the object is a semiconductor chip or a circuit, the manufacturing data may be its prediction, simulation, test, verification, performance, etc. data. Such data may also take the form of &#x201c;pings&#x201d; or &#x201c;heartbeats&#x201d; or measurements or surveillance footage or an operational report, performance data, or any other type of conceivable data generated by an object or expected to be generated by the object during its lifecycle.</p><p id="p-0142" num="0162">Baseline engine <b>110</b> then analyzes this data and determines if the corresponding object or objects that generated the data may be compromised. This determination is referred to as finding/detecting/generating an indicator of compromise in the object(s) by baseline engine <b>110</b>. Per prior teachings, this is accomplished by identifying anomalous packets far enough away from centroid <b>182</b> representing the normal population of packets of data received from the objects.</p><p id="p-0143" num="0163">In one example, object <b>400</b>A is a smart tachometer, such as the one used in a modern car, that may normally transmit its reading every 1 minute to rolling baseline engine <b>110</b>. Now, if the frequency of such a reading inexplicably changes to 5 minutes, then this may indicate a compromise of/in object/device <b>400</b>A as detected by baseline engine <b>110</b>. Explained further, a hacker or a malware may have intruded object <b>400</b>A and may be executing remote and unauthorized commands on it and/or be sending/receiving unauthorized messages to/from it. Remote command execution on an IoT device, such as object <b>400</b>A of <figref idref="DRAWINGS">FIG. <b>10</b></figref>, may result in consuming its limited computational and network resources. As a consequence, it may now only be able to report its readings at every 5 minutes, instead of every 1 minute, as originally intended.</p><p id="p-0144" num="0164">Our baseline engine <b>110</b> is able to detect such a misreporting or deviation of reporting frequency of object <b>400</b>A as a far enough distance from centroid <b>182</b> of hypercube <b>180</b> of baseline <b>120</b>, per prior teachings. This deviation is identified as an anomaly or an indicator of compromise of/in device/object <b>400</b>A in the present embodiments. As a consequence, remedial or corrective actions may be immediately taken, which otherwise could have resulted in a catastrophic outcome, such as a car accident.</p><p id="p-0145" num="0165">In a desirable set of variations of the present embodiments, the rolling baseline engine detects indicators of compromise in objects by analyzing their data sent to or residing in a cloud. There are many different types of clouds in which such internet-enabled objects may send their manufacturing, operational or any other data. These include at least:<ul id="ul0013" list-style="none">    <li id="ul0013-0001" num="0000">    <ul id="ul0014" list-style="none">        <li id="ul0014-0001" num="0166">1. Generic automation testing clouds or farms.</li>        <li id="ul0014-0002" num="0000">&#x2003;These clouds, also sometimes referred to as device farms or simply farms, are clouds that are used for the functional automation and testing of various devices, including IoT devices. Current providers of such farms include Saucelabs&#x2122;, Xamarin&#x2122;, Perfecto&#x2122;, etc. These clouds offer generic testing environments for many types of devices running a variety of operating systems, including iOS&#x2122; and Android&#x2122;. The devices testable in these cloud environments include not only mobile phones, but also a variety of IoT devices, such as smart refrigerators, smart TVs, smart thermostats, etc. that run on the supported operating systems.</li>        <li id="ul0014-0003" num="0000">&#x2003;As a consequence, a developer team or a concerned party can test the application(s) developed for the &#x201c;target&#x201d; device or devices with a target operating system(s) without incurring the capital expense of owning and operating those devices and operating systems. This is especially helpful when the developer needs to support an application on not only a single target device, e.g. iPhone 13, but a range of devices e.g. iPhone 6S through iPhone 15 running a variety of iOS versions, including iOS 10 through iOS 15.</li>        <li id="ul0014-0004" num="0167">2. Device specific clouds</li>        <li id="ul0014-0005" num="0000">&#x2003;These clouds are specific to a given type of object or device. For example, Amazon web services (AWS&#x2122;) device farms offer mobile application testing services for iOS and Android devices. Although the devices currently testable are mobile phones, the types of such devices are expected to grow and include other types of iOS and Android devices, including smart home and industrial devices, IoT devices, etc.</li>        <li id="ul0014-0006" num="0168">3. Vendor specific clouds</li>        <li id="ul0014-0007" num="0000">&#x2003;There are also clouds that receive data from specific vendor devices. For example, LG&#x2122; TV, Sony&#x2122; TV, Samsung&#x2122; TV, and other vendors have dedicated clouds that are intended to receive a variety of operational data from various types of smart appliances include smart TVs that are operating in production. There are also vendor specific clouds for smart TVs, smart fridges, toasters, and any conceivable internet-enabled device. Such clouds could also be specific to individual model numbers of the specific types of objects/devices.</li>        <li id="ul0014-0008" num="0169">4. Component clouds</li>        <li id="ul0014-0009" num="0000">&#x2003;These clouds are used for receiving manufacturing data from individual components of a product. Such components include semi-conductor components or microchips or simply a chips or circuit boards or assemblies. The components may also be contained in a consumer/finished product in which case the finished product may be sending its operational data to a device cloud discussed above while its individual component(s) would send their data to a component cloud.</li>        <li id="ul0014-0010" num="0000">&#x2003;Alternatively, the component cloud may be used for electronic design automation (EDA), also sometimes referred to as electronic computer-aided design (ECAD), of the component(s) during their design and manufacturing and before they have gone into production. Some of the current industry participants operating such component clouds include Invidia&#x2122;, Lattice&#x2122;, Siemens&#x2122;, Synopsis&#x2122;, etc.</li>        <li id="ul0014-0011" num="0000">&#x2003;Those skilled in semiconductor design will appreciate the tremendous benefits of using the cloud for EDA/ECAD. In a cloud-based EDA model, the various design, prediction, simulation, verification, testing and any other EDA artifacts are kept in the component cloud. The cloud is operated by a specialized contract manufacturer or a fab or a foundry or in some cases a large vertically integrated company. Regardless, the cloud-based EDA approach greatly optimizes the time to market, cost, quality and other metrics of EDA for a given chip, instead of the traditional approach of chip design where a company vertically owns and operates the various aspects of EDA for a given chip/product.</li>    </ul>    </li></ul></p><p id="p-0146" num="0170">The object/device clouds presented above may be multi-functional where a single cloud serves as more than one of the above presented clouds. They clouds may also be tiered or hierarchical such that data in component clouds is combined or integrated with the data in the next higher tier and so on.</p><p id="p-0147" num="0171">Regardless of the type and structure of clouds, including the ones described above, a variety of objects, which includes finished or end-products or simply products and/or their components, send their design, manufacturing, testing, performance and/or operational data to a cloud. The purposes of doing so may be various including their testing/verification, monitoring, improvement and optimization, analysis, etc. As noted, the objects may send their data to the cloud either before their operation in production i.e. during their design and development, as well as during post-deployment operation, or both.</p><p id="p-0148" num="0172">In the present variations, the rolling baseline engine analyzes this data sent by the objects to the cloud or the data residing in the cloud, and detects any anomalies with the associated contexts per prior teachings. A deviation or anomaly thus detected serves as an indicator of a compromise of/in the associated objects. In other words, if the data in the cloud observed by our baseline engine is far enough away from the centroid of the &#x201c;normal&#x201d; population of the data packets, then this acts as an indicator of compromise of the objects. The rolling baseline engine may also itself operate inside the same cloud, a different cloud, or on-premise while analyzing the object data in the cloud.</p><p id="p-0149" num="0173">The anomaly indicating a compromise may manifest itself in a variety of ways including an overload/overuse/overage or underload/underuse/shortage of any number of metrics or resources of the objects. These include CPU usage, memory usage, disk storage usage, network bandwidth usage, thermal output, to name a few. The manifestation may also be in the form of misreporting of operational data, such as underreporting or overreporting of data. It may also be in the interpretability of data, e.g. if the data report is obfuscated, unintentionally encrypted, or is incomprehensible or gibberish.</p><p id="p-0150" num="0174">Early knowledge of an indicator of a compromise allows the developer or a concerned party to patch or address the vulnerability that caused the compromise/infiltration. If the object in question is a component, then this prevents a costly production of products with inherent flaws or vulnerabilities in them, only to cause bigger and more consequential damage in the future. If the object is a product, then this facilitates their firmware/software updates or patches or recalls to ensure their secure operation and satisfied customers. The anomaly/anomalies detected by instant baseline engine may also denote technical flaw(s) in the design/manufacturing of the objects and not just necessarily exploited vulnerabilities.</p><p id="p-0151" num="0175"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows an embodiment <b>450</b> with an exemplary device cloud <b>452</b> feeding data to our rolling baseline engine <b>110</b>, with baseline <b>120</b>, hypercube <b>180</b> and centroid <b>182</b> of normal population of operational data per prior teachings. In the embodiment shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, rolling baseline engine <b>110</b> is obtaining data from cloud <b>452</b> for analysis, however per above, baseline engine <b>110</b> may itself be in cloud <b>452</b>.</p><p id="p-0152" num="0176">Regardless, baseline engine <b>110</b> analyzes data packets sent to or residing in cloud <b>452</b> that originated from various smart TVs <b>400</b>H. Based on this analysis, it detects indicators of compromise in one or more smart TVs <b>400</b>H. Per above, cloud <b>452</b> may be specific to a given TV manufacturer, and even a given TV model. By way of example, operational data of a given batch of smart TVs <b>400</b>H of a given model may indicate that 10% of such TVs are getting their current data/time settings reset or corrupted. This may indicate a compromise through an exploit of a vulnerability of that model of TVs. Baseline engine <b>110</b> can detect such an indicator of compromise so adequate patches/updates could be made.</p><p id="p-0153" num="0177"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows an embodiment <b>500</b> with an exemplary component cloud <b>454</b> containing design and manufacturing data received from component chips <b>400</b>E. By way of example, if component <b>400</b>E is a memory chip or a microcontroller or a central processing unit or processor (CPU) or a graphics processing unit (GPU) or the like, with specific model number, then data that may be EAD data is sent by chips <b>400</b>E to component cloud <b>454</b>. Cloud <b>454</b> may be dedicated for the EDA of chip <b>400</b>E or it may be shared for the EDA of a number of different types/models of semiconductor chips.</p><p id="p-0154" num="0178">Our baseline engine <b>110</b> analyzes this data and detects if a malware or a hacker has compromised components <b>400</b>E that may be causing their test data to deviate from the normal. Similarly, if verification data generated by an EDA job, such as functional verification data, is unintelligible or incomprehensible or gibberish or misreported, then this may be an indicator of compromise of chips <b>400</b>E. Similarly, if thermal data from chips <b>400</b>E indicates an overage of thermal output, this may be because a malware is overloading the chip, or is otherwise causing a design defect in the heat flow of chips <b>400</b>E.</p><p id="p-0155" num="0179">Thusly, an immediate response can be launched that could avoid expensive chip/circuit failures down the line. Similarly, EDA simulation data, such as logic simulation data may be encrypted by an attack, resulting in large enough distance from centroid <b>182</b> of normal population of data packets per prior teachings. This may be an indicator of compromise, such as a ransomware attack. In a similar manner, the data may be obfuscated in some other way indicating a compromise.</p><p id="p-0156" num="0180">The proactive knowledge of the compromise allows a developer or a concerned party to patch the flaw or vulnerability in the objects that allowed the exploit to occur. This limits the damage and avoids further and potentially more catastrophic compromises to occur in the future.</p><p id="p-0157" num="0181">Data in component clouds is used for improvements and optimization of the chip design. The present technology is thus effectively used in component clouds with its rolling baseline engine for detecting patterns of failures and/or compromise of/in the components/chip. In another exemplary scenario, if rolling baseline engine <b>110</b> detects a security flaw in 20% of chips <b>400</b>E that are sending their data to cloud <b>454</b>, then this may indicate a pattern of failure or exploitation of the chips. A timely knowledge of such a failure or flaw is useful for efficiently patching the flaw before additional batches of chips <b>400</b>E are produced and before a &#x201c;mass compromise&#x201d; occurs. This is especially the case once these components are fitted into potentially millions or more of consumer products that are then sold.</p><p id="p-0158" num="0182">In yet another interesting application, if a batch of cell phones from a deployment, such as a military deployment is detected to be sending unauthorized pings to a network by engine <b>110</b>, then this is an indicator of compromise of those cell phones. In this application, the rolling baseline engine analyzes the data on a network, which may be a secure cloud, and determine such pings as an overuse of network bandwidth and an anomaly or an indicator of compromise. Early detection of such a compromise by baseline engine <b>110</b> of the present design can prevent serious downstream consequences.</p><p id="p-0159" num="0183">In still another variation, the operational data received from various objects in the various clouds taught above, is used as training data for modeling the operational behavior of the respective objects using artificial intelligence (AI) techniques. Such modeling is then used to determine the normal patterns of behavior i.e. for generating an optimal operational model of the objects. This optimal operational model signifies or is correlated to centroid <b>182</b> of hypercube of <b>180</b> of baseline engine <b>110</b> shown in <figref idref="DRAWINGS">FIGS. <b>10</b>-<b>12</b></figref>, and thus facilitates establishing rolling baseline <b>120</b> for the objects.</p><p id="p-0160" num="0184">Medical or Healthcare Vertical:</p><p id="p-0161" num="0185">In a set of highly preferred embodiments directed to the medical or healthcare vertical(s), the rolling baseline of the above embodiments is used to detect indicators of compromise on medical/healthcare objects used by patients or users. There are a variety of the use-cases in the medical or healthcare industries that may benefit from the present embodiments. Let us now understand these embodiments in greater detail below.</p><p id="p-0162" num="0186">In today's interconnected and internet-enabled world, there is an ever-increasing number of wearable or implantable devices or products used by people and even animals for healthcare benefits. While pace-makers have been around for some time, it is commonplace now that they are internet-enabled and can transmit data outside of the patient's/user's body. Similarly, a host of other medical devices used by patients or even healthy users/people today are connected to the internet via one-way/unidirectional or two-way/bidirectional communication modes. As these products can communicate with the outside world, they are open to cyberattacks that can exploit any vulnerabilities therein.</p><p id="p-0163" num="0187">For example, in 2016 Johnson and Johnson&#x2122; warned its customers/patients using its insulin pump about a vulnerability that can exploited by a hacker(s) to inject a lethal dose of insulin into the patients. Similarly, Merlin&#x2122; remote monitoring system used in implantable pacemakers and defibrillators were purported to have a cybersecurity vulnerability that could allow a hacker(s) to drain the battery of the one or both of the devices or to manipulate the beat rate of the pacemaker. With the expanding variety of medical products/devices uses by our society, cybersecurity vulnerabilities in them or their components, and the potential exploitation of these vulnerabilities resulting in harm to or loss of human life is expected to continue and grow.</p><p id="p-0164" num="0188">The present technology can benefit the society by detecting and reporting these vulnerabilities or indicators of compromise to the concerned parties in a proactive manner, with the potential to protect/save lives. These medical/healthcare devices/products used by patients/users send their data to a cloud for a variety of purposes, as in the prior embodiments. Also, as in the prior embodiments, the cloud could be of one or more of a variety of types, and the products/devices or the components of such products/devices send the data to the cloud. For instance, the components of the products may send their data to a component cloud. The products and/or their components may send their data during manufacturing or while in operation post-production. This data may be sent for improving the manufacturing of the products or their components, or for monitoring their performance as in the prior embodiments.</p><p id="p-0165" num="0189"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows an exemplarily embodiment <b>550</b> from amongst the present embodiments for a better understanding of the above explanation. More specifically, embodiment <b>550</b> is a variation of <figref idref="DRAWINGS">FIG. <b>11</b></figref> and shows one or more pacemakers <b>400</b>J sending their data to a cloud <b>502</b>. More specifically still, and while referring briefly to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, reference numeral <b>400</b>J in <figref idref="DRAWINGS">FIG. <b>13</b></figref> represents a type of object from the list of objects <b>400</b> shown and explained earlier. <figref idref="DRAWINGS">FIG. <b>13</b></figref> further shows rolling baseline engine <b>110</b> with its rolling baseline <b>120</b> and hypercube <b>180</b> with centroid <b>182</b> of prior teachings.</p><p id="p-0166" num="0190">The present medical/healthcare embodiments of the instant technology apply to any conceivable medical/healthcare objects or devices including wearable or implantable or even industrial objects/devices. Exemplary objects that benefit from the present technology include but are not limited to pacemakers, insulin pumps, electrocardiogram (ECG/EKG) monitors, health alert bracelets, fitness trackers, smart health watches, blood pressure monitors, any type of biosensors, body temperature sensors, heartbeat monitors, kidney and/or dialysis monitors and sleep monitors. Furthermore, the users/patients may be of such object/devices may be humans or animals.</p><p id="p-0167" num="0191">A large number of such healthcare and/or medical objects/devices or components are designed from a &#x201c;common framework&#x201d; of technology for expediency's sake. As a result, it is easy for a vulnerability or flaw to quickly propagate to a large number of seemingly unrelated healthcare objects. The present design can benefit this situation by detecting a pattern of failure amongst the objects by analyzing their data residing in the cloud to which it is sent by these healthcare objects and/or their components. In the preferred variation, when an indicator of compromise is detected, the present technology informs the concerned party/parties which may be the manufacturer of the objects and/or healthcare or service provider(s) of the respective users/patients.</p><p id="p-0168" num="0192">The concerned party/parties may then attempt to isolate the affected device/product or component by sending the appropriate commands to its communication interface. It may do that so the exploit of the vulnerability may not flood the device and harm or kill the patient. Instead of or in addition, the concerned party may also notify the user/patient and warn the patient to come in for a software/hardware upgrade containing a patch for the indicator of compromise. A software upgrade is typically performed by the physician by waving a wand in proximity to healthcare object worn by or implanted in the user/patient. The wand thusly installs the new upgrade/patch onto the object via an appropriate mode of communication, such as near field communication (NFC).</p><p id="p-0169" num="0193">In a highly preferred variation of the present healthcare/medical embodiments, the present baseline engine, such as baseline engine <b>110</b> of <figref idref="DRAWINGS">FIG. <b>13</b></figref> correlates the medical record(s) of the users/patients to the software and/or hardware versions operating on/in the healthcare objects/devices/components, such as pacemakers <b>400</b>J. In the same or related embodiment, it may then further correlate the above-obtained correlation data to the various indicators of compromise detected in the respective healthcare objects.</p><p id="p-0170" num="0194">The advantage of this correlation data is that the concerned party/parties including the manufacturer and/or healthcare/service provider can then determine if a certain version of the product is associated with a compromise for a certain type of health condition of the user/patient. This information is highly useful in then safeguarding from future exploitation of the indicators of compromise in the objects. Of course, any medical records used in obtaining the above correlation data would need to be anonymized/tokenized based on techniques known in the art, in order to be Health Insurance Portability and Accountability Act (HIPAA) compliant.</p><p id="p-0171" num="0195"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows an embodiment <b>560</b> of the above variation with medical/health alert bracelet healthcare objects or products <b>400</b>K sending their data to a cloud <b>504</b>. Also shown explicitly is a correlation logic or module <b>506</b> that is responsible for working in conjunction with baseline engine <b>110</b>. Correlation logic/module <b>506</b> is in charge of computing/identifying the correlations of medical records of the users with various versions of software/hardware operating on objects <b>400</b>K and/or various types of compromises affecting objects/devices <b>400</b>K as explained above.</p><p id="p-0172" num="0196">All the relevant teachings of the prior embodiments apply to the present healthcare/medical embodiments also.</p><p id="p-0173" num="0197">In view of the above teaching, a person skilled in the art will recognize that the apparatus and method of invention can be embodied in many different ways in addition to those described without departing from the principles of the invention. Therefore, the scope of the invention should be judged in view of the appended claims and their legal equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A system comprising computer-readable instructions stored in non-transitory storage medium and at least one microprocessor coupled to said non-transitory storage medium for executing said computer-readable instructions, said at least one microprocessor configured to:<claim-text>(a) analyze data from one or more healthcare objects, wherein said data resides in a cloud;</claim-text><claim-text>(b) establish a rolling baseline of said data by assigning each packet of said data to a cluster of packets amongst a plurality of clusters of packets of said data;</claim-text><claim-text>(c) score, based on its distance from a centroid of said rolling baseline, each packet of said data; and</claim-text><claim-text>(d) identify based on said distance an indicator of compromise in said one or more healthcare objects;</claim-text><claim-text>wherein said one or more healthcare objects comprise one or both of a product and a component.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said indicator of compromise is manifested as said data being one or both of unintelligible and obfuscated.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said indicator of compromise is manifested as said data being unintentionally encrypted.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said indicator of compromise is manifested as said data being misreported.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The system of <claim-ref idref="CLM-00004">claim 4</claim-ref> wherein said data being misreported is due to one or both of:<claim-text>(e) at least one unauthorized remote command executed on said one or more healthcare objects; and</claim-text><claim-text>(f) at least one unauthorized message sent by said one or more healthcare objects.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said cloud is one or more of a generic automation testing cloud, a device specific cloud, a vendor specific cloud and a component cloud.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein when said one or more healthcare objects comprise a product including a pacemaker, an insulin pump, an electrocardiogram monitor, a health alert bracelet, a fitness tracker, a smart health watch, a blood pressure monitor, a biosensor, a body temperature sensor, a heartbeat monitor, a kidney monitor, a dialysis monitor and a sleep monitor.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein when said one or more healthcare objects comprise a component and said cloud is a component cloud used for electronic design automation (EDA) of said component.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said indicator of compromise signifies a pattern of failure of said component.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein a training dataset is created from said data, said training dataset used to generate an optimal operational model of said one or more healthcare objects to facilitate establishing said rolling baseline line in element (b) above.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said indictor of compromise is manifested as one or more of an overload of a CPU, an overuse of a memory, an overuse of a disk storage, an overuse of a network bandwidth and an overage of thermal output of said one or more healthcare objects.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A computer-implemented method executing computer-readable instructions by at least one processor, said computer-readable instructions stored in a non-transitory storage medium coupled to said at least one processor, and said computer-implemented method comprising the steps of:<claim-text>(a) analyzing data from one or more medical objects, said one or more medical objects comprising one or both of a component and a product;</claim-text><claim-text>(b) providing said data to be residing in a cloud;</claim-text><claim-text>(c) establishing a rolling baseline of said data by assigning each packet of said data to a cluster of packets amongst a plurality of clusters of packets of said data;</claim-text><claim-text>(d) scoring, based on its distance from a centroid of said rolling baseline, each packet of said data; and</claim-text><claim-text>(e) identifying based on said distance an indicator of compromise in said one or more medical objects.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The computer-implemented method of <claim-ref idref="CLM-00012">claim 12</claim-ref> manifesting said indicator of compromise as said data being one or both of unintelligible and obfuscated.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The computer-implemented method of <claim-ref idref="CLM-00012">claim 12</claim-ref> manifesting said indicator of compromise as said data being encrypted.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The computer-implemented method of <claim-ref idref="CLM-00012">claim 12</claim-ref> manifesting said indicator of compromise as said data being misreported.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The computer-implemented method of <claim-ref idref="CLM-00012">claim 12</claim-ref> providing said cloud to be one of a generic automation testing cloud, a device specific cloud, a vendor specific cloud and a component cloud.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The computer-implemented method of <claim-ref idref="CLM-00012">claim 12</claim-ref> whereby said one or more medical objects are comprising a component, providing said cloud to be a component cloud that is used for electronic design automation (EDA) of said component.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The computer-implemented method of <claim-ref idref="CLM-00012">claim 12</claim-ref> utilizing said data as a training dataset for generating an optimal operational model of said one or more medical objects for facilitating of said establishing of said rolling baseline line in step (c) above.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The computer-implemented method of <claim-ref idref="CLM-00012">claim 12</claim-ref> manifesting said indicator of compromise as one of an overage and an underage of one or more of a CPU usage, a memory usage, a disk storage usage, a network bandwidth usage and a thermal output associated with said one or more medical objects.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The computer-implemented method of <claim-ref idref="CLM-00012">claim 12</claim-ref> correlating a medical record of a user of said one or more medical objects with one or more of a version of software operating on said one or more medical objects, a version of hardware operating in said one or more medical objects and a type of said indicator of compromise in said one or more medical objects.</claim-text></claim></claims></us-patent-application>
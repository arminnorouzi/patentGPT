<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230000347A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230000347</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17779851</doc-number><date>20201103</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2019-0154909</doc-number><date>20191127</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>12</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>3</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD FOR DETERMINING STRUCTURAL PROGRESSION OF EYE DISEASE AND DEVICE THEREOF</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>IUCF-HYU (INDUSTRY-UNIVERSITY COOPERATION FOUNDATION HANYANG UNIVERSITY)</orgname><address><city>Seoul</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Won June</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>IUCF-HYU (INDUSTRY-UNIVERSITY COOPERATION FOUNDATION HANYANG UNIVERSITY)</orgname><role>03</role><address><city>Seoul</city><country>KR</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/KR2020/015219</doc-number><date>20201103</date></document-id><us-371c12-date><date>20220525</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present invention relates to a method and a device for determining structural progression of an eye disease using an ocular image. According to an embodiment of the present invention, a device for determining structural progression of an eye disease includes a processor, and a memory electrically connected to the processor, wherein, when the processor is executed, the memory stores instructions for obtaining a first-n<sup>th </sup>ocular image, which is an n<sup>th </sup>first ocular image for a user (where n is a natural number), obtaining a second-n<sup>th </sup>ocular image, which is an n<sup>th </sup>second ocular image for the user, combining the first-n<sup>th </sup>ocular image and the second-n<sup>th </sup>ocular image according to a preset method to generate an n<sup>th </sup>combined image, and generating an n<sup>th </sup>eye disease image for the user by using the n<sup>th </sup>combined image and a preset prone area image.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="160.53mm" wi="135.72mm" file="US20230000347A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="106.34mm" wi="155.70mm" file="US20230000347A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="179.92mm" wi="137.75mm" file="US20230000347A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="109.14mm" wi="137.75mm" file="US20230000347A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="147.07mm" wi="86.78mm" file="US20230000347A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="136.31mm" wi="101.94mm" file="US20230000347A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="107.95mm" wi="85.94mm" file="US20230000347A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="114.72mm" wi="74.93mm" file="US20230000347A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="120.82mm" wi="114.38mm" file="US20230000347A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a National Stage of International Application No. PCT/KR2020/015219, filed on Nov. 3, 2020, the contents of which are incorporated herein by reference in their entireties.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present invention relates to a method and a device for determining structural progression of an eye disease using an ocular image.</p><heading id="h-0003" level="1">BACKGROUND ART</heading><p id="p-0004" num="0003">Glaucoma is an optic nerve disorder due to an increase in intraocular pressure, resulting in visual field loss and visual loss, and is a very dangerous and frequent disease from among ophthalmic diseases. Glaucoma, along with cataract and macular degeneration, is one of the three major blindness-causing ophthalmic diseases. Because of the chronic and irreversible nature of glaucoma, early detection of glaucoma can be delayed through treatment or surgery, and the therapeutic effect is good.</p><p id="p-0005" num="0004">Currently, there are various methods of diagnosing glaucoma, such as scanning laser polarimetry (SLP) or optical coherence tomography (OCT), visual field test, and comparison of a depression ratio of optic disc (OD).</p><p id="p-0006" num="0005">In particular, in the case of optical coherence tomography (OCT), the spatial relationship between the optic disc and the macula related to glaucoma progression is difficult to grasp because the optic disc and the macula are photographed separately and the results are analyzed separately.</p><heading id="h-0004" level="1">DESCRIPTION OF EMBODIMENTS</heading><heading id="h-0005" level="1">Technical Problem</heading><p id="p-0007" num="0006">The present invention provides a method and a device capable of determining the structural progression of an eye disease by combining ocular images of various areas.</p><heading id="h-0006" level="1">Solution to Problem</heading><p id="p-0008" num="0007">According to an aspect of the disclosure, a device for determining structural progression of an eye disease comprises a processor and a memory electrically connected to the processor, when the processor is executed, the memory stores instructions for obtaining a first-n<sup>th </sup>ocular image, which is an n<sup>th </sup>first ocular image for a user (where n is a natural number), obtaining a second-n<sup>th </sup>ocular image, which is an n<sup>th </sup>second ocular image for the user, combining the first-n<sup>th </sup>ocular image and the second-n<sup>th </sup>ocular image according to a preset method to generate an n<sup>th </sup>combined image, and generating an n<sup>th </sup>eye disease image for the user by using the n<sup>th </sup>combined image and a preset prone area image.</p><p id="p-0009" num="0008">According to an exemplary embodiment, the memory stores instructions for generating a first-n<sup>th </sup>comparison image by using an optic nerve thickness of the first-n<sup>th </sup>ocular image and a pre-stored first-(n-1)<sup>th </sup>ocular image, generating a second-n<sup>th </sup>comparison image by using an optic nerve thickness of the second-n<sup>th </sup>ocular image and a pre-stored second-(n-1)<sup>th </sup>ocular image, and generating the n<sup>th </sup>combined image by combining the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image according to a preset method.</p><p id="p-0010" num="0009">According to an exemplary embodiment, the memory stores instructions for generating the n<sup>th </sup>combined image by matching a blood vessel portion of the first-n<sup>th </sup>comparison image and a blood vessel portion of the second-n<sup>th </sup>comparison image.</p><p id="p-0011" num="0010">According to an exemplary embodiment, the memory stores instructions for generating an n<sup>th </sup>eye disease progression image for the user using pre-stored first to n-1 combined images and the n<sup>th </sup>combined image, and generating the n<sup>th </sup>eye disease image by combining the n<sup>th </sup>eye disease progression image and the prone area image.</p><p id="p-0012" num="0011">According to an exemplary embodiment, the memory stores instructions for, when an eye disease progression image of another person corresponding to the n<sup>th </sup>eye disease progression image is searched, analyzing the degree of eye disease progression of the user using the eye disease progression image of another person.</p><p id="p-0013" num="0012">According to an exemplary embodiment, the memory stores instructions for searching for the eye disease progression image of another person considering a generation period and an optic nerve change position corresponding to the n<sup>th </sup>eye disease image, the generation period corresponds to a generation period of a first eye disease image to the n<sup>th </sup>eye disease image, the optic nerve change position corresponds to an optic nerve change position of each of the pre-stored first combined image to the n<sup>th </sup>combined image, the first eye disease image is a first image of eye disease of the user, and the first combined image is a first combined image of the user.</p><p id="p-0014" num="0013">According to an aspect of the disclosure, a method of determining structural progression of an eye disease performed in a device for determining structural progression of an eye disease comprises: obtaining a first-n<sup>th </sup>ocular image, which is an n<sup>th </sup>first ocular image for a user (where n is a natural number), obtaining a second-n<sup>th </sup>ocular image, which is an n<sup>th </sup>second ocular image for the user, generating an n<sup>th </sup>combined image by combining the first-n<sup>th </sup>ocular image and the second-n<sup>th </sup>ocular image according to a preset method, and generating an n<sup>th </sup>eye disease image for the user by using the n<sup>th </sup>combined image and a preset prone area image.</p><p id="p-0015" num="0014">According to an exemplary embodiment, the generating of the n<sup>th </sup>combined image comprises generating a first-n<sup>th </sup>comparison image by using an optic nerve thickness of the first-n<sup>th </sup>ocular image and a pre-stored first-(n-1)<sup>th </sup>ocular image, generating a second-n<sup>th </sup>comparison image by using an optic nerve thickness of the second-n<sup>th </sup>ocular image and a pre-stored second-(n-1)<sup>th </sup>ocular image, and generating the n<sup>th </sup>combined image by combining the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image according to a preset method.</p><p id="p-0016" num="0015">According to an exemplary embodiment, the generating of the n<sup>th </sup>combined image comprises generating the n<sup>th </sup>combined image by matching a blood vessel portion of the first-n<sup>th </sup>comparison image and a blood vessel portion of the second-n<sup>th </sup>comparison image.</p><p id="p-0017" num="0016">According to an exemplary embodiment, the generating of the n<sup>th </sup>eye disease image comprises generating an n<sup>th </sup>eye disease progression image for the user using pre-stored first to n-1 combined images and the n<sup>th </sup>combined image, and generating the n<sup>th </sup>eye disease image by combining the n<sup>th </sup>eye disease progression image and the prone area image.</p><p id="p-0018" num="0017">According to an exemplary embodiment, the method further comprises: when an eye disease progression image of another person corresponding to the n<sup>th </sup>eye disease progression image is searched, analyzing the degree of eye disease progression of the user using the eye disease progression image of another person.</p><p id="p-0019" num="0018">According to an exemplary embodiment, the analyzing of the degree of eye disease progression of the user comprises searching for the eye disease progression image of another person considering a generation period and an optic nerve change position corresponding to the n<sup>th </sup>eye disease progression image, the generation period corresponds to a generation period of a first eye disease progression image to the n<sup>th </sup>eye disease progression image, the optic nerve change position corresponds to an optic nerve change position of each of a first combined image to the n<sup>th </sup>combined image, the first eye disease progression image is a first eye disease progression image of the user, and the first combined image is a first combined image of the user.</p><heading id="h-0007" level="1">Advantageous Effects of Disclosure</heading><p id="p-0020" num="0019">According to the present invention, since ocular images of various areas, such as the macular area and the optic nerve area, can be combined and provided as one ocular image, it is possible for an administrator to grasp the structural progression of an eye disease at a glance.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0008" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0021" num="0020">A brief description of each drawing is provided to fully understand drawings recited in the detailed description of the present invention.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of a device for determining the structural progression of an eye disease according to an embodiment of the present invention.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart illustrating a method of determining the structural progression of an eye disease according to an embodiment of the present invention.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating a method of analyzing user's eye disease progression information according to an embodiment of the present invention.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a view illustrating a first-n<sup>th </sup>comparison image and a second-n<sup>th </sup>comparison image according to an embodiment of the present invention.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a view illustrating an n<sup>th </sup>eye disease progression image according to an embodiment of the present invention.</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a view of a prone area image according to an embodiment of the present invention.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a view of an n<sup>th </sup>eye disease image according to an embodiment of the present invention.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a view illustrating a case in which combined images are schematically transformed according to an embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0009" level="1">BEST MODE</heading><p id="p-0030" num="0029">Exemplary embodiments according to the inventive concept of the present invention are provided to more completely explain the inventive concept of the present invention to one of ordinary skill in the art, and the following embodiments may be modified in various other forms and the scope of the inventive concept of the present invention is not limited to the following embodiments. Rather, these embodiments are provided so that the present invention will be thorough and complete, and will fully convey the inventive concept of the present invention to one of ordinary skill in the art.</p><p id="p-0031" num="0030">It will be understood that, although the terms first, second, etc. may be used herein to describe various members, regions, layers, sections, and/or components, these members, regions, layers, sections, and/or components should not be limited by these terms. These terms do not denote any order, quantity, or importance, but rather are only used to distinguish one component, region, layer, and/or section from another component, region, layer, and/or section. Thus, a first member, component, region, layer, or section discussed below could be termed a second member, component, region, layer, or section without departing from the teachings of the inventive concept of the present invention. For example, as long as within the scope of the present invention, a first component may be named as a second component, and a second component may be named as a first component.</p><p id="p-0032" num="0031">Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which the inventive concept of the present invention belongs. It will be further understood that terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein.</p><p id="p-0033" num="0032">As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items.</p><p id="p-0034" num="0033">Hereinafter, embodiments of the inventive concept will be described in detail with reference to the accompanying drawings.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram of a device for determining the structural progression of an eye disease according to an embodiment of the present invention.</p><p id="p-0036" num="0035">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a device <b>100</b> for determining the structural progression of an eye disease according to an embodiment of the present invention may be a device capable of generating a fundus image by photographing the user's eye and analyzing the fundus image. Alternatively, the device <b>100</b> for determining the structural progression of an eye disease may be a device capable of receiving and analyzing a fundus image generated by another device. The device <b>100</b> for determining the structural progression of an eye disease may include a processor <b>110</b>, a communication modem <b>120</b>, a memory <b>130</b>, an input device <b>140</b>, and/or a camera <b>150</b>.</p><p id="p-0037" num="0036">The device <b>100</b> for determining the structural progression of an eye disease may analyze the degree of progression of an eye disease (e.g., glaucoma) by analyzing a plurality of fundus images (fundus images of the same user) generated with a time difference. That is, instructions and/or information for analyzing a user's fundus image may be stored in the memory <b>130</b>, and the processor <b>110</b> may access the memory <b>130</b> and execute the corresponding instructions and/or information to analyze user's eye disease progression information. Hereinafter, an analysis operation of the device <b>100</b> for determining the structural progression of an eye disease will be described in detail with reference to <figref idref="DRAWINGS">FIGS. <b>2</b> to <b>8</b></figref>.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flowchart illustrating a method of determining the structural progression of an eye disease according to an embodiment of the present invention.</p><p id="p-0039" num="0038">Before describing the method of determining the structural progression of an eye disease according to an embodiment of the present invention with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, terms to be used below are defined.</p><p id="p-0040" num="0039">First, an ocular image may be an image of the user's eyeball generated through optical coherence tomography (OCT).</p><p id="p-0041" num="0040">In addition, a first ocular image may be an ocular image obtained by photographing a user's optic disc. In addition, a first-n<sup>th </sup>ocular image may be an n<sup>th </sup>first ocular image from among a plurality of first ocular images photographed with a time difference (where n is a natural number).</p><p id="p-0042" num="0041">In addition, a second ocular image may be an ocular image in which the user's macula (yellow spot) is photographed. In addition, a second-n<sup>th </sup>ocular image may be an n<sup>th </sup>second ocular image from among a plurality of second ocular images photographed with a time difference.</p><p id="p-0043" num="0042">In addition, a first comparison image may be an image in which different portions are emphasized by comparing a plurality of first ocular images generated with a time difference (e.g., expressed by different colors of different portions). In addition, a first-n<sup>th </sup>comparison image may be an image generated by comparing the first-n<sup>th </sup>ocular image with a first-(n-1)<sup>th </sup>ocular image, and emphasizing different portions. The first-(n-1)<sup>th </sup>ocular image may be a first ocular image generated immediately before the first-n<sup>th </sup>ocular image.</p><p id="p-0044" num="0043">In addition, a second comparison image may be an image in which different portions are emphasized by comparing a plurality of second ocular images generated with a time difference (e.g., expressed by different colors of different portions). In addition, a second-n<sup>th </sup>comparison image may be an image generated by comparing the second-n<sup>th </sup>ocular image with a second-(n-1)<sup>th </sup>ocular image, and emphasizing different portions. The second-(n-1)<sup>th </sup>ocular image may be a second ocular image generated immediately before the second-n<sup>th </sup>ocular image.</p><p id="p-0045" num="0044">In addition, an n<sup>th </sup>combined image may be an image generated by combining the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image according to a preset method. A detailed description of the method of generating the n<sup>th </sup>combined image will be described later.</p><p id="p-0046" num="0045">In addition, an n<sup>th </sup>eye disease progression image may be an image generated by combining first to n<sup>th </sup>combined images into one image according to a preset method. A detailed description of a method of generating the n<sup>th </sup>eye disease progression image will be described later.</p><p id="p-0047" num="0046">In addition, an n<sup>th </sup>eye disease image may be an image generated by combining a first eye disease progression image and a preset prone area image into one image according to a preset method. A detailed description of a method of generating the n<sup>th </sup>eye disease image will be described later.</p><p id="p-0048" num="0047">In operation S<b>210</b>, the processor <b>110</b> may generate the first-n<sup>th </sup>comparison image by comparing the first-n<sup>th </sup>ocular image and the first-(n-1)<sup>th </sup>ocular image. The first-n<sup>th </sup>ocular image may be an image photographed by the camera <b>150</b>. In this case, the camera <b>150</b> may be a camera capable of optical coherence tomography (OCT). Alternatively, the first-n<sup>th </sup>ocular image may be an image generated by another device capable of optical coherence tomography (OCT) and received through the communication modem <b>120</b>. In this case, the communication modem <b>120</b> may be a modem that can connect to the Internet, a mobile network, etc., or a USB communication port. In addition, the first-(n-1)<sup>th </sup>ocular image may be previously stored in the memory <b>130</b>.</p><p id="p-0049" num="0048">In addition, the processor <b>110</b> may compare the first-n<sup>th </sup>ocular image and the first-(n-1)<sup>th </sup>ocular image, and may generate a first-n<sup>th </sup>comparison image by changing colors of different portions as a result of the comparison (i.e., portions of the first ocular images with different thicknesses of an optic nerve).</p><p id="p-0050" num="0049">In operation S<b>220</b>, the processor <b>110</b> may generate a second-n<sup>th </sup>comparison image by comparing the second-n<sup>th </sup>ocular image and the second-(n-1)<sup>th </sup>ocular image. The second-n<sup>th </sup>ocular image may be an image photographed by the camera <b>150</b>. In this case, the camera <b>150</b> may be a camera capable of optical coherence tomography (OCT). Alternatively, the second-n<sup>th </sup>ocular image may be an image generated by another device capable of OCT and received through the communication modem <b>120</b>. In addition, the processor <b>110</b> may compare the second-n<sup>th </sup>ocular image and the second-(n-1)<sup>th </sup>ocular image, and may generate a second-n<sup>th </sup>comparison image by changing colors of different portions as a result of the comparison (i.e., portions of the second ocular images with different thicknesses of the optic nerve).</p><p id="p-0051" num="0050">In operation S<b>230</b>, the processor <b>110</b> may generate an n<sup>th </sup>combined image by combining the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image according to a preset method. The processor <b>110</b> may detect a blood vessel portion in the first-n<sup>th </sup>comparison image. In addition, the processor <b>110</b> may detect a blood vessel portion in the second-n<sup>th </sup>comparison image. Accordingly, the processor <b>110</b> may generate the n<sup>th </sup>combined image by matching blood vessel portions of the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image. Since there are arteries, veins, and capillaries in the eye, the processor <b>110</b> may generate an n<sup>th </sup>combined image by separating them from each other and matching the corresponding blood vessel portions. A specific method of the processor <b>110</b> to generate the n<sup>th </sup>combined image by matching the blood vessel portions of the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image is similar to a known technique, and thus a detailed description thereof will be omitted.</p><p id="p-0052" num="0051">In operation S<b>240</b>, the processor <b>110</b> may generate an n<sup>th </sup>eye disease progression image by combining the first to n<sup>th </sup>combined images according to a preset method. The n<sup>th </sup>eye disease progression image will be described later with reference to <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref>.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a view illustrating the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image according to an embodiment of the present invention, and <figref idref="DRAWINGS">FIG. <b>5</b></figref> is a view illustrating an n<sup>th </sup>eye disease progression image according to an embodiment of the present invention.</p><p id="p-0054" num="0053">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a first image <b>410</b>, a second image <b>420</b>, and a general fundus image <b>430</b> are illustrated.</p><p id="p-0055" num="0054">The first image <b>410</b> is an image in which the first-<b>1</b> comparison image to the first-n<sup>th </sup>comparison image are combined, and may be an image in which a change in the thickness of an optic nerve near a user's optic disc according to the passage of time is expressed in color. The first image <b>410</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> is an image in which two first comparison images are combined, wherein an area darker than the background (hereinafter &#x2018;dark area&#x2019;) may be an optic nerve damage area generated in the first-<b>1</b> comparison image, and an area darker than the dark area (hereinafter &#x2018;darkest area&#x2019;) may be an optic nerve damage area newly generated in the first-<b>2</b> comparison images. Accordingly, an administrator may recognize an optic nerve damage sequence of the user's optic disc through the first image <b>410</b> at a glance.</p><p id="p-0056" num="0055">The second image <b>420</b> is an image in which the second-<b>1</b> comparison image to the second-n<sup>th </sup>comparison image are combined, and may be an image in which a change in the thickness of the optic nerve near the user's macula according to the passage of time is expressed in color. The second image <b>420</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> is an image in which two first comparison images are combined, wherein a dark area may be an optic nerve damage area generated in the second-<b>1</b> comparison image, and a darkest area may be an optic nerve damage area newly generated in the second-<b>2</b> comparison images. Accordingly, an administrator may recognize an optic nerve damage sequence of the user's macula through the second image <b>420</b> at a glance.</p><p id="p-0057" num="0056">The general fundus image <b>430</b> may be a fundus image of a normal person without an eye disease (e.g., glaucoma). Alternatively, the general fundus image <b>430</b> is a fundus image for the user, and may be a fundus image generated before the occurrence of an eye disease.</p><p id="p-0058" num="0057">Accordingly, the processor <b>110</b> may generate an n<sup>th </sup>eye disease progression image by combining the first image <b>410</b>, the second image <b>420</b>, and the general fundus image <b>430</b>.</p><p id="p-0059" num="0058">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, an n<sup>th </sup>eye disease progression image <b>500</b> generated by the processor <b>110</b> by combining the first image <b>410</b>, the second image <b>420</b>, and the general fundus image <b>430</b> is illustrated. The processor <b>110</b> may detect an optic disc portion (indicated by a circle in <figref idref="DRAWINGS">FIG. <b>4</b></figref>) and a blood vessel portion of the first image <b>410</b>. In addition, the processor <b>110</b> may detect a blood vessel portion from the second image <b>420</b>. In addition, the processor <b>110</b> may detect an optic disc portion and a blood vessel portion in the general fundus image <b>430</b>. Accordingly, as illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the processor <b>110</b> may generate the n<sup>th </sup>eye disease progression image <b>500</b> by matching the optic disc portion and the blood vessel portion.</p><p id="p-0060" num="0059">Accordingly, through the n<sup>th </sup>eye disease progression image <b>500</b>, the administrator may recognize at a glance the transformation of an optic nerve damage portion according to the progression of the user's eye disease (glaucoma) and the structural relationship between the optic nerve damage at the optic disc and the optic nerve damage at the macula.</p><p id="p-0061" num="0060">Referring back to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in operation S<b>250</b>, the processor <b>110</b> may generate the n<sup>th </sup>eye disease image by combining the n<sup>th </sup>eye disease progression image <b>500</b> and the prone area image previously stored in the memory <b>130</b>. The n<sup>th </sup>eye disease image will be described later with reference to <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref>.</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a view of a prone area image according to an embodiment of the present invention, and <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a view of an n<sup>th </sup>eye disease image according to an embodiment of the present invention.</p><p id="p-0063" num="0062">A prone area image <b>600</b> illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is an image previously stored in the memory <b>130</b>, and may be an image of an area in which optic nerve damage frequently occurs according to the occurrence of, for example, an eye disease. In other words, the prone area image <b>600</b> may include a first area <b>610</b> corresponding to the optic disc, a second area <b>620</b> in which damage to the optic nerve is frequently observed in the optic disc, and a third area <b>630</b> in which damage to the optic nerve is frequently observed in the macular area.</p><p id="p-0064" num="0063">Accordingly, as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the processor <b>110</b> may generate an n<sup>th </sup>eye disease image <b>700</b> by combining the n<sup>th </sup>eye disease progression image <b>500</b> and the frequent area image <b>600</b>. For example, the processor <b>110</b> may generate the n<sup>th </sup>eye disease image <b>700</b> by matching the first area <b>610</b> of the prone area image <b>600</b> with the optic disc of the n<sup>th </sup>eye disease progression image, and matching a macular center point <b>640</b> of the second area <b>620</b> of the prone area image <b>600</b> with the macular center (a circular area of the second image <b>420</b>) of the n<sup>th </sup>eye disease progression image.</p><p id="p-0065" num="0064">Accordingly, the administrator may recognize at a glance whether the user's eye disease (glaucoma) progression is general progression corresponding to a prone area through the n<sup>th </sup>eye disease image <b>700</b>.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flowchart illustrating a method of analyzing user's eye disease progression information according to an embodiment of the present invention.</p><p id="p-0067" num="0066">In operation S<b>310</b>, the processor <b>110</b> may search for an eye disease progression image of another person similar to the n<sup>th </sup>eye disease progression image <b>500</b>.</p><p id="p-0068" num="0067">For example, all of eye disease progression images corresponding to a plurality of users may be stored in the memory <b>130</b>. In this case, the processor <b>110</b> may search for an eye disease progression image of another person corresponding to the n<sup>th </sup>eye disease progression image <b>500</b> considering a generation period and an optic nerve change position corresponding to the n<sup>th </sup>eye disease progression image <b>500</b>.</p><p id="p-0069" num="0068">The generation period may correspond to a time from when a first eye disease progression image is generated to a time when the n<sup>th </sup>eye disease progression image <b>500</b> is generated.</p><p id="p-0070" num="0069">In addition, the optic nerve change position may correspond to optic nerve change positions displayed in a first combined image to the n<sup>th </sup>combined image, and an optic nerve change position displayed in a second eye disease progression image to an optic nerve change position displayed in the n<sup>th </sup>eye disease progression image <b>500</b>.</p><p id="p-0071" num="0070">Accordingly, the processor <b>110</b> may detect a first time at which the first eye disease progression image is generated and a first optic nerve change position corresponding to the optic nerve change position, may detect a second time at which the second eye disease progression image is generated and a second optic nerve change position corresponding to the optic nerve change position, and may detect an n<sup>th </sup>time at which the n<sup>th </sup>eye disease progression image is generated and an n<sup>th </sup>optic nerve change position corresponding to the optic nerve change position.</p><p id="p-0072" num="0071">In addition, the processor <b>110</b> may search the memory <b>130</b> for an eye disease progression image of another person in which the first time, the first optic nerve change position, the second time, the second optic nerve change position, the n<sup>th </sup>time, and the n<sup>th </sup>optic nerve change position all match, and may read the eye disease progression image of another person.</p><p id="p-0073" num="0072">For another example, eye disease progression images corresponding to a plurality of users are all stored in an external server (not shown), and after the external server (not shown) is connected to a communication modem <b>120</b> to receive the n<sup>th </sup>eye disease progression image <b>500</b>, a corresponding eye disease progression image of another person may be read. The external server (not shown) may transmit the read eye disease progression image of another person to the communication modem <b>120</b>, and the communication modem <b>120</b> may output the eye disease progression image of another person to the processor <b>110</b>.</p><p id="p-0074" num="0073">In operation S<b>320</b>, the processor <b>110</b> may analyze the degree of the user's eye disease progression by using the eye disease progression image of another person. The eye disease progression image of another person is for a case in which the degree of eye disease progression of another person is more severe than the degree of the user's eye disease progression, and may be an eye disease progression image corresponding to a case of already blindness. Accordingly, the processor <b>110</b> may be able to recognize which portion of the optic nerve is highly likely to be damaged in the future by comparing the eye disease progression image of another person with the n<sup>th </sup>eye disease progression image <b>500</b> of the user. Through this, the processor <b>110</b> may analyze the percentage of the user's eye disease progression to blindness, and the like.</p><p id="p-0075" num="0074"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a view illustrating a case in which combined images are schematically transformed according to an embodiment of the present invention.</p><p id="p-0076" num="0075">Drawings illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> are schematically converted images of a first combined image (<figref idref="DRAWINGS">FIG. <b>8</b>(<i>a</i>)</figref>), a second combined image (<figref idref="DRAWINGS">FIG. <b>8</b>(<i>b</i>)</figref>), and a third combined image (<figref idref="DRAWINGS">FIG. <b>8</b>(<i>c</i>)</figref>), and may each correspond to an image in which a fundus image portion is removed from each of the combined images.</p><p id="p-0077" num="0076">Accordingly, an administrator will be able to clearly recognize a change in a user's optic nerve through a schematically transformed image of each eye disease.</p><p id="p-0078" num="0077">Hereinabove, the present invention has been described with reference to the preferred embodiments. However, it will be appreciated by one of ordinary skill in the art that various modifications and changes of the present invention can be made without departing from the spirit and the scope of the inventive concept which are defined in the appended claims and their equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A device for determining structural progression of an eye disease, the device comprising:<claim-text>a processor; and</claim-text><claim-text>a memory electrically connected to the processor,</claim-text><claim-text>wherein, when the processor is executed, the memory stores instructions for obtaining a first-n<sup>th </sup>ocular image, which is an n<sup>th </sup>first ocular image for a user (where n is a natural number), obtaining a second-n<sup>th </sup>ocular image, which is an n<sup>th </sup>second ocular image for the user, combining the first-n<sup>th </sup>ocular image and the second-n<sup>th </sup>ocular image according to a preset method to generate an n<sup>th </sup>combined image, and generating an n<sup>th </sup>eye disease image for the user by using the n<sup>th </sup>combined image and a preset prone area image.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the memory stores instructions for generating a first-n<sup>th </sup>comparison image by using an optic nerve thickness of the first-n<sup>th </sup>ocular image and a pre-stored first-(n-1)<sup>th </sup>ocular image, generating a second-n<sup>th </sup>comparison image by using an optic nerve thickness of the second-n<sup>th </sup>ocular image and a pre-stored second-(n-1)<sup>th </sup>ocular image, and generating the n<sup>th </sup>combined image by combining the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image according to a preset method.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the memory stores instructions for generating the n<sup>th </sup>combined image by matching a blood vessel portion of the first-n<sup>th </sup>comparison image and a blood vessel portion of the second-n<sup>th </sup>comparison image.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the memory stores instructions for generating an n<sup>th </sup>eye disease progression image for the user using pre-stored first to n-1 combined images and the n<sup>th </sup>combined image, and generating the n<sup>th </sup>eye disease image by combining the n<sup>th </sup>eye disease progression image and the prone area image.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The device of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the memory stores instructions for, when an eye disease progression image of another person corresponding to the n<sup>th </sup>eye disease progression image is searched, analyzing the degree of eye disease progression of the user using the eye disease progression image of another person.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The device of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the memory stores instructions for searching for the eye disease progression image of another person considering a generation period and an optic nerve change position corresponding to the n<sup>th </sup>eye disease image,<claim-text>wherein the generation period corresponds to a generation period of a first eye disease image to the n<sup>th </sup>eye disease image,</claim-text><claim-text>the optic nerve change position corresponds to an optic nerve change position of each of the pre-stored first combined image to the n<sup>th </sup>combined image,</claim-text><claim-text>the first eye disease image is a first image of eye disease of the user, and</claim-text><claim-text>the first combined image is a first combined image of the user.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. A method of determining structural progression of an eye disease performed in a device for determining structural progression of an eye disease, the method comprising:<claim-text>obtaining a first-n<sup>th </sup>ocular image, which is an n<sup>th </sup>first ocular image for a user (where n is a natural number);</claim-text><claim-text>obtaining a second-n<sup>th </sup>ocular image, which is an n<sup>th </sup>second ocular image for the user;</claim-text><claim-text>generating an n<sup>th </sup>combined image by combining the first-n<sup>th </sup>ocular image and the second-n<sup>th </sup>ocular image according to a preset method; and</claim-text><claim-text>generating an n<sup>th </sup>eye disease image for the user by using the n<sup>th </sup>combined image and a preset prone area image.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the generating of the n<sup>th </sup>combined image comprises:<claim-text>generating a first-n<sup>th </sup>comparison image by using an optic nerve thickness of the first-n<sup>th </sup>ocular image and a pre-stored first-(n-1)<sup>th </sup>ocular image;</claim-text><claim-text>generating a second-n<sup>th </sup>comparison image by using an optic nerve thickness of the second-n<sup>th </sup>ocular image and a pre-stored second-(n-1)<sup>th </sup>ocular image; and</claim-text><claim-text>generating the n<sup>th </sup>combined image by combining the first-n<sup>th </sup>comparison image and the second-n<sup>th </sup>comparison image according to a preset method.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the generating of the n<sup>th </sup>combined image comprises:<claim-text>generating the n<sup>th </sup>combined image by matching a blood vessel portion of the first-n<sup>th </sup>comparison image and a blood vessel portion of the second-n<sup>th </sup>comparison image.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the generating of the n<sup>th </sup>eye disease image comprises:<claim-text>generating an n<sup>th </sup>eye disease progression image for the user using pre-stored first to n-1 combined images and the n<sup>th </sup>combined image; and</claim-text><claim-text>generating the n<sup>th </sup>eye disease image by combining the n<sup>th </sup>eye disease progression image and the prone area image.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:<claim-text>when an eye disease progression image of another person corresponding to the n<sup>th </sup>eye disease progression image is searched, analyzing the degree of eye disease progression of the user using the eye disease progression image of another person.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the analyzing of the degree of eye disease progression of the user comprises:<claim-text>searching for the eye disease progression image of another person considering a generation period and an optic nerve change position corresponding to the n<sup>th </sup>eye disease progression image,</claim-text><claim-text>wherein the generation period corresponds to a generation period of a first eye disease progression image to the n<sup>th </sup>eye disease progression image,</claim-text><claim-text>the optic nerve change position corresponds to an optic nerve change position of each of a first combined image to the n<sup>th </sup>combined image,</claim-text><claim-text>the first eye disease progression image is a first eye disease progression image of the user, and</claim-text><claim-text>the first combined image is a first combined image of the user.</claim-text></claim-text></claim></claims></us-patent-application>
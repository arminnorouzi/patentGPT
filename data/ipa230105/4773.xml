<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004774A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004774</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17578683</doc-number><date>20220119</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>202110732838.X</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">METHOD AND APPARATUS FOR GENERATING NODE REPRESENTATION, ELECTRONIC DEVICE AND READABLE STORAGE MEDIUM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</orgname><address><city>Beijing</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LI</last-name><first-name>Weibin</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>ZHU</last-name><first-name>Zhifan</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>FENG</last-name><first-name>Shikun</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>HUANG</last-name><first-name>Shiwei</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>HE</last-name><first-name>Jingzhou</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</orgname><role>03</role><address><city>Beijing</city><country>CN</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">The present disclosure provides a method and apparatus for generating a node representation, an electronic device and a readable storage medium, and relates to the field of deep learning technologies. The method for generating a node representation includes: acquiring a heterogeneous graph to be processed; performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path; obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node. With the present disclosure, accuracy of the generated node representation may be improved.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="101.52mm" wi="126.92mm" file="US20230004774A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="122.85mm" wi="128.95mm" file="US20230004774A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="103.72mm" wi="120.82mm" file="US20230004774A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="125.56mm" wi="120.48mm" file="US20230004774A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="158.58mm" wi="81.70mm" file="US20230004774A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="90.93mm" wi="113.28mm" file="US20230004774A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application claims the priority of Chinese Patent Application No. 202110732838.X, filed on Jun. 30, 2021, with the title of &#x201c;METHOD AND APPARATUS FOR GENERATING NODE REPRESENTATION, ELECTRONIC DEVICE AND READABLE STORAGE MEDIUM.&#x201d; The disclosure of the above application is incorporated herein by reference in its entirety.</p><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present disclosure relates to the field of computer technologies, and particularly to the field of deep learning technologies, and provides a method and apparatus for generating a node representation, an electronic device and a readable storage medium.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Currently, graph network representations may be used for a variety of downstream tasks, including node classification, link prediction, community detection, or the like. In the real world, there exist a large number of heterogeneous graphs, and the heterogeneous graphs contain various node types and edge types. In order to learn semantic information of different types of nodes, a method usually adopted in a prior art includes: performing a sampling operation according to a defined meta path to obtain different walk paths, and training the walk paths using training methods, such as word2vec, or the like, so as to finally obtain a representation result of the node in the heterogeneous graph. In this node representation learning method, only one meta path is considered, information of other meta paths may be lost, and accuracy of a node representation may be affected due to noise (wrongly connected edges between nodes).</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">According to a first aspect of the present disclosure, there is provided a method for generating a node representation, including: acquiring a heterogeneous graph to be processed; performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path; obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node.</p><p id="p-0006" num="0005">According to a second aspect of the present disclosure, there is provided an electronic device, including: at least one processor; and a memory communicatively connected with the at least one processor; wherein the memory stores instructions executable by the at least one processor, and the instructions are executed by the at least one processor to enable the at least one processor to perform a method for generating a node representation, wherein the method includes: acquiring a heterogeneous graph to be processed; performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path; obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node.</p><p id="p-0007" num="0006">According to a third aspect of the present disclosure, there is provided anon-transitory computer readable storage medium with computer instructions stored thereon, wherein the computer instructions are used for causing a computer to perform a method for generating a node representation, wherein the method includes: acquiring a heterogeneous graph to be processed; performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path; obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node.</p><p id="p-0008" num="0007">From the above technical solution, it is observed that, in the present embodiment, after the sampling operation is performed in the heterogeneous graph to be processed according to the first preset meta path to obtain the at least one first walk path, the initial node representation of each node in the heterogeneous graph to be processed is first obtained according to the at least one first walk path obtained by the sampling operation, and the final node representation of each node is then generated according to the initial node representations of each node and the neighbor nodes thereof, such that information of the neighbor nodes may be fused in the final node representation of each node, thus improving accuracy of the generated final node representation.</p><p id="p-0009" num="0008">It should be understood that the statements in this section are not intended to identify key or critical features of the embodiments of the present disclosure, nor limit the scope of the present disclosure. Other features of the present disclosure will become apparent from the following description.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">The drawings are used for better understanding the present solution and do not constitute a limitation of the present disclosure. In the drawings,</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram according to a first embodiment of the present disclosure;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram according to a second embodiment of the present disclosure;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram according to a third embodiment of the present disclosure;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram according to a fourth embodiment of the present disclosure; and</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram of an electronic device configured to implement a method for generating a node representation according to the embodiment of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0016" num="0015">The following part will illustrate exemplary embodiments of the present disclosure with reference to the drawings, including various details of the embodiments of the present disclosure for a better understanding. The embodiments should be regarded only as exemplary ones. Therefore, those skilled in the art should appreciate that various changes or modifications can be made with respect to the embodiments described herein without departing from the scope and spirit of the present disclosure. Similarly, for clarity and conciseness, the descriptions of the known functions and mechanisms are omitted in the descriptions below.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram according to a first embodiment of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a method for generating a node representation according to the present embodiment may include the following steps:</p><p id="p-0018" num="0017">S<b>101</b>: acquiring a heterogeneous graph to be processed;</p><p id="p-0019" num="0018">S<b>102</b>: performing a sampling operation in the heterogeneous graph to be processed according to a first preset meta path, so as to obtain at least one first walk path;</p><p id="p-0020" num="0019">S<b>103</b>: obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and</p><p id="p-0021" num="0020">S<b>104</b>: generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node.</p><p id="p-0022" num="0021">In the method for generating a node representation according to the present embodiment, after the sampling operation is performed in the heterogeneous graph to be processed according to the first preset meta path to obtain the at least one first walk path, the initial node representation of each node in the heterogeneous graph to be processed is first obtained according to the at least one first walk path obtained by the sampling operation, and the final node representation of each node is then generated according to the initial node representations of each node and the neighbor nodes thereof, such that information of the neighbor nodes may be fused in the final node representation of each node, thus improving accuracy of the generated final node representation.</p><p id="p-0023" num="0022">In the present embodiment, during execution of the S<b>101</b> of acquiring a heterogeneous graph to be processed, the heterogeneous graph to be processed may be selected according to different downstream tasks, the obtained heterogeneous graph to be processed includes different types of nodes and edges between the nodes, and the edge between two nodes represents a connection relationship between the two nodes.</p><p id="p-0024" num="0023">For example, if the downstream task is a news recommendation task, the to-be-processed heterogeneous graph obtained by executing the S<b>101</b> in the present embodiment may be a graph network composed of a news node, a user node, and an interest node.</p><p id="p-0025" num="0024">In the present embodiment, after the execution of the S<b>101</b> of acquiring a heterogeneous graph to be processed, the S<b>102</b> of performing a sampling operation in the acquired heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path is executed.</p><p id="p-0026" num="0025">The first meta path in the present embodiment may be preset according to a structure of the heterogeneous graph to be processed and the downstream task for which the heterogeneous graph to be processed is used, and the first meta path contains the specified node type and the connection relationship between the nodes.</p><p id="p-0027" num="0026">For example, if the heterogeneous graph to be processed includes three types of nodes of B (news), U (user), and A (interest); the first meta path <b>1</b> used to execute the S<b>102</b> in the present embodiment may be U-B-U (user-news-user) for describing a relationship that a piece of news is clicked by two users; the used first meta path <b>2</b> may be U-A-U for describing a relationship that two users have a same interest. It is clear that when the sampling operation is performed in the heterogeneous graph to be processed according to different first meta paths, the obtained first walk paths corresponding to the different first meta paths have different semantic information.</p><p id="p-0028" num="0027">It may be understood that, in the present embodiment, during the execution of the S<b>102</b>, the sampling operation may be performed according to one first metal path to obtain at least one first walk path, or according to plural first meta paths to obtain plural first walk paths.</p><p id="p-0029" num="0028">In the present embodiment, during the execution of the S<b>102</b> of performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path, an optional implementation which may be adopted includes: performing the sampling operation in the heterogeneous graph to be processed according to the node type specified based on each first meta path and the connection relationship between the nodes, so as to obtain the at least one first walk path corresponding to the first meta path.</p><p id="p-0030" num="0029">In the present embodiment, during the execution of the S<b>102</b>, the sampling operation may be performed in the heterogeneous graph to be processed based on a random walk strategy, so as to obtain the first walk path corresponding to each first meta path.</p><p id="p-0031" num="0030">For example, if the nodes included in the heterogeneous graph to be processed are U<b>1</b>, U<b>2</b>, U<b>3</b>, B<b>1</b>, B<b>2</b>, B<b>3</b>, B<b>4</b>, A<b>1</b>, A<b>2</b>, A<b>3</b>, and A<b>4</b>, if the first meta path <b>1</b> is U-B-U, the first walk path obtained by the sampling operation according to the first meta path <b>1</b> in the heterogeneous graph to be processed may be U<b>1</b>-B<b>2</b>-U<b>2</b>-B<b>4</b>-U<b>3</b>, and the first walk path may also be U<b>2</b>-B<b>3</b>-U<b>3</b>-B<b>2</b>-U<b>1</b>; if the first meta path <b>2</b> is U-A-U, the first walk path obtained by the sampling operation according to the first meta path <b>2</b> in the heterogeneous graph to be processed may be U<b>1</b>-A<b>2</b>-U<b>2</b>-A<b>4</b>-U<b>3</b>.</p><p id="p-0032" num="0031">In the present embodiment, after the S<b>102</b> is executed to obtain the at least one first walk path, the S<b>103</b> of obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the obtained at least one first walk path is executed.</p><p id="p-0033" num="0032">In the present embodiment, during the execution of the S<b>103</b> of obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path, each obtained first walk path may be directly input to a neural network model obtained by a pre-training operation, and the initial node representation of each node in the heterogeneous graph to be processed is obtained by the neural network model according to the edges between the nodes of each type in the input first walk path.</p><p id="p-0034" num="0033">In the present embodiment, after the S<b>103</b> is executed to obtain the initial node representation of each node in the heterogeneous graph to be processed, the S<b>104</b> of generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node is executed.</p><p id="p-0035" num="0034">Before the execution of the S<b>104</b> of generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node, the method according to the present embodiment may further include: for each node, taking, as the neighbor nodes of the node, the nodes in the heterogeneous graph to be processed which are a preset distance away from the node, and if the preset distance is 1, taking the nodes <b>1</b> away from the current node as the neighbor nodes of the current node in the present embodiment.</p><p id="p-0036" num="0035">In the present embodiment, during the execution of the S<b>104</b>, a weighted summation may be directly performed on the initial node representation of each node and the initial node representations of the neighbor nodes of each node, such that the obtained weighted summation result is used as the final node representation of each node.</p><p id="p-0037" num="0036">Specifically, in the present embodiment, during the execution of the S<b>104</b> of generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node, an optional implementation which may be adopted includes: performing the weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node, and taking the obtained weighted summation result as an updated node representation of each node; after the initial node representation of each node is replaced with the updated node representation, proceeding to the step of performing the weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node until a preset number of times is reached; taking, as the final node representation of each node, the updated node representation of each node when the preset number of times is reached.</p><p id="p-0038" num="0037">In the present embodiment, during the execution of the S<b>104</b>, when the weighted summation is performed on the initial node representation of each node and the initial node representations of the neighbor nodes of each node, the following computational formula may be used:</p><p id="p-0039" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>H</i><sup>(k+1)</sup><i>=&#x3b1;&#xc2;h</i><sup>k</sup>+(1&#x2212;&#x3b1;)<i>H</i><sup>k </sup><?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0040" num="0038">In the formula, H<sup>(k+1) </sup>represents the updated node representation of the current node at the (k+1)th weighted summation; &#x3b1; denotes a weight coefficient having a value ranging from 0 to 1; &#xc2; represents an adjacency matrix; h<sup>k </sup>represents the updated node representation of the neighbor node of the current node at the kth weighted summation; H<sup>k </sup>represents the updated node representation of the current node at the kth weighted summation.</p><p id="p-0041" num="0039">That is, in the present embodiment, aggregation is performed on each node and the neighbor node corresponding to each node in the heterogeneous graph to be processed, and the initial node representation of each node is updated plural times, such that the obtained final node representation of each node includes the information of the neighbor node, thus further improving the accuracy of the obtained final node representation.</p><p id="p-0042" num="0040"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram according to a second embodiment of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, in the present embodiment, the S<b>103</b> of obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path may include the following steps:</p><p id="p-0043" num="0041">S<b>201</b>: taking each node in each first walk path as a first node;</p><p id="p-0044" num="0042">S<b>202</b>: constructing a node pair of each first node according to the first walk path where each first node is located, each node pair including the first node and one neighbor node thereof; and</p><p id="p-0045" num="0043">S<b>203</b>: inputting the node pair of each first node into a node representation model, and taking, as the initial node representation of each node, an output result output by the node representation model for each node.</p><p id="p-0046" num="0044">In the present embodiment, during the execution of the S<b>103</b> of obtaining an initial node representation of each node according to the first walk path, after the construction of the node pair corresponding to each node, each node pair is processed by the node representation model obtained by a pre-training operation, so as to obtain the initial node representation of each node.</p><p id="p-0047" num="0045">In the present embodiment, during execution of the S<b>202</b> of constructing a node pair of each first node according to the first walk path where each first node is located, an optional implementation which may be adopted includes: for each first node, in the first walk path where the first node is located, determining at least one neighbor node of the first node, for example, taking a node located at a preset distance before and/or after the current node as the neighbor node of the current node; and obtaining the node pair of the first node according to the first node and one neighbor node thereof.</p><p id="p-0048" num="0046">The node representation model used in the execution of the S<b>203</b> in the present embodiment is obtained by the pre-training operation, and the node representation model may output the initial node representation of each node according to the input node pair corresponding to the node.</p><p id="p-0049" num="0047"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram according to a third embodiment of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the node representation model used in the execution of the S<b>203</b> in the present embodiment is obtained by the pre-training operation by:</p><p id="p-0050" num="0048">S<b>301</b>: acquiring training data, the training data including a sample heterogeneous graph and a marked node representation of each node in the sample heterogeneous graph;</p><p id="p-0051" num="0049">S<b>302</b>: performing a sampling operation in the sample heterogeneous graph according to a second meta path, so as to obtain at least one second walk path;</p><p id="p-0052" num="0050">S<b>303</b>: taking each node in each second walk path as a second node, and constructing a node pair of each second node, the node pair including the second node and one neighbor node thereof; and</p><p id="p-0053" num="0051">S<b>304</b>: training a neural network model using the node pair of the second node and the marked node representation of the second node until the neural network model converges to obtain the node representation model.</p><p id="p-0054" num="0052">The second meta path used in the execution of the S<b>302</b> in the present embodiment may be the same as or different from the first meta path.</p><p id="p-0055" num="0053">The process of executing the S<b>302</b> of performing a sampling operation to obtain at least one second walk path in the present embodiment is similar to the process of executing the S<b>102</b> of performing a sampling operation to obtain at least one first walk path in the foregoing embodiment, and is not repeated herein.</p><p id="p-0056" num="0054">The process of executing the S<b>303</b> of constructing a node pair of the second node in the present embodiment is similar to the process of executing the S<b>202</b> of constructing a node pair of the first node in the foregoing embodiment, and is not repeated herein.</p><p id="p-0057" num="0055">In the present embodiment, during execution of the S<b>304</b> of training a neural network model using the node pair of the second node and the marked node representation of the second node until the neural network model converges, an optional implementation which may be adopted includes: inputting the node pair of the second node into the neural network model to obtain an output result output by the neural network model for the node pair, the neural network model used in the present embodiment being a walk class diagram learning model; and updating parameters in the neural network model according to a loss function value calculated according to the obtained output result and the marked node representation of the second node until the neural network model converges.</p><p id="p-0058" num="0056">The node representation model obtained by the training operation in the present embodiment may output the node representation of the node according to the input node pair of the node.</p><p id="p-0059" num="0057"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a schematic diagram according to a fourth embodiment of the present disclosure. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, an apparatus <b>400</b> for generating a node representation according to the present embodiment includes: an acquiring unit <b>401</b> configured to acquire a heterogeneous graph to be processed; a sampling unit <b>402</b> configured to perform a sampling operation in the heterogeneous graph to be processed according to a first preset meta path, so as to obtain at least one first walk path; a processing unit <b>403</b> configured to obtain an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and a generating unit <b>404</b> configured to generate the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node.</p><p id="p-0060" num="0058">When acquiring the heterogeneous graph to be processed, the acquiring unit <b>401</b> may select the heterogeneous graph to be processed according to different downstream tasks, the obtained heterogeneous graph to be processed includes different types of nodes and edges between the nodes, and the edge between two nodes represents a connection relationship between the two nodes.</p><p id="p-0061" num="0059">In the present embodiment, after the acquiring unit <b>401</b> acquires the heterogeneous graph to be processed, the sampling unit <b>402</b> performs the sampling operation in the acquired heterogeneous graph to be processed according to the first meta path, so as to obtain the at least one first walk path.</p><p id="p-0062" num="0060">It may be understood that the sampling unit <b>402</b> may perform the sampling operation according to one first metal path to obtain at least one first walk path, or according to plural first meta paths to obtain plural first walk paths.</p><p id="p-0063" num="0061">When performing the sampling operation in the heterogeneous graph to be processed according to the first meta path, so as to obtain the at least one first walk path, in an optional implementation which may be adopted, the sampling unit <b>402</b> performs the sampling operation in the heterogeneous graph to be processed according to the node type specified based on each first meta path and the connection relationship between the nodes, so as to obtain the at least one first walk path corresponding to the first meta path.</p><p id="p-0064" num="0062">The sampling unit <b>402</b> may perform the sampling operation in the heterogeneous graph to be processed based on a random walk strategy, so as to obtain the first walk path corresponding to each first meta path.</p><p id="p-0065" num="0063">In the present embodiment, after the at least one first walk path is obtained by the sampling unit <b>402</b>, the processing unit <b>403</b> obtains the initial node representation of each node in the heterogeneous graph to be processed according to the obtained at least one first walk path.</p><p id="p-0066" num="0064">When obtaining the initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path, the processing unit <b>403</b> may directly input each obtained first walk path to a neural network model obtained by a pre-training operation, and the initial node representation of each node in the heterogeneous graph to be processed is obtained by the neural network model according to the edges between the nodes of each type in the input first walk path.</p><p id="p-0067" num="0065">When obtaining the initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path, in an optional implementation which may be adopted, the processing unit <b>403</b> may take each node in each first walk path as a first node; construct a node pair of each first node according to the first walk path where each first node is located, each node pair including the first node and one neighbor node thereof; and input the node pair of each first node into a node representation model, and take, as the initial node representation of each node, an output result output by the node representation model for each node.</p><p id="p-0068" num="0066">When constructing the node pair of each first node according to the first walk path where each first node is located, in an optional implementation which may be adopted, the processing unit <b>403</b> may, for each first node, in the first walk path where the first node is located, determine at least one neighbor node of the first node; and obtain the node pair of the first node according to the first node and one neighbor node thereof.</p><p id="p-0069" num="0067">The node representation model used by the processing unit <b>403</b> is obtained by the pre-training operation by a training unit <b>405</b>, and the node representation model may output the initial node representation of each node according to the input node pair corresponding to the node.</p><p id="p-0070" num="0068">The apparatus <b>400</b> for generating a node representation according to the present embodiment may further include the training unit <b>405</b> configured to perform the pre-training operation to obtain the node representation model by: acquiring training data, the acquired training data including a sample heterogeneous graph and a marked node representation of each node in the sample heterogeneous graph; performing a sampling operation in the acquired sample heterogeneous graph according to a second meta path, so as to obtain at least one second walk path; taking each node in each second walk path as a second node, and constructing a node pair of each second node, the constructed node pair including the second node and one neighbor node thereof; and training a neural network model using the node pair of the second node and the marked node representation of the second node until the neural network model converges to obtain the node representation model.</p><p id="p-0071" num="0069">The second meta path used by the training unit <b>405</b> may be the same as or different from the first meta path used by the sampling unit <b>402</b>.</p><p id="p-0072" num="0070">The process of performing the sampling operation to obtain the at least one second walk path by the training unit <b>405</b> is similar to the process of performing the sampling operation to obtain the at least one first walk path by the sampling unit <b>402</b>, and is not repeated herein.</p><p id="p-0073" num="0071">The process of constructing the node pair of the second node by the training unit <b>405</b> is similar to the process of constructing the node pair of the first node by the processing unit <b>403</b>, and is not repeated herein.</p><p id="p-0074" num="0072">When training the neural network model using the node pair of the second node and the marked node representation of the second node until the neural network model converges, in an optional implementation which may be adopted, the training unit <b>405</b>: inputs the node pair of the second node into the neural network model to obtain an output result output by the neural network model for the node pair, the neural network model used in the present embodiment being a walk class diagram learning model; and updates parameters in the neural network model according to a loss function value calculated according to the obtained output result and the marked node representation of the second node until the neural network model converges.</p><p id="p-0075" num="0073">In the present embodiment, after the processing unit <b>403</b> obtains the initial node representation of each node in the heterogeneous graph to be processed, the generating unit <b>404</b> generates the final node representation of each node according to the initial node representation of each node and the initial node representations of the neighbor nodes of each node.</p><p id="p-0076" num="0074">Before generating the final node representation of each node according to the initial node representation of each node and the initial node representations of the neighbor nodes of each node, the generating unit <b>404</b> may: for each node, take, as the neighbor nodes of the node, the nodes in the heterogeneous graph to be processed which are a preset distance away from the node.</p><p id="p-0077" num="0075">The generating unit <b>404</b> may directly perform a weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node, such that the obtained weighted summation result is used as the final node representation of each node.</p><p id="p-0078" num="0076">Specifically, when generating the final node representation of each node according to the initial node representation of each node and the initial node representations of the neighbor nodes of each node, in an optional implementation which may be adopted, the generating unit <b>404</b>: performs the weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node, and takes the obtained weighted summation result as an updated node representation of each node; after the initial node representation of each node is replaced with the updated node representation, proceeds to the step of performing the weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node until a preset number of times is reached; takes, as the final node representation of each node, the updated node representation of each node when the preset number of times is reached.</p><p id="p-0079" num="0077">In the technical solution of the present disclosure, the acquisition, storage and application of involved user personal information are in compliance with relevant laws and regulations, and do not violate public order and good customs.</p><p id="p-0080" num="0078">According to the embodiment of the present disclosure, there are also provided an electronic device, a readable storage medium and a computer program product.</p><p id="p-0081" num="0079"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram of an electronic device for the method for generating a node representation according to the embodiment of the present disclosure. The electronic device is intended to represent various forms of digital computers, such as laptop computers, desktop computers, workstations, personal digital assistants, servers, blade servers, mainframe computers, and other appropriate computers. The electronic device may also represent various forms of mobile apparatuses, such as personal digital assistants, cellular telephones, smart phones, wearable devices, and other similar computing apparatuses. The components shown herein, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementation of the present disclosure described and/or claimed herein.</p><p id="p-0082" num="0080">As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the device <b>500</b> includes a computing unit <b>501</b> which may perform various appropriate actions and processing operations according to a computer program stored in a read only memory (ROM) <b>502</b> or a computer program loaded from a storage unit <b>508</b> into a random access memory (RAM) <b>503</b>. Various programs and data necessary for the operation of the device <b>500</b> may be also stored in the RAM <b>503</b>. The computing unit <b>501</b>, the ROM <b>502</b>, and the RAM <b>503</b> are connected with one other through a bus <b>504</b>. An input/output (I/O) interface <b>505</b> is also connected to the bus <b>504</b>.</p><p id="p-0083" num="0081">The plural components in the device <b>500</b> are connected to the I/O interface <b>505</b>, and include: an input unit <b>506</b>, such as a keyboard, a mouse, or the like; an output unit <b>507</b>, such as various types of displays, speakers, or the like; the storage unit <b>508</b>, such as a magnetic disk, an optical disk, or the like; and a communication unit <b>509</b>, such as a network card, a modem, a wireless communication transceiver, or the like. The communication unit <b>509</b> allows the device <b>500</b> to exchange information/data with other devices through a computer network, such as the Internet, and/or various telecommunication networks.</p><p id="p-0084" num="0082">The computing unit <b>501</b> may be a variety of general and/or special purpose processing components with processing and computing capabilities. Some examples of the computing unit <b>501</b> include, but are not limited to, a central processing unit (CPU), a graphic processing unit (GPU), various dedicated artificial intelligence (AI) computing chips, various computing units running machine learning model algorithms, a digital signal processor (DSP), and any suitable processor, controller, microcontroller, or the like. The computing unit <b>501</b> performs the methods and processing operations described above, such as the method for generating a node representation. For example, in some embodiments, the method for generating a node representation may be implemented as a computer software program tangibly contained in a machine readable medium, such as the storage unit <b>508</b>.</p><p id="p-0085" num="0083">In some embodiments, part or all of the computer program may be loaded and/or installed into the device <b>500</b> via the ROM <b>502</b> and/or the communication unit <b>509</b>. When the computer program is loaded into the RAM <b>503</b> and executed by the computing unit <b>501</b>, one or more steps of the method for generating a node representation described above may be performed. Alternatively, in other embodiments, the computing unit <b>501</b> may be configured to perform the method for generating a node representation by any other suitable means (for example, by means of firmware).</p><p id="p-0086" num="0084">Various implementations of the systems and technologies described herein may be implemented in digital electronic circuitry, integrated circuitry, field programmable gate arrays (FPGA), application specific integrated circuits (ASIC), application specific standard products (ASSP), systems on chips (SOC), complex programmable logic devices (CPLD), computer hardware, firmware, software, and/or combinations thereof. The systems and technologies may be implemented in one or more computer programs which are executable and/or interpretable on a programmable system including at least one programmable processor, and the programmable processor may be special or general, and may receive data and instructions from, and transmit data and instructions to, a storage system, at least one input apparatus, and at least one output apparatus.</p><p id="p-0087" num="0085">Program codes for implementing the method according to the present disclosure may be written in any combination of one or more programming languages. These program codes may be provided to a processor or a controller of a general purpose computer, a special purpose computer, or other programmable data processing apparatuses, such that the program code, when executed by the processor or the controller, causes functions/operations specified in the flowchart and/or the block diagram to be implemented. The program code may be executed entirely on a machine, partly on a machine, partly on a machine as a stand-alone software package and partly on a remote machine, or entirely on a remote machine or a server.</p><p id="p-0088" num="0086">In the context of the present disclosure, the machine readable medium may be a tangible medium which may contain or store a program for use by or in connection with an instruction execution system, apparatus, or device. The machine readable medium may be a machine readable signal medium or a machine readable storage medium. The machine readable medium may include, but is not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples of the machine readable storage medium may include an electrical connection based on one or more wires, a portable computer disk, a hard disk, a random access memory (RAM), a read only memory (ROM), an erasable programmable read only memory (EPROM or flash memory), an optical fiber, a portable compact disc read only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing.</p><p id="p-0089" num="0087">To provide interaction with a user, the systems and technologies described here may be implemented on a computer having: a display apparatus (for example, a cathode ray tube (CRT) or liquid crystal display (LCD) monitor) for displaying information to a user; and a keyboard and a pointing apparatus (for example, a mouse or a trackball) by which a user may provide input for the computer. Other kinds of apparatuses may also be used to provide interaction with a user; for example, feedback provided for a user may be any form of sensory feedback (for example, visual feedback, auditory feedback, or tactile feedback); and input from a user may be received in any form (including acoustic, speech or tactile input).</p><p id="p-0090" num="0088">The systems and technologies described here may be implemented in a computing system (for example, as a data server) which includes a back-end component, or a computing system (for example, an application server) which includes a middleware component, or a computing system (for example, a user computer having a graphical user interface or a web browser through which a user may interact with an implementation of the systems and technologies described here) which includes a front-end component, or a computing system which includes any combination of such back-end, middleware, or front-end components. The components of the system may be interconnected through any form or medium of digital data communication (for example, a communication network). Examples of the communication network include: a local area network (LAN), a wide area network (WAN) and the Internet.</p><p id="p-0091" num="0089">A computer system may include a client and a server. Generally, the client and the server are remote from each other and interact through the communication network. The relationship between the client and the server is generated by virtue of computer programs which run on respective computers and have a client-server relationship to each other. The server may be a cloud server, also called a cloud computing server or a cloud host, and is a host product in a cloud computing service system, so as to overcome the defects of high management difficulty and weak service expansibility in conventional physical host and virtual private server (VPS) service. The server may also be a server of a distributed system, or a server incorporating a blockchain.</p><p id="p-0092" num="0090">It should be understood that various forms of the flows shown above may be used and reordered, and steps may be added or deleted. For example, the steps described in the present disclosure may be executed in parallel, sequentially, or in different orders, which is not limited herein as long as the desired results of the technical solution disclosed in the present disclosure may be achieved.</p><p id="p-0093" num="0091">The above-mentioned implementations are not intended to limit the scope of the present disclosure. It should be understood by those skilled in the art that various modifications, combinations, sub-combinations and substitutions may be made, depending on design requirements and other factors. Any modification, equivalent substitution and improvement made within the spirit and principle of the present disclosure all should be included in the extent of protection of the present disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for generating a node representation, comprising:<claim-text>acquiring a heterogeneous graph to be processed;</claim-text><claim-text>performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path;</claim-text><claim-text>obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and</claim-text><claim-text>generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path comprises:<claim-text>performing the sampling operation in the heterogeneous graph to be processed according to a node type specified based on each first meta path and a connection relationship between nodes, so as to obtain the at least one first walk path corresponding to the first meta path.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path comprises:<claim-text>taking each node in each first walk path as a first node;</claim-text><claim-text>constructing a node pair of each first node according to the first walk path where each first node is located, each node pair comprising the first node and one neighbor node thereof; and</claim-text><claim-text>inputting the node pair of each first node into a node representation model, and taking, as the initial node representation of each node, an output result output by the node representation model for each node.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, further comprising: performing a pre-training operation to obtain the node representation model by:<claim-text>acquiring training data, the training data comprising a sample heterogeneous graph and a marked node representation of each node in the sample heterogeneous graph;</claim-text><claim-text>performing a sampling operation in the sample heterogeneous graph according to a second meta path, so as to obtain at least one second walk path;</claim-text><claim-text>taking each node in each second walk path as a second node, and constructing a node pair of each second node, the node pair comprising the second node and one neighbor node thereof; and</claim-text><claim-text>training a neural network model using the node pair of the second node and the marked node representation of the second node until the neural network model converges to obtain the node representation model.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node comprises:<claim-text>performing a weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node, and taking the obtained weighted summation result as an updated node representation of each node;</claim-text><claim-text>after the initial node representation of each node is replaced with the updated node representation, proceeding to the step of performing a weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node until a preset number of times is reached; and</claim-text><claim-text>taking, as the final node representation of each node, the updated node representation of each node when the preset number of times is reached.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. An electronic device, comprising:<claim-text>at least one processor; and</claim-text><claim-text>a memory communicatively connected with the at least one processor;</claim-text><claim-text>wherein the memory stores instructions executable by the at least one processor, and the instructions are executed by the at least one processor to enable the at least one processor to perform a method for generating a node representation, wherein the method comprises:</claim-text><claim-text>acquiring a heterogeneous graph to be processed;</claim-text><claim-text>performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path;</claim-text><claim-text>obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and</claim-text><claim-text>generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The electronic device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path comprises:<claim-text>performing the sampling operation in the heterogeneous graph to be processed according to a node type specified based on each first meta path and a connection relationship between nodes, so as to obtain the at least one first walk path corresponding to the first meta path.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The electronic device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path comprises:<claim-text>taking each node in each first walk path as a first node;</claim-text><claim-text>constructing a node pair of each first node according to the first walk path where each first node is located, each node pair comprising the first node and one neighbor node thereof; and</claim-text><claim-text>inputting the node pair of each first node into a node representation model, and taking, as the initial node representation of each node, an output result output by the node representation model for each node.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The electronic device according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising: performing a pre-training operation to obtain the node representation model by:<claim-text>acquiring training data, the training data comprising a sample heterogeneous graph and a marked node representation of each node in the sample heterogeneous graph;</claim-text><claim-text>performing a sampling operation in the sample heterogeneous graph according to a second meta path, so as to obtain at least one second walk path;</claim-text><claim-text>taking each node in each second walk path as a second node, and constructing a node pair of each second node, the node pair comprising the second node and one neighbor node thereof; and</claim-text><claim-text>training a neural network model using the node pair of the second node and the marked node representation of the second node until the neural network model converges to obtain the node representation model.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The electronic device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node comprises:<claim-text>performing a weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node, and taking the obtained weighted summation result as an updated node representation of each node;</claim-text><claim-text>after the initial node representation of each node is replaced with the updated node representation, proceeding to the step of performing a weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node until a preset number of times is reached; and</claim-text><claim-text>taking, as the final node representation of each node, the updated node representation of each node when the preset number of times is reached.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A non-transitory computer readable storage medium with computer instructions stored thereon, wherein the computer instructions are used for causing a computer to perform a method for generating a node representation, wherein the method comprises:<claim-text>acquiring a heterogeneous graph to be processed;</claim-text><claim-text>performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path;</claim-text><claim-text>obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path; and</claim-text><claim-text>generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the performing a sampling operation in the heterogeneous graph to be processed according to a first meta path, so as to obtain at least one first walk path comprises:<claim-text>performing the sampling operation in the heterogeneous graph to be processed according to a node type specified based on each first meta path and a connection relationship between nodes, so as to obtain the at least one first walk path corresponding to the first meta path.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the obtaining an initial node representation of each node in the heterogeneous graph to be processed according to the at least one first walk path comprises:<claim-text>taking each node in each first walk path as a first node;</claim-text><claim-text>constructing a node pair of each first node according to the first walk path where each first node is located, each node pair comprising the first node and one neighbor node thereof; and</claim-text><claim-text>inputting the node pair of each first node into a node representation model, and taking, as the initial node representation of each node, an output result output by the node representation model for each node.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising: performing a pre-training operation to obtain the node representation model by:<claim-text>acquiring training data, the training data comprising a sample heterogeneous graph and a marked node representation of each node in the sample heterogeneous graph;</claim-text><claim-text>performing a sampling operation in the sample heterogeneous graph according to a second meta path, so as to obtain at least one second walk path;</claim-text><claim-text>taking each node in each second walk path as a second node, and constructing a node pair of each second node, the node pair comprising the second node and one neighbor node thereof; and</claim-text><claim-text>training a neural network model using the node pair of the second node and the marked node representation of the second node until the neural network model converges to obtain the node representation model.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The non-transitory computer readable storage medium according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the generating the final node representation of each node according to the initial node representation of each node and initial node representations of neighbor nodes of each node comprises:<claim-text>performing a weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node, and taking the obtained weighted summation result as an updated node representation of each node;</claim-text><claim-text>after the initial node representation of each node is replaced with the updated node representation, proceeding to the step of performing a weighted summation on the initial node representation of each node and the initial node representations of the neighbor nodes of each node until a preset number of times is reached; and</claim-text><claim-text>taking, as the final node representation of each node, the updated node representation of each node when the preset number of times is reached.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005311A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005311</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17853043</doc-number><date>20220629</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>07</class><subclass>C</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>764</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>07</class><subclass>C</subclass><main-group>9</main-group><subgroup>00563</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>764</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>40</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">System and Method for Authenticating Identity of a Person Wearing an Earpiece</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63216775</doc-number><date>20210630</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Kyocera AVX Components Corporation</orgname><address><city>Fountain Inn</city><state>SC</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Desclos</last-name><first-name>Laurent</first-name><address><city>San Diego</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A person authentication system is provided. The person authentication system includes one or more image capture devices. The person authentication system includes a computing system. The computing system includes one or more computing devices. The computing system is configured to obtain data indicative of a unique identifier associated with an earpiece worn by a person. The computing system is configured to obtain image data of an ear of the person via the one or more image capture devices. The computing system is configured to authenticate an identity of the person based, at least in part, on the image data and the data indicative of the unique identifier.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="96.35mm" wi="158.75mm" file="US20230005311A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="183.30mm" wi="142.58mm" orientation="landscape" file="US20230005311A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="203.62mm" wi="84.75mm" file="US20230005311A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="205.57mm" wi="97.45mm" file="US20230005311A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="215.98mm" wi="81.87mm" file="US20230005311A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="193.21mm" wi="88.65mm" file="US20230005311A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="193.21mm" wi="88.73mm" file="US20230005311A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="202.78mm" wi="59.44mm" file="US20230005311A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="210.48mm" wi="115.99mm" file="US20230005311A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">PRIORITY CLAIM</heading><p id="p-0002" num="0001">This application claims the benefit of priority of U.S. Provisional Patent Application Ser. No. 63/216,775, filed on Jun. 30, 2021, titled &#x201c;System and Method for Authenticating Identity of a Person Wearing an Earpiece,&#x201d; which is incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The present disclosure relates generally to earpieces and, more particularly, to a system and method for authenticating the identity of a person wearing an earpiece.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Earpieces are wearable devices that can be inserted into an ear of a person. Earpieces can include one or more electronic components (e.g., transducers) associated with converting an electrical signal into an audio signal. For example, the audio signal can be associated with an incoming call to a mobile computing device (e.g., smartphone, tablet) associated with the person. In this manner, the person can listen to the audio signal in private.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0005" num="0004">Aspects and advantages of embodiments of the present disclosure will be set forth in part in the following description, or may be learned from the description, or may be learned through practice of the embodiments.</p><p id="p-0006" num="0005">In one aspect, a method of authenticating a person is provided. The method includes obtaining data indicative of a unique identifier associated with an earpiece worn by a person. The method includes obtaining image data of an ear of the person. The method includes authenticating an identity of the person based, at least in part, on the image data and the data indicative of the unique identifier.</p><p id="p-0007" num="0006">In another aspect, a person authentication system is provided. The person authentication system includes one or more image capture devices. The person authentication system includes a computing system. The computing system includes one or more computing devices. The computing system is configured to obtain data indicative of a unique identifier associated with an earpiece worn by a person. The computing system is configured to obtain image data of an ear of the person via the one or more image capture devices. The computing system is configured to authenticate an identity of the person based, at least in part, on the image data and the data indicative of the unique identifier.</p><p id="p-0008" num="0007">These and other features, aspects and advantages of various embodiments will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate embodiments of the present disclosure and, together with the description, serve to explain the related principles.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0009" num="0008">Detailed discussion of embodiments directed to one of ordinary skill in the art are set forth in the specification, which makes reference to the appended figures, in which:</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a block diagram of a person authentication system.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>2</b></figref> depicts a block diagram of components of an earpiece according to example embodiments of the present disclosure.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts an image of an ear of a person according to example embodiments of the present disclosure.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts a flow diagram of a method for authenticating identity of a person wearing an earpiece according to example embodiments of the present disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>5</b></figref> depicts a flow diagram of a method of authenticating identity of a person wearing an earpiece according to example embodiments of the present disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>6</b></figref> depicts a flow diagram of a method of authenticating identity of a person wearing an earpiece according to example embodiments of the present disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>7</b></figref> depicts a block diagram of components of a computing system according to example embodiments of the present disclosure.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>8</b></figref> depicts a modal antenna according to example embodiments of the present disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts a two-dimensional radiation pattern associated with a modal antenna according to example embodiments of the present disclosure.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts a frequency plot of a modal antenna according to example embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0020" num="0019">Reference now will be made in detail to embodiments, one or more examples of which are illustrated in the drawings. Each example is provided by way of explanation of the embodiments, not limitation of the present disclosure. In fact, it will be apparent to those skilled in the art that various modifications and variations can be made to the embodiments without departing from the scope or spirit of the present disclosure. For instance, features illustrated or described as part of one embodiment can be used with another embodiment to yield a still further embodiment. Thus, it is intended that aspects of the present disclosure cover such modifications and variations.</p><p id="p-0021" num="0020">Example aspects of the present disclosure are directed to authentication systems. In some examples, an earpiece issued to a person can be configured to broadcast or otherwise communicate data indicative of a unique identifier associated with the earpiece. The unique identifier can be used to determine an identity (e.g., name) of the person that was issued the earpiece. However, instances can occur in which the person wearing the earpiece is not the person that was issued the earpiece. In such instances, the identity of the person wearing the earpiece cannot be determined based on the unique identifier.</p><p id="p-0022" num="0021">Example aspects of the present disclosure are directed to a person authentication system. The person authentication system can include a computing system configured to obtain the data indicative of the unique identifier associated with an earpiece worn by a person. For instance, the computing system can be communicatively coupled to the earpiece over a network. In this manner, the earpiece can, for instance, communicate the data indicative of the unique identifier to the computing system via the network.</p><p id="p-0023" num="0022">The computing system can be configured to obtain image data indicative of an ear of the person. For instance, the image data can be obtained from one or more image capture devices (e.g., cameras) positioned at an entrance to a restricted area the person wearing the earpiece is attempting to enter. In some implementations, the image data can include one or more images of an outer ear of the person. For instance, the one or more images of the outer ear can depict one or more anatomical features (e.g., helix) of the periphery of the ear that are specific to the person wearing the earpiece. Alternatively, or additionally, the image data can include one or more images of an inner ear. It should be appreciated that the inner ear can include one or more anatomical features (e.g., antihelix, triangular fossa) of the ear that are positioned closer to an entrance to a canal of the ear than the outer ear.</p><p id="p-0024" num="0023">The computing system can be configured to authenticate the identity of the person wearing the earpiece based, at least in part, on the unique identifier associated with the earpiece and the image data. For instance, the computing system can be configured to determine the identity of person to whom the earpiece was issued based, at least in part, on the unique identifier associated with the earpiece. Additionally, the computing system can be configured to determine whether the person wearing the earpiece is the same person to whom the earpiece was issued based, at least in part, on the image data.</p><p id="p-0025" num="0024">In some implementations, the computing system can compare the one or more images of the ear of the person wearing the earpiece to one or more images of the ear of the person issued the earpiece. For instance, the computing system can determine whether one or more anatomical features of the ear of the person wearing the earpiece correspond (e.g., match) one or more anatomical features of the ear of the person issued the earpiece. In some implementations, the computing system can compare one or more anatomical features of the outer ear of the person to whom the earpiece was issued to one or more anatomical features of the outer ear of the person wearing the earpiece. Alternatively, or additionally, the computing system can compare one or more anatomical features of the inner ear of the person to whom the earpiece was issued to one or more anatomical features of the inner ear of the person wearing the earpiece.</p><p id="p-0026" num="0025">In alternative implementations, the computing system can classify the image data of the ear of the person wearing the earpiece using one or more machine-learned image classifier models to determine an image classification for the image data. Furthermore, the computing system can be configured to authenticate the identity of the person wearing the earpiece based, at least in part, on the image classification. The person authentication system according to example aspects of the present disclosure can provide numerous technical benefits and advantages. For instance, since the person authentication system authenticates the identity of the person wearing the earpiece based on both the unique identifier (e.g., MAC address) associated with the earpiece and the image data of the ear of the person wearing the earpiece, the person authentication system can more accurately authenticate the identity of the person. Furthermore, since the image data can include one or more images of the outer ear and the inner ear (that is, portions of the ear that are closer to an entrance the ear canal than the outer ear), the person authentication system can authenticate the identity of the person based on one or more anatomical features associated with the outer ear and one or more anatomical features associated with the inner ear. In this manner, person authentication systems according to example aspects of the present disclosure can provide three-factor (e.g., unique identifier, outer ear, inner ear) authentication of the identity of the person wearing the earpiece.</p><p id="p-0027" num="0026">Referring now to the FIGS, <figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a person authentication system <b>100</b> for a person <b>102</b> wearing an earpiece <b>110</b> according to an example embodiment of the present disclosure. In some implementations, the earpiece <b>110</b> can be an over-the-ear earpiece. In alternative implementations, the earpiece <b>110</b> can be an in-ear earpiece. It should be understood, however, that the earpiece <b>110</b> can include any suitable earpiece.</p><p id="p-0028" num="0027">The earpiece <b>110</b> can be configured to transmit data indicative of a unique identifier (e.g., MAC address) for the earpiece <b>110</b>. For instance, the earpiece <b>110</b> can be configured to transmit a beacon signal that includes data indicative of the unique identifier for the earpiece <b>110</b>. It should be appreciated that the unique identifier can be indicative of the identity (e.g., name) of the person to whom the earpiece <b>110</b> was issued. In some instances, the person to whom the earpiece <b>110</b> was issued can be the person <b>102</b> wearing the earpiece <b>110</b>. Alternatively, the person <b>102</b> wearing the earpiece <b>110</b> can be different than the person to whom the earpiece <b>110</b> was issued. The person authentication system <b>100</b> can include one or more image capture devices <b>120</b>. The one or more image capture devices <b>120</b> can obtain image data of the ear <b>104</b> of the person <b>102</b> wearing the earpiece <b>110</b>. For instance, the image data of the ear <b>104</b> of the person <b>102</b> wearing the earpiece <b>110</b> can include one or more images of an outer ear of the person <b>102</b>.</p><p id="p-0029" num="0028">In some implementations, the one or more image capture devices <b>120</b> can be positioned at an entrance (e.g., door) to a restricted area. In this manner, the one or more image capture devices <b>120</b> can obtain image data of the ear <b>104</b> of the person <b>102</b> prior to the person <b>102</b> entering the restricted area. As will be discussed below in more detail, the person authentication system <b>100</b> can authenticate the identity of the person <b>102</b> based, at least in part, on unique identifier (e.g., medium access control (MAC) address) obtained from the earpiece <b>110</b> and the image data obtained from the one or more image capture devices <b>120</b>.</p><p id="p-0030" num="0029">As shown, the person authentication system <b>100</b> can include a computing system <b>140</b>. The computing system <b>140</b> can be communicatively coupled to the earpiece <b>110</b>. In this manner, the computing system <b>140</b> can obtain the data indicative of the unique identifier associated with the earpiece <b>110</b>. Furthermore, the computing system <b>140</b> can be communicatively coupled to the one or more image capture devices <b>120</b>. In this manner, the computing system <b>140</b> can obtain the image data of the ear <b>104</b> of the person <b>102</b>.</p><p id="p-0031" num="0030">In some implementations, the computing system <b>140</b> can be communicatively coupled to the earpiece <b>110</b> and the one or more image capture devices <b>120</b> via one or more wireless networks <b>150</b>. In some implementations, the one or more wireless networks <b>150</b> can include a cellular network. Alternatively, or additionally, the one or more wireless networks <b>150</b> can include a wireless local area network (WLAN), such as a 802.11 network (e.g., WiFi network). It should also be understood that the one or more wireless networks <b>150</b> can have any suitable topology. For instance, in some implementations, the one or more wireless networks <b>150</b> can be a mesh network. In such implementations, the earpiece <b>110</b> can communicate with other earpieces on the mesh network.</p><p id="p-0032" num="0031">The computing system <b>140</b> can be configured to determine the identity of the person to whom the earpiece <b>110</b> was issued based, at least in part, on the data indicative of the unique identifier associated with the earpiece <b>110</b>. For instance, the computing system <b>140</b> can obtain the beacon signal from the earpiece <b>110</b> via the one or more wireless network <b>150</b>. As discussed above, the beacon signal can include the data indicative of the unique identifier. In some implementations, the computing system <b>140</b> can be configured to access a database configured to store data (e.g., table, list, etc.) that associates the unique identifier associated with the earpiece <b>110</b> to a person to whom the earpiece <b>110</b> was issued. For instance, in some implementations, the data stored in the database can include the name of the person to whom the earpiece <b>110</b> was assigned. In this manner, the computing system <b>140</b> can access the data stored in the database to determine the identity (e.g., name) of the person to whom the earpiece <b>110</b> was issued.</p><p id="p-0033" num="0032">The computing system <b>140</b> can be configured to obtain the image data from the one or more image capture devices <b>120</b>. For instance, the computing system <b>140</b> can obtain the image data from the one or more image capture devices <b>120</b> via the one or more wireless network <b>150</b>. In some implementations, the computing system <b>140</b> can be configured to classify the image data of the ear <b>104</b> of the person <b>102</b> to determine an image classification. For instance, the image data can be provided as an input to one or more machine-learned image classifier models of the computing system <b>140</b>. The one or more machine-learned image classifier models can be configured to process the image data to output the image classification.</p><p id="p-0034" num="0033">Furthermore, in such implementations, the computing system <b>140</b> can be configured to authenticate the identity (e.g., name) of the person <b>102</b> wearing the earpiece <b>110</b> based, at least in part, on the image classification output by the one or more machine-learned image classifier models.</p><p id="p-0035" num="0034">In some implementations, the computing system <b>140</b> can compare the one or more images of the ear <b>104</b> of the person <b>102</b> wearing the earpiece <b>110</b> to one or more images of the ear of the person to whom the earpiece <b>110</b> was issued. For instance, the computing system <b>140</b> can compare anatomical features of the ear <b>104</b> of the person <b>102</b> wearing the earpiece <b>110</b> to one or more anatomical features of the person to whom the earpiece <b>110</b> was issued. When one or more anatomical features of the ear <b>104</b> of the person <b>102</b> wearing the earpiece <b>110</b> differ from one or more anatomical feature of the ear of the person issued the earpiece <b>110</b>, the computing system <b>140</b> can determine the person <b>102</b> wearing the earpiece <b>110</b> is not the person to whom the earpiece <b>110</b> was issued. Alternatively, the computing system <b>140</b> can determine the person <b>102</b> wearing the earpiece <b>110</b> is the person to whom the earpiece <b>110</b> was issued when the one or more anatomical features of the ear of the person <b>102</b> wearing the earpiece <b>110</b> correspond to the one or more anatomical features of the ear of the person to whom the earpiece <b>110</b> was issued. In some implementations, the one or more anatomical features can be associated with the outer ear (e.g., scaphoid fossa, helix, anti-helix, anti-tragus). For instance, one or more anatomical features of the outer ear of the person <b>102</b> wearing the earpiece <b>110</b> can be compared to the one or more anatomical features of the outer ear of the person to whom the earpiece <b>110</b> was issued.</p><p id="p-0036" num="0035">In some implementations, the computing system <b>140</b> can be configured to provide a notification indicative of whether the identity of the person <b>102</b> wearing the earpiece <b>110</b> has been authenticated. For instance, the notification can be displayed via one or more output devices <b>160</b> (e.g., display screen, speaker, etc.) of the person authentication system <b>100</b>. It should be appreciated that the notification can include at least one of an audible or visual alert. In some implementations, the one or more output devices <b>160</b> can be positioned at the entrance to the restricted area. In this manner, personnel posted at the entrance to the restricted area can determine whether to permit the person <b>102</b> wearing the earpiece <b>110</b> to enter the restricted area based, at least in part, on the notification.</p><p id="p-0037" num="0036">Referring now to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, components of the earpiece <b>110</b> are provided according to example embodiments of the present disclosure. As shown, the earpiece <b>110</b> can include a communication circuit <b>210</b> and an antenna <b>212</b>. In this manner the earpiece <b>110</b> can transmit and receive data. In some implementations, the communication circuit <b>210</b> can include a near-field communication circuit. The antenna <b>212</b> can, in some implementations, include an antenna having a fixed radiation pattern.</p><p id="p-0038" num="0037">In alternative implementations, the antenna can include a modal antenna configurable in a plurality of antenna modes. Furthermore, each of the plurality of antenna modes can have a distinct radiation pattern, polarization, or both. In some implementations, the modal antenna can be configured in different antenna modes based, at least in part, on a link quality (e.g., channel quality indicator) between the earpiece and a receiver (e.g., another earpiece, access point, base station). For instance, the modal antenna can be configured in different antenna modes as the person <b>102</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) navigates an area to steer the radiation pattern towards the receiver (e.g., other earpieces, access points, base stations) in the area. In this manner, a link quality (e.g., channel quality indicator) between the modal antenna and the receiver (e.g., other earpieces, access points, base stations, etc.) can be improved.</p><p id="p-0039" num="0038">The earpiece <b>110</b> can further include one or more transducers <b>220</b>. The one or more transducers <b>220</b> can be configured to convert an electrical signal to an audio signal. For instance, the electrical signal can be received via the antenna <b>212</b> and can be provided as an input to the one or more transducers <b>220</b>. The one or more transducers <b>220</b> can convert the electrical signal to output the audio signal. In this manner, audible noise associated with the audio signal can be provided to the ear <b>104</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) of the person <b>102</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>).</p><p id="p-0040" num="0039">The earpiece <b>110</b> can include one or more processors <b>230</b> configured to perform a variety of computer-implemented functions (e.g., performing the methods, steps, calculations and the like disclosed herein). As used herein, the term &#x201c;processor&#x201d; refers not only to integrated circuits referred to in the art as being included in a computer, but also refers to a controller, microcontroller, a microcomputer, a programmable logic controller (PLC), an application specific integrated circuit (ASIC), a Field Programmable Gate Array (FPGA), and other programmable circuits.</p><p id="p-0041" num="0040">The earpiece <b>110</b> can include a memory device <b>232</b>. Examples of the memory device <b>232</b> can include computer-readable media including, but not limited to, non-transitory computer-readable media, such as RAM, ROM, hard drives, flash drives, or other suitable memory devices. The memory device <b>232</b> can store information accessible by the one or more processors <b>230</b> including the unique identifier <b>234</b> associated with the earpiece <b>110</b>. The one or more processors <b>230</b> can access the memory device <b>232</b> to obtain the unique identifier <b>234</b>. For instance, in some implementations, the one or more processors <b>230</b> can be configured to generate a beacon signal that includes the unique identifier <b>234</b>. Furthermore, the one or more processors <b>230</b> can be further configured to transmit the beacon signal via the antenna <b>212</b>.</p><p id="p-0042" num="0041">In some implementations, the earpiece <b>110</b> can include one or more inertial sensors <b>240</b> configured to obtain data indicative of motion of the earpiece <b>110</b>. For instance, in some implementations, the one or more inertial sensors <b>240</b> can include an accelerometer. The accelerometer can be configured to obtain data indicative of acceleration of the earpiece <b>110</b> along one or more axes. Alternatively, or additionally, the one or more inertial sensors <b>240</b> can include a gyroscope. The gyroscope can be configured to obtain data indicative of orientation of the earpiece <b>110</b>. Additionally, the gyroscope can be configured to obtain data indicative of angular velocity of the earpiece <b>110</b>.</p><p id="p-0043" num="0042">Referring now to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, an image of the ear <b>104</b> without the earpiece <b>110</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>) is provided according to example embodiments of the present disclosure. As shown, the image is of the ear <b>104</b> of the person <b>102</b> (<figref idref="DRAWINGS">FIG. <b>1</b></figref>). The image of the ear <b>104</b> depicts an outer ear and an inner ear. The outer ear includes a portion of a periphery of the ear <b>104</b>. For instance, the outer ear can include a helix <b>302</b> of the ear <b>104</b>. Conversely, the inner ear can include one or more portions of the ear <b>104</b> that are closer to an entrance of a canal of the ear <b>104</b> than the outer ear (e.g., helix <b>302</b>). For instance, the inner ear can include, a scaphoid fossa <b>304</b> of the ear <b>104</b>, an antihelix <b>306</b> of the ear <b>104</b>, an antitragus <b>308</b> of the ear <b>104</b>, a lobule <b>310</b> of the ear <b>104</b>, a concha cavum <b>312</b> of the ear <b>104</b>, a concha cymba <b>314</b> of the ear <b>104</b>, an inferior crus <b>316</b> of the ear <b>104</b>, a triangular fossa <b>318</b> of the ear <b>104</b>, and a superior crus <b>320</b> of the ear <b>104</b>.</p><p id="p-0044" num="0043">Referring now to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a flow diagram of a method <b>400</b> of authenticating a person is provided according to example embodiments of the present disclosure. In general, the method <b>400</b> will be discussed herein with reference to the person authentication system <b>100</b> described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In addition, although <figref idref="DRAWINGS">FIG. <b>4</b></figref> depicts steps performed in a particular order for purposes of illustration and discussion, the method discussed herein is not limited to any particular order or arrangement. One skilled in the art, using the disclosure provided herein, will appreciate that various steps of the method disclosed herein can be omitted, rearranged, combined, and/or adapted in various ways without deviating from the scope of the present disclosure.</p><p id="p-0045" num="0044">At (<b>402</b>), the method <b>400</b> can include obtaining, by a computing system having one or more computing devices, data indicative of a unique identifier associated with an earpiece worn by a person. In some implementations, the data indicative of the unique identifier can be included in one or more signals (e.g., beacon signal) transmitted by the earpiece. Furthermore, in some implementations, the one or more signals can be transmitted to the computing system via a network. Still further, in some implementations, the one or more signals can be transmitted to the computing system via the network when the person is within a predetermined proximity (e.g., about <b>15</b> feet) of an entrance to a restricted area.</p><p id="p-0046" num="0045">At (<b>404</b>), the method <b>400</b> can include obtaining, by the computing system, image data of an ear of the person. For instance, obtaining image data can include obtaining one or more images of the ear. In some implementations, the one or more images can include an image of the outer ear of the person. As will be discussed below, identity of the person wearing the earpiece can be authenticated based, at least in part, on one or more anatomical features associated with the outer ear of the person.</p><p id="p-0047" num="0046">At (<b>406</b>), the method <b>400</b> can include authenticating, by the computing system, an identity of the person wearing the earpiece based, at least in part, on unique identifier obtained at (<b>402</b>) and the image data obtained at (<b>404</b>). For instance, authenticating the identity of the person wearing the earpiece can include determining, by the computing system, whether the person wearing the earpiece is the person to whom the earpiece was issued. Furthermore, in some implementations, authenticating the identity of the person can include authenticating the identity of the person based, at least in part on, one or more anatomical features of the outer ear and one or more anatomical features of the inner ear.</p><p id="p-0048" num="0047">At (<b>408</b>), the method <b>400</b> can include determining, by the computing system, whether the person wearing the earpiece is permitted to access the restricted area the person is attempting to enter. For instance, determining whether the person wearing the earpiece is permitted to access the restricted area can include, for instance, accessing, by the computing system, a database storing data that is indicative of persons permitted to access the restricted area. In some implementations, the data stored in the database can include a list of persons that are permitted to access the restricted area. It should be understood, however, that the data can be stored in the database in any suitable format.</p><p id="p-0049" num="0048">At (<b>410</b>), the method <b>400</b> can include providing, by the computing system, a notification indicative of whether the person wearing the earpiece is permitted to access the restricted area. For instance, in some implementations, providing the notification can include providing, by the computing system, the notification for display on the one or more output devices located at an entrance to the restricted area. It should be understood that the notification can include at least one of an audible alert or a visual alert.</p><p id="p-0050" num="0049">Referring now to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, a flow diagram of a process for authenticating the identity of the person wearing the earpiece the person at (<b>406</b>) of the method <b>400</b> discussed above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref> is provided according to an example embodiment of the present disclosure. As shown, authenticating the identity of the person wearing the earpiece can include, at (<b>502</b>) determining the identity of the person to whom the earpiece was issued based, at least in part, on the data indicative of the unique identifier obtained at (<b>402</b>) of the method <b>400</b> discussed with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>. In some implementations, determining the identity of the person to whom the earpiece was issue can include determining, by the computing system, one of the plurality of persons as the person associated with the earpiece can include accessing, by the computing system, a database storing data that associates each of the plurality of persons to a different earpiece based, at least in part, on the unique identifier associated with each earpiece. In this, manner, the computing system can match the unique identifier associated with the earpiece worn by the person to one of the plurality of persons to determine the identity (e.g., name) of the person to whom the earpiece was issued.</p><p id="p-0051" num="0050">The process for authenticating the identity of the person wearing the earpiece at (<b>406</b> of the method <b>400</b> discussed above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref> can include, at (<b>504</b>), classifying, by the computing system, the image data obtained at (<b>404</b>) of the method <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> to determine an image classification. For instance, classifying the image data to determine an image classification can include providing, by the computing system, the image data as an input to one or more machine-learned image classifier models. The one or more machine-learned image classifier models can process the image data to provide the image classification of the image data as an output of the one or more machine-learned image classifier models.</p><p id="p-0052" num="0051">In some implementations, the one or more machine-learned image classifier models can be configured to determine the image classification for the image data based, at least in part, on one or more anatomical features of the ear of the person wearing the earpiece. For instance, the one or more machine-learned image classifier models can be configured to determine the image classification based, at least in part, on one or more anatomical features of the outer ear of the person wearing the earpiece. It should be appreciated that the one or more anatomical features can include, for instance, the size and/or shape of various portions of the outer ear of the person wearing the earpiece.</p><p id="p-0053" num="0052">The process for authenticating the identity of the person wearing the earpiece at (<b>406</b> of the method <b>400</b> discussed above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref> can include, at (<b>506</b>), authenticating, by the computing system, the identity of the person wearing the earpiece based, at least in part, on the image classification determined at (<b>504</b>). For instance, in some implementations, authenticating the identity of the person wearing the earpiece based, at least in part, on the image classification can include determining, by the computing system, the person wearing the earpiece is not the person to whom the earpiece was issued. In alternative implementations, authenticating the identity of the person wearing the earpiece based, at least in part, on the image classification can include determining, by the computing system, the person wearing the earpiece is the person to whom the earpiece was issued.</p><p id="p-0054" num="0053">Referring now to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a flow diagram of a process for authenticating the identity of the person wearing the earpiece the person at (<b>406</b>) of the method <b>400</b> discussed above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref> is provided according to an example embodiment of the present disclosure. As shown, authenticating the identity of the person wearing the earpiece can include, at (<b>602</b>) determining the identity of the person to whom the earpiece was issued based, at least in part, on the data indicative of the unique identifier obtained at (<b>402</b>) of the method <b>400</b> discussed with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0055" num="0054">The process for authenticating the identity of the person wearing the earpiece at (<b>406</b> of the method <b>400</b> discussed above with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref> can include, at (<b>604</b>), obtaining image data of the ear of the person to whom the earpiece was issued. For instance, obtaining image data of the ear of the person to whom the earpiece was issued can include accessing, by the computing system, a database configured to store image data of the ear of each of a plurality persons to whom an earpiece was issued.</p><p id="p-0056" num="0055">At (<b>606</b>), the process of authenticating the identity of the person wearing the earpiece can include comparing, by the computing system, the image data of the ear of the person wearing the earpiece and the image data of the ear of the person to whom the earpiece was issued. The computing system can be configured to determine whether one or more anatomical features of the ear of the person wearing the earpiece correspond to one or more anatomical features of the ear of the person to whom the earpiece was issued.</p><p id="p-0057" num="0056">In some implementations, the computing system can be configured to determine whether one or more anatomical features of the outer ear of the person wearing the earpiece correspond to one or more anatomical features of the outer ear of the person to whom the earpiece was assigned. For example, the computing system can be configured to determine whether a portion (e.g., helix, antihelix, triangular fossa etc.) of the outer ear of the person wearing the earpiece matches the corresponding portion of the outer ear of the person to whom the earpiece was issued.</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates suitable components of the computing system <b>140</b> according to example embodiments of the present disclosure. As shown, the computing system <b>140</b> can include one or more computing devices <b>700</b>. The one or more computing devices <b>700</b> can include one or more processors <b>702</b> configured to perform a variety of computer-implemented functions (e.g., performing the methods, steps, calculations and the like disclosed herein). As used herein, the term &#x201c;processor&#x201d; refers not only to integrated circuits referred to in the art as being included in a computer, but also refers to a controller, microcontroller, a microcomputer, a programmable logic controller (PLC), an application specific integrated circuit (ASIC), a Field Programmable Gate Array (FPGA), and other programmable circuits. As shown, the computing system <b>140</b> can include a memory device <b>704</b>. Examples of the memory device <b>704</b> can include computer-readable media including, but not limited to, non-transitory computer-readable media, such as RAM, ROM, hard drives, flash drives, or other suitable memory devices. The memory device <b>704</b> can store information accessible by the one or more processors <b>702</b> including computer-readable instructions <b>706</b> that can be executed by the one or more processors <b>702</b>. The computer-readable instructions <b>706</b> can be any set of instructions that, when executed by the one or more processors <b>702</b>, cause the one or more processors <b>702</b> to perform operations associated with authenticating the identity of the person wearing the earpiece. The computer-readable instructions <b>706</b> can be software written in any suitable programming language or can be implemented in hardware. In some implementations, the computing system <b>140</b> can include one or more classifier models <b>708</b>. For example, the one or more classifier models <b>708</b> can include various machine-learned models, such as a random forest classifier; a logistic regression classifier; a support vector machine; one or more decision trees; a neural network; and or other types of machine-learned models, including both linear models and non-linear models. Example neural networks can include feed-forward neural networks, recurrent neural networks (e.g., long short-term memory recurrent neural networks), or other forms of neural networks.</p><p id="p-0059" num="0058">In some implementations, the computing system <b>140</b> can train the one or more classifier models <b>708</b> through use of a model trainer <b>710</b>. The model trainer <b>710</b> can train the one or more classifier models <b>708</b> using one or more training or learning algorithms. One example training technique is backwards propagation of errors (&#x201c;backpropagation&#x201d;). For example, backpropagation can include Levenberg-Marquardt backpropagation. In some implementations, the model trainer <b>710</b> can perform supervised training techniques using a set of labeled training data. In other implementations, the model trainer <b>710</b> can perform unsupervised training techniques using a set of unlabeled training data. The model trainer <b>710</b> can perform a number of generalization techniques to improve the generalization capability of the models being trained. Generalization techniques include weight decays, dropouts, or other techniques.</p><p id="p-0060" num="0059">In particular, the model trainer <b>710</b> can train the one or more classifier models <b>708</b> based on a set of training data <b>712</b>. The training data <b>712</b> can includes a number of training examples. Each training example can include example images of the ear (e.g., inner portion, outer portion) of different persons. In this manner, the one or more classifier models <b>708</b> can learn to classify the different images of the ear. <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example embodiment of a modal antenna <b>800</b> according to the present disclosure. The modal antenna <b>800</b> can, for instance, be used in the earpiece <b>110</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>). For instance, the antenna <b>212</b> (<figref idref="DRAWINGS">FIG. <b>2</b></figref>) of the earpiece <b>110</b> can include the modal antenna <b>800</b>. The modal antenna can be configurable in a plurality of antenna modes. Each of the antenna modes can have a distinct radiation pattern, polarization, or both. The modal antenna <b>800</b> can be configured in different antenna modes based, at least in part, on a link quality (e.g., channel quality indicator) between the earpiece and another device (e.g., other earpiece, access point, base station) to steer the radiation pattern of the modal antenna <b>800</b> towards the device. In this manner, the antenna mode of the modal antenna <b>800</b> can be adjusted as needed to maintain the communication link between the earpiece and another device as the user navigates an area.</p><p id="p-0061" num="0060">As shown, the driven element <b>804</b> of the modal antenna <b>800</b> can be disposed on an circuit board <b>802</b>. An antenna volume may be defined between the circuit board <b>802</b> (e.g., and the ground plane) and the driven element <b>804</b>. The modal antenna <b>800</b> can include a first parasitic element <b>806</b> positioned at least partially within the antenna volume. The modal antenna <b>800</b> can further include a first tuning element <b>808</b> coupled with the first parasitic element <b>806</b>. The first tuning element <b>808</b> can be a passive or active component or series of components and can be configured to alter a reactance on the first parasitic element <b>806</b> either by way of a variable reactance or shorting to ground. It should be appreciated that altering the reactance of the first parasitic element <b>806</b> can result in a frequency shift of the modal antenna <b>800</b>. It should also be appreciated that the first tuning element <b>808</b> can include at least one of a tunable capacitor, MEMS device, tunable inductor, switch, a tunable phase shifter, a field-effect transistor, or a diode.</p><p id="p-0062" num="0061">In some implementations, the modal antenna <b>800</b> can include a second parasitic element <b>810</b> disposed adjacent the driven element <b>804</b> and outside of the antenna volume. The modal antenna <b>800</b> can further include a second tuning element <b>812</b>. In some implementations, the second tuning element <b>812</b> can be a passive or active component or series of components and may be configured to alter a reactance on the second parasitic element <b>810</b> by way of a variable reactance or shorting to ground. It should be appreciated that altering the reactance of the second parasitic element <b>810</b> can result in a frequency shift of the modal antenna <b>800</b>. It should also be appreciated that the second tuning element <b>812</b> can include at least one of a tunable capacitor, MEMS device, tunable inductor, switch, a tunable phase shifter, a field-effect transistor, or a diode.</p><p id="p-0063" num="0062">In some implementations, operation of at least one of the first tuning element <b>808</b> and the second tuning element <b>812</b> can be controlled to adjust (e.g., shift) the antenna radiation pattern of the driven element <b>804</b>. For example, a reactance of at least one of the first tuning element <b>808</b> and the second tuning element <b>812</b> can be controlled to adjust the antenna radiation pattern of the driven element <b>804</b>.</p><p id="p-0064" num="0063">Adjusting the antenna radiation pattern can be referred to as &#x201c;beam steering&#x201d;. However, in instances where the antenna radiation pattern includes a null, a similar operation, commonly referred to as &#x201c;null steering&#x201d;, can be performed to shift the null to an alternative position about the driven element <b>804</b> (e.g., to reduce interference). <figref idref="DRAWINGS">FIG. <b>9</b></figref> depicts antenna radiation patterns associated with the modal antenna <b>800</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref> according to example embodiments of the present disclosure. It should be appreciated that operation of at least one of the first parasitic element <b>806</b> and the second parasitic element <b>810</b> can be controlled to configure the modal antenna <b>800</b> in a plurality of modes. It should also be appreciated that the modal antenna <b>800</b> can have a distinct antenna radiation pattern or antenna polarization when configured in each of the plurality of modes.</p><p id="p-0065" num="0064">In some implementations, the modal antenna <b>800</b> can have a first antenna radiation pattern <b>900</b> when the modal antenna <b>800</b> is configured in a first mode of the plurality of modes. In addition, the modal antenna <b>800</b> can have a second antenna radiation pattern <b>902</b> when the modal antenna <b>800</b> is configured in a second mode of the plurality of modes. Furthermore, the modal antenna <b>800</b> can have a third antenna radiation pattern <b>904</b> when the modal antenna <b>800</b> is configured in a third mode of the plurality of modes. As shown, the first antenna radiation pattern <b>900</b>, the second antenna radiation pattern <b>902</b>, and the third antenna radiation pattern <b>904</b> can be distinct from one another. In this manner, the modal antenna <b>800</b> can have a distinct radiation pattern when configured in each of the first mode, second mode, and third mode.</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts an example frequency plot of the modal antenna <b>800</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref> according to some aspects of the present disclosure. It should be understood that an electrical characteristic (e.g., reactance) of at least one of the first parasitic element <b>806</b> and the second parasitic element <b>810</b> can be controlled. In this manner, the electrical characteristic of at least one of the first parasitic element <b>806</b> and the second parasitic element <b>810</b> can be adjusted to shift a frequency at which the modal antenna <b>800</b> is operating.</p><p id="p-0067" num="0066">In some implementations, the modal antenna <b>800</b> can be tuned to a first frequency f<sub>0 </sub>when the first parasitic element <b>806</b> and the second parasitic element <b>810</b> are deactivated (e.g., switched off). Alternatively, or additionally, the modal antenna <b>800</b> can be tuned to frequencies f<sub>L </sub>and f<sub>H </sub>when the second parasitic element <b>810</b> is shorted to ground. Furthermore, the modal antenna <b>800</b> can be tuned to frequency f<sub>4 </sub>when both the first parasitic element <b>806</b> and the second parasitic element <b>810</b> are shorted to ground. Still further, the modal antenna <b>800</b> can be tuned to frequencies f<sub>4 </sub>and f<sub>0 </sub>when the first parasitic element <b>806</b> and the second parasitic element <b>810</b> are each shorted to ground. It should be understood that other configurations are within the scope of this disclosure. For example, more or fewer parasitic elements may be employed. The positioning of the parasitic elements may be altered to achieve additional modes that may exhibit different frequencies and/or combinations of frequencies.</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIGS. <b>8</b>-<b>10</b></figref> depict one example modal antenna having a plurality of modes for purposes of illustration and discussion. Those of ordinary skill in the art, using the disclosures provided herein, will understand that other modal antennas and/or antenna configurations can be used without deviating from the scope of the present disclosure. As used herein a &#x201c;modal antenna&#x201d; refers to an antenna capable of operating in a plurality of modes where each mode is associated with a distinct radiation pattern.</p><p id="p-0069" num="0068">While the present subject matter has been described in detail with respect to specific example embodiments thereof, it will be appreciated that those skilled in the art, upon attaining an understanding of the foregoing may readily produce alterations to, variations of, and equivalents to such embodiments. Accordingly, the scope of the present disclosure is by way of example rather than by way of limitation, and the subject disclosure does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method of authenticating a person, the method comprising:<claim-text>obtaining, by a computing system comprising one or more computing devices, data indicative of a unique identifier associated with an earpiece worn by a person;</claim-text><claim-text>obtaining, by the computing system, image data of an ear of the person; and</claim-text><claim-text>authenticating, by the computing system, an identity of the person based, at least in part, on the image data and the data indicative of the unique identifier.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein obtaining image data of the ear of the person comprises obtaining, by the computing system, one or more images of an outer ear.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein obtaining image data of the ear of the person comprises obtaining, by the computing system, one or more images of an inner ear, the inner ear being closer to an entrance of a canal of the ear than an outer ear.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein obtaining image data of the ear of the person comprises obtaining, by the computing system, one or more images of an outer ear and an inner ear, the inner ear being closer to an entrance of a canal of the ear than the outer ear.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein authenticating the identity of the person comprises authenticating, by the computing system, the identity based, at least in part, on one or more anatomical features of the outer ear and one or more anatomical features of the inner ear.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein obtaining data indicative of a unique identifier associated with an earpiece worn by a person comprises obtaining, by the computing system, one or more signals from a near-field communication circuit located in the earpiece.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein authenticating the identity of the person comprises:<claim-text>determining, by the computing system, one of a plurality of persons as a person associated with the earpiece based, at least in part, on the data indicative of the unique identifier; and</claim-text><claim-text>determining, by the computing system, whether the person is the person associated with the earpiece based, at least in part, on the image data.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein determining whether the person is the person associated with the earpiece comprises:<claim-text>classifying, by the computing system, the image data of the ear to determine an image classification; and</claim-text><claim-text>authenticating, by the computing system, the identity of the person based on the image classification.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the unique identifier comprises a medium access control (MAC) address.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein obtaining image data of an ear of the person occurs when the person is at an entrance to an area.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, further comprising:<claim-text>responsive to authenticating the identity of the person, determining, by the computing system, whether the person is permitted to access an area based, at least in part, on the identity of the person.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>providing, by the computing system, a notification indicative of whether the person is permitted to access the area.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A person authentication system comprising:<claim-text>one or more image capture devices; and</claim-text><claim-text>a computing system comprising one or more computing devices, the computing system configured to perform operations comprising:<claim-text>obtaining data indicative of a unique identifier associated with an earpiece worn by a person;</claim-text></claim-text><claim-text><claim-text>obtaining image data of an ear of the person via the one or more image capture devices; and</claim-text><claim-text>authenticating an identity of the person based, at least in part, on the image data and the data indicative of the unique identifier.</claim-text></claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The person authentication system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the image data comprises one or more images of an outer ear and an inner ear, the inner ear being closer to an entrance of a canal of the ear than the outer ear.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The person authentication system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the operation of authenticating the identity of the person comprises authenticating the identity of the person based, at least in part, on one or more anatomical features of the outer ear and one or more anatomical features of the inner ear.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The person authentication system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the operation of authenticating the identity of the person comprises:<claim-text>determining one of a plurality of persons as a person associated with the earpiece based, at least in part, on the data indicative of the unique identifier; and</claim-text><claim-text>determining whether the person is the person associated with the earpiece based, at least in part, on the image data.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The person authentication system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein determining whether the person is the person associated with the earpiece comprises:<claim-text>comparing image data of the ear of the person to image data of an ear of the person associated with the earpiece; and</claim-text><claim-text>authenticating the identity of the person when the image data of the ear of the person corresponds to the image data of the ear of the person associated with the earpiece.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The person authentication system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the one or more image capture devices are positioned at an entrance to a restricted area.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The person authentication system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein obtaining data indicative of the unique identifier associated with the earpiece comprises obtaining one or more signals from the earpiece when the person is within a predetermined proximity of the entrance of the area.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The person authentication system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the operation of obtaining data indicative of the unique identifier comprises obtaining a beacon signal transmitted from an antenna of the earpiece.</claim-text></claim></claims></us-patent-application>
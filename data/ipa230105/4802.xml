<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004803A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004803</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17939057</doc-number><date>20220907</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>01</class><subclass>L</subclass><main-group>45</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>45</main-group><subgroup>1206</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>45</main-group><subgroup>142</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>45</main-group><subgroup>143</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>45</main-group><subgroup>144</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>45</main-group><subgroup>14</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>45</main-group><subgroup>16</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">RECONFIGURABLE MEMTRANSISTORS, FABRICATING METHODS AND APPLICATIONS OF SAME</invention-title><us-related-documents><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>17036428</doc-number><date>20200929</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17939057</doc-number></document-id></child-doc></relation></continuation-in-part><continuation-in-part><relation><parent-doc><document-id><country>US</country><doc-number>16770662</doc-number><date>20200608</date></document-id><parent-status>PENDING</parent-status><parent-pct-document><document-id><country>WO</country><doc-number>PCT/US2018/065929</doc-number><date>20181217</date></document-id></parent-pct-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17036428</doc-number></document-id></child-doc></relation></continuation-in-part><us-provisional-application><document-id><country>US</country><doc-number>63245997</doc-number><date>20210920</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62908841</doc-number><date>20191001</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>62599946</doc-number><date>20171218</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NORTHWESTERN UNIVERSITY</orgname><address><city>Evanston</city><state>IL</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>THE BOARD OF TRUSTEES OF THE UNIVERSITY OF ILLINOIS</orgname><address><city>Urbana</city><state>IL</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Hersam</last-name><first-name>Mark C.</first-name><address><city>Wilmette</city><state>IL</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Yuan</last-name><first-name>Jiangtan</first-name><address><city>Evanston</city><state>IL</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Liu</last-name><first-name>Stephanie E.</first-name><address><city>Evanston</city><state>IL</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Sangwan</last-name><first-name>Vinod K.</first-name><address><city>Evanston</city><state>IL</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Trivedi</last-name><first-name>Amit R.</first-name><address><city>Oak Park</city><state>IL</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">This invention relates to memtransistors, fabricating methods and applications of the same. The memtransistor includes a polycrystalline monolayer film of an atomically thin material. The polycrystalline monolayer film is grown directly on a sapphire substrate and transferred onto an SiO<sub>2</sub>/Si substrate; and a gate electrode defined on the SiO<sub>2</sub>/Si substrate; and source and drain electrodes spatially-apart formed on the polycrystalline monolayer film to define a channel region in the polycrystalline monolayer film therebetween. The gate electrode is capacitively coupled with the channel region.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="213.78mm" wi="158.75mm" file="US20230004803A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="233.68mm" wi="162.73mm" file="US20230004803A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="188.64mm" wi="162.90mm" file="US20230004803A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="229.79mm" wi="133.86mm" file="US20230004803A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="168.74mm" wi="155.11mm" orientation="landscape" file="US20230004803A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="178.73mm" wi="138.26mm" orientation="landscape" file="US20230004803A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="202.69mm" wi="107.87mm" orientation="landscape" file="US20230004803A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="212.77mm" wi="111.84mm" orientation="landscape" file="US20230004803A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="200.74mm" wi="121.33mm" orientation="landscape" file="US20230004803A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="147.66mm" wi="130.05mm" orientation="landscape" file="US20230004803A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="219.79mm" wi="97.62mm" orientation="landscape" file="US20230004803A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="191.77mm" wi="139.02mm" orientation="landscape" file="US20230004803A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="225.21mm" wi="98.55mm" orientation="landscape" file="US20230004803A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED PATENT APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority to and the benefit of U.S. Provisional Application No. 63/245,997, filed Sep. 20, 2021, which is incorporated herein in its entirety by reference.</p><p id="p-0003" num="0002">This application is also a continuation-in-part application of U.S. application Ser. No. 17/036,428, filed Sep. 29, 2020, which itself claims priority to and the benefit of U.S. Provisional Application Ser. No. 62/908,841, filed Oct. 1, 2019, which are incorporated herein in its entireties by reference.</p><p id="p-0004" num="0003">This application is also a continuation-in-part application of U.S. application Ser. No. 16/770,662, filed Jun. 8, 2020, which is a U.S. national stage application of PCT Application No. PCT/US2018/065929, filed Dec. 17, 2018, which itself claims priority to and the benefit of U.S. Provisional Application No. 62/599,946, filed Dec. 18, 2017, which are incorporated herein in their entireties by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?federal-research-statement description="Federal Research Statement" end="lead"?><heading id="h-0002" level="1">STATEMENT AS TO RIGHTS UNDER FEDERALLY-SPONSORED RESEARCH</heading><p id="p-0005" num="0004">This invention was made with government support under 1720139 and 1542205 awarded by the National Science Foundation, and DE-NA0003525 awarded by the Department of Energy. The government has certain rights in the invention.</p><?federal-research-statement description="Federal Research Statement" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0003" level="1">FIELD OF THE INVENTION</heading><p id="p-0006" num="0005">The present invention generally relates to material science, particularly to reconfigurable memtransistors for continuous learning in spiking neural networks, fabricating methods, and applications of the same.</p><heading id="h-0004" level="1">BACKGROUND OF THE INVENTION</heading><p id="p-0007" num="0006">The background description provided herein is to present the context of the invention generally. The subject matter discussed in the background of the invention section should not be assumed to be prior art merely due to its mention in the background of the invention section. Similarly, a problem mentioned in the background of the invention section or associated with the subject matter of the background of the invention section should not be assumed to have been previously recognized in the prior art. The subject matter in the background of the invention section merely represents different approaches, which in and of themselves may also be inventions. Work of the presently named inventors, to the extent it is described in the background of the invention section, as well as aspects of the description that may not otherwise qualify as prior art at the time of filing, are neither expressly nor impliedly admitted as prior art against the invention.</p><p id="p-0008" num="0007">Exponential improvement in solid-state digital electronics over the past several decades has led to an array of modern ubiquitous technologies such as the Internet of Things, edge computing, artificial intelligence (AI), and machine learning (ML) that are impacting nearly all aspects of society. Recent progress in AI/ML has been primarily driven by software improvements exemplified by the DeepMind AlphaGo program that defeated a world champion in the game of Go. However, running AI/ML algorithms on conventional von Neumann hardware platforms results in substantial energy consumption, which is orders of magnitude higher than that of the human brain. AI/ML hardware accelerators based on neuromorphic architectures are being actively pursued using memristors, phase change memory, and synaptic transistors to improve energy efficiency. These devices imitate specific biological responses, such as synaptic plasticity, where the conductance state is modified by a temporal relation between pre-synaptic and post-synaptic neuron spikes. However, synaptic plasticity in biology is more complex than current neuromorphic demonstrations and involves more than two neurons to regulate the strength of synaptic connections. Therefore, to better mimic complex biological synapses, three-terminal neuromorphic devices have emerged to improve energy efficiency, linearity, and reconfigurability.</p><p id="p-0009" num="0008">In parallel with advances in neuromorphic device concepts, two-dimensional (2D) materials have attracted significant attention as a platform for next-generation electronics. The atomic-level thickness of 2D materials imparts weak screening that allows strong electrostatic tunability and reconfigurability of device responses. For example, monolayer polycrystalline MoS<sub>2 </sub>memtransistors have achieved gate-tunable memristive switching. The memtransistor is a promising building block for next-generation bio-realistic neuromorphic systems by co-locating memory and transistor functionality. Dual-gated MoS<sub>2 </sub>memtransistors also minimize crosstalk and sneak currents in scalable crossbar architectures, thus simplifying integration challenges that have hindered memristive architectures based on bulk materials. Despite the unique attributes of memtransistors, their implementation in neuromorphic architectures has been limited to standard artificial neural networks, suggesting that their full potential for AI/ML has not yet been realized.</p><p id="p-0010" num="0009">Therefore, a heretofore unaddressed need exists in the art to address the aforementioned deficiencies and inadequacies.</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><p id="p-0011" num="0010">In one aspect, this invention relates to a memtransistor. The memtransistor comprises a polycrystalline monolayer film of an atomically thin material, wherein the polycrystalline monolayer film is grown directly on a first substrate and transferred onto a second substrate; and a gate electrode defined on the second substrate; and source and drain electrodes spatially-apart formed on the polycrystalline monolayer film to define a channel region in the polycrystalline monolayer film therebetween, wherein the gate electrode is capacitively coupled with the channel region.</p><p id="p-0012" num="0011">In one embodiment, the atomically thin material comprises two-dimensional (2D) semiconductor material.</p><p id="p-0013" num="0012">In one embodiment, the 2D semiconductor material comprises MoS<sub>2</sub>, MoSe<sub>2</sub>, WS<sub>2</sub>, WSe<sub>2</sub>, InSe, GaTe, black phosphorus (BP), or related two-dimensional materials.</p><p id="p-0014" num="0013">In one embodiment, the polycrystalline monolayer film of MoS<sub>2 </sub>has well-defined grain boundaries, sub-stoichiometric S:Mo ratio, and predominantly monolayer coverage.</p><p id="p-0015" num="0014">In one embodiment, the first substrate is formed of sapphire, quartz, graphene, or hexagonal boron nitride.</p><p id="p-0016" num="0015">In one embodiment, the second substrate is an SiO<sub>2</sub>/Si substrate, or an substrate of a high-k dielectric layer including Al<sub>2</sub>O<sub>3 </sub>or HfO<sub>2</sub>.</p><p id="p-0017" num="0016">In one embodiment, the SiO<sub>2</sub>/Si substrate comprises a silicon substrate with a silicon dioxide overlayer.</p><p id="p-0018" num="0017">In one embodiment, the gate, source, and drain electrodes comprise a same conductive material or different conductive materials.</p><p id="p-0019" num="0018">In one embodiment, the polycrystalline monolayer film of MoS<sub>2 </sub>has well-defined grain boundaries, sub-stoichiometric S:Mo ratio, and predominantly monolayer coverage.</p><p id="p-0020" num="0019">In one embodiment, the memtransistor is reconfigurable with gate tunability that enables continuous learning that allows selective forgetting of inessential tasks, thus freeing up neural resources to learn new tasks.</p><p id="p-0021" num="0020">In one embodiment, by growing the polycrystalline monolayer film grown directly on the sapphire, quartz, graphene, or hexagonal boron nitride substrate, lattice defects in the polycrystalline monolayer film are reduced and the crystallographic registry is improved, thereby enabling accentuation of the vertical field effect from the gate compared to drain bias induced resistive switching, and heightening reconfigurability of a synaptic learning behavior from long-term potentiation (LTP) to long-term depression (LTD).</p><p id="p-0022" num="0021">In one embodiment, the LTP and the LTD are controlled by the gate bias polarity and not the drain pulse polarity, which parallels biological systems' synaptic weight update and neuroplasticity.</p><p id="p-0023" num="0022">In one embodiment, by mimicking the biological systems, LTP/LTD tuning is achieved by biasing the gate without changing the polarity of drain pulses.</p><p id="p-0024" num="0023">In one embodiment, additional learning behaviors are achieved by varying the temporal evolution of gate bias pulses.</p><p id="p-0025" num="0024">In one embodiment, the gate pulses are used to modulate potentiation and depression, resulting in diverse learning curves and simplified spike-timing-dependent plasticity that facilitate unsupervised learning in a simulated spiking neural network (SNN).</p><p id="p-0026" num="0025">In one embodiment, a library of learning curves obtained from temporal evolution of the pulsing amplitude is used to perform unsupervised image recognition in the SNN with functions of continuous learning.</p><p id="p-0027" num="0026">In one embodiment, the unsupervised learning in the SNN is performed using an experimental memtransistor learning behavior modeled in a simplified spike-timing-dependent plasticity (STDP) scheme.</p><p id="p-0028" num="0027">In another aspect, the invention relates to a circuit comprising one or more memtransistors as disclosed above.</p><p id="p-0029" num="0028">In yet another aspect, the invention relates to an electronic device comprising one or more memtransistors as disclosed above.</p><p id="p-0030" num="0029">In a further aspect, the invention relates a system for continuous learning in a spiking neural network, comprising one or more synaptic units, wherein each synaptic unit comprises one or more memtransistors as disclosed above.</p><p id="p-0031" num="0030">In one embodiment, each synaptic unit has learning and/or unlearning behaviors, with the gate-tunable characteristics of the memtransistors.</p><p id="p-0032" num="0031">In one embodiment, switching LTP-LTD learning behavior is achieved by only reversing the polarity of the gate pulses, while further adjustments in the gate amplitude produced diverse learning curves and thus learning behaviors.</p><p id="p-0033" num="0032">In one aspect, the invention relates a method for fabricating a memtransistor, comprising growing a polycrystalline monolayer film of an atomically thin material on a first substrate; transferring the polycrystalline monolayer film to a second substrate; and forming a gate electrode on the second substrate and source and drain electrodes on the grown polycrystalline monolayer film, wherein the source and drain electrodes define a channel region in the polycrystalline monolayer film therebetween, and wherein the gate electrode is capacitively coupled with the channel region.</p><p id="p-0034" num="0033">In one embodiment, the first substrate is formed of sapphire, quartz, graphene, or hexagonal boron nitride.</p><p id="p-0035" num="0034">In one embodiment, the second substrate is an SiO<sub>2</sub>/Si substrate, or an substrate of a high-k dielectric layer including Al<sub>2</sub>O<sub>3 </sub>or HfO<sub>2</sub>.</p><p id="p-0036" num="0035">In one embodiment, the polycrystalline monolayer film is grown by chemical vapor deposition (CVD) on the substrates.</p><p id="p-0037" num="0036">In one embodiment, said transferring comprises coating a polymer film on the polycrystalline monolayer film grown on the first substrate; separating the polymer film with the polycrystalline monolayer film from the first substrate; adhering the separated polymer film with the polycrystalline monolayer film to the second substrate; and removing the polymer film.</p><p id="p-0038" num="0037">In one embodiment, the polymer film is formed of polycarbonate (PC).</p><p id="p-0039" num="0038">In one embodiment, said forming is performed by photolithography.</p><p id="p-0040" num="0039">In one embodiment, the atomically thin material comprises 2D semiconductor material.</p><p id="p-0041" num="0040">In one embodiment, the 2D semiconductor material comprises MoS<sub>2</sub>, MoSe<sub>2</sub>, WS<sub>2</sub>, WSe<sub>2</sub>, InSe, GaTe, BP, or related two-dimensional materials.</p><p id="p-0042" num="0041">These and other aspects of the present invention will become apparent from the following description of the preferred embodiment taken in conjunction with the following drawings, although variations and modifications therein may be affected without departing from the spirit and scope of the novel concepts of the invention.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0043" num="0042">The accompanying drawings illustrate one or more embodiments of the invention and together with the written description, serve to explain the principles of the invention. Wherever possible, the same reference numbers are used throughout the drawings to refer to the same or like elements of an embodiment.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows MoS<sub>2 </sub>memtransistor device architecture and characteristics according to embodiments of the invention. Panel a: Schematic of a MoS<sub>2 </sub>memtransistor on a SiO<sub>2</sub>/Si substrate that was fabricated following transfer of CVD MoS<sub>2 </sub>from the sapphire growth substrate. Inset: Optical image of memtransistor devices with channel length of 5&#x3bc;m and channel width of 100 &#x3bc;m. MoS<sub>2 </sub>films are highlighted by the dotted rectangles. Scale bar: 100 &#x3bc;m. Panel b: Gate-dependent pinched hysteretic loops of the MoS<sub>2 </sub>memtransistor. Black arrows indicate the switching directions. Panel c: Atomic force microscopy topography image (left) shows the MoS<sub>2 </sub>film as predominantly monolayer. Lateral force microscopy image (right) reveals the grain boundaries of the polycrystalline MoS<sub>2 </sub>film with grain size 4 &#x3bc;m<sup>2</sup>. Scale bars: 1 &#x3bc;m. X-ray photoelectron spectra of Mo and S (bottom), resulting in a calculated ratio of S:Mo of about 1.82. Panel d: Gate and drain bias pulse scheme used for long-term potentiation (LTP) and long-term depression (LTD) characterization. For a fixed V<sub>D </sub>bias polarity, negative V<sub>G </sub>results in LTP (gray region) and positive V<sub>G </sub>results in LTD (blue region). V<sub>D </sub>pulse width is 50 ms, and V<sub>G </sub>pulse width is 2000 ms. Panel e: Conductance as a function of pulse number for different gate biases. All drain pulses are 80 V. Panel f: The amplitude of the LTP and LTD curves is modulated as a function of the magnitude of V<sub>G</sub>.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows spiking neural network architecture and simulations according to embodiments of the invention. Panel a: In the preprocessing step, 60,000 digits from the MNIST handwritten digit dataset were used for training. Each digit was composed of 784 grayscale pixels, which were one-to-one mapped to input neurons in the network, defining the input neuron (N=784) layer in the two-layer network. Panel b: The two-layer spiking neural network consisted of the input neuron layer connected to the output neuron layer of M neurons with 784&#xd7;M synaptic connections. The grayscale intensity of each pixel (e.g., #376-380 from panel a) corresponded to the frequency of applied input pulses (black), where black pixels (e.g., #378) yielded higher frequency pulse trains (i.e., higher neuron firing rate). When the internal state of an output neuron exceeded a threshold, a spiking event was induced, followed by an applied output pulse (blue). Panel c: The time window in which the spiking events of the input and output neurons occur affected the weight update of the respective synaptic connections. If the difference in applied voltage within the defined time window exceeded a positive (negative) voltage threshold, the synaptic connections connected to the spiking input and output neurons experienced potentiation (depression) and a positive (negative) change in synaptic weight. Panel d: STDP learning rules were used to train, classify, and test the two-layer model. The normalized conductance maps from output neuron M1 as a function of digits trained highlight the direct correlation between training and recognition rate. Panel e: Normalized conductance (G) maps for 5 out of 200 output neurons after training with 0, 60, 600, 6,000, and 60,000 digits. These images are weight maps of the inferred digits of the respective output neuron determined by STDP spiking rules. Panel f: Digit recognition rate as a function of training digits for varying numbers of output neurons. Panel g: Recognition rate as a function of the number of output neurons.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows tuning the learning behavior of MoS2 memtransistors through gate voltage bias modulation according to embodiments of the invention. Panel a: Gate programming pulse train (equal amplitude) that results in learning curve 1. Panel b: Gate programming pulse train (staircase followed by equal amplitude) that results in learning curve 2. Panel c: A stepwise gate modulation sequence from high to low magnitude (left) results in a relatively larger change in conductance in the initial steps followed by rapid saturation for both LTP and LTD (right). Panel d: A mixture of constant potentiation pulses with stepwise depression pulses (left) results in a gradual and symmetric concave learning behavior (right). Panel e: Inverting the stepwise gate modulation sequence from low to high magnitude (left) results in a concave learning response (right). Source/drain programming pulses are 80 V in all cases.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows continuous learning with MoS2 memtransistors according to embodiments of the invention. Panel a: Network architecture for continuous learning consisting of 10 output neurons and H hidden neurons divided into group A and group B with H/2 neurons in each group. Panel b: Since neurons in both groups A and B were trained for Task-1 using the same memtransistor learning curve 1, STDP normalized conductance maps of neurons in both groups show robust learning of the handwritten digits 0 and 1. Panel c: Before mapping Task-2 on weights connected to neurons in group B, those synapses were trained to first unlearn Task-1 by applying memtransistor learning curve 2. Meanwhile, the original learning in group A was essentially unaffected. Panel d: During subsequent training of the network with Task-2, some of the synaptic connections stemming from group A tried to learn digits 3 and 4 but their learning was significantly suppressed due to lateral inhibition from group B neurons, and thus overall knowledge of Task-1 is retained. Panel e: A similar phenomenon occurs in the group B neurons, wherein Task-2 training caused synaptic connections to rigorously learn digits 3 and 4, but retention of Task-1 was further attenuated. Panel f: Recognition accuracies for Task 1, Task 2, and their average as a function of the number of training epochs during the unlearning process of synapses for group B neurons. For fewer Unlearning Epochs, the residual knowledge of Task-1 on group B synapses is significant enough to degrade the Task-2 efficiency due to fewer effective number of neurons. On the other hand, with increasing Unlearning Epochs, the number of neurons contributing to Task-1 and Task-2 each approach H/2, improving the average accuracy.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows schematic depiction of the transfer process according to embodiments of the invention. Monolayer MoS<sub>2 </sub>film grown on sapphire is first spin-coated with PC (polycarbonate), and then lifted with PC in an aqueous solution. Subsequently, PC/MoS<sub>2 </sub>is transferred on a clean SiO<sub>2</sub>/Si substrate, followed by PC polymer removal in chloroform solution to obtain the MoS<sub>2 </sub>film on SiO<sub>2</sub>/Si.</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows (panel a) characteristic monolayer Raman peaks of MoS<sub>2 </sub>with spacing between E<sub>2g </sub>and A<sub>1g</sub>&#x2248;20 cm<sup>&#x2212;1</sup>, and (panel b) PL spectrum of monolayer MoS<sub>2 </sub>centered at 1.88 eV.</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows (panel a) lateral force microscopy image, and (panel b) trace/retrace curves for the grain boundary marked by the dotted line in panel a, according to embodiments of the invention.</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows sulfur vacancy-induced defect levels that are close to the conduction band of MoS<sub>2 </sub>according to embodiments of the invention. At zero gate bias (panel a), the sulfur vacancies are positively charged. When a negative (positive) gate bias is applied as shown in panel b (panel c), the Fermi level of MoS<sub>2 </sub>will be lower (higher), leaving the vacancy levels empty (occupied) and the sulfur vacancies will be more (less) positively charged.</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows cycle-to-cycle variation of a memtransistor device according to embodiments of the invention. The device shows a stable response after 1,000 pulses.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows data from a total of 28 devices according to embodiments of the invention. Panel a: Initial conductance has a mean value of 64.1 nS, with maximum and minimum conductance of 65.7 nS and 61.9 nS, respectively. Panel b: After 20 pulses, the conductance has a mean value of 102.9 nS, with maximum and minimum conductance being 134 nS and 76.5 nS, respectively. Panel c: The on/off ratio has a mean value of 160.5%, with maximum and minimum conductance of 204% and 121%, respectively.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows conductance maps from other output neurons display all MNIST digits 0-9 for various training digits according to embodiments of the invention.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>12</b></figref> demonstrates selective learning-unlearning (i.e., continuous learning) using the two-layer SNN network according to embodiments of the invention. Panel a: Resulting recognition rate as a function of training digits when an interrupted model (represented by panel a of <figref idref="DRAWINGS">FIG. <b>3</b></figref>) is injected with new learning parameters from another model (represented by panel b of <figref idref="DRAWINGS">FIG. <b>3</b></figref>). Increased training with more digits gradually decreases recognition rate, rather than resetting the device array, highlighting the selective (un)learning capability. Panel b: Conductance maps after training the network under Learning Curve 1 (top row) and 2 (bottom row) from panels a-b of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, after the exercise described in panel a.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION OF THE INVENTION</heading><p id="p-0056" num="0055">The invention will now be described more fully hereinafter with reference to the accompanying drawings, in which exemplary embodiments of the invention are shown. However, this invention may be embodied in many different forms and should not be construed as limited to the embodiments set forth herein. Rather, these embodiments are provided so that this specification will be thorough and complete and fully convey the invention's scope to those skilled in the art. Like reference numerals refer to like elements throughout.</p><p id="p-0057" num="0056">The terms used in this specification generally have their ordinary meanings in the art, within the context of the invention, and in the specific context where each term is used. Certain terms used to describe the invention are discussed below, or elsewhere in the specification, to provide additional guidance to the practitioner regarding the description. For convenience, certain terms may be highlighted, for example using italics and/or quotation marks. The use of highlighting has no influence on the scope and meaning of a term; the scope and meaning of a term are the same, in the same context, whether or not it is highlighted. It will be appreciated that same thing can be said in more than one way. Consequently, alternative language and synonyms may be used for any one or more of the terms discussed herein, nor is any special significance to be placed upon whether or not a term is elaborated or discussed herein. Synonyms for certain terms are provided. A recital of one or more synonyms does not exclude the use of other synonyms. The use of examples anywhere in this specification including examples of any terms discussed herein is illustrative only, and in no way limits the scope and meaning of the invention or of any exemplified term. Likewise, the invention is not limited to various embodiments given in this specification.</p><p id="p-0058" num="0057">It will be understood that, as used in the description herein and throughout the claims that follow, the meaning of &#x201c;a&#x201d;, &#x201c;an&#x201d;, and &#x201c;the&#x201d; includes plural reference unless the context clearly dictates otherwise. Also, it will be understood that when an element is referred to as being &#x201c;on&#x201d; another element, it can be directly on the other element or intervening elements may be present therebetween. In contrast, when an element is referred to as being &#x201c;directly on&#x201d; another element, there are no intervening elements present. As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items.</p><p id="p-0059" num="0058">It will be understood that, although the terms first, second, third, etc. may be used herein to describe various elements, components, regions, layers and/or sections, these elements, components, regions, layers and/or sections should not be limited by these terms. These terms are only used to distinguish one element, component, region, layer or section from another element, component, region, layer or section. Thus, a first element, component, region, layer or section discussed below could be termed a second element, component, region, or section without departing from the invention's teachings.</p><p id="p-0060" num="0059">Furthermore, relative terms, such as &#x201c;lower&#x201d; or &#x201c;bottom&#x201d; and &#x201c;upper&#x201d; or &#x201c;top,&#x201d; may be used herein to describe one element's relationship to another element as illustrated in the figures. It will be understood that relative terms are intended to encompass different orientations of the device in addition to the orientation depicted in the figures. For example, if the device in one of the figures. is turned over, elements described as being on the &#x201c;lower&#x201d; side of other elements would then be oriented on &#x201c;upper&#x201d; sides of the other elements. The exemplary term &#x201c;lower&#x201d;, can, therefore, encompasses both an orientation of &#x201c;lower&#x201d; and &#x201c;upper,&#x201d; depending on the particular orientation of the figure. Similarly, if the device in one of the figures is turned over, elements described as &#x201c;below&#x201d; or &#x201c;beneath&#x201d; other elements would then be oriented &#x201c;above&#x201d; the other elements. Therefore, the exemplary terms &#x201c;below&#x201d; or &#x201c;beneath&#x201d; can encompass both an orientation of above and below.</p><p id="p-0061" num="0060">It will be further understood that the terms &#x201c;comprises&#x201d; and/or &#x201c;comprising,&#x201d; or &#x201c;includes&#x201d; and/or &#x201c;including&#x201d; or &#x201c;has&#x201d; and/or &#x201c;having&#x201d;, or &#x201c;carry&#x201d; and/or &#x201c;carrying,&#x201d; or &#x201c;contain&#x201d; and/or &#x201c;containing,&#x201d; or &#x201c;involve&#x201d; and/or &#x201c;involving, and the like are to be open-ended, i.e., to mean including but not limited to. When used in this specification, they specify the presence of stated features, regions, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, regions, integers, steps, operations, elements, components, and/or groups thereof.</p><p id="p-0062" num="0061">Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this invention belongs. It will be further understood that terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and this specification, and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein.</p><p id="p-0063" num="0062">As used in this specification, &#x201c;around&#x201d;, &#x201c;about&#x201d;, &#x201c;approximately&#x201d; or &#x201c;substantially&#x201d; shall generally mean within 20 percent, preferably within 10 percent, and more preferably within 5 percent of a given value or range. Numerical quantities given herein are approximate, meaning that the term &#x201c;around&#x201d;, &#x201c;about&#x201d;, &#x201c;approximately&#x201d; or &#x201c;substantially&#x201d; can be inferred if not expressly stated.</p><p id="p-0064" num="0063">As used in this specification, the phrase &#x201c;at least one of A, B, and C&#x201d; should be construed to mean a logical (A or B or C), using a non-exclusive logical OR. As used herein, the term &#x201c;and/or&#x201d; includes any and all combinations of one or more of the associated listed items.</p><p id="p-0065" num="0064">The description below is merely illustrative in nature and is in no way intended to limit the invention, its application, or uses. The broad teachings of the invention can be implemented in a variety of forms. Therefore, while this invention includes particular examples, the true scope of the invention should not be so limited since other modifications will become apparent upon a study of the drawings, the specification, and the following claims. For purposes of clarity, the same reference numbers will be used in the drawings to identify similar elements. It should be understood that one or more steps within a method may be executed in a different order (or concurrently) without altering the principles of the invention.</p><p id="p-0066" num="0065">Artificial intelligence and machine learning are growing computing paradigms, but current algorithms incur undesirable energy costs on conventional silicon-based hardware, motivating the exploration of efficient neuromorphic architectures.</p><p id="p-0067" num="0066">One of the objectives of this invention is to provide a novel device concept in the class of three-terminal memtransistors with gate-tunable dynamic learning behavior. Unprecedented synaptic behavior is achieved by fabricating memtransistors from monolayer MoS<sub>2 </sub>grown on sapphire by chemical vapor deposition (CVD). Due to reduced lattice defects in CVD MoS<sub>2 </sub>grown on sapphire, the vertical field effect from the gate is enhanced compared to drain bias induced resistive switching, heightening the reconfigurability of the synaptic learning behavior from long-term potentiation (LTP) to long-term depression (LTD). Mimicking biological systems, LTP/LTD tuning is achieved by biasing the gate terminal without changing the polarity of drain terminal pulses. Furthermore, additional learning behaviors emerge by varying the temporal evolution of gate bias pulses. The resulting spike-timing-dependent plasticity facilitates unsupervised learning in simulated spiking neural networks (SNN). The gate tunability of these reconfigurable MoS<sub>2 </sub>memtransistors uniquely enables continuous learning, which is an underexplored cognitive concept that allows selective forgetting of inessential tasks, thus freeing up neural resources to learn new tasks. Overall, this invention demonstrates that the reconfigurability of memtransistors provides unique opportunities for energy-efficient artificial intelligence and machine learning.</p><p id="p-0068" num="0067">The previous reports that fabricate memristors, memtransistors, or similar resistive switching devices use polycrystalline monolayer MoS<sub>2 </sub>film grown directly on SiO<sub>2</sub>/Si for ease of fabrication, and do not use transferred MoS<sub>2 </sub>initially grown on sapphire wafers. Growing MoS<sub>2 </sub>on sapphire imparts crystalline registry to the film and reduced density of lattice defects that are responsible for resistive switching. Thus, in memtransistors fabricated from MoS<sub>2 </sub>grown on sapphire, the electric field from the gate has a disproportionally large effect compared to the lateral source-drain field, which incurs qualitative changes in the learning behavior from potentiation to depression. The library of learning curves obtained from temporal evolution of the pulsing amplitude can then be used to perform unsupervised image recognition in a simulated spiking neural network where the concept of continuous learning is demonstrated. An electronic device with potential applications in continuously evolving neural networks has not been demonstrated previously and thus the present reconfigurable MoS<sub>2 </sub>memtransistor solves this problem uniquely.</p><p id="p-0069" num="0068">In addition, current commercial solutions for brain-inspired neuromorphic hardware cannot adapt to dynamically varying application needs. For example, a neuromorphic chip intended for automated digit recognition cannot reconfigure itself on-demand to perform both digit recognition and character recognition, which is in stark contrast to real biological systems. Bridging this critical gap between artificial and natural intelligence, we demonstrate synaptic units that can learn and forget by the first demonstration of continuous learning by a solid-state electronic device, namely reconfigurable memtransistor devices using MoS<sub>2 </sub>grown on sapphire. Therefore, systems comprised of such synaptic units can assimilate new functionalities by replacing older (unused) functions. Our reconfigurable memtransistors can also dynamically reconfigure themselves to a diverse range of tasks over the device lifetime. This dynamic learning greatly enhances commercial opportunities for artificial intelligence hardware accelerators.</p><p id="p-0070" num="0069">More specifically, the invention relates to memtransistors, fabricating methods, and applications of the same.</p><p id="p-0071" num="0070">In one aspect of the invention, the memtransistor comprises a polycrystalline monolayer film of an atomically thin material, wherein the polycrystalline monolayer film is grown directly on a first substrate and transferred onto a second substrate; and a gate electrode defined on the second substrate; and source and drain electrodes spatially-apart formed on the polycrystalline monolayer film to define a channel region in the polycrystalline monolayer film therebetween, wherein the gate electrode is capacitively coupled with the channel region.</p><p id="p-0072" num="0071">In one embodiment, the atomically thin material comprises two-dimensional (2D) semiconductor material.</p><p id="p-0073" num="0072">In one embodiment, the 2D semiconductor material comprises MoS<sub>2</sub>, MoSe<sub>2</sub>, WS<sub>2</sub>, WSe<sub>2</sub>, InSe, GaTe, black phosphorus (BP), or related two-dimensional materials.</p><p id="p-0074" num="0073">In one embodiment, the polycrystalline monolayer film of MoS<sub>2 </sub>has well-defined grain boundaries, sub-stoichiometric S:Mo ratio, and predominantly monolayer coverage.</p><p id="p-0075" num="0074">In one embodiment, the first substrate is formed of sapphire, quartz, graphene, or hexagonal boron nitride.</p><p id="p-0076" num="0075">In one embodiment, the second substrate is an SiO<sub>2</sub>/Si substrate, or an substrate of a high-k dielectric layer including Al<sub>2</sub>O<sub>3 </sub>or HfO<sub>2</sub>.</p><p id="p-0077" num="0076">In one embodiment, the SiO<sub>2</sub>/Si substrate comprises a silicon substrate with a silicon dioxide overlayer.</p><p id="p-0078" num="0077">In one embodiment, the gate, source and drain electrodes comprise a same conductive material or different conductive materials.</p><p id="p-0079" num="0078">In one embodiment, the memtransistor is reconfigurable with gate tunability that enables continuous learning that allows selective forgetting of inessential tasks, thus freeing up neural resources to learn new tasks.</p><p id="p-0080" num="0079">In one embodiment, by growing the polycrystalline monolayer film grown directly on the sapphire, quartz, graphene, or hexagonal boron nitride substrate, lattice defects in the polycrystalline monolayer film are reduced and the crystallographic registry is improved, thereby enabling accentuation of the vertical field effect from the gate compared to drain bias induced resistive switching, and heightening reconfigurability of a synaptic learning behavior from long-term potentiation (LTP) to long-term depression (LTD). It should be noted that other substrates can also be utilized to practice the invention if a similar reduction in defect density can be achieved.</p><p id="p-0081" num="0080">In one embodiment, the LTP and the LTD are controlled by the gate bias polarity and not the drain pulse polarity, which parallels the synaptic weight update and neuroplasticity in biological systems.</p><p id="p-0082" num="0081">In one embodiment, by mimicking the biological systems, LTP/LTD tuning is achieved by biasing the gate without changing the polarity of drain pulses.</p><p id="p-0083" num="0082">In one embodiment, additional learning behaviors are achieved by varying the temporal evolution of gate bias pulses.</p><p id="p-0084" num="0083">In one embodiment, the gate pulses are used to modulate potentiation and depression, resulting in diverse learning curves and simplified spike-timing-dependent plasticity that facilitate unsupervised learning in a simulated spiking neural network (SNN).</p><p id="p-0085" num="0084">In one embodiment, a library of learning curves obtained from temporal evolution of the pulsing amplitude is used to perform unsupervised image recognition in the SNN with functions of continuous learning.</p><p id="p-0086" num="0085">In one embodiment, the unsupervised learning in the SNN is performed using an experimental memtransistor learning behavior modeled in a simplified spike-timing-dependent plasticity (STDP) scheme.</p><p id="p-0087" num="0086">In another aspect, the invention relates a circuitry, comprising one or more memtransistors as disclosed above.</p><p id="p-0088" num="0087">In yet another aspect, the invention relates an electronic device, comprising one or more memtransistors as disclosed above.</p><p id="p-0089" num="0088">In a further aspect, the invention relates a system for continuous learning in a spiking neural network, comprising one or more synaptic units, wherein each synaptic unit comprises one or more memtransistors as disclosed above.</p><p id="p-0090" num="0089">In one embodiment, each synaptic unit has learning and/or unlearning behaviors, with the gate-tunable characteristics of the memtransistors.</p><p id="p-0091" num="0090">In one embodiment, switching LTP-LTD learning behavior is achieved by only reversing the polarity of the gate pulses, while further adjustments in the gate amplitude produced diverse learning curves and thus learning behaviors.</p><p id="p-0092" num="0091">In one aspect, the invention relates a method for fabricating a memtransistor, comprising growing a polycrystalline monolayer film of an atomically thin material on a first substrate; transferring the polycrystalline monolayer film to a second substrate; and forming a gate electrode on the second substrate and source and drain electrodes on the grown polycrystalline monolayer film, wherein the source and drain electrodes define a channel region in the polycrystalline monolayer film therebetween, and wherein the gate electrode is capacitively coupled with the channel region.</p><p id="p-0093" num="0092">In one embodiment, the first substrate is formed of sapphire, quartz, graphene, or hexagonal boron nitride.</p><p id="p-0094" num="0093">In one embodiment, the second substrate is an SiO<sub>2</sub>/Si substrate, or an substrate of a high-k dielectric layer including Al<sub>2</sub>O<sub>3 </sub>or HfO<sub>2</sub>.</p><p id="p-0095" num="0094">In one embodiment, the polycrystalline monolayer film is grown by chemical vapor deposition (CVD) on the substrates.</p><p id="p-0096" num="0095">In one embodiment, said transferring comprises coating a polymer film on the polycrystalline monolayer film grown on the first substrate; separating the polymer film with the polycrystalline monolayer film from the first substrate; adhering the separated polymer film with the polycrystalline monolayer film to the second substrate; and removing the polymer film.</p><p id="p-0097" num="0096">In one embodiment, the polymer film is formed of polycarbonate (PC).</p><p id="p-0098" num="0097">In one embodiment, said forming is performed by photolithography.</p><p id="p-0099" num="0098">In one embodiment, the atomically thin material comprises two-dimensional (2D) semiconductor material.</p><p id="p-0100" num="0099">In one embodiment, the 2D semiconductor material comprises MoS<sub>2</sub>, MoSe<sub>2</sub>, WS<sub>2</sub>, WSe<sub>2</sub>, InSe, GaTe, black phosphorus (BP), or related two-dimensional materials.</p><p id="p-0101" num="0100">Among other things, the invention has at least the following advantages.<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0101">Using polycrystalline, monolayer MoS<sub>2 </sub>grown directly on sapphire instead of SiO<sub>2</sub>/Si reduces lattice defects, enabling accentuation of the gate field effect in memtransistors.</li>        <li id="ul0002-0002" num="0102">Attenuated resistive switching from the reduced defect density enables gate-reconfigurable synaptic learning without changing the polarity of drain bias pulses, thus mimicking biological systems more realistically.</li>        <li id="ul0002-0003" num="0103">These reconfigurable MoS<sub>2 </sub>memtransistors allow the gate bias to change the learning behavior from LTP to LTD and vice versa in contrast to existing memristors and memtransistors.</li>        <li id="ul0002-0004" num="0104">Gate tunability of the learning curves from super-linear to sub-linear LTP and LTD enables unsupervised continuous learning in spiking neural networks where inessential tasks are forgotten selectively to free up resources for learning newer tasks.</li>    </ul>    </li></ul></p><p id="p-0102" num="0105">The invention may have widespread applications in neuromorphic computing, edge computing, artificial intelligence, machine learning, artificial neural networks, non-volatile memory, sensors, hardware accelerators, and the likes.</p><p id="p-0103" num="0106">These and other aspects of the invention are further described below. Without intent to limit the scope of the invention, exemplary instruments, apparatus, methods, and their related results according to the embodiments of the invention are given below. Note that titles or subtitles may be used in the examples for convenience of a reader, which in no way should limit the scope of the invention. Moreover, certain theories are proposed and disclosed herein; however, in no way they, whether they are right or wrong, should limit the scope of the invention so long as the invention is practiced according to the invention without regard for any particular theory or scheme of action.</p><heading id="h-0008" level="1">EXAMPLE</heading><heading id="h-0009" level="1">Reconfigurable MoS<sub>2 </sub>Memtransistors for Continuous Learning in Spiking Neural Networks</heading><p id="p-0104" num="0107">Artificial intelligence (AI) and machine learning (ML) are growing computing paradigms, but current algorithms incur undesirable energy costs on conventional hardware platforms, thus motivating the exploration of more efficient neuromorphic architectures.</p><p id="p-0105" num="0108">This example discloses a memtransistor with gate-tunable dynamic learning behavior. By fabricating memtransistors from monolayer MoS<sub>2 </sub>grown on sapphire, the relative importance of the vertical field effect from the gate is enhanced, thereby heightening reconfigurability of the device response. Inspired by biological systems, gate pulses are used to modulate potentiation and depression, resulting in diverse learning curves and simplified spike-timing-dependent plasticity that facilitate unsupervised learning in simulated spiking neural networks. This capability also enables continuous learning, which is a previously underexplored cognitive concept in neuromorphic computing. Overall, this work demonstrates that the reconfigurability of memtransistors provides unique hardware accelerator opportunities for energy efficient artificial intelligence and machine learning.</p><p id="p-0106" num="0109">Specifically, the range of learning behaviors of memtransistors is expanded through a combination of enhanced electrostatic control and tailored gate bias pulsing profiles. Utilizing monolayer MoS<sub>2 </sub>grown on sapphire, memtransistors are efficiently modulated by the gate electrode. Long-term potentiation (LTP) and long-term depression (LTD) are controlled by the gate bias polarity and not the drain pulse polarity, which parallels the synaptic weight update and neuroplasticity in biological systems. This unique capability imparted by 2D materials is leveraged to perform unsupervised learning in a simulated spiking neural network (SNN) using the experimental memtransistor learning behavior modelled in a simplified spike-timing-dependent plasticity (STDP) scheme. The experimental learning curves further enable undemonstrated unsupervised continuous learning in simulated SNNs, which circumvents traditional tradeoffs between image recognition accuracy and resource allocation. This proof-of-concept demonstration is crucial to developing lifelong learning capabilities in artificial intelligence (AI) and machine learning (ML) algorithms in addition to addressing catastrophic forgetting, which is a persistent challenge in neuromorphic computing that requires continuous, energy intensive task updates.</p><heading id="h-0010" level="2">Materials and Methods</heading><p id="p-0107" num="0110">Material growth: Continuous MoS<sub>2 </sub>films were synthesized by chemical vapor deposition (CVD) using molybdenum trioxide (Millipore-Sigma, 99.97% trace metals basis) and sulfur powder (Millipore-Sigma, 99.98% trace metals basis). Sapphire (&#x3c;0001&#x3e;, MTI Corporation) was used as the substrate for CVD growth. Prior to growth, the substrates were bath-sonicated for 10 min in acetone and 10 min in isopropyl alcohol, followed by deionized water rinsing and nitrogen drying. An oxygen plasma step was applied for 3 min at about 200 mTorr to further clean the substrates. Substrates were then placed in the middle of a 1-inch tube furnace (Lindberg/Blue), with 12 mg molybdenum trioxide and 150 mg sulfur positioned approximately 2 cm and 32 cm away from the substrates upstream. The tube furnace was purged with ultra-high purity Ar (99.99%) at 200 sccm for 10 min and flushed twice (increased pressure to 400 Torr and then pumped down to about 78 mTorr) to create an inert environment. The pressure was kept at 150 Torr at 25 sccm Ar for the remainder of the procedure. To begin the growth, the furnace was first heated to 150&#xb0; C. in 5 min and held at this temperature for 20 min, then ramped to 800&#xb0; C. at a rate of 12&#xb0; C./min and maintained for 20 min, followed by natural cooling. Meanwhile, sulfur power was heated up to 50&#xb0; C. for 5 min by a heating tape wrapped around the quartz tube and maintained at that temperature for 49 min, then further heating to 150&#xb0; C. at a rate of 4.5&#xb0; C./min and held for 23 min, and finally natural cooling to room temperature.</p><p id="p-0108" num="0111">Device fabrication: Synthesized MoS<sub>2 </sub>films on sapphire were transferred to silicon substrates with a 285 nm thick silicon dioxide overlayer. Polycarbonate (PC) solution was spin-coated on MoS<sub>2 </sub>on sapphire at 1600 rpm for 1 min. After heating the film at 100&#xb0; C. for 1 min, the sapphire substrate was submerged into a water bath. The PC film with MoS<sub>2 </sub>was then separated from sapphire due to the hydrophobic nature of PC film and floated on top of the water bath. A clean oxidized silicon substrate was used to scoop up the floated film. Heating the silicon substrate gradually from 80&#xb0; C. to 180&#xb0; C. in 30 minutes allowed the MoS<sub>2 </sub>film to adhere fully to the silicon substrate. Finally, the PC film was removed by a chloroform bath for 4 h, followed by isopropyl alcohol rinsing and nitrogen drying preceding device fabrication.</p><p id="p-0109" num="0112">MoS<sub>2 </sub>memtransistor devices were fabricated by standard photolithography. In the first step, to pattern metal electrodes, negative photoresist Futurrex NR-9 1000PY was spin-coated at 3,000 rpm for 40 s. The photoresist was baked at 150&#xb0; C. for 60 s and then exposed for 30 s under a 365 nm wavelength UV light for a dose of 390 mJ/cm<sup>2</sup>. The post-exposure bake was performed at 100&#xb0; C. for 60 s. Then, the patterns were developed by immersing the substrate in Futurrex resist developer RD 6 for 10 s. Subsequently, Ti/Au (5 nm/50 nm) was evaporated by thermal evaporation and the photoresist was lifted off by MicroChem resist Remover PG. Next, another step of photolithography was performed to define the channel region. Positive resist Microposit S1813 was spin-coated on the substrate at 4,000 rpm for 60 s and then baked at 100&#xb0; C. for 60 s. After exposing for 15 sat a dose of 35 mJ/cm<sup>2</sup>, the resist was developed in MF-319 for 60 s. Reactive ion etching using an Ar plasma was used to remove the exposed MoS<sub>2 </sub>film outside the channel region. Finally, the photoresist was lifted off by Remover PG.</p><p id="p-0110" num="0113">Spiking neuron network simulation: A simulated spiking neural network (SNN) was developed with Python 3.7 and the BRIAN 2.2 simulator package. A simplified spike-timing-dependent plasticity (STDP) learning model was used following previous reports. The MNIST (Modified National Institute of Standards and Technology) dataset of handwritten digits was used to train and test the two-layer neural network, which included one input layer of 784 input neurons and one output layer of M output neurons (M=10, 20, 50, 100, 200). The output neurons were modeled after the leaky-integrate-and-fire model in Equation (1), where t is time, &#x3c4;=1 (leak time constant), g=&#x3b3;=1 (multiplicative factor for leaky integrate and fire output neurons), and I<sub>input </sub>is the current resulting from resistance modulation of memtransistors connected to the output neurons (summation of the product of weights and internal state variable X for input neurons). The weights of the 784&#xd7;M synaptic connections were randomly initialized from a Gaussian distribution between 0 and 1, which represented the minimum and maximum normalized conductance.</p><p id="p-0111" num="0114">Linearity and symmetry of the device long-term potentiation and depression curves influenced the SNN weight update rule. This was achieved by fitting the learning curves against the STDP exponential models, as illustrated in Equations (2)-(3) where &#x3b1; and &#x3b2; designate learning rate and linearity fitting parameters, &#x3b4;G normalized conductance change, and subscripts p and m potentiation and depression. Notably, the equations do not specify an explicit time dependence, which may seem contrary to the fundamental basis of STDP. However, the simplified framework adopted here implies the time dependence through the exponential function, since repeated voltage pulses (i.e., large time window between input and output neuron spike events) are likely to evoke smaller changes in conductance than singular voltage pulses (i.e., smaller time window between input and output neuron spike events). The weight update scheme in the simulation also assumed that 784&#xd7;M synaptic weights were stored on the fabricated devices. Likewise, output neuron dynamics aided in network stability. Lateral inhibition resets the internal state variable (for each output neuron) to zero after an output neuron spiking event to prevent simultaneous spiking among neighboring output neurons. Furthermore, homeostasis corrected each input neuron firing threshold every 200 training digits to aid in network stability. In the corresponding Equation (4), X<sub>th </sub>is the threshold X internal state variable, &#x3b3;=5 (multiplicative factor to increase threshold modifications for homeostasis), A is the average spiking activity, and T=1/M (target activity to achieve equal firing rates in homeostasis). The simulation used 60,000 training digits and 10,000 testing MNIST digits to measure the recognition rate of the network and was run ten times for reproducibility.</p><p id="p-0112" num="0115">Alternate architectures like multilayer perceptron (MLP) networks were previously implemented to demonstrate the efficacy of memristive hardware and have reported recognition accuracies greater than 90%. While the recognition rates reported by the SNN were lower than those previous MLP reports, we emphasize that recognition rate is not the only figure of merit for neural networks. In this work, we highlight the unique capability of SNNs to conduct unsupervised continuous learning, a significant step in developing lifelong learning capabilities without forgoing energy considerations for neuromorphic computing. Here, key compositional differences between the two networks was briefly distinguished to clarify why SNN was used in this context. MLPs usually have fewer output neurons and layers than SNNs and use backpropagation and continuous activation functions (relying on multiply-and-accumulate summation functions) to propagate strictly spatial information. These methods are relatively straightforward to implement, but are also sensitive to noise and typically more power intensive. Due to these factors, MLPs are more suitable for supervised learning. SNNs in contrast are more structurally complex (with additional layers and input neurons, and thus synaptic connections), and communicate spatiotemporal information via spiking patterns of the input and output neurons, where past spiking history and timing affect such patterns. The bio-realistic STDP algorithm, which informs the frequency and timing of the spiking trains, consequently helps promote Hebbian learning in the connecting synapses. In the SNN, a homeostasis mechanism was also integrated into the structure where the threshold values of the internal states of the output neurons dynamically adjusted based on the activity of the neuron (i.e., the greater post-synaptic neuronal activity would lead to a gradual increase in the threshold X value). This added feature makes the network extremely robust against device-to-device variation and other non-idealities and noise, and thus more desirable for unsupervised learning.</p><p id="p-0113" num="0116">Furthermore, the concept presented in this work of the learning-unlearning capability in memtransistor devices for application to continuous learning can be generalized to other datasets, such as the recently devised dynamic analog to MNIST known as Neuromorphic-MNIST (NMNIST). The use of other datasets can often achieve improved recognition rates. However, we emphasize that recognition rate is not the chief figure of merit that distinguishes STDP-SNN from other neural networks, but rather the unique capability of unsupervised continuous learning that emerges from the integration of 2D memtransistors with SNNs. Additionally, more recent datasets (e.g., NMNIST) have not yet reached a standardized protocol in the literature, which complicates performance benchmarking. Consequently, we limited ourselves to the most established MNIST database in this work.</p><p id="p-0114" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mrow>       <mi>&#x3c4;</mi>       <mo>&#x2062;</mo>       <mfrac>        <mi>dX</mi>        <mi>dt</mi>       </mfrac>      </mrow>      <mo>+</mo>      <mi>gX</mi>     </mrow>     <mo>=</mo>     <mrow>      <mi>&#x3b3;</mi>      <mo>&#x2062;</mo>      <msub>       <mi>I</mi>       <mi>input</mi>      </msub>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00001-2" num="00001.2"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>&#x3b4;</mi>      <mo>&#x2062;</mo>      <msub>       <mi>G</mi>       <mi>p</mi>      </msub>     </mrow>     <mo>=</mo>     <mrow>      <msub>       <mi>&#x3b1;</mi>       <mi>p</mi>      </msub>      <mo>&#x2062;</mo>      <msup>       <mi>e</mi>       <mrow>        <mrow>         <mo>-</mo>         <msub>          <mi>&#x3b2;</mi>          <mi>p</mi>         </msub>        </mrow>        <mo>&#x2062;</mo>        <mfrac>         <mrow>          <mi>G</mi>          <mo>-</mo>          <msub>           <mi>G</mi>           <mi>min</mi>          </msub>         </mrow>         <mrow>          <msub>           <mi>G</mi>           <mi>max</mi>          </msub>          <mo>-</mo>          <msub>           <mi>G</mi>           <mi>min</mi>          </msub>         </mrow>        </mfrac>       </mrow>      </msup>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00001-3" num="00001.3"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>&#x3b4;</mi>      <mo>&#x2062;</mo>      <msub>       <mi>G</mi>       <mi>m</mi>      </msub>     </mrow>     <mo>=</mo>     <mrow>      <msub>       <mi>&#x3b1;</mi>       <mi>m</mi>      </msub>      <mo>&#x2062;</mo>      <msup>       <mi>e</mi>       <mrow>        <mrow>         <mo>-</mo>         <msub>          <mi>&#x3b2;</mi>          <mi>m</mi>         </msub>        </mrow>        <mo>&#x2062;</mo>        <mfrac>         <mrow>          <msub>           <mi>G</mi>           <mi>max</mi>          </msub>          <mo>-</mo>          <mi>G</mi>         </mrow>         <mrow>          <msub>           <mi>G</mi>           <mi>max</mi>          </msub>          <mo>-</mo>          <msub>           <mi>G</mi>           <mi>min</mi>          </msub>         </mrow>        </mfrac>       </mrow>      </msup>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>3</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths><maths id="MATH-US-00001-4" num="00001.4"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mfrac>      <msub>       <mi>dX</mi>       <mi>th</mi>      </msub>      <mi>dt</mi>     </mfrac>     <mo>=</mo>     <mrow>      <mi>&#x3b3;</mi>      <mo>&#x2061;</mo>      <mo>(</mo>      <mrow>       <mi>A</mi>       <mo>-</mo>       <mi>T</mi>      </mrow>      <mo>)</mo>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>4</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0115" num="0117">Continuous learning simulation: Similar to the setup above, the simulation framework for SNN-based continuous learning was developed using Python, BRIAN 2.0, and PyTorch packages. A three-layer network including an input-layer with N=784 neurons, a hidden-layer with H=200 neurons, and an output layer with M=10 neurons was used to classify MNIST handwritten digits in a continuous learning setup. While training the network, synaptic weights between the input neurons and hidden neurons were updated using unsupervised STDP learning following Equations (2)-(3). In contrast, the weights between hidden and output neurons were updated using supervised learning to automate the learning-digit association process. Meanwhile, the hidden layer was divided into group A and group B with H/2 neurons each. Such segregation of neurons in groups allowed dynamic programming of neurons in each group for either learning or unlearning. Selective learning/unlearning for neurons in group A and group B was achieved by using corresponding &#x3b1; and &#x3b2; from the learning curves in panels a-b of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Unlearning process is found to correlate with change in the sign change of &#x3b2; for potentiation curves used for learning (negative) and unlearning (positive) (refer to Equations (2)-(3) to observe how varying sign in &#x3b2; impacts degree of unlearning). We considered two-sets of digit recognition tasks (Task-1 and Task-2) to demonstrate suitability of our memtransistors for continuous learning. Task-1 consisted of 11,000 training images of digits 0 and 1, whereas Task-2 had 10,000 training images of digits 3 and 4. The slight discrepancy in the number of training images fed to the network defining Task-1 and Task-2 should have minimal impact on accuracy (refer to panel f of <figref idref="DRAWINGS">FIG. <b>2</b></figref> for network recognition accuracy dependence on number of training digits passed).</p><p id="p-0116" num="0118">Experimental setup: All electrical measurements were carried out in a vacuum probe station (Lakeshore CRX 4K) at a base pressure of 5&#xd7;10<sup>&#x2212;5 </sup>Torr. The DC voltage sweep, pulse potentiation/depression, and retention measurements were conducted using source meters (Keithley, 2400) and home-built LabVIEW programs.</p><heading id="h-0011" level="2">Results and Discussion</heading><p id="p-0117" num="0119">As shown in panel a of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>5</b></figref>, polycrystalline MoS<sub>2 </sub>films were grown on sapphire substrates by chemical vapor deposition (CVD) and transferred onto SiO<sub>2</sub>/Si substrates followed by photolithography to define the devices. The resulting memtransistors showed a strong response to applied gate biases as observed in panel b of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The polycrystalline MoS<sub>2 </sub>films were primarily monolayer with small areas of scattered second layer islands. Raman and photoluminescence spectra confirmed the predominantly monolayer nature of the MoS<sub>2 </sub>film, with spacing between the A<sub>1g </sub>and E<sub>2g </sub>Raman peaks of about 20 cm<sup>&#x2212;1 </sup>and a photoluminescence peak at 1.88 eV, in agreement with previous literature, as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. Grain boundaries in the polycrystalline film (grain size&#x2248;4 &#x3bc;m<sup>2</sup>) were visualized by comparing lateral force and atomic force microscopy images as illustrated in panel c of <figref idref="DRAWINGS">FIG. <b>1</b></figref> (see <figref idref="DRAWINGS">FIG. <b>7</b></figref> for trace-retrace lateral force curves). Analysis of X-ray photoelectron spectra yielded an S:Mo ratio of about 1.82, which is significantly less than the nominal stoichiometry ratio of 2, suggesting a significant concentration of sulfur vacancies and point defects, as shown in panel c of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. This combination of well-defined grain boundaries, sub-stoichiometric S:Mo ratio, and predominantly monolayer coverage was critical in realizing the memtransistor device characteristic.</p><p id="p-0118" num="0120">Program and read pulses were applied to the drain electrode with the source grounded. The resulting memristive response showed a strong gate dependence, where LTP and LTD were achieved by reversing the gate bias's polarity without changing the source-drain pulsing's polarity, as shown in panel e of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. To achieve this gate-tunable switching, the memtransistor response from the gate bias was enhanced relative to that from the source-drain bias. In particular, the memristive loop output curve was attenuated to provide a strong response to the gate bias, as shown in panel b of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Thus, CVD growth of polycrystalline MoS<sub>2 </sub>on sapphire substrates was critical compared to direct growth on SiO<sub>2</sub>/Si substrates. Sapphire substrates have previously been shown to reduce defect density and improve crystallographic registry for CVD-grown MoS<sub>2 </sub>films, which reduces the distribution of grain boundary angles. In this manner, at the same source-drain voltage, fewer defects participate in resistive switching, resulting in an attenuation of the memristive response and thus a relative increase in the influence of the gate modulation. The net effect is the ability to qualitatively change the learning behavior as a function of the gate voltage.</p><p id="p-0119" num="0121">Sulfur vacancies create defect states that can be filled/vacated with a change in the gate bias, as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, which further modulates the Schottky barrier at the source/drain electrodes. Previous switching in MoS<sub>2 </sub>memtransistors grown on SiO<sub>2 </sub>was attributed to tunable Schottky barrier height, resulting from defect migration or charge trapping near the source/drain contacts. Similarly, reduced Schottky barrier height drives the change from LTP to LTD with gate voltage, where a switching direction reversal occurred due to a change in the dominant Schottky diode direction at the drain contact.</p><p id="p-0120" num="0122">A representative pulsing scheme to achieve gate-tunable LTP and LTD is shown in panel d of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The gate voltage (V<sub>G</sub>) was held at a predetermined value for each program step while a voltage pulse was applied to the drain electrode (V<sub>D</sub>). During the subsequent reading step, V<sub>G </sub>was returned to a zero-bias state while a small V<sub>D </sub>was applied to read the device's non-volatile conductance (G) state. The combination of a positive V<sub>D </sub>and a negative V<sub>G </sub>resulted in LTP behavior, whereas the combination of a positive V<sub>D </sub>and a positive V<sub>G </sub>resulted in LTD behavior. The conductance change as a function of pulse number is depicted in panel e of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The conductance modulation for LTP (LTD) was visualized at negative (positive) V<sub>G</sub>, while the amplitude of the conductance modulation at V<sub>G</sub>=0 V was ten times smaller than that for V<sub>G</sub>=30 or &#x2212;30 V, as shown in panel e of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Furthermore, the amplitude of the conductance modulation increased by a factor of 4.5 as the gate voltage magnitude was increased from 10 V to 30 V, as shown in panel f of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. Memtransistor devices showed stable cycle-to-cycle behavior and small device-to-device variation about 20%, as shown in <figref idref="DRAWINGS">FIGS. <b>9</b>-<b>10</b></figref>. It is noted that the proof-of-concept devices according to embodiments of the invention used a large lateral geometry and thick (300 nm) dielectric layer, thus requiring relatively high operating voltages. However, it was recently reported that memtransistors can operate at sub-1 volt levels (source-drain terminal) with 20 fJ/bit level switching energy upon optimization of engineering controls during device fabrication. In addition, scaling of device dimensions (less than 500 nm channel length, width), grain size, and dielectric thickness, as well as high-&#x3ba; dielectric selection, can further reduce gate voltage and overall device footprint. Therefore, memtransistors do not present fundamental issues from a scaling or integration perspective and as such do not necessitate additional peripheral circuits.</p><p id="p-0121" num="0123">To explore the MoS<sub>2 </sub>memtransistor device response in neural networks, unsupervised image recognition learning tasks were performed by simulating a two-layer SNN operating on a simplified STDP algorithm. Previous multilayer perceptron demonstrations using backpropagation reported higher recognition accuracies using fewer neurons in supervised learning. However, as accuracy is not a critical figure of merit here, SNN is more appropriate for continuous and unsupervised learning by exploiting the gate-tunable characteristics of memtransistors to achieve bio-realistic STDP (un)learning functions. Panel a of <figref idref="DRAWINGS">FIG. <b>2</b></figref> conceptualizes the workflow setup using the widely accepted MNIST handwritten digits dataset. Experimental learning curves shown in panel f of <figref idref="DRAWINGS">FIG. <b>1</b></figref> were normalized and fitted with an STDP model to yield LTP and LTD parameters, which characterized the curves' learning rate, linearity, and symmetry and directly impacted the STDP weight update.</p><p id="p-0122" num="0124">Panel a of <figref idref="DRAWINGS">FIG. <b>2</b></figref> shows N=784 input neurons connected to =M leaky-integrate-and-fire output neurons (M=10 to 200) to directly map the 28&#xd7;28 pixel MNIST images. The weights of the 784&#xd7;M synaptic connections were randomly initialized from a normalized Gaussian distribution and included a built-in 20% noise window to simulate device-to-device variation and other non-idealities. The internal state variable X, analogous to neural membrane potential, was defined for input and output neurons to characterize spiking behavior. The pre-synaptic input neurons were initialized at X=0 and exhibited firing rates proportional to the grayscale intensity of the MNIST images (i.e., darker pixels would more likely induce spiking behavior). As such, a spiking pre-synaptic neuron would propagate its signal to the adjacent synaptic connection for 100 ms, as shown in leftmost panel b of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The X states for post-synaptic output neurons evolved with time following a leaky-integrate-and-fire model and homeostasis mechanism, which dynamically adjusted X values based on output spiking activity. To resemble the winner-take-all biological paradigm, an output neuron spiking event would reset all lateral output neurons to X=0 to inhibit simultaneous output neuron spiking. If the spike occurred (did not occur) within the temporal propagation delay from the input neuron spike, the connecting synapse would potentiate (depress). This relationship between frequency of spiking events and the STDP weight update is visualized with the spiking train pulses in panel c of <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0123" num="0125">After the network trained for 60,000 training MNIST digits, the output neurons were classified and tested against another set of 10,000 digits, resulting in the calculated recognition rates, as shown in panel d of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. Since learning was unsupervised, the classification step was necessary to conduct digit inference. Panels e-g of <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrate the direct relationship between recognition rate and the number of output neurons and training digits for the &#xb1;10 V learning curve from panel f of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. The conductance maps highlighted in panel e of <figref idref="DRAWINGS">FIG. <b>2</b></figref> and <figref idref="DRAWINGS">FIG. <b>11</b></figref> depict an arbitrary selection of output neurons during training as more digits are fed through. Each pixel map corresponds to individual synaptic connections mapped to that output neuron, where the color intensity is normalized weight conductance. The small error bars (less than 2%) in panels f-g of <figref idref="DRAWINGS">FIG. <b>2</b></figref> suggest sufficient convergence of the simplified STDP algorithm. Varying the gate modulation voltage from &#xb1;10 V to &#xb1;30 V did not noticeably affect the final recognition rate, indicating the robustness of the simulated architecture. Higher gate modulation voltage (e.g., &#xb1;30 V) would improve current resolution for practical applications, thereby further suppressing device or simulation non-idealities.</p><p id="p-0124" num="0126">Since LTP and LTD responses can be tuned by the magnitude of V<sub>G</sub>, qualitatively diverse learning curves can also be realized by varying the V<sub>G </sub>profile during constant V<sub>D </sub>pulsing (presented as square waves in panel d of <figref idref="DRAWINGS">FIG. <b>1</b></figref>). For example, the learning curve shown in panel b of <figref idref="DRAWINGS">FIG. <b>3</b></figref> differs from that of panel a of <figref idref="DRAWINGS">FIG. <b>3</b></figref> in its smooth initial change in concavity, which stems from the gradual increase in V<sub>G </sub>magnitude (panel b of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, left panel) during pulsing compared to a constant V<sub>G </sub>rate (panel a of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, left panel). When a stepwise gate modulation sequence in panel c of <figref idref="DRAWINGS">FIG. <b>3</b></figref> was applied from large V<sub>G </sub>magnitude to low V<sub>G </sub>magnitude (left panel), conductance increased significantly at initial steps followed by rapid saturation in both potentiation and depression (right panel). In contrast, a combination of constant and stepwise pulses resulted in a gradual, symmetric convex learning behavior, as shown in panel d of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Concave learning behavior was also achieved through a stepwise increase in V<sub>G </sub>magnitude, as shown in panel e of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The overall learning curve shape, especially in the potentiation branch, impacts the STDP learning network parameters, thereby influencing simulation behavior as learning or unlearning. The pulsing profile-learning curve shape relation informs design rules to selectively induce (un)learning-conducive behaviors solely based on the gate amplitude or rate of increase thereof. The gate-tunability of the learning curves themselves imply that memtransistor array functionality can be dynamically tuned without changing the underlying hardware, lending versatility and reconfigurability in 2D MoS<sub>2 </sub>memtransistors like in biological systems. This capability is especially desirable for applications where varying degrees of adaptability are useful such as online learning where weight updates are concurrent with live input of data.</p><p id="p-0125" num="0127">Dynamic modulation of synaptic weights opens opportunities for SNNs such as continuous learning, an emerging AI/ML framework that enables lifelong adaptation of learning systems in response to dynamic real-world conditions. Conventional AI/ML models learn and exceed human-level performance in certain tasks, although their inherent rigidity can lead to &#x201c;catastrophic forgetting&#x201d; of learned information while processing incoming information. Conversely, continuous learning models learn new tasks without forgetting older high-priority tasks, enabling flexibility to perform diverse AI/ML tasks on the same processing resource. Continuous learning models neuro-cognitive mechanisms in the human brain that are responsible for continually acquiring new knowledge by selectively unlearning and overwriting unused, insignificant knowledge. Therefore, under limited implementation resources, continuous learning models are compelling for AI/ML to unlearn lower priority knowledge to accommodate new task learning, which can be realized using tunable LTP and LTD memtransistor learning curves in a modified SNN.</p><p id="p-0126" num="0128">Panel a of <figref idref="DRAWINGS">FIG. <b>4</b></figref> presents the three-layer architecture including N input neurons, H hidden neurons equally divided into groups A and B, and 10 output neurons. Unsupervised continuous learning of the synapses using the STDP learning equations was conducted between the N input and H hidden neurons (conductance maps shown in panels b-e of <figref idref="DRAWINGS">FIG. <b>4</b></figref>). After continuous learning, a supervised backpropagation learning scheme between the hidden and output neurons automated the association of learned weights with the MNIST digits (i.e., calculation of accuracy). Similar to the previous setup, homeostasis and lateral inhibition were used for group A and B neurons to simulate competitive learning.</p><p id="p-0127" num="0129">Two recognition tasks were considered: Task-1 was to learn MNIST digits 0 and 1, and Task-2 was to learn MNIST digits 3 and 4. The synaptic platform was initially trained to perform Task-1 such that all H neurons were trained with training images of 0s and 1s using memtransistor learning curve 1, as shown in panel a of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. Panel b of <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows conductance maps for group A and B neurons after Task-1 training, revealing efficient learning of the digits 0 and 1. As on-field operations progressed, the network would ideally retain its knowledge of Task-1 and adapt to perform Task-2 under the same resources. Therefore, a subset of hidden neurons must partially forget Task-1 learning to accommodate new knowledge. To enable efficient dynamic task provisioning, group A synapses were allowed to retain knowledge of Task-1, while those for group B were trained to continuously forget Task-1 to free up allocation for Task-2. This outcome was achieved by applying different weight update rules to synapses linked to groups A and B during Task-1 training. Learning curve 1 was applied under the governing STDP equations to reinforce the knowledge stored in group A synapses, while learning curve 2 shown in panel b of <figref idref="DRAWINGS">FIG. <b>3</b></figref> was applied for group B synapses to gradually unlearn Task-1. Notably, this learning and unlearning does not require a change in hardware since the memtransistor learning curve shapes can be tuned with the gate voltage profile.</p><p id="p-0128" num="0130">Conductance maps in panel c of <figref idref="DRAWINGS">FIG. <b>4</b></figref> indicate that group A synapses retained their knowledge of Task-1, while those from group B do not. The total number of neurons associated with Task-1 became effectively less than H, resulting in overall Task-1 recognition degradation. Subsequently, as seen in panels d-e of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the network was trained with 3s and 4s for Task-2 learning using memtransistor learning curve 1 for synapses in both groups A and B. Group B synaptic weights consequently learned the digits 3 and 4 successfully, while some held residual information from Task-1. In parallel, although a few connections from group A attempted to learn digits 3 and 4 during Task-2 training, their learning was substantially suppressed from lateral inhibition from competing group B neurons. Overall, the group A weights remained largely unaffected during network training of Task-2 and maintained robust knowledge of Task-1.</p><p id="p-0129" num="0131">Panel f of <figref idref="DRAWINGS">FIG. <b>4</b></figref> describes the classification accuracy of Task-1 and Task-2 as a function of unlearning training epochs with respect to group B. The lower unlearning epochs limit pinpoints the competitive learning, wherein Group B synapses had higher residue and accuracy of Task-1, revealing that Task-1 effectively operated with more than H/2 neurons, while the learning space for Task-2 was constrained due to only a partial unlearning of the weights responsible for executing Task-1. The upper limit shows the convergence of an effective number of neurons for each task towards H/2. This analysis reveals the benefits of the continuous learning approach, particularly the tradeoff between target accuracy and allocated resource for each task. Consequently, an optimal number of &#x201c;Unlearning Epochs&#x201d; can be selected based on task priority. This observation, in addition to the material properties of polycrystalline, sub-stoichiometric, monolayer MoS<sub>2 </sub>grown on sapphire that enable reconfigurability by gate-tunable learning, underscores the need for synergistic design of materials, devices, and architectures to achieve bio-realistic functionality in neuromorphic hardware.</p><p id="p-0130" num="0132">In conclusion, the atomically thin and gate-tunable nature of 2D materials were leveraged to fabricate MoS<sub>2 </sub>memtransistors with gate-selective control of individual synapses for dynamic reconfigurability of synapses for unsupervised continuous learning. Monolayer MoS<sub>2 </sub>on sapphire was critical in enhancing the effect of the gate voltage in the memtransistor device response. Switching LTP-LTD learning behavior was achieved by only reversing the polarity of the gate potential, while further adjustments in the gate amplitude produced diverse learning curves and thus learning behaviors. The resulting learning and unlearning behaviors in a simulated STDP-SNN setup permitted dynamic reallocation of resources for different on-field tasks, thus demonstrating hardware implementation of continuous learning. Further efforts in 2D materials defect engineering, device fabrication optimization, and improved simulation methods are likely to further enhance neuromorphic performance and help realize the full potential of memtransistors as a reconfigurable platform for advanced neuromorphic functionality.</p><p id="p-0131" num="0133">The foregoing description of the exemplary embodiments of the invention has been presented only for the purposes of illustration and description and is not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations are possible in light of the above teaching.</p><p id="p-0132" num="0134">The embodiments were chosen and described to explain the principles of the invention and their practical application to enable others skilled in the art to utilize the invention and various embodiments and with various modifications as are suited to the particular use contemplated. Alternative embodiments will become apparent to those skilled in the art to which the invention pertains without departing from its spirit and scope. Accordingly, the scope of the invention is defined by the appended claims rather than the foregoing description and the exemplary embodiments described therein.</p><p id="p-0133" num="0135">Some references, which may include patents, patent applications, and various publications, are cited and discussed in the description of this invention. The citation and/or discussion of such references is provided merely to clarify the description of the invention and is not an admission that any such reference is &#x201c;prior art&#x201d; to the invention described herein. All references cited and discussed in this specification are incorporated herein by reference in their entireties and to the same extent as if each reference was individually incorporated by reference.</p><heading id="h-0012" level="1">LIST OF REFERENCES</heading><p id="p-0134" num="0000"><ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0136">[1]. Office of Science and Technology Policy. Science &#x26; technology highlights in the second year of the trump administration. https://www.whitehouse.gov/wp-content/uploads/2018/03/Science-and-Technology-Highlights-Report-from-the-1st-Year-of-the-Trump-Administration.pdf (accessed Feb. 11, 2020).</li>    <li id="ul0003-0002" num="0137">[2]. National Science Foundation. Statement on an executive order to maintain American leadership in artificial intelligence. https://www.nsf.gov/news/news_summ.jsp?cntn_id=297658 (accessed Feb. 11, 2020).</li>    <li id="ul0003-0003" num="0138">[3]. Silver, D.; Schrittwieser, J.; Simonyan, K.; Antonoglou, I.; Huang, A.; Guez, A.; Hubert, T.; Baker, L.; Lai, M.; Bolton, A.; Chen, Y.; Lillicrap, T.; Hui, F.; Sifre, L.; van den Driessche, G.; Graepel, T.; Hassabis, D. Mastering the game of Go without human knowledge. <i>Nature </i>2017, 550, 354-359.</li>    <li id="ul0003-0004" num="0139">[4]. Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; van der Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.; Dieleman, S.; Grewe, D.; Nham, J.; Kalchbrenner, N.; Sutskever, I.; Lillicrap, T.; Leach, M.; Kavukcuoglu, K.; Graepel, T.; Hassabis, D. Mastering the game of Go with deep neural networks and tree search. <i>Nature </i>2016, 529, 484-489.</li>    <li id="ul0003-0005" num="0140">[5]. J. Mattheij, J. Another way of looking at Lee Sedol vs AlphaGo. https://jacquesmattheij.com/another-way-of-looking-at-lee-sedol-vs-alphago/ (accessed Mar. 17, 2020).</li>    <li id="ul0003-0006" num="0141">[6]. Xia, Q.; Yang, J. J. Memristive crossbar arrays for brain-inspired computing. <i>Nat. Mater. </i>2019, 18, 309-323.</li>    <li id="ul0003-0007" num="0142">[7]. Merolla, P. A.; Arthur, J. V.; Alvarez-Icaza, R.; Cassidy, A. S.; Sawada, J.; Akopyan, F.; Jackson, B. L.; Imam, N.; Guo, C.; Nakamura, Y.; Brezzo, B.; Vo, I.; Esser, S. K.; Appuswamy, R.; Taba, B.; Amir, A.; Flickner, M. D.; Risk, W. P.; Manohar, R.; Modha, D. S. A million spiking-neuron integrated circuit with a scalable communication network and interface. <i>Science </i>2014, 345, 668-673.</li>    <li id="ul0003-0008" num="0143">[8]. Yang, J. J.; Pckett, M. D.; Li, X.; Ohlberg, D. A. A.; Stewart, D. R.; Williams, S. Memristive switching mechanism for metal/oxide/metal nanodevices. <i>Nat. Nano. </i>2008, 13, 429-433.</li>    <li id="ul0003-0009" num="0144">[9]. Jo, S. H.; Chang, T.; Ebong, I.; Bhadviya, B. B.; Mazumder, P.; Lu, W. Nanoscale memristor device as synapse in neuromorphic systems. <i>Nano Lett. </i>2010, 10, 1297-1301.</li>    <li id="ul0003-0010" num="0145">[10]. Zidan, M. A.; Strachan, J. P.; Lu, W. D. The future of electronics based on memristive systems. <i>Nat. Electron. </i>2018, 1, 22-29.</li>    <li id="ul0003-0011" num="0146">[11]. van de Burgt, Y.; Lubberman, E.; Fuller, E. J.; Keene, S. T.; Faria, G. C.; Agarwal, S.; Marinella, M. J.; Talin, A. A.; Salleo, A. A non-volatile organic electrochemical device as a low-voltage artificial synapse for neuromorphic computing. <i>Nat. Mater. </i>2017, 16, 414-418.</li>    <li id="ul0003-0012" num="0147">[12]. Yeon, H.; Lin, P.; Choi, C.; Tan, S. H.; Park, Y.; Lee, D.; Lee, J.; Xu, F.; Gao, B.; Wu, H.; Qian, H.; Nie, Y.; Kim, S.; Kim, J. Alloying conducting channels for reliable neuromorphic computing. <i>Nat. Nano. </i>2020, 15, 574-579.</li>    <li id="ul0003-0013" num="0148">[13]. van der Burgt, Y.; Melianas, A.; Keene, S. T.; Malliaras, G.; Salleo, A. Organic electronics for neuromorphic computing. <i>Nat. Electron. </i>2018, 1, 386-397.</li>    <li id="ul0003-0014" num="0149">[14]. Bear, M. F.; Connors, B. W.; Paradiso, M. A. Neuroscience: Exploring the Brain, 2<sup>nd </sup>ed.; Wolters Kluwer: Philadelphia, 2016.</li>    <li id="ul0003-0015" num="0150">[15]. Upadhyay, N. K.; Jiang, H.; Wang, Z.; Asapu, S.; Xia, Q.; Yang, J. J. Emerging memory devices for neuromorphic computing. <i>Adv. Mater. Technol. </i>2019, 4, 1800589.</li>    <li id="ul0003-0016" num="0151">[16]. Nishitani, Y.; Kaneko, Y.; Ueda, M.; Morie, T.; Fujii, E. Three-terminal ferroelectric synapse device with concurrent learning function for artificial neural networks. <i>J. Appl. </i>2012, 111, 124108.</li>    <li id="ul0003-0017" num="0152">[17]. Mennel, L.; Symonowicz, J.; Wachter, S.; Polyushkin, D. K.; Molina-Mendoza, A. J.; Mueller, T. Ultrafast machine vision with 2D material neural network image sensors. <i>Nature </i>2020, 579, 62-66.</li>    <li id="ul0003-0018" num="0153">[18]. Novoselov, K. S.; Mishchenko, A.; Carvalho, A.; Castro Neto, A. H. 2D materials and van der Waals heterostructures. <i>Science </i>2016, 353, aac9439-1-11.</li>    <li id="ul0003-0019" num="0154">[19]. Sangwan, V. K. and Hersam, M. C. Electronic transport in two-dimensional materials. <i>Annu. Rev. Phys. Chem. </i>2018, 69, 299.</li>    <li id="ul0003-0020" num="0155">[20]. Beck, M. E. and Hersam, M. C. Emerging opportunities for electrostatic control in atomically thin devices. <i>ACS Nano </i>2020 14, 6498-6518.</li>    <li id="ul0003-0021" num="0156">[21]. Sangwan, V. K.; Lee, H.-S.; Bergeron, H.; Balla, I.; Beck, M. E.; Chen, K.-S.; Hersam, M. C. Multi-terminal memtransistors from polycrystalline monolayer molybdenum disulfide. <i>Nature </i>2018, 554, 500-504.</li>    <li id="ul0003-0022" num="0157">[22]. Sangwan, V. K.; Hersam, M. C. Neuromorphic nanoelectronic materials. <i>Nat. Nanotechnol. </i>2020, 15, 517-528.</li>    <li id="ul0003-0023" num="0158">[23]. Beck, M. E.; Shylendra, A.; Sangwan, V. K.; Guo, S.; Rojas, W. A. G.; Yoo, H.; Bergeron, H.; Su, K.; Trivedi, A. R.; Hersam, M. C. Spiking neurons from tunable Gaussian heterojunction transistors. <i>Nat. Commun. </i>2020, 11, 1565.</li>    <li id="ul0003-0024" num="0159">[24]. Sangwan, V. K.; Jariwala, D.; Kim, I. S.; Chen, K. S.; Marks, T. J.; Lauhon, L. J.; Hersam, M. C. Gate-tunable memristive phenomena mediated by grain boundaries in single layer MoS<sub>2</sub><i>. Nat. Nano. </i>2015, 10, 403-406.</li>    <li id="ul0003-0025" num="0160">[25]. Lee, H.-S.; Sangwan, V. K.; Rojas, W. A. G.; Bergeron, H.; Jeong, H. Y.; Yuan, J.; Su, K.; Hersam, M. C. Dual-gated MoS<sub>2 </sub>memtransistor crossbar array. <i>Adv. Funct. Mater. </i>2020, 30, 2003683.</li>    <li id="ul0003-0026" num="0161">[26]. Lee, C.; Yan, H.; Brus, L. E.; Heinz, T. F.; Hone. J.; Ryu, S. Anomalous lattice vibrations of single- and few-layer MoS<sub>2</sub><i>. ACS Nano </i>2010, 4, 2695-2700.</li>    <li id="ul0003-0027" num="0162">[27]. Ling, X.; Lee, Y.-H.; Lin, Y.; Fang, W.; Yu, L.; Dresselhaus, M. S.; Kong, J. Role of the seeding promoter in MoS<sub>2 </sub>growth by chemical vapor deposition. <i>Nano Lett. </i>2014, 14, 464-472.</li>    <li id="ul0003-0028" num="0163">[28]. Laskar, M. R.; Ma, L.; Kannapan, S.; Park, P. S.; Krishnamoorthy, S.; Nath, D. N.; Lu, W.; Wu, Y.; Raja, S. Large area single crystal (0001) oriented MoS<sub>2</sub><i>. Appl. Phys. Lett. </i>2013, 102, 252108.</li>    <li id="ul0003-0029" num="0164">[29]. Esqueda, I. S.; Yan, X.; Rutherglen, C.; Kane, A.; Cain, T.; Marsh, P.; Liu, Q.; Galatsis, K.; Wang, H.; Zhou, C. Aligned carbon nanotube synaptic transistors for large-scale neuromorphic computing. <i>ACS Nano </i>2018, 12, 7352-7361.</li>    <li id="ul0003-0030" num="0165">[30]. Querlioz, D.; Bichler, O.; Dollfus, P.; Gamrat, C. Immunity to device variations in a spiking neural network with memristive nanodevices. <i>IEEE Trans. Nanotechnol. </i>2013, 12, 288-295.</li>    <li id="ul0003-0031" num="0166">[31]. Feng, X.; Li, S.; Wong, S. L.; Tong, S.; Chen, L.; Zhang, P.; Wang, L.; Fong, X.; Chi, D.; Ang, K.-W. Self-selective multi-terminal memtransistor crossbar array for in-memory computing. <i>ACS Nano </i>2021, 15, 1764-1774.</li>    <li id="ul0003-0032" num="0167">[32]. Hu, W.; Lin, Z.; Liu, B.; Tao, C.; Tao, Z.; Zhao, D.; Ma, J.; Yan, R. Overcoming catastrophic forgetting for continual learning via model adaptation. <i>ICLR </i>2019, 1.</li>    <li id="ul0003-0033" num="0168">[33]. Parisi, G. I.; Kemker, R.; Part, J. L.; Kanan, C.; Wertmer, S. Continual lifelong learning with neural networks: A review. <i>Neural Netw. </i>2019, 113, 54-71.</li>    <li id="ul0003-0034" num="0169">[34]. Aljundi, R.; Babiloni, F.; Elhoseiny, M.; Rohrbach, M.; Tuytelaars, T. Memory aware synapses: learning what (not) to forget. In: Ferrari V., Hebert M., Sminchisescu C., Weiss Y. (eds) Computer Vision&#x2014;ECCV 2018. ECCV 2018. Lecture Notes in Computer Science, Springer, Cham. 2018; vol 11207; p 144.</li>    <li id="ul0003-0035" num="0170">[35]. Zhou, W.; Zou, X.; Najmaei, S.; Liu, Z.; Shi, Y.; Kong, J.; Lou, J.; Ajayan, P.; Yakobson, B.; Idrobo, J.-C. Intrinsic Structural Defects in Monolayer Molybdenum Disulfide. <i>Nano Lett. </i>2013, 13, 2615-2622</li>    <li id="ul0003-0036" num="0171">[36]. Diehl, P. U.; Cook, M. Unsupervised Learning of Digit Recognition Using Spike-Timing-Dependent Plasticity. <i>Front. Comput. Neurosci. </i>2015, 9, 99.</li>    <li id="ul0003-0037" num="0172">[37]. Song, S. H.; Joo, M. K.; Neumann, M.; Kim, H.; Lee, Y. H. Probing Defect Dynamics in Monolayer MoS<sub>2 </sub>via Noise Nanospectroscopy. <i>Nat. Commun. </i>2017, 8, 2121.</li>    <li id="ul0003-0038" num="0173">[38]. Sanchez Esqueda, I. et al. <i>ACS Nano </i>12, 7352-7361 (2018)-DOI: 10.1021/acsnano.8b03831.</li>    <li id="ul0003-0039" num="0174">[39]. R. Stanley Williams, Jianhua Yang, Duncan Stewart, Semiconductor memristor devices, U.S. Pat. No. 8,450,711 B2, May 28, 2013.</li>    <li id="ul0003-0040" num="0175">[40]. Mark C. Hersam, Vinod K. Sangwan, Deep M. Jariwala, In Soo Kim, Tobin J. Marks, Lincoln J. Lauhon, Gate-tunable atomically-thin memristors and methods for preparing same and applications of same, U.S. Pat. No. 9,515,257 B2, Dec. 6, 2016.</li>    <li id="ul0003-0041" num="0176">[41]. Minxian Max Zhang, Kathryn Samuels, Jianhua Joshua Yang, R. Stanley Williams, Zhiyong Li, Nonvolatile memory crossbar array, U.S. Publication No. 2017/0271410 A1, Sep. 21, 2017.</li>    <li id="ul0003-0042" num="0177">[42]. Gregory S. Snider, Neuromorphic circuit, PCT Publication No. WO/2009/113993 A1, Sep. 17, 2009.</li>    <li id="ul0003-0043" num="0178">[43]. Yi Tang, Venkat Rangan, Jeffrey A. Levin, Subramaniam Venkatraman, Methods and systems for memristor-based neuron circuits, PCT Publication No. WO/2012/006471 A1, Jan. 12, 2012</li>    <li id="ul0003-0044" num="0179">[44]. Peter A J van der Made, Anil Shamrao Mankar, Spiking neural network, U.S. Publication No. 2020/0143229 A1, May 7, 2020.</li>    <li id="ul0003-0045" num="0180">[45]. Filip Piekniewski, Eugene Izhikevich, Botond Szatmary, Csaba Petre, Spiking neural network feedback apparatus and methods, U.S. Publication No. 2013/0297541 A1, Nov. 13, 2013.</li>    <li id="ul0003-0046" num="0181">[46]. Carver A. Mead, Timothy P. Allen, Federico Faggin, Dynamic Synapse for Neural Network, U.S. Pat. No. 4,962,342 A, Oct. 9, 1990.</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001 MATH-US-00001-2 MATH-US-00001-3 MATH-US-00001-4" nb-file="US20230004803A1-20230105-M00001.NB"><img id="EMI-M00001" he="24.30mm" wi="76.20mm" file="US20230004803A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A memtransistor, comprising:<claim-text>a polycrystalline monolayer film of an atomically thin material, wherein the polycrystalline monolayer film is grown directly on a first sapphire substrate (growth on quartz, graphene, or hexagonal boron nitride substrates may also work) and transferred onto a second substrate;</claim-text><claim-text>a gate electrode defined on the second substrate; and</claim-text><claim-text>source and drain electrodes spatially-apart formed on the polycrystalline monolayer film to define a channel region in the polycrystalline monolayer film therebetween,</claim-text><claim-text>wherein the gate electrode is capacitively coupled with the channel region.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The memtransistor of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the atomically thin material comprises two-dimensional (2D) semiconductor material.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The memtransistor of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the 2D semiconductor material comprises MoS<sub>2</sub>, MoSe<sub>2</sub>, WS<sub>2</sub>, WSe<sub>2</sub>, InSe, GaTe, black phosphorus (BP), or related two-dimensional materials.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The memtransistor of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the polycrystalline monolayer film of MoS<sub>2 </sub>has well-defined grain boundaries, sub-stoichiometric S:Mo ratio, and predominantly monolayer coverage.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The memtransistor of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first substrate is formed of sapphire, quartz, graphene, or hexagonal boron nitride.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The memtransistor of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second substrate is an SiO<sub>2</sub>/Si substrate, or an substrate of a high-k dielectric layer including Al<sub>2</sub>O<sub>3 </sub>or HfO<sub>2</sub>.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The memtransistor of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the SiO<sub>2</sub>/Si substrate comprises a silicon substrate with a silicon dioxide overlayer.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The memtransistor of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the gate, source and drain electrodes comprises a same conductive material or different conductive materials.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The memtransistor of <claim-ref idref="CLM-00001">claim 1</claim-ref>, being reconfigurable with gate tunability that enables continuous learning that allows selective forgetting of inessential tasks, thereby freeing up neural resources to learn new tasks.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The memtransistor of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein by growing the polycrystalline monolayer film grown directly on the sapphire substrate, lattice defects in the polycrystalline monolayer film are reduced and crystallographic registry is improved, thereby enabling accentuation of a vertical field effect from the gate compared to drain bias induced resistive switching, and heightening reconfigurability of a synaptic learning behavior from long-term potentiation (LTP) to long-term depression (LTD).</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The memtransistor of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the LTP and the LTD are controlled by the gate bias polarity and not the drain pulse polarity, which parallels the synaptic weight update and neuroplasticity in biological systems.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The memtransistor of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein by mimicking the biological systems, LTP/LTD tuning is achieved by biasing the gate without changing the polarity of drain pulses.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The memtransistor of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein additional learning behaviors are achieved by varying temporal evolution of gate bias pulses.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The memtransistor of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the gate pulses are used to modulate potentiation and depression, resulting in diverse learning curves and simplified spike-timing-dependent plasticity that facilitate unsupervised learning in a simulated spiking neural network (SNN).</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The memtransistor of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein a library of learning curves obtained from temporal evolution of the pulsing amplitude is used to perform unsupervised image recognition in the SNN with functions of continuous learning.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The memtransistor of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the unsupervised learning in the SNN is performed using an experimental memtransistor learning behavior modelled in a simplified spike-timing-dependent plasticity (STDP) scheme.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. A circuit, comprising one or more memtransistors according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. An electronic device, comprising one or more memtransistors according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A system for continuous learning in a spiking neural network, comprising:<claim-text>one or more synaptic units, wherein each synaptic unit comprises one or more memtransistors according to <claim-ref idref="CLM-00001">claim 1</claim-ref>.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein each synaptic unit has learning and/or unlearning behaviors, with the gate-tunable characteristics of the memtransistors.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein switching LTP-LTD learning behavior is achieved by only reversing the polarity of the gate pulses, while further adjustments in the gate amplitude produced diverse learning curves and thus learning behaviors.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. A method for fabricating a memtransistor, comprising:<claim-text>growing a polycrystalline monolayer film of an atomically thin material on a first sapphire substrate;</claim-text><claim-text>transferring the polycrystalline monolayer film to a second substrate; and</claim-text><claim-text>forming a gate electrode on the second substrate and source and drain electrodes on the grown polycrystalline monolayer film, wherein the source and drain electrodes define a channel region in the polycrystalline monolayer film therebetween, and wherein the gate electrode is capacitively coupled with the channel region.</claim-text></claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the first substrate is formed of sapphire, quartz, graphene, or hexagonal boron nitride.</claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the second substrate is an SiO<sub>2</sub>/Si substrate, or an substrate of a high-k dielectric layer including Al<sub>2</sub>O<sub>3 </sub>or HfO<sub>2</sub>.</claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the polycrystalline monolayer film is grown by chemical vapor deposition (CVD) on the first substrate.</claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein said transferring comprises:<claim-text>coating a polymer film on the polycrystalline monolayer film grown on the first substrate;</claim-text><claim-text>separating the polymer film with the polycrystalline monolayer film from the first substrate;</claim-text><claim-text>adhering the separated polymer film with the polycrystalline monolayer film to the second substrate; and</claim-text><claim-text>removing the polymer film.</claim-text></claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. The method of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein the polymer film is formed of polycarbonate (PC).</claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein said forming is performed by photolithography.</claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. The method of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein the atomically thin material comprises two-dimensional (2D) semiconductor material.</claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. The method of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the 2D semiconductor material comprises MoS<sub>2</sub>, MoSe<sub>2</sub>, WS<sub>2</sub>, WSe<sub>2</sub>, InSe, GaTe, black phosphorus (BP), or related two-dimensional materials.</claim-text></claim></claims></us-patent-application>
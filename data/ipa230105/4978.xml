<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004979A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004979</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17898324</doc-number><date>20220829</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>202010840924.8</doc-number><date>20200820</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>20</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>Q</subclass><main-group>20</main-group><subgroup>38</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>50</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>20</main-group><subgroup>4016</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>Q</subclass><main-group>20</main-group><subgroup>382</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>535</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">ABNORMAL BEHAVIOR DETECTION METHOD AND APPARATUS, ELECTRONIC DEVICE, AND COMPUTER-READABLE STORAGE MEDIUM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/CN2021/104999</doc-number><date>20210707</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17898324</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Tencent Technology (Shenzhen) Company Limited</orgname><address><city>Shenzhen</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>CHENG</last-name><first-name>Zhehao</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>DONG</last-name><first-name>Jingran</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>CHEN</last-name><first-name>Shouzhi</first-name><address><city>Shenzhen</city><country>CN</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">This application provides an abnormal online operational behavior detection method performed by an electronic device. The method includes: obtaining a first target sub-model corresponding to a first target object from a first preset object model; determining an abnormal data volume from the first target sub-model based on a preset model parameter and a first detection result by comparing a target data volume and the abnormal data volume; obtaining a second target sub-model corresponding to a second target object and having a highest similarity with the first target sub-model from a second preset object model; obtaining a target maximum data volume corresponding to the second target sub-model, and determining a second detection result by comparing the target data volume and the target maximum data volume; and determining a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="154.60mm" wi="137.24mm" file="US20230004979A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="164.42mm" wi="139.11mm" file="US20230004979A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="134.96mm" wi="149.52mm" file="US20230004979A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="200.32mm" wi="145.80mm" file="US20230004979A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="207.18mm" wi="146.90mm" file="US20230004979A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="203.45mm" wi="97.79mm" file="US20230004979A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="188.98mm" wi="150.11mm" file="US20230004979A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="163.24mm" wi="148.34mm" file="US20230004979A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation application of PCT Patent Application No. PCT/CN2021/104999, entitled &#x201c;ABNORMAL BEHAVIOR DETECTION METHOD AND APPARATUS, AND ELECTRONIC DEVICE AND COMPUTER-READABLE STORAGE MEDIUM&#x201d; filed on Jul. 7, 2021, which claims priority to Chinese Patent Application No. 202010840924.8, filed with the State Intellectual Property Office of the People's Republic of China on Aug. 20, 2020, and entitled &#x201c;ABNORMAL BEHAVIOR DETECTION METHOD, DEVICE AND EQUIPMENT AND COMPUTER READABLE STORAGE MEDIUM&#x201d;, all of which are incorporated herein by reference in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD OF THE TECHNOLOGY</heading><p id="p-0003" num="0002">This application relates to information processing technologies in the field of computer application, and in particular, to an abnormal online operational behavior detection method and apparatus, an electronic device, and a computer-readable storage medium.</p><heading id="h-0003" level="1">BACKGROUND OF THE APPLICATION</heading><p id="p-0004" num="0003">With the rapid development of the computer application technologies, an application with various network functions is more widely applied. However, during application of the network functions, malicious processing such as false brushing or stolen account payment is often performed in an abnormal manner. In view of this, to improve the network security, abnormal online operational behavior detection has become increasingly important.</p><p id="p-0005" num="0004">Generally, abnormal online operational behavior detection is usually performed in an unsupervised manner. For example, historical behavior information is clustered to obtain a plurality of clusters, and after online operation behavior information is obtained, the abnormality of the online operation behavior information is determined by judging an ownership relationship between the online operation behavior information and the plurality of clusters. However, during the abnormal online operational behavior detection, since a feature dimension of the online operation behavior information is low, when clustering processing is performed based on the low-dimensional feature to determine a detection result, an error is probably existed in the detection result, resulting in a relatively low accuracy of the abnormal online operational behavior detection.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0006" num="0005">Embodiments of this application provide an abnormal online operational behavior detection method and apparatus, an electronic device, and a computer-readable storage medium, to improve the accuracy of abnormal online operational behavior detection.</p><p id="p-0007" num="0006">Technical solutions in the embodiments of this application are implemented as follows:</p><p id="p-0008" num="0007">an embodiment of this application provides an abnormal online operational behavior detection method, performed by an electronic device, the method including:</p><p id="p-0009" num="0008">acquiring online operation behavior information, the online operation behavior information including a first target object, a second target object, and a target data volume;</p><p id="p-0010" num="0009">obtaining a first target sub-model corresponding to the first target object from a first preset object model;</p><p id="p-0011" num="0010">determining an abnormal data volume from the first target sub-model based on a preset model parameter, and determining a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume;</p><p id="p-0012" num="0011">obtaining a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model;</p><p id="p-0013" num="0012">obtaining a target maximum data volume corresponding to the second target sub-model, and determining a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume; and</p><p id="p-0014" num="0013">determining a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result.</p><p id="p-0015" num="0014">An embodiment of this application provides an abnormal online operational behavior detection apparatus, including:</p><p id="p-0016" num="0015">an information obtaining module, configured to acquire online operation behavior information, the online operation behavior information including a first target object, a second target object, and a target data volume;</p><p id="p-0017" num="0016">a first detection module, configured to obtain a first target sub-model corresponding to the first target object from a first preset object model,</p><p id="p-0018" num="0017">the first detection module being further configured to determine an abnormal data volume from the first target sub-model based on a preset model parameter, and determine a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume;</p><p id="p-0019" num="0018">a second detection module, configured to obtain a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model,</p><p id="p-0020" num="0019">the second detection module being further configured to obtain a target maximum data volume corresponding to the second target sub-model, and determine a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume; and</p><p id="p-0021" num="0020">a result determination module, configured to determine a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result.</p><p id="p-0022" num="0021">An embodiment of this application provides an electronic device for abnormal online operational behavior detection, including:</p><p id="p-0023" num="0022">a memory, configured to store executable instructions; and</p><p id="p-0024" num="0023">a processor, configured to implement, when executing the executable instructions stored in the memory, the abnormal online operational behavior detection method provided in this embodiment of this application.</p><p id="p-0025" num="0024">An embodiment of this application provides a computer-readable storage medium, storing executable instructions, the executable instructions, when executed by a processor, causing the processor to implement the abnormal online operational behavior detection method provided in this embodiment of this application.</p><p id="p-0026" num="0025">The embodiments of this application have at least the following beneficial effects: When the online operation behavior information includes three dimensional features of the first target object, the second target object, and the target data volume, when the target detection result of whether the online operation behavior information is abnormal is determined with reference to results of respectively comparing the target data volume with the abnormal data volume and the target maximum data volume, since the abnormal data volume is an abnormality judgment condition for the first target object determined based on the first preset object model, and the target maximum data volume is an abnormality judgment condition for the second target object determined based on the second preset object model, in a low-dimensional feature, whether the target data volume is within a preset interval is determined from two dimensions of the first target object and the second target object, to further accurately obtain the target detection result of whether the online operation behavior information is abnormal, thereby improving the accuracy of abnormal online operational behavior detection.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is an exemplary schematic architecture diagram of an abnormal online operational behavior detection system according to an embodiment of this application.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of a composition structure of a server in <figref idref="DRAWINGS">FIG. <b>1</b></figref> according to an embodiment of this application.</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is an exemplary schematic flowchart of an abnormal online operational behavior detection method according to an embodiment of this application.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is an exemplary schematic diagram of determining an abnormal data volume according to an embodiment of this application.</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is another exemplary schematic flowchart of an abnormal online operational behavior detection method according to an embodiment of this application.</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is an exemplary schematic diagram of a to-be-converted data volume according to an embodiment of this application.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> is an exemplary schematic diagram of data volume conversion according to an embodiment of this application.</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is an exemplary schematic diagram of obtaining a similarity according to an embodiment of this application.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is an exemplary schematic diagram of obtaining a merged sub-model according to an embodiment of this application.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is an exemplary schematic flowchart of abnormal online operational behavior detection according to an embodiment of this application.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is an exemplary schematic diagram of obtaining a model according to an embodiment of this application.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is an exemplary schematic diagram of a model according to an embodiment of this application.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DESCRIPTION OF EMBODIMENTS</heading><p id="p-0039" num="0038">To make the objectives, technical solutions, and advantages of this application clearer, the following describes this application in further detail with reference to the accompanying drawings. The described embodiments are not to be considered as a limitation to this application. All other embodiments obtained by a person of ordinary skill in the art without creative efforts shall fall within the protection scope of this application.</p><p id="p-0040" num="0039">In the following descriptions, related &#x201c;some embodiments&#x201d; describe a subset of all possible embodiments. However, it may be understood that the &#x201c;some embodiments&#x201d; may be the same subset or different subsets of all the possible embodiments, and may be combined with each other without conflict.</p><p id="p-0041" num="0040">In the following descriptions, the included term &#x201c;first/second&#x201d; is merely intended to distinguish similar objects but does not necessarily indicate a specific order of an object. It may be understood that &#x201c;first/second&#x201d; is interchangeable in terms of a specific order or sequence if permitted, so that the embodiments of this application described herein can be implemented in a sequence in addition to the sequence shown or described herein.</p><p id="p-0042" num="0041">Unless otherwise defined, meanings of all technical and scientific terms used in the embodiments of this application are the same as those usually understood by a person skilled in the art to which this application belongs. Terms used in the embodiments of this application are merely intended to describe objectives of the embodiments of this application, but are not intended to limit this application.</p><p id="p-0043" num="0042">Before the embodiments of this application are further described in detail, a description is made on nouns and terms in the embodiments of this application, and the nouns and terms in the embodiments of this application are applicable to the following explanations.</p><p id="p-0044" num="0043">1) Abnormal behavior detection: It refers to detection of whether data corresponding to a user's operation behavior conforms to a preset operation process or an actual process, for example, detection of stolen account payment and false brushing.</p><p id="p-0045" num="0044">2) Offline environment: It refers to a platform for processing massive f data (for example, billion-level data) based on a data mining tool (for example, &#x201c;Hadoop&#x201d; and &#x201c;spark&#x201d;). Usually there is a relatively high delay (for example, a delay of one day), causing poor real-time performance.</p><p id="p-0046" num="0045">3) Real-time/online environment: It is used for a platform for efficiently storing and computing to-be-processed data in real time, a delay is usually within milliseconds, the complexity is low, and the real-time performance is relatively high.</p><p id="p-0047" num="0046">Generally, abnormal online operational behavior detection is usually implemented in an unsupervised and supervised manner. When abnormal online operational behavior detection is performed in an unsupervised manner, it indicates that an unsupervised algorithm is applied to the abnormal online operational behavior detection. For example, when behavior information in an application scenario obeys mixture Gaussian distribution, during abnormal online operational behavior detection, whether online operation behavior information is abnormal may be determined by judging whether the online operation behavior information obeys mixture Gaussian distribution. In another example, historical behavior information is clustered to obtain a plurality of clusters, and after online operation behavior information is obtained, the abnormality of the online operation behavior information is determined by judging an ownership relationship between the online operation behavior information and the plurality of clusters. In still another example, behavioral information corresponding to an isolated point in a space is determined as abnormal online operational behavioral information by using an outlier detection algorithm (for example, an isolation forest algorithm). However, when abnormal online operational behavior detection is performed in an unsupervised manner, the feature is low-dimensional when the online operation behavior information includes three dimensional features of a first target object, a second target object, and a target data volume (for example, a user, a merchant, and an amount; a user, a product, and an amount; or a user, an article, and views); and when detection is performed based on the low-dimensional feature in an unsupervised manner to determine a detection result, an error is probably existed in the detection result, resulting in a relatively low accuracy of the abnormal online operational behavior detection. In addition, when a feature of more than three dimensions is obtained for unsupervised detection, a detection duration is relatively long due to a relatively high feature dimension/complexity, resulting in poor real-time performance of the detection.</p><p id="p-0048" num="0047">When abnormal online operational behavior detection is performed in a supervised manner, it indicates that a sample is labeled, a network model is trained by using a sample feature and labeled information, and then whether the online operation behavior information is abnormal is detected by using the network model. However, when abnormal online operational behavior is performed in a supervised manner, the sample needs to be labeled, and it is less feasible to perform labeling when a data volume of the sample is relatively large, for example, reaches a level of hundred million. For example, when whether payment is abnormal is detected, since hundreds of millions of payments are generated every day, it is less feasible to perform manual labeling. In addition, a long labeling duration may result in a relatively long duration for network model training. After the network model is trained, the trained network model may no longer be applicable to the current application scenario when the behavior information in the application scenario changes rapidly and abnormal online operational behavior detection in the application scenario is time-based. As a result, labeling is less feasible and cannot be applied to an application scenario with higher timeliness.</p><p id="p-0049" num="0048">In view of this, embodiments of this application provide an abnormal online operational behavior detection method and apparatus, an electronic device, and a computer-readable storage medium, which can quickly and accurately perform abnormal online operational behavior detection and is applicable to an application scenario with higher timeliness.</p><p id="p-0050" num="0049">The following describes an exemplary application of an electronic device for abnormal online operational behavior detection (hereinafter briefly referred to as an abnormal online operational behavior detection device) provided in the embodiments of this application. The abnormal online operational behavior detection device provided in the embodiments of this application may be implemented as various types of terminals such as a notebook computer, a tablet computer, a desktop computer, a set top box, or a mobile device (such as a mobile phone, a portable music player, a personal digital assistant, a dedicated messaging device, a portable game device, an in-vehicle device, a smartphone, or a smart watch), or may be implemented as a server. An exemplary application in which the device is implemented as a server is described below.</p><p id="p-0051" num="0050">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, <figref idref="DRAWINGS">FIG. <b>1</b></figref> is an exemplary schematic architecture diagram of an abnormal online operational behavior detection system according to an embodiment of this application. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, to support an abnormal online operational behavior detection application, in an abnormal online operational behavior detection system <b>100</b>, terminals <b>200</b> (where a terminal <b>200</b>-<b>1</b> and a terminal <b>200</b>-<b>2</b> are shown as an example) are connected to a server <b>400</b> (the abnormal online operational behavior detection device) through a network <b>300</b>. The network <b>300</b> may be a wide area network, a local area network, or a combination of thereof. In addition, the abnormal online operational behavior detection system <b>100</b> further includes a database <b>500</b>.</p><p id="p-0052" num="0051">The database <b>500</b> is configured to store a first preset object model and a second preset object model, and provide the first preset object model and the second preset object model to the server <b>400</b>, to implement abnormal online operational behavior detection.</p><p id="p-0053" num="0052">The terminal <b>200</b>-<b>1</b> is configured to receive a payment operation by a user through a control <b>200</b>-<b>111</b> (a payment button is exemplarily shown) on a graphical interface <b>200</b>-<b>11</b>, send, in response to the payment operation, online operation behavior information including a merchant (a first target object), a user (a second target object), and an amount (a target data volume) to the server <b>400</b> through the network <b>300</b>, receive, through the network <b>300</b>, a target detection result sent by the server <b>400</b>, and display the target detection result on a graphical interface <b>200</b>-<b>12</b>.</p><p id="p-0054" num="0053">The terminal <b>200</b>-<b>2</b> is configured to receive a reading operation by the user through a control <b>200</b>-<b>211</b> (a reading button is exemplarily shown) on a graphical interface <b>200</b>-<b>21</b>, send, in response to the reading operation, online operation behavior information including an article (a first target object), a user (a second target object), and views (a target data volume) to the server <b>400</b> through the network <b>300</b>, receive, through the network <b>300</b>, a target detection result sent by the server <b>400</b>, and display the target detection result on a graphical interface <b>200</b>-<b>22</b>.</p><p id="p-0055" num="0054">The server <b>400</b> is configured to: acquire online operation behavior information from the terminals <b>200</b> through the network <b>300</b>, the online operation behavior information including a first target object, a second target object, and a target data volume; obtain a first target sub-model corresponding to the first target object from a first preset object model provide by the database <b>500</b>; determine an abnormal data volume from the first target sub-model based on a preset model parameter, and determine a first detection result corresponding to the online operation behavior information by comparing the target data volume with the abnormal data volume; obtain a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model provided by the database <b>500</b>; obtain a target maximum data volume corresponding to the second target sub-model, and determine a second detection result corresponding to the online operation behavior information by comparing the target data volume with the target maximum data volume; determine a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result; and send the target detection result to the terminals <b>200</b> through the network <b>300</b>.</p><p id="p-0056" num="0055">In some embodiments, the server <b>400</b> may be an independent physical server, or may be a server cluster or a distributed system formed by a plurality of physical servers, or may be a cloud server that provides basic cloud computing services such as a cloud service, a cloud database, cloud computing, a cloud function, cloud storage, a network service, cloud communication, a middleware service, a domain name service, a security service, a content delivery network (CDN), big data, and an artificial intelligence platform. The terminal and the server may be directly or indirectly connected in a wired or wireless communication manner. This is not limited in the embodiments of the present disclosure.</p><p id="p-0057" num="0056">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of a composition structure of a server in <figref idref="DRAWINGS">FIG. <b>1</b></figref> according to an embodiment of this application. The server <b>400</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes at least one processor <b>410</b>, a memory <b>450</b>, at least one network interface <b>420</b>, and a user interface <b>430</b>. Components in the server <b>400</b> are coupled together by using a bus system <b>440</b>. It may be understood that the bus system <b>440</b> is configured to implement connection and communication between the components. In addition to a data bus, the bus system <b>440</b> further includes a power bus, a control bus, and a status signal bus. However, for ease of clear description, all types of buses are marked as the bus system <b>440</b> in <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0058" num="0057">The processor <b>410</b> may be an integrated circuit chip having a signal processing capability, for example, a general purpose processor, a digital signal processor (DSP), or another programmable logic device (PLD), discrete gate, transistor logical device, or discrete hardware component. The general purpose processor may be a microprocessor, any conventional processor, or the like.</p><p id="p-0059" num="0058">The user interface <b>430</b> includes one or more output apparatuses <b>431</b> that enable presentation of media content, including one or more speakers and/or one or more visualization displays. The user interface <b>430</b> further includes one or more input apparatuses <b>432</b>, including user interface components helping a user input, such as a keyboard, a mouse, a microphone, a touch display screen, a camera, and other input buttons and controls.</p><p id="p-0060" num="0059">The memory <b>450</b> may be a removable memory, a non-removable memory, or a combination thereof. Exemplary hardware devices include a solid-state memory, a hard disk drive, an optical disc driver, or the like. The memory <b>450</b> includes one or more storage devices physically away from the processor <b>410</b>.</p><p id="p-0061" num="0060">The memory <b>450</b> includes a volatile memory or a non-volatile memory, or may include both a volatile memory and a non-volatile memory. The non-volatile memory may be a read-only memory (ROM), and the volatile memory may be a random access memory (RAM). The memory <b>450</b> described in this embodiment of this application includes any suitable type of memory.</p><p id="p-0062" num="0061">In some embodiments, the memory <b>450</b> may store data to support various operations. Examples of the data include programs, modules, and data structures, or a subset or a superset thereof. The descriptions are made below by using examples.</p><p id="p-0063" num="0062">An operating system <b>451</b> includes a system program configured to process various basic system services and perform a hardware-related task, for example, a framework layer, a core library layer, and a driver layer, and is configured to implement various basic services and process a hardware-related task.</p><p id="p-0064" num="0063">A network communication module <b>452</b> is configured to reach another computing device through one or more (wired or wireless) network interfaces <b>420</b>. Exemplary network interfaces <b>420</b> include: Bluetooth, wireless compatible authentication (Wi-Fi), a universal serial bus (USB), and the like.</p><p id="p-0065" num="0064">A display module <b>453</b> is configured to display information by using an output apparatus <b>431</b> (for example, a display screen or a speaker) associated with one or more user interfaces <b>430</b> (for example, a user interface configured to operate a peripheral device and display content and information).</p><p id="p-0066" num="0065">An input processing module <b>454</b> is configured to detect one or more user inputs or interactions from one of the one or more input apparatuses <b>432</b> and translate the detected input or interaction.</p><p id="p-0067" num="0066">In some embodiments, the abnormal online operational behavior detection apparatus provided in this embodiment of this application may be implemented in a form of software. <figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an abnormal online operational behavior detection apparatus <b>455</b> stored in the memory <b>450</b>, which may be software in a form such as a program and a plug-in, and includes the following software modules: an information obtaining module <b>4551</b>, a first detection module <b>4552</b>, a second detection module <b>4553</b>, a result determination module <b>4554</b>, and a model obtaining module <b>4555</b>. Such modules are logical, and therefore may be randomly combined or further divided according to a function to be implemented. A function of each module is described below.</p><p id="p-0068" num="0067">In some other embodiments, the abnormal online operational behavior detection apparatus provided in this embodiment of this application may be implemented by using hardware. For example, the abnormal online operational behavior detection apparatus provided in this embodiment of this application may be a processor in a form of a hardware decoding processor, programmed to perform the abnormal online operational behavior detection method provided in the embodiments of this application. For example, the processor in the form of a hardware decoding processor may use one or more application-specific integrated circuits (ASIC), a DSP, a programmable logic device (PLD), a complex programmable logic device (CPLD), a field-programmable gate array (FPGA), or other electronic components.</p><p id="p-0069" num="0068">The abnormal online operational behavior detection method provided in the embodiments of this application is described below with reference to an exemplary application in which the abnormal online operational behavior detection device provided in this embodiment of this application is implemented as a server.</p><p id="p-0070" num="0069">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, <figref idref="DRAWINGS">FIG. <b>3</b></figref> is an exemplary schematic flowchart of an abnormal online operational behavior detection method according to an embodiment of this application, and the method is described with reference to steps shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0071" num="0070">S<b>301</b>: Acquire online operation behavior information, the online operation behavior information including a first target object, a second target object, and a target data volume.</p><p id="p-0072" num="0071">In this embodiment of this application, when the user performs an operation on a functional application in a terminal, for example, performing payment, reading an article, or clicking on an advertisement, the terminal generates operation data in response to the operation performed by the user, and sends the operation data to the server, and then the server receives the online operation behavior information. In this way, the online operation behavior information is obtained.</p><p id="p-0073" num="0072">The online operation behavior information is a detection object, including a first target object, a second target object, and a target data volume. The first target object is an operated object, for example, an advertisement, a merchant, a product, or an article. The second target object is an operation object, for example, a user, or the like. The target data volume is a data volume generated by performing an operation on the first target object by the second target object, for example, an amount, clicks, or views.</p><p id="p-0074" num="0073">S<b>302</b>: Obtain a first target sub-model corresponding to the first target object from a first preset object model.</p><p id="p-0075" num="0074">In this embodiment of this application, the server pre-stores the first preset object model, or the server can obtain the first preset object model in advance. The first preset object model is a model corresponding to each first object, and the model is data volume distribution information. Since the first target object is a first object, the server can obtain a model corresponding to the first target object from the first preset object model. In this case, the first target sub-model is obtained.</p><p id="p-0076" num="0075">In other words, the first preset object model is a correspondence between first objects and the data volume distribution information. Since the first target object is a first object, on the basis of the correspondence between the first objects and the data volume distribution information, the server matches the first target object with each first object in the correspondence between the first objects and the data volume distribution information, to obtain a first object from the first objects through matching, and determines data volume distribution information corresponding to the matched first object as the first target sub-model.</p><p id="p-0077" num="0076">The first target sub-model is data volume distribution information corresponding to the first target object, for example, a histogram of an amount corresponding to a merchant A, or distribution of views corresponding to an article B.</p><p id="p-0078" num="0077">In addition, in this embodiment of this application, when the model corresponding to the first target object is not obtained from the first preset object model, the server constructs a first target sub-model for the first target object, and adds the first target sub-model corresponding to the first target object to the first preset object model.</p><p id="p-0079" num="0078">S<b>303</b>: Determine an abnormal data volume from the first target sub-model based on a preset model parameter, and determine a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume.</p><p id="p-0080" num="0079">In this embodiment of this application, the server stores the preset model parameter, or the server can obtain the preset model parameter in advance. The preset model parameter is a preset quantile in the data volume distribution information, and is used for determining a preset range of a data volume corresponding to the first target object. The determined preset interval of the data volume corresponding to the first target object is an abnormality judgment condition corresponding to the first target object. Therefore, the server can determine a target position corresponding to the preset model parameter from the first target sub-model, where a data volume of the target position is the abnormal data volume. Next, after comparing the target data volume with the abnormal data volume, the server can determine whether the target data volume is within the preset interval (ranging from zero to the abnormal data volume) of the data volume corresponding to the first target object according to the comparison result between the target data volume and the abnormal data volume. In this case, the first detection result corresponding to the online operation behavior information is obtained.</p><p id="p-0081" num="0080">The first detection result is a result of whether the online operation behavior information is abnormal determined for the first target object. When the target data volume is greater than the abnormal data volume, it indicates that the target data volume exceeds the preset interval of the data volume corresponding to the first target object, and the server determines the first detection result that the online operation behavior information is abnormal with respect to the first target object. When the target data volume is less than or equal to the abnormal data volume, it indicates that the target data volume is within the preset interval of the data volume corresponding to the first target object, and the server determines the first detection result that the online operation behavior information is normal with respect to the first target object.</p><p id="p-0082" num="0081">Exemplarily, referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, <figref idref="DRAWINGS">FIG. <b>4</b></figref> is an exemplary schematic diagram of determining an abnormal data volume according to an embodiment of this application. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in a histogram <b>4</b>-<b>1</b> (the first target sub-model), a transverse axis is an amount value, and a longitudinal axis is a probability value. Probability values of amount segments in the histogram <b>4</b>-<b>1</b> are superimposed in ascending order of the amount value when the preset model parameter is the 99<sup>th </sup>quantile, and when a superposition result is greater than 99%, an amount value corresponding to a position <b>14</b>-<b>2</b> (which is a target position, a probability of an amount less than an amount value corresponding to the position <b>14</b>-<b>2</b> is greater than 99%) is the abnormal data volume.</p><p id="p-0083" num="0082">S<b>304</b>: Obtain a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model.</p><p id="p-0084" num="0083">In this embodiment of this application, the server pre-stores the second preset object model, or the server can obtain the second preset object model in advance. The second preset object model is a model set formed by each piece of data volume distribution information corresponding to the second object with respect to each first object. Since the second target object is a second object, the server can obtain a model group corresponding to the second target object from the second preset object model, and match a model having a highest similarity with the first target sub-model from the obtained model group corresponding to the second target object, so that the second target sub-model is obtained.</p><p id="p-0085" num="0084">In other words, in the second preset object model, the server matches each second target object with the second objects to obtain matched each piece of data volume distribution information (the model group) corresponding to the second object with respect to the first object, and further obtains data volume distribution information most similar to the obtained first target sub-model from the piece of data volume distribution information, where the data volume distribution information most similar to the first target sub-model is the second target sub-model. Data volume distribution information corresponding to the first object in the first preset object model is different from data volume distribution information corresponding to the first object in the second preset object model, the data volume distribution information corresponding to the first object in the second preset object model is obtained by processing the data volume distribution information corresponding to the first object in the first preset object model, which is data volume distribution information corresponding to the second object with respect to the first object.</p><p id="p-0086" num="0085">The second target sub-model is data volume distribution information corresponding to the second target object with respect to the first target object, for example, an amount histogram of a user C with respect to the merchant A, or distribution of views of a user D with respect to the article B.</p><p id="p-0087" num="0086">S<b>305</b>: Obtain a target maximum data volume corresponding to the second target sub-model, and determine a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume.</p><p id="p-0088" num="0087">In this embodiment of this application, after the server obtains the second target sub-model, since the second preset object model not only includes a model group corresponding to each second object, but also includes a maximum data volume corresponding to the second object, the server determines the target maximum data volume based on a maximum data volume corresponding to the second target object in the second preset object model. In other words, the target maximum data volume may be the maximum data volume corresponding to the second target object, or may be determined based on the maximum data volume corresponding to the second target object in the second preset object model. This is not specifically limited in this embodiment of this application.</p><p id="p-0089" num="0088">In this case, the server obtains the target maximum data volume, so that a preset interval of a data volume corresponding to the second target object is determined, where the determined preset interval of the data volume corresponding to the second target object is an abnormality judgment condition corresponding to the second target object. Therefore, after comparing the target data volume with the target maximum data volume, the server can determine whether the target data volume is within the preset interval (ranging from zero to the target maximum data volume) of the data volume corresponding to the second target object according to the comparison result between the target data volume and the target maximum data volume. In this case, the second detection result corresponding to the online operation behavior information is obtained.</p><p id="p-0090" num="0089">The second detection result is a result of whether the online operation behavior information is abnormal determined for the second target object. When the target data volume is greater than the target maximum data volume, it indicates that the target data volume exceeds the preset interval of the data volume corresponding to the second target object, and the server determines the second detection result that the online operation behavior information is abnormal with respect to the second target object. When the target data volume is less than or equal to the target maximum data volume, it indicates that the target data volume is within the preset interval of the data volume corresponding to the second target object, and the server determines the second detection result that the online operation behavior information is normal with respect to the second target object.</p><p id="p-0091" num="0090">S<b>306</b>: Determine a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result.</p><p id="p-0092" num="0091">In this embodiment of this application, after obtaining the first detection result and the second detection result, the server determines the target detection result of the online operation behavior information in accordance with the first detection result and the second detection result. The target detection result indicates whether the online operation behavior information is abnormal.</p><p id="p-0093" num="0092">The determining, by the server, a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result includes: when the first detection result is that the online operation behavior information is abnormal with respect to the first target object and the second detection result is that the online operation behavior information is abnormal with respect to the second target object, determining, by the server, the target detection result including that the online operation behavior information is abnormal; when the first detection result is that the online operation behavior information is normal with respect to the first target object and the second detection result is that the online operation behavior information is abnormal with respect to the second target object, determining, by the server, the target detection result including that the online operation behavior information is abnormal, determining the target detection result including that the online operation behavior information is normal, and determining the online operation behavior information as to-be-audited behavior information, to further detect by performing intelligent detection processing in manual manner; when the first detection result is that the online operation behavior information is normal with respect to the first target object and the second detection result is that the online operation behavior information is normal with respect to the second target object, determining, by the server, the target detection result including that the online operation behavior information is normal; and when the first detection result is that the online operation behavior information is abnormal with respect to the first target object and the second detection result is that the online operation behavior information is normal with respect to the second target object, determining, by the server, the target detection result including that the online operation behavior information is normal, determining the target detection result including that the online operation behavior information is abnormal, and determining the online operation behavior information as to-be-audited behavior information, to further detect by performing intelligent detection processing in manual manner.</p><p id="p-0094" num="0093">In this embodiment of this application, after obtaining the target detection result, the server may further determine target processing information according to the target detection result. The target processing information is a processing manner for the online operation behavior information, for example, when the online operation behavior information is the payment operation, when the target detection result is that the online operation behavior information is abnormal, the target processing information is the processing of blocking the payment operation. In another example, when the online operation behavior information is advertisement clicking, when the target detection result is that the online operation behavior information is abnormal, the target processing information is the processing of blocking the advertisement clicking.</p><p id="p-0095" num="0094">It may be understood that, when the online operation behavior information includes three dimensional features of the first target object, the second target object, and the target data volume, when the target detection result of whether the online operation behavior information is abnormal is determined with reference to results of respectively comparing the target data volume with the abnormal data volume and the target maximum data volume, since the abnormal data volume is an abnormality judgment condition for the first target object determined based on the first preset object model, and the target maximum data volume is an abnormality judgment condition for the second target object determined based on the second preset object model, in a low-dimensional feature, whether the target data volume is within a preset interval is determined from two dimensions of the first target object and the second target object, to further accurately obtain the target detection result of whether the online operation behavior information is abnormal, so that the accuracy of abnormal online operational behavior detection is relatively high.</p><p id="p-0096" num="0095">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, <figref idref="DRAWINGS">FIG. <b>5</b></figref> is another optional schematic flowchart of an abnormal online operational behavior detection method according to an embodiment of this application. As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, in this embodiment of this application, before S<b>302</b>, the method further includes S<b>307</b> to S<b>311</b>. In other words, before the obtaining, by the server, a first target sub-model corresponding to the first target object from a first preset object model, the abnormal online operational behavior detection method further includes S<b>307</b> to S<b>311</b>. The steps are described as follows:</p><p id="p-0097" num="0096">S<b>307</b>: Obtain a behavior information sample.</p><p id="p-0098" num="0097">In this embodiment of this application, the server obtains behavior information in a current cycle, so that the behavior information sample is obtained, for example, payment orders in a last week, or reading records in a last month. The current cycle refers to the most recent preset cycle.</p><p id="p-0099" num="0098">The behavior information sample is a set formed by behavior information corresponding to a first object, a second object, and a data volume in a current cycle, and therefore, each piece of behavior information in the behavior information sample includes the first object, the second object, and the data volume.</p><p id="p-0100" num="0099">S<b>308</b>: Aggregate the behavior information sample according to a first preset object type to obtain a data volume set corresponding to each first object, construct a first sub-model corresponding to the first object according to the data volume set, and determine each constructed first sub-model corresponding to the first object as the first preset object model.</p><p id="p-0101" num="0100">After obtaining the behavior information sample, the server aggregates the behavior information sample according to different preset types, to obtain the first preset object model and the second preset object model. The different preset types include a first preset object type (for example, a merchant type or a product type) and a second preset object type (for example, a user), where the first preset object type is an object type to which the first object belongs, and the second preset object type is an object type to which the second object belongs. Therefore, the data volume set corresponding to the first object is obtained when the server aggregates the behavior information sample according to the first preset object type, to obtain each data volume corresponding to each first object.</p><p id="p-0102" num="0101">The object type corresponding to each first object is the first preset object type. The data volume set is a set formed by a data volume of the first object with respect to the second object.</p><p id="p-0103" num="0102">In this embodiment of this application, after obtaining the data volume set, the server determines data volume distribution information corresponding to each first object according to the data volume set, so that the first sub-model corresponding to the first object is constructed. The first sub-model corresponding to the first object is obtained after the first sub-model corresponding to the first object is constructed, where the first sub-model corresponding to the first object is the first preset object model. The first object refers to any object in the first objects, and the first preset object model refers to a set formed by the first sub-model of the first object. The first target sub-model is a first sub-model.</p><p id="p-0104" num="0103">S<b>309</b>: Aggregate the behavior information sample according to a second preset object type, to obtain a first object set and a maximum data volume corresponding to each second object.</p><p id="p-0105" num="0104">In this embodiment of this application, the first object set corresponding to the second object is obtained when the server aggregates the behavior information sample according to the second preset object type, to obtain the first object corresponding to the second object. Each data volume corresponding to the second object is further obtained when the server aggregates the behavior information sample according to the second preset object type, and a maximum data volume is selected from the data volume corresponding to the second object, so that the maximum data volume corresponding to the second object.</p><p id="p-0106" num="0105">S<b>310</b>: Traverse the first object set, and construct at least one second object sub-model based on the first sub-model corresponding to the traversed first object.</p><p id="p-0107" num="0106">In this embodiment of this application, after obtaining the first object set, the server traverses the first objects in the first object set, and the traversed first objects is matched with the first objects in the first preset object model, where a model corresponding to a matched first object is a first sub-model corresponding to the traversed first object. The server constructs the at least one second object sub-model corresponding to the second object by using the first sub-model corresponding to the traversed first object.</p><p id="p-0108" num="0107">The at least one second object sub-model is a set formed by the data volume of the first object associated with the second object, for example, an amount histogram of a user C with respect to the merchant A, an amount histogram of the user C with respect to a merchant E, and an amount histogram of the user C with respect to a merchant F. The traversed first object is any first object in the first object set.</p><p id="p-0109" num="0108">S<b>311</b>: Combine the at least one second object sub-model and the maximum data volume into a second sub-model corresponding to the second object, and determine each combined second sub-model corresponding to the second object as the second preset object model.</p><p id="p-0110" num="0109">After obtaining the at least one second object sub-model corresponding to the second object, the server combines the at least one second object sub-model and the maximum data volume, where an obtained combination result is the second sub-model corresponding to the second object. The second preset object model of the second sub-model corresponding to the second object is obtained when the second sub-model corresponding to the second object is obtained. The second object refers to any object in the second objects, and the second preset object model refers to a set formed by the second sub-model of the second object.</p><p id="p-0111" num="0110">In this embodiment of this application, the constructing, by the server, a first sub-model corresponding to the first object according to the data volume set described in S<b>308</b> includes S<b>3081</b> to S<b>3085</b>. The steps are described as follows:</p><p id="p-0112" num="0111">S<b>3081</b>: Obtain a data volume range corresponding to each data volume in the data volume set.</p><p id="p-0113" num="0112">In this embodiment of this application, the server extracts a minimum data volume and a maximum data volume from each data volume in the data volume set, where a range between the minimum data volume and the maximum data volume is the data volume range.</p><p id="p-0114" num="0113">S<b>3082</b>: Segment the data volume range to obtain a plurality of target segments.</p><p id="p-0115" num="0114">In this embodiment of this application, the server segments the data volume range according to a magnitude or quantity of a preset segment, so that the plurality of target segments are obtained.</p><p id="p-0116" num="0115">S<b>3083</b>: Collect statistics on a target quantity of data volumes of each target segment in the plurality of target segments from the data volume set.</p><p id="p-0117" num="0116">In this embodiment of this application, after obtaining the plurality of target segments and the data volume set, the server determines a target segment to which the data volume in the data volume set belongs, to further collect statistics a quantity of the data volumes of the target segment in the plurality of target segments. The quantity of the data volumes of the target segment obtained by collecting statistics is the target quantity corresponding to the target segment.</p><p id="p-0118" num="0117">S<b>3084</b>: Determine a ratio of the target quantity to a set element quantity corresponding to the data volume set as a probability value corresponding to the target segment.</p><p id="p-0119" num="0118">In this embodiment of this application, the server collects statistics on the quantity of the data volumes in the data volume set, the quantity of the data volumes in the data volume set obtained by collecting statistics is the set element quantity corresponding to the data volume set. In this case, a ratio is calculated by using the target data volume as a numerator and using the set element quantity as a denominator, and an obtained ratio result is the probability value corresponding to the target segment. The plurality of probability values corresponding to the plurality of target segments are obtained after the probability value corresponding to the target segment is obtained, where the plurality of target segments and the plurality of probability values are in a one-to-one correspondence.</p><p id="p-0120" num="0119">S<b>3085</b>: Determine a plurality of determined probability values corresponding to the plurality of target segments as the first sub-model corresponding to the first object.</p><p id="p-0121" num="0120">The first sub-model is the plurality of probability values corresponding to the plurality of target segments associated with the first objects.</p><p id="p-0122" num="0121">In this embodiment of this application, S<b>3081</b> may be implemented through S<b>30811</b> and S<b>30812</b>. In other words, the obtaining, by the server, a data volume range corresponding to each data volume in the data volume set includes S<b>30811</b> and S<b>30812</b>. The steps are described as follows:</p><p id="p-0123" num="0122">S<b>30811</b>: Convert the data volume in the data volume set, to obtain a converted data volume set.</p><p id="p-0124" num="0123">Since distribution corresponding to the data volume in the data volume set is usually logarithmic normal distribution, there is a smooth portion (a long tail portion) in the logarithmic normal distribution, a probability corresponding to the smooth portion is close to 0, a detection result for a larger data volume is inaccurate, and data support cannot be provided for subsequent abnormal online operational behavior detection. Therefore, to improve the accuracy of abnormal online operational behavior detection, the server converts the data volume in the data volume set and eliminates the smooth portion, so that distribution corresponding to each converted data volume in a data volume set after conversion obeys standard normal distribution.</p><p id="p-0125" num="0124">The conversion herein may be a logarithmic conversion, or may be a simultaneous reduction of a preset multiple, or may be a corresponding multiplication performed on the data volume by using different weights, or the like. This is not specifically limited in this embodiment of this application. The data volume is converted in a process of model obtaining, the data volume described in the processes of model obtaining and model application is a data volume after conversion.</p><p id="p-0126" num="0125">Referring to <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, when the data volume is an amount value, since an amount value corresponding to micropayment is sometimes small, for example, several yuan, and an amount value corresponding to large payment is sometimes large, for example, hundreds of thousands of yuan, a smooth portion <b>6</b>-<b>11</b> may appear in a distribution curve <b>6</b>-<b>1</b> corresponding to the data volume, a probability in probability distribution corresponding to the smooth portion <b>6</b>-<b>11</b> is almost 0, and data support cannot be provided for subsequent abnormal payment detection. In <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, a transverse axis is an amount value, and a longitudinal axis is a probability value. In this case, the data volume is converted by using a natural logarithm (ln), and the distribution curve <b>6</b>-<b>1</b> in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> is converted into a distribution curve <b>6</b>-<b>2</b> in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>. In <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, a transverse axis is a converted amount value, and a longitudinal axis is a probability value. It is easy to learn that, logarithm-taking operation is performed on the amount value, so that a fluctuation of several yuan can be encoded by the model during the micropayment, and a fluctuation of thousands or even tens of thousands of yuan can be encoded by the model during the large payment. Such a small sensitive and large insensitive trend is consistent with a change curve of a logarithmic function, for example, ln 2&#x2212;ln 1&#x2245;ln 20000&#x2212;ln 10000.</p><p id="p-0127" num="0126">S<b>30812</b>: Determine a range corresponding to each converted data volume in the converted data volume set as the data volume range.</p><p id="p-0128" num="0127">After obtaining the converted data volume set, the server extracts a minimum converted data volume and a maximum converted data volume from each converted data volume in a data volume set after conversion, where a range between the minimum converted data volume and the maximum converted data volume is the data volume range.</p><p id="p-0129" num="0128">Correspondingly, the collecting, by the server, statistics on a target quantity of data volumes of each target segment in the plurality of target segments from the data volume set described in S<b>3083</b> includes: collecting, by the server, statistics on a target quantity of converted data volumes of the target segment in the plurality of target segments from the converted data volume set. In other words, the server determines the target segment of the converted data volume in the converted data volume set, to further collect statistics on a quantity of the converted data volumes of the target segment in the plurality of target segments. The quantity of the converted data volumes of the target segment obtained by collecting statistics is the target quantity corresponding to the target segment. In addition, the data volume such as the target data volume is a corresponding data volume after conversion.</p><p id="p-0130" num="0129">In this embodiment of this application, S<b>310</b> may be implemented through S<b>3101</b> to S<b>3105</b>. In other words, the traversing, by the server, the first object set, and constructing at least one second object sub-model based on the first sub-model corresponding to the traversed first object includes S<b>3101</b> to S<b>3105</b>. The steps are described as follows:</p><p id="p-0131" num="0130">S<b>3101</b>: Traverse the first object set, determining a first sub-model corresponding to the 1st traversed first object as a current sub-model, and construct the 1st current sub-model set including the current sub-model.</p><p id="p-0132" num="0131">When the first object set is traversed, a current sub-model set corresponding to an associated second object is an empty set when the traversed first object is the 1st traversed first object. In this case, the server uses first sub-model corresponding to the 1st traversed first object as the current sub-model and an element in the current sub-model set, to construct the 1st current sub-model set.</p><p id="p-0133" num="0132">S<b>3102</b>: Perform the following processing by iterating i: comparing a first sub-model corresponding to a traversed i<sup>th </sup>first object with each current sub-model in an (i&#x2212;1)<sup>th </sup>current sub-model set, to obtain a similar sub-model, 2&#x3c;i&#x2264;I, i being an incremental positive integer variable, and I being a quantity of first objects in the first object set.</p><p id="p-0134" num="0133">When the traversed first object is another first object traversed after the 1st traversed first object, the server compares a first sub-model corresponding to a traversed i<sup>th </sup>first object with each current sub-model in an (i&#x2212;1)<sup>th </sup>current sub-model set, and selects a current sub-model most similar to the first sub-model corresponding to the i<sup>th </sup>first object from the (i&#x2212;1)<sup>th </sup>current sub-model set according to a comparison result, so that the similar sub-model is obtained.</p><p id="p-0135" num="0134">S<b>3103</b>: Merge the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model when a similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model is greater than a first preset similarity, to obtain a merged sub-model, and replace the similar sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set with the merged sub-model, to obtain an i<sup>th </sup>current sub-model set.</p><p id="p-0136" num="0135">After obtaining the similar sub-model, the server compares a similarity between the similar sub-model and the first sub-model corresponding to the i<sup>th </sup>first object with the first preset similarity. When the similarity between the similar sub-model and the first sub-model corresponding to the i<sup>th </sup>first object is greater than the first preset similarity, it indicates that a first object (for example, a convenience store A) corresponding to the first sub-model corresponding to the i<sup>th </sup>first object is similar to a first object (for example, convenience store B) corresponding to the similar sub-model in terms of the data volume. In this case, the server merges the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model, and a merged result is the merged sub-model. Then, the server replaces the similar sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set with the merged sub-model, and the (i&#x2212;1)<sup>th </sup>current sub-model set after replacement is the i<sup>th </sup>current sub-model set.</p><p id="p-0137" num="0136">S<b>3104</b>: Insert a to-be-updated sub-model into the current sub-model set when the similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model is less than or equal to the first preset similarity, to update the current sub-model set.</p><p id="p-0138" num="0137">When the similarity between the similar sub-model and the first sub-model corresponding to the i<sup>th </sup>first object is less than or equal to the first preset similarity, it indicates that a first object (for example, a convenience store A) corresponding to the first sub-model corresponding to the i<sup>th </sup>first object is not similar to a first object (for example, convenience store B) corresponding to the similar sub-model in terms of the data volume. In this case, the server inserts the first sub-model corresponding to the i<sup>th </sup>first object into the (i&#x2212;1)<sup>th </sup>current sub-model set, and the (i&#x2212;1)<sup>th </sup>current sub-model set after insertion is the i<sup>th </sup>current sub-model set.</p><p id="p-0139" num="0138">S<b>3105</b>: Determine an I<sup>th </sup>current sub-model set obtained by iterating i as the at least one second object sub-model.</p><p id="p-0140" num="0139">In this embodiment of this application, when the server traverses the first object set, for any first object in the first object set, a current sub-model set corresponding to a current first object is updated by performing S<b>3102</b> to S<b>3104</b>. After the first object set is traversed, an obtained current sub-model set after traversal and update is the constructed at least one second object sub-model.</p><p id="p-0141" num="0140">In this embodiment of this application, S<b>3102</b> further includes S<b>31021</b> to S<b>31024</b>. In other words, the comparing, by the server, a to-be-updated sub-model corresponding to the current first object in the first preset object model with each current sub-model in a current sub-model set corresponding to each second object, to obtain a similar sub-model includes S<b>31021</b> to S<b>31024</b>. The steps are described as follows:</p><p id="p-0142" num="0141">S<b>31021</b>: Obtain a plurality of first target probability values corresponding to the plurality of target segments from the first sub-model corresponding to the traversed i<sup>th </sup>first object.</p><p id="p-0143" num="0142">Since a first sub-model corresponding to each first object is a plurality of probability values corresponding to the plurality of target segments, the first sub-model corresponding to the traversed i<sup>th </sup>first object also includes the plurality of probability values corresponding to the plurality of target segments, referred to as the first target probability values corresponding to the target segments herein. That is, the plurality of first target probability values corresponding to the plurality of target segments refer to a relationship between a plurality of target segments and a plurality of probability values corresponding to the to-be-updated sub-model. The plurality of target segments and the plurality of first target probability values are in a one-to-one correspondence.</p><p id="p-0144" num="0143">S<b>31022</b>: Obtain a plurality of second target probability values corresponding to the plurality of target segments from the current sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set.</p><p id="p-0145" num="0144">The current sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set also includes the plurality of probability values corresponding to the plurality of target segments, referred to as the plurality of second target probability values corresponding to the plurality of target segments herein. That is, the plurality of second target probability values corresponding to the plurality of target segments refer to a relationship between a plurality of target segments and a plurality of probability values corresponding to the current sub-model. The plurality of target segments and the plurality of second target probability values are in a one-to-one correspondence.</p><p id="p-0146" num="0145">S<b>31023</b>: Compare the plurality of first target probability values with the plurality of second target probability values one by one to obtain a plurality of minimum probability values, and determine an accumulated sum of the plurality of minimum probability values as a similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the current sub-model.</p><p id="p-0147" num="0146">Since the plurality of first target probability values and the plurality of second target probability values are in a one-to-one correspondence, the server further compares a plurality of first target probability values of the first sub-model corresponding to the traversed i<sup>th </sup>first object with a plurality of second target probability values of the current sub-model, to determine the similarity between the first sub-model corresponding to the traversed i<sup>th </sup>first object and the current sub-model. At least one similarity corresponding to at least one current sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set is obtained after the similarity between the first sub-model corresponding to the traversed i<sup>th </sup>first object and the current sub-model is obtained.</p><p id="p-0148" num="0147">The plurality of minimum probability values and the plurality of first target probability values are in a one-to-one correspondence, the plurality of minimum probability values and the plurality of second target probability values are in a one-to-one correspondence, and the at least one current sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set and the plurality of similarities are in a one-to-one correspondence.</p><p id="p-0149" num="0148">Referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, <figref idref="DRAWINGS">FIG. <b>7</b></figref> is an exemplary schematic diagram of obtaining a similarity according to an embodiment of this application. As shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, in a coordinate system in which a horizontal coordinate is a logarithm-taking amount value and a vertical coordinate is a probability value, a similarity between a first sub-model <b>7</b>-<b>1</b> corresponding to the i<sup>th </sup>first object and each current sub-model <b>7</b>-<b>2</b> is an area corresponding to a region <b>7</b>-<b>3</b>. When a plurality of first target probability values corresponding to the first sub-model <b>7</b>-<b>1</b> corresponding to the i<sup>th </sup>first object is a<sub>j</sub>, a plurality of second target probability values corresponding to the current sub-model <b>7</b>-<b>2</b> is b<sub>i</sub>, and j is an integer greater than or equal to 2, a similarity S between the first sub-model <b>7</b>-<b>1</b> corresponding to the i<sup>th </sup>first object and the current sub-model <b>7</b>-<b>2</b> is shown in formula (1):</p><p id="p-0150" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>S=&#x3a3;</i><sub>j=1</sub><sup>n </sup>min(<i>a</i><sub>j</sub><i>,b</i><sub>j</sub>)&#x2003;&#x2003;(1), where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0151" num="0149">n is a quantity of the plurality of target segments.</p><p id="p-0152" num="0150">S<b>31024</b>: Select a highest similarity from determined at least one similarity corresponding to the (i&#x2212;1)<sup>th </sup>current sub-model set, and determine a current sub-model corresponding to the highest similarity in the (i&#x2212;1)<sup>th </sup>current sub-model set as the similar sub-model.</p><p id="p-0153" num="0151">In this embodiment of this application, the server obtains the highest similarity from the plurality of similarities, and uses a current sub-model corresponding to the highest similarity in the (i&#x2212;1)<sup>th </sup>current sub-model set as the similar sub-model.</p><p id="p-0154" num="0152">In this embodiment of this application, the merging, by the server, the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model, to obtain a merged sub-model described in S<b>3103</b> includes S<b>31031</b> to S<b>31034</b>. The steps are described as follows:</p><p id="p-0155" num="0153">S<b>31031</b>: Obtain a plurality of first target probability values corresponding to the plurality of target segments from the first sub-model corresponding to the i<sup>th </sup>first object.</p><p id="p-0156" num="0154">An implementation process of S<b>31031</b> is consistent with the implementation process described in S<b>31021</b>.</p><p id="p-0157" num="0155">S<b>31032</b>: Obtain a plurality of to-be-merged probability values corresponding to the plurality of target segments from the similar sub-model.</p><p id="p-0158" num="0156">The current sub-model also includes the plurality of probability values corresponding to the plurality of target segments, referred to as the plurality of second target probability values corresponding to the plurality of target segments herein. That is, the plurality of second target probability values corresponding to the plurality of target segments refer to a relationship between a plurality of target segments and a plurality of probability values corresponding to the current sub-model, where the plurality of target segments and the plurality of to-be-merged probability values.</p><p id="p-0159" num="0157">S<b>31033</b>: Compare the plurality of first target probability values with the plurality of to-be-merged probability values one by one, to obtain a plurality of maximum probability values.</p><p id="p-0160" num="0158">The plurality of first target probability values and the plurality of to-be-merged probability values are in a one-to-one correspondence, the plurality of maximum probability values and the plurality of first target probability values are in a one-to-one correspondence, and the plurality of maximum probability values and the plurality of to-be-merged probability values are in a one-to-one correspondence.</p><p id="p-0161" num="0159">S<b>31034</b>: Combine the plurality of target segments and the plurality of maximum probability values, to obtain the merged sub-model.</p><p id="p-0162" num="0160">Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, <figref idref="DRAWINGS">FIG. <b>8</b></figref> is an exemplary schematic diagram of obtaining a merged sub-model according to an embodiment of this application. As shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, in a coordinate system in which a horizontal coordinate is a logarithm-taking amount value and a vertical coordinate is a probability value, a first sub-model <b>8</b>-<b>1</b> corresponding to the i<sup>th </sup>first object and a merged sub-model <b>8</b>-<b>3</b> corresponding to a similar sub-model <b>8</b>-<b>2</b> are shown. When a plurality of first target probability values corresponding to the first sub-model <b>8</b>-<b>1</b> corresponding to the i<sup>th </sup>first object is a<sub>j</sub>, and a plurality of to-be-merged probability values corresponding to the similar sub-model <b>8</b>-<b>2</b> is c<sub>j</sub>, a process in which the first sub-model <b>8</b>-<b>1</b> corresponding to the i<sup>th </sup>first object and the similar sub-model <b>8</b>-<b>2</b> are merged to obtain the merged sub-model <b>8</b>-<b>3</b> may be implemented by using formula (2), which is expressed as follows:</p><p id="p-0163" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>C</i>={ . . . ,max(<i>a</i><sub>j</sub><i>,c</i><sub>j</sub>), . . . },<i>i&#x2208;n</i>&#x2003;&#x2003;(2), where<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0164" num="0161">C is used for representing the merged sub-model <b>8</b>-<b>3</b>.</p><p id="p-0165" num="0162">In this embodiment of this application, S<b>304</b> may be implemented through S<b>3041</b> to S<b>3044</b>. In other words, the obtaining, by the server, a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model includes S<b>3041</b> to S<b>3044</b>. The steps are described as follows:</p><p id="p-0166" num="0163">S<b>3041</b>: Obtain at least one target second object sub-model corresponding to the second target object from the second preset object model.</p><p id="p-0167" num="0164">Since the second object sub-model is obtained by combining at least one second preset object model corresponding to each second object, the server matches the second target object with the second object in the second preset object model, and at least one second object sub-model corresponding to a matched second object is the at least one target second object sub-model.</p><p id="p-0168" num="0165">S<b>3042</b>: Obtain at least one target similarity between the first target sub-model and the at least one target second object sub-model.</p><p id="p-0169" num="0166">In this embodiment of this application, the server compares the first target sub-model with each target second object sub-model, so that a target similarity between the first target sub-model and the target second object sub-model is obtained, and the at least one target similarity corresponding to the at least one target second object sub-model is obtained. The at least one target second object sub-model and the at least one target similarity are in a one-to-one correspondence.</p><p id="p-0170" num="0167">A process of obtaining a plurality of target similarities by the server is similar to the processes of obtaining a plurality of similarities described in S<b>31011</b> to S<b>31013</b>. Details are not described again in this embodiment of this application.</p><p id="p-0171" num="0168">S<b>3043</b>: Obtain a highest target similarity from the at least one target similarity.</p><p id="p-0172" num="0169">The highest target similarity is a target similarity that is highest in the at least one target similarity corresponding to the at least one target second object sub-model.</p><p id="p-0173" num="0170">S<b>3044</b>: Determine a target second object sub-model corresponding to the highest target similarity in the at least one target second object sub-model as the second target sub-model.</p><p id="p-0174" num="0171">The server selects a corresponding target second object sub-model from the at least one target second object sub-model according to the highest target similarity, and determines the selected target second object sub-model corresponding to the highest target similarity as the second target sub-model. The second target sub-model has the highest similarity with the first target sub-model.</p><p id="p-0175" num="0172">In this embodiment of this application, the obtaining, by the server, a target maximum data volume corresponding to the second target sub-model described in S<b>305</b> includes: determining, by the server, a maximum data volume corresponding to the second target object in the second preset object model as the target maximum data volume corresponding to the second target sub-model when the highest target similarity is greater than a second preset similarity; and determining, by the server, a preset data volume as the target maximum data volume corresponding to the second target sub-model when the highest target similarity is less than or equal to the second preset similarity. The preset data volume may be, for example, 0 or any other value. In addition, the first preset similarity and the second preset similarity may be the same or different. This is not specifically limited in this embodiment of this application.</p><p id="p-0176" num="0173">The following describes an exemplary application of this embodiment of this application in an actual application scenario by using an example in which abnormality detection is performed on a payment order in a payment scenario of an instant messaging client.</p><p id="p-0177" num="0174">Referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, <figref idref="DRAWINGS">FIG. <b>9</b></figref> is an exemplary schematic flowchart of abnormal online operational behavior detection according to an embodiment of this application. As shown in <figref idref="DRAWINGS">FIG. <b>9</b></figref>, in a payment scenario, after a user submits a payment order <b>9</b>-<b>1</b> (online operation behavior information), first, before the payment is completed according to the payment order, the server pulls the payment order and obtains an order triplet <b>9</b>-<b>2</b> from the payment order: a user <b>9</b>-<b>21</b> (a first target object), a merchant <b>9</b>-<b>22</b> (a first target object), and an amount value <b>9</b>-<b>23</b> (a target data volume).</p><p id="p-0178" num="0175">Then, the server obtains a merchant histogram <b>9</b>-<b>311</b> (a first target sub-model) corresponding to the merchant <b>9</b>-<b>22</b> from a merchant model <b>9</b>-<b>31</b> (a first preset object model), and determines a normal transaction threshold t<sub>u </sub>(an abnormal data volume) of the merchant <b>9</b>-<b>22</b> according to a 99<sup>th </sup>quantile (a preset model parameter) of the merchant histogram <b>9</b>-<b>311</b>; The process of determining the normal transaction threshold t<sub>u</sub>, is shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>. It is easy to learn that, the normal transaction threshold t<sub>u </sub>indicates that, when an amount value is greater than the normal transaction threshold t<sub>u</sub>, a payment order corresponding to the amount value exceeds 99% of the normal situation, and it is determined that the payment order corresponding to the amount value is an abnormal transaction on a merchant side. Since the amount value <b>9</b>-<b>23</b> is greater than the normal transaction threshold t<sub>u</sub>, it indicates that the payment order <b>9</b>-<b>1</b> exceeds 99% of the normal situation, and it is determined that the payment order <b>9</b>-<b>1</b> is of a result <b>9</b>-<b>41</b> (a first detection result) of abnormal transaction on the merchant side.</p><p id="p-0179" num="0176">Then, the server obtains a merchant histogram group <b>9</b>-<b>321</b> (at least one target second object sub-model) corresponding to the user <b>9</b>-<b>21</b> from a user model <b>9</b>-<b>32</b> (a second preset object model), and searches the merchant histogram group <b>9</b>-<b>321</b> for a merchant histogram <b>9</b>-<b>322</b> (a second target sub-model) most similar to the merchant histogram <b>9</b>-<b>311</b>. When a similarity between the merchant histogram <b>9</b>-<b>322</b> and the merchant histogram group <b>9</b>-<b>321</b> is greater than 0.8 (a second preset similarity), a historical maximum transaction amount (a maximum data volume corresponding to a second target object) corresponding to the user <b>9</b>-<b>21</b> in the user model <b>9</b>-<b>32</b> is obtained as the normal transaction t<sub>v </sub>(a target maximum data volume). Otherwise, it indicates that the user <b>9</b>-<b>21</b> has not consumed at the merchant <b>9</b>-<b>22</b>, and the normal transaction threshold t<sub>v </sub>is set to 0 (a preset data volume). It is easy to learn that, the normal transaction threshold t<sub>v </sub>indicates that, when an amount value is less than or equal to the normal transaction threshold t<sub>v</sub>, it indicates that the amount value has the same amount value in a historical payment order, and it is determined that a payment order corresponding to the amount value is a normal transaction on a user side. Since the amount value <b>9</b>-<b>23</b> is greater than the normal transaction threshold t<sub>v</sub>, it indicates that the amount value <b>9</b>-<b>23</b> has not appeared in the historical payment order, and it is determined that the payment order <b>9</b>-<b>1</b> is of a result <b>9</b>-<b>42</b> (a second detection result) of abnormal transaction on the user side.</p><p id="p-0180" num="0177">Finally, the payment order <b>9</b>-<b>1</b> is determined to be abnormal (a target detection result) according to a decision matrix shown in Table 1 with reference to the result <b>9</b>-<b>41</b> and the result <b>9</b>-<b>42</b>, which may be a transaction performed by a stolen account. In view of this, blocking processing <b>9</b>-<b>5</b> is performed on the payment order <b>9</b>-<b>1</b> to improve the network security.</p><p id="p-0181" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="offset" colwidth="49pt" align="left"/><colspec colname="1" colwidth="161pt" align="center"/><colspec colname="2" colwidth="7pt" align="center"/><thead><row><entry/><entry namest="offset" nameend="2" rowsep="1">TABLE 1</entry></row></thead><tbody valign="top"><row><entry/><entry namest="offset" nameend="2" align="center" rowsep="1"/></row><row><entry/><entry>Merchant side</entry><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="49pt" align="left"/><colspec colname="2" colwidth="70pt" align="left"/><colspec colname="3" colwidth="98pt" align="left"/><tbody valign="top"><row><entry>User side</entry><entry>Abnormal</entry><entry>Normal</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry>Abnormal</entry><entry>Abnormal payment</entry><entry>Suspected abnormal payment</entry></row><row><entry>Normal</entry><entry>Normal payment</entry><entry>Normal payment</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0182" num="0178">It is easy to learn from the decision matrix shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> that, the payment order is determined to be abnormal when the merchant side indicates that the payment order is abnormal and the user side indicates that the payment order is also abnormal; the payment order is determined to be normal when the merchant side indicates that the payment order is abnormal and the user side indicates that the payment order is normal; the payment order is determined to be a suspected abnormal payment when the merchant side indicates that the payment order is normal and the user side indicates that the payment order is abnormal, where in this case, abnormality of the payment order is determined according to an actual situation, that is, the payment order may be considered as normal or abnormal according to the actual situation; and the payment order is determined to be normal when the merchant side indicates that the payment order is normal and the user side also indicates that the payment order is normal.</p><p id="p-0183" num="0179">In addition, an embodiment of this application further provides another decision matrix, which is shown in Table 2:</p><p id="p-0184" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="offset" colwidth="35pt" align="left"/><colspec colname="1" colwidth="182pt" align="center"/><thead><row><entry/><entry namest="offset" nameend="1" rowsep="1">TABLE 2</entry></row></thead><tbody valign="top"><row><entry/><entry namest="offset" nameend="1" align="center" rowsep="1"/></row><row><entry/><entry>Merchant side</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="35pt" align="left"/><colspec colname="2" colwidth="91pt" align="left"/><colspec colname="3" colwidth="91pt" align="left"/><tbody valign="top"><row><entry>User side</entry><entry>Abnormal</entry><entry>Normal</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry>Abnormal</entry><entry>Abnormal payment</entry><entry>Suspected abnormal payment</entry></row><row><entry>Normal</entry><entry>Suspected abnormal payment</entry><entry>Normal payment</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0185" num="0180">It is easy to learn from the decision matrix shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> that, the payment order is determined to be abnormal when the merchant side indicates that the payment order is abnormal and the user side indicates that the payment order is also abnormal; the payment order is determined to be a suspected abnormal payment when the merchant side indicates that the payment order is abnormal and the user side indicates that the payment order is normal, where in this case, abnormality of the payment order is determined according to an actual situation, that is, the payment order may be considered as normal or abnormal according to the actual situation; the payment order is determined to be a suspected abnormal payment when the merchant side indicates that the payment order is normal and the user side indicates that the payment order is abnormal, where in this case, abnormality of the payment order is determined according to an actual situation, that is, the payment order may be considered as normal or abnormal according to the actual situation; and the payment order is determined to be normal when the merchant side indicates that the payment order is normal and the user side also indicates that the payment order is normal.</p><p id="p-0186" num="0181">There may be another decision matrix when the server determines the target detection result according to the first detection result and the second detection result. This is not listed one by one in this embodiment of this application.</p><p id="p-0187" num="0182">In addition, the foregoing process of determining the abnormality of the payment order is real-time, which is implemented in a real-time/online environment. The foregoing process of determining the abnormality of the payment order may further be applied to a scenario such as credit card anti-spoofing or black market confrontation.</p><p id="p-0188" num="0183">It may be understood that, in the payment scenario of the instant messaging client, abnormality detection is performed, and processing such as payment blocking or authentication is performed when the payment is determined to be abnormal based on a detection result, so that payment security of the instant messaging client can be ensured.</p><p id="p-0189" num="0184">The following continues to describe the application of abnormal online operational behavior detection in the payment scenario.</p><p id="p-0190" num="0185">Referring to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, <figref idref="DRAWINGS">FIG. <b>10</b></figref> is an exemplary schematic diagram of obtaining a model according to an embodiment of this application. As shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the server obtains a historical payment order <b>10</b>-<b>1</b> (a behavior information sample) recently generated (in a current preset cycle), where each payment order in the historical payment order <b>10</b>-<b>1</b> includes a user (a second object), a merchant (a first object), and an amount (a data volume).</p><p id="p-0191" num="0186">First, the historical payment order <b>10</b>-<b>1</b> is aggregated according to the merchant (a first preset object type) to obtain a transaction amount <b>10</b>-<b>2</b> (a data volume set) of all recent users of each merchant; after the transaction amount <b>10</b>-<b>2</b> of all the recent users of the merchant is converted by using a natural logarithm, segmented statistics is collected, to obtain an amount distribution histogram <b>10</b>-<b>31</b> (a first sub-model), where a histogram <b>11</b>-<b>1</b> shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref> is the amount distribution histogram <b>10</b>-<b>31</b> in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, and in a coordinate system, a horizontal coordinate is logarithm-taking amount value and a vertical coordinate is a probability value; and the amount distribution histogram <b>10</b>-<b>31</b> corresponding to the merchant is combined, to obtain a merchant model <b>10</b>-<b>3</b>.</p><p id="p-0192" num="0187">Further, the historical payment order <b>10</b>-<b>1</b> is aggregated according to the user (a second preset object type) to obtain merchants <b>10</b>-<b>41</b> (a first object set) that each user has recently paid for and a payment amount <b>10</b>-<b>42</b> of the user recently paid for the merchants, and selects a maximum payment amount <b>10</b>-<b>421</b> (a maximum data volume) from the payment amount <b>10</b>-<b>42</b> of the user recently paid for the merchants as a historical maximum payment amount.</p><p id="p-0193" num="0188">Then, the merchants <b>10</b>-<b>41</b> that each user has recently paid for are traversed, a corresponding merchant amount distribution histogram <b>10</b>-<b>32</b> is obtained from the merchant model <b>10</b>-<b>3</b> for each merchant <b>10</b>-<b>411</b> (an i<sup>th </sup>first object). The merchant amount distribution histogram <b>10</b>-<b>32</b> is directly inserted into a histogram group <b>10</b>-<b>51</b> (a current sub-model set) when each merchant <b>10</b>-<b>411</b> is the first traversed merchant in the merchants <b>10</b>-<b>41</b>; and the merchant amount distribution histogram <b>10</b>-<b>32</b> is compared with each histogram in the histogram group <b>10</b>-<b>51</b> when each merchant <b>10</b>-<b>411</b> is not the first traversed merchant in the merchants <b>10</b>-<b>41</b>, to compare a histogram <b>10</b>-<b>511</b> (a similar sub-model) with the highest similarity from the histogram group <b>10</b>-<b>51</b>. The comparison process is shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>. The merchant amount distribution histogram <b>10</b>-<b>32</b> is merged into the histogram <b>10</b>-<b>511</b> when a similarity between the histogram <b>10</b>-<b>511</b> and the merchant amount distribution histogram <b>10</b>-<b>32</b> is greater than 0.8 (a first preset similarity), where the merging process is shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>; and the merchant amount distribution histogram <b>10</b>-<b>32</b> is inserted into the histogram group <b>10</b>-<b>51</b> when the similarity between the histogram <b>10</b>-<b>511</b> and the merchant amount distribution histogram <b>10</b>-<b>32</b> is less than or equal to 0.8. In this way, after the merchants <b>10</b>-<b>41</b> are traversed (where the histogram group <b>10</b>-<b>51</b> is at least one second object sub-model), the histogram group <b>10</b>-<b>51</b> corresponding to each user is combined with the maximum payment amount <b>10</b>-<b>421</b> to obtain the second sub-model, so that a user model <b>10</b>-<b>5</b> (a second preset object model) is obtained.</p><p id="p-0194" num="0189">The process of obtaining the first preset object model and the second preset object model may be performed in an offline environment.</p><p id="p-0195" num="0190">It may be understood that, the abnormal online operational behavior detection method provided in the embodiments of this application is performed in an unsupervised manner, and there is no need to label, thereby improving the enforceability of detection in the payment scenario of the instant messaging client. Furthermore, in the process of obtaining the merchant model and the user model, only the merchant, the user, and the amount value are required, so that abnormal online operational behavior detection in the payment scenario of the instant messaging client may be accurately implemented even when there are three dimensional features. In addition, since data annotation is not required for obtaining the merchant model and the user model, the obtaining efficiency is improved, so that the obtained merchant model and the user model are time-based and can be applied to a real-time payment environment of the instant messaging client.</p><p id="p-0196" num="0191">The following further describes an exemplary structure in which the abnormal online operational behavior detection apparatus <b>455</b> provided in this embodiment of this application is implemented as software modules. In some embodiments, as shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the software module stored in the abnormal online operational behavior detection apparatus <b>455</b> of the memory <b>450</b> may include:</p><p id="p-0197" num="0192">an information obtaining module <b>4551</b>, configured to acquire online operation behavior information, the online operation behavior information including a first target object, a second target object, and a target data volume;</p><p id="p-0198" num="0193">a first detection module <b>4552</b>, configured to obtain a first target sub-model corresponding to the first target object from a first preset object model,</p><p id="p-0199" num="0194">the first detection module <b>4552</b> being further configured to determine an abnormal data volume from the first target sub-model based on a preset model parameter, and determine a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume;</p><p id="p-0200" num="0195">a second detection module <b>4553</b>, configured to obtain a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model,</p><p id="p-0201" num="0196">the second detection module <b>4553</b> being further configured to obtain a target maximum data volume corresponding to the second target sub-model, and determine a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume; and</p><p id="p-0202" num="0197">a result determination module <b>4554</b>, configured to determine a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result.</p><p id="p-0203" num="0198">In this embodiment of this application, the abnormal online operational behavior detection apparatus <b>455</b> further includes a model obtaining module <b>4555</b>, configured to: obtain a behavior information sample; aggregate the behavior information sample according to a first preset object type to obtain a data volume set corresponding to each first object, construct a first sub-model corresponding to the first object according to the data volume set, and determine each constructed first sub-model corresponding to the first object as the first preset object model; aggregate the behavior information sample according to a second preset object type, to obtain a first object set and a maximum data volume corresponding to each second object; traverse the first object set, and constructing at least one second object sub-model based on the first sub-model corresponding to the traversed first object; and combine the at least one second object sub-model and the maximum data volume into a second sub-model corresponding to the second object, and determine each combined second sub-model corresponding to the second object as the second preset object model.</p><p id="p-0204" num="0199">In this embodiment of this application, the model obtaining module <b>4555</b> is further configured to: obtain a data volume range corresponding to each data volume in the data volume set; segment the data volume range to obtain a plurality of target segments; collect statistics on a target quantity of data volumes of each target segment in the plurality of target segments from the data volume set; determine a ratio of the target quantity to a set element quantity corresponding to the data volume set as a probability value corresponding to the target segment; and determine a plurality of determined probability values corresponding to the plurality of target segments as the first sub-model corresponding to the first object.</p><p id="p-0205" num="0200">In this embodiment of this application, the model obtaining module <b>4555</b> is further configured to: convert the data volume in the data volume set, to obtain a converted data volume set; and determine a range corresponding to each converted data volume in the converted data volume set as the data volume range.</p><p id="p-0206" num="0201">In this embodiment of this application, the model obtaining module <b>4555</b> is further configured to collect statistics on a target quantity of converted data volumes of the target segment in the plurality of target segments from the converted data volume set.</p><p id="p-0207" num="0202">In this embodiment of this application, the model obtaining module <b>4555</b> is further configured to: traverse the first object set, determine a first sub-model corresponding to the 1st traversed first object as a current sub-model, and construct the 1st current sub-model set including the current sub-model; and perform the following processing by iterating i: comparing a first sub-model corresponding to a traversed i<sup>th </sup>first object with each current sub-model in an (i&#x2212;1)<sup>th </sup>current sub-model set, to obtain a similar sub-model, 2&#x3c;i&#x2264;i&#x2264;I, i being an incremental positive integer variable, and I being a quantity of first objects in the first object set; merge the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model when a similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model is greater than a first preset similarity, to obtain a merged sub-model, and replace the similar sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set with the merged sub-model, to obtain an i<sup>th </sup>current sub-model set; insert the first sub-model corresponding to the i<sup>th </sup>first object into the (i&#x2212;1)<sup>th </sup>current sub-model set when the similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model is less than or equal to the first preset similarity, to obtain the i<sup>th </sup>current sub-model set; and determine an I<sup>th </sup>current sub-model set obtained by iterating i as the at least one second object sub-model.</p><p id="p-0208" num="0203">In this embodiment of this application, the model obtaining module <b>4555</b> is further configured to: obtain a plurality of first target probability values corresponding to the plurality of target segments from the first sub-model corresponding to the traversed i<sup>th </sup>first object; obtain a plurality of second target probability values corresponding to the plurality of target segments from the current sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set; compare the plurality of first target probability values with the plurality of second target probability values one by one to obtain a plurality of minimum probability values, and determine an accumulated sum of the plurality of minimum probability values as a similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the current sub-model; and select a highest similarity from determined at least one similarity corresponding to the (i&#x2212;1)<sup>th </sup>current sub-model set, and determine a current sub-model corresponding to the highest similarity in the (i&#x2212;1)<sup>th </sup>current sub-model set as the similar sub-model.</p><p id="p-0209" num="0204">In this embodiment of this application, the model obtaining module <b>4555</b> is further configured to: obtain a plurality of first target probability values corresponding to the plurality of target segments from the first sub-model corresponding to the i<sup>th </sup>first object; obtain a plurality of to-be-merged probability values corresponding to the plurality of target segments from the similar sub-model; compare the plurality of first target probability values with the plurality of to-be-merged probability values one by one, to obtain a plurality of maximum probability values; and combine the plurality of target segments and the plurality of maximum probability values, to obtain the merged sub-model.</p><p id="p-0210" num="0205">In this embodiment of this application, the second detection module <b>4553</b> is further configured to: obtain at least one target second object sub-model corresponding to the second target object from the second preset object model; obtain at least one target similarity between the first target sub-model and the at least one target second object sub-model; obtain a highest target similarity from the at least one target similarity; and determine a target second object sub-model corresponding to the highest target similarity in the at least one target second object sub-model as the second target sub-model.</p><p id="p-0211" num="0206">In this embodiment of this application, the second detection module <b>4553</b> is further configured to: determine a maximum data volume corresponding to the second target object in the second preset object model as the target maximum data volume corresponding to the second target sub-model when the highest target similarity is greater than a second preset similarity; and determine a preset data volume as the target maximum data volume corresponding to the second target sub-model when the highest target similarity is less than or equal to the second preset similarity.</p><p id="p-0212" num="0207">In this embodiment of this application, the first detection module <b>4552</b> is further configured to: determine, when the target data volume is greater than the abnormal data volume, that the online operation behavior information is abnormal with respect to the first target object, the first detection result being that the online operation behavior information is abnormal with respect to the first target object; and determine, when the target data volume is less than or equal to the abnormal data volume, that the online operation behavior information is normal with respect to the first target object, the first detection result being that the online operation behavior information is normal with respect to the first target object.</p><p id="p-0213" num="0208">In this embodiment of this application, the second detection module <b>4553</b> is further configured to: determine, when the target data volume is greater than the target maximum data volume, that the online operation behavior information is abnormal with respect to the second target object, the second detection result being that the online operation behavior information is abnormal with respect to the second target object; and determine, when the target data volume is less than or equal to the target maximum data volume, that the online operation behavior information is normal with respect to the second target object, the second detection result being that the online operation behavior information is normal with respect to the second target object.</p><p id="p-0214" num="0209">In this embodiment of this application, the result determination module <b>4554</b> is further configured to: when the first detection result is that the online operation behavior information is abnormal with respect to the first target object and the second detection result is that the online operation behavior information is abnormal with respect to the second target object, determine the target detection result including that the online operation behavior information is abnormal; when the first detection result is that the online operation behavior information is normal with respect to the first target object and the second detection result is that the online operation behavior information is abnormal with respect to the second target object, determine the target detection result including that the online operation behavior information is abnormal; when the first detection result is that the online operation behavior information is normal with respect to the first target object and the second detection result is that the online operation behavior information is normal with respect to the second target object, determine the target detection result including that the online operation behavior information is normal; and when the first detection result is that the online operation behavior information is abnormal with respect to the first target object and the second detection result is that the online operation behavior information is normal with respect to the second target object, determine the target detection result including that the online operation behavior information is normal; and</p><p id="p-0215" num="0210">An embodiment of this application provides a computer program product or a computer program. The computer program product or the computer program includes computer instructions, and the computer instructions are stored in a computer-readable storage medium. A processor of an abnormal online operational behavior detection device reads the computer instructions from the computer-readable storage medium. The processor executes the computer instructions, to cause the computer device to perform the abnormal online operational behavior detection method of the embodiments of this application.</p><p id="p-0216" num="0211">An embodiment of this application provides a computer-readable storage medium storing executable instructions, the executable instructions, when executed by a processor, causing the processor to perform the abnormal online operational behavior detection method provided in the embodiments of this application, for example, the abnormal online operational behavior detection method shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0217" num="0212">In some embodiments, the computer-readable storage medium may be a memory such as a ferroelectric RAM (FRAM), a ROM, a programmable ROM (PROM), an electrically programmable ROM (EPROM), an electrically erasable PROM (EEPROM), a flash memory, a magnetic surface memory, an optical disk, or a CD-ROM, or may be any device including one of or any combination of the foregoing memories.</p><p id="p-0218" num="0213">In some embodiments, the executable instructions can be written in a form of a program, software, a software module, a script, or code and according to a programming language (including a compiler or interpreter language or a declarative or procedural language) in any form, and may be deployed in any form, including an independent program or a module, a component, a subroutine, or another unit suitable for use in a computing environment.</p><p id="p-0219" num="0214">In an example, the executable instructions may, but do not necessarily, correspond to a file in a file system, and may be stored in a part of a file that saves another program or other data, for example, be stored in one or more scripts in a hypertext markup language (HTML) file, stored in a file that is specially used for a program in discussion, or stored in the plurality of collaborative files (for example, be stored in files of one or modules, subprograms, or code parts).</p><p id="p-0220" num="0215">In an example, the executable instructions can be deployed for execution on one computing device, execution on a plurality of computing devices located at one location, or execution on a plurality of computing devices that are distributed at a plurality of locations and that are interconnected through a communication network.</p><p id="p-0221" num="0216">Based on the above, in the embodiments of this application, when the online operation behavior information includes three dimensional features of the first target object, the second target object, and the target data volume, when the target detection result of whether the online operation behavior information is abnormal is determined with reference to results of respectively comparing the target data volume with the abnormal data volume and the target maximum data volume, since the abnormal data volume is an abnormality judgment condition for the first target object determined based on the first preset object model, and the target maximum data volume is an abnormality judgment condition for the second target object determined based on the second preset object model, in a low-dimensional feature, whether the target data volume is within a preset interval is determined from two dimensions of the first target object and the second target object, to further accurately obtain the target detection result of whether the online operation behavior information is abnormal, so that the accuracy of abnormal online operational behavior detection is relatively high.</p><p id="p-0222" num="0217">The foregoing descriptions are merely embodiments of this application and are not intended to limit the protection scope of this application. Any modification, equivalent replacement, or improvement made without departing from the spirit and range of this application shall fall within the protection scope of this application. In this application, the term &#x201c;unit&#x201d; or &#x201c;module&#x201d; in this application refers to a computer program or part of the computer program that has a predefined function and works together with other related parts to achieve a predefined goal and may be all or partially implemented by using software, hardware (e.g., processing circuitry and/or memory configured to perform the predefined functions), or a combination thereof. Each unit or module can be implemented using one or more processors (or processors and memory). Likewise, a processor (or processors and memory) can be used to implement one or more modules or units. Moreover, each module or unit can be part of an overall module that includes the functionalities of the module or unit.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An abnormal online operational behavior detection method, performed by an electronic device, the method comprising:<claim-text>acquiring online operation behavior information, the online operation behavior information comprising a first target object, a second target object, and a target data volume;</claim-text><claim-text>obtaining a first target sub-model corresponding to the first target object from a first preset object model;</claim-text><claim-text>determining an abnormal data volume from the first target sub-model based on a preset model parameter, and determining a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume;</claim-text><claim-text>obtaining a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model;</claim-text><claim-text>obtaining a target maximum data volume corresponding to the second target sub-model, and determining a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume; and</claim-text><claim-text>determining a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first preset object model and the second preset object model are generated by:<claim-text>obtaining a behavior information sample;</claim-text><claim-text>aggregating the behavior information sample according to a first preset object type to obtain a data volume set corresponding to each first object, constructing a first sub-model corresponding to the first object according to the data volume set, and determining each constructed first sub-model corresponding to the first object as the first preset object model;</claim-text><claim-text>aggregating the behavior information sample according to a second preset object type, to obtain a first object set and a maximum data volume corresponding to each second object;</claim-text><claim-text>traversing the first object set, and constructing at least one second object sub-model based on the first sub-model corresponding to the traversed first object; and</claim-text><claim-text>combining the at least one second object sub-model and the maximum data volume into a second sub-model corresponding to the second object, and determining each combined second sub-model corresponding to the second object as the second preset object model.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the constructing a first sub-model corresponding to the first object according to the data volume set comprises:<claim-text>obtaining a data volume range corresponding to each data volume in the data volume set;</claim-text><claim-text>segmenting the data volume range to obtain a plurality of target segments;</claim-text><claim-text>collecting statistics on a target quantity of data volumes of each target segment in the plurality of target segments from the data volume set;</claim-text><claim-text>determining a ratio of the target quantity to a set element quantity corresponding to the data volume set as a probability value corresponding to the target segment; and</claim-text><claim-text>determining a plurality of determined probability values corresponding to the plurality of target segments as the first sub-model corresponding to the first object.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the obtaining a data volume range corresponding to each data volume in the data volume set comprises:<claim-text>converting the data volume in the data volume set, to obtain a converted data volume set; and</claim-text><claim-text>determining a range corresponding to each converted data volume in the converted data volume set as the data volume range; and</claim-text><claim-text>the collecting statistics on a target quantity of data volumes of each target segment in the plurality of target segments from the data volume set comprises:</claim-text><claim-text>collecting statistics on a target quantity of converted data volumes of the target segment in the plurality of target segments from the converted data volume set.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the traversing the first object set, and constructing at least one second object sub-model based on the first sub-model corresponding to the traversed first object comprises:<claim-text>traversing the first object set, determining a first sub-model corresponding to the 1st traversed first object as a current sub-model, and constructing the 1st current sub-model set comprising the current sub-model; and</claim-text><claim-text>performing the following processing by iterating i:</claim-text><claim-text>comparing a first sub-model corresponding to a traversed i<sup>th </sup>first object with each current sub-model in an (i&#x2212;1)<sup>th </sup>current sub-model set, to obtain a similar sub-model, 2&#x3c;i&#x2264;I, i being an incremental positive integer variable, and I being a quantity of first objects in the first object set;</claim-text><claim-text>merging the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model when a similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model is greater than a first preset similarity, to obtain a merged sub-model, and replacing the similar sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set with the merged sub-model, to obtain an i<sup>th </sup>current sub-model set;</claim-text><claim-text>inserting the first sub-model corresponding to the i<sup>th </sup>first object into the (i&#x2212;1)<sup>th </sup>current sub-model set when the similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model is less than or equal to the first preset similarity, to obtain the i<sup>th </sup>current sub-model set; and</claim-text><claim-text>determining an I<sup>th </sup>current sub-model set obtained by iterating i as the at least one second object sub-model.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the comparing a first sub-model corresponding to a traversed i<sup>th </sup>first object with each current sub-model in an (i&#x2212;1)<sup>th </sup>current sub-model set, to obtain a similar sub-model comprises:<claim-text>obtaining a plurality of first target probability values corresponding to the plurality of target segments from the first sub-model corresponding to the traversed i<sup>th </sup>first object;</claim-text><claim-text>obtaining a plurality of second target probability values corresponding to the plurality of target segments from the current sub-model in the (i&#x2212;1)<sup>th </sup>current sub-model set;</claim-text><claim-text>comparing the plurality of first target probability values with the plurality of second target probability values one by one to obtain a plurality of minimum probability values, and determining an accumulated sum of the plurality of minimum probability values as a similarity between the first sub-model corresponding to the i<sup>th </sup>first object and the current sub-model; and</claim-text><claim-text>selecting a highest similarity from determined at least one similarity corresponding to the (i&#x2212;1)<sup>th </sup>current sub-model set, and determining a current sub-model corresponding to the highest similarity in the (i&#x2212;1)<sup>th </sup>current sub-model set as the similar sub-model.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the merging the first sub-model corresponding to the i<sup>th </sup>first object and the similar sub-model, to obtain a merged sub-model comprises:<claim-text>obtaining a plurality of first target probability values corresponding to the plurality of target segments from the first sub-model corresponding to the i<sup>th </sup>first object;</claim-text><claim-text>obtaining a plurality of to-be-merged probability values corresponding to the plurality of target segments from the similar sub-model;</claim-text><claim-text>comparing the plurality of first target probability values with the plurality of to-be-merged probability values one by one, to obtain a plurality of maximum probability values; and</claim-text><claim-text>combining the plurality of target segments and the plurality of maximum probability values, to obtain the merged sub-model.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the obtaining a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model comprises:<claim-text>obtaining at least one target second object sub-model corresponding to the second target object from the second preset object model;</claim-text><claim-text>obtaining at least one target similarity between the first target sub-model and the at least one target second object sub-model;</claim-text><claim-text>obtaining a highest target similarity from the at least one target similarity; and</claim-text><claim-text>determining a target second object sub-model corresponding to the highest target similarity in the at least one target second object sub-model as the second target sub-model.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the obtaining a target maximum data volume corresponding to the second target sub-model comprises:<claim-text>determining a maximum data volume corresponding to the second target object in the second preset object model as the target maximum data volume corresponding to the second target sub-model when the highest target similarity is greater than a second preset similarity; and</claim-text><claim-text>determining a preset data volume as the target maximum data volume corresponding to the second target sub-model when the highest target similarity is less than or equal to the second preset similarity.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume comprises:<claim-text>determining, when the target data volume is greater than the abnormal data volume, that the online operation behavior information is abnormal with respect to the first target object, the first detection result being that the online operation behavior information is abnormal with respect to the first target object; and</claim-text><claim-text>determining, when the target data volume is less than or equal to the abnormal data volume, that the online operation behavior information is normal with respect to the first target object, the first detection result being that the online operation behavior information is normal with respect to the first target object.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume comprises:<claim-text>determining, when the target data volume is greater than the target maximum data volume, that the online operation behavior information is abnormal with respect to the second target object, the second detection result being that the online operation behavior information is abnormal with respect to the second target object; and</claim-text><claim-text>determining, when the target data volume is less than or equal to the target maximum data volume, that the online operation behavior information is normal with respect to the second target object, the second detection result being that the online operation behavior information is normal with respect to the second target object.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the determining a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result comprises:<claim-text>when the first detection result is that the online operation behavior information is abnormal with respect to the first target object and the second detection result is that the online operation behavior information is abnormal with respect to the second target object, determining the target detection result comprising that the online operation behavior information is abnormal;</claim-text><claim-text>when the first detection result is that the online operation behavior information is normal with respect to the first target object and the second detection result is that the online operation behavior information is abnormal with respect to the second target object, determining the target detection result comprising that the online operation behavior information is abnormal;</claim-text><claim-text>when the first detection result is that the online operation behavior information is normal with respect to the first target object and the second detection result is that the online operation behavior information is normal with respect to the second target object, determining the target detection result comprising that the online operation behavior information is normal; and</claim-text><claim-text>when the first detection result is that the online operation behavior information is abnormal with respect to the first target object and the second detection result is that the online operation behavior information is normal with respect to the second target object, determining the target detection result comprising that the online operation behavior information is normal.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. An electronic device for detecting abnormal online operational behaviors, comprising:<claim-text>a memory, configured to store executable instructions; and</claim-text><claim-text>a processor, configured to implement, when executing the executable instructions stored in the memory, an abnormal online operational behavior detection method including:</claim-text><claim-text>acquiring online operation behavior information, the online operation behavior information comprising a first target object, a second target object, and a target data volume;</claim-text><claim-text>obtaining a first target sub-model corresponding to the first target object from a first preset object model;</claim-text><claim-text>determining an abnormal data volume from the first target sub-model based on a preset model parameter, and determining a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume;</claim-text><claim-text>obtaining a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model;</claim-text><claim-text>obtaining a target maximum data volume corresponding to the second target sub-model, and determining a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume; and</claim-text><claim-text>determining a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The electronic device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the first preset object model and the second preset object model are generated by:<claim-text>obtaining a behavior information sample;</claim-text><claim-text>aggregating the behavior information sample according to a first preset object type to obtain a data volume set corresponding to each first object, constructing a first sub-model corresponding to the first object according to the data volume set, and determining each constructed first sub-model corresponding to the first object as the first preset object model;</claim-text><claim-text>aggregating the behavior information sample according to a second preset object type, to obtain a first object set and a maximum data volume corresponding to each second object;</claim-text><claim-text>traversing the first object set, and constructing at least one second object sub-model based on the first sub-model corresponding to the traversed first object; and</claim-text><claim-text>combining the at least one second object sub-model and the maximum data volume into a second sub-model corresponding to the second object, and determining each combined second sub-model corresponding to the second object as the second preset object model.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The electronic device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the obtaining a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model comprises:<claim-text>obtaining at least one target second object sub-model corresponding to the second target object from the second preset object model;</claim-text><claim-text>obtaining at least one target similarity between the first target sub-model and the at least one target second object sub-model;</claim-text><claim-text>obtaining a highest target similarity from the at least one target similarity; and</claim-text><claim-text>determining a target second object sub-model corresponding to the highest target similarity in the at least one target second object sub-model as the second target sub-model.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The electronic device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the determining a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume comprises:<claim-text>determining, when the target data volume is greater than the abnormal data volume, that the online operation behavior information is abnormal with respect to the first target object, the first detection result being that the online operation behavior information is abnormal with respect to the first target object; and</claim-text><claim-text>determining, when the target data volume is less than or equal to the abnormal data volume, that the online operation behavior information is normal with respect to the first target object, the first detection result being that the online operation behavior information is normal with respect to the first target object.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The electronic device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the determining a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume comprises:<claim-text>determining, when the target data volume is greater than the target maximum data volume, that the online operation behavior information is abnormal with respect to the second target object, the second detection result being that the online operation behavior information is abnormal with respect to the second target object; and</claim-text><claim-text>determining, when the target data volume is less than or equal to the target maximum data volume, that the online operation behavior information is normal with respect to the second target object, the second detection result being that the online operation behavior information is normal with respect to the second target object.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The electronic device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the determining a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result comprises:<claim-text>when the first detection result is that the online operation behavior information is abnormal with respect to the first target object and the second detection result is that the online operation behavior information is abnormal with respect to the second target object, determining the target detection result comprising that the online operation behavior information is abnormal;</claim-text><claim-text>when the first detection result is that the online operation behavior information is normal with respect to the first target object and the second detection result is that the online operation behavior information is abnormal with respect to the second target object, determining the target detection result comprising that the online operation behavior information is abnormal;</claim-text><claim-text>when the first detection result is that the online operation behavior information is normal with respect to the first target object and the second detection result is that the online operation behavior information is normal with respect to the second target object, determining the target detection result comprising that the online operation behavior information is normal; and</claim-text><claim-text>when the first detection result is that the online operation behavior information is abnormal with respect to the first target object and the second detection result is that the online operation behavior information is normal with respect to the second target object, determining the target detection result comprising that the online operation behavior information is normal.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A non-transitory computer-readable storage medium, storing executable instructions that, when executed by a processor of an electronic device, cause the electronic device to implement an abnormal online operational behavior detection method including:<claim-text>acquiring online operation behavior information, the online operation behavior information comprising a first target object, a second target object, and a target data volume;</claim-text><claim-text>obtaining a first target sub-model corresponding to the first target object from a first preset object model;</claim-text><claim-text>determining an abnormal data volume from the first target sub-model based on a preset model parameter, and determining a first detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the abnormal data volume;</claim-text><claim-text>obtaining a second target sub-model corresponding to the second target object and having a highest similarity with the first target sub-model from a second preset object model;</claim-text><claim-text>obtaining a target maximum data volume corresponding to the second target sub-model, and determining a second detection result corresponding to the online operation behavior information based on a comparison result between the target data volume and the target maximum data volume; and</claim-text><claim-text>determining a target detection result of the online operation behavior information in accordance with the first detection result and the second detection result.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable storage medium according to <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the first preset object model and the second preset object model are generated by:<claim-text>obtaining a behavior information sample;</claim-text><claim-text>aggregating the behavior information sample according to a first preset object type to obtain a data volume set corresponding to each first object, constructing a first sub-model corresponding to the first object according to the data volume set, and determining each constructed first sub-model corresponding to the first object as the first preset object model;</claim-text><claim-text>aggregating the behavior information sample according to a second preset object type, to obtain a first object set and a maximum data volume corresponding to each second object;</claim-text><claim-text>traversing the first object set, and constructing at least one second object sub-model based on the first sub-model corresponding to the traversed first object; and</claim-text><claim-text>combining the at least one second object sub-model and the maximum data volume into a second sub-model corresponding to the second object, and determining each combined second sub-model corresponding to the second object as the second preset object model.</claim-text></claim-text></claim></claims></us-patent-application>
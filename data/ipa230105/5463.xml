<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005464A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005464</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17942644</doc-number><date>20220912</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>PCT/JP2020/044293</doc-number><date>20201127</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>10</class><subclass>K</subclass><main-group>15</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>S</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>10</class><subclass>K</subclass><main-group>15</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>S</subclass><main-group>7</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">LIVE DATA DISTRIBUTION METHOD, LIVE DATA DISTRIBUTION SYSTEM, AND LIVE DATA DISTRIBUTION APPARATUS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/011374</doc-number><date>20210319</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17942644</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>YAMAHA CORPORATION</orgname><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>SHIRAKIHARA</last-name><first-name>Futoshi</first-name><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>MORIKAWA</last-name><first-name>Tadashi</first-name><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>NOTO</last-name><first-name>Kentaro</first-name><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>ISHIKAWA</last-name><first-name>Katsumi</first-name><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>OKUMURA</last-name><first-name>Hiraku</first-name><address><city>Hamamatsu-shi</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A live data distribution method obtains information on a sound source according to sound generated at the first venue, and information on space reverberation, as distribution data, distributes the distribution data to the second venue, and renders the distribution data and providing sound according to the distribution data at the second venue.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="199.56mm" wi="149.10mm" file="US20230005464A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="201.76mm" wi="151.13mm" file="US20230005464A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="116.50mm" wi="107.44mm" file="US20230005464A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="116.50mm" wi="98.64mm" file="US20230005464A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="158.92mm" wi="108.03mm" orientation="landscape" file="US20230005464A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="111.08mm" wi="134.28mm" file="US20230005464A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="134.96mm" wi="56.22mm" file="US20230005464A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="111.08mm" wi="134.28mm" file="US20230005464A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="156.97mm" wi="64.85mm" file="US20230005464A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="201.76mm" wi="155.11mm" file="US20230005464A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="110.49mm" wi="99.06mm" file="US20230005464A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="201.76mm" wi="151.13mm" file="US20230005464A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="158.92mm" wi="108.03mm" orientation="landscape" file="US20230005464A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="201.76mm" wi="151.13mm" file="US20230005464A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="111.25mm" wi="152.32mm" file="US20230005464A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="201.76mm" wi="151.13mm" file="US20230005464A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="140.63mm" wi="155.96mm" file="US20230005464A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="164.85mm" wi="84.41mm" orientation="landscape" file="US20230005464A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="90.00mm" wi="88.14mm" file="US20230005464A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">The present application is a continuation application of International Patent Application No. PCT/JP2021/011374, filed on Mar. 19, 2021, which claims priority to International Patent Application No. PCT/JP2020/044293, filed on Nov. 27, 2020. The contents of these applications are incorporated herein by reference in their entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">An embodiment of the present disclosure relates to a live data distribution method, a live data distribution system, and a live data distribution apparatus.</p><p id="p-0004" num="0003">In Japanese Unexamined Patent Application Publication No. 2015-530043, in order to provide a more immersive spatial audio experience, a system to render spatial audio content in a listening environment is disclosed.</p><p id="p-0005" num="0004">It is described that the system of Japanese Unexamined Patent Application Publication No. 2015-530043 measures an impulse response of a sound to be outputted from a speaker in the listening environment, and performs filter processing according to a measured impulse response.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0006" num="0005">The system of Japanese Unexamined Patent Application Publication No. 2015-530043 is not a distribution system for live data. In a case in which the live data is distributed, realistic sensation in a live venue is also desired to be provided to a venue being a distribution destination.</p><p id="p-0007" num="0006">An embodiment of the present disclosure is directed to provide a live data distribution method, a live data distribution system, and a live data distribution apparatus that, in a case in which live data is distributed, are also able to provide realistic sensation in a live venue, to a venue being a distribution destination.</p><p id="p-0008" num="0007">A live data distribution method obtains information on a sound source according to sound generated at the first venue, and information on space reverberation, as distribution data, distributes the distribution data to the second venue, and renders the distribution data and providing sound according to the distribution data at the second venue.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a plan schematic diagram of a first venue <b>10</b>.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a plan schematic diagram of a second venue <b>20</b>.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram showing a configuration of a mixer <b>11</b>.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram showing a configuration of a distribution apparatus <b>12</b>.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow chart showing an operation of the distribution apparatus <b>12</b>.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram showing a configuration of a reproduction apparatus <b>22</b>.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flow chart showing an operation of the reproduction apparatus <b>22</b>.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>A according to a first modification.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a plan schematic diagram of a second venue <b>20</b> in the live data distribution system <b>1</b>A according to the first modification.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>B according to a second modification.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram showing a configuration of an AV receiver <b>32</b>.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>C according to a third modification.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a block diagram showing a configuration of a terminal <b>42</b>.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>D according to a fourth modification.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a view showing an example of a live video <b>700</b> displayed on a reproduction apparatus in each venue.</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a block diagram showing an application example of signal processing performed by the reproduction apparatus.</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a schematic diagram showing a path of a sound reflected by a wall surface from a sound source <b>70</b> and arriving at a sound receiving point <b>75</b>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>. The live data distribution system <b>1</b> includes a plurality of acoustic devices and information processing apparatuses that are installed in each of a first venue <b>10</b> and a second venue <b>20</b>.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a plan schematic diagram of a first venue <b>10</b>, and <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a plan schematic diagram of a second venue <b>20</b>. In this example, the first venue <b>10</b> is a live venue in which a performer performs a performance. The second venue <b>20</b> is a public viewing venue in which a listener at a remote place watches the performance by the performer.</p><p id="p-0029" num="0028">A mixer <b>11</b>, a distribution apparatus <b>12</b>, a plurality of microphones <b>13</b>A to <b>13</b>F, a plurality of speakers <b>14</b>A to <b>14</b>G, a plurality of trackers <b>15</b>A to <b>15</b>C, and a camera <b>16</b> are installed in the first venue <b>10</b>. A mixer <b>21</b>, a reproduction apparatus <b>22</b>, a display <b>23</b>, and a plurality of speakers <b>24</b>A to <b>24</b>F are installed in the second venue <b>20</b>. The distribution apparatus <b>12</b> and the reproduction apparatus <b>22</b> are connected through Internet <b>5</b>. It is to be noted that the number of microphones, the number of speakers, the number of trackers, and the like are not limited to the number shown in the present embodiment. In addition, the installation mode of the microphones and the speakers is not limited to the example shown in the present embodiment.</p><p id="p-0030" num="0029">The mixer <b>11</b> is connected to the distribution apparatus <b>12</b>, the plurality of microphones <b>13</b>A to <b>13</b>F, the plurality of speakers <b>14</b>A to <b>14</b>G, and the plurality of trackers <b>15</b>A to <b>15</b>C. The mixer <b>11</b>, the plurality of microphones <b>13</b>A to <b>13</b>F, and the plurality of speakers <b>14</b>A to <b>14</b>G are connected through a network cable or an audio cable. The plurality of trackers <b>15</b>A to <b>15</b>C are connected to the mixer <b>11</b> through wireless communication. The mixer <b>11</b> and the distribution apparatus <b>12</b> are connected to each other through a network cable. In addition, the distribution apparatus <b>12</b> is connected to the camera <b>16</b> through a video cable. The camera <b>16</b> captures a live video including a performer.</p><p id="p-0031" num="0030">The plurality of speaker <b>14</b>A to the speaker <b>14</b>G are installed along a wall surface of the first venue <b>10</b>. The first venue <b>10</b> of this example has a rectangular shape in a plan view. A stage is disposed at the front of the first venue <b>10</b>. On the stage, a performer performs a performance such as singing or playing. The speaker <b>14</b>A is installed on the left side of the stage, the speaker <b>14</b>B is installed in the center of the stage, and the speaker <b>14</b>C is installed on the right side of the stage. The speaker <b>14</b>D is installed on the left side of the center of the front and rear of the first venue <b>10</b>, and the speaker <b>14</b>E is installed on the right side of the center of the front and rear of the first venue <b>10</b>. The speaker <b>14</b>F is installed on the rear left side of the first venue <b>10</b>, and the speaker <b>14</b>G is installed on the rear right side of the first venue <b>10</b>.</p><p id="p-0032" num="0031">The microphone <b>13</b>A is installed on the left side of the stage, the microphone <b>13</b>B is installed in the center of the stage, and the microphone <b>13</b>C is installed on the right side of the stage. The microphone <b>13</b>D is installed on the left side of the center of the front and rear of the first venue <b>10</b>, and the microphone <b>13</b>E is installed in the rear center of the first venue <b>10</b>. The microphone <b>13</b>F is installed on the right side of the center of the front and rear of the first venue <b>10</b>.</p><p id="p-0033" num="0032">The mixer <b>11</b> receives an audio signal from the microphones <b>13</b>A to <b>13</b>F. In addition, the mixer <b>11</b> outputs the audio signal to the speakers <b>14</b>A to <b>14</b>G. While the present embodiment shows the speaker and the microphone as an example of an acoustic device to be connected to the mixer <b>11</b>, in practice, a greater number of acoustic devices may be connected to the mixer <b>11</b>. The mixer <b>11</b> receives an audio signal from the plurality of acoustic devices such as microphones, performs signal processing such as mixing, and outputs the audio signal to the plurality of acoustic devices such as speakers.</p><p id="p-0034" num="0033">The microphones <b>13</b>A to <b>13</b>F each obtain a singing sound or playing sound of a performer, as a sound generated in the first venue <b>10</b>. Alternatively, the microphones <b>13</b>A to <b>13</b>F obtain an ambient sound of the first venue <b>10</b>. In the example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the microphones <b>13</b>A to <b>13</b>C obtain the sound of the performer, and the microphones <b>13</b>D to <b>13</b>F obtain the ambient sound. The ambient sound includes a sound such as a cheer, applause, calling, shout, chorus, or murmur of a listener. However, the sound of the performer may be line-inputted. Line-input does not mean receiving an input of a sound outputted from a sound source such as a musical instrument by collecting the sound with a microphone, but means receiving an input of an audio signal from an audio cable or the like connected to the sound source. The sound of the performer may be preferably obtained with a high SN ratio and may not preferably include other sounds.</p><p id="p-0035" num="0034">The speaker <b>14</b>A to the speaker <b>14</b>G output the sound of the performer to the first venue <b>10</b>. The speaker <b>14</b>A to the speaker <b>14</b>G may output an early reflected sound or a late reverberant sound for controlling a sound field of the first venue <b>10</b>.</p><p id="p-0036" num="0035">The mixer <b>21</b> at the second venue <b>20</b> is connected to the reproduction apparatus <b>22</b> and the plurality of speakers <b>24</b>A to <b>24</b>F. These acoustic devices are connected through the network cable or the audio cable. In addition, the reproduction apparatus <b>22</b> is connected to the display <b>23</b> through the video cable.</p><p id="p-0037" num="0036">The plurality of speaker <b>24</b>A to the speaker <b>24</b>F are installed along a wall surface of the second venue <b>20</b>. The second venue <b>20</b> of this example has a rectangular shape in a plan view. The display <b>23</b> is disposed at the front of the second venue <b>20</b>. A live video captured at the first venue <b>10</b> is displayed on the display <b>23</b>. The speaker <b>24</b>A is installed on the left side of the display <b>23</b>, and the speaker <b>24</b>B is installed on the right side of the display <b>23</b>. The speaker <b>24</b>C is installed on the left side of the center of the front and rear of the second venue <b>20</b>, and the speaker <b>24</b>D is installed on the right side of the center of the front and rear of the second venue <b>20</b>. The speaker <b>24</b>E is installed on the rear left side of the second venue <b>20</b>, and the speaker <b>24</b>F is installed on the rear right side of the second venue <b>20</b>.</p><p id="p-0038" num="0037">The mixer <b>21</b> outputs the audio signal to the speakers <b>24</b>A to <b>24</b>F. The mixer <b>21</b> receives an audio signal from the reproduction apparatus <b>22</b>, performs signal processing such as mixing, and outputs the audio signal to the plurality of acoustic devices such as speakers.</p><p id="p-0039" num="0038">The speaker <b>24</b>A to the speaker <b>24</b>F output the sound of the performer to the second venue <b>20</b>. In addition, the speaker <b>24</b>A to the speaker <b>24</b>F output an early reflected sound or a late reverberant sound for reproducing the sound field of the first venue <b>10</b>. Moreover, the speaker <b>24</b>A to the speaker <b>24</b>F output an ambient sound such as a shout of the listener in the first venue <b>10</b>, to the second venue <b>20</b>.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram showing a configuration of the mixer <b>11</b>. It is to be noted that, since the mixer <b>21</b> has the same configuration and function as the mixer <b>11</b>, <figref idref="DRAWINGS">FIG. <b>4</b></figref> shows the configuration of the mixer <b>11</b> as a representative example. The mixer <b>11</b> includes a display <b>101</b>, a user I/F <b>102</b>, an audio I/O (Input/Output) <b>103</b>, a digital signal processor (DSP) <b>104</b>, a network I/F <b>105</b>, a CPU <b>106</b>, a flash memory <b>107</b>, and a RAM <b>108</b>.</p><p id="p-0041" num="0040">The CPU <b>106</b> is a controller that controls an operation of the mixer <b>11</b>. The CPU <b>106</b> reads and executes a predetermined program stored in the flash memory <b>107</b> being a storage medium to the RAM <b>108</b> and performs various types of operations.</p><p id="p-0042" num="0041">It is to be noted that the program that the CPU <b>106</b> reads does not need to be stored in the flash memory <b>107</b> in the own apparatus. For example, the program may be stored in a storage medium of an external apparatus such as a server. In such a case, the CPU <b>106</b> may read out the program each time from the server to the RAM <b>108</b> and may execute the program.</p><p id="p-0043" num="0042">The digital signal processor <b>104</b> includes a DSP for performing various types of signal processing. The digital signal processor <b>104</b> performs signal processing such as mixing processing and filter processing, on an audio signal inputted from an acoustic device such as a microphone, through the audio I/O <b>103</b> or the network I/F <b>105</b>. The digital signal processor <b>104</b> outputs the audio signal on which the signal processing has been performed, to an acoustic device such as a speaker, through the audio I/O <b>103</b> or the network I/F <b>105</b>.</p><p id="p-0044" num="0043">In addition, the digital signal processor <b>104</b> may perform panning processing, early reflected sound generation processing, and late reverberant sound generation processing. The panning processing is processing to control the volume of an audio signal to be distributed to the plurality of speakers <b>14</b>A to <b>14</b>G so that an acoustic image may be localized at a position of a performer. In order to perform the panning processing, the CPU <b>106</b> obtains position information of the performer through the trackers <b>15</b>A to <b>15</b>C. The position information is information that shows two-dimensional or three-dimensional coordinates on the basis of a certain position of the first venue <b>10</b>. The trackers <b>15</b>A to <b>15</b>C are tags that send and receive radio waves such as Bluetooth (registered trademark), for example. The performer or the musical instrument is equipped with the trackers <b>15</b>A to <b>15</b>C. At least three beacons are previously installed in the first venue <b>10</b>. Each beacon measures a distance with the trackers <b>15</b>A to <b>15</b>C, based on a time difference from when sending radio waves until when receiving the radio waves. The CPU <b>106</b> previously obtains position information of the beacon, and is able to uniquely determine a position of the trackers <b>15</b>A to <b>15</b>C by measuring a distance from each of the at least three beacons to a tag.</p><p id="p-0045" num="0044">The CPU <b>106</b>, in such a manner, obtains position information of each performer, that is, position information of the sound generated in the first venue <b>10</b>, through the trackers <b>15</b>A to <b>15</b>C. The CPU <b>106</b> determines the volume of each audio signal outputted to the speaker <b>14</b>A to the speaker <b>14</b>G so that an acoustic image may be localized at the position of the performer, based on obtained position information and the position of the speaker <b>14</b>A to the speaker <b>14</b>G. The digital signal processor <b>104</b> controls the volume of each audio signal outputted to the speaker <b>14</b>A to the speaker <b>14</b>G, according to control of the CPU <b>106</b>. For example, the digital signal processor <b>104</b> increases the volume of the audio signal outputted to a speaker near the position of the performer, and reduces the volume of the audio signal outputted to a speaker far from the position of the performer. As a result, the digital signal processor <b>104</b> is able to localize an acoustic image of a playing sound or a singing sound of the performer, at a predetermined position.</p><p id="p-0046" num="0045">The early reflected sound generation processing and the late reverberant sound generation processing are processing to convolve an impulse response into the sound of the performer by an FIR filter. The digital signal processor <b>104</b> convolves the impulse response previously obtained, for example, at a predetermined venue (a venue other than the first venue <b>10</b>) into the sound of the performer. As a result, the digital signal processor <b>104</b> controls the sound field of the first venue <b>10</b>. Alternatively, the digital signal processor <b>104</b> may control the sound field of the first venue <b>10</b> by further feeding back the sound obtained by the microphone installed near the ceiling or wall surface of the first venue <b>10</b>, to the speaker <b>14</b>A to the speaker <b>14</b>G.</p><p id="p-0047" num="0046">The digital signal processor <b>104</b> outputs the sound of the performer and the position information of the performer, to the distribution apparatus <b>12</b>. The distribution apparatus <b>12</b> obtains the sound of the performer and the position information of the performer from the mixer <b>11</b>.</p><p id="p-0048" num="0047">In addition, the distribution apparatus <b>12</b> obtains a video signal from the camera <b>16</b>. The camera <b>16</b> captures each performer, the entirety of the first venue <b>10</b>, or the like, and outputs a video signal according to a live video, to the distribution apparatus <b>12</b>.</p><p id="p-0049" num="0048">Furthermore, the distribution apparatus <b>12</b> obtains information on space reverberation of the first venue <b>10</b>. The information on space reverberation includes information for generating an indirect sound. The indirect sound is a sound such that a sound of a sound source may be reflected in a venue and may reach a listener, and includes at least an early reflected sound and a late reverberant sound. The information on space reverberation includes information that shows the size, shape, and wall surface material quality of the space of the first venue <b>10</b>, and an impulse response according to the late reverberant sound, for example. The information that shows the size, shape, and wall surface material quality of the space is information for generating an early reflected sound. The information for generating the early reflected sound may be an impulse response. The impulse response is previously measured, for example, in the first venue <b>10</b>. The information on space reverberation may be information that varies according to a position of a performer. The information that varies according to a position of a performer is an impulse response previously measured for each position of a performer in the first venue <b>10</b>, for example. The distribution apparatus <b>12</b> obtains, for example, a first impulse response when a sound of a performer is generated at the front of the stage of the first venue <b>10</b>, a second impulse response when a sound of a performer is generated at the left of the stage, and a third impulse response when a sound of a performer is generated at the right of the stage. However, impulse responses are not limited to three. In addition, the impulse response is not necessary to be actually measured in the first venue <b>10</b>, and, for example, may be calculated by simulation from the size, shape, wall surface material quality, and the like of the space of the first venue <b>10</b>.</p><p id="p-0050" num="0049">It is to be noted that the early reflected sound is a reflected sound of which the arrival direction of a sound is fixed, and the late reverberant sound is a reflected sound of which the arrival direction of a sound is not fixed. The late reverberant sound is less affected by a variation in the position of the sound of the performer than the early reflected sound. Therefore, the information on space reverberation may include an impulse response of the early reflected sound that varies according to the position of the performer and an impulse response of the late reverberant sound that is constant independent of the position of the performer.</p><p id="p-0051" num="0050">In addition, the digital signal processor <b>104</b> may obtain ambience information according to an ambient sound, and may output the ambience information to the distribution apparatus <b>12</b>. The ambient sound is a sound obtained by the microphones <b>13</b>D to <b>13</b>F as described above, and includes a sound such as background noise, and a cheer, applause, calling, shout, chorus, or murmur of a listener. However, the ambient sound may be obtained by the microphones <b>13</b>A to <b>13</b>C on the stage. The digital signal processor <b>104</b> outputs an audio signal according to the ambient sound, to the distribution apparatus <b>12</b>, as ambience information. It is to be noted that, the ambience information may include position information of the ambient sound. Of the ambient sound, a cheer such as &#x201c;Go for it&#x201d; from an individual listener, calling for a name of an individual performer, an exclamation such as &#x201c;Bravo,&#x201d; or the like is a sound that is able to be recognized as a voice of the individual listener without being lost in an audience. The digital signal processor <b>104</b> may obtain position information of these individual sounds. The position information of the ambient sound is able to be determined from the sound obtained by the microphones <b>13</b>D to <b>13</b>F, for example. The digital signal processor <b>104</b>, in a case of recognizing the individual sounds by processing such as speech recognition, determines the correlation of an audio signal of the microphones <b>13</b>D to <b>13</b>F, and determines a difference in timing when the individual sounds are respectively collected by the microphones <b>13</b>D to <b>13</b>F. The digital signal processor <b>104</b>, based on the difference in timing when the sounds are collected by the microphones <b>13</b>D to <b>13</b>F, is able to uniquely determine a position in the first venue <b>10</b> in which the sound is generated. In addition, the position information of the ambient sound may be considered as the position information of each microphone <b>13</b>D to <b>13</b>F.</p><p id="p-0052" num="0051">The distribution apparatus <b>12</b> encodes and distributes information on a sound source according to the sound generated in the first venue <b>10</b>, and information on space reverberation, as distribution data. The information on a sound source includes at least a sound of a performer, and may include position information of the sound of the performer. In addition, the distribution apparatus <b>12</b> may distribute the distribution data including ambience information according to an ambient sound. The distribution apparatus <b>12</b> may distribute the distribution data including a video signal according to a video of the performer.</p><p id="p-0053" num="0052">Alternatively, the distribution apparatus <b>12</b> may distribute at least information on a sound source according to a sound of a performer and position information of the performer, and ambience information according to an ambient sound, as distribution data.</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram showing a configuration of the distribution apparatus <b>12</b>. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a flow chart showing an operation of the distribution apparatus <b>12</b>.</p><p id="p-0055" num="0054">The distribution apparatus <b>12</b> includes an information processing apparatus such as a general personal computer. The distribution apparatus <b>12</b> includes a display <b>201</b>, a user I/F <b>202</b>, a CPU <b>203</b>, a RAM <b>204</b>, a network I/F <b>205</b>, a flash memory <b>206</b>, and a general-purpose communication I/F <b>207</b>.</p><p id="p-0056" num="0055">The CPU <b>203</b> reads out a program stored in the flash memory <b>206</b> being a storage medium to the RAM <b>204</b> and implements a predetermined function. It is to be noted that the program that the CPU <b>203</b> reads out does not also need to be stored in the flash memory <b>206</b> in the own apparatus. For example, the program may be stored in a storage medium of an external apparatus such as a server. In such a case, the CPU <b>203</b> may read out the program each time from the server to the RAM <b>204</b> and may execute the program.</p><p id="p-0057" num="0056">The CPU <b>203</b> obtains a sound of a performer and position information (information on a sound source) of the performer, from the mixer <b>11</b> through the network I/F <b>205</b> (S<b>11</b>). In addition, the CPU <b>203</b> obtains information on space reverberation of the first venue <b>10</b> (S<b>12</b>). Furthermore, the CPU <b>203</b> obtains ambience information according to an ambient sound (S<b>13</b>). Moreover, the CPU <b>203</b> may obtain a video signal from the camera <b>16</b> through the general-purpose communication I/F <b>207</b>.</p><p id="p-0058" num="0057">The CPU <b>203</b> encodes and distributes data according to the position information (the information on a sound source) of the sound of the performer and the sound, data according to the information on space reverberation, data according to the ambience information, and data according to the video signal, as distribution data (S<b>14</b>).</p><p id="p-0059" num="0058">The reproduction apparatus <b>22</b> receives the distribution data from the distribution apparatus <b>12</b> through the Internet <b>5</b>. The reproduction apparatus <b>22</b> renders the distribution data and provides a sound of the performer and a sound according to the space reverberation, to the second venue <b>20</b>. Alternatively, the reproduction apparatus <b>22</b> provides the ambient sound included in the sound of the performer and the ambience information, to the second venue <b>20</b>. The reproduction apparatus <b>22</b> may provide the sound according to the space reverberation corresponding to the ambience information, to the second venue <b>20</b>.</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram showing a configuration of the reproduction apparatus <b>22</b>. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flow chart showing an operation of the reproduction apparatus <b>22</b>.</p><p id="p-0061" num="0060">The reproduction apparatus <b>22</b> includes an information processing apparatus such as a general personal computer. The reproduction apparatus <b>22</b> includes a display <b>301</b>, a user I/F <b>302</b>, a CPU <b>303</b>, a RAM <b>304</b>, a network I/F <b>305</b>, a flash memory <b>306</b>, and a video I/F <b>307</b>.</p><p id="p-0062" num="0061">The CPU <b>303</b> reads out a program stored in the flash memory <b>306</b> being a storage medium to the RAM <b>304</b> and implements a predetermined function. It is to be noted that the program that the CPU <b>303</b> reads out does not also need to be stored in the flash memory <b>306</b> in the own apparatus. For example, the program may be stored in a storage medium of an external apparatus such as a server. In such a case, the CPU <b>303</b> may read out the program each time from the server to the RAM <b>304</b> and may execute the program.</p><p id="p-0063" num="0062">The CPU <b>303</b> receives the distribution data from the distribution apparatus <b>12</b> through the network I/F <b>305</b> (S<b>21</b>). The CPU <b>303</b> decodes the distribution data into information on a sound source, information on space reverberation, ambience information, a video signal, and the like (S<b>22</b>), and renders the information on a sound source, the information on space reverberation, the ambience information, the video signal, and the like.</p><p id="p-0064" num="0063">The CPU <b>303</b>, as an example of rendering of the information on a sound source, causes the mixer <b>21</b> to perform panning processing on a sound of a performer (S<b>23</b>). The panning processing is processing to localize the sound of the performer at the position of the performer, as described above. The CPU <b>303</b> determines the volume of an audio signal to be distributed to the speakers <b>24</b>A to <b>24</b>F so that the sound of the performer may be localized at a position shown in the position information included in the information on a sound source. The CPU <b>303</b>, by outputting information that shows an audio signal according to the sound of the performer and an output amount of the audio signal according to the sound of the performer to the speakers <b>24</b>A to <b>24</b>F, to the mixer <b>21</b>, causes the mixer <b>21</b> to perform the panning processing.</p><p id="p-0065" num="0064">As a result, the listener in the second venue <b>20</b> can perceive a sound as if the sound is emitted from the position of the performer. The listener in the second venue <b>20</b> can listen to a sound of the performer present on the right side of the stage of the first venue <b>10</b>, for example, from the front right side in the second venue <b>20</b> as well. In addition, the CPU <b>303</b> may render the video signal and may display a live video on the display <b>23</b> through the video I/F <b>307</b>. Accordingly, the listener in the second venue <b>20</b> listens to the sound of the performer on which the panning processing has been performed, while watching a video of the performer displayed on the display <b>23</b>. As a result, the listener in the second venue <b>20</b>, since visual information and auditory information match with each other, is able to obtain more sense of immersion to a live performance.</p><p id="p-0066" num="0065">Furthermore, the CPU <b>303</b>, as an example of rendering of the information on space reverberation, causes the mixer <b>21</b> to perform indirect sound generation processing (S<b>24</b>). The indirect sound generation processing includes the early reflected sound generation processing and the late reverberant sound generation processing. An early reflected sound is generated based on a sound of a performer included in the information on a sound source, and information that shows the size, shape, wall surface material quality, and the like of the space of the first venue <b>10</b> included in the information on space reverberation. The CPU <b>303</b> determines an arrival timing of the early reflected sound, based on the size and shape of a space, and determines a level of the early reflected sound, based on the material quality of a wall surface. More specifically, the CPU <b>303</b> determines coordinates of the wall surface by which the sound of a sound source is reflected, based on information on the size and shape of the space. Then, the CPU <b>303</b>, based on a position of the sound source, a position of the wall surface, and a position of a sound receiving point, determines a position of a virtual sound source (an imaginary sound source) that exists with the wall surface as a mirror surface with respect to the position of the sound source. The CPU <b>303</b> determines a delay amount of the imaginary sound source, based on a distance from the position of the imaginary sound source to the sound receiving point. In addition, the CPU <b>303</b> determines a level of the imaginary sound source, based on the information on the material quality of the wall surface. The information on the material quality corresponds to energy loss at the time of reflection on the wall surface. Therefore, the CPU <b>303</b> determines the level of the imaginary sound source in consideration of the energy loss of the audio signal of the sound source. The CPU <b>303</b>, by repeating such processing, is able to determine a delay amount and level of a sound according to the space reverberation, by calculation. The CPU <b>303</b> outputs the calculated delay amount and level to the mixer <b>21</b>. The mixer <b>21</b> convolves a level tap coefficient according to these delay amount and level into the sound of a performer. As a result, the mixer <b>21</b> reproduces the space reverberation of the first venue <b>10</b>, in the second venue <b>20</b>. In addition, in a case in which the information on space reverberation includes an impulse response of the early reflected sound, the CPU <b>303</b> causes the mixer <b>11</b> to execute processing to convolve the impulse response into the sound of a performer by the FIR filter. The CPU <b>303</b> outputs the information on space reverberation (the impulse response) included in the distribution data to the mixer <b>21</b>. The mixer <b>21</b> convolves the information on space reverberation (the impulse response) received from the reproduction apparatus <b>22</b> into the sound of a performer. Accordingly, the mixer <b>21</b> reproduces the space reverberation of the first venue <b>10</b>, in the second venue <b>20</b>.</p><p id="p-0067" num="0066">Furthermore, in a case in which the information on space reverberation varies according to a position of a performer, the reproduction apparatus <b>22</b> outputs the information on space reverberation corresponding to the position of a performer, to the mixer <b>21</b>, based on the position information included in the information on a sound source. For example, when the performer present at the front of the stage of the first venue <b>10</b> moves to the left of the stage, the impulse response to be convolved into the sound of a performer is changed from the first impulse response to the second impulse response. Alternatively, in a case in which the imaginary sound source is reproduced based on the information on the size and shape of the space, the delay amount and the level are recalculated according to the position of a performer after movement. As a result, appropriate space reverberation according to the position of a performer is also reproduced in the second venue <b>20</b>.</p><p id="p-0068" num="0067">In addition, the reproduction apparatus <b>22</b> may cause the mixer <b>21</b> to generate a space reverberation sound corresponding to an ambient sound, based on the ambience information and the information on space reverberation. In other words, a sound according to the space reverberation may include a first reverberation sound corresponding to a sound (a sound of a first sound source) of a performer and a second reverberation sound corresponding to an ambient sound (a sound of a second sound source). As a result, the mixer <b>21</b> reproduces the reverberation of an ambient sound in the first venue <b>10</b>, in the second venue <b>20</b>. In addition, in a case in which the ambience information includes position information, the reproduction apparatus <b>22</b> may output the information on space reverberation corresponding to the position of the ambient sound to the mixer <b>11</b>, based on the position information included in the ambience information. The mixer <b>21</b> reproduces a reverberation sound of the ambient sound, based on the position of the ambient sound. For example, in a case in which a spectator present at the left rear of the first venue <b>10</b> moves to the right rear, the impulse response to be convolved into a shout of the spectator is changed. Alternatively, in a case in which the imaginary sound source is reproduced based on the information on the size and shape of the space, the delay amount and the level are recalculated according to the position of a spectator after movement. In this manner, the information on space reverberation includes first reverberation information that varies according to the position of the sound (the first sound source) of a performer, and second reverberation information that varies according to the position of an ambient sound (the second sound source), the rendering may include processing to generate the first reverberation sound based on the first reverberation information, and processing to generate the second reverberation sound based on the second reverberation information.</p><p id="p-0069" num="0068">In addition, the late reverberant sound is a reflected sound of which the arrival direction of a sound is not fixed. The late reverberant sound is less affected by a variation in the position of the sound than the early reflected sound. Therefore, the reproduction apparatus <b>22</b> changes only the impulse response of the early reflected sound that varies according to the position of a performer, and may fix the impulse response of the late reverberant sound.</p><p id="p-0070" num="0069">It is to be noted that the reproduction apparatus <b>22</b> may omit the indirect sound generation processing, and may use the reverberation of the second venue <b>20</b> as it is. In addition, the indirect sound generation processing may include only the early reflected sound generation processing. The late reverberant sound may use the reverberation of the second venue <b>20</b> as it is. Alternatively, the mixer <b>21</b> may reinforce the control of the second venue <b>20</b> by further feeding back the sound obtained by a not-shown microphone installed near the ceiling or wall surface of the second venue <b>20</b>, to the speaker <b>24</b>A to the speaker <b>24</b>F.</p><p id="p-0071" num="0070">The CPU <b>303</b> of the reproduction apparatus <b>22</b> performs ambient sound reproduction processing, based on the ambience information (S<b>25</b>). The ambience information includes an audio signal of a sound such as background noise, and a cheer, applause, calling, shout, chorus, or murmur of a listener. The CPU <b>303</b> outputs these audio signals to the mixer <b>21</b>. The mixer <b>21</b> outputs the audio signals received from the reproduction apparatus <b>22</b>, to the speakers <b>24</b>A to <b>24</b>F.</p><p id="p-0072" num="0071">The CPU <b>303</b>, in a case in which the ambience information includes the position information of an ambient sound, causes the mixer <b>21</b> to perform processing to localize the ambient sound by panning processing. In such a case, the CPU <b>303</b> determines the volume of an audio signal to be distributed to the speakers <b>24</b>A to <b>24</b>F so that the ambient sound may be localized at a position of the position information included in the ambience information. The CPU <b>303</b>, by outputting information that shows an audio signal of the ambient sound and an output amount of the audio signal according to the ambient sound to the speakers <b>24</b>A to <b>24</b>F, to the mixer <b>21</b>, causes the mixer <b>21</b> to perform the panning processing. In addition, the same applies to a case in which the position information of the ambient sound is position information of each microphone <b>13</b>D to <b>13</b>F. The CPU <b>303</b> determines the volume of the audio signal to be distributed to the speakers <b>24</b>A to <b>24</b>F so that the ambient sound may be localized at the position of the microphone. Each microphone <b>13</b>D to <b>13</b>F collects a plurality of ambient sounds (the second sound source) such as background noise, applause, choruses, or shouts such as &#x201c;wow,&#x201d; and murmurs. The sound of each sound source includes a predetermined delay amount and level and reaches the microphone. In other words, the background noise, applause, choruses, or shouts such as &#x201c;wow,&#x201d; murmurs, and the like also reach the microphone as individual sound sources including a predetermined delay amount and level (information for localizing a sound source). The CPU <b>303</b> can also simply reproduce individual sound source localization by performing panning processing so that a sound collected by a microphone may be localized at the position of the microphone.</p><p id="p-0073" num="0072">It is to be noted that the CPU <b>303</b> may perform processing to perceive spatial expansion by causing the mixer <b>21</b> to perform effect processing such as reverb, on a sound unrecognized as a voice of an individual listener or sounds simultaneously emitted by a large number of listeners. For example, the background noise, applause, choruses, or shouts such as &#x201c;wow,&#x201d; murmurs, and the like are sounds that reverberate throughout a live venue. The CPU <b>303</b> causes the mixer <b>21</b> to perform effect processing to perceive spatial expansion, on these sounds.</p><p id="p-0074" num="0073">The reproduction apparatus <b>22</b> may provide the ambient sound based on the above ambience information, to the second venue <b>20</b>. As a result, the listener in the second venue <b>20</b> can watch a live performance with more realistic sensation, as if watching the live performance in the first venue <b>10</b>.</p><p id="p-0075" num="0074">As described above, the live data distribution system <b>1</b> according to the present embodiment distributes the information on a sound source according to a sound generated in the first venue <b>10</b>, and the information on space reverberation, as distribution data, and renders the distribution data and provides a sound according to the information on a sound source and a sound according to the space reverberation, to the second venue <b>20</b>. As a result, the realistic sensation in the live venue is able to be provided to a venue being a distribution destination.</p><p id="p-0076" num="0075">In addition, the live data distribution system <b>1</b> distributes first information on a sound source according to a sound (a sound of a performer, for example) of a first sound source generated at a first place (a stage, for example) of the first venue <b>10</b> and position information of the first sound source, and second information on a sound source according to a second sound source (an ambient sound, for example) generated at a second place (a place at which a listener is present, for example) of the first venue <b>10</b>, as distribution data, and renders the distribution data and provides a sound of the first sound source on which localization processing based on the position information of the first sound source has been performed and a sound of the second sound source, to the second venue. As a result, the realistic sensation in the live venue is able to be provided to a venue being a distribution destination.</p><p id="p-0077" num="0076">Next, <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>A according to a first modification. <figref idref="DRAWINGS">FIG. <b>10</b></figref> is a plan schematic diagram of a second venue <b>20</b> in the live data distribution system <b>1</b>A according to the first modification. The same reference numerals are used to refer to components common to <figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and the description will be omitted.</p><p id="p-0078" num="0077">A plurality of microphones <b>25</b>A to <b>25</b>C are installed in the second venue <b>20</b> of the live data distribution system <b>1</b>A. The microphone <b>25</b>A is installed on the left side of the center of the front and rear to a stage <b>80</b> of the second venue <b>20</b>, and the microphone <b>25</b>B is installed in the rear center of the second venue <b>20</b>. The microphone <b>25</b>C is installed on the right side of the center of the front and rear of the second venue <b>20</b>.</p><p id="p-0079" num="0078">The microphones <b>25</b>A to <b>25</b>C obtain an ambient sound of the second venue <b>20</b>. The mixer <b>21</b> outputs an audio signal of the ambient sound, to the reproduction apparatus <b>22</b>, as ambience information. It is to be noted that, the ambience information may include position information of the ambient sound. The position information of the ambient sound, as described above, is able to be determined from the sound obtained by the microphones <b>25</b>A to <b>25</b>C, for example.</p><p id="p-0080" num="0079">The reproduction apparatus <b>22</b> sends the ambience information according to the ambient sound generated at the second venue <b>20</b> as a third sound source, to a different venue. For example, the reproduction apparatus <b>22</b> feeds back the ambient sound generated at the second venue <b>20</b>, to the first venue <b>10</b>. As a result, a performer on the stage of the first venue <b>10</b> can hear a voice, applause, a shout, or the like other than the listener in the first venue <b>10</b>, and can perform a live performance under an environment full of realistic sensation. In addition, the listener present in the first venue <b>10</b> can also hear the voice, the applause, the shout, or the like of the listener in the different venue, and can watch the live performance under the environment full of realistic sensation.</p><p id="p-0081" num="0080">Furthermore, when the reproduction apparatus in the different venue renders distribution data, provides the sound of the first venue to the different venue, and provides an ambient sound generated in the second venue <b>20</b> to the different venue, the listener in the different venue can also hear the voice, the applause, the shout, or the like of a large number of listeners, and can watch the live performance under the environment full of realistic sensation.</p><p id="p-0082" num="0081">Next, <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>B according to a second modification. The same reference numerals are used to refer to components common to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and the description will be omitted.</p><p id="p-0083" num="0082">In the live data distribution system <b>1</b>B, the distribution apparatus <b>12</b> is connected to an AV receiver <b>32</b> in a third venue <b>20</b>A through the Internet <b>5</b>. The AV receiver <b>32</b> is connected to a display <b>33</b>, a plurality of speakers <b>34</b>A to <b>34</b>F, and a microphone <b>35</b>. The third venue <b>20</b>A is a private house of a certain listener, for example. The AV receiver <b>32</b> is an example of a reproduction apparatus. A user of the AV receiver <b>32</b> is a listener remotely watching a live performance in the first venue <b>10</b>.</p><p id="p-0084" num="0083"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a block diagram showing a configuration of the AV receiver <b>32</b>. The AV receiver <b>32</b> includes a display <b>401</b>, a user I/F <b>402</b>, an audio I/O (Input/Output) <b>403</b>, a digital signal processor (DSP) <b>404</b>, a network I/F <b>405</b>, a CPU <b>406</b>, a flash memory <b>407</b>, a RAM <b>408</b>, and a video I/F <b>409</b>.</p><p id="p-0085" num="0084">The CPU <b>406</b> is a controller that controls an operation of the AV receiver <b>32</b>. The CPU <b>406</b> reads and executes a predetermined program stored in the flash memory <b>407</b> being a storage medium to the RAM <b>408</b> and performs various types of operations.</p><p id="p-0086" num="0085">It is to be noted that the program that the CPU <b>406</b> reads also has no need to be stored in the flash memory <b>407</b> in the own apparatus. For example, the program may be stored in a storage medium of an external apparatus such as a server. In such a case, the CPU <b>406</b> may read out the program each time from the server to the RAM <b>408</b> and may execute the program.</p><p id="p-0087" num="0086">The digital signal processor <b>404</b> includes a DSP for performing various types of signal processing. The digital signal processor <b>404</b> performs signal processing on an audio signal inputted through the audio I/O <b>403</b> or the network I/F <b>405</b>. The digital signal processor <b>404</b> outputs the audio signal on which the signal processing has been performed, to an acoustic device such as a speaker, through the audio I/O <b>403</b> or the network I/F <b>405</b>.</p><p id="p-0088" num="0087">The AV receiver <b>32</b> performs the same processing as the processing performed by the mixer <b>21</b> and the reproduction apparatus <b>22</b>. The CPU <b>406</b> receives the distribution data from the distribution apparatus <b>12</b> through the network I/F <b>405</b>. The CPU <b>406</b> renders the distribution data and provides a sound according to the sound of a performer and the space reverberation, to the third venue <b>20</b>A. Alternatively, the CPU <b>406</b> renders the distribution data and provides the ambient sound generated in the first venue <b>10</b>, to the third venue <b>20</b>A. Alternatively, the CPU <b>406</b> may render the distribution data and may display a live video on the display <b>33</b> through the video I/F <b>307</b>.</p><p id="p-0089" num="0088">The digital signal processor <b>404</b> performs panning processing on the sound of a performer. In addition, the digital signal processor <b>404</b> performs indirect sound generation processing. Alternatively, the digital signal processor <b>404</b> may perform panning processing on an ambient sound.</p><p id="p-0090" num="0089">As a result, the AV receiver <b>32</b> is able to provide the realistic sensation of the first venue <b>10</b> to the third venue <b>20</b>A as well.</p><p id="p-0091" num="0090">In addition, the AV receiver <b>32</b> obtains an ambient sound (a sound such as a cheer, applause, or calling of a listener) in the third venue <b>20</b>A, through the microphone <b>35</b>. The AV receiver <b>32</b> sends the ambient sound in the third venue <b>20</b>A to another apparatus. For example, the AV receiver <b>32</b> feeds back the ambient sound in the third venue <b>20</b>A, to the first venue <b>10</b>.</p><p id="p-0092" num="0091">In such a manner, when the sound from a plurality of listeners is fed back to the first venue <b>10</b>, a performer on the stage of the first venue <b>10</b> can hear a cheer, applause, a shout, or the like of the large number of listeners other than the listener in the first venue <b>10</b>, and can perform a live performance under an environment full of realistic sensation. In addition, the listener present in the first venue <b>10</b> can also hear the cheer, the applause, the shout, or the like of the large number of listeners in a remote place, and can watch the live performance under the environment full of realistic sensation.</p><p id="p-0093" num="0092">Alternatively, the AV receiver <b>32</b> displays icon images including a &#x201c;cheer,&#x201d; &#x201c;applause,&#x201d; &#x201c;calling,&#x201d; and a &#x201c;murmur,&#x201d; on the display <b>401</b>, and, by receiving an operation to select these icon images from listeners through the user I/F <b>402</b>, may receive reactions of the listeners. The AV receiver <b>32</b>, when receiving an operation to select these reactions, may generate an audio signal corresponding to each reaction and may send the audio signal as ambience information to another apparatus.</p><p id="p-0094" num="0093">Alternatively, the AV receiver <b>32</b> may send information that shows the type of the ambient sound such as the cheer, the applause, or the calling of the listeners, as ambience information. In such a case, an apparatus (the distribution apparatus <b>12</b> and the mixer <b>11</b>, for example) on a receiving side generates a corresponding audio signal, based on the ambience information, and provides the sound such as the cheer, the applause, or the calling of the listeners, to the inside of a venue. In such a manner, the ambience information may be information that shows not the audio signal of an ambient sound, but a sound to be generated, and may be processing in which the distribution apparatus <b>12</b> and the mixer <b>11</b> reproduce a pre-recorded ambient sound or the like.</p><p id="p-0095" num="0094">In addition, the ambience information of the first venue <b>10</b> may also be a pre-recorded ambient sound, rather than the ambient sound generated in the first venue <b>10</b>. In such a case, the distribution apparatus <b>12</b> distributes information that shows a sound to be generated, as ambience information. The reproduction apparatus <b>22</b> or the AV receiver <b>32</b> reproduces a corresponding ambient sound, based on the ambience information. In addition, among the ambience information, a background noise, a murmur, and the like may be a recorded sound, and another ambient sound (such as a cheer, applause, or calling of a listener, for example) may be a sound generated in the first venue <b>10</b>.</p><p id="p-0096" num="0095">In addition, the AV receiver <b>32</b> may receive position information of a listener through the user I/F <b>402</b>. The AV receiver <b>32</b> displays an image that imitates a plan view, a perspective view, or a similar view of the first venue <b>10</b> on the display <b>401</b> or the display <b>33</b>, and receives the position information from a listener through the user I/F <b>402</b> (see <figref idref="DRAWINGS">FIG. <b>16</b></figref>, for example). The position information is information to designate any position in the first venue <b>10</b>. The AV receiver <b>32</b> sends received position information of the listener, to the first venue <b>10</b>. The distribution apparatus <b>12</b> and the mixer <b>11</b> in the first venue perform processing to localize the ambient sound of the third venue <b>20</b>A at a designated position, based on the ambient sound in the third venue <b>20</b>A and the position information of a listener that have been received from the AV receiver <b>32</b>.</p><p id="p-0097" num="0096">In addition, the AV receiver <b>32</b> may change the content of the panning processing, based on the position information received from the user. For example, when a listener designates a position immediately in front of the stage of the first venue <b>10</b>, the AV receiver <b>32</b> sets a localization position of the sound of a performer to the position immediately in front of the listener and performs the panning processing. As a result, the listener in the third venue <b>20</b>A can obtain realistic sensation, as if being present immediately in front of the stage of the first venue <b>10</b>.</p><p id="p-0098" num="0097">The sound of the listener in the third venue <b>20</b>A may send to the second venue <b>20</b> instead of the first venue <b>10</b>, and may also send to a different venue. For example, the sound of the listener in the third venue <b>20</b>A may be sent only to a house (a fourth venue) of a friend. A listener in the fourth venue can watch the live performance of the first venue <b>10</b>, while listening to the sound of the listener in the third venue <b>20</b>A. In addition, a not-shown reproduction apparatus in the fourth venue may send the sound of the listener in the fourth venue to the third venue <b>20</b>A. In such a case, the listener in the third venue <b>20</b>A can watch the live performance of the first venue <b>10</b>, while listening to the sound of the listener in the fourth venue. As a result, the listener in the third venue <b>20</b>A and the listener in the fourth venue can watch the live performance of the first venue <b>10</b>, while talking to each other.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>C according to a third modification. The same reference numerals are used to refer to components common to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and the description will be omitted.</p><p id="p-0100" num="0099">In the live data distribution system <b>1</b>C, the distribution apparatus <b>12</b> is connected to a terminal <b>42</b> in a fifth venue <b>20</b>B through the Internet <b>5</b>. The terminal <b>42</b> is connected to headphones <b>43</b>. The fifth venue <b>20</b>B is a private house of a certain listener, for example. However, in a case in which the terminal <b>42</b> is portable, the fifth venue <b>20</b>B may be any place such as inside of a cafe shop, inside of a car, or inside of public transportation. In such a case, everywhere can be the fifth venue <b>20</b>B. The terminal <b>42</b> is an example of a reproduction apparatus. A user of the terminal <b>42</b> may be a listener remotely watching the live performance of the first venue <b>10</b>. In this case as well, the terminal <b>42</b> renders distribution data and provides a sound according to information on a sound source through the headphones <b>43</b> and a sound according to space reverberation, to the second venue (the fifth venue <b>20</b>B in this example).</p><p id="p-0101" num="0100"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a block diagram showing a configuration of the terminal <b>42</b>. The terminal <b>42</b> may be an information processing apparatus such as a personal computer, a smartphone, or a tablet computer, for example. The terminal <b>42</b> includes a display <b>501</b>, a user I/F <b>502</b>, a CPU <b>503</b>, a RAM <b>504</b>, a network I/F <b>505</b>, a flash memory <b>506</b>, an audio I/O (Input/Output) <b>507</b>, and a microphone <b>508</b>.</p><p id="p-0102" num="0101">The CPU <b>503</b> is a controller that controls the operation of the terminal <b>42</b>. The CPU <b>503</b> reads and executes a predetermined program stored in the flash memory <b>506</b> being a storage medium to the RAM <b>504</b> and performs various types of operations.</p><p id="p-0103" num="0102">It is to be noted that the program that the CPU <b>503</b> reads also has no need to be stored in the flash memory <b>506</b> in the own apparatus. For example, the program may be stored in a storage medium of an external apparatus such as a server. In such a case, the CPU <b>503</b> may read the program each time from the server to the RAM <b>504</b> and may execute the program.</p><p id="p-0104" num="0103">The CPU <b>503</b> performs signal processing on an audio signal inputted through the network I/F <b>505</b>. The CPU <b>503</b> outputs the audio signal on which the signal processing has been performed, to the headphones <b>43</b> through the audio I/O <b>507</b>.</p><p id="p-0105" num="0104">The CPU <b>503</b> receives the distribution data from the distribution apparatus <b>12</b> through the network I/F <b>505</b>. The CPU <b>503</b> renders the distribution data and provides a sound of a performer and a sound according to space reverberation, to the listeners in the fifth venue <b>20</b>B.</p><p id="p-0106" num="0105">Specifically, the CPU <b>503</b> convolves a head-related transfer function (hereinafter referred to as HRTF) into an audio signal according to the sound of a performer, and performs acoustic image localization processing (binaural processing) so that the sound of a performer may be localized at the position of the performer. The HRTF corresponds to a transfer function between a predetermined position and an ear of a listener. The HRTF corresponds to a transfer function expressing the loudness, the reaching time, the frequency characteristics, and the like of a sound emitted from a sound source in a certain position to each of left and right ears. The CPU <b>503</b> convolves the HRTF into the audio signal of the sound of the performer, based on the position of the performer. As a result, the sound of the performer is localized at a position according to position information.</p><p id="p-0107" num="0106">In addition, the CPU <b>503</b> performs indirect sound generation processing on the audio signal of the sound of the performer by binaural processing to convolve the HRTF corresponding to information on space reverberation. The CPU <b>503</b> localizes an early reflected sound and a late reverberant sound by convolving the HRTF from a position of a virtual sound source corresponding to each early reflected sound included in the information on space reverberation to each of the left and right ears. However, the late reverberant sound is a reflected sound of which the arrival direction of a sound is not fixed. Therefore, the CPU <b>503</b> may perform effect processing such as reverb, without performing the localization processing, on the late reverberant sound. It is to be noted that the CPU <b>503</b> may perform digital filter processing (headphone inverse characteristic processing) to reproduce the inverse characteristics of the acoustic characteristics of the headphones <b>43</b> that a listener uses.</p><p id="p-0108" num="0107">In addition, the CPU <b>503</b> renders ambience information among the distribution data and provides an ambient sound generated in the first venue <b>10</b>, to the listener in the fifth venue <b>20</b>B. The CPU <b>503</b>, in a case in which position information of the ambient sound is included in the ambience information, performs the localization processing by the HRTF and performs the effect processing on a sound of which the arrival direction is not fixed.</p><p id="p-0109" num="0108">In addition, the CPU <b>503</b> may render a video signal among the distribution data and may display a live video on the display <b>501</b>.</p><p id="p-0110" num="0109">As a result, the terminal <b>42</b> is also able to provide the realistic sensation of the first venue <b>10</b> to the listener in the fifth venue <b>20</b>B.</p><p id="p-0111" num="0110">In addition, the terminal <b>42</b> obtains the sound of the listener in the fifth venue <b>20</b>B through the microphone <b>508</b>. The terminal <b>42</b> sends the sound of the listener to another apparatus. For example, the terminal <b>42</b> feeds back the sound of the listener to the first venue <b>10</b>. Alternatively, the terminal <b>42</b> displays icon images including a &#x201c;cheer, &#x201c;&#x201d;applause,&#x201d; &#x201c;calling,&#x201d; and a &#x201c;murmur,&#x201d; on the display <b>501</b>, and, by receiving an operation to select these icon images from listeners through the user I/F <b>502</b>, may receive reactions of the listeners. The terminal <b>42</b> generates a sound corresponding to received reactions, and sends a generated sound as ambience information to another apparatus. Alternatively, the terminal <b>42</b> may send information that shows the type of the ambient sound such as the cheer, the applause, or the calling of the listeners, as ambience information. In such a case, an apparatus (the distribution apparatus <b>12</b> and the mixer <b>11</b>, for example) on a receiving side generates a corresponding audio signal, based on the ambience information, and provides the sound such as the cheer, the applause, or the calling of the listeners, to the inside of a venue.</p><p id="p-0112" num="0111">In addition, the terminal <b>42</b> may also receive position information of a listener through the user I/F <b>502</b>. The terminal <b>42</b> sends received position information of a listener, to the first venue <b>10</b>. The distribution apparatus <b>12</b> and the mixer <b>11</b> in the first venue perform processing to localize the sound of the listener at a designated position, based on the sound of the listener in the third venue <b>20</b>A and the position information that have been received from the AV receiver <b>32</b>.</p><p id="p-0113" num="0112">In addition, the terminal <b>42</b> may change the HRTF, based on the position information received from the user. For example, when a listener designates a position immediately in front of the stage of the first venue <b>10</b>, the terminal <b>42</b> sets a localization position of the sound of a performer to the position immediately in front of the listener and convolves the HRTF such that the sound of a performer may be localized at the position. As a result, the listener in the fifth venue <b>20</b>B can obtain realistic sensation, as if being present immediately in front of the stage of the first venue <b>10</b>.</p><p id="p-0114" num="0113">The sound of the listener in the fifth venue <b>20</b>B may be sent to the second venue <b>20</b> instead of the first venue <b>10</b>, and may further be sent to a different venue. In the same manner as described above, the sound of the listener in the fifth venue <b>20</b>B may be sent only to the house (the fourth venue) of a friend. As a result, the listener in the fifth venue <b>20</b>B and the listener in the fourth venue can watch the live performance of the first venue <b>10</b>, while talking to each other.</p><p id="p-0115" num="0114">In addition, in the live data distribution system according to the present embodiment, a plurality of users can designate the same position. For example, each of the plurality of users may designate a position immediately in front of the stage of the first venue <b>10</b>. In such a case, each listener can obtain realistic sensation, as if being present immediately in front of the stage. As a result, a plurality of listeners can watch a performance of a performer, with the same realistic sensation, with respect to one position (a seat in the venue). In such a case, a live operator can provide service to audience beyond capacity of a real space.</p><p id="p-0116" num="0115"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a block diagram showing a configuration of a live data distribution system <b>1</b>D according to a fourth modification. The same reference numerals are used to refer to components common to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, and the description will be omitted.</p><p id="p-0117" num="0116">The live data distribution system <b>1</b>D further includes a server <b>50</b> and a terminal <b>55</b>. The terminal <b>55</b> is installed in a sixth venue <b>10</b>A. The server <b>50</b> is an example of the distribution apparatus, and a hardware configuration of the server <b>50</b> is the same as the hardware configuration of the distribution apparatus <b>12</b>. A hardware configuration of the terminal <b>55</b> is the same as the configuration of the terminal <b>42</b> shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>.</p><p id="p-0118" num="0117">The sixth venue <b>10</b>A is a house of a performer remotely performing a performance such as playing. The performer present in the sixth venue <b>10</b>A performs a performance such as playing or singing, according to playing or singing in the first venue. The terminal <b>55</b> sends the sound of the performer in the sixth venue <b>10</b>A to the server <b>50</b>. In addition, the terminal <b>55</b>, by a not-shown camera, may capture the performer in the sixth venue <b>10</b>A, and may send a video signal to the server <b>50</b>.</p><p id="p-0119" num="0118">The server <b>50</b> distributes distribution data including the sound of a performer in the first venue <b>10</b>, the sound of a performer in the sixth venue <b>10</b>A, the information on space reverberation of the first venue <b>10</b>, the ambience information of the first venue <b>10</b>, the live video of the first venue <b>10</b>, and the video of the performer in the sixth venue <b>10</b>A.</p><p id="p-0120" num="0119">In such a case, the reproduction apparatus <b>22</b> renders the distribution data and provides the sound of the performer in the first venue <b>10</b>, the sound of the performer in the sixth venue <b>10</b>A, the space reverberation of the first venue <b>10</b>, the ambient sound of the first venue <b>10</b>, the live video of the first venue <b>10</b>, and the video of the performer in the sixth venue <b>10</b>A, to the second venue <b>20</b>. For example, the reproduction apparatus <b>22</b> displays the video of the performer in the sixth venue <b>10</b>A, the video being superimposed on the live video of the first venue <b>10</b>.</p><p id="p-0121" num="0120">The sound of the performer in the sixth venue <b>10</b>A, although having no need to be performed by the localization processing, may be localized at a position matching with the video displayed on a display. For example, in a case in which the performer in the sixth venue <b>10</b>A is displayed on the right side in the live video, the sound of the performer in the sixth venue <b>10</b>A is localized on the right side.</p><p id="p-0122" num="0121">In addition, the performer in the sixth venue <b>10</b>A or a distributor of the distribution data may designate the position of the performer. In such a case, the distribution data includes position information of the performer in the sixth venue <b>10</b>A. The reproduction apparatus <b>22</b> localizes the sound of the performer in the sixth venue <b>10</b>A, based on the position information of the performer in the sixth venue <b>10</b>A.</p><p id="p-0123" num="0122">The video of the performer in the sixth venue <b>10</b>A is not limited to the video captured by the camera. For example, a two-dimensional image or a character image (a virtual video) of <b>3</b>D modeling may be distributed as a video of the performer in the sixth venue <b>10</b>A.</p><p id="p-0124" num="0123">It is to be noted that the distribution data may include audio recording data. In addition, the distribution data may also include video recording data. For example, the distribution apparatus may distribution data including the sound of the performer in the first venue <b>10</b>, audio recording data, the information on space reverberation of the first venue <b>10</b>, the ambience information of the first venue <b>10</b>, the live video of the first venue <b>10</b>, and video recording data. In such a case, the reproduction apparatus renders the distribution data and provides the sound of the performer in the first venue <b>10</b>, the sound according to the audio recording data, the space reverberation of the first venue <b>10</b>, the ambient sound of the first venue <b>10</b>, the live video of the first venue <b>10</b>, and the video according to the video recording data, to a different venue. The reproduction apparatus <b>22</b> displays the video of the performer corresponding to the video recording data, the video being superimposed on the live video of the first venue <b>10</b>.</p><p id="p-0125" num="0124">In addition, the distribution apparatus, when recording the sound according to the audio recording data, may determine the type of a musical instrument. In such a case, the distribution apparatus distributes the distribution data including information that shows the audio recording data and an identified type of the musical instrument. The reproduction apparatus generates a video of a corresponding musical instrument, based on the information that shows the type of the musical instrument. The reproduction apparatus may display a video of the musical instrument, the video being superimposed on the live video of the first venue <b>10</b>.</p><p id="p-0126" num="0125">In addition, the distribution data does not require superimposition of the video of the performer in the sixth venue <b>10</b>A on the live video of the first venue <b>10</b>. For example, the distribution data may distribute a video of a performer in each of the first venue <b>10</b> and the sixth venue <b>10</b>A and a background video, as separate data. In such a case, the distribution data includes information that shows a display position of each video. The reproduction apparatus renders the video of each performer, based on the information that shows a display position.</p><p id="p-0127" num="0126">In addition, the background video is not limited to a video of a venue such as the first venue <b>10</b> in which a live performance is being actually performed. The background video may be a video of a venue different from the venue in which a live performance is being performed.</p><p id="p-0128" num="0127">Furthermore, the information on space reverberation included in the distribution data also has no need to correspond to the space reverberation of the first venue <b>10</b>. For example, the information on space reverberation may be virtual space information (information that shows the size, shape, wall surface material quality, and the like of the space of each venue, or an impulse response that shows a transfer function of each venue) for virtually reproducing the space reverberation of a venue corresponding to the background video. The impulse response in each venue may be measured in advance or may be determined by simulation from the size, shape, wall surface material quality, and the like of the space of each venue.</p><p id="p-0129" num="0128">Furthermore, the ambience information may also be changed to content according to the background video. For example, in a case in which the background video is for a large venue, the ambience information includes sounds such as cheers, applause, shouts, and the like of a large number of listeners. In addition, an outdoor venue includes background noise different from background noise of an indoor venue. Moreover, the reverberation of the ambient sound may also vary according to the information on space reverberation. In addition, the ambience information may include information that shows the number of spectators, and information that shows the degree of congestion (density of people). The reproduction apparatus increases or decreases the number of sounds such as cheers, applause, shouts, and the like of listeners, based on the information that shows the number of spectators. In addition, the reproduction apparatus increases or decreases the volume of cheers, applause, shouts, and the like of listeners, based on the information that shows the degree of congestion.</p><p id="p-0130" num="0129">Alternatively, the ambience information may be changed according to a performer. For example, in a case in which a performer with a large number of female fans performs a live performance, the sounds such as cheers, calling, shouts, and the like of listeners that are included in the ambience information are changed to a female voice. The ambience information may include an audio signal of the voice of these listeners, and may also include information that shows an audience attribute such as a male-to-female ratio or an age ratio. The reproduction apparatus changes the voice quality of the cheers, applause, shouts, and the like of listeners, based on the information that shows the attribute.</p><p id="p-0131" num="0130">In addition, listeners in each venue may designate a background video and information on space reverberation. The listeners in each venue use the user I/F of the reproduction apparatus and designate a background video and information on space reverberation.</p><p id="p-0132" num="0131"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a view showing an example of a live video <b>700</b> displayed on the reproduction apparatus in each venue. The live video <b>700</b> includes a video captured at the first venue <b>10</b> or other venues, or a virtual video (computer graphics) corresponding to each venue. The live video <b>700</b> is displayed on the display of the reproduction apparatus. The live video <b>700</b> displays a video including a background of a venue, a stage, a performer including a musical instrument, and listeners in the venue. The video including the background of a venue, the stage, the performer including a musical instrument, and the listeners in the venue may all be actually captured or may be virtual. In addition, only the background video may be actually captured while other videos may be virtual. Moreover, the live video <b>700</b> displays an icon image <b>751</b> and icon image <b>752</b> for designating a space. The icon image <b>751</b> is an image for designating a space of Stage A (the first venue <b>10</b>, for example) being a certain venue, and the icon image <b>752</b> is an image for designating a space of Stage B (a different concert hall, for example) being a different venue. Furthermore, the live video <b>700</b> displays a listener image <b>753</b> for designating a position of a listener.</p><p id="p-0133" num="0132">A listener using the reproduction apparatus uses the user I/F of the reproduction apparatus and designates a desired space by designating either the icon image <b>751</b> or the icon image <b>752</b>. The distribution apparatus distributes the distribution data including a background video and information on space reverberation corresponding to a designated space. Alternatively, the distribution apparatus may distribute the distribution data including a plurality of background videos and a plurality of pieces of information on space reverberation. In such a case, the reproduction apparatus renders the background video and information on space reverberation corresponding to the space designated by the listener, among received distribution data.</p><p id="p-0134" num="0133">In the example of <figref idref="DRAWINGS">FIG. <b>16</b></figref>, the icon image <b>751</b> is designated. The reproduction apparatus displays the background video (the video of the first venue <b>10</b>, for example) corresponding to Stage A of the icon image <b>751</b>, and reproduces a sound according to space reverberation corresponding to designated Stage A. When the listener designates the icon image <b>752</b>, the reproduction apparatus switches and displays the background video of Stage B being a different space corresponding to the icon image <b>752</b>, and reproduces a sound according to corresponding different space reverberation, based on virtual space information corresponding to Stage B.</p><p id="p-0135" num="0134">As a result, the listener of each reproduction apparatus can obtain realistic sensation, as if being watching a live performance in a desired space.</p><p id="p-0136" num="0135">In addition, the listener of each reproduction apparatus can designate a desired position in a venue by moving the listener image <b>753</b> in the live video <b>700</b>. The reproduction apparatus performs localization processing based on the position designated by a user. For example, when the listener moves the listener image <b>753</b> to a position immediately in front of a stage, the reproduction apparatus sets a localization position of the sound of a performer to the position immediately in front of the listener, and performs the localization processing so as to localize the sound of a performer at the position. As a result, the listener of each reproduction apparatus can obtain realistic sensation, as if being present immediately in front of the stage.</p><p id="p-0137" num="0136">In addition, as described above, when the position of a sound source and the position (the position of a sound receiving point) of a listener change, the sound according to space reverberation also varies. The reproduction apparatus is able to determine an early reflected sound by calculation, in a case in which a space varies, in a case in which the position of a sound source varies, or even in a case in which the position of a sound receiving point varies. Therefore, even when measurement of an impulse response or the like is not performed in an actual space, the reproduction apparatus is able to obtain a sound according to space reverberation, based on virtual space information. Therefore, the reproduction apparatus is able to implement reverberation that occurs in a space also including a real space, with high accuracy.</p><p id="p-0138" num="0137">For example, the mixer <b>11</b> may function as a distribution apparatus and the mixer <b>21</b> may function as a reproduction apparatus. In addition, the reproduction apparatus does not need to be installed in each venue. For example, the server <b>50</b> shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref> may render the distribution data and may distribute the audio signal on which the signal processing has been performed, to a terminal or the like in each venue. In such a case, the server <b>50</b> functions as a reproduction apparatus.</p><p id="p-0139" num="0138">The information on a sound source may include information that shows a posture (left or right orientation of a performer, for example) of a performer. The reproduction apparatus may perform processing to adjust volume or frequency characteristics, based on posture information of a performer. For example, the reproduction apparatus performs processing to reduce the volume as the left or right orientation is increased, on the basis of a case in which the orientation of the performer is directly in front. In addition, the reproduction apparatus may perform processing to attenuate a high frequency more than a low frequency as the left or right orientation is increased. As a result, since a sound varies according to the posture of a performer, the listener can watch a live performance with more realistic sensation.</p><p id="p-0140" num="0139">Next, <figref idref="DRAWINGS">FIG. <b>17</b></figref> is a block diagram showing an application example of signal processing performed by the reproduction apparatus. In this example, the terminal <b>42</b> and headphones <b>43</b> that are shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref> are used to perform rendering. The reproduction apparatus (the terminal <b>42</b> in the example of <figref idref="DRAWINGS">FIG. <b>13</b></figref>) functionally includes a musical instrument model processor <b>551</b>, an amplifier model processor <b>552</b>, a speaker model processor <b>553</b>, a space model processor <b>554</b>, a binaural processor <b>555</b>, and a headphone inverse characteristics processor <b>556</b>.</p><p id="p-0141" num="0140">The musical instrument model processor <b>551</b>, the amplifier model processor <b>552</b>, and the speaker model processor <b>553</b> perform signal processing to add acoustic characteristics of an acoustic device to an audio signal according to a playing sound. A first digital signal processing model for performing the signal processing is included in the information on a sound source distributed by the distribution apparatus <b>12</b>, for example. The first digital signal processing model is a digital filter to simulate each of the acoustic characteristics of a musical instrument, the acoustic characteristics of an amplifier, and the acoustic characteristics of a speaker, respectively. The first digital signal processing model is created in advance by the manufacturer of a musical instrument, the manufacturer of an amplifier, and the manufacturer of a speaker through simulation or the like. The musical instrument model processor <b>551</b>, the amplifier model processor <b>552</b>, and the speaker model processor <b>553</b> respectively perform digital filter processing to simulate the acoustic characteristics of a musical instrument, the acoustic characteristics of an amplifier, and the acoustic characteristics of a speaker. It is to be noted that, in a case in which the musical instrument is an electronic musical instrument such as a synthesizer, the musical instrument model processor <b>551</b> inputs note event data (information that shows pronunciation timing to be pronounced, the pitch of a sound, or the like) instead of an audio signal and generates an audio signal with the acoustic characteristics of the electronic musical instrument such as a synthesizer.</p><p id="p-0142" num="0141">As a result, the reproduction apparatus is able to reproduce the acoustic characteristics of any musical instrument or a similar tool. For example, in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, the live video <b>700</b> of a virtual video (computer graphics) is displayed. Herein, the listener using the reproduction apparatus may use the user I/F of the reproduction apparatus and may change to a video of another virtual musical instrument. When the listener changes the musical instrument currently displayed on the live video <b>700</b> to the video of a different musical instrument, the musical instrument model processor <b>551</b> of the reproduction apparatus performs signal processing according to the first digital signal processing model according to a changed musical instrument. As a result, the reproduction apparatus outputs a sound reproducing the acoustic characteristics of the musical instrument currently displayed on the live video <b>700</b>.</p><p id="p-0143" num="0142">Similarly, the listener using the reproduction apparatus may use the user I/F of the reproduction apparatus, and may change the type of an amplifier and the type of a speaker into a different type. The amplifier model processor <b>552</b> and the speaker model processor <b>553</b> perform digital filter processing to simulate the acoustic characteristics of an amplifier of a changed type, and the acoustic characteristics of a speaker of a changed type. It is to be noted that the speaker model processor <b>553</b> may simulate the acoustic characteristics for each direction of a speaker. In such a case, the listener using the reproduction apparatus may use the user I/F of the reproduction apparatus and may change the direction of a speaker. The speaker model processor <b>553</b> performs digital filter processing according to a changed direction of a speaker.</p><p id="p-0144" num="0143">The space model processor <b>554</b> is a second digital signal processing model in which the acoustic characteristics (the above space reverberation, for example) of a room in the live venue is reproduced. The second digital signal processing model may be obtained at an actual live venue by use of a test sound or the like, for example. Alternatively, the second digital signal processing model, as described above, may obtain by calculation a delay amount and level of the imaginary sound source from the virtual space information (the information that shows the size, shape, wall surface material quality, and the like of the space of each venue).</p><p id="p-0145" num="0144">When the position of a sound source and the position (the position of a sound receiving point) of a listener change, the sound according to space reverberation also varies. The reproduction apparatus is able to determine by calculation a delay amount and level of the imaginary sound source, in a case in which a space varies, in a case in which the position of a sound source varies, and even in a case in which the position of a sound receiving point varies. Therefore, even when the measurement of an impulse response or the like is not performed in an actual space, the reproduction apparatus is able to obtain a sound according to space reverberation, based on virtual space information. Therefore, the reproduction apparatus is able to implement reverberation that occurs in a space also including a real space, with high accuracy.</p><p id="p-0146" num="0145">It is to be noted that the virtual space information may include the position and material quality of a structure (an acoustic obstacle) such as a column. The reproduction apparatus, in sound source localization and indirect sound generation processing, when an obstacle is present in a path of a direct sound and an indirect sound that reach from a sound source, reproduces phenomena of reflection, shielding, and diffraction by the obstacle.</p><p id="p-0147" num="0146"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a schematic diagram showing a path of a sound reflected by a wall surface from a sound source <b>70</b> and arriving at a sound receiving point <b>75</b>. The sound source <b>70</b> shown in <figref idref="DRAWINGS">FIG. <b>18</b></figref> may be either of a playing sound (a first sound source) or an ambient sound (a second sound source). The reproduction apparatus determines a position of an imaginary sound source <b>70</b>A that exists with the wall surface as a mirror surface with respect to the position of the sound source <b>70</b>, based on the position of the sound source <b>70</b>, the position of the wall surface, and the position of the sound receiving point <b>75</b>. Then, the reproduction apparatus determines a delay amount of the imaginary sound source <b>70</b>A, based on a distance from the imaginary sound source <b>70</b>A to the sound receiving point <b>75</b>. In addition, the reproduction apparatus determines a level of the imaginary sound source <b>70</b>A, based on the information on the material quality of the wall surface. Furthermore, the reproduction apparatus, as shown in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, in a case in which an obstacle <b>77</b> is present in a path from the position of the imaginary sound source <b>70</b>A to the sound receiving point <b>75</b>, determines frequency characteristics caused by diffraction of the obstacle <b>77</b>. The diffraction attenuates a sound in the high frequency, for example. Therefore, the reproduction apparatus, as shown in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, in the case in which the obstacle <b>77</b> is present in the path from the position of the imaginary sound source <b>70</b>A to the sound receiving point <b>75</b>, performs equalizer processing to reduce the level in the high frequency. The frequency characteristics caused by diffraction may be included in the virtual space information.</p><p id="p-0148" num="0147">In addition, the reproduction apparatus may set a second imaginary sound source <b>77</b>A and a third imaginary sound source <b>77</b>B that are new at left and right positions of the obstacle <b>77</b>. The second imaginary sound source <b>77</b>A and the third imaginary sound source <b>77</b>B correspond to a new sound source to be caused by diffraction. Both of the second imaginary sound source <b>77</b>A and the third imaginary sound source <b>77</b>B are sounds obtained by adding the frequency characteristics caused by diffraction to the sound of the imaginary sound source <b>70</b>A. The reproduction apparatus recalculates the delay amount and the level, based on the positions of the second imaginary sound source <b>77</b>A and the third imaginary sound source <b>77</b>B, and the position of the sound receiving point <b>75</b>. As a result, the diffraction phenomenon of the obstacle <b>77</b> is able to be reproduced.</p><p id="p-0149" num="0148">The reproduction apparatus may calculate a delay amount and level of a sound such that a sound of the imaginary sound source <b>70</b>A may be reflected by the obstacle <b>77</b> and may further be reflected by a wall surface, and reaches the sound receiving point <b>75</b>. In addition, the reproduction apparatus, when determining that the imaginary sound source <b>70</b>A is shielded by the obstacle <b>77</b>, may erase the imaginary sound source <b>70</b>A. The information to determine whether or not to shield may be included in the virtual space information.</p><p id="p-0150" num="0149">The reproduction apparatus, by performing the above processing, performs the first digital signal processing that represents the acoustic characteristics of an acoustic device, and the second digital signal processing that represents the acoustic characteristics of a room, and generates a sound according to the sound of a sound source and the space reverberation.</p><p id="p-0151" num="0150">Then, the binaural processor <b>555</b> convolves a head-related transfer function (hereinafter referred to as HRTF) into an audio signal, and performs the acoustic image localization processing on a sound source and various types of indirect sounds. The headphone inverse characteristics processor <b>556</b> performs digital filter processing to reproduce the inverse characteristics of the acoustic characteristics of the headphones that a listener uses.</p><p id="p-0152" num="0151">By the above processing, a user can obtain realistic sensation, as if being watching a live performance in a desired space and with a desired acoustic device.</p><p id="p-0153" num="0152">It is to be noted that the reproduction apparatus does not need to include all of the musical instrument model processor <b>551</b>, the amplifier model processor <b>552</b>, the speaker model processor <b>553</b>, and the space model processor <b>554</b> that are shown in <figref idref="DRAWINGS">FIG. <b>17</b></figref>. The reproduction apparatus may execute signal processing by use of at least one digital signal processing model. In addition, the reproduction apparatus may perform signal processing using one digital signal processing model, on one certain audio signal (a sound of a certain performer, for example), or may perform signal processing using one digital signal processing model, on each of a plurality of audio signals. The reproduction apparatus may perform signal processing using a plurality of digital signal processing models, on one certain audio signal (a sound of a certain performer, for example), or may perform signal processing using a plurality of digital signal processing models, on a plurality of audio signals. The reproduction apparatus may perform signal processing using a digital signal processing model, on an ambient sound.</p><p id="p-0154" num="0153">The description of the foregoing embodiments is illustrative in all points and should not be construed to limit the present disclosure. The scope of the present disclosure is defined not by the foregoing embodiments but by the following claims for patent. Further, the scope of the present disclosure is intended to include all modifications within the scopes of the claims for patent and within the meanings and scopes of equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A live data distribution method of distributing live sound data among a plurality of venues, including a first venue and a second venue, the method comprising:<claim-text>obtaining information on a sound source according to sound generated at the first venue, and information on space reverberation, as distribution data;</claim-text><claim-text>distributing the distribution data to the second venue; and</claim-text><claim-text>rendering the distribution data and providing sound according to the distribution data at the second venue.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The live data distribution method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the information on the sound source includes an audio signal of the sound generated at the first venue and position information of the sound source, and</claim-text><claim-text>the rendering includes localization processing of the audio signal according to the position information.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The live data distribution method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the information on the space reverberation includes information for generating an indirect sound, and</claim-text><claim-text>the rendering includes generating the indirect sound of sound of the sound source.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The live data distribution method according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the information on the space reverberation varies according to the position of the sound source.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The live data distribution method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the distribution data includes ambience information according to an ambient sound, and</claim-text><claim-text>the rendering includes processing according to the ambient information to further provide the ambient sound.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The live data distribution method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the information on the space reverberation includes virtual space information for reproducing reverberation other than reverberation of the first venue, and</claim-text><claim-text>the rendering reproduces the sound according to the space reverberation, based on the virtual space information.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The live data distribution method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:<claim-text>receiving an operation to designate a space from a user at the second venue,</claim-text><claim-text>wherein the rendering reproduces the sound according to the space reverberation, based on the virtual space information according to the space received by the operation.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The live data distribution method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:<claim-text>providing a live video to the second venue,</claim-text><claim-text>wherein the virtual space information corresponds to the space reverberation of the live video.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The live data distribution method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>rendering the distribution data and providing the sound according to the distribution data at a third venue, among the plurality of venues,</claim-text><claim-text>wherein the sound according to the space reverberation is common to the second venue and the third venue.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The live data distribution method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the information on the sound source includes a digital signal processing model that represents acoustic characteristics of an acoustic device; and</claim-text><claim-text>the sound according to the information on the sound source is provided to the second venue using the digital signal processing model.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The live data distribution method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the information on the space reverberation includes a digital signal processing model that represents acoustic characteristics of a room; and</claim-text><claim-text>the sound according to the space reverberation is provided to the second venue using the digital signal processing model.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The live data distribution method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>distributing position information that shows a position of a structure installed in the first venue,</claim-text><claim-text>wherein the information on the sound source includes an audio signal of the sound generated at the first venue and position information of the sound source, and</claim-text><claim-text>wherein the rendering includes signal processing of the audio signal based on the position information that shows the position of the structure and the position information of the sound source.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A live data distribution system for distributing live sound data among a plurality of venues, including a first venue and a second venue, the system comprising:<claim-text>a live data distribution apparatus including at least a first processor that obtains and distributes information on a sound source according to sound generated at the first venue, and information on space reverberation, as distribution data; and</claim-text><claim-text>a live data reproduction apparatus including at least a second processor that renders the distribution data and provides sound according to the distribution data at the second venue.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The live data distribution system according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein:<claim-text>the information on the sound source includes an audio signal of the sound generated at the first venue and position information of the sound source; and</claim-text><claim-text>the rendering by the at least the second processor includes localization processing of the audio signal according to the position information.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The live data distribution system according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein:<claim-text>the information on the space reverberation includes information for generating an indirect sound; and</claim-text><claim-text>the rendering by the at least the second processor includes generating the indirect sound of sound of the sound source.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The live data distribution system according to <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the information on the space reverberation varies according to the position of the sound source.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The live data distribution system according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein:<claim-text>the distribution data includes ambience information according to an ambient sound; and</claim-text><claim-text>the rendering by the at least the second processor includes processing according to the ambient information to further provide the ambient sound.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The live data distribution system according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein:<claim-text>the information on the space reverberation includes virtual space information for reproducing reverberation other than reverberation of the first venue; and</claim-text><claim-text>the rendering by the at least the second processor reproduces the sound according to the space reverberation, based on the virtual space information.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The live data distribution system according to <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein:<claim-text>the live data reproduction apparatus receives an operation to designate a space from a user at the second venue; and</claim-text><claim-text>the rendering by the at least the second processor reproduces the sound according to the space reverberation, based on the virtual space information corresponding to the space received by the operation.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A live data distribution apparatus for distributing live sound data among a plurality of venues, including a first venue and a second venue, the live data distribution apparatus comprising:<claim-text>at least one processor that:</claim-text></claim-text><claim-text>obtains information on a sound source according to sound generated at the first venue, and information on space reverberation, as distribution data; and</claim-text><claim-text>distributes the distribution data to the second venue,</claim-text><claim-text>wherein a reproduction apparatus at the second venue renders the distribution data and provides sound according to the distribution data at the second venue.</claim-text></claim></claims></us-patent-application>
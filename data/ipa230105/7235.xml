<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007236A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007236</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17894501</doc-number><date>20220824</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>17</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>J</subclass><main-group>1</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>J</subclass><main-group>1</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>3225</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>17</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>006</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>J</subclass><main-group>1</main-group><subgroup>0228</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>J</subclass><main-group>1</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>3</main-group><subgroup>3225</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2320</main-group><subgroup>0693</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>09</class><subclass>G</subclass><main-group>2320</main-group><subgroup>0233</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">OPTICAL CORRECTION SYSTEMS AND METHODS FOR CORRECTING NON-UNIFORMITY OF EMISSIVE DISPLAY DEVICES</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17245090</doc-number><date>20210430</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11457206</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17894501</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>15675095</doc-number><date>20170811</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11025899</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17245090</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Ignis Innovation Inc.</orgname><address><city>Waterloo</city><country>CA</country></address></addressbook><residence><country>CA</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Shyshkin</last-name><first-name>Vyacheslav</first-name><address><city>Mississauga</city><country>CA</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Saechao</last-name><first-name>Adam</first-name><address><city>Kitchener</city><country>CA</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">What is disclosed are systems and methods of optical correction for pixel evaluation and correction for active matrix light emitting diode device (AMOLED) and other emissive displays. Optical correction for correcting for non-homogeneity of a display panel uses sparse display test patterns in conjunction with a defocused camera as the measurement device to avoid aliasing (moir&#xe9;) of the pixels of the display in the captured images.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="213.61mm" wi="132.00mm" file="US20230007236A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="199.64mm" wi="152.15mm" file="US20230007236A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="96.52mm" wi="156.80mm" file="US20230007236A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="227.67mm" wi="134.03mm" file="US20230007236A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="208.96mm" wi="115.57mm" file="US20230007236A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD OF THE INVENTION</heading><p id="p-0002" num="0001">The present disclosure relates to optically measuring and calibrating light emissive visual display technology, and particularly to optical correction systems and methods for individual pixel luminance evaluation and correction for active matrix organic light emitting diode device (AMOLED) and other emissive displays.</p><heading id="h-0002" level="1">BRIEF SUMMARY</heading><p id="p-0003" num="0002">According to a first aspect there is provided an optical correction method for correcting for non-uniformity of an emissive display panel having pixels, each pixel having a light-emitting device, the method comprising: arranging a camera in front of the display panel; defocusing the camera such that the focal point of the camera lies outside of a plane passing through the light-emitting devices of the display panel, the defocusing such that individual pixels of the display panel are blurred in images of the display panel captured by the camera; displaying a plurality of test patterns while capturing respective images of said test patterns displayed, said captured images for use as luminance measurement data for pixels of the display panel, each of said displayed test patterns comprising a set of activated pixels spaced apart such that in each captured image, at least one portion of each blurred image of each activated pixel does not overlap with a blurred image of another activated pixel; and determining from said luminance measurement data, correction data for correcting non-uniformity of images displayed in the display panel.</p><p id="p-0004" num="0003">In some embodiments, the amount of blurring in images of the display panel captured by the camera is sufficient to avoid aliasing in the captured images of the display panel.</p><p id="p-0005" num="0004">In some embodiments, a resolution of the camera is less than twice a resolution of the display panel. In some embodiments, said activated pixels of each displayed test pattern are arranged in a diamond or rectangular lattice.</p><p id="p-0006" num="0005">In some embodiments, said activated pixels of the plurality of displayed test patterns comprise regular test pixels, each of said regular test pixels of said plurality of displayed test patterns having a greyscale luminance value selected from a set of at least two predetermined greyscale luminance values. In some embodiments, the set of at least two predetermined greyscale luminance values includes a relatively low greyscale luminance value and a relatively high greyscale luminance value.</p><p id="p-0007" num="0006">In some embodiments, said activated pixels of the plurality of the displayed test patterns comprise multilevel pixels, each of said multilevel pixels of said plurality of displayed test patterns having a greyscale luminance value greater or less than one of the greyscale luminance values of the set of at least two predetermined greyscale luminance values by a relatively small greyscale luminance value.</p><p id="p-0008" num="0007">Some embodiments further provide for determining correction data for each pixel of the display panel with use of a first luminance measurement of that pixel when displaying a first greyscale luminance value of the set of at least two predetermined greyscale luminance values and a second luminance measurement of that pixel when displaying a second greyscale luminance value of the set of at least two predetermined greyscale luminance values, and with use of a scale factor for that pixel determined with use of luminance measurements of pixels throughout the display panel when displaying the multilevel pixels of the displayed test patterns.</p><p id="p-0009" num="0008">In some embodiments, said activated pixels of the plurality of the displayed test patterns comprise calibration pixels, the embodiment further providing for determining locations of the activated pixels of the displayed test patterns as they appear in the captured images of the displayed test patterns; and determining at least one point spread function exhibited by blurred images of activated pixels of the displayed test pattern in the captured images, in which the activated pixels of the plurality of displayed test patterns are spaced apart such that in the captured images, blurred images of each calibration pixel does not overlap with blurred images of any other activated pixel.</p><p id="p-0010" num="0009">In some embodiments, each of the luminance measurements of each of the regular test pixels and each of the multilevel pixels is performed with use of an acquisition kernel determined from at least one of a spacing of the activated pixels of the displayed test patterns and the at least one point spread function.</p><p id="p-0011" num="0010">In some embodiments, the relatively low greyscale luminance value is substantially 10 percent of the maximum possible greyscale luminance value, and the relatively high greyscale luminance value is substantially 80 percent of the maximum greyscale luminance value. In some embodiments, the relatively small greyscale luminance value is one of substantially 1 percent of the maximum possible greyscale luminance value and the smallest incremental digital value of possible greyscale luminance values.</p><p id="p-0012" num="0011">In some embodiments, all of said regular test pixels of the relatively low greyscale luminance value are displayed in a first set of sparse flat test patterns, wherein all of said regular test pixels of the relatively high greyscale luminance value are displayed in a second set of sparse flat test patterns, wherein all of said multilevel pixels having a greyscale luminance value greater or less than the relatively low greyscale luminance value are displayed in a first set of multilevel patterns, and wherein all of said multilevel pixels having a greyscale luminance value greater or less than the relatively high greyscale luminance value are displayed in a second set of multilevel patterns.</p><p id="p-0013" num="0012">Some embodiments further provide for correcting image data with use of the correction data prior to driving the pixels to display an image corresponding to the image data.</p><p id="p-0014" num="0013">According to a second aspect there is provided an optical correction system for correcting non-uniformity of an emissive display having pixels, each pixel having a light-emitting device, the system comprising: a camera arranged in front of the display for capturing images of a plurality of test patterns displayed on the display, the camera defocused such that the focal point of the camera lies outside of a plane passing through the light-emitting devices of the display and such that individual pixels of the display are blurred in images of the display captured by the camera, each of said displayed test patterns comprising a set of activated pixels spaced apart such that in each captured image, at least one portion of each blurred image of each activated pixel does not overlap with a blurred image of another activated pixel; optical correction processing coupled to the camera and for receiving from the camera captured images of said test patterns displayed on the display, said captured images for use as luminance measurement data for pixels of the display; determining from said luminance measurement data, correction data for correcting non-uniformity of images displayed in the display; and transmitting the correction data to the display for storage in a memory of the display.</p><p id="p-0015" num="0014">In some embodiments, the optical correction processing is further for determining correction data for each pixel of the display with use of a first luminance measurement of that pixel when displaying a first greyscale luminance value of the set of at least two predetermined greyscale luminance values and a second luminance measurement of that pixel when displaying a second greyscale luminance value of the set of at least two predetermined greyscale luminance values, and with use of a scale factor for that pixel determined with use of luminance measurements of pixels throughout the display when displaying the multilevel pixels of the displayed test patterns.</p><p id="p-0016" num="0015">In some embodiments, said activated pixels of the plurality of the displayed test patterns comprise calibration pixels, and wherein the optical correction processing is further for determining locations of the activated pixels of the displayed test patterns as they appear in the captured images of the displayed test patterns; and determining at least one point spread function exhibited by blurred images of activated pixels of the displayed test pattern in the captured images, wherein the activated pixels of the plurality of displayed test patterns are spaced apart such that in the captured images, blurred images of each calibration pixel does not overlap with blurred images of any other activated pixel.</p><p id="p-0017" num="0016">In some embodiments, each of the luminance measurements of each of the regular test pixels and each of the multilevel pixels is performed by the optical correction processing with use of an acquisition kernel determined from at least one of a spacing of the activated pixels of the displayed test patterns and the at least one point spread function.</p><p id="p-0018" num="0017">Some embodiments, further provide for a controller of the emissive display system coupled to said optical correction processing, said controller for receiving image data for display by the display; receiving from the optical correction processing the correction data; and correcting the image data with use of the correction data prior to driving the pixels to display an image corresponding to the image data.</p><p id="p-0019" num="0018">The foregoing and additional aspects and embodiments of the present disclosure will be apparent to those of ordinary skill in the art in view of the detailed description of various embodiments and/or aspects, which is made with reference to the drawings, a brief description of which is provided next.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0020" num="0019">The foregoing and other advantages of the disclosure will become apparent upon reading the following detailed description and upon reference to the drawings.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example display system which participates in and whose pixels are to be measured and corrected by the optical correction systems and methods disclosed;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a system block diagram of an optical correction system;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a high level functional block diagram of an optical correction method; and</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example method of displaying and capturing display test patterns of the method illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0025" num="0024">While the present disclosure is susceptible to various modifications and alternative forms, specific embodiments or implementations have been shown by way of example in the drawings and will be described in detail herein. It should be understood, however, that the disclosure is not intended to be limited to the particular forms disclosed. Rather, the disclosure is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of an invention as defined by the appended claims.</p><heading id="h-0004" level="1">DETAILED DESCRIPTION</heading><p id="p-0026" num="0025">Many modern display technologies suffer from defects, variations, and non-uniformities, from the moment of fabrication, and can suffer further from aging and deterioration over the operational lifetime of the display, which result in the production of images which deviate from those which are intended. Optical correction systems and methods can be used, either during fabrication or after a display has been put into use, to measure and correct pixels (and sub-pixels) whose output luminance varies from the expected luminance. AMOLED panels in particular are characterized by luminance non-uniformity.</p><p id="p-0027" num="0026">To correct for this intrinsic non-uniformity of the display, the incoming video signal is deliberately modified with compensation data or correction data such that it compensates for the non-uniformity. In some approaches, to obtain the correction data the luminance of each individual panel pixel is measured for a range of greyscale luminance values, and correction values for each pixel are determined. A typical setup utilizes a monochrome or conventional RGB still picture camera as the measurement device. At least one calibration pattern is displayed on the display and captured with the camera. Measurements in the form of captured images are then processed to extract the actual luminance of each individual pixel of the display. Taking into account the greyscale luminance value of the pixel of the calibration pattern which was used to drive the pixel of the display, a correction signal for that pixel of the display driven at that greyscale luminance value is generated. Limitations with this technique arise when the spatial sampling rate of the camera falls below two times the spatial frequency of the pixel image of the display. According to well-known sampling principles, the camera should operate at or above the Nyquist rate, i.e. at or above twice the frequency of the pixel image of the display, in order to reconstruct the displayed image accurately from a single captured image taken by the camera. When the sampling rate of the camera falls below twice the image pixel rate of the display, the reconstructed image will suffer from aliasing (moir&#xe9;) and pixel overlap, i.e. images of different pixels of the display will overlap in images taken by the camera. As displays are produced with increasingly higher and higher resolutions this poses a problem for obtaining correction data with existing standard resolution cameras which do not have resolutions as high as twice as that of the display, and alternatively increases costs by necessitating deployment of optical correction systems which include much higher resolution cameras.</p><p id="p-0028" num="0027">While the embodiments described herein will be in the context of AMOLED displays it should be understood that the optical correction systems and methods described herein are applicable to any other display comprising pixels, including but not limited to light emitting diode displays (LED), electroluminescent displays (ELD), organic light emitting diode displays (OLED), plasma display panels (PSP), microLED or quantum dot displays, among other displays.</p><p id="p-0029" num="0028">It should be understood that the embodiments described herein pertain to systems and methods of optical correction and compensation and do not limit the display technology underlying their operation and the operation of the displays in which they are implemented. The systems and methods described herein are applicable to any number of various types and implementations of various visual display technologies.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of an example display system <b>150</b> implementing the methods described further below in conjunction with an arrangement with a camera and optical correction processing. The display system <b>150</b> includes a display panel <b>120</b>, an address driver <b>108</b>, a data driver <b>104</b>, a controller <b>102</b>, and a memory storage <b>106</b>.</p><p id="p-0031" num="0030">The display panel <b>120</b> includes an array of pixels <b>110</b> (only one explicitly shown) arranged in rows and columns. Each of the pixels <b>110</b> is individually programmable to emit light with individually programmable luminance values. The controller <b>102</b> receives digital data indicative of information to be displayed on the display panel <b>120</b>. The controller <b>102</b> sends signals <b>132</b> to the data driver <b>104</b> and scheduling signals <b>134</b> to the address driver <b>108</b> to drive the pixels <b>110</b> in the display panel <b>120</b> to display the information indicated. The plurality of pixels <b>110</b> of the display panel <b>120</b> thus comprise a display array or display screen adapted to dynamically display information according to the input digital data received by the controller <b>102</b>. The display screen and various subsets of its pixels define &#x201c;display areas&#x201d; which may be used for monitoring and managing display brightness. The display screen can display images and streams of video information from data received by the controller <b>102</b>. The supply voltage <b>114</b> provides a constant power voltage or can serve as an adjustable voltage supply that is controlled by signals from the controller <b>102</b>. The display system <b>150</b> can also incorporate features from a current source or sink (not shown) to provide biasing currents to the pixels <b>110</b> in the display panel <b>120</b> to thereby decrease programming time for the pixels <b>110</b>.</p><p id="p-0032" num="0031">For illustrative purposes, only one pixel <b>110</b> is explicitly shown in the display system <b>150</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. It is understood that the display system <b>150</b> is implemented with a display screen that includes an array of a plurality of pixels, such as the pixel <b>110</b>, and that the display screen is not limited to a particular number of rows and columns of pixels. For example, the display system <b>150</b> can be implemented with a display screen with a number of rows and columns of pixels commonly available in displays for mobile devices, monitor-based devices, and/or projection-devices. In a multichannel or color display, a number of different types of pixels, each responsible for reproducing color of a particular channel or color such as red, green, or blue, will be present in the display. Pixels of this kind may also be referred to as &#x201c;subpixels&#x201d; as a group of them collectively provide a desired color at a particular row and column of the display, which group of subpixels may collectively also be referred to as a &#x201c;pixel&#x201d;.</p><p id="p-0033" num="0032">The pixel <b>110</b> is operated by a driving circuit or pixel circuit that generally includes a driving transistor and a light emitting device. Hereinafter the pixel <b>110</b> may refer to the pixel circuit. The light emitting device can optionally be an organic light emitting diode, but implementations of the present disclosure apply to pixel circuits having other electroluminescence devices, including current-driven light emitting devices and those listed above. The driving transistor in the pixel <b>110</b> can optionally be an n-type or p-type amorphous silicon thin-film transistor, but implementations of the present disclosure are not limited to pixel circuits having a particular polarity of transistor or only to pixel circuits having thin-film transistors. The pixel circuit <b>110</b> can also include a storage capacitor for storing programming information and allowing the pixel circuit <b>110</b> to drive the light emitting device after being addressed. Thus, the display panel <b>120</b> can be an active matrix display array.</p><p id="p-0034" num="0033">As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the pixel <b>110</b> illustrated as the top-left pixel in the display panel <b>120</b> is coupled to a select line <b>124</b>, a supply line <b>126</b>, a data line <b>122</b>, and a monitor line <b>128</b>. A read line may also be included for controlling connections to the monitor line. In one implementation, the supply voltage <b>114</b> can also provide a second supply line to the pixel <b>110</b>. For example, each pixel can be coupled to a first supply line <b>126</b> charged with Vdd and a second supply line <b>127</b> coupled with Vss, and the pixel circuits <b>110</b> can be situated between the first and second supply lines to facilitate driving current between the two supply lines during an emission phase of the pixel circuit. It is to be understood that each of the pixels <b>110</b> in the pixel array of the display <b>120</b> is coupled to appropriate select lines, supply lines, data lines, and monitor lines. It is noted that aspects of the present disclosure apply to pixels having additional connections, such as connections to additional select lines, and to pixels having fewer connections.</p><p id="p-0035" num="0034">With reference to the pixel <b>110</b> of the display panel <b>120</b>, the select line <b>124</b> is provided by the address driver <b>108</b>, and can be utilized to enable, for example, a programming operation of the pixel <b>110</b> by activating a switch or transistor to allow the data line <b>122</b> to program the pixel <b>110</b>. The data line <b>122</b> conveys programming information from the data driver <b>104</b> to the pixel <b>110</b>. For example, the data line <b>122</b> can be utilized to apply a programming voltage or a programming current to the pixel <b>110</b> in order to program the pixel <b>110</b> to emit a desired amount of luminance. The programming voltage (or programming current) supplied by the data driver <b>104</b> via the data line <b>122</b> is a voltage (or current) appropriate to cause the pixel <b>110</b> to emit light with a desired amount of luminance according to the digital data received by the controller <b>102</b>. The programming voltage (or programming current) can be applied to the pixel <b>110</b> during a programming operation of the pixel <b>110</b> so as to charge a storage device within the pixel <b>110</b>, such as a storage capacitor, thereby enabling the pixel <b>110</b> to emit light with the desired amount of luminance during an emission operation following the programming operation. For example, the storage device in the pixel <b>110</b> can be charged during a programming operation to apply a voltage to one or more of a gate or a source terminal of the driving transistor during the emission operation, thereby causing the driving transistor to convey the driving current through the light emitting device according to the voltage stored on the storage device.</p><p id="p-0036" num="0035">Generally, in the pixel <b>110</b>, the driving current that is conveyed through the light emitting device by the driving transistor during the emission operation of the pixel <b>110</b> is a current that is supplied by the first supply line <b>126</b> and is drained to a second supply line <b>127</b>. The first supply line <b>126</b> and the second supply line <b>127</b> are coupled to the voltage supply <b>114</b>. The first supply line <b>126</b> can provide a positive supply voltage (e.g., the voltage commonly referred to in circuit design as &#x201c;Vdd&#x201d;) and the second supply line <b>127</b> can provide a negative supply voltage (e.g., the voltage commonly referred to in circuit design as &#x201c;Vss&#x201d;). Implementations of the present disclosure can be realized where one or the other of the supply lines (e.g., the supply line <b>127</b>) is fixed at a ground voltage or at another reference voltage.</p><p id="p-0037" num="0036">The display system <b>150</b> also includes a monitoring system <b>112</b>. With reference again to the pixel <b>110</b> of the display panel <b>120</b>, the monitor line <b>128</b> connects the pixel <b>110</b> to the monitoring system <b>112</b>. The monitoring system <b>12</b> can be integrated with the data driver <b>104</b>, or can be a separate stand-alone system. In particular, the monitoring system <b>112</b> can optionally be implemented by monitoring the current and/or voltage of the data line <b>122</b> during a monitoring operation of the pixel <b>110</b>, and the monitor line <b>128</b> can be entirely omitted. The monitor line <b>128</b> allows the monitoring system <b>112</b> to measure a current or voltage associated with the pixel <b>110</b> and thereby extract information indicative of a degradation or aging of the pixel <b>110</b> or indicative of a temperature of the pixel <b>110</b>. In some embodiments, display panel <b>120</b> includes temperature sensing circuitry devoted to sensing temperature implemented in the pixels <b>110</b>, while in other embodiments, the pixels <b>110</b> comprise circuitry which participates in both sensing temperature and driving the pixels. For example, the monitoring system <b>112</b> can extract, via the monitor line <b>128</b>, a current flowing through the driving transistor within the pixel <b>110</b> and thereby determine, based on the measured current and based on the voltages applied to the driving transistor during the measurement, a threshold voltage of the driving transistor or a shift thereof.</p><p id="p-0038" num="0037">The controller and <b>102</b> and memory store <b>106</b> together or in combination with a compensation block (not shown) use compensation data or correction data, in order to address and correct for the various defects, variations, and non-uniformities, existing at the time of fabrication, and optionally, defects suffered further from aging and deterioration after usage. In some embodiments, the correction data includes data for correcting the luminance of the pixels obtained through measurement and processing using an external optical feedback system such as that described below. Some embodiments employ the monitoring system <b>112</b> to characterize the behavior of the pixels and to continue to monitor aging and deterioration as the display ages and to update the correction data to compensate for said aging and deterioration over time.</p><p id="p-0039" num="0038">For the embodiments disclosed herein, correction data is directly determined during an optical correction operation either during or subsequent to fabrication or after the display has been in operation for some time, from observing the luminance of each pixel and determining the correction data to produce luminance of an acceptable level.</p><p id="p-0040" num="0039">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, an optical correction system <b>200</b> according to an embodiment will now be described.</p><p id="p-0041" num="0040">The optical correction system <b>200</b> includes display system <b>250</b> which is to be corrected, a camera <b>230</b>, a controller <b>202</b> for overall control the process, which in the embodiment of <figref idref="DRAWINGS">FIG. <b>2</b></figref> is shown as part of the display system <b>250</b>, and an optical correction processing module <b>240</b> for controlling specific processes of the optical correction methods. The optical correction processing <b>240</b> can be part of an external tool that is used for example in a production factory for correction of the displays. In another case, optical correction processing <b>240</b> can be part of the display system and/or the controller, for example, integrated in a timing controller TCON. The display system <b>250</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref> may correspond more or less to the display system <b>150</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and includes similar components thereof, of which specifically, drivers <b>207</b>, the display panel <b>220</b>, and the controller <b>202</b> are shown explicitly for convenience. The controller <b>202</b> may correspond to controller <b>102</b> or controller <b>102</b> and memory <b>106</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0042" num="0041">The camera <b>230</b> is arranged to measure the luminance of all of the pixels <b>110</b> of the display panel <b>220</b>. The camera <b>230</b> may be based on a digital photography system with lenses, and may be a monochromatic digital camera or a standard digital camera, such as a monochromatic or RGB, CCD CMOS or other sensor array based camera, or any other suitable optical measurement technology capable of taking optical images through a lens and generating a luminance measurement image representative of the optical output of the display panel <b>220</b>. Optical correction processing <b>240</b> receives the luminance measurement image data from the camera <b>230</b>. Luminance measurement image data refers to any matrix containing optical luminance data corresponding to the output of the display panel <b>220</b>, and may comprise multiple channels such as red (R), green (G), blue (B) etc. and in some cases may be monochromatic as in the case where the camera <b>230</b> is monochromatic. Hereinafter, luminance measurement image data will be referred to simply as a &#x201c;captured image&#x201d; and if monochromatic, will be assumed to include one luminance value for every pixel of the captured image. It should be understood that any reference made to &#x201c;greyscale luminance value&#x201d; is a reference to the DAC (Digital to Analogue Converter) signal data value used to drive a pixel and which results in a pixel producing an actual luminance. For simplicity, the preset luminance values associated with the various pixel patterns described below are characterized in terms of the corresponding DAC signal i.e. greyscale luminance value which is used to drive the pixels. Advantages of using a monochromatic camera versus an RGB camera include faster exposure times, avoidance of display and sensor R,G,B frequency mismatch and/or crosstalk, avoidance of mismatching numbers or arrangements of the R,G,B sub-pixels of the display and the R,G,B elements of the sensor array, and ease of handing yellow or white subpixels of display panel <b>220</b>. In some embodiments utilizing either a monochromatic or an RGB camera, measurements of each pixel of the display occurs only for a single channel or subpixel color (R, G, B, Y, or W etc.) at any one time.</p><p id="p-0043" num="0042">For the embodiments herein described, the resolution of the camera <b>230</b> and equally a ratio of the resolution of the camera <b>230</b> to the resolution of the display panel <b>220</b>, are not required to exceed the thresholds otherwise required according to the Nyquist rate. This is because the camera is intentionally defocused and test patterns incorporate activated pixels whose blurred images have portions which do not overlap with one another, as described below. In particular, the resolution of the camera <b>230</b> need not be greater than twice the resolution of the display panel <b>220</b>. The camera <b>230</b> may be operated manually or automatically controlled by one or both of the controller <b>202</b> and optical correction processing <b>240</b>.</p><p id="p-0044" num="0043">With reference also to the optical correction method <b>300</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, camera <b>230</b> and the display panel <b>220</b> are arranged <b>302</b> such that the entirety of the viewable area of the display panel <b>220</b> appears within the field of view of the camera <b>230</b>. In some embodiments, the camera <b>230</b> is positioned in front of display panel <b>220</b>, aimed at the center of the viewable area of the display panel <b>220</b> and with the viewable area of the display panel <b>220</b> maximized to occupy as much of the field of view of the camera <b>230</b> as possible. The line of sight of the camera <b>230</b> (controlled by camera pan, tilt, and positioning) may be such that it is parallel and coincident with a normal to the plane of the front surface of the display panel <b>220</b> emerging at the center of the display panel <b>220</b> to reduce distortions and to ensure any remaining distortions are as symmetrical as possible in the resulting images of the display panel <b>220</b>. Calibration pattern processing discussed below, however, can compensate for deviations in the relative placement and alignment of the camera <b>230</b> and the display panel <b>220</b>.</p><p id="p-0045" num="0044">Once the camera <b>230</b> and the display panel <b>220</b> have been arranged <b>302</b> relative to each other, the camera <b>230</b> is intentionally defocused <b>304</b>. The defocusing of the camera <b>230</b> results in the focal point of the camera being positioned either in front of or behind a plane passing through the light emitting elements of the pixels <b>110</b> of the display panel <b>220</b>. The amount of defocusing is set such that it is sufficient, in the context of the particular display panel <b>220</b> and camera <b>230</b>, to avoid aliasing (moir&#xe9;). This amount of defocusing generally depends upon a number of factors, primarily upon the ratio of the resolution of the camera <b>230</b> to the resolution of the display panel <b>220</b>, but also upon the number and arrangement of subpixels per pixel <b>110</b> in the display panel <b>220</b>, the number and arrangement of optical sensors (CCD, CMOS, etc.), the presence of color/bayer and/or antialiasing filters in the camera <b>230</b>, and any effects caused by the optics of the front surface layers of the display panel <b>220</b>, etc. The level of defocusing will vary from case to case, but generally the amount of defocusing which is sufficient to avoid aliasing (moir&#xe9;) is directly determined through empirical testing. In some embodiments the minimum amount of defocusing to completely remove aliasing is chosen.</p><p id="p-0046" num="0045">Instead of displaying all pixels of the display panel <b>220</b> simultaneously according to known techniques, in combination with intentional defocusing, the present embodiments display a number of display test patterns, each of which includes a sparse set of activated pixels which are spaced apart far enough so that at least some portion of the blurred images of each of the activated pixels in the captured images do not overlap or interfere with each other. Typically this portion would include (but is not limited to) the center of each blurred image of the activated pixels, and in some cases this non-overlapping portion would constitute a majority of each blurred image of an activated pixel, in which case, only the outer portions or edges of the blurred images of the pixels would overlap. In some embodiments, and for some test patterns, the blurred images of the activated pixels in the captured images do not have any overlap with each other. Combining the defocusing with appropriately spaced apart activated pixels simultaneously avoids aliasing (moir&#xe9;) while accommodating use of a camera <b>220</b> with a resolution well below the Nyquist limit to measure individual pixel luminances. Moreover, by avoiding overlap for at least some portion of each image of each pixel, the highest frequency mura may be characterized i.e. accurate measurements of the luminance on an individual pixel basis is possible. As described below, even in embodiments with some overlap of the blurred images of the individual pixels, as long as the overlap is controlled, accurate measurements of the luminance of each individual pixel may be made with appropriately chosen acquisition kernals which avoid or processes areas of overlap with appropriate weights.</p><p id="p-0047" num="0046">In embodiments where the amount of defocusing is chosen to be as small as possible while still avoiding aliasing (moir&#xe9;), smaller point spread images of the activated pixels are created, allowing for a more streamlined process by involving fewer test patterns each of which requires smaller spaces between activated pixels to avoid overlap. In some embodiments, only individual channels (R, G, B, Y, W etc) of each activated pixel are activated at any one time.</p><p id="p-0048" num="0047">Once the camera has been defocused <b>304</b> a calibration pattern is displayed on the display panel <b>230</b> and an image is captured <b>306</b> by the camera <b>220</b>. In some embodiments, the calibration pattern includes a sparse set of single pixels activated differently from a flat background. Preferably, in some embodiments, the spacing of the sparse set of single activated pixels of the calibration pattern is such that the images of those pixels in images taken by the camera <b>230</b> do not have any overlap. In some embodiments the activated pixels are set at a discernably bright greyscale and the flat background is black. In some embodiments, only individual channels (e.g. R, G, or B) of any activated pixel are activated at any one time. In some embodiments, the activated pixels are arranged in a spaced rectilinear array or a rectangular lattice. In such embodiments the activated pixels are located at corners of an imaginary grid which would result from imaginary lines drawn through the rows and columns of activated pixels and is also known as a dot grid. Other regular lattices include triangular, and diamond pattern lattices. Any sparse set of activated pixels of sufficient spacing may be used whether arranged in a regular or irregular lattice. The calibration pattern is utilized to establish the location of the individual pixels on the display panel <b>220</b> in the captured images which are captured by the camera <b>230</b>. The activated pixels in the calibration pattern are chosen such that the subpixel layout of the panel is sufficiently captured. The center of the activated pixels are then located within the captured image and an nth polynomial approximation is then performed, to calculate the location of every subpixel on the panel in the image. The distribution and pattern of the locations of the pixels of the calibration pattern as they appear in the captured image which is captured by the camera <b>230</b> (hereinafter the &#x201c;calibration image&#x201d;) allows correction of any geometrical distortion, such as rotation, tilt and skew, in subsequent images of the display panel <b>220</b> taken by the camera <b>230</b>. The calibration image also samples the point spread function (PSF) caused by the defocusing and corresponding to the blurring of pixels located in each area of the image of the display panel <b>220</b>. Although the PSF may be substantially homogeneous across the captured images taken of the display panel <b>220</b>, often due to many factors, including the structure of the lens system of the camera <b>230</b>, the PSF may be non-uniform throughout various areas of the captured images of the display panel <b>220</b>. In the case of a calibration pattern of sparse individual pixels, the point spread function is substantially directly observable in the image captured by the camera <b>230</b>. In some embodiments more than one calibration pattern is utilized. In some embodiments, no separate calibration pattern is used, and instead, one or more of the test patterns discussed below serve the same functions as the calibration pattern and in other embodiments &#x201c;calibration pixels&#x201d; are included within the series of display test patterns and serve the same function as the calibration pattern. The point spread function may be utilized in display panel <b>220</b> pixel luminance determination as discussed below.</p><p id="p-0049" num="0048">In some embodiments, the number, size, and arrangement of the sub-pixels will be such that it is preferable to limit each activated pixel of the calibration pattern to a single channel R, G, B, etc. This ensures any slight difference between sub-pixel locations of R, G, B, and any slight differences in the PSFs for each channel R, G, B, etc. will accurately be associated with each measurement separately. The calibration pattern or patterns should have enough red, green, and blue calibration pixels to adequately characterize the display panel <b>220</b> in accordance with the foregoing.</p><p id="p-0050" num="0049">Once the calibration pattern has been displayed and captured <b>306</b>, a series of display test patterns is displayed by the display panel <b>220</b> and images are captured by the camera <b>230</b>. Each test pattern of the series of display test patterns include pixels having non-zero greyscale luminance spaced apart far enough so that some portion of each image of each pixel of the pattern displayed on the display panel <b>220</b> as it appears in the captured images, which are blurred according to the PSF, do not interfere or overlap with images of the other pixels of the pattern. As described above, intentional defocusing of the camera <b>230</b> is such that images of each illuminated pixel of the display panel <b>220</b> appears as a spread out blurred image of that pixel according to the PSF and problems due to aliasing (moir&#xe9;) are avoided. In some embodiments, the activated pixels of the display test patterns are arranged in a spaced rectilinear array or a rectangular lattice. In such embodiments the activated pixels are located at corners of an imaginary grid which would result from imaginary lines drawn through the rows and columns of activated pixels and is also known as a dot grid. Other regular lattices include triangular, and diamond pattern lattices. Any sparse set of activated pixels of sufficient spacing may be used whether arranged in a regular or irregular lattice.</p><p id="p-0051" num="0050">The series of display test patterns are such that each pixel <b>110</b> of the display panel <b>220</b> may be corrected with correction data based on measurements in the form of the captured images by the camera <b>230</b> of the display panel <b>220</b> displaying the display test patterns. Preferably, the resolution of the display test pattern is the same as the resolution of the display panel <b>220</b>.</p><p id="p-0052" num="0051">In some embodiments, the series of display test patterns are such that each pixel of the display panel <b>220</b> is activated at more than one level of greyscale luminance. In some embodiments, this is done separately for each channel R, G, B, etc. In some embodiments, the series of display test patterns include, for every pixel, at least one pattern having that pixel activated at a fixed first greyscale luminance value P<b>1</b> and at least one other pattern having that pixel activated at a fixed second greyscale luminance value P<b>2</b>. The first and second fixed greyscale luminance values P<b>1</b>, P<b>2</b> used to activate the pixel are generally chosen based on what levels of greyscale are desired to exhibit the greatest uniformity. In some embodiments, the series of display test patterns include, for every pixel, at least one pattern having that pixel activated at a fixed relatively low greyscale luminance value P<b>1</b> (for example 10 percent of the possible maximum greyscale luminance value) and at least one other pattern having that pixel activated at a fixed relatively high greyscale luminance value P<b>2</b> (for example 80 percent of the possible maximum greyscale luminance value). Over the series of display test patterns, every single pixel is programmed at least once with each of P<b>1</b> and P<b>2</b> and corresponding resulting luminances of the pixel caused by programming the pixel with P<b>1</b> and P<b>2</b> are determined from the images of that pixel in those captured images of the display panel <b>220</b> displaying those display test patterns with that pixel at values P<b>1</b> and P<b>2</b>. Pixels of the display test patterns having values P<b>1</b> or P<b>2</b> are referred to hereinafter as &#x201c;regular test pixels&#x201d;.</p><p id="p-0053" num="0052">The number of display test patterns and the levels of the illuminated pixels therein depends upon the technique used to correct the data used to program each pixel. The example embodiments which follow correct the display panel non-uniformity by determining the DAC (Digital to Analogue Converter) signal which corrects the luminance non-uniformity of the panel by determining information about the DAC signal to luminance scale factor. The scale factor, once determined is used to scale the DAC correction signal to the luminance non-uniformity so that the correction applied corrects for the non-uniformity. This scale factor is obtained by also including in the series of test patterns, a subset of pixels (for example &#x2153; or &#xbc; of the total number of pixels of the display panel <b>220</b>) throughout the display test patterns such that the pixel is activated with greyscale luminance values near P<b>1</b> and P<b>2</b>, i.e. at a DAC signal level of P<b>1</b> or P<b>2</b> changed by some small &#x394; (+&#x394; or &#x2212;&#x394;). In some embodiments, &#x394; is a small percentage of the maximum greyscale luminance level (such as 1%), and in other embodiments, &#x394; is on the order of the smallest incremental digital value in the DAC signal. In some embodiments, this is done separately for each channel R, G, B, etc. The difference between the luminance produced by the pixels of the display panel <b>220</b> displaying a value of P<b>1</b> (or P<b>2</b>) and the luminance produced by the pixels of the display panel <b>220</b> displaying a value of P<b>1</b> +&#x394; or &#x2212;&#x394; (or P<b>2</b> +&#x394; or &#x2212;&#x394;allows extraction of the scale factor between the DAC signal and measured luminance at P<b>1</b> (or P<b>2</b>) and therefore can be used to translate luminance non-uniformity into a correction signal. In some embodiments, the series of display test patterns includes pixels of greyscale luminance levels including both +&#x394; and &#x2212;&#x394; about values P<b>1</b> and P<b>2</b>. In some embodiments, instead of small positive and negative changes symmetrically about the midpoint PX, the small positive change +delta and the small negative change are &#x2212;Delta not identical in magnitude. In some embodiments, the multilevel pixels about P<b>1</b> are not at the same locations as the multilevel pixels about P<b>2</b>. In some embodiments the multilevel pixels include multilevel sample greyscale luminances of more than two levels for each PX.</p><p id="p-0054" num="0053">The subset of pixels of the display test patterns is chosen to be less than the total number of pixels of the display panel <b>220</b> because the scale factor does not deviate greatly pixel to pixel and generally exhibits localized uniformity but exhibits global non-uniformity over the entire display panel <b>220</b>. Although multilevel data for only those display panel pixels which display the subset of pixels (hereinafter &#x201c;multilevel pixels&#x201d;) of the display test patterns is extracted, the scale factors corresponding to P<b>1</b> and P<b>2</b> for all pixels may be estimated with use of an interpolation algorithm, such as bilinear interpolation for a rectilinear subset, or any other method appropriate for the particular arrangement of the subset of pixels. In some embodiments the measured luminances are interpolated first, and scale factors for all pixels are determined from those values, while in other embodiments the scale factors are determined first for some pixels and then interpolated for all pixels.</p><p id="p-0055" num="0054">To correct the panel within the set of all possible input DAC, P<b>1</b> and P<b>2</b> should be chosen to be far apart, and value P<b>1</b> should be chosen low enough to approximate properly panel non-uniformity for all possible DAC values. In other embodiments, regular test pixels include pixels at N levels, P<b>1</b>, . . . , PN, and the multilevel pixels include pixels at 2N levels, namely, at P<b>1</b>+&#x394;, P<b>1</b>&#x2212;&#x394;, . . . , PN+&#x394;, PN&#x2212;&#x394;.</p><p id="p-0056" num="0055">Once all of the display test patterns have been displayed and captured <b>308</b>, correction data is determined <b>310</b> from a processing by the optical correction processing <b>240</b> of all of the images taken by the camera <b>230</b>. The calibration image or images taken by the camera of the calibration pattern or patterns are processed. As described above, the calibration image is processed to establish the location of individual pixels on the display panel <b>220</b> and to correct for any geometrical distortion such as rotation, tilt, and skew. For calibration patterns with sparse activated pixels whose images in the calibration image do not overlap, the PSFs of various regions of the display panel <b>220</b> are directly observable from the images of the blurred activated pixels and may be substantially directly extracted from the calibration image. Generally, data forming a mapping of display panel <b>220</b> pixel locations to image pixel locations in images captured by the camera <b>230</b> are produced along with data which allow the extraction of an estimate of the PSF for every pixel of the display panel <b>220</b>.</p><p id="p-0057" num="0056">Once the calibration image is processed, the captured images of the display test patterns displayed by the display panel <b>220</b> are processed. Using the known location within the captured image of each pixel of the display panel <b>220</b>, and using the expected PSF in the area of the known location, a luminance of each pixel of the display panel <b>220</b> is extracted. In some embodiments, an acquisition kernel, acquisition filter, or integration window is used to extract a value of the luminance of each pixel of the display panel <b>220</b>. In some embodiments, a deblurring, sharpening, or deconvolution algorithm is used to extract a value of the luminance of each pixel of the display panel <b>220</b>. In some embodiments, this is done separately for each channel R, G, B, etc. In some embodiments the acquisition kernel is centered on the expected known location of each pixel being measured, and uses either an unweighted or weighted integral of a size and shape taking into account the PSF of the particular area of the pixel and the spacing in the captured image between the activated pixels of the test pattern. In some embodiments in which the defocusing and spacing of the pixels causes images of the pixels to partially overlap, the acquisition kernel is weighted so as to ignore the areas of overlap, or is otherwise configured and processed so that areas of overlap do not introduce errors in the determination of the luminance of each pixel. In some embodiments the acquisition kernel is generally rectangular and in other embodiments it is generally circular. Other acquisition kernals are possible, and in general they are sized, shaped, and weighted in accordance with the PSF and the spacing in the captured image of the activated pixels of the test pattern.</p><p id="p-0058" num="0057">The luminances L<b>1</b> and L<b>2</b> for every pixel of the display panel <b>220</b> when driven respectively at P<b>1</b> and P<b>2</b> are determined. These correspond to the luminance measurements of the pixels <b>110</b> of the display panel <b>220</b> which displayed the regular test pixels of the display test patterns. Further luminances L<b>1</b><i>a</i>, L<b>1</b><i>b</i>, L<b>2</b><i>a</i>, and L<b>2</b><i>b </i>for the sparse subset of the pixels of the display panel <b>220</b> when driven respectively by P<b>1</b>+&#x394;, P<b>1</b>&#x2212;&#x394;, P<b>2</b>+&#x394;, and P<b>2</b>&#x2212;&#x394; are also determined. These correspond to the luminance measurements of the pixels <b>110</b> display panel <b>220</b> which displayed the multilevel test pixels of the display test patterns. For every pixel of the display, scale factors S<b>1</b> and S<b>2</b> associated respectively with DAC signal P<b>1</b> and P<b>2</b> may be determined from measured luminances L<b>1</b><i>a</i>, L<b>1</b><i>b</i>, L<b>2</b><i>a</i>, and L<b>2</b><i>b </i>when available for that pixel, or are interpolated from scale factors S<b>1</b> and S<b>2</b> of other pixels of the display for which measured luminances L<b>1</b><i>a</i>, L<b>1</b><i>b</i>, L<b>2</b><i>a</i>, and L<b>2</b><i>b </i>are available or are calculated from L<b>1</b><i>a</i>, L<b>1</b><i>b</i>, L<b>2</b><i>a</i>, and L<b>2</b><i>b </i>values interpolated from L<b>1</b><i>a</i>, L<b>1</b><i>b</i>, L<b>2</b><i>a</i>, and L<b>2</b><i>b </i>of other pixels of the display for which those measurements exist. In embodiments where the multilevel pixels about P<b>1</b> are not at the same locations as the multilevel pixels about P<b>2</b>, spatial interpolation of the luminances L<b>1</b><i>a</i>, L<b>1</b><i>b</i>, L<b>2</b><i>a</i>, and L<b>2</b><i>b </i>at pixels which have the values can be used to determine a luminance L<b>1</b><i>a</i>, L<b>1</b><i>b</i>, L<b>2</b><i>a</i>, and L<b>2</b><i>b </i>for the pixel in question, in order to determine the scale factors.</p><p id="p-0059" num="0058">In one embodiment, S<b>1</b> is determined from measured luminances Ll, L<b>1</b><i>a</i>, and L<b>1</b><i>b </i>and &#x394; as:</p><p id="p-0060" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>S</mi>      <mo>&#x2062;</mo>      <mn>1</mn>     </mrow>     <mo>=</mo>     <mrow>      <mfrac>       <mn>1</mn>       <mn>2</mn>      </mfrac>      <mo>&#x2062;</mo>      <mrow>       <mo>(</mo>       <mrow>        <mfrac>         <mi>&#x394;</mi>         <mrow>          <mrow>           <mi>L</mi>           <mo>&#x2062;</mo>           <mn>1</mn>           <mo>&#x2062;</mo>           <mi>a</mi>          </mrow>          <mo>-</mo>          <mrow>           <mi>L</mi>           <mo>&#x2062;</mo>           <mn>1</mn>          </mrow>         </mrow>        </mfrac>        <mo>+</mo>        <mfrac>         <mi>&#x394;</mi>         <mrow>          <mrow>           <mi>L</mi>           <mo>&#x2062;</mo>           <mn>1</mn>          </mrow>          <mo>-</mo>          <mrow>           <mi>L</mi>           <mo>&#x2062;</mo>           <mn>1</mn>           <mo>&#x2062;</mo>           <mi>b</mi>          </mrow>         </mrow>        </mfrac>       </mrow>       <mo>)</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>1</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0061" num="0000">and S<b>2</b> is determined from measured luminances L<b>2</b>, L<b>2</b><i>a</i>, and L<b>2</b><i>b </i>and &#x394; as:</p><p id="p-0062" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mtable>  <mtr>   <mtd>    <mrow>     <mrow>      <mi>S</mi>      <mo>&#x2062;</mo>      <mn>2</mn>     </mrow>     <mo>=</mo>     <mrow>      <mfrac>       <mn>1</mn>       <mn>2</mn>      </mfrac>      <mo>&#x2062;</mo>      <mrow>       <mo>(</mo>       <mrow>        <mfrac>         <mi>&#x394;</mi>         <mrow>          <mrow>           <mi>L</mi>           <mo>&#x2062;</mo>           <mn>2</mn>           <mo>&#x2062;</mo>           <mi>a</mi>          </mrow>          <mo>-</mo>          <mrow>           <mi>L</mi>           <mo>&#x2062;</mo>           <mn>2</mn>          </mrow>         </mrow>        </mfrac>        <mo>+</mo>        <mfrac>         <mi>&#x394;</mi>         <mrow>          <mrow>           <mi>L</mi>           <mo>&#x2062;</mo>           <mn>2</mn>          </mrow>          <mo>-</mo>          <mrow>           <mi>L</mi>           <mo>&#x2062;</mo>           <mn>2</mn>           <mo>&#x2062;</mo>           <mi>b</mi>          </mrow>         </mrow>        </mfrac>       </mrow>       <mo>)</mo>      </mrow>     </mrow>    </mrow>   </mtd>   <mtd>    <mrow>     <mo>(</mo>     <mn>2</mn>     <mo>)</mo>    </mrow>   </mtd>  </mtr> </mtable></math></maths></p><p id="p-0063" num="0059">Analogous scale factors may be determined similarly for embodiments having regular test pixels which include pixels at N levels, P<b>1</b>, . . . , PN, and the multilevel test pixels include pixels at 2N levels, namely, at P<b>1</b>+&#x394;, P<b>1</b>&#x2212;&#x394;, . . . , PN+&#x394;, PN&#x2212;&#x394;. In some embodiments, processing is performed separately for each channel R, G, B, etc. Higher order approximations may be obtained for embodiments with more than two multilevel samples about each point PX, e.g. for four multilevel pixels P<b>1</b>+&#x394;, P<b>1</b>&#x2212;&#x394;, P<b>1</b>+&#x3b4;, P<b>1</b>&#x2212;&#x3b4;.</p><p id="p-0064" num="0060">As can be seen from equations (1) and (2), the scale factors S<b>1</b> and S<b>2</b> quantify the relationship, respectively at DAC points P<b>1</b> and P<b>2</b>, between a change in DAC signal value and the resulting change in luminance.</p><p id="p-0065" num="0061">The measured luminance L<b>1</b> at P<b>1</b> is compared to a known expected luminance to determine an actual deviation in luminance. The actual deviation in luminance and the scale factor S<b>1</b> are used to determine a corrected DAC signal CP<b>1</b>, i.e. the corrected signal which causes the pixel to produce the desired actual luminance for greyscale luminance value P<b>1</b>. Similarly a corrected DAC signal CP<b>2</b> is calculated for correcting greyscale luminance value P<b>2</b>. From these two points (P<b>1</b>, CP<b>1</b>) and (P<b>2</b>, CP<b>2</b>) a linear relationship of the form CPn=B*Pn+C is determined and hence for any desired greyscale luminance value Pn, a corrected DAC value CPn may be calculated.</p><p id="p-0066" num="0062">The correction data for each pixel therefore includes the slope B and offset C, as determined above using L<b>1</b>, L<b>2</b>, S<b>1</b>, and S<b>2</b>, to determine the corrected DAC value CPn from any input greyscale luminance value Pn.</p><p id="p-0067" num="0063">The correction data, once determined <b>310</b> is transferred <b>312</b> to the display <b>250</b> via the controller <b>202</b> and stored in memory <b>106</b>.</p><p id="p-0068" num="0064">During operation of the display <b>250</b>, correction data stored in memory <b>106</b> is used by the controller <b>202</b> or in combination with a separate compensation block (not shown) to correct image data input to the display <b>250</b> for display on the display panel <b>220</b>. In some embodiments, the slope B and offset C are calculated for each pixel of the display panel <b>220</b>, using for example interpolation, prior to being stored in the display <b>250</b>, to reduce processing required of the display <b>250</b> while correcting DAC signals. For embodiments having regular test pixels which include pixels at N levels (where N&#x3e;2), and multilevel test pixels at 2N levels, the correction data includes higher order coefficients of (N&#x2212;1)th order polynomials directly analogous to the linear relationship described above. In some embodiments, the correction data include slope B and offset C (or analogous higher order coefficients) for each channel, R, G, B, etc.</p><p id="p-0069" num="0065">When the pixels <b>110</b> of the display panel <b>220</b> are driven by the corrected signals, the image displayed by the display panel <b>220</b> exhibits greatly reduced or negligible non-uniformity.</p><p id="p-0070" num="0066">As described herein above, the calibration patterns along with the display test patterns should include the calibration pixels, the regular test pixels, and the multilevel pixels, while ensuring that in each pattern the pixels are spaced far enough apart so images of these activated pixels in the captured images have at least some portion which does not overlap with blurred images of other pixels. In some embodiment these pixels are displayed separately for each of the channels R, G, B, etc. The ordering and grouping of the pixels in the display test patterns does not matter. In some embodiments, each display test pattern only has pixels of the same channel, in other embodiments only of the same level (e.g. P<b>1</b> or P<b>2</b>), while in other embodiments each display test pattern includes pixels of more than one or of all channels, and in other embodiments each test pattern includes pixels of both levels. As described above each pixel of the display panel <b>220</b> should be driven at the two levels P<b>1</b>, P<b>2</b> (or more in the case of P<b>1</b>, . . . PN) and a subset of pixels should be driven as multilevel pixels to provide data for the scale factors S<b>1</b>, S<b>2</b> (or possibly S<b>1</b>, . . . , SN). Although the ordering and grouping of the pixels in the test patterns does not matter, ideally the spacing is minimized to minimize the total number of display test patterns displayed. This reduces the capture time of the process.</p><p id="p-0071" num="0067">In some embodiments, the pixels of the display test patterns displayed and captured <b>308</b> are grouped into specific types of display test patterns. <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a specific method <b>400</b> of displaying and capturing <b>308</b> display test patterns in which the regular test pixels and multilevel pixels have been grouped in specific ways. In some embodiment, all of the following is performed separately for each channel of the display R, G, B, etc.</p><p id="p-0072" num="0068">At <b>402</b> a first set of sparse flat test patterns are displayed, each pattern of the set such that all of the activated pixels of the pattern are at level P<b>1</b>. The number of display test patterns in the first set of sparse flat patterns depends upon the spacing of pixels in the array which avoids or produces the expected amount of overlap. For example, if each flat test pattern has activated pixels in a square rectilinear array or rectangular lattice spaced apart vertically and horizontally by three inactive pixels, then the first set of sparse flat patterns would include a total of <b>16</b> test patterns, each shifted vertically and or horizontally with respect to each other. The first set of sparse test patterns, ensures the regular test pixel at level P<b>1</b> is measured for every pixel of the display panel <b>220</b>.</p><p id="p-0073" num="0069">At <b>404</b> a first set of one or more multilevel patterns is displayed, each pattern of the set such that all of the activated pixels of the pattern are at level P<b>1</b> plus or minus a small &#x394;. The desired number of pixels (equivalently the density of pixels) for the subset constituting the multilevel pixels about P<b>1</b> will vary depending upon the exhibited amount of nonuniformity in the scale factor for the type of particular display panel <b>220</b> being measured. The number of display test patterns in the first set of one or more multilevel patterns depends upon the spacing of pixels in the array which avoids or produces the expected amount of overlap, and the desired number of pixels (or the desired pixel density) in the subset constituting the multilevel pixels about P<b>1</b>. In embodiments where the scale factor exhibited across the display panel <b>220</b> is generally uniform, only one multilevel pattern for P<b>1</b> may be required. The first set of one or more multilevel patterns (P<b>1</b>&#xb1;&#x394;), ensures all desired multilevel pixels for the display panel <b>220</b> about level P<b>1</b> are measured.</p><p id="p-0074" num="0070">At <b>406</b> a second set of sparse flat test patterns are displayed, each pattern of the set such that all of the activated pixels of the pattern are at level P<b>2</b>. The number of display test patterns in the second set of sparse flat patterns depends upon the spacing of pixels in the array which avoids or produces the expected amount of overlap. For example, if each flat test pattern has activated pixels in a square rectilinear array or rectangular lattice spaced vertically and horizontally by three pixels, then the second set of sparse flat patterns would include a total of <b>16</b> test patterns, each shifted vertically and or horizontally with respect to each other. The second set of sparse test patterns, ensures the regular test pixel at level P<b>2</b> is measured for every pixel of the display panel <b>220</b>.</p><p id="p-0075" num="0071">At <b>408</b> a second set of one or more multilevel patterns is displayed, each pattern of the set such that all of the activated pixels of the pattern are at level P<b>2</b> plus or minus a small &#x394;. The number of display test patterns in the second set of one or more multilevel patterns depends upon the spacing of pixels in the array which avoids or produces the expected amount of overlap, and the desired number of pixels (or desired pixel density) in the subset constituting the multilevel pixels about P<b>2</b>. Generally this number of pixels (or pixel density) will be the same as that for the number of pixels in the subset constituting the multilevel pixels about P<b>1</b>, and for the same reasons. In embodiments where the scale factor exhibited across the display panel <b>220</b> is generally uniform, only one multilevel pattern for P<b>2</b> may be required. The second set of one or more multilevel patterns (P<b>2</b>&#xb1;&#x394;), ensures all desired multilevel pixels for the display panel <b>220</b> about level P<b>2</b> are measured.</p><p id="p-0076" num="0072">While particular implementations and applications of the present disclosure have been illustrated and described, it is to be understood that the present disclosure is not limited to the precise construction and compositions disclosed herein and that various modifications, changes, and variations can be apparent from the foregoing descriptions without departing from the spirit and scope of an invention as defined in the appended claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230007236A1-20230105-M00001.NB"><img id="EMI-M00001" he="5.67mm" wi="76.20mm" file="US20230007236A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230007236A1-20230105-M00002.NB"><img id="EMI-M00002" he="5.67mm" wi="76.20mm" file="US20230007236A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><claims id="claims"><claim id="CLM-01-28" num="01-28"><claim-text><b>1</b>-<b>28</b>. (canceled)</claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. An optical correction method for correcting for non-uniformity of an emissive display panel having pixels, each pixel having a light-emitting device, the method comprising:<claim-text>arranging a camera in front of the display panel;</claim-text><claim-text>activating a plurality of pixels of the display panel to display:<claim-text>a first greyscale luminance value of a relatively low greyscale luminance value;</claim-text><claim-text>a second greyscale luminance value of a relatively high greyscale luminance value which is spaced apart from the first greyscale luminance value by a relatively large greyscale luminance value difference;</claim-text><claim-text>a third greyscale luminance value greater or less than the first greyscale luminance value by a first relatively small greyscale luminance value difference, the relatively large greyscale luminance value difference being greater than said first relatively small greyscale luminance value difference; and</claim-text><claim-text>a fourth greyscale luminance value greater or less than the second greyscale luminance value by a second relatively small greyscale luminance value difference, the relatively large greyscale luminance value difference being greater than said second relatively small greyscale luminance value difference,</claim-text></claim-text><claim-text>wherein each activated pixel displays at least one of the first, second, third, and fourth greyscale luminance values;</claim-text><claim-text>measuring a luminance of each activated pixel with the camera while displaying the first, second, third, and fourth greyscale luminance values, to generate luminance measurement data including respectively first, second, third, and fourth luminance measurement data; and</claim-text><claim-text>determining correction data from said first, second, third, and fourth luminance measurement data for correcting non-uniformity of images displayed in the display panel.</claim-text></claim-text></claim><claim id="CLM-00030" num="00030"><claim-text><b>30</b>. The optical correction method of <claim-ref idref="CLM-00029">claim 29</claim-ref> wherein said determining correction data comprises comparing the first and third luminance measurement data and comparing the second and fourth luminance measurement data.</claim-text></claim><claim id="CLM-00031" num="00031"><claim-text><b>31</b>. The optical correction method of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein correction data is determined for each pixel of the display panel with use of the first and second luminance measurement data of activated pixels local to the pixel, and with use of the third and fourth luminance measurement data of activated pixels throughout the display panel.</claim-text></claim><claim id="CLM-00032" num="00032"><claim-text><b>32</b>. The optical correction method of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the relatively low greyscale luminance value is substantially 10 percent of a maximum greyscale luminance value, and the relatively high greyscale luminance value is substantially 80 percent of the maximum greyscale luminance value.</claim-text></claim><claim id="CLM-00033" num="00033"><claim-text><b>33</b>. The optical correction method of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the relatively small greyscale luminance value is one of substantially one percent of a maximum greyscale luminance value and the smallest incremental digital value of possible greyscale luminance values.</claim-text></claim><claim id="CLM-00034" num="00034"><claim-text><b>34</b>. The optical correction method of <claim-ref idref="CLM-00029">claim 29</claim-ref>, further comprising correcting image data with use of the correction data prior to driving the pixels to display an image corresponding to the image data.</claim-text></claim><claim id="CLM-00035" num="00035"><claim-text><b>35</b>. The optical correction method of <claim-ref idref="CLM-00029">claim 29</claim-ref> wherein activating the plurality of pixels comprises displaying one or more sparse sets of activated pixels.</claim-text></claim><claim id="CLM-00036" num="00036"><claim-text><b>36</b>. The optical correction method of <claim-ref idref="CLM-00035">claim 35</claim-ref> wherein the one or more sparse sets of activated pixels are displayed one set at a time.</claim-text></claim><claim id="CLM-00037" num="00037"><claim-text><b>37</b>. The optical correction method of <claim-ref idref="CLM-00035">claim 35</claim-ref>, wherein each of the first, second, third, and fourth greyscale luminance values are different from a greyscale luminance of a flat background greyscale displayed between said activated pixels of each sparse set.</claim-text></claim><claim id="CLM-00038" num="00038"><claim-text><b>38</b>. The optical correction method of <claim-ref idref="CLM-00035">claim 35</claim-ref>, wherein the activated pixels comprise calibration pixels, the method further comprising:<claim-text>determining locations of the calibration pixels as they appear in images captured by the camera.</claim-text></claim-text></claim><claim id="CLM-00039" num="00039"><claim-text><b>39</b>. The optical correction method of <claim-ref idref="CLM-00035">claim 35</claim-ref>, wherein displaying said one or more sparse sets of activated pixels comprises displaying one or more test patterns and wherein said measuring the luminance of each activated pixel comprises capturing images of the display with the camera, the method further comprising:<claim-text>defocusing the camera such that the focal point of the camera lies outside of a plane passing through the light-emitting devices of the display panel, the defocusing such that individual pixels of the display panel are blurred in images of the display panel captured by the camera;</claim-text><claim-text>wherein locations of said activated pixels are spaced apart in each sparse set such that in each captured image, at least one portion of each blurred image of each activated pixel does not overlap with a blurred image of another activated pixel, wherein a resolution of the camera is less than twice a resolution of the display panel, and wherein the amount of blurring in images of the display panel captured by the camera is sufficient to avoid aliasing in the captured images of the display panel, and wherein each of the luminance measurements of each of the activated pixels is performed with use of an acquisition kernel determined from a spacing of the activated pixels in each sparse set.</claim-text></claim-text></claim><claim id="CLM-00040" num="00040"><claim-text><b>40</b>. An optical correction system for correcting non-uniformity of an emissive display having pixels, each pixel having a light-emitting device, the system comprising:<claim-text>a camera arranged in front of the display for capturing images of the display while a plurality of pixels of the display is activated to display:<claim-text>a first greyscale luminance value of a relatively low greyscale luminance value, and</claim-text><claim-text>a second greyscale luminance value of a relatively high greyscale luminance value which is spaced apart from the first greyscale luminance value by a relatively large greyscale luminance value difference;</claim-text><claim-text>a third greyscale luminance value greater or less than the first greyscale luminance value by a first relatively small greyscale luminance value difference, the relatively large greyscale value difference being greater than said first relatively small greyscale luminance value difference; and</claim-text><claim-text>a fourth greyscale luminance value greater or less than the second greyscale luminance value by a second relatively small greyscale luminance value difference, the relatively large greyscale luminance value difference being greater than said second relatively small greyscale luminance value difference;</claim-text></claim-text><claim-text>wherein each activated pixel displays at least one of the first, second, third, and fourth greyscale luminance values; and</claim-text><claim-text>optical correction processing coupled to the camera and for:<claim-text>receiving from the camera captured images of each activated pixel while displaying the first, second, third, and the fourth greyscale luminance values, to generate luminance measurement data including respectively first, second, third, and fourth luminance measurement data;</claim-text><claim-text>determining correction data from said first, second, third, and fourth luminance measurement data for correcting non-uniformity of images displayed in the display; and</claim-text><claim-text>transmitting the correction data to the display for storage in a memory of the display.</claim-text></claim-text></claim-text></claim><claim id="CLM-00041" num="00041"><claim-text><b>41</b>. The optical correction system of <claim-ref idref="CLM-00040">claim 40</claim-ref>, wherein said determining correction data comprises comparing the first and third luminance measurement data and comparing the second and fourth luminance measurement data.</claim-text></claim><claim id="CLM-00042" num="00042"><claim-text><b>42</b>. The optical correction system of <claim-ref idref="CLM-00040">claim 40</claim-ref>, wherein the optical correction processing is further for determining correction data for each pixel of the display with use of the first and second luminance measurement data of activated pixels local to the pixel, and with use of the third and fourth luminance measurement data of activated pixels throughout the display.</claim-text></claim><claim id="CLM-00043" num="00043"><claim-text><b>43</b>. The optical correction system of <claim-ref idref="CLM-00040">claim 40</claim-ref>, wherein the relatively low greyscale luminance value is substantially 10 percent of a maximum greyscale luminance value, and the relatively high greyscale luminance value is substantially 80 percent of the maximum greyscale luminance value.</claim-text></claim><claim id="CLM-00044" num="00044"><claim-text><b>44</b>. The optical correction system of <claim-ref idref="CLM-00040">claim 40</claim-ref>, wherein the relatively small greyscale luminance value is one of substantially one percent of a maximum greyscale luminance value and the smallest incremental digital value of possible greyscale luminance values.</claim-text></claim><claim id="CLM-00045" num="00045"><claim-text><b>45</b>. The optical correction system of <claim-ref idref="CLM-00040">claim 40</claim-ref>, further comprising:<claim-text>a controller of the emissive display coupled to said optical correction processing, said controller for:<claim-text>receiving image data for display by the display;</claim-text><claim-text>receiving from the optical correction processing the correction data; and</claim-text><claim-text>correcting the image data with use of the correction data prior to driving the pixels to display an image corresponding to the image data.</claim-text></claim-text></claim-text></claim><claim id="CLM-00046" num="00046"><claim-text><b>46</b>. The optical correction system of <claim-ref idref="CLM-00040">claim 40</claim-ref> wherein the plurality of pixels of the display are activated to display one or more sparse sets of activated pixels.</claim-text></claim><claim id="CLM-00047" num="00047"><claim-text><b>47</b>. The optical correction system of <claim-ref idref="CLM-00046">claim 46</claim-ref> wherein the one or more sparse sets of activated pixels are displayed one set at a time.</claim-text></claim><claim id="CLM-00048" num="00048"><claim-text><b>48</b>. The optical correction system of <claim-ref idref="CLM-00046">claim 46</claim-ref>, wherein each of the first, second, third, and fourth greyscale luminance values are different from a greyscale luminance of a flat background greyscale displayed between said activated pixels of each sparse set.</claim-text></claim><claim id="CLM-00049" num="00049"><claim-text><b>49</b>. The optical correction system of <claim-ref idref="CLM-00047">claim 47</claim-ref>, wherein said activated pixels comprise calibration pixels, and wherein the optical correction processing is further for:<claim-text>determining locations of the calibration pixels as they appear in the images captured by the camera.</claim-text></claim-text></claim><claim id="CLM-00050" num="00050"><claim-text><b>50</b>. The optical correction system of <claim-ref idref="CLM-00046">claim 46</claim-ref>, wherein displaying said one or more sparse sets of activated pixels comprises displaying one or more test patterns, wherein the camera is defocused such that the focal point of the camera lies outside of a plane passing through the light-emitting devices of the display and such that individual pixels of the display are blurred in images of the display captured by the camera, wherein locations of said activated pixels are spaced apart in each sparse set such that in each captured image, at least one portion of each blurred image of each activated pixel does not overlap with a blurred image of another activated pixel, wherein a resolution of the camera is less than twice a resolution of the display, and wherein the amount of blurring in images of the display captured by the camera is sufficient to avoid aliasing in the captured images of the display, and wherein generating measurement data associated with each of the activated pixels is performed by the optical correction processing with use of an acquisition kernel determined from a spacing of the activated pixels in each sparse set.</claim-text></claim></claims></us-patent-application>
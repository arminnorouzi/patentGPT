<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007038A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007038</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17902067</doc-number><date>20220902</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20220101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>9</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20190101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20180101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>455</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>63</main-group><subgroup>1433</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>63</main-group><subgroup>1441</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>45558</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>7</main-group><subgroup>005</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>2009</main-group><subgroup>45587</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS FOR AUTOMATED QUANTITATIVE RISK AND THREAT CALCULATION AND REMEDIATION</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>16796429</doc-number><date>20200220</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11463468</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17902067</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Verizon Patent and Licensing Inc.</orgname><address><city>Basking Ridge</city><state>NJ</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Grounds</last-name><first-name>Gavin Anthony</first-name><address><city>Austin</city><state>TX</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Grantges</last-name><first-name>David R.</first-name><address><city>Clearwater</city><state>FL</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system described herein may provide a technique for identifying and remediating potential threat vectors in a system, such as containers or applications in a virtual or cloud computing environment. Attributes of potential threat vectors may be identified, and the potential threat vectors may be scored based on the attributes. Values or scores of individual attributes may be determined through machine learning or other suitable techniques. Scores exceeding a threshold may indicate that a remedial measure should be performed. A remedial measure may be identified using machine learning or other suitable techniques. After the remedial measure is performed, the threat vector may be scored again, and a machine learning model may be refined based on whether the remedial measure was successful.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="105.07mm" wi="158.75mm" file="US20230007038A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="233.00mm" wi="169.93mm" orientation="landscape" file="US20230007038A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="95.67mm" wi="107.53mm" file="US20230007038A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="234.87mm" wi="158.41mm" orientation="landscape" file="US20230007038A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="234.87mm" wi="158.41mm" orientation="landscape" file="US20230007038A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="198.80mm" wi="107.61mm" orientation="landscape" file="US20230007038A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="218.36mm" wi="137.41mm" orientation="landscape" file="US20230007038A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="227.08mm" wi="155.11mm" file="US20230007038A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="182.20mm" wi="113.96mm" file="US20230007038A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="170.10mm" wi="157.14mm" file="US20230007038A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION(S)</heading><p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 16/796,429, filed Feb. 20, 2020, the disclosure of which is hereby expressly incorporated herein by reference in its entirety.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Entities, such as web-based service providers, cloud infrastructure providers or users, etc., may operate and/or configure systems or services based on the potential presence of risk factors (e.g., system failures or crashes, information theft or other compromise of sensitive information, attacks by malicious actors, denial of service (&#x201c;DOS&#x201d;) events, etc.). The risk factors may include vulnerabilities or threats that may jeopardize the Quality of Service (&#x201c;QoS&#x201d;) associated with the systems, potentially disrupting user experience and/or increasing the cost of providing such systems or services.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0003" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0004" num="0003"><figref idref="DRAWINGS">FIGS. <b>1</b>A and <b>1</b>B</figref> illustrate an example overview of one or more embodiments described herein, in which one or more risk scores may be generated for one or more threat vectors (e.g., in a virtualized and/or cloud computing environment);</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> illustrates an example remediation of potential threat in accordance with some embodiments, which may include moving a virtualized container, which has been identified as having a high risk score (e.g., greater than a threshold), from a first node and/or cluster to a different node and/or cluster:</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates an example remediation of potential threat in accordance with some embodiments, which may include moving a first virtualized container, which is configured on a same node as a second virtualized container that has been identified as having a high risk score, from the same node as the second container to a different node;</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b>C</figref> illustrates an example remediation of potential threat in accordance with some embodiments, which may include disabling or uninstalling a virtualized container, which has been identified as having a high risk score;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b>D</figref> illustrates an example remediation of potential threat in accordance with some embodiments, which may include quarantining a virtualized container, which has been identified as having a high risk score;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example environment in which one or more embodiments, described herein, may be implemented;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example process for identifying a potential threat vector with a risk score exceeding a threshold and using machine learning techniques to remediate the identified threat vector; and</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates example functional components of one or more devices, in accordance with one or more embodiments described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0004" level="1">DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0012" num="0011">The following detailed description refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements.</p><p id="p-0013" num="0012">Embodiments described herein provide for the identification of elements that introduce undue risk within a system, and the remediation of issues (or potential issues) caused by such identified elements. For example, elements of a system may have attributes that, through machine learning and/or other suitable techniques, are attributable to values based on which a risk score can be generated for the elements. For example, an application running in a cloud system may have attributes such as &#x201c;mission critical,&#x201d; &#x201c;web-enabled,&#x201d; &#x201c;confidential,&#x201d; etc. Embodiments described herein may generate a risk score for the application based on these attributes, and may take remedial action if the risk score exceeds a threshold.</p><p id="p-0014" num="0013">For instance, as shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, threat remediation system <b>101</b> may communicate with one or more containers (i.e., Container_<b>1</b>, Container_<b>2</b>, Container_<b>3</b>, and Container_<b>4</b>, in this example), which may be or include virtual images, installed or instantiated on one or more nodes (i.e., Node_<b>1</b> and Node_<b>2</b>, in this example).</p><p id="p-0015" num="0014">A &#x201c;node,&#x201d; as discussed herein, may refer to a distributed system, a &#x201c;cloud&#x201d; device, and/or some other designation of a set of hardware or virtualized resources (e.g., processor resources, memory resources, storage resources, and/or other resources). A particular node may be implemented by multiple hardware devices (e.g., server devices and/or some other type of device), which may be co-located and/or may be located in geographically distinct locations. Threat remediation system <b>101</b> may include, and/or may be communicatively coupled to, an orchestration system that provisions virtual machines and/or other virtual functions on a node. For example, threat remediation system <b>101</b> and/or the orchestration system and one or more nodes may implement an application programming interface (&#x201c;API&#x201d;) that allows for threat remediation system <b>101</b> and/or the orchestration system to provision resources of the nodes for virtual machines and/or virtual functions). One such API to allow for the provisioning of virtual functionalities on a node is the Kubernetes API.</p><p id="p-0016" num="0015">Nodes may be arranged into clusters. For example, in this example, Node_<b>1</b> and Node_<b>2</b> are part of the same cluster, Cluster_<b>1</b>. A cluster may include one node as a &#x201c;master&#x201d; or addressable node, which may handle or route intra-cluster communications (e.g., communications between nodes of the same cluster) and/or inter-cluster communications (e.g., communications between nodes of the cluster and devices or systems external to the cluster).</p><p id="p-0017" num="0016">In some embodiments, a given container may correspond to some or all of the functionality of a Virtualized Network Function (&#x201c;VNF&#x201d;) associated with a wireless telecommunications network. For example, a container may correspond to a User Plane Function (&#x201c;UPF&#x201d;), Packet Data Network (&#x201c;PDN&#x201d;) Gateway (&#x201c;PGW&#x201d;), Policy Control Function (&#x201c;PCF&#x201d;), Home Subscriber Server (&#x201c;HSS&#x201d;), Unified Data Management function (&#x201c;UDM&#x201d;), Serving Gateway (&#x201c;SGW&#x201d;), Authentication Server Function (&#x201c;AUSF&#x201d;), Application Function (&#x201c;AF&#x201d;), Access and Mobility Management Function (&#x201c;AMF&#x201d;), Session Management Function (&#x201c;SMF&#x201d;), Mobility and Management Entity (&#x201c;MME&#x201d;), Distributed Unit (&#x201c;DU&#x201d;), Control Unit (&#x201c;CU&#x201d;), and/or some other device or system of the wireless telecommunications network. Thus, examples described herein, which may involve the instantiating, moving, disabling, etc. of containers, may refer to the modification of the configuration of the wireless telecommunications network, at least inasmuch as VNFs of the wireless telecommunications network may be moved from one node and/or cluster to another node and/or cluster, thereby improving the operation of the wireless telecommunications network.</p><p id="p-0018" num="0017">As shown, threat remediation system <b>101</b> may identify (at <b>102</b>) attributes of potential threat vectors to the system shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>. For example, threat remediation system <b>101</b> may receive attributes of the depicted containers, nodes, and/or cluster. Each container, node, cluster, and/or other aspect of the system may be a discrete threat vector that may be evaluated to determine a risk or threat level of the threat vector, an annualized loss expectancy (&#x201c;ALE&#x201d;) associated with the threat vector and/or the overall system, etc.</p><p id="p-0019" num="0018">Threat remediation system <b>101</b> may receive these attributes from the containers, nodes, or cluster (e.g., via direct communication), and/or may receive these attributes from some other source (e.g., a device or system that communicates with the containers, nodes, and/or cluster). The attributes may describe aspects of the containers, nodes, and/or cluster, and may have been generated or determined using machine learning and/or other automated techniques. Additionally, or alternatively, the attributes may include manually defined or configured attributes.</p><p id="p-0020" num="0019">As an example of the received attributes, threat remediation system <b>101</b> may receive attributes <b>103</b> associated with Container_<b>1</b>, and attributes <b>111</b> associated with Container_<b>2</b>. As shown, attributes <b>103</b> and Ill may include fields <b>105</b>, such as &#x201c;Mission Critical,&#x201d; &#x201c;Web-based.&#x201d; &#x201c;Confidential,&#x201d; and &#x201c;Last Scanned.&#x201d; As mentioned above, these (and/or other) attributes may be assigned to or correlated with Container_<b>1</b> and Container_<b>2</b> based on machine learning and/or other automated techniques. For example, a system configured to analyze and classify containers as having certain attributes, and/or as having particular values <b>107</b> associated with attributes, may have analyzed Container_<b>1</b> to determine that Container_<b>1</b> is a mission critical container (as denoted by the &#x201c;Yes&#x201d; value <b>107</b> for the &#x201c;Mission Critical&#x201d; field <b>105</b>), is accessible via a network (as denoted by the &#x201c;Yes&#x201d; value <b>107</b> for the &#x201c;Web-based&#x201d; field <b>105</b>) such as the Internet), includes material that is confidential (as denoted by the Yes&#x201d; value <b>107</b> for the &#x201c;Confidential&#x201d; field <b>105</b>), and was last scanned for viruses or malware over 30 days ago (as denoted by the &#x201c;30+ days&#x201d; value <b>107</b> for the &#x201c;Last Scanned&#x201d; field <b>105</b>).</p><p id="p-0021" num="0020">Values <b>107</b> may also be associated with scores <b>109</b>, which may be a normalized representation (e.g., on the same scale, such as 0-10, 0-100, and/or some other suitable scale), of values <b>107</b>. For example, scores <b>109</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref> may be on a scale of 0-10, with a higher score generally corresponding to a higher risk or threat level, and a lower score generally corresponding to a lower risk or threat level. As shown, for instance, the &#x201c;Yes&#x201d; value <b>107</b> for the &#x201c;Mission Critical&#x201d; field <b>105</b> for Container_<b>1</b> may correspond to a score <b>109</b> of &#x201c;10,&#x201d; while the &#x201c;No&#x201d; value <b>113</b> for the &#x201c;Mission Critical&#x201d; field <b>105</b> for Container_<b>2</b> may correspond to a score <b>115</b> of &#x201c;0.&#x201d; Thus, for Container_<b>1</b>, an overall risk score may be increased based on the score of 10 associated with the &#x201c;Mission Critical&#x201d; field <b>105</b>, while an overall risk score for Container_<b>2</b> may not be increased based on the &#x201c;Mission Critical&#x201d; field <b>105</b> (i.e., based on the corresponding score of 0).</p><p id="p-0022" num="0021">Further, relationships between potential threat vectors (and/or other attributes of the system) may be evaluated to determine a risk score associated with a given potential threat vector. For example, Container_<b>1</b> may have been indicated (e.g., determined based on machine learning and/or other suitable techniques) as having an anti-affinity with Container_<b>2</b>. An &#x201c;anti-affinity&#x201d; may indicate a constraint that two containers should not be installed on the same node, in the same cluster, and/or some other similar constraint. In some embodiments, threat remediation system <b>101</b> may determine or modify an overall risk score for Container_<b>1</b> based on the anti-affinity <b>117</b> with Container_<b>2</b>, and based on the presence of Container_<b>1</b> and Container_<b>2</b> on the same node (i.e., Node_<b>1</b>). In some embodiments, threat remediation system <b>101</b> may further determine or modify the risk score for Container_<b>2</b> based on the anti-affinity <b>117</b> associated with Container_<b>1</b>. Additionally. or alternatively, threat remediation system <b>101</b> may determine or modify the risk score for Container_<b>1</b> based on the anti-affinity <b>119</b> associated with Container_<b>2</b> (i.e., indicating that Container_<b>2</b> has an anti-affinity with Container_<b>1</b>), and/or may determine or modify the risk score for Container_<b>2</b> based on the anti-affinity <b>119</b> associated with Container_<b>2</b>. While not shown here, similar concepts may apply for affinities between different attributes or potential threat vectors in a system.</p><p id="p-0023" num="0022">While examples are discussed herein the context of Container_<b>1</b> and Container_<b>2</b> being evaluated, similar concepts may apply to the other containers shown in <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, as well as to nodes, clusters, applications, hardware configurations, or other elements of a system.</p><p id="p-0024" num="0023">In some embodiments, different categories or groups of attributes may be associated with different weights, based on which the overall risk score may be determined. For example, as shown in <figref idref="DRAWINGS">FIG. <b>1</b>B</figref>, data structure <b>121</b> may conceptually reflect some of the scores for the attributes of Container_<b>1</b>, adjusted by weights for groups with which the attributes are associated. For instance, row <b>123</b> may indicate the group of a particular attribute, row <b>125</b> may indicate the weight associated with the group, and row <b>127</b> may indicate the weighted score for a given attribute. The groups may have been determined or generated based on machine learning and/or other suitable techniques, such as by a device or system that analyzes attributes and categorizes the attributes into suitable groups. Further, the weights may be adjusted or refined via an ongoing machine learning process, and/or may be adjusted or defined manually.</p><p id="p-0025" num="0024">As illustrated, the &#x201c;Mission Critical&#x201d; and &#x201c;Web-based&#x201d; attributes may be associated with Group_<b>1</b>, and the &#x201c;Confidential&#x201d; and &#x201c;Last Scanned&#x201d; attributes may be associated with Group_<b>2</b>. As further shown, the weight associated with Group_<b>1</b> may be &#x201c;1,&#x201d; while the weight associated with Group_<b>2</b> may be &#x201c;0.33.&#x201d; Thus, the weighted scores <b>127</b> associated with the above-mentioned factors in this example are 10, 10, 3.3, and 3.3.</p><p id="p-0026" num="0025">Returning to <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, based on the attributes associated with the potential threat vectors (e.g., based on the scores <b>109</b>, <b>115</b>, and/or weighted scores, such as weighted scores <b>127</b>), threat remediation system <b>101</b> may generate (at <b>104</b>) one or more risk scores associated with the potential threat vectors. For example, threat remediation system <b>101</b> may generate an overall risk score of 36.6 for Container_<b>1</b>, which may be based on weighted scores <b>127</b> and anti-affinity <b>117</b> (e.g., a score of &#x201c;10&#x201d; indicating the anti-affinity with Container_<b>2</b>). In some embodiments, the overall risk score may be calculated using other methodologies, such as using an average, median, minimum, maximum, etc.</p><p id="p-0027" num="0026">In some embodiments, threat remediation system <b>101</b> may automatically set the overall risk score to a certain value based on certain factors or attributes. For example, in some embodiments, the overall risk score for Container_<b>1</b> and/or Container_<b>2</b> may be automatically set to a maximum level, regardless of other factors, based on the anti-affinity between Container_<b>1</b> and Container_<b>2</b>.</p><p id="p-0028" num="0027">In the example of <figref idref="DRAWINGS">FIG. <b>1</b>A</figref>, assume that threat remediation system <b>101</b> has determined (at <b>104</b>) that the overall risk score associated with Container_<b>1</b> exceeds a threshold risk score. As shown in <figref idref="DRAWINGS">FIGS. <b>2</b>A-<b>2</b>D</figref>, threat remediation system <b>101</b> may take various remedial measures based on the risk score exceeding the threshold value. For example, as shown in <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, threat remediation system <b>101</b> may cause Container_<b>1</b> (i.e., the container identified as having the excessive risk score) to be moved from Node_<b>1</b> of Cluster_<b>1</b> to another node, such as Node_<b>3</b> of Cluster_<b>3</b>. For example, threat remediation system <b>101</b> may communicate with an orchestration system to cause resources of Node_<b>3</b> to be provisioned to host Container_<b>1</b>, may obtain state information and/or other portability information from Node_<b>1</b> and/or Container_<b>1</b> while running on Node_<b>1</b>, and instantiate Container_<b>1</b> on Node_<b>3</b> (e.g., using the state information) in order to allow Container_<b>1</b> to continue to operate.</p><p id="p-0029" num="0028">After moving Container_<b>1</b> to Node_<b>3</b>, threat remediation system <b>101</b> may identify (at <b>106</b>) attributes of potential threat vectors of the system, such as attributes associated with the illustrated containers, nodes, clusters, etc., including relationships between the threat vectors (e.g., affinities or anti-affinities). Threat remediation system <b>101</b> may generate (or regenerate) the risk scores (e.g., weighted risk scores) associated with the potential threat vectors, and may determine (at <b>108</b>) whether the risk scores associated with the various potential threat vectors are above the threshold.</p><p id="p-0030" num="0029">If the risk scores are below the threshold, then the moving of Container_<b>1</b> to Node_<b>3</b> may be considered a successful move, and threat remediation system <b>101</b> may maintain information regarding circumstances of the move (e.g., attributes of one or more the potential threat vectors before and/or after the move). This information may be used to refine a predictive machine learning model that may be used in future situations with similar circumstances (e.g., similar attributes). If, on the other hand, the risk scores are above the threshold, then the moving of Container_<b>1</b> to Node_<b>3</b> may be considered an unsuccessful move, and threat remediation system <b>101</b> may maintain information regarding circumstances of the move, to prevent similar moves being made under similar circumstances.</p><p id="p-0031" num="0030">In some embodiments, threat remediation system <b>101</b> may perform different remedial actions, and/or may simulate the performance of multiple remedial actions, and may select one particular remedial action based on suitable criteria (e.g., overall system performance, reduction of individual or overall risk scores, reduction of resources used, etc.). For example, <figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates another remedial action that may be taken (or simulated) by threat remediation system <b>101</b>. As shown in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, threat remediation system <b>101</b> may move (or cause to be moved) Container_<b>2</b> to Node_<b>3</b> (e.g., a different node than the node on which Container_<b>1</b> is installed). Threat remediation system <b>101</b> may make (or simulate) this move based on a predictive model (e.g., as discussed above), which indicates that moving a container having attributes similar to those of Container_<b>2</b> in similar circumstances (e.g., when installed on the same node as a container having an anti-affinity as the container, and/or other attributes of containers, nodes, clusters, etc. based on historical information) resulted in a satisfactory result. For example, the satisfactory result may indicate that the resulting move yields risk scores for the system, or components of the system, that are below a threshold.</p><p id="p-0032" num="0031">As similarly discussed above, threat remediation system <b>101</b> may determine (at <b>112</b>) whether the risk scores of the system and/or components of the system are above the threshold. Threat remediation system <b>101</b> may maintain information indicating whether the risk scores are above the threshold in order to refine a predictive model (e.g., which may cause a similar move to be made in the future under similar circumstances if the risk scores are above the threshold, and/or which may cause a similar move to be avoided in the future under similar circumstances if the risk scores are not above the threshold). In some embodiments, where <figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates a simulation of the move, threat remediation system <b>101</b> may determine performance key performance indicators (&#x201c;KPIs&#x201d;) and/or other suitable metrics associated with the move, and may ultimately determine whether to make the move (or another move, or another remedial measure entirely) based on the KPIs and/or other metrics associated with the move and/or other potential remedial measures.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>2</b>C</figref> illustrates another potential remedial measure that may be taken (or simulated) by threat remediation system <b>101</b>. In some embodiments, for example, threat remediation system <b>101</b> may simulate the moves shown in <figref idref="DRAWINGS">FIGS. <b>2</b>A and <b>2</b>B</figref>, as well as the remedial measures shown in <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>, and may ultimately select a particular remedial measure to take. As shown in <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>, for example, threat remediation system <b>101</b> may disable (at <b>114</b>) Container_<b>1</b>. For example, threat remediation system <b>101</b> may cause an orchestration system to communicate with Container_<b>1</b>, Node_<b>1</b>, and/or Cluster_<b>1</b>, to uninstall, deprovision, and/or take some other similar measure pertaining to Container_<b>1</b>.</p><p id="p-0034" num="0033">After disabling Container_<b>1</b>, threat remediation system <b>101</b> may identify (at <b>116</b>) updated attributes of other components of the system (e.g., Container_<b>2</b>, Container_<b>3</b>, Container_<b>4</b>, Node_<b>1</b>, Node_<b>2</b>, and/or Cluster_<b>1</b>). As similarly discussed above, threat remediation system <b>101</b> may determine (at <b>118</b>) whether the risk scores associated with the system are below a threshold. Threat remediation system <b>101</b> may also use this information to refine a predictive model and/or to ultimately select a remedial measure to take.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>2</b>D</figref> illustrates another potential remedial measure that may be taken (or simulated) by threat remediation system <b>101</b>. As shown, threat remediation system <b>101</b> may quarantine Container_<b>1</b>. For example, threat remediation system <b>101</b> may configure or instantiate quarantine component <b>129</b> at Node_<b>1</b>. Quarantine component <b>129</b> may be configured to receive, inspect, intercept, etc., traffic or data that is sent and/or received by Container_<b>1</b>. As similarly discussed above, the parameters used to configure quarantine component <b>129</b> (e.g., whether to block all inbound and/or outbound traffic associated with Container_<b>1</b>, whether to block particular types of traffic associated with Container_<b>1</b>, whether to block traffic to and/or from a particular device or system, etc.) may be determined based on machine learning and/or other suitable techniques.</p><p id="p-0036" num="0035">Additionally, or alternatively, threat remediation system <b>101</b> may provide (at <b>122</b>) an indication of the quarantine of Node_<b>1</b> to a device or system that maintains information regarding quarantined containers or other components (e.g., quarantine repository <b>131</b>). For example, Container_<b>4</b> may receive (at <b>124</b>) an indication that Container_<b>1</b> is quarantined. Based on this indication, Container_<b>4</b> may forgo (at <b>126</b>) communicating with Node_<b>1</b>.</p><p id="p-0037" num="0036">In some embodiments, the calculated risk score for a given system or element of a system may be used to determine or calculate other metrics associated with the system. For example, a risk score for a system (and/or risk scores for elements of the system) may be used with other risk-related metrics, such as delivery risk and/or annualized loss expectancy (&#x201c;ALE&#x201d;), to determine an overall level of risk associated with the system or elements of the system. The overall risk for a system may be quantified in terms of risk scores, ALE, delivery risk, and/or a combination thereof.</p><p id="p-0038" num="0037">The use of risk scores (e.g., in lieu of, or in addition to, evaluating risk based on monetary currencies) may be beneficial because using risk scores may provide a consistent relative baseline for comparison and evaluation of risks in context of the operating environment and various threat vectors, and is also free of other complications when measuring based on fiscal currencies, such as, for example, foreign exchange variations. Risk scores may reflect base risk and/or actionable risk for potential threat vectors. Base risk may be based on one or more factors, such as: (a) factors inherent to an application such as application functionality, data elements, number of servers, or number of external third party interfaces, (b) a periodic risk reduction evaluation with strategic actions for risk reduction, and/or (c) one or more other similar factors. Actionable risk may be based on one or more factors, such as: (a) identified security vulnerabilities, (b) non-compliance with rules and/or regulations, (c) a continual evaluation or reporting of identified risk elements, and/or (d) other items that elevate the risk level of a given application but can be mitigated or fixed in some way.</p><p id="p-0039" num="0038">Delivery risk may reflect the potential operational performance impact and potential financial impact resulting in unplanned spend to respond, contain, and/or mitigate issues arising from the materialization of a risk associated with a given element. Delivery risk may, in some scenarios, fluctuate based on multiple variables including the financial cost of services, foreign exchange rates, labor and other resource availability, etc., whereas risk scores, in accordance with some embodiments, may remain constant in the relation to risk materialization.</p><p id="p-0040" num="0039">ALE may reflect the actual cost if a loss event materializes (e.g., availability loss, revenue loss, regulatory fines, etc.). ALE may be modeled using the Factor Analysis of Information Risk (&#x201c;FAIR&#x201d;) taxonomy and/or using other suitable methodologies. In some embodiments, the risk score for a system or element of the system may be a factor in determining the ALE associated with the system or element of the system.</p><p id="p-0041" num="0040">For example, one manner of defining ALE may include multiplying a Loss Event Frequency by a Loss Event Magnitude. Loss Event Frequency may be based on one or more of: (a) how often a loss event might materialize in a given year, which may be expressed as a Threat Event Frequency (e.g., how often a threat or attack occurs) multiplied by Susceptibility (e.g., how likely the threat or attack is to succeed). ALE may, in some embodiments, further be based on the magnitude of a given loss.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example environment <b>300</b>, in which one or more embodiments may be implemented. In some embodiments, environment <b>300</b> may correspond to a Fifth Generation (&#x201c;5G&#x201d;) network, and/or may include elements of a 5G network. In some embodiments, environment <b>300</b> may correspond to a 5G Non-Standalone (&#x201c;NSA&#x201d;) architecture, in which a 5G radio access technology (&#x201c;RAT&#x201d;) may be used in conjunction with one or more other RATs (e.g., a Long-Term Evolution (&#x201c;LTE&#x201d;) RAT), and/or in which elements of a 5G core network may be implemented by, may be communicatively coupled with, and/or may include elements of another type of core network (e.g., an evolved packet core (&#x201c;EPC&#x201d;)). As shown, environment <b>300</b> may include UE <b>301</b>, radio access network (&#x201c;RAN&#x201d;) <b>310</b> (which may include one or more Next Generation Node Bs (&#x201c;gNBs&#x201d;) <b>311</b>), RAN <b>312</b> (which may include one or more one or more evolved Node Bs (&#x201c;eNBs&#x201d;) <b>313</b>), AMF <b>315</b>, SMF/PGW-Control plane function (&#x201c;PGW-C&#x201d;) <b>320</b>, PCF/Policy Charging and Rules Function (&#x201c;PCRF&#x201d;) <b>325</b>, AF <b>330</b>, UPF/PGW-User plane function (&#x201c;PGW-U&#x201d;) <b>335</b>, HSS/UDM <b>340</b>, AUSF <b>345</b>, Data Network (&#x201c;DN&#x201d;) <b>350</b>, and threat remediation system <b>101</b>.</p><p id="p-0043" num="0042">The quantity of devices and/or networks, illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, is provided for explanatory purposes only. In practice, environment <b>300</b> may include additional devices and/or networks, fewer devices and/or networks, different devices and/or networks, or differently arranged devices and/or networks than illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. For example, while not shown, environment <b>300</b> may include devices that facilitate or enable communication between various components shown in environment <b>300</b>, such as routers, modems, gateways, switches, hubs, etc. Alternatively, or additionally, one or more of the devices of environment <b>300</b> may perform one or more functions described as being performed by another one or more of the devices of environment <b>300</b>. Devices of environment <b>300</b> may interconnect with each other and/or other devices via wired connections, wireless connections, or a combination of wired and wireless connections. In some implementations, one or more devices of environment <b>300</b> may be physically integrated in, and/or may be physically attached to, one or more other devices of environment <b>300</b>.</p><p id="p-0044" num="0043">UE <b>301</b> may include a computation and communication device, such as a wireless mobile communication device that is capable of communicating with RAN <b>310</b> and/or DN <b>350</b>. UE <b>301</b> may be, or may include, a radiotelephone, a personal communications system (&#x201c;PCS&#x201d;) terminal (e.g., a device that combines a cellular radiotelephone with data processing and data communications capabilities), a personal digital assistant (&#x201c;PDA&#x201d;) (e.g., a device that may include a radiotelephone, a pager, Internet/intranet access, etc.), a smart phone, a laptop computer, a tablet computer, a camera, a personal gaming system, an IoT device (e.g., a sensor, a smart home appliance, or the like), a wearable device, a Mobile-to-Mobile (&#x201c;M2M&#x201d;) device, or another type of mobile computation and communication device. UE <b>301</b> may send traffic to and/or receive traffic (e.g., user plane traffic) from DN <b>350</b> via RAN <b>310</b> and UPF/PGW-U <b>335</b>.</p><p id="p-0045" num="0044">RAN <b>310</b> may be, or may include, a 5G RAN that includes one or more base stations (e.g., one or more gNBs <b>311</b>), via which UE <b>301</b> may communicate with one or more other elements of environment <b>300</b>. UE <b>301</b> may communicate with RAN <b>310</b> via an air interface (e.g., as provided by gNB <b>311</b>). For instance, RAN <b>310</b> may receive traffic (e.g., voice call traffic, data traffic, messaging traffic, signaling traffic, etc.) from UE <b>301</b> via the air interface, and may communicate the traffic to UPF/PGW-U <b>335</b>, and/or one or more other devices or networks. Similarly, RAN <b>310</b> may receive traffic intended for UE <b>301</b> (e.g., from UPF/PGW-U <b>335</b>, AMF <b>315</b>, and/or one or more other devices or networks) and may communicate the traffic to UE <b>301</b> via the air interface.</p><p id="p-0046" num="0045">RAN <b>312</b> may be, or may include, an LTE RAN that includes one or more base stations (e.g., one or more eNBs <b>313</b>), via which UE <b>301</b> may communicate with one or more other elements of environment <b>300</b>. UE <b>301</b> may communicate with RAN <b>312</b> via an air interface (e.g., as provided by eNB <b>313</b>). For instance, RAN <b>310</b> may receive traffic (e.g., voice call traffic, data traffic, messaging traffic, signaling traffic, etc.) from UE <b>301</b> via the air interface, and may communicate the traffic to UPF/PGW-U <b>335</b>, and/or one or more other devices or networks. Similarly, RAN <b>310</b> may receive traffic intended for UE <b>301</b> (e.g., from UPF/PGW-U <b>335</b>, SGW <b>517</b>, and/or one or more other devices or networks) and may communicate the traffic to UE <b>301</b> via the air interface.</p><p id="p-0047" num="0046">AMF <b>315</b> may include one or more devices, systems, Virtualized Network Functions (&#x201c;VNFs&#x201d;), etc., that perform operations to register UE <b>301</b> with the 5G network, to establish bearer channels associated with a session with UE <b>301</b>, to hand off UE <b>301</b> from the 5G network to another network, to hand off UE <b>301</b> from the other network to the 5G network, and/or to perform other operations. In some embodiments, the 5G network may include multiple AMFs <b>315</b>, which communicate with each other via the N14 interface (denoted in <figref idref="DRAWINGS">FIG. <b>3</b></figref> by the line marked &#x201c;N14&#x201d; originating and terminating at AMF <b>315</b>).</p><p id="p-0048" num="0047">SGW <b>517</b> may include one or more devices, systems, VNFs, etc., that aggregate traffic received from one or more eNBs <b>313</b> and send the aggregated traffic to an external network or device via UPF/PGW-U <b>335</b>. Additionally, SGW <b>517</b> may aggregate traffic received from one or more UPF/PGW-Us <b>335</b> and may send the aggregated traffic to one or more eNBs <b>313</b>. SGW <b>517</b> may operate as an anchor for the user plane during inter-eNB handovers and as an anchor for mobility between different telecommunication networks or RANs (e.g., RANs <b>310</b> and <b>312</b>).</p><p id="p-0049" num="0048">SMF/PGW-C <b>320</b> may include one or more devices, systems, VNFs, etc., that gather, process, store, and/or provide information in a manner described herein. SMF/PGW-C <b>320</b> may, for example, facilitate in the establishment of communication sessions on behalf of UE <b>301</b>. In some embodiments, the establishment of communications sessions may be performed in accordance with one or more policies provided by PCF % PCRF <b>325</b>.</p><p id="p-0050" num="0049">PCF/PCRF <b>325</b> may include one or more devices, systems, VNFs, etc., that aggregate information to and from the 5G network and/or other sources. PCF/PCRF <b>325</b> may receive information regarding policies and/or subscriptions from one or more sources, such as subscriber databases and/or from one or more users (such as, for example, an administrator associated with PCF/PCRF <b>325</b>).</p><p id="p-0051" num="0050">AF <b>330</b> may include one or more devices, systems, VNFs, etc., that receive, store, and/or provide information that may be used in determining parameters (e.g., quality of service parameters, charging parameters, or the like) for certain applications.</p><p id="p-0052" num="0051">UPF/PGW-U <b>335</b> may include one or more devices, systems, VNFs, etc., that receive, store, and/or provide data (e.g., user plane data). For example, UPF/PGW-U <b>335</b> may receive user plane data (e.g., voice call traffic, data traffic, etc.), destined for UE <b>301</b>, from DN <b>350</b>, and may forward the user plane data toward UE <b>301</b> (e.g., via RAN <b>310</b>, SMF/PGW-C <b>320</b>, and/or one or more other devices). In some embodiments, multiple UPFs <b>335</b> may be deployed (e.g., in different geographical locations), and the delivery of content to UE <b>301</b> may be coordinated via the N9 interface (e.g., as denoted in <figref idref="DRAWINGS">FIG. <b>3</b></figref> by the line marked &#x201c;N9&#x201d; originating and terminating at UPF/PGW-U <b>335</b>). Similarly, UPF/PGW-U <b>335</b> may receive traffic from UE <b>301</b> (e.g., via RAN <b>310</b>, SMF/PGW-C <b>320</b>, and/or one or more other devices), and may forward the traffic toward DN <b>350</b>. In some embodiments, UPF/PGW-U <b>335</b> may communicate (e.g., via the N4 interface) with SMF/PGW-C <b>320</b>, regarding user plane data processed by UPF/PGW-U <b>335</b>.</p><p id="p-0053" num="0052">HSS/UDM <b>340</b> and AUSF <b>345</b> may include one or more devices, systems, VNFs, etc., that manage, update, and/or store, in one or more memory devices associated with AUSF <b>345</b> and/or HSS/UDM <b>340</b>, profile information associated with a subscriber. AUSF <b>345</b> and/or HSS/UDM <b>340</b> may perform authentication, authorization, and/or accounting operations associated with the subscriber and/or a communication session with UE <b>301</b>.</p><p id="p-0054" num="0053">DN <b>350</b> may include one or more wired and/or wireless networks. For example, DN <b>350</b> may include an Internet Protocol (&#x201c;IP&#x201d;)-based PDN, a wide area network (&#x201c;WAN&#x201d;) such as the Internet, a private enterprise network, and/or one or more other networks. UE <b>301</b> may communicate, through DN <b>350</b>, with data servers, other UEs <b>301</b>, and/or to other servers or applications that are coupled to DN <b>350</b>. DN <b>350</b> may be connected to one or more other networks, such as a public switched telephone network (&#x201c;PSTN&#x201d;), a public land mobile network (&#x201c;PLMN&#x201d;), and/or another network. DN <b>350</b> may be connected to one or more devices, such as content providers, applications, web servers, and/or other devices, with which UE <b>301</b> may communicate.</p><p id="p-0055" num="0054">Threat remediation system <b>101</b> may include one or more devices or systems that perform one or more operations described herein. For example, threat remediation system <b>101</b> may communicate with one or more of the devices, systems, VNFs, or networks shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, may identify potential threat vectors (e.g., using machine learning and/or other techniques), and may perform remedial actions when detecting risk levels (e.g., risk scores) that exceed a threshold level. As mentioned above, threat remediation system <b>101</b> may include, or may be communicatively coupled to, an orchestration system that is capable of receiving information (e.g., diagnostic or monitoring information) from the devices or systems shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, and is capable of installing or instantiating containers on nodes (e.g., as implemented by physical or virtual hardware). While no explicit connections are shown between threat remediation system <b>101</b> and other devices or systems of environment <b>300</b>, threat remediation system <b>101</b> may, in some embodiments, be communicatively coupled to some or all of the devices or systems of environment <b>300</b>. In some embodiments, the same devices, nodes, clusters, etc., that implement one or more of the devices or systems of environment <b>300</b> may implement some or all of the functionality of threat remediation system <b>101</b>.</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example process <b>400</b> for identifying a potential threat vector with a risk score exceeding a threshold and using machine learning techniques to remediate the identified threat vector. In some embodiments, some or all of process <b>400</b> may be performed by threat remediation system <b>101</b>. In some embodiments, one or more other devices may perform some or all of process <b>400</b> (e.g., in concert with, and/or in lieu of, threat remediation system <b>101</b>).</p><p id="p-0057" num="0056">As shown, process <b>400</b> may include identifying (at <b>402</b>) attributes of potential threat vectors, including relationships between potential threat vectors. For example, as discussed above, threat remediation system <b>101</b> may identify attributes of a system and/or components of the system to identify aspects of the system (e.g., particular devices or VNFs) which may potentially be associated with risk or loss. The devices, systems, VNFs, etc., may be identified through machine learning techniques, such as supervised or unsupervised learning. K-means clustering, categorization, etc. As discussed above, potential threat vectors may include, or be related to, VNFs or other aspects of a wireless telecommunications network, such as 5G network, and LTE network, a network implementing an NSA architecture, etc.</p><p id="p-0058" num="0057">Process <b>400</b> may further include generating (at <b>404</b>) risk scores for one or more potential threat vectors. For example, as discussed above, threat remediation system <b>101</b> may generate one or more risk scores for the potential threat vectors, which may be based on the attributes identified with respect to the potential threat vectors, and may in some embodiments be further based on weights assigned to the attributes.</p><p id="p-0059" num="0058">Process <b>400</b> may additionally include identifying (at <b>406</b>) a potential threat vector with a risk score exceeding threshold. As mentioned above, the threshold may be determined or adjusted automatically (e.g., based on machine learning or other suitable techniques, and/or may be manually determined or adjusted).</p><p id="p-0060" num="0059">Process <b>400</b> may also include identifying (at <b>408</b>) remedial action for identified threat vector using machine learning techniques. For example, threat remediation system <b>101</b> may identify past remedial actions that were taken for threat vectors having the same or similar attributes of the identified threat vector. The past remedial actions and/or past threat vectors may be identified using a suitable correlation or similarity analysis. For example, threat remediation system <b>101</b> may determine that the present threat vector and the past threat vector(s) have a measure of similarity that exceeds a threshold measure of similarity, based on the similarity analysis.</p><p id="p-0061" num="0060">If the threat vector is a container installed on a node, the attributes may include attributes of the container (e.g., provisioned resources associated with the container, type of container, applications included in the container, etc.), of the node (e.g., used or available resources associated with the node, a cluster on which the node resides, other containers installed on the node, etc.), and/or some other device or system associated with the threat vector. The remedial action may, in some embodiments, be identified based on past remedial actions for threat vectors with a same or similar risk score, and/or for threat vectors with attributes that have the same or similar score as attributes associated with the threat vector (e.g., where a &#x201c;Mission Critical&#x201d; attribute associated with the threat vector and the one or more other threat vectors is associated with a score of &#x201c;10&#x201d; or a value of &#x201c;Yes&#x201d;). The remedial action may also be based on other constraints, rules, attributes, etc. associated with the threat vector and/or other threat vectors with which the threat vector has a relationship. For example, the threat vector may have an anti-affinity with another threat vector (e.g., two containers installed on the same node, in which the two containers have an anti-affinity with each other), based on which the remedial measure may be based on remediating the anti-affinity (e.g., by moving one or both containers, and/or by taking some other suitable measure).</p><p id="p-0062" num="0061">Process <b>400</b> may further include taking (at <b>410</b>) the identified remedial action. For example, threat remediation system <b>101</b> may cause the remedial action to be taken, and/or may simulate the results of taking the remedial action. In some embodiments, threat remediation system <b>101</b> may communicate with an orchestration system and/or some other type of device or system in order to cause the remedial action to be taken or simulated.</p><p id="p-0063" num="0062">Process <b>400</b> may additionally include verifying (at <b>412</b>) the results of the remedial action. For example, once the remedial action has been taken or has been simulated, threat remediation system <b>101</b> may determine one or more metrics that indicate whether the remedial action was successful. For example, as discussed above, threat remediation system <b>101</b> may determine (or re-determine) one or more risk scores associated with the threat vector that was remediated. Additionally, or alternatively, threat remediation system <b>101</b> may determine other types of scores or metrics, such as performance metrics, ALE-based metrics, and/or other suitable metrics, that indicate whether the remediation was successful.</p><p id="p-0064" num="0063">Process <b>400</b> may also include refining (at <b>414</b>) a machine learning model based on the results of the remedial action. For example, threat remediation system <b>101</b> may refine a machine learning model with attributes of the threat vector as well as an indication of the remedial action that was taken. If the remediation was successful (e.g., one or more risk scores and/or other suitable metrics do not exceed a threshold, and/or improve with regard to before the remediation), refining the machine learning model may cause similar threat vectors in the future to be more likely to be remediated in the same way. If, on the other hand, the remediation was not successful (e.g., one or more risk scores and/or other suitable metrics exceed the threshold, and/or do not improve with regard to before the remediation), refining the machine learning model may cause similar threat vectors in the future to be less likely to be remediated in the same way.</p><p id="p-0065" num="0064">As denoted by the dotted line in the figure, some or all of process <b>400</b> may repeat on an iterative basis. For example, one or more of blocks <b>408</b>-<b>414</b> may be repeated until an optimal configuration is reached. For example, multiple different remedial actions may be simulated (at <b>410</b>), the results of the multiple remedial actions may be determined and/or verified (at <b>412</b>), and a particular one of the remedial actions may be selected (e.g., based on the resultant risk scores, performance metrics, changes to ALE, and/or other factors). The machine learning model may be refined (at <b>414</b>) for each iteration, whether a given remedial action was ultimately selected or not.</p><p id="p-0066" num="0065">In some embodiments, multiple different threat vectors may be identified, with corresponding risk scores (e.g., exceeding a risk score threshold). Threat remediation system <b>101</b> may, in some embodiments, prioritize the threat vectors based on the corresponding risk scores, and/or may use the risk scores as a factor in ultimately determining an order in which to remediate the threat vectors. For example, assume that threat remediation system <b>101</b> identifies two different containers in a virtualized environment, with two different risk scores that exceed the risk score threshold. Threat remediation system <b>101</b> may prioritize the container with the higher risk score (e.g., may take (at <b>410</b>) a remedial action, verify (at <b>412</b>) the remedial action, etc., for this container prior to addressing the container with the lesser risk score.</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates example components of device <b>500</b>. One or more of the devices described above may include one or more devices <b>500</b>. Device <b>500</b> may include bus <b>510</b>, processor <b>520</b>, memory <b>530</b>, input component <b>540</b>, output component <b>550</b>, and communication interface <b>560</b>. In another implementation, device <b>500</b> may include additional, fewer, different, or differently arranged components.</p><p id="p-0068" num="0067">Bus <b>510</b> may include one or more communication paths that permit communication among the components of device <b>500</b>. Processor <b>520</b> may include a processor, microprocessor, or processing logic that may interpret and execute instructions. Memory <b>530</b> may include any type of dynamic storage device that may store information and instructions for execution by processor <b>520</b>, and/or any type of non-volatile storage device that may store information for use by processor <b>520</b>.</p><p id="p-0069" num="0068">Input component <b>540</b> may include a mechanism that permits an operator to input information to device <b>500</b>, such as a keyboard, a keypad, a button, a switch, etc. Output component <b>550</b> may include a mechanism that outputs information to the operator, such as a display, a speaker, one or more light emitting diodes (&#x201c;LEDs&#x201d;), etc.</p><p id="p-0070" num="0069">Communication interface <b>560</b> may include any transceiver-like mechanism that enables device <b>500</b> to communicate with other devices and/or systems. For example, communication interface <b>560</b> may include an Ethernet interface, an optical interface, a coaxial interface, or the like. Communication interface <b>560</b> may include a wireless communication device, such as an infrared (&#x201c;IR&#x201d;) receiver, a Bluetooth&#xae; radio, or the like. The wireless communication device may be coupled to an external device, such as a remote control, a wireless keyboard, a mobile telephone, etc. In some embodiments, device <b>500</b> may include more than one communication interface <b>560</b>. For instance, device <b>500</b> may include an optical interface and an Ethernet interface.</p><p id="p-0071" num="0070">Device <b>500</b> may perform certain operations relating to one or more processes described above. Device <b>500</b> may perform these operations in response to processor <b>520</b> executing software instructions stored in a computer-readable medium, such as memory <b>530</b>. A computer-readable medium may be defined as a non-transitory memory device. A memory device may include space within a single physical memory device or spread across multiple physical memory devices. The software instructions may be read into memory <b>530</b> from another computer-readable medium or from another device. The software instructions stored in memory <b>530</b> may cause processor <b>520</b> to perform processes described herein. Alternatively, hardwired circuitry may be used in place of or in combination with software instructions to implement processes described herein. Thus, implementations described herein are not limited to any specific combination of hardware circuitry and software.</p><p id="p-0072" num="0071">The foregoing description of implementations provides illustration and description, but is not intended to be exhaustive or to limit the possible implementations to the precise form disclosed. Modifications and variations are possible in light of the above disclosure or may be acquired from practice of the implementations.</p><p id="p-0073" num="0072">For example, while series of blocks and/or signals have been described above (e.g., with regard to <figref idref="DRAWINGS">FIGS. <b>1</b>A, <b>2</b>A-<b>2</b>D, and <b>4</b></figref>), the order of the blocks and/or signals may be modified in other implementations. Further, non-dependent blocks and/or signals may be performed in parallel. Additionally, while the figures have been described in the context of particular devices performing particular acts, in practice, one or more other devices may perform some or all of these acts in lieu of, or in addition to, the above-mentioned devices.</p><p id="p-0074" num="0073">The actual software code or specialized control hardware used to implement an embodiment is not limiting of the embodiment. Thus, the operation and behavior of the embodiment has been described without reference to the specific software code, it being understood that software and control hardware may be designed based on the description herein.</p><p id="p-0075" num="0074">Even though particular combinations of features are recited in the claims and/or disclosed in the specification, these combinations are not intended to limit the disclosure of the possible implementations. In fact, many of these features may be combined in ways not specifically recited in the claims and/or disclosed in the specification. Although each dependent claim listed below may directly depend on only one other claim, the disclosure of the possible implementations includes each dependent claim in combination with every other claim in the claim set.</p><p id="p-0076" num="0075">Further, while certain connections or devices are shown, in practice, additional, fewer, or different, connections or devices may be used. Furthermore, while various devices and networks are shown separately, in practice, the functionality of multiple devices may be performed by a single device, or the functionality of one device may be performed by multiple devices. Further, multiple ones of the illustrated networks may be included in a single network, or a particular network may include multiple networks. Further, while some devices are shown as communicating with a network, some such devices may be incorporated, in whole or in part, as a part of the network.</p><p id="p-0077" num="0076">To the extent the aforementioned implementations collect, store, or employ personal information provided by individuals, it should be understood that such information shall be collected, stored, and used in accordance with all applicable laws concerning protection of personal information. Additionally, the collection, storage, and use of such information may be subject to consent of the individual to such activity (for example, through &#x201c;opt-in&#x201d; or &#x201c;opt-out&#x201d; processes, as may be appropriate for the situation and type of information). Storage and use of personal information may be in an appropriately secure manner reflective of the type of information, for example, through various encryption and anonymization techniques for particularly sensitive information.</p><p id="p-0078" num="0077">No element, act, or instruction used in the present application should be construed as critical or essential unless explicitly described as such. An instance of the use of the term &#x201c;and,&#x201d; as used herein, does not necessarily preclude the interpretation that the phrase &#x201c;and/or&#x201d; was intended in that instance. Similarly, an instance of the use of the term &#x201c;or,&#x201d; as used herein, does not necessarily preclude the interpretation that the phrase &#x201c;and/or&#x201d; was intended in that instance. Also, as used herein, the article &#x201c;a&#x201d; is intended to include one or more items, and may be used interchangeably with the phrase &#x201c;one or more.&#x201d; Where only one item is intended, the terms &#x201c;one,&#x201d; &#x201c;single,&#x201d; &#x201c;only,&#x201d; or similar language is used. Further, the phrase &#x201c;based on&#x201d; is intended to mean &#x201c;based, at least in part, on&#x201d; unless explicitly stated otherwise.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A device, comprising:<claim-text>one or more processors configured to:<claim-text>receive attribute information for a plurality of containers in a virtualized environment;</claim-text><claim-text>identify, for each attribute associated with a particular container, of the plurality of containers, a value associated with the attribute;</claim-text><claim-text>generate, for each container of the plurality of containers, a score that is based on the respective values associated with the attributes of the each container;</claim-text><claim-text>identify that the generated score for the particular container exceeds a threshold;</claim-text><claim-text>identify a particular remedial action, out of a plurality of candidate remedial actions, to take based on identifying that the generated score exceeds the threshold;</claim-text><claim-text>cause the identified remedial action to be performed;</claim-text><claim-text>recalculate the score for the particular container based on taking the particular remedial action; and</claim-text><claim-text>retain the particular remedial action when the recalculated score does not exceed the threshold.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the attributes associated with the particular container are associated with a plurality of groups, wherein each attribute associated with the particular container is associated with a particular one of the groups, of the plurality of groups, wherein each group is associated with a different weight.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the score for the particular container is calculated based on:<claim-text>the values of the attributes associated with the particular container, and</claim-text><claim-text>the weights associated with the groups, with which the attributes are associated.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the generated score and the recalculated score indicate a measure of risk associated with the particular container.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein identifying the particular remedial action includes:<claim-text>identifying another container for which the same particular remedial action was previously taken;</claim-text><claim-text>performing a similarity analysis to identify that the other container and the particular container have a measure of similarity that exceeds a threshold measure of similarity; and</claim-text><claim-text>selecting the particular remedial action for the particular container based on identifying that the other container, for which the same particular remedial action was taken, and the particular container have the measure of similarity that exceeds the threshold measure of similarity.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more processors are further configured to:<claim-text>refine a machine learning model to indicate that the identified remedial action was selected based on the attributes associated with the particular container.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a particular attribute, associated with the particular container, includes an anti-affinity between the particular container and another container, wherein the device is further configured to:<claim-text>identify that the particular container is installed on a same node as the other container for which the particular container has the anti-affinity,</claim-text><claim-text>wherein the score is generated further based on identifying that the particular container is installed on the same node as the other container for which the particular container has the anti-affinity.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of containers include at least one of a virtual machine, virtual image or virtual network function.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the device is further configured to:<claim-text>when the recalculated score exceeds the threshold, identify another remedial action, and cause the another remedial action to be performed.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the plurality of potential remedial actions includes at least one of:<claim-text>moving the particular container to a different node within the virtualized environment;</claim-text><claim-text>moving a container other than the particular container to a different node within the virtualized environment;</claim-text><claim-text>disabling the particular container; or</claim-text><claim-text>quarantining the particular container.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A method, comprising:<claim-text>receiving attribute information for a plurality of containers in a virtualized environment;</claim-text><claim-text>identifying, for each attribute associated with a particular container, of the plurality of containers, a value associated with the attribute;</claim-text><claim-text>generating, for each container of the plurality of containers, a score that is based on the respective values associated with the attributes of the each container;</claim-text><claim-text>identifying that the generated score for the particular container exceeds a threshold;</claim-text><claim-text>identifying a particular remedial action, out of a plurality of candidate remedial actions, to take based on identifying that the generated score exceeds the threshold;</claim-text><claim-text>causing the identified remedial action to be performed;</claim-text><claim-text>recalculating the score for the particular container based on taking the particular remedial action; and</claim-text><claim-text>retaining the remedial action when the recalculated score does not exceed the threshold.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the attributes associated with the particular container are associated with a plurality of groups, wherein each attribute associated with the particular container is associated with a particular one of the groups, of the plurality of groups, wherein each group is associated with a different weight.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the score for the particular container is calculated based on:<claim-text>the values of the attributes associated with the particular container, and</claim-text><claim-text>the weights associated with the groups, with which the attributes are associated.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the generated score and the recalculated score indicate a measure of risk associated with the particular container.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein identifying the particular remedial action includes:<claim-text>identifying another container for which the same particular remedial action was previously taken;</claim-text><claim-text>performing a similarity analysis to identify that the other container and the particular container have a measure of similarity that exceeds a threshold measure of similarity; and</claim-text><claim-text>selecting the particular remedial action for the particular container based on identifying that the other container, for which the same particular remedial action was taken, and the particular container have the measure of similarity that exceeds the threshold measure of similarity.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>refining a machine learning model to indicate that the identified remedial action was selected based on the attributes associated with the particular container.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein a particular attribute, associated with the particular container, includes an anti-affinity between the particular container and another container, the method further comprising:<claim-text>identifying that the particular container is installed on a same node as the other container for which the particular container has the anti-affinity,</claim-text><claim-text>wherein the score is generated further based on identifying that the particular container is installed on the same node as the other container for which the particular container has the anti-affinity.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the plurality of containers include at least one of a virtual machine, virtual image or virtual network function.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:<claim-text>when the recalculated score exceeds the threshold, identifying another remedial action, and causing the another remedial action to be performed.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the plurality of potential remedial actions includes at least one of:<claim-text>moving the particular container to a different node within the virtualized environment;</claim-text><claim-text>moving a container other than the particular container to a different node within the virtualized environment;</claim-text><claim-text>disabling the particular container; or</claim-text><claim-text>quarantining the particular container.</claim-text></claim-text></claim></claims></us-patent-application>
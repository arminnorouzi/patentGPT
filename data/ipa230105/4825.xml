<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004826A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004826</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17831750</doc-number><date>20220603</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>21 18 2890.0</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>022</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e61">DEVICE AND METHOD FOR CLASSIFYING A SIGNAL AND/OR FOR PERFORMING REGRESSION ANALYSIS ON A SIGNAL</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee"><addressbook><orgname>Robert Bosch GmbH</orgname><address><city>Stuttgart</city><country>DE</country></address></addressbook><residence><country>DE</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Schuff</last-name><first-name>Hendrik</first-name><address><city>Leonberg</city><country>DE</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Adel-Vu</last-name><first-name>Heike</first-name><address><city>Renningen</city><country>DE</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Vu</last-name><first-name>Ngoc Thang</first-name><address><city>Stuttgart</city><country>DE</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A computer-implemented method for determining an output signal characterizing a classification and/or a regression result of an input signal. The method includes: determining a feature representation characterizing the input signal; determining an intermediate signal characterizing a classification and/or regression result of the feature representation; predicting, based on the feature representation and the intermediate signal, a deviation of the intermediate signal from a desired output signal of the input signal; adapting the intermediate signal according to the determined deviation thereby determining an adapted signal; providing the adapted signal as output signal.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="83.90mm" wi="158.75mm" file="US20230004826A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="206.42mm" wi="133.94mm" orientation="landscape" file="US20230004826A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="161.71mm" wi="155.45mm" orientation="landscape" file="US20230004826A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="154.43mm" wi="132.76mm" orientation="landscape" file="US20230004826A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="208.79mm" wi="165.35mm" orientation="landscape" file="US20230004826A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="187.88mm" wi="112.95mm" orientation="landscape" file="US20230004826A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="191.01mm" wi="140.72mm" orientation="landscape" file="US20230004826A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="161.97mm" wi="120.65mm" orientation="landscape" file="US20230004826A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="198.71mm" wi="150.20mm" orientation="landscape" file="US20230004826A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS REFERENCE</heading><p id="p-0002" num="0001">The present application claims the benefit under 35 U.S.C. &#xa7; 119 of European Patent Application No. EP 21 18 2890.0 filed on Jun. 30, 2021, which is expressly incorporated herein by reference in its entirety.</p><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">The present invention concerns a method for determining a classification and/or regression result for an input signal, a method for training a machine learning system, a machine learning system, a device for training the machine learning system, a computer program, and a computer-readable storage medium.</p><heading id="h-0003" level="1">BACKGROUND INFORMATION</heading><p id="p-0004" num="0003">Hastie et al. 2009 &#x201c;10. Boosting and Additive Trees&#x201d; in <i>The Elements of Statistical Learning </i>describes a method for boosted classification.</p><p id="p-0005" num="0004">The use of machine learning systems for classification and/or regression analysis has become ubiquitous in a variety of technical fields. Especially for robotic applications, machine learning systems are used heavily to, e.g., infer knowledge from sensor data of the surroundings of a respective robot. Here, especially neural networks are widely applied as they constitute the state-of-the-art with respect to prediction performance.</p><p id="p-0006" num="0005">A major drawback in most machine learning systems and neural networks in particular is that they determine wrong predictions for a provided input yet still output high confidences in their predictions. This is, of course, highly undesirable as one would like a machine learning system to be correct if it is confident it its own prediction and unconfident of it if its prediction is wrong.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0007" num="0006">The present invention concerns a computer-implemented method for determining an output signal characterizing a classification and/or a regression result of an input signal. In accordance with an example embodiment of the present invention, the method comprises the following steps:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0007">a. Determining a feature representation characterizing the input signal;</li>    <li id="ul0001-0002" num="0008">b. Determining an intermediate signal characterizing a classification and/or regression result of the feature representation;</li>    <li id="ul0001-0003" num="0009">c. Predicting, based on the feature representation and the intermediate signal, a deviation of the intermediate signal from a desired output signal of the input signal;</li>    <li id="ul0001-0004" num="0010">d. Adapting the intermediate signal according to the determined deviation thereby determining an adapted signal;</li>    <li id="ul0001-0005" num="0011">e. Providing the adapted signal as output signal.</li></ul></p><p id="p-0008" num="0012">The feature representation, the intermediate signal and the deviation are preferably each determined by a machine learning system. The method may hence be understood as a method for predicting a classification and/or regression result for the input signal, wherein the prediction is self-corrected. That means that the method corrects incorrect predictions automatically before the prediction is actually put out as the output signal.</p><p id="p-0009" num="0013">The input signal is a technical signal. It may preferably characterize data obtained from a sensor. The sensor may, for example, be an optical sensor, e.g., a camera sensor, a radar sensor, a LIDAR, an ultrasonic, or a thermal camera. The data obtained from these exemplary sensors may all be considered images. It is also possible that the input signal characterize data from an audio sensor such as a microphone. It is also possible that the input signal characterizes data obtained from a piezo sensor, a temperature sensor or a sensor for measuring pressure. In particular, the input signal may also characterize data from different types of sensors or and/or multiple data from a single sensor type (e.g., two images form a stereo camera sensor). The method may hence be understood as a method performed by a virtual sensor, i.e., a method for detecting content in a sensor signal that cannot be derived directly from the sensor data itself.</p><p id="p-0010" num="0014">The output signal may characterize a classification and/or a regression result of the input signal. The term regression result may be understood as a result from a method for performing regression analysis. In other words, while a method for classification is understood as outputting discrete data (e.g., class labels), a regression result is a continuous value characterizing the input signal. The term classification is understood to comprise different types of classifications. For example, object detection, semantic segmentation, multi-label classification and multi-class classification are all understood to fall under the more general term classification. The output signal may also characterize both a regression result and a classification, e.g., in form of an object detection wherein the method classifies whether an object is present in a certain part of an image and wherein the method further performs a regression with respect to the size of the object (e.g., size of the object in the image or in the real world).</p><p id="p-0011" num="0015">The intermediate signal may be understood as a signal which could possibly be used as output signal also but may be corrected in the method before being put out as output signal.</p><p id="p-0012" num="0016">The output signal may especially be used for controlling an actuator. For example, the output signal may serve as basis for determining a control signal of a robot comprising the actuator. The input signal may, for example, characterize a surrounding of the robot and the control signal may be determined such that the robot interacts with its environment suitably. For example, the input signal may characterize an image of the surroundings of the robot and the output signal may characterize the presence and/or locations of objects in the environment. The control signal may then be determined such that the robot moves to a desired position without colliding with the objects.</p><p id="p-0013" num="0017">The advantage of the method according to the present invention is that the classification and/or the regression result characterized by the output signal is corrected such that it matches a desired output signal more closely, i.e., the quality of the output signal is improved. Especially when using machine learning systems to determine the output signal, the machine learning signal may output an output signal which is inaccurate with respect to a desired output signal while the machine learning system is nevertheless confident that it provided an accurate output signal.</p><p id="p-0014" num="0018">In preferred example embodiments of the present invention, the feature representation is determined by a first machine learning system using the input signal as input of the first machine learning system and that the intermediate signal is determined by a second machine learning system using the feature representation as input of the second machine learning system and that the deviation is determined by a third machine learning system using the feature representation and the intermediate signal as input of the third machine learning system. The first, second and third machine learning system may be understood as parts of a fourth machine learning system, i.e., a machine learning system that comprises the first, second and third machine learning system.</p><p id="p-0015" num="0019">The feature representation may be understood as a preferably high-dimensional encoding of the input signal. Preferably, the first neural network is used for determining the feature representation. In this case, the feature representation may be the output of a layer, preferably a hidden layer, of the first neural network when provided the input signal as input. The feature representation may be a vector or may be reshaped into a vector. In case of the feature vector being a vector, the second machine learning model and/or third machine learning model may especially be a multilayer perceptron respectively.</p><p id="p-0016" num="0020">Preferably, the first, second and third machine learning system are each neural networks. The inventors found that the output signal is most accurate when using neural networks for the first, second and third machine learning system.</p><p id="p-0017" num="0021">The deviation may, for example, characterize a metric or semimetric (e.g., the cosine similarity) between the intermediate signal and the desired output signal. For example, the intermediate signal and the desired output signal may each be in the form of a vector and the deviation may be the Euclidean distance or Manhattan distance between the two vectors. It should be noted here that the desired output signal is not required in the method, as is common when determining classifications and/or regression results. The prediction of the deviation is not dependent on the presence of the desired output signal, i.e., a ground truth of the input signal. The desired output signal can rather be understood as an implicit property of an input signal. For example, an image showing objects may be understood as implicitly containing information about the location and extent of the objects.</p><p id="p-0018" num="0022">While for, e.g., training a machine learning system, the desired output signal could be required, this is not the case for the proposed method for predicting the output signal.</p><p id="p-0019" num="0023">The deviation may also characterize a probability of the intermediate signal being accurate enough with respect to the desired output signal. For example, a distance between an intermediate signal and a desired output signal can be defined, wherein the distance characterizes a maximum distance for which the intermediate signal is still accurate enough with respect to the desired output signal. The deviation predicted in the method may then characterize a probability of the intermediate signal being within this maximum distance to the desired output signal.</p><p id="p-0020" num="0024">In preferred example embodiments of the present invention, the steps c. and d. are repeated iteratively until an exit criterion is fulfilled, wherein the adapted signal is used as intermediate signal in a next iteration.</p><p id="p-0021" num="0025">In other words, the steps c. and d. may be run in a loop until the exit criterion is fulfilled. The exit criterion may, for example, characterize a predefined maximum number of executed iterations and/or the deviation characterizing a difference of the intermediate signal and output signal that is less than or equal to a predefined threshold.</p><p id="p-0022" num="0026">The inventors found that iteratively adapting the intermediate representation leads to an even bigger increase in accuracy of the output signal. As an additional technical effect, the inventors found that when using an exit criterion characterizing the deviation characterizing a difference of the intermediate signal and output signal that is less than or equal to a predefined threshold, the number of iterations necessary to fulfill the exit criterion characterizes an information about how hard it is to determine an accurate enough output signal. This information may be used as an uncertainty measure, i.e., the more steps necessary the harder it is to determine an output signal for the input signal and the larger the uncertainty in the output signal.</p><p id="p-0023" num="0027">In preferred example embodiments of the present invention, the deviation is predicted by a differentiable model and the intermediate signal is adapted based on a gradient of the deviation with respect to the intermediate signal.</p><p id="p-0024" num="0028">This approach may be understood as gradient descent on the deviation with respect to the intermediate signal, i.e., optimizing the intermediate signal.</p><p id="p-0025" num="0029">Irrespective of the type of model, the intermediate signal may also be adapted according to other optimization methods, especially black-box optimization methods such as evolutionary algorithms. For optimization, the deviation is used as objective value and the intermediate representation is used as variable to be optimized.</p><p id="p-0026" num="0030">In preferred example embodiments of the present invention, it is also possible that the second machine learning system is a neural network and an output of a hidden layer of the second machine learning system is used as additional input to the third machine learning system for determining the deviation.</p><p id="p-0027" num="0031">This may be understood as providing an additional input to the second machine learning system, namely an output of a layer of the second machine learning system. The inventors found that this improves the accuracy of the output signal even further.</p><p id="p-0028" num="0032">In another aspect, the present invention concerns a computer-implemented method for training a fourth machine learning system configured according to the specifications above. In accordance with an example embodiment of the present invention, the training comprises the following steps:<ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0033">f. Training the second machine learning model of the fourth machine learning model or the first machine learning model and the second machine learning model of the fourth machine learning model to determine a desired output signal for a provided first training input signal;</li>    <li id="ul0002-0002" num="0034">g. After training the second machine learning model or after training the first machine learning model and the second machine learning model, training the third machine learning model to determine a deviation of an intermediate signal determined from the first machine learning model and the second machine learning model for a provided second training input signal to a desired output signal for the supplied second training input signal, wherein the first machine learning model and the second machine learning model is not trained.</li></ul></p><p id="p-0029" num="0035">The method may be understood as enabling the method for determining the output as specified above. The training procedure can be understood as a two stage approach. First, the fourth machine learning system is trained to be able to predict intermediate signals. Second, the fourth machine learning system is trained to correct intermediate signals. It is possible that a pretrained machine learning system is used as first machine learning system and that the first machine learning system is not trained during the training procedure. Preferably, the first machine learning system and second machine learning system are both trained during the first stage (step f.) of the training procedure as the inventors found that this leads to an improvement in accuracy of the output signal later during inference (i.e., when executing the method for determining the output signal from above).</p><p id="p-0030" num="0036">Training of the first stage may be understood as supervised training of the first machine learning system and/or the second machine learning system. In supervised training input signals are used for training, i.e., training input signals, wherein for each training input signal a desired output signal is supplied.</p><p id="p-0031" num="0037">In accordance with an example embodiment of the present invention, during the second stage (step g.) the parameters of the first machine learning system and the second machine learning system may preferably be frozen and only the parameters of the third machine learning system may be optimized. The training data of the third machine learning system may be understood as the intermediate signals predicted from the training input signals in combination with a respective deviation of an intermediate signal to a desired output signal. In other words, in order to train the third machine learning system, a training input signal is forwarded through the first machine learning model and the resulting feature representation is then forwarded through the second model in order to determine an intermediate output. The determined feature representation and the intermediate signal are then used as training input for the third machine learning system. As desired deviation to be predicted from the third machine learning system, a deviation between the intermediate signal and the desired output signal for the training input signal can be determined. The third machine learning system may then be trained in a supervised fashion using the feature representation determined for the training input signal and the intermediate signal determined for the training input signal as independent variable for training the third machine learning system and the desired deviation as the dependent variable for training the third machine learning system.</p><p id="p-0032" num="0038">If the first machine learning system or the second machine learning system are neural networks, they may preferably be trained using a gradient descent algorithm in step f. Likewise, if the third machine learning system is a neural network, it may preferably be trained using a gradient descent algorithm in step g.</p><p id="p-0033" num="0039">As detailed above in this description, the desired deviation may also characterize a binary variable indicating whether the distance between the intermediate signal and the desired output signal is equal to or a below a predefined threshold or not.</p><p id="p-0034" num="0040">Example embodiments of the present invention will be discussed with reference to the figures in more detail.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0035" num="0041"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a machine learning system, in accordance with an example embodiment of the present invention.</p><p id="p-0036" num="0042"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a control system comprising a machine learning system controlling an actuator in its environment, in accordance with an example embodiment of the present invention.</p><p id="p-0037" num="0043"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows the control system controlling an at least partially autonomous robot, in accordance with an example embodiment of the present invention.</p><p id="p-0038" num="0044"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows the control system controlling a manufacturing machine, in accordance with an example embodiment of the present invention.</p><p id="p-0039" num="0045"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows the control system controlling an automated personal assistant, in accordance with an example embodiment of the present invention.</p><p id="p-0040" num="0046"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows the control system controlling a medical analysis system, in accordance with an example embodiment of the present invention.</p><p id="p-0041" num="0047"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows the control system controlling a valve, in accordance with an example embodiment of the present invention.</p><p id="p-0042" num="0048"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows a training system for training the machine learning system, in accordance with an example embodiment of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION OF EXAMPLE EMBODIMENTS</heading><p id="p-0043" num="0049"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows an embodiment of a machine learning system (<b>60</b>), wherein the machine learning (<b>60</b>) is configured to determine an output signal (y) for an input signal (x), wherein the output signal (y) characterizes a classification and/or a regression result.</p><p id="p-0044" num="0050">The input signal (x) is provided to a first machine learning system (<b>61</b>), wherein the first machine learning system (<b>61</b>) is part of the machine learning system (<b>60</b>). In the embodiment, the first machine learning system (<b>61</b>) is a neural network. In further embodiments, other machine learning systems such as support vector machines or random forests are possible as first machine learning system (<b>61</b>) as well. The first machine learning system (<b>61</b>) determines a feature representation (f) of the input signal (x). Preferably, the feature representation (f) is in the form of a vector.</p><p id="p-0045" num="0051">The feature representation (f) is then provided to a second machine learning system (<b>62</b>) of the machine learning system (<b>60</b>). The second machine learning system (<b>62</b>) is preferably a neural network. The second machine learning system (<b>62</b>) is configured to determine an intermediate signal (i) based on the feature representation (f). The intermediate signal (i) characterizes a classification and/or a regression result obtained for the feature representation (f). Hence, the intermediate signal (i) can be understood as characterizing a classification and/or regression result for the input signal (x). For example, the intermediate signal (i) may characterize probabilities for a plurality of classes obtained after a softmax operation of the second machine learning system (<b>62</b>).</p><p id="p-0046" num="0052">The intermediate signal (i) and the feature representation (f) are used as input of a third machine learning system (<b>63</b>) that is part of the machine learning system (<b>60</b>). The third machine learning system (<b>63</b>) is configured to predict a deviation (d) between the intermediate signal (i) and a desired output signal of the input signal (x). In the depicted embodiment, the deviation (d) preferably characterizes whether the intermediate signal (i)</p><p id="p-0047" num="0053">The predicted deviation (d) is then forwarded to a decision unit (<b>64</b>) of the machine learning system (<b>60</b>). The decision unit (<b>64</b>) decides based on the predicted deviation (d) whether to adapt the signal or not. If the deviation (d) is less than or equal to a predefined threshold, the intermediate signal (i) is put out as output signal (y) of the machine learning system (<b>60</b>). Otherwise, the decision unit (<b>64</b>) in combination with the second machine learning system (<b>62</b>) determines an adapted signal. In the depicted embodiment, a gradient (g) of the deviation with respect to the intermediate signal (i) is determined and the adapted signal is then determined based a gradient descent of the deviation (d). If the intermediate signal (i) is the result of a softmax operation, the gradient may preferably be determined with respect to an input of the softmax operation (i.e., the logits) and the adapted signal may then be determined by adapting the logits according to a negative direction of the gradient and passing the resulting signal through the softmax operation. In further embodiments (not shown), other optimization methods may be used to determine the adapted signal, wherein the deviation is used as objective value. The other optimization methods may, for example, be evolutionary algorithms. In any case, the adapted signal is then provided as intermediate signal (i) to the third machine learning system (<b>63</b>) to again determine a deviation (d).</p><p id="p-0048" num="0054">This procedure of determining the deviation (d) and adapting the intermediate signal (i) based on the deviation (d) is repeated for a predefined amount of iterations or until the deviation (d) is less than or equal to the predefined threshold. In further embodiments, other exit criteria may be applied, e.g., exiting after a predefined energy budget has been consumed by the computer running the machine learning system (<b>60</b>). In any case, after the exit criterion is fulfilled, the intermediate signal (i) is provided as output signal (y) of the machine learning system (<b>60</b>).</p><p id="p-0049" num="0055"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows an embodiment of an actuator (<b>10</b>) in its environment (<b>20</b>), wherein the actuator (<b>10</b>) is controlled based on an output signal (y) of the machine learning system (<b>60</b>). The actuator (<b>10</b>) interacts with a control system (<b>40</b>). The actuator (<b>10</b>) and its environment (<b>20</b>) will be jointly called actuator system. At preferably evenly spaced points in time, a sensor (<b>30</b>) senses a condition of the actuator system. The sensor (<b>30</b>) may comprise several sensors. Preferably, the sensor (<b>30</b>) is an optical sensor that takes images of the environment (<b>20</b>). An output signal (S) of the sensor (<b>30</b>) (or, in case the sensor (<b>30</b>) comprises a plurality of sensors, an output signal (S) for each of the sensors) which encodes the sensed condition is transmitted to the control system (<b>40</b>).</p><p id="p-0050" num="0056">Thereby, the control system (<b>40</b>) receives a stream of sensor signals (S). It then computes a series of control signals (A) depending on the stream of sensor signals (S), which are then transmitted to the actuator (<b>10</b>).</p><p id="p-0051" num="0057">The control system (<b>40</b>) receives the stream of sensor signals (S) of the sensor (<b>30</b>) in an optional receiving unit (<b>50</b>). The receiving unit (<b>50</b>) transforms the sensor signals (S) into input signals (x). Alternatively, in case of no receiving unit (<b>50</b>), each sensor signal (S) may directly be taken as an input signal (x). The input signal (x) may, for example, be given as an excerpt from the sensor signal (S). Alternatively, the sensor signal (S) may be processed to yield the input signal (x). In other words, the input signal (x) is provided in accordance with the sensor signal (S).</p><p id="p-0052" num="0058">The input signal (x) is then passed on to the machine learning system (<b>60</b>).</p><p id="p-0053" num="0059">The machine learning system (<b>60</b>) is parametrized by parameters (&#x3a6;), which are stored in and provided by a parameter storage (St<sub>1</sub>).</p><p id="p-0054" num="0060">The machine learning system (<b>60</b>) determines an output signal (y) from the input signals (x). The output signal (y) characterizes a classification and/or a regression result of the input signal (x). The output signal (y) is transmitted to an optional conversion unit (<b>80</b>), which converts the output signal (y) into the control signals (A). The control signals (A) are then transmitted to the actuator (<b>10</b>) for controlling the actuator (<b>10</b>) accordingly. Alternatively, the output signal (y) may directly be taken as control signal (A).</p><p id="p-0055" num="0061">The actuator (<b>10</b>) receives control signals (A), is controlled accordingly and carries out an action corresponding to the control signal (A). The actuator (<b>10</b>) may comprise a control logic which transforms the control signal (A) into a further control signal, which is then used to control actuator (<b>10</b>).</p><p id="p-0056" num="0062">In further embodiments, the control system (<b>40</b>) may comprise the sensor (<b>30</b>). In even further embodiments, the control system (<b>40</b>) alternatively or additionally may comprise an actuator (<b>10</b>).</p><p id="p-0057" num="0063">In still further embodiments, it can be envisioned that the control system (<b>40</b>) controls a display (<b>10</b><i>a</i>) instead of or in addition to the actuator (<b>10</b>).</p><p id="p-0058" num="0064">Furthermore, the control system (<b>40</b>) may comprise at least one processor (<b>45</b>) and at least one machine-readable storage medium (<b>46</b>) on which instructions are stored which, if carried out, cause the control system (<b>40</b>) to carry out a method according to an aspect of the invention.</p><p id="p-0059" num="0065">It is also possible that the machine learning system (<b>60</b>) of the control system (<b>40</b>) is configured to perform regression analysis. In this case, the output signal (y) predicted from the machine learning system (<b>60</b>) comprises continuous values, which are then forwarded to the optional conversion unit (<b>80</b>).</p><p id="p-0060" num="0066"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an embodiment in which the control system (<b>40</b>) is used to control an at least partially autonomous robot, e.g., an at least partially autonomous vehicle (<b>100</b>).</p><p id="p-0061" num="0067">The sensor (<b>30</b>) may comprise one or more video sensors and/or one or more radar sensors and/or one or more ultrasonic sensors and/or one or more LiDAR sensors. Some or all of these sensors are preferably but not necessarily integrated in the vehicle (<b>100</b>). The input signal (x) may hence be understood as an input image and the machine learning system (<b>60</b>) as an image classifier.</p><p id="p-0062" num="0068">The image classifier (<b>60</b>) may be configured to detect objects in the vicinity of the at least partially autonomous robot based on the input image (x). The output signal (y) may comprise information, which characterizes where objects are located in the vicinity of the at least partially autonomous robot. The control signal (A) may then be determined in accordance with this information, for example to avoid collisions with the detected objects.</p><p id="p-0063" num="0069">The actuator (<b>10</b>), which is preferably integrated in the vehicle (<b>100</b>), may be given by a brake, a propulsion system, an engine, a drivetrain, or a steering of the vehicle (<b>100</b>). The control signal (A) may be determined such that the actuator (<b>10</b>) is controlled such that vehicle (<b>100</b>) avoids collisions with the detected objects. The detected objects may also be classified according to what the image classifier (<b>60</b>) deems them most likely to be, e.g., pedestrians or trees, and the control signal (A) may be determined depending on the classification. For example, the actuator (<b>10</b>) may be a break and the control signal (A) may be chosen such that the vehicle (<b>100</b>) breaks if the vehicle (<b>100</b>) is closer to a detected object than a predefined threshold.</p><p id="p-0064" num="0070">Alternatively or additionally, the control signal (A) may also be used to control the display (<b>10</b><i>a</i>), e.g., for displaying the objects detected by the image classifier (<b>60</b>). It can also be imagined that the control signal (A) may control the display (<b>10</b><i>a</i>) such that it produces a warning signal, if the vehicle (<b>100</b>) is close to colliding with at least one of the detected objects. The warning signal may be a warning sound and/or a haptic signal, e.g., a vibration of a steering wheel of the vehicle.</p><p id="p-0065" num="0071">In further embodiments, the at least partially autonomous robot may be given by another mobile robot (not shown), which may, for example, move by flying, swimming, diving or stepping. The mobile robot may, inter alia, be an at least partially autonomous lawn mower, or an at least partially autonomous cleaning robot. In all of the above embodiments, the control signal (A) may be determined such that propulsion unit and/or steering and/or brake of the mobile robot are controlled such that the mobile robot may avoid collisions with said identified objects.</p><p id="p-0066" num="0072">In a further embodiment, the at least partially autonomous robot may be given by a gardening robot (not shown), which uses the sensor (<b>30</b>), preferably an optical sensor, to determine a state of plants in the environment (<b>20</b>). The actuator (<b>10</b>) may control a nozzle for spraying liquids and/or a cutting device, e.g., a blade. Depending on an identified species and/or an identified state of the plants, an control signal (A) may be determined to cause the actuator (<b>10</b>) to spray the plants with a suitable quantity of suitable liquids and/or cut the plants.</p><p id="p-0067" num="0073">In even further embodiments, the at least partially autonomous robot may be given by a domestic appliance (not shown), like e.g. a washing machine, a stove, an oven, a microwave, or a dishwasher. The sensor (<b>30</b>), e.g., an optical sensor, may detect a state of an object which is to undergo processing by the household appliance. For example, in the case of the domestic appliance being a washing machine, the sensor (<b>30</b>) may detect a state of the laundry inside the washing machine. The control signal (A) may then be determined depending on a detected material of the laundry.</p><p id="p-0068" num="0074">Shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> is an embodiment in which the control system (<b>40</b>) is used to control a manufacturing machine (<b>11</b>), e.g., a punch cutter, a cutter, a gun drill or a gripper, of a manufacturing system (<b>200</b>), e.g., as part of a production line. The manufacturing machine may comprise a transportation device, e.g., a conveyer belt or an assembly line, which moves a manufactured product (<b>12</b>). The control system (<b>40</b>) controls an actuator (<b>10</b>), which in turn controls the manufacturing machine (<b>11</b>). The actuator (<b>10</b>) may, for example, be an electric or hydraulic drive that opens or closes a gripper.</p><p id="p-0069" num="0075">The sensor (<b>30</b>) may be given by an optical sensor which captures properties of, e.g., a manufactured product (<b>12</b>). The machine learning system (<b>60</b>) may hence be understood as an image classifier.</p><p id="p-0070" num="0076">The image classifier (<b>60</b>) may determine a position of the manufactured product (<b>12</b>) with respect to the transportation device. The actuator (<b>10</b>) may then be controlled depending on the determined position of the manufactured product (<b>12</b>) for a subsequent manufacturing step of the manufactured product (<b>12</b>). For example, the actuator (<b>10</b>) may be controlled to cut the manufactured product at a specific location of the manufactured product itself. Alternatively, it may be envisioned that the image classifier (<b>60</b>) classifies, whether the manufactured product is broken or exhibits a defect. The actuator (<b>10</b>) may then be controlled as to remove the manufactured product from the transportation device.</p><p id="p-0071" num="0077">Shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is an embodiment in which the control system (<b>40</b>) is used for controlling an automated personal assistant (<b>250</b>). The sensor (<b>30</b>) may be an optic sensor, e.g., for receiving video images of a gestures of a user (<b>249</b>). Alternatively, the sensor (<b>30</b>) may also be an audio sensor, e.g., for receiving a voice command of the user (<b>249</b>).</p><p id="p-0072" num="0078">The control system (<b>40</b>) then determines control signals (A) for controlling the automated personal assistant (<b>250</b>). The control signals (A) are determined in accordance with the sensor signal (S) of the sensor (<b>30</b>). The sensor signal (S) is transmitted to the control system (<b>40</b>). For example, the machine learning system (<b>60</b>) may be configured to, e.g., carry out a gesture recognition algorithm to identify a gesture made by the user (<b>249</b>). The control system (<b>40</b>) may then determine a control signal (A) for transmission to the automated personal assistant (<b>250</b>). It then transmits the control signal (A) to the automated personal assistant (<b>250</b>). Alternatively, the machine learning system (<b>60</b>) may be configured for audio classification to classify a voice command uttered by the user (<b>249</b>)</p><p id="p-0073" num="0079">For example, the control signal (A) may be determined in accordance with the identified user gesture or the identified voice command recognized by the machine learning system (<b>60</b>). It may comprise information that causes the automated personal assistant (<b>250</b>) to retrieve information from a database and output this retrieved information in a form suitable for reception by the user (<b>249</b>).</p><p id="p-0074" num="0080">In further embodiments, it may be envisioned that instead of the automated personal assistant (<b>250</b>), the control system (<b>40</b>) controls a domestic appliance (not shown) controlled in accordance with the identified user gesture. The domestic appliance may be a washing machine, a stove, an oven, a microwave or a dishwasher.</p><p id="p-0075" num="0081">Shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is an embodiment of a medical imaging system (<b>500</b>) controlled by the control system (<b>40</b>). The imaging system may, for example, be an MRI apparatus, x-ray imaging apparatus or ultrasonic imaging apparatus. The sensor (<b>30</b>) may, for example, be an imaging sensor which takes at least one image of a patient, e.g., displaying different types of body tissue of the patient.</p><p id="p-0076" num="0082">The machine learning system (<b>60</b>) may then determine a classification of at least a part of the sensed image. The at least part of the image is hence used as input image (x) to the machine learning system (<b>60</b>). The machine learning system (<b>60</b>) may hence be understood as an image classifier.</p><p id="p-0077" num="0083">The control signal (A) may then be chosen in accordance with the classification, thereby controlling a display (<b>10</b><i>a</i>). For example, the image classifier (<b>60</b>) may be configured to detect different types of tissue in the sensed image, e.g., by classifying the tissue displayed in the image into either malignant or benign tissue. This may be done by means of a semantic segmentation of the input image (x) by the image classifier (<b>60</b>). The control signal (A) may then be determined to cause the display (<b>10</b><i>a</i>) to display different tissues, e.g., by displaying the input image (x) and coloring different regions of identical tissue types in a same color.</p><p id="p-0078" num="0084">In further embodiments (not shown) the imaging system (<b>500</b>) may be used for non-medical purposes, e.g., to determine material properties of a workpiece. In these embodiments, the image classifier (<b>60</b>) may be configured to receive an input image (x) of at least a part of the workpiece and perform a semantic segmentation of the input image (x), thereby classifying the material properties of the workpiece. The control signal (A) may then be determined to cause the display (<b>10</b><i>a</i>) to display the input image (x) as well as information about the detected material properties.</p><p id="p-0079" num="0085"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an embodiment of the control system (<b>40</b>) for controlling a valve (<b>10</b>). In the embodiment, the sensor (<b>30</b>) is a pressure sensor that senses a pressure of a fluid that can be output by the valve (<b>10</b>). In particular, the machine learning system (<b>60</b>) may be configured to determine an injection amount of fluid dispensed by the valve (<b>10</b>) based on a time series (x) of pressure values.</p><p id="p-0080" num="0086">In particular, the valve (<b>10</b>) may be part of a fuel injector of an internal combustion engine, wherein the valve (<b>10</b>) is configured to inject the fuel into the internal combustion engine. Based on the determined injection quantity, the valve (<b>10</b>) can then be controlled in future injection processes in such a way that an excessively large quantity of injected fuel or an excessively small quantity of injected fuel is compensated for accordingly.</p><p id="p-0081" num="0087">Alternatively, it is also possible that the valve (<b>10</b>) is part of an agricultural fertilizer system, wherein the valve (<b>10</b>) is configured to spray a fertilizer. Based on the determined amount of fertilizer sprayed, the valve (<b>10</b>) can then be controlled in future spraying operations in such a way that an excessive amount of fertilizer sprayed or an insufficient amount of fertilizer sprayed is compensated for accordingly.</p><p id="p-0082" num="0088"><figref idref="DRAWINGS">FIG. <b>8</b></figref> shows an embodiment of a training system (<b>140</b>) for training the machine learning system (<b>60</b>) of the control system (<b>40</b>) by means of a training data set (T). The training data set (T) comprises a plurality of input signals (x<sub>i</sub>) which are used for training the machine learning system (<b>60</b>), wherein the training data set (T) further comprises, for each input signal (x<sub>i</sub>), a desired output signal (t<sub>i</sub>) which corresponds to the input signal (x<sub>i</sub>) and characterizes a classification and/or regression result of the input signal (x<sub>i</sub>).</p><p id="p-0083" num="0089">Training is conducted in two stages. In a first stage, a training data unit (<b>150</b>) accesses a computer-implemented database (St<sub>2</sub>), the database (St<sub>2</sub>) providing the training data set (T). The training data unit (<b>150</b>) determines from the training data set (T) preferably randomly at least one input signal (x<sub>i</sub>) and the desired output signal (t<sub>i</sub>) corresponding to the input signal (x<sub>i</sub>) and transmits the input signal (x<sub>i</sub>) to the machine learning system (<b>60</b>). The machine learning system (<b>60</b>) determines an intermediate signal (y<sub>i</sub>) based on the input signal (x<sub>i</sub>).</p><p id="p-0084" num="0090">The desired output signal (t<sub>i</sub>) and the determined intermediate signal (y<sub>i</sub>) are transmitted to a modification unit (<b>180</b>).</p><p id="p-0085" num="0091">Based on the desired output signal (t<sub>i</sub>) and the determined intermediate signal (y<sub>i</sub>), the modification unit (<b>180</b>) then determines new parameters (&#x3a6;&#x2032;) for the machine learning system (<b>60</b>). Specifically, the new parameters (&#x3a6;&#x2032;) are determined for the second machine learning system (<b>62</b>). In further embodiments, the new parameters (&#x3a6;&#x2032;) may also comprise new parameters (&#x3a6;&#x2032;) of the first machine learning system (<b>61</b>). For determining the new parameters (&#x3a6;&#x2032;), the modification unit (<b>180</b>) compares the desired output signal (t<sub>i</sub>) and the determined intermediate signal (y<sub>i</sub>) using a loss function. The loss function determines a first loss value that characterizes how far the determined intermediate signal (y<sub>i</sub>) differs from the desired output signal (t<sub>i</sub>). In the given embodiment, a negative log-likehood function is used as the loss function. Other loss functions are also conceivable in alternative embodiments.</p><p id="p-0086" num="0092">Furthermore, it is possible that the determined intermediate signal (y<sub>i</sub>) and the desired output signal (t<sub>i</sub>) each comprise a plurality of sub-signals, for example in the form of tensors, wherein a sub-signal of the desired output signal (t<sub>i</sub>) corresponds to a sub-signal of the determined intermediate signal (y<sub>i</sub>). It is possible, for example, that the machine learning system (<b>60</b>) is configured for object detection and a first sub-signal characterizes a probability of occurrence of an object with respect to a part of the input signal (x<sub>i</sub>) and a second sub-signal characterizes the exact position of the object. If the determined intermediate signal (y<sub>i</sub>) and the desired output signal (t<sub>i</sub>) comprise a plurality of corresponding sub-signals, a second loss value is preferably determined for each corresponding sub-signal by means of a suitable loss function and the determined second loss values are suitably combined to form the first loss value, for example by means of a weighted sum.</p><p id="p-0087" num="0093">The modification unit (<b>180</b>) determines the new parameters (&#x3a6;&#x2032;) based on the first loss value. In the given embodiment, this is done using a gradient descent method, preferably stochastic gradient descent, Adam, or AdamW. In further embodiments, training may also be based on an evolutionary algorithm or a second-order method for training neural networks.</p><p id="p-0088" num="0094">In other preferred embodiments, the first stage of training is repeated iteratively for a predefined number of iteration steps or repeated iteratively until the first loss value falls below a predefined threshold value. Alternatively or additionally, it is also possible that the first stage of training is terminated when an average first loss value with respect to a test or validation data set falls below a predefined threshold value. In at least one of the iterations the new parameters (&#x3a6;&#x2032;) determined in a previous iteration are used as parameters (&#x3a6;) of the machine learning system (<b>60</b>), in particular as parameters of the second machine learning system (<b>62</b>) or the first machine learning system (<b>61</b>) and the second machine learning system (<b>62</b>).</p><p id="p-0089" num="0095">In a second stage of training, the new parameters (&#x3a6;&#x2032;) of the third machine learning system (<b>63</b>) are determined. For this, an input signal (x<sub>i</sub>) and a desired output signal (t<sub>i</sub>) are determined from the dataset (T) as in the first stage of training. A feature representation (f) is determined for the input signal (x<sub>i</sub>) from the first machine learning system (<b>61</b>) and an intermediate signal (y<sub>i</sub>) is determined from the second machine learning system (<b>62</b>). The feature representation (f) and intermediate representation (y<sub>i</sub>) are used as input for the third machine learning system (<b>63</b>). Additionally, the output of a hidden layer of the second machine learning system (<b>62</b>) may be used as input of the third machine learning system (<b>63</b>).</p><p id="p-0090" num="0096">Based on the provided input, the third machine learning system (<b>63</b>) is trained in the second stage to predict a deviation of the determined intermediate signal (y<sub>i</sub>) to the desired output signal (t<sub>i</sub>). The deviation may, for example, be characterized by a metric (e.g., Euclidean distance) or a semimetric (e.g., cosine distance). The deviation is determined by the modification unit (<b>180</b>) and subsequently used in the modification unit (<b>180</b>) in order to determine a gradient of the deviation with respect to the parameters of the third machine learning system (<b>63</b>). Based on this gradient, the modification unit (<b>180</b>) determines new parameters (&#x3a6;&#x2032;) of the third machine learning system. As the first stage, the second stage may be repeated iteratively for a predefined number of iteration steps or repeated iteratively until the deviation falls below a predefined threshold value. Alternatively or additionally, it is also possible that the second stage of training is terminated when an average deviation with respect to a test or validation data set falls below a predefined threshold. In at least one of the iterations the new parameters (&#x3a6;&#x2032;) determined in a previous iteration are used as parameters (&#x3a6;) of the machine learning system (<b>60</b>), in particular as parameters of the third machine learning system (<b>63</b>).</p><p id="p-0091" num="0097">Furthermore, the training system (<b>140</b>) may comprise at least one processor (<b>145</b>) and at least one machine-readable storage medium (<b>146</b>) containing instructions which, when executed by the processor (<b>145</b>), cause the training system (<b>140</b>) to execute a training method according to one of the aspects of the invention.</p><p id="p-0092" num="0098">The term &#x201c;computer&#x201d; may be understood as covering any devices for the processing of pre-defined calculation rules. These calculation rules can be in the form of software, hardware or a mixture of software and hardware.</p><p id="p-0093" num="0099">In general, a plurality can be understood to be indexed, that is, each element of the plurality is assigned a unique index, preferably by assigning consecutive integers to the elements contained in the plurality. Preferably, if a plurality comprises N elements, wherein N is the number of elements in the plurality, the elements are assigned the integers from 1 to N. It is also understood that elements of the plurality can be accessed by their index.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method for determining an output signal characterizing a classification and/or a regression result of an input signal comprising the following steps:<claim-text>a. determining a feature representation characterizing the input signal;</claim-text><claim-text>b. determining an intermediate signal characterizing a classification and/or regression result of the feature representation;</claim-text><claim-text>c. predicting, based on the feature representation and the intermediate signal, a deviation of the intermediate signal from a desired output signal of the input signal;</claim-text><claim-text>d. adapting the intermediate signal according to the determined deviation thereby determining an adapted signal; and</claim-text><claim-text>e. providing the adapted signal as the output signal.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the steps c. and d. are repeated iteratively until an exit criterion is fulfilled, and wherein the adapted signal is used as intermediate signal in a next iteration.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the deviation is predicted by a differentiable model and the intermediate signal is adapted based on a gradient of the deviation with respect to the intermediate signal.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the feature representation is determined by a first machine learning system using the input signal as input of the first machine learning system; and/or</claim-text><claim-text>the intermediate signal is determined by a second machine learning system using the feature representation as input of the second machine learning system; and/or</claim-text><claim-text>the deviation is determined by a third machine learning system using the feature representation and the intermediate signal as input of the third machine learning system.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the first machine learning system, the second machine learning system, and the third machine learning system are parts of a fourth machine learning system.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the second machine learning system is a neural network and an output of a hidden layer of the second machine learning system is used as additional input to the third machine learning system for determining the deviation.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. A computer-implemented method for training a fourth machine learning system including a first machine learning model, a second machine learning model, and a third machine learning model, the method comprising the following steps:<claim-text>training (i) the second machine learning model, or (ii) the first machine learning model and the second machine learning model, to determine a desired output signal for a provided first training input signal;</claim-text><claim-text>after training the second machine learning model or after training the first machine learning model and the second machine learning model, training the third machine learning model to determine a deviation of an intermediate signal determined from the first machine learning model and the second machine learning model for a provided second training input signal to a desired output signal for the supplied second training input signal, wherein the first machine learning model and the second machine learning model is not trained.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the input signal includes a sensor signal.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a robot is controlled based on the output signal.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A machine learning system comprising:<claim-text>a fourth machine learning system including a first machine leaning system, a second machine learning system, and a third learning system, wherein the first machine system is configured to determine a feature representation characterizing an input signal, the second machine learning system is configured to determine an intermediate signal characterizing a classification and/or regression result of the feature representation, and the third machine learning system is configured to determine, based on the feature representation and the intermediate signal, a deviation of the intermediate signal from a desired output signal of the input signal, and wherein the fourth machine learning system is configured to adapt the intermediate signal according to the determined deviation thereby determining an adapted signal, and provide the adapted signal as an output signal characterizing a classification result and/or a regression result of the input signal.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A training system configured to train a fourth machine learning system including a first machine learning model, a second machine learning model, and a third machine learning model, the training system configured to:<claim-text>train (i) the second machine learning model, or (ii) the first machine learning model and the second machine learning model, to determine a desired output signal for a provided first training input signal;</claim-text><claim-text>after training the second machine learning model, or after training the first machine learning model and the second machine learning model, train the third machine learning model to determine a deviation of an intermediate signal determined from the first machine learning model and the second machine learning model for a provided second training input signal to a desired output signal for the supplied second training input signal, wherein the first machine learning model and the second machine learning model is not trained.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. A non-transitory machine-readable storage medium on which is stored a computer program for determining an output signal characterizing a classification and/or a regression result of an input signal, the computer program, when executed by a processor, causing the processor to perform the following steps:<claim-text>a. determining a feature representation characterizing the input signal;</claim-text><claim-text>b. determining an intermediate signal characterizing a classification and/or regression result of the feature representation;</claim-text><claim-text>c. predicting, based on the feature representation and the intermediate signal, a deviation of the intermediate signal from a desired output signal of the input signal;</claim-text><claim-text>d. adapting the intermediate signal according to the determined deviation thereby determining an adapted signal; and</claim-text><claim-text>e. providing the adapted signal as the output signal</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005299A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005299</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17783723</doc-number><date>20191216</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>40</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>16</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>45</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>40</main-group><subgroup>161</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>70</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>21</main-group><subgroup>32</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10016</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30204</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30196</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">DETERMINATION SYSTEM, DETERMINATION METHOD, COMPUTER PROGRAM, AND AUTHENTICATION SYSTEM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NEC Corporation</orgname><address><city>Minato-ku, Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>HAYASAKA</last-name><first-name>Akihiro</first-name><address><city>Tokyo</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>NEC Corporation</orgname><role>03</role><address><city>Minato-ku, Tokyo</city><country>JP</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2019/049178</doc-number><date>20191216</date></document-id><us-371c12-date><date>20220609</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A determination system includes: a projection control unit that controls a projection unit to project a random marker within an angle of view of an imaging unit; an acquisition unit that obtains an image of a target person including the marker from the imaging unit; and a determination unit that determines whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image. According to such a determination system, it is possible to accurately determine whether or not the target person is a living body. Therefore, for example, it is possible to avoid a breakthrough of biometric authentication by an illegal method, or the like.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="166.71mm" wi="102.70mm" file="US20230005299A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="81.03mm" wi="44.62mm" file="US20230005299A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="124.97mm" wi="123.36mm" file="US20230005299A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="127.17mm" wi="140.46mm" file="US20230005299A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="189.65mm" wi="104.73mm" file="US20230005299A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="153.25mm" wi="84.07mm" file="US20230005299A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="148.67mm" wi="116.08mm" file="US20230005299A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="218.19mm" wi="109.81mm" file="US20230005299A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="223.27mm" wi="109.81mm" file="US20230005299A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present invention relates to a determination system, a determination method, a computer program, and an authentication system that make a determination related to a target person.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">A known system of this type detects fraud when biometric authentication is performed.</p><p id="p-0004" num="0003">For example, Patent Literature 1 discloses a technique/technology of detecting spoofing by utilizing a difference between a biological distance and a non-biological distance. Patent Literature 2 discloses a technique/technology of detecting spoofing by comparing an image captured in a pupil of a subject with a particular image. Patent Literature 3 discloses a technique/technology of displaying a particular background image in an authentication place and of detecting spoofing by using brightness of a captured image.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0005" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0004">Patent Literature 1: International Publication No. WO2009/110323</li>    <li id="ul0001-0002" num="0005">Patent Literature 2: JP2007-072861A</li>    <li id="ul0001-0003" num="0006">Patent Literature 3: JP2007-026330A</li></ul></p><heading id="h-0005" level="1">SUMMARY</heading><heading id="h-0006" level="1">Technical Problem</heading><p id="p-0006" num="0007">The determination of spoofing uses various methods. In the techniques/technologies described in the respective Patent Literatures, however, an apparatus configuration and processing contents are complicated, or a determination accuracy becomes low depending on the circumstances, which are technically problematic.</p><p id="p-0007" num="0008">The present invention has been made in view of the above problems, and it is an example object of the present invention to provide a determination system, a determination method, a computer program, and an authentication apparatus that are configured accurately determine whether or not a target person is a living body.</p><heading id="h-0007" level="1">Solution to Problem</heading><p id="p-0008" num="0009">A determination system according to an example aspect of the present invention includes: a projection control unit that controls a projection unit to project a random marker within an angle of view of an imaging unit; an acquisition unit that obtains an image of a target person including the marker from the imaging unit; and a determination unit that determines whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</p><p id="p-0009" num="0010">A determination method according to an example aspect of the present invention includes: controlling a projection unit to project a random marker within an angle of view of an imaging unit; obtaining an image of a target person including the marker from the imaging unit; and determining whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</p><p id="p-0010" num="0011">A computer program according to an example aspect of the present invention operates a computer: to control a projection unit to project a random marker within an angle of view of an imaging unit; to obtain an image of a target person including the marker from the imaging unit; and to determine whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</p><p id="p-0011" num="0012">An authentication system according to an example aspect of the present invention includes: a projection control unit that controls a projection unit to project a random marker within an angle of view of an imaging unit; an acquisition unit that obtains an image of a target person including the marker from the imaging unit; a determination unit that determines whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image; and an execution unit that performs an authentication process on the target person when it is determined that the target person is a living body.</p><heading id="h-0008" level="1">Effect of the Invention</heading><p id="p-0012" num="0013">According to the determination system, the determination method, the computer program, and the authentication system in the respective aspects described above, it is possible to accurately determine whether or not a target person is a living body. This makes it possible to detect, for example, spoofing by a photograph or the like and to appropriately perform biometric authentication.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0013" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating a functional configuration of a determination system according to an example embodiment.</p><p id="p-0014" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating a hardware configuration of a determination system according to the example embodiment.</p><p id="p-0015" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating an overall configuration of an authentication system according to the example embodiment.</p><p id="p-0016" num="0017"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart illustrating a flow of operation of the authentication system according to the example embodiment.</p><p id="p-0017" num="0018"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an image diagram illustrating an example of marker projection in normal times.</p><p id="p-0018" num="0019"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is an image diagram illustrating an example of marker projection in attack.</p><p id="p-0019" num="0020"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> are comparative diagrams illustrating a difference between a captured image in normal times and a captured image in attack.</p><p id="p-0020" num="0021"><figref idref="DRAWINGS">FIG. <b>8</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> are comparative diagrams illustrating an example of projecting a marker to overlap a target person.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">DESCRIPTION OF EXAMPLE EMBODIMENT</heading><p id="p-0021" num="0022">Hereinafter, a determination system, a determination method, a computer program, and an authentication system according to an example embodiment will be described with reference to the drawings.</p><heading id="h-0011" level="2">&#x3c;Determination System&#x3e;</heading><p id="p-0022" num="0023">The determination system according to the example embodiment will be described with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref> and <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><heading id="h-0012" level="2">(Functional Configuration)</heading><p id="p-0023" num="0024">Referring first to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a functional configuration of the determination system according to the example embodiment will be described. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a block diagram illustrating the functional configuration of the determination system according to the example embodiment.</p><p id="p-0024" num="0025">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a determination system <b>10</b> according to the example embodiment is configured as an apparatus for determining whether or not a target person of an authentication process (in other words, an imaging target of a face image) is a living body. The determination system <b>10</b> includes, as processing blocks for realizing its function, a projection control unit <b>101</b>, an image acquisition unit <b>102</b>, and a living body determination unit <b>103</b>.</p><p id="p-0025" num="0026">The projection control unit <b>101</b> is configured to control the operation of a projection unit that projects a marker (e.g., a projector <b>20</b> described later). The projection control unit <b>101</b> is allowed to control the projection unit to project a random marker so as to overlap a background of the target person or the target person. The projection control unit <b>101</b>, for example, stores a plurality of types of markers in advance (specifically, markers with different colors, shapes, sizes, or the like) and selects one or more markers at random from among them to project. Alternatively, the projection control unit <b>101</b> may automatically generate and project a marker at each time.</p><p id="p-0026" num="0027">The image acquisition unit <b>102</b> is configured to obtain an image of the target person for whom it is determined whether or not to be a living body. The image acquisition unit <b>102</b> obtains an image of the target person including the marker projected by the projection control unit <b>101</b>. The image acquisition unit <b>102</b> may also be configured to obtain a plurality of temporally continuous images (in other words, a moving image). The image obtained by image acquisition unit <b>102</b> is configured to be outputted to the living body determination unit <b>103</b></p><p id="p-0027" num="0028">The living body determination unit <b>103</b> determines whether or not the target person is a living body on the basis of the image obtained by the image acquisition unit <b>102</b>. More specifically, the living body determining unit <b>103</b> determines whether the target person is actually in front of an imaging unit (e.g., a camera <b>30</b> described later) or &#x201c;spoofing&#x201d; by a photograph or the like is performed. The living body determination unit <b>103</b> determines whether or not the target person is a living body on the basis of a state of the marker included in the image of the target person (i.e., the marker projected by the projection control unit <b>101</b>). A specific determination method in the living body determination unit <b>103</b> will be described in detail later. A result of the determination by the living body determining unit <b>103</b> is configured to be outputted to an external apparatus (e.g., an authentication apparatus <b>40</b> described later).</p><heading id="h-0013" level="2">(Hardware Configuration)</heading><p id="p-0028" num="0029">Next, with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a hardware configuration of the determination system <b>10</b> according to the example embodiment will be described. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram illustrating the hardware configuration of the determination system according to the example embodiment.</p><p id="p-0029" num="0030">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the determination system <b>10</b> according to the example embodiment includes a CPU (Central Processing Unit) <b>11</b>, a RAM (Random Access Memory) <b>12</b>, a ROM (Read Only Memory) <b>13</b>, and a storage apparatus <b>14</b>. The determination system <b>10</b> may further include an input apparatus <b>15</b> and an output apparatus <b>16</b>. The CPU <b>11</b>, the RAM <b>12</b>, the ROM <b>13</b>, the storage apparatus <b>14</b>, the input apparatus <b>15</b>, and the output apparatus <b>16</b> are connected through a data bus <b>17</b>.</p><p id="p-0030" num="0031">The CPU <b>11</b> reads a computer program. For example, the CPU <b>11</b> is configured to read a computer program stored in at least one of the RAM <b>12</b>, the ROM <b>13</b> and the storage apparatus <b>14</b>. Alternatively, the CPU <b>11</b> may read a computer program stored by a computer readable recording medium by using a not-illustrated recording medium reading apparatus. The CPU <b>11</b> may obtain (i.e., read) a computer program from a not-illustrated apparatus that is located outside the determination system <b>10</b> through a network interface. The CPU <b>11</b> controls the RAM <b>12</b>, the storage apparatus <b>14</b>, the input apparatus <b>15</b>, and the output apparatus <b>16</b> by executing the read computer program. Especially in the example embodiment, when the CPU <b>11</b> executes the read computer program, a functional block for determining whether or not the target person is a living body is implemented in the CPU <b>11</b>.</p><p id="p-0031" num="0032">The RAM <b>12</b> temporarily stores the computer program to be executed by the CPU <b>11</b>. The RAM <b>12</b> temporarily stores the data that is temporarily used by the CPU <b>11</b> when the CPU <b>11</b> executes the computer program. The RAM <b>12</b> may be, for example, a D-RAM (Dynamic RAM).</p><p id="p-0032" num="0033">The ROM <b>13</b> stores the computer program to be executed by the CPU <b>11</b>. The ROM <b>13</b> may otherwise store fixed data. The ROM <b>13</b> may be, for example, a P-ROM (Programmable ROM).</p><p id="p-0033" num="0034">The storage apparatus <b>14</b> stores the data that is stored for a long term by the determination system <b>10</b>. The storage apparatus <b>14</b> may operate as a temporary storage apparatus of the CPU <b>11</b>. The storage apparatus <b>14</b> may include, for example, at least one of a hard disk apparatus, a magneto-optical disk apparatus, an SSD (Solid State Drive), and a disk array apparatus.</p><p id="p-0034" num="0035">The input apparatus <b>15</b> is an apparatus that receives an input instruction from a user of the determination system <b>10</b>. The input apparatus <b>15</b> may include, for example, at least one of a keyboard, a mouse, and a touch panel.</p><p id="p-0035" num="0036">The output apparatus <b>16</b> is an apparatus that outputs information about the determination system <b>10</b> to the outside. For example, the output apparatus <b>16</b> may be a display apparatus (e.g., a display) that is configured to display the information about the determination system <b>10</b>.</p><heading id="h-0014" level="2">&#x3c;Authentication System&#x3e;</heading><p id="p-0036" num="0037">Next, an authentication system including the determination system <b>10</b> described above will be described with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref> to <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p><heading id="h-0015" level="2">(System Configuration)</heading><p id="p-0037" num="0038">First, with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, an overall configuration of the authentication system according to the example embodiment will be described. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram illustrating the overall configuration of the authentication system according to the example embodiment.</p><p id="p-0038" num="0039">In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, an authentication system <b>1</b> according to the example embodiment is configured as a system for performing an authentication process that uses a face image of the target person (so-called face authentication). The authentication system <b>1</b> includes the determination system <b>10</b> described above, a projector <b>20</b>, a camera <b>30</b>, and an authentication apparatus <b>40</b>.</p><p id="p-0039" num="0040">The projector <b>20</b> is configured to project a random marker in accordance with an instruction of the projection control unit <b>101</b> in the determination system <b>10</b>. The projector <b>20</b> is disposed in a position in which the marker can be projected within an angle of view of the camera <b>30</b>. The projector <b>20</b> may project the marker with visible light or invisible light such as near infrared light.</p><p id="p-0040" num="0041">The camera <b>30</b> is configured to capture an image of the target person of the authentication process (especially, an image around a face). Furthermore, the camera <b>30</b> is disposed in a position in which the marker projected from the projector <b>20</b> together with target person can be imaged. The image obtained by the camera <b>30</b> is configured to be outputted to the image acquisition unit <b>102</b> in the determination system <b>10</b>. Incidentally, when the projector <b>20</b> projects the marker with invisible light, the camera <b>30</b> may be configured as a camera that is configured to image invisible light.</p><p id="p-0041" num="0042">The authentication apparatus <b>40</b> performs face authentication of the target person on the basis of the image captured by the camera <b>30</b>. In particular, the authentication apparatus <b>40</b> is configured to perform the authentication process on the basis of a determination result of the determination system <b>10</b> (i.e., whether the target person is a living body). The use of the determination result of the determination system <b>10</b> in the authentication apparatus <b>40</b> will be described in detail later. The authentication apparatus <b>40</b> may be configured to perform biometric authentication other than the face authentication (e.g., iris authentication, etc.) in place of the face authentication. A detailed description of specific contents of the authentication process performed by the authentication apparatus <b>40</b> will be omitted here because the existing techniques can be adapted. The authentication apparatus <b>40</b> may be configured, for example, as a cloud.</p><heading id="h-0016" level="2">(Flow of Operation)</heading><p id="p-0042" num="0043">Next, with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a flow of operation of the authentication system <b>1</b> according to the example embodiment will be described. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flow chart illustrating the flow of the operation of the authentication system according to the example embodiment.</p><p id="p-0043" num="0044">As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the authentication system <b>1</b> according to the example embodiment firstly determines whether or not there is a target person of the authentication process (step S<b>101</b>). Whether or not there is a target person can be determined, for example, by detecting the presence of an object within the angle of view of a camera. The presence of the target person may be detected by the camera <b>30</b> or another not-illustrated sensor or the like. Alternatively, the presence of the target person may be detected when there is a terminal operated by the target person. When it is determined that there is no target person (the step S<b>101</b>: NO), the subsequent steps are omitted and a series of operation steps is ended. In this case, the step S<b>101</b> may be restarted after a lapse of a predetermined period.</p><p id="p-0044" num="0045">When it is determined that there is a target person (the step S<b>101</b>: YES), the projection control unit <b>101</b> randomly selects a marker to be projected (step S<b>102</b>). Then, the projection control unit <b>101</b> controls the projector <b>20</b> to project the selected marker. At this time, the projection control unit <b>101</b> may specify a projection position of the marker. Specifically, the projection control unit <b>101</b> may give an instruction to project the marker on the background of the target person (in other words, a position that does not overlap the target person), or give an instruction to project the marker at a position that allows at least a partial overlap of the target person. When projecting the marker to overlap the target person, however, it is preferable to project it while avoiding the position of eyes so as not to give a dazzling feeling to the target person, or to project it with invisible light. Furthermore, an instruction may be given to project a plurality of markers at different positions.</p><p id="p-0045" num="0046">When the marker is projected, the image acquisition unit <b>102</b> obtains an image of the target person from the camera <b>30</b> (step S<b>104</b>). This image also includes the marker projected by the projector <b>20</b>. When obtaining a moving image of the target person, the image acquisition unit <b>102</b> may continuously obtain images of the target person.</p><p id="p-0046" num="0047">Subsequently, the living body determination unit <b>103</b> determines whether or not the target person is a living body on the basis of the image of the target person obtained by the image acquisition unit <b>102</b> (step S<b>105</b>). The living body determination unit <b>103</b> determines whether or not the target person is a living body, depending on whether or not the marker included in the image of the target person is captured in an expected state. Specifically, the living body determination unit <b>103</b> determines that the target person is a living body when the state of the marker included in the image of the target person is as expected, and determines that the target person is not a living body when it is not as expected. The living body determination unit <b>103</b> determines whether or not the state of the marker is as expected, for example, by using at least one of a position, an angle, and a size of the marker. The living body determination unit <b>103</b> may determine whether or not the target person is a living body, by using a parameter other than the position, the angle and the size of the marker (e.g., color and shape, etc.).</p><p id="p-0047" num="0048">The living body determination unit <b>103</b>, for example, projects the marker to a wall in a condition where there is no target person in advance, and stores a captured image at that time as a reference image. In this way, it is possible to determine whether or not the state of the marker is as expected by comparing the marker with the reference image. More specifically, the living body determination unit <b>103</b> is configured to determine whether or not the target person is a living body on the basis of a degree of matching of (at least one of) the position, the angle, the size between the marker included in the image obtained by imaging the target person and the marker in the reference image. The existing method may be adopted, as appropriate, to the derivation of the degree of matching, but common template matching or pattern matching in an imaging process, such as, for example, a SSD (Sum Of Squared Difference) and a SAD (Sum of Absolute Difference), may be used.</p><p id="p-0048" num="0049">When it is determined that the target person is a living body (the step S<b>105</b>: YES), the authentication apparatus <b>40</b> performs the authentication process (in this example, face authentication that uses a face image) on the target person (step S<b>106</b>). Specifically, the authentication apparatus <b>40</b> extracts a face area from the image of the target person and determines whether or not the face of the target person matches a face registered in advance. Incidentally, the face authentication may use the image of the target person as it is, or may use a feature quantity (e.g., brightness, etc.) extracted from the image of the target person. When the authentication process is ended, the authentication apparatus <b>40</b> outputs a result (e.g., &#x201c;authentication OK&#x201d; or &#x201c;authentication NG&#x201d;).</p><p id="p-0049" num="0050">On the other hand, when it is determined that the target person is not a living body (the step S<b>105</b>: NO), the authentication apparatus <b>40</b> does not perform the face authentication (i.e., the step S<b>106</b> is omitted). When the target person is not a living body, for example, &#x201c;spoofing&#x201d; by a photograph or the like is suspected. As a result of the authentication process being not performed, for example, it is possible to avoid an attack from a user who attempts to illegally break through the authentication process. When it determining that the target person is not a living body, the living body determination unit <b>103</b> may give a notice indicating that spoofing is performed. Specifically, the living body determining unit <b>103</b> may output a warning display or a warning sound to a system administrator or manager or the like.</p><heading id="h-0017" level="2">(Specific Example of Operation)</heading><p id="p-0050" num="0051">Next, with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, a specific example of the operation of the authentication system <b>1</b> according to the example embodiment (especially, the determination system <b>10</b>) will be described. <figref idref="DRAWINGS">FIG. <b>5</b></figref> is an image diagram illustrating an example of marker projection in normal times. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is an image diagram illustrating an example of marker projection in attack. <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>7</b>B</figref> are comparative diagrams illustrating a difference between a captured image in normal times and a captured image in attack.</p><p id="p-0051" num="0052">As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, when a target person <b>500</b> is actually in front of the projector <b>20</b> and the camera <b>30</b> (in other words, when the target person <b>500</b> is a living body), a marker <b>200</b> projected from the projector <b>20</b> is projected on a background of the target person <b>500</b> (e.g., a wall behind the target person <b>500</b> or the like). In this case, since a position relationship between the projector <b>20</b> and the background is known in advance, it is possible to accurately predict in what state the marker is projected on the background. For example, by projecting the marker on the background (e.g., a wall or the like) in advance without a target person and storing a captured image at that time as a reference image, it is possible to know the position relationship between the projector <b>20</b> and the background in advance.</p><p id="p-0052" num="0053">On the other hand, as illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, when an attacker <b>600</b> points a photograph of the target person <b>500</b> at the camera <b>30</b> (in other words, when the target person <b>500</b> is not a living body), the marker <b>200</b> projected from the projector <b>20</b> is projected on the photograph of the target person <b>500</b>. In this case, since the marker <b>200</b> is projected at a position closer than expected, for example, the size of the marker <b>200</b> is smaller than that expected.</p><p id="p-0053" num="0054">As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, when comparing the images of the target person <b>500</b> captured in the situations of <figref idref="DRAWINGS">FIG. <b>5</b></figref> and <figref idref="DRAWINGS">FIG. <b>6</b></figref> described above, there is a clear difference in how the marker <b>200</b> appears. Specifically, when the target person <b>500</b> is a living body, as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, the marker <b>200</b> appears in the captured image in an expected state. On the other hand, when the target person <b>500</b> is not a living body, as in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, the marker <b>200</b> appears in the captured image in an unexpected state (specifically, a state in which the marker <b>200</b> is projected to be smaller than that in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>). Thus, by analyzing how the marker <b>200</b> appears in the captured image, it is possible to accurately determine whether or not the target person <b>500</b> is a living body.</p><p id="p-0054" num="0055">In the example described above, for convenience of description, the marker <b>200</b> is set to be a circle mark, but the shape of the marker is not particularly limited. For example, the marker <b>200</b> may include more complex patterns or may include characters or the like. Furthermore, a plurality of markers <b>200</b> may be projected on the background of the target person. In this case, when at least one marker <b>200</b> of the projected markers <b>200</b> appears in the captured image in an unexpected state, it may be determined that the target person <b>500</b> is not a living body.</p><heading id="h-0018" level="1">MODIFIED EXAMPLE</heading><p id="p-0055" num="0056">Next, with reference to <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>, a specific example of the operation of the authentication system <b>1</b> according to a modified example will be described. <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> are comparative diagrams illustrating an example of projecting the marker to overlap the target person.</p><p id="p-0056" num="0057">As illustrated in <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>, the marker <b>200</b> may be projected to overlap the target person <b>500</b>. Even in such a case, depending on whether or not the target person <b>500</b> is a living body, there is a clear difference in how the marker <b>200</b> appears in the captured image. Specifically, when the target person <b>500</b> is a living body, as in <figref idref="DRAWINGS">FIG. <b>8</b>A</figref>, the marker <b>200</b> is distorted (or deviated) at a border part of the living body. Alternatively, even if the marker <b>200</b> is projected to overlap the target person <b>500</b> completely, the marker <b>200</b> is distorted to a greater or lesser extent due to the unevenness of the target person <b>500</b>. On the other hand, when the target person <b>500</b> is not a living body (e.g., for a planar object such as a photograph), as in <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>, the marker <b>200</b> is not distorted. As descried above, by projecting the marker <b>200</b> to overlap the target person <b>500</b>, it is possible to determine whether or not the target person <b>500</b> is a living body depending on whether or not the marker <b>200</b> is distorted in the captured image. Even when the marker <b>200</b> is distorted, if the distortion is unnatural, it may be determined that the target person <b>500</b> is not a living body.</p><heading id="h-0019" level="1">Modified Example 2</heading><p id="p-0057" num="0058">The projector <b>20</b> (i.e., a projection unit that projects the marker <b>200</b>) may be provided independently of the determination system <b>10</b>. For example, the projector <b>20</b> may be configured to project the marker <b>200</b> manually (i.e., by an operation of an operator). In this way, it is possible to project the marker <b>200</b> at any timing of an operator. In this case, the determination system <b>10</b> may not include the projection control unit <b>101</b>.</p><heading id="h-0020" level="1">Modified Example 3</heading><p id="p-0058" num="0059">The projection of the marker <b>200</b> may be started without the target person <b>500</b>. Specifically, it may be determined whether or not there is the target person <b>500</b> after the marker <b>200</b> is projected, and when there is the target person <b>500</b>, the image of the target person <b>500</b> may be obtained. In this way, the target person <b>500</b> can view the position of the marker <b>200</b> in advance (i.e., the target person <b>500</b> can confirm the position of the marker <b>200</b> before being imaged by the camera <b>30</b>). Therefore, the target person <b>500</b> can adjust his or her own position in accordance with the position of the marker <b>200</b>. For example, the target person <b>500</b> can adjust a standing position such that the marker <b>200</b> does not overlap the eyes.</p><heading id="h-0021" level="1">Technical Effect</heading><p id="p-0059" num="0060">Next, a technical effect obtained by the authentication system <b>1</b> according to the example embodiment will be described.</p><p id="p-0060" num="0061">As described in <figref idref="DRAWINGS">FIG. <b>1</b></figref> to <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, in the authentication system <b>1</b> according to the example embodiment, when the authentication process is performed, the marker <b>200</b> is projected, and it is determined whether or not the target person <b>500</b> is a living body. Therefore, it is possible to avoid, for example, an attack by &#x201c;spoofing&#x201d; that uses a photograph or the like. By utilizing the marker <b>200</b> as in the example embodiment, it is possible to avoid illegal authentication breakthrough by a relatively simple apparatus configuration. Furthermore, since a special action is not required of the target person <b>500</b>, a burden on the target person <b>500</b> is not increased in the authentication process.</p><heading id="h-0022" level="2">&#x3c;Supplementary Notes&#x3e;</heading><p id="p-0061" num="0062">The example embodiment described above may be further described as, but not limited to, the following Supplementary Notes.</p><heading id="h-0023" level="2">(Supplementary Note 1)</heading><p id="p-0062" num="0063">A determination system described in Supplementary Note 1 is a determination system including: a proj ection control unit that controls a projection unit to proj ect a random marker within an angle of view of an imaging unit; an acquisition unit that obtains an image of a target person including the marker from the imaging unit; and a determination unit that determines whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</p><heading id="h-0024" level="2">(Supplementary Note 2)</heading><p id="p-0063" num="0064">A determination system described in Supplementary Note 2 is the determination system described in Supplementary Note 1, wherein the determination unit determines whether or not the target person imaged by the imaging unit is a living body on the basis of at least one of a position, an angle, and a size of the marker in the image.</p><heading id="h-0025" level="2">(Supplementary Note 3)</heading><p id="p-0064" num="0065">A determination system described in Supplementary Note 3 is the determination system described in Supplementary Note 1 or 2, wherein the determination unit gives a notice indicating that spoofing is performed when it is determined that the target person imaged by the imaging unit is not a living body.</p><heading id="h-0026" level="2">(Supplementary Note 4)</heading><p id="p-0065" num="0066">A determination system described in Supplementary Note 4 is the determination system described in any one of Supplementary Notes 1 to 3, wherein the projection control unit allows the marker to be projected in a background part of the target person.</p><heading id="h-0027" level="2">(Supplementary Note 5)</heading><p id="p-0066" num="0067">A determination system described in Supplementary Note 5 is the determination system described in any one of Supplementary Notes 1 to 3, wherein the projection control unit allows the marker to be projected so as to at least partially overlap the target person.</p><heading id="h-0028" level="2">(Supplementary Note 6)</heading><p id="p-0067" num="0068">A determination system described in Supplementary Note 6 is the determination system described in any one of Supplementary Notes 1 to 5, wherein the projection control unit allows the marker to be projected with invisible light.</p><heading id="h-0029" level="2">(Supplementary Note 7)</heading><p id="p-0068" num="0069">A determination system described in Supplementary Note 7 is the determination system described in any one of Supplementary Notes 1 to 6, wherein the acquisition unit obtains a plurality of temporally continuous images from the imaging unit, and the determination unit determines whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the plurality of images.</p><heading id="h-0030" level="2">(Supplementary Note 8)</heading><p id="p-0069" num="0070">A determination method described in Supplementary Note 8 is A determination method including: controlling a projection unit to project a random marker within an angle of view of an imaging unit; obtaining an image of a target person including the marker from the imaging unit; and determining whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</p><heading id="h-0031" level="2">(Supplementary Note 9)</heading><p id="p-0070" num="0071">A computer program described in Supplementary Note 9 is a computer program that operates a computer: to control a projection unit to project a random marker within an angle of view of an imaging unit; to obtain an image of a target person including the marker from the imaging unit; and to determine whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</p><heading id="h-0032" level="2">(Supplementary Note 10)</heading><p id="p-0071" num="0072">An authentication system described in Supplementary Note 10 is an authentication system including: a proj ection control unit that controls a projection unit to project a random marker within an angle of view of an imaging unit; an acquisition unit that obtains an image of a target person including the marker from the imaging unit; a determination unit that determines whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image; and an execution unit that performs an authentication process on the target person when it is determined that the target person is a living body.</p><p id="p-0072" num="0073">The present invention is not limited to the examples described above and is allowed to be changed, if desired, without departing from the essence or spirit of the invention which can be read from the claims and the entire specification. A determination system, a determination method, a computer program, and an authentication system with such modifications are also intended to be within the technical scope of the present invention.</p><heading id="h-0033" level="1">DESCRIPTION OF REFERENCE CODES</heading><p id="p-0073" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0074"><b>1</b> Authentication system</li>    <li id="ul0002-0002" num="0075"><b>10</b> Determination system</li>    <li id="ul0002-0003" num="0076"><b>20</b> Projector</li>    <li id="ul0002-0004" num="0077"><b>30</b> Camera</li>    <li id="ul0002-0005" num="0078"><b>40</b> Authentication apparatus</li>    <li id="ul0002-0006" num="0079"><b>101</b> Projection control unit</li>    <li id="ul0002-0007" num="0080"><b>102</b> Image acquisition unit</li>    <li id="ul0002-0008" num="0081"><b>103</b> Living body determination unit</li>    <li id="ul0002-0009" num="0082"><b>200</b> Marker</li>    <li id="ul0002-0010" num="0083"><b>500</b> Target person</li>    <li id="ul0002-0011" num="0084"><b>600</b> Attacker</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A determination system comprising:<claim-text>at least one memory that is configured to store instructions; and</claim-text><claim-text>at least one processor that is configured to execute instructions</claim-text><claim-text>to control a projection unit to project a random marker within an angle of view of an imaging unit;</claim-text><claim-text>to obtain an image of a target person including the marker from the imaging unit; and</claim-text><claim-text>to determine whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The determination system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor determines whether or not the target person imaged by the imaging unit is a living body on the basis of at least one of a position, an angle, and a size of the marker in the image.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The determination system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor gives a notice indicating that spoofing is performed when it is determined that the target person imaged by the imaging unit is not a living body.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The determination system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor allows the marker to be projected in a background part of the target person.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The determination system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor allows the marker to be projected so as to at least partially overlap the target person.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The determination system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the processor allows the marker to be projected with invisible light.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The determination system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein<claim-text>the processor obtains a plurality of temporally continuous images from the imaging unit, and</claim-text><claim-text>the processor determines whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the plurality of images.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A determination method comprising:<claim-text>controlling a projection unit to project a random marker within an angle of view of an imaging unit;</claim-text><claim-text>obtaining an image of a target person including the marker from the imaging unit; and</claim-text><claim-text>determining whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A non-transitory recording medium on which a computer program that allows a computer to execute a determination method is recorded, the determination method comprising:<claim-text>controlling a projection unit to project a random marker within an angle of view of an imaging unit;</claim-text><claim-text>obtaining an image of a target person including the marker from the imaging unit; and</claim-text><claim-text>determining whether or not the target person imaged by the imaging unit is a living body on the basis of a state of the marker included in the image.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. (canceled)</claim-text></claim></claims></us-patent-application>
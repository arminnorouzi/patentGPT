<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007077A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007077</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930608</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>1008</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>67</main-group><subgroup>1008</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e43">TECHNIQUES FOR DEPLOYING WORKLOADS ON NODES IN A CLOUD-COMPUTING ENVIRONMENT</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17316314</doc-number><date>20210510</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11477275</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17930608</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Microsoft Technology Licensing, LLC</orgname><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>MEHROTRA</last-name><first-name>Sanjeev</first-name><address><city>Kirkland</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>BAHL</last-name><first-name>Paramvir</first-name><address><city>Bellevue</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>KALIA</last-name><first-name>Anuj</first-name><address><city>Newcastle</city><state>WA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Described are examples for deploying workloads in a cloud-computing environment. In an aspect, based on a desired number of workloads of a process to be executed in a cloud-computing environment and based on one or more failure probabilities, an actual number of workloads of the process to execute in the cloud-computing environment to provide a level of service can be determined and deployed. In another aspect, a standby workload can be executed as a second instance of the process without at least a portion of the separate configuration used by the multiple workloads, and based on detecting termination of one of multiple workloads, the standby workload can be configured to execute based on the separate configuration of the separate instance of the process corresponding to the one of the multiple workloads.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="87.97mm" wi="158.75mm" file="US20230007077A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="213.44mm" wi="145.12mm" orientation="landscape" file="US20230007077A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="202.10mm" wi="145.12mm" orientation="landscape" file="US20230007077A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="231.73mm" wi="159.00mm" orientation="landscape" file="US20230007077A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="242.99mm" wi="152.40mm" file="US20230007077A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="242.99mm" wi="155.11mm" file="US20230007077A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="203.96mm" wi="88.48mm" file="US20230007077A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CLAIM OF PRIORITY UNDER 35 U.S.C. &#xa7; 119</heading><p id="p-0002" num="0001">The present Application is a continuation of U.S. patent application Ser. No. 17/316,314, entitled &#x201c;TECHNIQUES FOR DEPLOYING WORKLOADS ON NODES IN A CLOUD-COMPUTING ENVIRONMENT&#x201d; filed May 10, 2021, which is assigned to the assignee hereof and hereby expressly incorporated by reference herein for all purposes.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">Cloud-computing environments are provided for distributed storage and access of software (e.g., services or other applications), files, data, etc. across multiple devices connected via a network, such as the Internet. Using distributed nodes to store data and/or allow execution of the software can improve reliability of the software and data through redundancy, improved on-demand access of the software and data from various other nodes in the network, more efficient execution of software or retrieval of data by using certain nodes or services in the network, and/or the like. A cloud-computing environment can include one or more compute clusters that provide one or more functions. The compute clusters can include a workload that executes on one or more nodes to provide redundant functionality, and a load balancer or router that can balance requests across workloads or route requests based on a characteristic (e.g., an identifier in the request that is associated with one of the workloads). In one specific example, cloud-computing environments can be used to provide mobile edge computing (MEC) where certain functions of a mobile network can be provided as workloads on nodes in the cloud-computing environment.</p><p id="p-0004" num="0003">In MEC, a centralized unit (CU) can be implemented in a back-end node, one or more distributed units (DUs) can be implemented in intermediate nodes, and various remote units (RU), which can provide at least physical (PHY) and/or media access control (MAC) layers of a base station or other radio access network (RAN) node of the mobile network, can be deployed at edge serves. The RUs can communicate with the CU via one or more DUs. In an example, the DUs can provide higher network layer functionality for the RAN, such as radio link control (RLC) or packet data convergence protocol (PDCP) layer functions. The RUs can facilitate access to the CU for various downstream devices, such as user equipment (UE), Internet-of-Things (IoT) devices, etc. In addition, the CU, DUs, RUs, or portions thereof, may each execute as a workload on nodes of the cloud-computing environment and/or in a given compute cluster thereof.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0005" num="0004">The following presents a simplified summary of one or more aspects in order to provide a basic understanding of such aspects. This summary is not an extensive overview of all contemplated aspects, and is intended to neither identify key or critical elements of all aspects nor delineate the scope of any or all aspects. Its sole purpose is to present some concepts of one or more aspects in a simplified form as a prelude to the more detailed description that is presented later.</p><p id="p-0006" num="0005">In an example, a computer-implemented method for deploying workloads on nodes in a cloud-computing environment is provided. The method includes determining, for a process to be provided in the cloud-computing environment, a desired number of workloads of the process to be executed in the cloud-computing environment, determining, based on the desired number of workloads and based on one or more failure probabilities, an actual number of workloads of the process to execute in the cloud-computing environment to provide a level of service, wherein the actual number of workloads includes the desired number of workloads and one or more additional workloads, and deploying, based on determining the actual number of workloads, one or more workloads to one or more nodes of the cloud-computing environment to reach the actual number of workloads of the process executing in the cloud-computing environment.</p><p id="p-0007" num="0006">In another example, a computer-implemented method for handling failure for workloads in a cloud-computing environment is provided. The method includes executing multiple workloads in a cloud-computing environment cluster, wherein each workload of the multiple workloads corresponds to a separate instance of a process that is executed according to a separate configuration, executing a standby workload as a second instance of the process without at least a portion of the separate configuration used by the multiple workloads, and based on detecting termination of one of the multiple workloads, configuring the standby workload to execute based on the separate configuration of the separate instance of the process corresponding to the one of the multiple workloads.</p><p id="p-0008" num="0007">In another example, a device for deploying workloads on nodes in a cloud-computing environment is provided that includes a memory storing one or more parameters or instructions for deploying workloads in the cloud-computing environment, and at least one processor coupled to the memory. The at least one processor is configured to determine, for a process to be provided in the cloud-computing environment, a desired number of workloads of the process to be executed in the cloud-computing environment, determine, based on the desired number of workloads and based on one or more failure probabilities, an actual number of workloads of the process to execute in the cloud-computing environment to provide a level of service, wherein the actual number of workloads includes the desired number of workloads and one or more additional workloads, and deploy, based on determining the actual number of workloads, one or more workloads to one or more nodes of the cloud-computing environment to reach the actual number of workloads of the process executing in the cloud-computing environment.</p><p id="p-0009" num="0008">To the accomplishment of the foregoing and related ends, the one or more aspects comprise the features hereinafter fully described and particularly pointed out in the claims. The following description and the annexed drawings set forth in detail certain illustrative features of the one or more aspects. These features are indicative, however, of but a few of the various ways in which the principles of various aspects may be employed, and this description is intended to include all such aspects and their equivalents.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of an example of a cloud-computing environment cluster for executing multiple workloads, in accordance with aspects described herein.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram of an example of a cloud-computing environment cluster for executing multiple separately configured workloads, in accordance with aspects described herein.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram of an example of a device for deploying and/or configuring workloads, in accordance with aspects described herein.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flow diagram of an example of a method for deploying workloads, in accordance with aspects described herein.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flow diagram of an example of a method for configuring standby workloads, in accordance with aspects described herein.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a schematic diagram of an example of a device for performing functions described herein, in accordance with aspects described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0016" num="0015">The detailed description set forth below in connection with the appended drawings is intended as a description of various configurations and is not intended to represent the only configurations in which the concepts described herein may be practiced. The detailed description includes specific details for the purpose of providing a thorough understanding of various concepts. However, it will be apparent to those skilled in the art that these concepts may be practiced without these specific details. In some instances, well-known components are shown in block diagram form in order to avoid obscuring such concepts.</p><p id="p-0017" num="0016">This disclosure describes various examples related to deploying workloads over nodes in a cloud-computing environment. In some aspects, given a number of workloads of a process to be deployed, one or more additional workloads can be deployed to provide redundancy to improve failure or fault scenarios where one or more of the original workloads, or a respective node on which the one or more workloads are executing, fail. A node, as described herein, can include a physical machine (e.g., a physical device, such as a server or other computer), a virtual machine (e.g., where a physical machine can execute one or more virtual machines and/or where a virtual machine can execute over one or more physical machines), or any machine or location at which a workload can execute. In one aspect, the workloads may execute a same or similar process according to a different configuration. In this aspect, for example, an additional workload may be a standby workload that is a fully functioning instance of the process that does not execute, or does not execute according to a specific configuration, until it is configured based on a specific configuration. In this aspect, when a workload executing based on a given configuration fails, the standby workload can be configured based on the configuration, and executed to provide the function of the workload based on the given configuration to provide a redundant process. In this regard, the standby workload can be used to recover any workload based on the failing workload's given configuration. In this aspect, it may not be required to have a redundant node for each specifically configured workload, but rather one or more standby nodes are provided that can be configured using any of the given configurations of the other workloads.</p><p id="p-0018" num="0017">In another aspect, the number of additional workloads to deploy can be determined based on a desired number of workloads for the process and one or more failure probabilities. For example, the one or more failure probabilities can correspond to failure probability of the process, failure probability of a node on which the workload is executing, etc. The one or more failure probabilities can be determined or specified for a given timeslot. In an example, the one or more failure probabilities can be determined based on a history of failures for the process, the one or more nodes, etc. In any case, given a desired number of workloads and the one or more failure probabilities, an actual number of workloads to deploy can be determined. In this aspect, one or more additional workloads can be deployed based on determining the actual number (e.g., one or more additional workloads over the desired number of workloads) to achieve a level of service. Other considerations can be used in determining the actual number of workloads as well (e.g., and/or in determining the one or more failure probabilities), such as a location of the nodes on which the workloads are deployed (or are to be deployed), a node type desired for the workload, a cost of deploying at one or more nodes, etc.</p><p id="p-0019" num="0018">Turning now to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>6</b></figref>, examples are depicted with reference to one or more components and one or more methods that may perform the actions or operations described herein, where components and/or actions/operations in dashed line may be optional. Although the operations described below in <figref idref="DRAWINGS">FIGS. <b>4</b>-<b>5</b></figref> are presented in a particular order and/or as being performed by an example component, the ordering of the actions and the components performing the actions may be varied, in some examples, depending on the implementation. Moreover, in some examples, one or more of the actions, functions, and/or described components may be performed by a specially-programmed processor, a processor executing specially-programmed software or computer-readable media, or by any other combination of a hardware component and/or a software component capable of performing the described actions or functions.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of an example of a compute cluster <b>100</b> in a cloud-computing environment. Compute cluster <b>100</b> can include multiple workloads <b>102</b>, <b>104</b>, <b>106</b>, <b>108</b>, <b>110</b>, <b>112</b>, <b>114</b>, <b>116</b> that can be similarly configured to execute at least a portion of a process or service. For example, workloads <b>102</b>, <b>104</b>, <b>106</b>, <b>108</b>, <b>110</b> can be configured to execute stage <b>1</b> of a multi-stage process, and may be configured, using the same configuration, to perform the same process stage to provide redundancy for the process stage <b>1</b>. Similarly, workloads <b>112</b>, <b>114</b>, <b>116</b> can be configured to execute stage <b>2</b> of the multi-stage process, and may be configured, using the same configuration, to perform the same process stage to provide redundancy for the process stage <b>2</b>. Load balancers/routers <b>118</b>, <b>120</b> can be provided to receive requests or commands for processing via the corresponding process stage, and can select a workload to handle the request based on various considerations, such as processing load on each of the workloads or other routing considerations (e.g., distance to a location of a node on which the workload is operating, node type or hardware that may relate to the request to be fulfilled, etc.), a cost of deploying the workload at one or more nodes (e.g., and whether this cost complies with the SLA or other agreement for deploying the workload), etc.</p><p id="p-0021" num="0020">In an example, the workloads <b>102</b>, <b>104</b>, <b>106</b>, <b>108</b>, <b>110</b>, <b>112</b>, <b>114</b>, <b>116</b> can be executed on various nodes of a cloud-computing environment, as described further herein. For example, workloads <b>102</b>, <b>104</b>, <b>106</b> may represent a desired number of workloads for process (or process stage <b>1</b>). An actual number of workloads can be determined based on one or more failure probabilities, as described further herein, to provide a desired level of service. The actual number of workloads can be greater than the desired number of workloads, and as such, additional workloads <b>108</b>, <b>110</b> can be added, activated, etc. to provide at least the level of service (e.g., at least the number of desired workloads executing at a given point in time or time duration) in view of failure probabilities for the process (or process stage), corresponding nodes on which the process is executing, etc. Similarly, for example, workloads <b>112</b>, <b>114</b> may represent a desired number of workloads for process (or process stage <b>2</b>). The actual number of workloads can be determined based on one or more failure probabilities, as described further herein, to provide a desired level of service for the process stage <b>2</b>. The actual number of workloads can be greater than the desired number of workloads, and as such, additional workload <b>116</b> can be added, activated, etc. to provide at least the level of service in view of failure probabilities for the process stage <b>2</b>, corresponding nodes on which the process stage <b>2</b> is executing, etc.</p><p id="p-0022" num="0021">The compute cluster <b>100</b> can be part of the cloud-computing environment and can include machines (e.g., physical or virtual) with memory, processor(s), devices, etc., and the machines can be managed by an orchestration environment. In this regard, for example, the orchestration environment can manage execution of, access to, etc. various nodes in the cloud-computing environment. In an example, the load balancers/routers <b>118</b>, <b>120</b> can use abstractions of the orchestration environment to route requests to the corresponding workloads <b>102</b>, <b>104</b>, <b>106</b>, <b>108</b>, <b>110</b>, <b>112</b>, <b>114</b>, <b>116</b>. In the specific example of compute cluster <b>100</b>, any workload can handle any request for the processor stage, and load balancers/routers <b>118</b>, <b>120</b> can accordingly route a request to any of the corresponding workloads <b>102</b>, <b>104</b>, <b>106</b>, <b>108</b>, <b>110</b>, <b>112</b>, <b>114</b>, <b>116</b>.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a diagram of an example of a compute cluster <b>200</b> in a cloud-computing environment including separately configured workloads. Compute cluster <b>200</b> can include multiple workloads <b>202</b>, <b>204</b>, <b>206</b> that can be configured to execute at least a portion of a similar process or service using a different configuration. For example, workload <b>202</b> can be configured to execute the process using configuration <b>1</b>, workload <b>204</b> can be configured to execute the process using configuration <b>2</b>, workload <b>206</b> can be configured to execute the process using configuration <b>3</b>, etc. For example, the configurations can differ by one or more parameters or corresponding values, such as an environment variable. In one specific example, the workloads <b>202</b>, <b>204</b>, <b>206</b> can execute a base station process, or at least a portion of a RAN function of a base station process, and each workload <b>202</b>, <b>204</b>, <b>206</b> can be configured as a different base station (e.g., where each workload <b>202</b>, <b>204</b>, <b>206</b> has a different base station identifier).</p><p id="p-0024" num="0023">Compute cluster <b>200</b> can also include a standby workload <b>208</b> that may not be configured based on a specific configuration. Standby workload <b>208</b>, for example, may operate in a suspended state or be deactivated until activated to replace a failed or otherwise terminated workload. For example, a controller <b>212</b> can monitor the workloads <b>202</b>, <b>204</b>, <b>206</b> to detect a failure or other termination (e.g., termination of the corresponding node as a failure, a planned termination for servicing the node, etc.). In any case, based on detecting the failure or termination of the workload, controller <b>212</b> can activate standby workload <b>208</b> with the configuration of the failed workload. For example, where controller <b>212</b> detects failure of workload <b>206</b>, controller <b>212</b> can activate the standby workload with configuration <b>3</b> to replace workload <b>206</b>. In this regard, a separate redundant workload may not be needed for each separately configured workload in order to provide redundancy for the similar (e.g., same) process being executed by the workloads <b>202</b>, <b>204</b>, <b>206</b>.</p><p id="p-0025" num="0024">As similarly described with respect to compute cluster <b>100</b>, for example, load balancer/router <b>210</b> can be provided to receive requests or commands for processing via the corresponding process, and can select a workload to handle the request based on the configuration of the given workload. In addition, for example, each configuration may have multiple workloads, and load balancer/router <b>210</b> can select among multiple workloads having the desired configuration based on various other considerations, as described above, such as processing load on each of the workloads or other routing considerations (e.g., distance to a location of a node on which the workload is operating, node type or hardware that may relate to the request to be fulfilled, etc.). Moreover, in an example, workloads <b>202</b>, <b>204</b>, <b>206</b> (and/or <b>208</b> if configured and activated) can be one stage of a multi-stage process and can pass output to another stage of the multi-stage process, which may also be specific to the corresponding configuration. In a specific example, the workloads <b>202</b>, <b>204</b>, <b>206</b> can operate a RAN function, such as in a fifth generation (5G) network, which may be part of a mobile edge computing (MEC) configuration. In this example, each workload <b>202</b>, <b>204</b>, <b>206</b> can operate a function or node of a 5G RAN, such as a RU to provide at least PHY layer of the RAN. In an example, the workloads <b>202</b>, <b>204</b>, <b>206</b> can each be coupled to another workload (e.g., a MAC layer for the RU) for the specific RU or other base station or portion thereof.</p><p id="p-0026" num="0025">In an example, the workloads <b>202</b>, <b>204</b>, <b>206</b>, <b>208</b> can be executed on various nodes of a cloud-computing environment, as described further herein. For example, workloads <b>202</b>, <b>204</b>, <b>206</b>, may represent a desired number of workloads for process (or process stage <b>1</b>). An actual number of workloads can be determined based on one or more failure probabilities, as described further herein, to provide a desired level of service. The actual number of workloads can be greater than the desired number of workloads, and as such, additional standby workload <b>208</b> can be added, activated, etc. to provide at least the level of service (e.g., at least the number of desired workloads executing at a given point in time or time duration) in view of failure probabilities for the process (or process stage), corresponding nodes on which the process is executing, etc.</p><p id="p-0027" num="0026">The compute cluster <b>200</b> can be part of the cloud-computing environment and can include machines (e.g., physical or virtual) with memory, processor(s), devices, etc., and the machines can be managed by an orchestration environment. In this regard, for example, the orchestration environment can manage execution of, access to, etc. various nodes in the cloud-computing environment. In an example, the load balancer/router <b>210</b> can use abstractions of the orchestration environment to route requests to the corresponding workloads <b>202</b>, <b>204</b>, <b>206</b>, <b>208</b>.</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram of an example of a device <b>300</b> (e.g., a computing device) for performing functions related to deploying or managing workloads over nodes of a cloud-computing environment. In an example, device <b>300</b> can include a processor <b>302</b> and/or memory <b>304</b> configured to execute or store instructions or other parameters related to providing an operating system <b>306</b>, which can execute one or more applications or processes, such as, but not limited to, at least one of a workload deploying component <b>308</b> for deploying workloads over nodes of a cloud-computing environment <b>310</b> (e.g., nodes <b>312</b>, <b>314</b>, <b>316</b>) or a workload configuring component <b>320</b> for configuring or activating a standby workload to provide a workload function of a configured workload that failed or was otherwise terminated, as described further herein. For example, processor <b>302</b> and memory <b>304</b> may be separate components communicatively coupled by a bus (e.g., on a motherboard or other portion of a computing device, on an integrated circuit, such as a system on a chip (SoC), etc.), components integrated within one another (e.g., processor <b>302</b> can include the memory <b>304</b> as an on-board component), and/or the like. Memory <b>304</b> may store instructions, parameters, data structures, etc. for use/execution by processor <b>302</b> to perform functions described herein.</p><p id="p-0029" num="0028">In an example, workload deploying component <b>308</b> can include one or more of a process information component <b>330</b> for obtaining information related to a process to be deployed in multiple workloads in a cloud-computing environment <b>310</b>, a failure metric component <b>332</b> for measuring or otherwise determining one or more failure metrics related to the multiple workloads or corresponding nodes over which the workloads are, or are to be, deployed, an additional workload component <b>334</b> for determining additional workloads to deploy to achieve a level of service for the process, a node information component <b>336</b> for obtaining other information related to nodes over which the workloads are, or are to be, deployed, which can be used in determining the additional workloads, and/or a machine learning component <b>338</b> for using machine learning to determine the additional workloads. Thus, in one example, additional workload component <b>334</b> can determine one or more additional workloads over a desired number of workloads for the process to ensure the level of service given determined failure probabilities, node types, cost, machine learning, etc., as described further herein. Additional workload component <b>334</b> can determine how many and/or where to deploy the additional workloads (e.g., which nodes) in the cloud-computing environment <b>310</b>.</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of an example of a method <b>400</b> for deploying workloads for a process over nodes in a cloud-computing environment. For example, method <b>400</b> can be performed by a device <b>300</b> and/or one or more components thereof to facilitate workload deployment or management in a cloud-computing environment.</p><p id="p-0031" num="0030">In method <b>400</b>, at action <b>402</b>, a desired number of workloads of a process to be executed in a cloud-computing environment can be determined for a process to be provided in the cloud-computing environment. In an example, process information component <b>330</b> of a workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can determine, for a process to be provided in a cloud-computing environment (e.g., cloud-computing environment <b>310</b>), the desired number of workloads of the process to be executed in the cloud-computing environment. For example, the process information can indicate the number of workloads to be executed for the process, where the more workloads can provide redundancy for the process. The process information can be indicated in a configuration, which can be obtained by the process information component <b>330</b> as part of workload deploying component <b>308</b> determining or effectuating a deployment plan for the process. In addition, for example, the process can be associated with a service level agreement (SLA), which may be indicated in the process information. For example, the SLA may have or be associated with a level of service or reliability (e.g., workloads available x % of the time). In this regard, as described herein, workload deploying component <b>308</b> may determine to activate additional workloads over the desired number of workloads in an attempt to ensure the SLA is met or achieved.</p><p id="p-0032" num="0031">In an example, the SLA (or level of reliability), the desired number of workloads for the process, etc. can be input into a configuration, into an orchestration environment that can manage deployment of the workloads, etc. In this example, process information component <b>330</b> can obtain the SLA, desired number of workloads, or related information or parameters from the configuration, the orchestration environment, etc.</p><p id="p-0033" num="0032">In method <b>400</b>, at action <b>404</b>, an actual number of workloads of the process to execute in the cloud-computing environment to provide a level of service can be determined based on the desired number of workloads and based on one or more failure probabilities. In an example, additional workload component <b>334</b> of a workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can determine, based on the desired number of workloads and based on the one or more failure probabilities, the actual number of workloads of the process to execute in the cloud-computing environment to provide the level of service. For example, failure metric component <b>332</b> can determine one or more failure metrics related to the desired number of workloads, which can include determining a failure probability that the workload fails or otherwise terminates at a time instance or during a time duration, a failure probability that a node on which the workload is executing fails or otherwise terminates at a time instance or during a time duration, etc. In any case, additional workload component <b>334</b> can determine a number of additional workloads to add in the cloud computing environment <b>310</b> so that the desired number of workloads are executing at the time instance or during the time duration even if one or more workloads or corresponding nodes fail or otherwise terminate.</p><p id="p-0034" num="0033">In one specific example, additional workload component <b>334</b> can determine the total actual number of workloads or at least the number of additional workloads using a formula similar to the following and finding the smallest value K that satisfies the formula:</p><p id="p-0035" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mrow>   <munderover>    <mo>&#x2211;</mo>    <mrow>     <mi>i</mi>     <mo>=</mo>     <mi>n</mi>    </mrow>    <mrow>     <mi>N</mi>     <mo>+</mo>     <mi>K</mi>    </mrow>   </munderover>   <mrow>    <mrow>     <mo>(</mo>     <mtable>      <mtr>       <mtd>        <mrow>         <mi>N</mi>         <mo>+</mo>         <mi>K</mi>        </mrow>       </mtd>      </mtr>      <mtr>       <mtd>        <mi>i</mi>       </mtd>      </mtr>     </mtable>     <mo>)</mo>    </mrow>    <mo>&#x2062;</mo>    <msup>     <mrow>      <mo>(</mo>      <mrow>       <mn>1</mn>       <mo>-</mo>       <mi>p</mi>       <mo>-</mo>       <mi>n</mi>      </mrow>      <mo>)</mo>     </mrow>     <mi>i</mi>    </msup>    <mo>&#x2062;</mo>    <msup>     <mrow>      <mo>(</mo>      <mrow>       <mi>p</mi>       <mo>+</mo>       <mi>n</mi>      </mrow>      <mo>)</mo>     </mrow>     <mrow>      <mi>N</mi>      <mo>+</mo>      <mi>K</mi>      <mo>-</mo>      <mi>i</mi>     </mrow>    </msup>   </mrow>  </mrow>  <mo>&#x2264;</mo>  <mi>&#x3b1;</mi> </mrow></math></maths></p><p id="p-0036" num="0000">where N is the desired number of workloads, K is the number of additional workloads, p is the probability of workload failure or termination for a given timeslot, n is the probability of node failure or termination for the given timeslot, and &#x3b1; is a SLA (e.g., a reliability probability) for the service. In an example, one or more of the probabilities, p or n, can be determined based on received or observed historical state information for the workload or node (e.g., an amount of time or number of time slots within a period of time or time slots during which the workload or node is terminated). In another example, one or more of the probabilities, p or n, can be determined from, or received in, a configuration related to the workload or node. In yet another example, as described further herein, one or more of the probabilities, p or n, can be determined by machine learning where one or more other input parameters related to a workload or node can be modeled with an output of failure probability or time periods/time slots during which a workload is likely to be in a terminated or failed state. In one example, the above formula can be used for certain values of p and n where adding the probabilities can reflect a total probability of failure for the workload at the node and/or where other assumptions made regarding workload failure and node failure may be independent.</p><p id="p-0037" num="0034">In an example, in determining the actual number of workloads at action <b>404</b>, optionally at action <b>406</b>, a location of the one or more nodes for deploying the one or more workloads can be determined. In an example, node information component <b>336</b> of a workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can determine the location of the one or more nodes for deploying the one or more workloads, which can include determining location of one or more nodes to which the one or more workloads are, or are to be, deployed. For example, the location of the one or more nodes can include a physical location of the node in the world (e.g., global positioning system (GPS) coordinates of the node). In one example, the location of the one or more nodes may be used to determine a failure probability for the one or more nodes. For example, nodes located in a first location having more frequency earthquakes or other natural disaster than a second location may have a higher failure probability than nodes located in the second location. In an example, additional workload component <b>334</b> can accordingly use different failure probabilities based on location in computing the number of additional workloads.</p><p id="p-0038" num="0035">In another example, in determining the actual number of workloads at action <b>404</b>, optionally at action <b>408</b>, a node type for deploying the one or more workloads can be determined. In an example, node information component <b>336</b> of a workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can determine the node type for deploying the one or more workloads. For example, nodes of a first type (e.g., nodes having certain hardware, such as more complex hardware) may have a higher failure rate and/or higher downtime caused by failure than nodes of a second type. In an example, additional workload component <b>334</b> can accordingly use different failure probabilities based on node type in computing the number of additional workloads.</p><p id="p-0039" num="0036">In another example, in determining the actual number of workloads at action <b>404</b>, optionally at action <b>410</b>, a cost for deploying the one or more workloads can be determined. In an example, node information component <b>336</b> of a workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can determine the cost for deploying the one or more workloads. For example, the cost can be associated with a monetary equipment cost or latency cost, etc. associated with one or more of the nodes. In this example, additional workload component <b>334</b> can determine whether using the one or more nodes complies with the cost requirements for deploying the workload in the cloud computing environment <b>310</b>, where the cost may be part of or specified in the SLA or other agreement. In another example, additional workload component <b>334</b> can select the one or more nodes such to comply with the cost requirements. In other examples, as described above and further herein, additional workload component <b>334</b> can select the one or more nodes that maximize other properties, such as distance between locations of the nodes, with the cost requirements.</p><p id="p-0040" num="0037">In yet another example, in determining the actual number of workloads at action <b>404</b>, optionally at action <b>412</b>, the actual number of workloads can be determined using a machine learning process. In an example, machine learning component <b>338</b> of a workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can determine the actual number of workloads using the machine learning process. For example, machine learning component <b>338</b> can use a model trained using data from deployed workloads that can provide a failure probability for the workload or node based on various inputs.</p><p id="p-0041" num="0038">In an example, machine learning component <b>338</b> can accept inputs including one or more workload related parameters (e.g., type of the workload, such as a RAN workload, a specific RAN type of workload, such as RU, DU, CU, etc., size of the workload, an expected or historical utilization metric of the workload, an expected or historical processor or memory usage metric of the workload, etc.). In another example, machine learning component <b>338</b> can accept inputs including one or more node related parameters (e.g., location of the node, a node type, an expected or historical utilization metric of the node, an expected or historical processor or memory usage metric of the node, etc.). Based on the inputs, machine learning component <b>338</b> can train a model, or access a model trained on such inputs, to provide an output of failure probability that the workload or node will be in a terminated or failed state in a given time or time slot, as described.</p><p id="p-0042" num="0039">In method <b>400</b>, at action <b>414</b>, one or more workloads can be deployed, based on determining the actual number of workloads, to one or more nodes of the cloud-computing environment to reach the actual number of workloads of the process in the cloud-computing environment. In an example, workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can deploy, based on determining the actual number of workloads, the one or more workloads to one or more nodes of the cloud-computing environment to reach the actual number of workloads of the process in the cloud-computing environment. In an example, workload deploying component <b>308</b> can deploy the desired number of workloads, and then can determine and deploy the additional workloads. In another example, workload deploying component <b>308</b> can generate a deployment plan based on the number of desired workloads, can determine the additional number of workloads, and can deploy all workloads based on the deployment plan. As described, workload deploying component <b>308</b> can be, or can be part of, an orchestration environment that can manage and access various distributed nodes to deploy workloads, forward requests to the workloads, handle responses from the workloads, etc. In addition, the one or more workloads may include actual workloads, configured workloads, standby workloads, etc., as described above and further herein.</p><p id="p-0043" num="0040">In deploying the one or more workloads at action <b>414</b>, optionally at action <b>416</b>, a deployment plan for the actual number of workloads over the one or more nodes can be determined. In an example, workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can determine the deployment plan for the actual number of workloads over the one or more nodes. For example, based on the actual number of workloads, workload deploying component <b>308</b> can determine or select nodes of the cloud-computing environment <b>310</b> (e.g., nodes <b>312</b>, <b>314</b>, <b>316</b>, etc.) over which to deploy the additional workloads (and/or the desired number of workloads). In an example, workload deploying component <b>308</b> can determine or select the nodes based on properties of the nodes, as described, such as location, node type, etc. For example, some workloads may require or benefit from certain node types (e.g., nodes having certain types of hardware), which workload deploying component <b>308</b> can consider in developing a deployment plan or otherwise deploying the workloads. In another example, workload deploying component <b>308</b> can consider location of the node(s) in developing the deployment plan such to avoid deploying workloads on the same node where possible, to balance benefits of maximally distributing nodes with latency caused by distance between nodes, etc.</p><p id="p-0044" num="0041">In an example, workload deploying component <b>308</b> can develop the deployment plan and can then determine additional workloads based on the plan at action <b>404</b>. In another example, workload deploying component <b>308</b> can use similar considerations described for determining the actual number of workloads in determining the deployment plan. For example, workload deploying component <b>308</b> can determine the deployment plan based on the location of nodes, node type, cost of deployment, using machine learning, etc. In an example, workload deploying component <b>308</b> can test hypotheses of where to deploy workloads (e.g., on which nodes) based on the functions described in action <b>404</b>, such to determine node locations for the workloads (e.g., that may result in the lowest number, or acceptable number, of additional workloads). In this example, workload deploying component <b>308</b> can select nodes for deploying each of the actual number of workloads, and the selection may be based on determining a location of the nodes, node type of the nodes, etc. to balance distribution of the nodes with latency, to ensure desired node types are used, etc. Workload deploying component <b>308</b> can then determine, based on the selected nodes, whether additional workloads are needed to meet the SLA (e.g., to satisfy the equation shown above based on failure probability of the selected nodes (and/or of the workload)). If so, workload deploying component <b>308</b> can either determine nodes over which to deploy additional workloads or can modify the deployment plan (e.g., modify the nodes over which the workloads are to be deployed) in an attempt to reduce the number of additional workloads needed to achieve the SLA.</p><p id="p-0045" num="0042">In some examples, workload and node failures may be correlated and measured to determine true probability of failure at any given time. Measurement may include duration of each failure &#x2014; for example, some failures can be longer, leading to consideration of time slot in determining failure probability, as described. A goal of deployment can be to distribute workloads across nodes as much as possible, while also considering latency related to distance between nodes (which can impact the service level), corresponding changes in failure probability, etc.</p><p id="p-0046" num="0043"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of an example of a method <b>500</b> for configuring standby workloads in a cloud-computing environment. For example, method <b>500</b> can be performed by a device <b>300</b> and/or one or more components thereof to facilitate deploying, configuring, activating, or otherwise managing standby workloads.</p><p id="p-0047" num="0044">In method <b>500</b>, at action <b>502</b>, multiple workloads can be executed in a cloud-computing environment cluster, where each workload corresponds to a separate instance of a process executed according to a separate configuration. In an example, workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can execute, or manage deployment or execution of, the multiple workloads in the cloud-computing environment <b>310</b> cluster (e.g., over one or more nodes <b>312</b>, <b>314</b>, <b>316</b> of the cloud-computing environment <b>310</b>), where each workload corresponds to a separate instance of a process executed according to a separate configuration. For example, workload configuring component <b>320</b> can configure the multiple workloads each with a separate configuration, and workload deploying component <b>308</b> can deploy the multiple workloads, as described above.</p><p id="p-0048" num="0045">In a specific example, the workloads can each correspond to a different instance of a RAN component, as described, such as a different base station. In this example, the configurations may each specify a different base station or cell identifier, which can allow for routing of requests to an appropriate workload based on the base station or cell identifier.</p><p id="p-0049" num="0046">Moreover, for example, where the workloads operate based on a separate configuration, workload deploying component <b>308</b> can determine additional workloads, as desired to reach a SLA, as standby workloads, which workload deploying component <b>308</b> may additionally deploy one or more nodes in the cloud-computing environment <b>310</b>. As described above with respect to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, workload deploying component <b>308</b> can deploy workload <b>202</b> with a first configuration, workload <b>204</b> with a second configuration, workload <b>206</b> with a third configuration, and/or standby workload <b>208</b>, each on a node of the cloud-computing environment, based on a deployment plan, etc.</p><p id="p-0050" num="0047">In method <b>500</b>, at action <b>504</b>, a standby workload can be executed as a second instance of the process without at least a portion of the separate configuration used by the multiple workloads. In an example, workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can execute the standby workload as the second instance of the process without, or otherwise agnostic to, at least the portion of the separate configuration used by the multiple workloads. For example, the standby workload, as described, can be a functional instance of the workload that may not be initially executing, or may not have a configuration for executing or activating the workload, and as such the standby workload can be configured to execute as one of multiple deployed nodes to provide redundancy thereof. In an example, the standby workload can be executing such that a load balancer/router <b>210</b> does not forward requests to the standby workload until the standby workload is configured (e.g., by a controller <b>212</b>).</p><p id="p-0051" num="0048">In method <b>500</b>, at action <b>506</b>, the multiple workloads can be monitored for failure or other termination. In an example, workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can monitor the multiple workloads for failure or other termination (e.g., termination of the node or of processes executing via the node for maintenance, etc.). As described, for example, workload deploying component <b>308</b> can be, or can be part of, an orchestration environment for managing workloads, and as such can receive, or monitor for, information of the workloads or related nodes, such as node failure or termination of the workload.</p><p id="p-0052" num="0049">In method <b>500</b>, at action <b>508</b>, it can be determined whether (or detected that) one of the multiple workloads is terminated. In an example, workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can determine termination of one of the multiple workloads. In this example, where the workload has terminated, at action <b>510</b>, the standby workload can be configured to execute based on the separate configuration of the separate instance of the process corresponding to the failed workload. In an example, workload configuring component <b>320</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can configure the standby workload to execute based on the separate configuration of the separate instance of the process corresponding to the failed workload. For example, workload configuring component <b>320</b> can determine the configuration of the terminated workload and can use the configuration in configuring the standby workload to execute as the terminated workload to provide redundancy therefor. In an example, the configuration can include one or more environment variables, such as a base station or cell identifier, and workload configuring component <b>320</b> can configure the standby workload to function as the terminated workload based on the base station or cell identifier. For example, workload configuring component <b>320</b> can provide the function of the controller <b>212</b> described herein.</p><p id="p-0053" num="0050">In addition, for example, based on termination of the one of the multiple workloads (and/or based on configuring the standby workload), optionally at action <b>512</b>, a second standby workload can be executed as a second instance of the process without at least the portion of the separate configuration used by the multiple workloads. In an example, workload deploying component <b>308</b>, e.g., in conjunction with processor <b>302</b>, memory <b>304</b>, operating system <b>306</b>, etc., can execute the second standby workload as the second instance of the process without at least the portion of the separate configuration used by the multiple workloads. For example, workload deploying component <b>308</b> can determine to add the second standby workload as an additional workload using the functions described above with reference to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In another example, workload deploying component <b>308</b> can determine to add the second standby workload as the terminated workload, such that the standby workload configured at action <b>510</b> can continue operating as the configured workload even when the terminated workload is reinitialized or reestablished, and the reinitialized terminated workload can be reinitiated as the standby workload. In yet another example, workload deploying component <b>308</b> can reinitialize or reestablish the terminated workload as originally configured once available, and can reconfiguration the standby workload that was configured at action <b>510</b> to return as the standby workload with no specific configuration.</p><p id="p-0054" num="0051"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example of device <b>600</b> including additional optional component details as those shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In one aspect, device <b>600</b> may include processor <b>602</b>, which may be similar to processor <b>302</b> for carrying out processing functions associated with one or more of components and functions described herein. Processor <b>602</b> can include a single or multiple set of processors or multi-core processors. Moreover, processor <b>602</b> can be implemented as an integrated processing system and/or a distributed processing system.</p><p id="p-0055" num="0052">Device <b>600</b> may further include memory <b>604</b>, which may be similar to memory <b>304</b> such as for storing local versions of operating systems (or components thereof) and/or applications being executed by processor <b>602</b>, such as a workload deploying component <b>308</b>, workload configuring component <b>320</b>, etc. Memory <b>604</b> can include a type of memory usable by a computer, such as random access memory (RAM), read only memory (ROM), tapes, magnetic discs, optical discs, volatile memory, non-volatile memory, and any combination thereof.</p><p id="p-0056" num="0053">Further, device <b>600</b> may include a communications component <b>606</b> that provides for establishing and maintaining communications with one or more other devices, parties, entities, etc. utilizing hardware, software, and services as described herein. Communications component <b>606</b> may carry communications between components on device <b>600</b>, as well as between device <b>600</b> and external devices, such as devices located across a communications network and/or devices serially or locally connected to device <b>600</b>. For example, communications component <b>606</b> may include one or more buses, and may further include transmit chain components and receive chain components associated with a wireless or wired transmitter and receiver, respectively, operable for interfacing with external devices.</p><p id="p-0057" num="0054">Additionally, device <b>600</b> may include a data store <b>608</b>, which can be any suitable combination of hardware and/or software, that provides for mass storage of information, databases, and programs employed in connection with aspects described herein. For example, data store <b>608</b> may be or may include a data repository for operating systems (or components thereof), applications, related parameters, etc.) not currently being executed by processor <b>602</b>. In addition, data store <b>608</b> may be a data repository for workload deploying component <b>308</b>, workload configuring component <b>320</b>, and/or one or more other components of the device <b>600</b>.</p><p id="p-0058" num="0055">Device <b>600</b> may optionally include a user interface component <b>610</b> operable to receive inputs from a user of device <b>600</b> and further operable to generate outputs for presentation to the user. User interface component <b>610</b> may include one or more input devices, including but not limited to a keyboard, a number pad, a mouse, a touch-sensitive display, a navigation key, a function key, a microphone, a voice recognition component, a gesture recognition component, a depth sensor, a gaze tracking sensor, a switch/button, any other mechanism capable of receiving an input from a user, or any combination thereof. Further, user interface component <b>610</b> may include one or more output devices, including but not limited to a display, a speaker, a haptic feedback mechanism, a printer, any other mechanism capable of presenting an output to a user, or any combination thereof.</p><p id="p-0059" num="0056">Device <b>600</b> may additionally include a workload deploying component <b>308</b> for deploying workloads of a process in a cloud-computing environment, a workload configuring component <b>320</b> for configuring different workloads as different instances of the process according to separate configurations, etc., as described herein.</p><p id="p-0060" num="0057">By way of example, an element, or any portion of an element, or any combination of elements may be implemented with a &#x201c;processing system&#x201d; that includes one or more processors. Examples of processors include microprocessors, microcontrollers, digital signal processors (DSPs), field programmable gate arrays (FPGAs), programmable logic devices (PLDs), state machines, gated logic, discrete hardware circuits, and other suitable hardware configured to perform the various functionality described throughout this disclosure. One or more processors in the processing system may execute software. Software shall be construed broadly to mean instructions, instruction sets, code, code segments, program code, programs, subprograms, software modules, applications, software applications, software packages, routines, subroutines, objects, executables, threads of execution, procedures, functions, etc., whether referred to as software, firmware, middleware, microcode, hardware description language, or otherwise.</p><p id="p-0061" num="0058">Accordingly, in one or more aspects, one or more of the functions described may be implemented in hardware, software, firmware, or any combination thereof. If implemented in software, the functions may be stored on or encoded as one or more instructions or code on a computer-readable medium. Computer-readable media includes computer storage media. Storage media may be any available media that can be accessed by a computer. By way of example, and not limitation, such computer-readable media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc, as used herein, includes compact disc (CD), laser disc, optical disc, digital versatile disc (DVD), and floppy disk where disks usually reproduce data magnetically, while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer-readable media.</p><p id="p-0062" num="0059">The previous description is provided to enable any person skilled in the art to practice the various aspects described herein. Various modifications to these aspects will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other aspects. Thus, the claims are not intended to be limited to the aspects shown herein, but is to be accorded the full scope consistent with the language claims, wherein reference to an element in the singular is not intended to mean &#x201c;one and only one&#x201d; unless specifically so stated, but rather &#x201c;one or more.&#x201d; Unless specifically stated otherwise, the term &#x201c;some&#x201d; refers to one or more. All structural and functional equivalents to the elements of the various aspects described herein that are known or later come to be known to those of ordinary skill in the art are expressly incorporated herein by reference and are intended to be encompassed by the claims. Moreover, nothing disclosed herein is intended to be dedicated to the public regardless of whether such disclosure is explicitly recited in the claims. No claim element is to be construed as a means plus function unless the element is expressly recited using the phrase &#x201c;means for.&#x201d;</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230007077A1-20230105-M00001.NB"><img id="EMI-M00001" he="8.13mm" wi="76.20mm" file="US20230007077A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method for deploying workloads on nodes in a cloud-computing environment, comprising:<claim-text>determining, for a process to be provided in the cloud-computing environment, a desired number of workloads of the process to be executed in the cloud-computing environment, wherein the desired number of workloads are each of a different configuration of the process;</claim-text><claim-text>determining a location of one or more nodes for deploying one or more workloads based on the desired number of workloads;</claim-text><claim-text>determining, based on the desired number of workloads and based on one or more failure probabilities associated with the location of the one or more nodes, an actual number of workloads of the process to execute in the cloud-computing environment to provide a level of service, wherein the actual number of workloads includes the desired number of workloads and one or more additional workloads; and</claim-text><claim-text>deploying, based on determining the actual number of workloads, the one or more workloads to the one or more nodes of the cloud-computing environment to reach the actual number of workloads of the process executing in the cloud-computing environment, wherein the one or more additional workloads are standby instances of the process agnostic to a configuration.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the actual number of workloads is based on the one or more failure probabilities of failure within a timeslot.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired number of workloads and the one or more additional workloads are of a same configuration of the process.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the actual number of workloads is further based on a type of node for executing the process.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the actual number of workloads is further based on an equipment cost of the one or more nodes.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the actual number of workloads is further based on a latency cost of the one or more nodes.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein determining the actual number of workloads includes using machine learning to determine the actual number of workloads based on a trained model of actual numbers of workloads to achieve desired numbers of workloads that achieved the level of service.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the process corresponds to a remote unit (RU) process, and wherein the desired number of workloads are each for a different configuration of the RU process, and wherein the one or more additional workloads are standby instances of the RU process agnostic to a configuration.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A device for deploying workloads on nodes in a cloud-computing environment, comprising:<claim-text>a memory storing one or more parameters or instructions for deploying workloads in the cloud-computing environment; and</claim-text><claim-text>at least one processor coupled to the memory, wherein the at least one processor is configured to:<claim-text>execute multiple workloads in a cloud-computing environment cluster, wherein each workload of the multiple workloads corresponds to a separate instance of a process that is executed according to a separate configuration;</claim-text><claim-text>execute a standby workload as a second instance of the process without at least a portion of the separate configuration used by the multiple workloads; and</claim-text><claim-text>based on detecting termination of one of the multiple workloads, configure the standby workload to execute based on the separate configuration of the separate instance of the process corresponding to the one of the multiple workloads,</claim-text><claim-text>wherein the process corresponds to a remote unit (RU) process in a mobile edge computing environment, and the multiple workloads are each for a different configuration of the RU process, and the standby workload is the second instance of the RU process without at least the portion of the separate configuration.</claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the at least one processor is further configured to, based on configuring the standby workload, execute a second standby workload as the second instance of the process without at least the portion of the separate configuration used by the multiple workloads.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The device of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the standby workload is the one of the multiple workloads for which termination was detected.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the process is a base station process and the separate configuration for each process relates to performing the process for a separate base station.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A device for deploying workloads on nodes in a cloud-computing environment, comprising:<claim-text>a memory storing one or more parameters or instructions for deploying workloads in the cloud-computing environment; and</claim-text><claim-text>at least one processor coupled to the memory, wherein the at least one processor is configured to:<claim-text>determine, for a process to be provided in the cloud-computing environment, a desired number of workloads of the process to be executed in the cloud-computing environment, wherein the desired number of workloads are each of a different configuration of the process;</claim-text><claim-text>determine a location of one or more nodes for deploying one or more workloads based on the desired number of workloads;</claim-text><claim-text>determine, based on the desired number of workloads and based on one or more failure probabilities associated with the location of the one or more nodes, an actual number of workloads of the process to execute in the cloud-computing environment to provide a level of service, wherein the actual number of workloads includes the desired number of workloads and one or more additional workloads; and</claim-text><claim-text>deploy, based on determining the actual number of workloads, the one or more workloads to the one or more nodes of the cloud-computing environment to reach the actual number of workloads of the process executing in the cloud-computing environment, wherein the one or more additional workloads are standby instances of the process agnostic to a configuration.</claim-text></claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the at least one processor is configured to determine the actual number of workloads based on the one or more failure probabilities of failure within a timeslot.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the desired number of workloads and the one or more additional workloads are of a same configuration of the process.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the at least one processor is configured to determine the actual number of workloads further based on a type of node for executing the process.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the at least one processor is configured to determine the actual number of workloads further based on an equipment cost of the one or more nodes.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the at least one processor is configured to determine the actual number of workloads further based on a latency cost of the one or more nodes.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the at least one processor is configured to determine the actual number of workloads at least in part by using machine learning to determine the actual number of workloads based on a trained model of actual numbers of workloads to achieve desired numbers of workloads that achieved the level of service.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The device of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the process corresponds to a remote unit (RU) process, and wherein the desired number of workloads are each for a different configuration of the RU process, and wherein the one or more additional workloads are standby instances of the RU process agnostic to a configuration.</claim-text></claim></claims></us-patent-application>
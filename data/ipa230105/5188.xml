<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005189A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005189</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17857189</doc-number><date>20220705</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>TW</country><doc-number>110148848</doc-number><date>20211227</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>9</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>9</main-group><subgroup>001</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e61">CONTENT PATCH ENCODING METHOD AND CONTENT PATCH DECODING METHOD</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63218401</doc-number><date>20210705</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Industrial Technology Research Institute</orgname><address><city>Hsinchu</city><country>TW</country></address></addressbook><residence><country>TW</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Lin</last-name><first-name>Jie-Ru</first-name><address><city>Yilan County</city><country>TW</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Lin</last-name><first-name>Ching-Chieh</first-name><address><city>Hsinchu City</city><country>TW</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Lin</last-name><first-name>Chun-Lung</first-name><address><city>Taipei City</city><country>TW</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Wang</last-name><first-name>Sheng-Po</first-name><address><city>Taoyuan City</city><country>TW</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Tu</last-name><first-name>Jih-Sheng</first-name><address><city>Yilan County</city><country>TW</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Industrial Technology Research Institute</orgname><role>03</role><address><city>Hsinchu</city><country>TW</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A content patch encoding method and a content patch decoding method are provided. The content patch decoding method includes: receiving a bit stream, and obtaining multiple information corresponding to a point cloud patch and a mesh patch accordingly; obtaining a connectivity between multiple vertices of the mesh patch based on the bit stream; and reconstructing the point cloud patch and the mesh patch based on the information and the connectivity between the vertices.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="74.85mm" wi="158.75mm" file="US20230005189A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="249.60mm" wi="140.72mm" orientation="landscape" file="US20230005189A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="247.90mm" wi="149.27mm" orientation="landscape" file="US20230005189A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="220.64mm" wi="119.80mm" orientation="landscape" file="US20230005189A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="141.82mm" wi="147.07mm" orientation="landscape" file="US20230005189A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="243.76mm" wi="158.83mm" orientation="landscape" file="US20230005189A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="224.03mm" wi="142.66mm" orientation="landscape" file="US20230005189A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="218.52mm" wi="152.40mm" orientation="landscape" file="US20230005189A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="162.48mm" wi="138.94mm" orientation="landscape" file="US20230005189A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="247.82mm" wi="158.07mm" orientation="landscape" file="US20230005189A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="230.80mm" wi="162.39mm" orientation="landscape" file="US20230005189A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="242.82mm" wi="148.42mm" orientation="landscape" file="US20230005189A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="190.33mm" wi="106.51mm" file="US20230005189A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="223.86mm" wi="166.88mm" orientation="landscape" file="US20230005189A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="237.74mm" wi="145.20mm" orientation="landscape" file="US20230005189A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="244.09mm" wi="146.13mm" orientation="landscape" file="US20230005189A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="159.85mm" wi="152.74mm" orientation="landscape" file="US20230005189A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="143.59mm" wi="134.11mm" orientation="landscape" file="US20230005189A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="195.33mm" wi="133.01mm" orientation="landscape" file="US20230005189A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="190.75mm" wi="159.85mm" orientation="landscape" file="US20230005189A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application claims the priority benefit of U.S. Provisional Application No. 63/218,401, filed on Jul. 5, 2021 and Taiwan Application No. 110148848, filed on Dec. 27, 2021. The entirety of each of the above-mentioned patent applications is hereby incorporated by reference herein and made a part of this specification.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Technical Field</heading><p id="p-0003" num="0002">The disclosure relates to a content encoding/decoding mechanism, and in particular to a content patch encoding method and a content patch decoding method.</p><heading id="h-0004" level="1">Description of Related Art</heading><p id="p-0004" num="0003">The mechanism of point cloud or contour is often used to process content in a three-dimensional space. In the concept of point cloud, a three-dimensional content is represented as multiple points in the three-dimensional space. Point cloud is often used to process real-time telepresence (for example, virtual reality) in application scenarios such as cultural heritage, sports broadcasting, and autonomous vehicles. The point cloud mechanism can enable some three-dimensional content to have finer quality.</p><p id="p-0005" num="0004">In the contour mechanism, a mechanism known as mesh based contour is often used to process a three-dimensional content. In the mesh based contour mechanism, one three-dimensional content may be divided into multiple triangles. The mesh based contour mechanism enables relatively smooth regions in the three-dimensional content to have better quality.</p><p id="p-0006" num="0005">For persons skilled in the art, how to design a three-dimensional content processing mechanism that has the advantages of both the point cloud and contour mechanisms is being discussed.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0007" num="0006">The disclosure provides a content patch encoding method and a content patch decoding method.</p><p id="p-0008" num="0007">The disclosure provides a content patch encoding method, which is suitable for an encoder and includes the following steps. A point cloud patch is obtained. The point cloud patch includes multiple points. A mesh patch is determined in the point cloud patch based on the points. The points include multiple first points and multiple second points corresponding to the mesh patch. The point cloud patch is updated to include the first points but not the second points. A first bit stream is generated according to the point cloud patch and the mesh patch, and the first bit stream is sent.</p><p id="p-0009" num="0008">The disclosure provides a content patch decoding method, which is suitable for a decoder and includes the following steps. At least one bit stream is received. Multiple information corresponding to a point cloud patch and a mesh patch are obtained based on the at least one bit stream. A connectivity between multiple vertices of the mesh patch is obtained based on the at least one bit stream. The point cloud patch and the mesh patch are reconstructed based on the information and the connectivity between the vertices.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0010" num="0009">The drawings are included to provide a further understanding of the disclosure, and the drawings are incorporated in and constitute a part of the specification. The drawings illustrate embodiments of the disclosure and serve to explain the principles of the disclosure together with the description.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram of a point cloud mechanism according to an embodiment of the disclosure.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of mesh based contour according to an embodiment of the disclosure.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic diagram of a three-dimensional content processing system according to an embodiment of the disclosure.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a flowchart of a content patch encoding method according to an embodiment of the disclosure.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a flowchart of determining a mesh patch in a point cloud patch according to an embodiment of the disclosure.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>6</b>G</figref> are application scenario diagrams according to an embodiment of the disclosure.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a schematic diagram of determining a first point and a second point according to an embodiment of the disclosure.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a schematic diagram of replacing the second point with a mesh patch according to <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic diagram of an occupancy map, a geometry map, and an attribute map according to an embodiment of the disclosure.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a schematic diagram of a recording manner of adjusted coordinates according to an embodiment of the disclosure.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a schematic diagram of estimating roughness of a point cloud patch according to an embodiment of the disclosure.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart of a content patch decoding method according to an embodiment of the disclosure.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>12</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>12</b>B</figref> are schematic diagrams of a syntax design according to an embodiment of the disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION OF DISCLOSED EMBODIMENTS</heading><p id="p-0024" num="0023">Reference will now be made in detail to the exemplary embodiments of the disclosure, examples of which are illustrated in the drawings. Wherever possible, the same reference numerals are used in the drawings and description to refer to the same or similar parts.</p><p id="p-0025" num="0024">Please refer to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, which is a schematic diagram of a point cloud mechanism according to an embodiment of the disclosure. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a three-dimensional content <b>11</b> may include multiple points, wherein the points do not necessarily have a specific order, and there is not necessarily a specific relationship between the points. In addition, each point in the point cloud has corresponding geometry information (for example, coordinates of the point in a three-dimensional space) and attribute information (for example, color, reflectivity, transparency, etc.). The points are individually projected onto a corresponding projection plane via a projection mechanism. Specifically, after obtaining the three-dimensional content <b>11</b>, an encoder may first estimate a normal vector of each point, and project each point onto one of multiple projection planes of a projection space <b>12</b> (for example, a rectangular parallelepiped) accordingly. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the projection space <b>12</b> includes, for example, 6 projection planes, and each point in the three-dimensional content <b>11</b> may be projected onto the corresponding projection plane according to the normal vector thereof, thereby forming multiple point cloud patches on the 6 projection planes. Then, the encoder may generate a corresponding occupancy map <b>13</b><i>a</i>, geometry map <b>13</b><i>b</i>, and attribute map <b>13</b><i>c </i>according to the point cloud patches.</p><p id="p-0026" num="0025">In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the occupancy map <b>13</b><i>a </i>is, for example, a bitmap including only 1 and 0. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the occupancy map <b>13</b><i>a </i>may include, for example, multiple white regions (that is, regions composed of 1), and each white region corresponds to one of the point cloud patches. Each white region also has corresponding regions in the geometry map <b>13</b><i>b </i>and the attribute map <b>13</b><i>c</i>, and the regions may be used to record geometry information and attribute information of the corresponding point cloud patch. For example, assuming that a first region corresponding to a certain point cloud patch A is included in the occupancy map <b>13</b><i>a</i>, the geometry map <b>13</b><i>b </i>and the attribute map <b>13</b><i>c </i>will respectively include a second region and a third region corresponding to the first region, wherein the second region may record three-dimensional coordinates of each point in the point cloud patch A, and the third region may record the attribute information (for example, color, etc.) of each point in the point cloud patch A.</p><p id="p-0027" num="0026">After that, the encoder may encode the occupancy map <b>13</b><i>a</i>, the geometry map <b>13</b><i>b</i>, and the attribute map <b>13</b><i>c </i>into a bit stream <b>14</b>, and a decoder may obtain an occupancy map <b>15</b><i>a</i>, a geometry map <b>15</b><i>b</i>, and an attribute map <b>15</b><i>c </i>(which are respectively the restored occupancy map <b>13</b><i>a</i>, geometry map <b>13</b><i>b</i>, and attribute map <b>13</b><i>c</i>) based on the bit stream <b>14</b>. Afterwards, the decoder may then reconstruct each point cloud patch in the three-dimensional space based on the occupancy map <b>15</b><i>a</i>, the geometry map <b>15</b><i>b</i>, and the attribute map <b>15</b><i>c</i>, and each reconstructed point cloud patch may form a three-dimensional content <b>16</b> (which is, for example, the reconstructed three-dimensional content <b>11</b>).</p><p id="p-0028" num="0027">Generally speaking, although the point cloud mechanism can enable some three-dimensional content to have finer quality, discontinuous holes or noises may, for example, appear in certain relatively smooth regions, thereby affecting the quality of the three-dimensional content.</p><p id="p-0029" num="0028">Please refer to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, which is a schematic diagram of mesh based contour according to an embodiment of the disclosure. In <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a three-dimensional content <b>21</b> may be divided into multiple triangles (for example, triangles <b>21</b><i>a</i>), wherein each triangle may be represented by coordinates and a connectivity of vertices thereof. In this case, geometry information (for example, coordinates) and attributes (for example, color, reflectivity, transparency, etc.) of each vertex of each triangle are recorded, and the connectivity between the vertices is also recorded.</p><p id="p-0030" num="0029">For example, it is assumed that the three vertices of the triangle <b>21</b><i>a </i>are respectively V<sub>1</sub>, V<sub>2</sub>, and V<sub>3</sub>, where the coordinates of V<sub>1 </sub>in the three-dimensional space are, for example, (X<sub>V1</sub>, Y<sub>V1</sub>, Z<sub>V1</sub>), the coordinates of V<sub>2 </sub>in the three-dimensional space are, for example, (X<sub>V2</sub>, Y<sub>V2</sub>, Z<sub>V2</sub>), and the coordinates of V<sub>3 </sub>in the three-dimensional space are, for example, (X<sub>V3</sub>, Y<sub>V3</sub>, Z<sub>V3</sub>). In addition, the connectivity between V<sub>1</sub>, V<sub>2</sub>, and V<sub>3 </sub>may be, for example, represented as (V<sub>1</sub>, V<sub>2</sub>, V<sub>3</sub>).</p><p id="p-0031" num="0030">In general, although the mesh based contour mechanism can enable relatively smooth regions in the three-dimensional content to have better quality, it may be more difficult to effectively present fine textures.</p><p id="p-0032" num="0031">The disclosure provides the content patch encoding method, the encoder, the content patch decoding method, and the decoder, which can enable the reconstructed point cloud patch and mesh patch to have better image quality.</p><p id="p-0033" num="0032">Please refer to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, which is a schematic diagram of a three-dimensional content processing system according to an embodiment of the disclosure. In <figref idref="DRAWINGS">FIG. <b>3</b></figref>, a three-dimensional content processing system <b>300</b> includes an encoder <b>310</b> and a decoder <b>320</b>, wherein the encoder <b>310</b> includes a transceiver <b>312</b> and a processor <b>314</b>, and the decoder <b>320</b> includes a transceiver <b>322</b> and a processor <b>324</b>.</p><p id="p-0034" num="0033">In different embodiments, the transceivers <b>312</b> and <b>322</b> may be, for example, implemented as various transceiver interfaces that may be used to transmit/receive a bit stream ST, such as a wired or wireless network such as Ethernet, wireless LAN (WLAN), Bluetooth, ZigBee, worldwide interoperability for microwave access (WiMAX), third generation (3G) mobile communication technology, fourth generation (4G) mobile communication technology, long term evolution (LTE), LTE-advanced, and fifth generation (5G) mobile communication technology. In addition, the processor <b>314</b> is coupled to the transceiver <b>312</b>, and the processor <b>324</b> is coupled to the transceiver <b>322</b>.</p><p id="p-0035" num="0034">In different embodiments, the processors <b>314</b> and <b>324</b> may be general purpose processors, specific purpose processors, conventional processors, digital signal processors, microprocessors, one or more microprocessors combined with digital signal processor cores, controllers, microcontrollers, application specific integrated circuits (ASICs), field programmable gate arrays (FPGAs), any other types of integrated circuits, state machines, processors based on advanced RISC machine (ARM), etc.</p><p id="p-0036" num="0035">In the embodiment of the disclosure, the processor <b>314</b> may access specific (for example, but not limited to) modules and program codes to implement the content patch encoding method provided by the disclosure, and the details thereof are described below.</p><p id="p-0037" num="0036">Please refer to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, which is a flowchart of a content patch encoding method according to an embodiment of the disclosure. The method of the embodiment may be executed by the encoder <b>310</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The following describes the details of each step in <figref idref="DRAWINGS">FIG. <b>4</b></figref> with the components shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0038" num="0037">In the embodiment, the encoder may first project each point in the considered three-dimensional content onto the corresponding projection plane based on the mechanism shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> to form multiple point cloud patches. Afterwards, the encoder <b>310</b> may execute the method shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> on each point cloud patch to encode each point cloud patch, and the details thereof are described below.</p><p id="p-0039" num="0038">First, in Step S<b>410</b>, the processor <b>314</b> obtains a point cloud patch PA, wherein the point cloud patch PA includes multiple points PP, and the point cloud patch PA may correspond to a certain projection plane (for example, one of the projection planes in the projection space <b>12</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, hereinafter referred to as a specific projection plane).</p><p id="p-0040" num="0039">After that, in Step S<b>420</b>, the processor <b>314</b> determines a mesh patch MP in the point cloud patch PA based on the points PP. In some embodiments, the mesh patch MP may include, for example, multiple reference triangles, and the details of Step S<b>420</b> will be described below with reference to <figref idref="DRAWINGS">FIG. <b>5</b></figref>. In addition, in order for the concept of <figref idref="DRAWINGS">FIG. <b>5</b></figref> to be easier to understand, the following will be further described in conjunction with <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>, wherein <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> to <figref idref="DRAWINGS">FIG. <b>6</b>G</figref> are application scenario diagrams according to an embodiment of the disclosure.</p><p id="p-0041" num="0040">Please refer to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, which is a flowchart of determining a mesh patch in a point cloud patch according to an embodiment of the disclosure. First, in Step S<b>510</b>, the processor <b>314</b> obtains a first reference point p among the points of the point cloud patch PA, and finds a second reference point m and a third reference point n among the points of the point cloud patch PA accordingly.</p><p id="p-0042" num="0041">Taking <figref idref="DRAWINGS">FIG. <b>6</b>A</figref> as an example, it is assumed that each point in the point cloud patch PA is illustrated as a circle in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>. The processor <b>314</b> may, for example, select one (for example, randomly select one) of the points as the first reference point p. Afterwards, the processor <b>314</b> may, for example, determine a specified region Q based on the first reference point p and a specified radius R, and find the second reference point m and the third reference point n in the specified region Q.</p><p id="p-0043" num="0042">In an embodiment, the processor <b>314</b> may, for example, determine the specified radius R based on the bounding box, the quantization parameter (denoted by QP), and the reference factor (denoted by a) of the point cloud patch PA. Taking <figref idref="DRAWINGS">FIG. <b>6</b>B</figref> as an example, assuming that the processor <b>314</b> determines a bounding box BB corresponding to the point cloud patch PA based on the distribution of each point in the point cloud patch PA, the processor <b>314</b> may, for example, correspondingly estimate a diagonal length PD of the bounding box BB.</p><p id="p-0044" num="0043">Afterwards, the processor <b>314</b> may, for example, estimate the specified radius R based on the equation of</p><p id="p-0045" num="0000"><maths id="MATH-US-00001" num="00001"><math overflow="scroll"> <mrow>  <mrow>   <mo>&#x201c;</mo>   <mrow>    <mi>R</mi>    <mo>=</mo>    <mrow>     <mfrac>      <mn>1</mn>      <mi>&#x3b1;</mi>     </mfrac>     <mo>&#xd7;</mo>     <mi>PD</mi>     <mo>&#xd7;</mo>     <msub>      <mi>Q</mi>      <mi>step</mi>     </msub>    </mrow>   </mrow>   <mo>&#x201d;</mo>  </mrow>  <mo>,</mo> </mrow></math></maths></p><p id="p-0046" num="0000">but not limited thereto.</p><p id="p-0047" num="0044">In an embodiment, in response to different combinations of quantization parameters, reference factors, and diagonal lengths PD, the estimation result of the specified radius R may be exemplified in Table 1 below, but not limited thereto.</p><p id="p-0048" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0"><tgroup align="left" colsep="0" rowsep="0" cols="5"><colspec colname="1" colwidth="56pt" align="center"/><colspec colname="2" colwidth="21pt" align="center"/><colspec colname="3" colwidth="63pt" align="center"/><colspec colname="4" colwidth="21pt" align="center"/><colspec colname="5" colwidth="56pt" align="center"/><thead><row><entry namest="1" nameend="5" rowsep="1">TABLE 1</entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row><row><entry>R</entry><entry>&#x3b1;</entry><entry>PD</entry><entry>Q<sub>step</sub></entry><entry>QP</entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="5"><colspec colname="1" colwidth="56pt" align="char" char="."/><colspec colname="2" colwidth="21pt" align="char" char="."/><colspec colname="3" colwidth="63pt" align="char" char="."/><colspec colname="4" colwidth="21pt" align="char" char="."/><colspec colname="5" colwidth="56pt" align="char" char="."/><tbody valign="top"><row><entry>3</entry><entry>200</entry><entry>60</entry><entry>11</entry><entry>25</entry></row><row><entry>4</entry><entry>400</entry><entry>80</entry><entry>20</entry><entry>30</entry></row><row><entry>6</entry><entry>600</entry><entry>100</entry><entry>36</entry><entry>35</entry></row><row><entry>10</entry><entry>800</entry><entry>120</entry><entry>64</entry><entry>40</entry></row><row><entry>17</entry><entry>1000</entry><entry>150</entry><entry>114</entry><entry>45</entry></row><row><entry namest="1" nameend="5" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0049" num="0045">After obtaining the specified radius R, the processor <b>314</b> may define a spherical region as the specified region Q with the first reference point p as the center and the specified radius R as the radius, but not limited thereto.</p><p id="p-0050" num="0046">After determining the specified region Q, the processor <b>314</b> may find any two points therein that meet the following condition as the second reference point m and the third reference point n.</p><p id="p-0051" num="0000"><maths id="MATH-US-00002" num="00002"><math overflow="scroll"> <mrow>  <mi>m</mi>  <mo>,</mo>  <mrow>   <mi>n</mi>   <mo>=</mo>   <mrow>    <munder>     <mrow>      <mi>arg</mi>      <mo>&#x2062;</mo>      <mi>min</mi>     </mrow>     <mrow>      <mi>m</mi>      <mtext> </mtext>      <mo>,</mo>      <mrow>       <mi>n</mi>       <mo>&#x2208;</mo>       <mi>Q</mi>      </mrow>     </mrow>    </munder>    <mo>&#x2062;</mo>    <mi>&#x3b8;</mi>   </mrow>  </mrow>  <mo>,</mo>  <mrow>   <mi>&#x3b8;</mi>   <mo>=</mo>   <mrow>    <msup>     <mi>cos</mi>     <mrow>      <mo>-</mo>      <mn>1</mn>     </mrow>    </msup>    <mo>(</mo>    <mfrac>     <mrow>      <mrow>       <mo>(</mo>       <mrow>        <mover>         <mi>pm</mi>         <mo>&#x2192;</mo>        </mover>        <mo>&#xd7;</mo>        <mover>         <mi>pn</mi>         <mo>&#x2192;</mo>        </mover>       </mrow>       <mo>)</mo>      </mrow>      <mo>&#xb7;</mo>      <mover>       <mi>N</mi>       <mo>&#x2192;</mo>      </mover>     </mrow>     <mrow>      <mrow>       <mo>&#xf605;</mo>       <mrow>        <mover>         <mi>pm</mi>         <mo>&#x2192;</mo>        </mover>        <mo>&#xd7;</mo>        <mover>         <mi>pn</mi>         <mo>&#x2192;</mo>        </mover>       </mrow>       <mo>&#xf606;</mo>      </mrow>      <mo>&#x2062;</mo>      <mrow>       <mo>&#xf605;</mo>       <mover>        <mi>N</mi>        <mo>&#x2192;</mo>       </mover>       <mo>&#xf606;</mo>      </mrow>     </mrow>    </mfrac>    <mo>)</mo>   </mrow>  </mrow> </mrow></math></maths></p><p id="p-0052" num="0047">where {right arrow over (pm)} is the vector between the first reference point p and the second reference point m, {right arrow over (pn)} is the vector between the first reference point p and the third reference point n, {right arrow over (N)} is the normal vector of the first reference point p, and the normal vector of the first reference point p points to the specific projection plane corresponding to the point cloud patch PA.</p><p id="p-0053" num="0048">In an embodiment, the concept of the above condition may be illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>C</figref>. In <figref idref="DRAWINGS">FIG. <b>6</b>C</figref>, after the processor <b>314</b> finds the vectors between the first reference point p and any two points in the specified region Q, the outer product vector between the two vectors is taken, and an included angle (&#x3b8;) between the outer product vector and the normal vector ({right arrow over (N)}) of the first reference point p is estimated accordingly. Afterwards, the processor <b>314</b> may adopt the two points corresponding to the smallest included angle as the second reference point m and the third reference point n, but not limited thereto.</p><p id="p-0054" num="0049">After determining the first reference point p, the second reference point m, and the third reference point n, in Step S<b>520</b>, the processor <b>314</b> forms multiple vertices of the i-th reference triangle among the reference triangles of the mesh patch MP with the first reference point p, the second reference point m, and the third reference point n, and determines multiple candidate triangles based on multiple edges of the i-th reference triangle, wherein an initial value of i is 1, and multiple vertices of each candidate triangle include two of the first reference point p, the second reference point m, and the third reference point n, and one of the points.</p><p id="p-0055" num="0050">Taking <figref idref="DRAWINGS">FIG. <b>6</b>D</figref> as an example, the processor <b>314</b> may form vertices of a reference triangle T<b>1</b> based on the first reference point p, the second reference point m, and the third reference point n, and determine candidate triangles CT<b>1</b> to CT<b>3</b> based on multiple edges E<b>1</b> to E<b>3</b> of the reference triangle T<b>1</b>. As shown in <figref idref="DRAWINGS">FIG. <b>6</b>D</figref>, the candidate triangle CT<b>1</b> includes the first reference point p, the third reference point n, and a point o<sub>1 </sub>in the point cloud patch PA; the candidate triangle CT<b>2</b> includes the first reference point p, the second reference point m, and a point o<sub>2 </sub>in the point cloud patch PA; and the candidate triangle CT<b>2</b> includes the second reference point m, the third reference point n, and a point o<sub>3 </sub>in the point cloud patch PA.</p><p id="p-0056" num="0051">In an embodiment, during the process of determining the candidate triangles CT<b>1</b> to CT<b>3</b>, the processor <b>314</b> may be, for example, configured to execute: determining a specific sphere based on the vertices of the i-th reference triangle; moving the specific sphere respectively toward the edges E<b>1</b> to E<b>3</b> to determine multiple reference spheres, wherein each reference sphere includes at least two of the vertices of the i-th reference triangle; and in response to judging that the j-th reference sphere also includes another point (hereinafter referred to as a specific point), determining the j-th candidate triangle with two of the vertices of the i-th reference triangle and the other point, where 1&#x2264;j&#x2264;3.</p><p id="p-0057" num="0052">On the other hand, in response to judging that the j-th reference sphere includes only two of the vertices of the i-th reference triangle, the processor <b>314</b> may adjust the size of the j-th reference sphere until after the adjusted j-th reference sphere includes two of the vertices of the i-th reference triangle and the other point. Afterwards, the processor <b>314</b> may determine the j-th candidate triangle with two of the vertices of the i-th reference triangle and the other point.</p><p id="p-0058" num="0053">The concept of determining the candidate triangles CT<b>1</b> to CT<b>3</b> will be further described in conjunction with <figref idref="DRAWINGS">FIG. <b>6</b>E</figref>. In <figref idref="DRAWINGS">FIG. <b>6</b>E</figref>, the processor <b>314</b> may first determine the specific sphere based on the vertices of the i-th reference triangle (that is, the reference triangle T<b>1</b>). In an embodiment, the vertices (that is, the first reference point p, the second reference point m, and the third reference point n) of the reference triangle T<b>1</b> simultaneously fall on the specific sphere. Afterwards, the processor <b>314</b> may move the specific sphere toward the edge E<b>2</b>, and the moved specific sphere is, for example, a reference sphere S. As shown in <figref idref="DRAWINGS">FIG. <b>6</b>E</figref>, the reference sphere S still includes the first reference point p and the second reference point m.</p><p id="p-0059" num="0054">In Scenario 1, if the moved specific sphere (that is, the reference sphere S) includes another point in addition to the first reference point p and the second reference point m, the processor <b>314</b> may use the point as the point o<sub>2</sub>, thereby determining the candidate triangle CT<b>2</b> (that is, the 2-nd candidate triangle), wherein the point o<sub>2 </sub>may be understood as a specific point of the candidate triangle CT<b>2</b>.</p><p id="p-0060" num="0055">In Scenario 2, if the moved specific sphere (that is, the reference sphere S) includes only the first reference point p and the second reference point m, and the reference sphere S does not include other points therein, the processor <b>314</b> may expand the reference sphere S (for example, increase a radius r of the reference sphere S to a radius r&#x2032;) until the expanded reference sphere S includes another point in addition to the first reference point p and the second reference point m. At this time, the processor <b>314</b> may use the point as the point o<sub>2</sub>, thereby determining the candidate triangle CT<b>2</b>, wherein the point o<sub>2 </sub>may be understood as the specific point of the candidate triangle CT<b>2</b>.</p><p id="p-0061" num="0056">In Scenario 3, if the reference sphere S only includes the first reference point p and the second reference point m, and the reference sphere S includes another point therein, the processor <b>314</b> may shrink the reference sphere S (for example, shrink the radius r of the reference sphere S to the radius r&#x2032;) until the shrunk reference sphere S includes the other point in addition to the first reference point p and the second reference point m. At this time, the processor <b>314</b> may use the point as the point o<sub>2</sub>, thereby determining the candidate triangle CT<b>2</b>, wherein the point o<sub>2 </sub>may be understood as the specific point of the candidate triangle CT<b>2</b>.</p><p id="p-0062" num="0057">Based on the above teachings, persons skilled in the art should be able to correspondingly understand the manner in which the processor <b>314</b> determines the candidate triangles CT<b>1</b> and CT<b>3</b>, and details are not described herein.</p><p id="p-0063" num="0058">After determining the candidate triangles CT<b>1</b> to CT<b>3</b>, in Step S<b>530</b>, the processor <b>314</b> selects a specific candidate triangle from the candidate triangles CT<b>1</b> to CT<b>3</b>. In an embodiment, the processor <b>314</b> may estimate the contour cost of each of the candidate triangles CT<b>1</b> to CT<b>3</b>, and select the specific candidate triangle from the candidate triangles CT<b>1</b> to CT<b>3</b> accordingly. In an embodiment, the contour cost of the specific candidate triangle is the lowest.</p><p id="p-0064" num="0059">In an embodiment, when estimating the j-th candidate triangle, the processor <b>314</b> may be configured to execute: projecting points in the j-th reference sphere onto the j-th candidate triangle, and determining a projection distance of each point in the j-th reference sphere accordingly; and estimating the contour cost of the j-th candidate triangle based on the projection distance of each point in the j-th reference sphere, the number of points in the j-th reference sphere, and a reference factor.</p><p id="p-0065" num="0060">The concept of estimating the contour cost of each of the candidate triangles CT<b>1</b> to CT<b>3</b> will be further explained in conjunction with <figref idref="DRAWINGS">FIG. <b>6</b>F</figref>. In <figref idref="DRAWINGS">FIG. <b>6</b>F</figref>, when estimating the contour cost (denoted by J<sub>1</sub>) of the candidate triangle CT<b>1</b> (that is, the 1-st candidate triangle), the processor <b>314</b> may project all points (for example, a point <b>611</b>) in the corresponding reference sphere (that is, the 1-st reference sphere, which is shown by dotted lines) onto the candidate triangle CT<b>1</b>, and determine the projection distance of each point accordingly. For example, the processor <b>314</b> may estimate a projection distance <b>612</b> accordingly after projecting the point <b>611</b> onto the candidate triangle CT<b>1</b>. Based on this, the processor <b>314</b> may estimate the projection distance of each point in the 1-st reference sphere.</p><p id="p-0066" num="0061">Afterwards, the processor <b>314</b> may estimate the contour cost J<sub>1 </sub>of the candidate triangle CT<b>1</b> based on the projection distance of each point in the 1-st reference sphere, the number of points in the 1-st reference sphere, and the reference factor (denoted by &#x3bb;). In an embodiment, the contour cost J<sub>1 </sub>may be, for example, represented as</p><p id="p-0067" num="0000"><maths id="MATH-US-00003" num="00003"><math overflow="scroll"> <mrow>  <mrow>   <mo>&#x201c;</mo>   <mrow>    <msub>     <mi>J</mi>     <mn>1</mn>    </msub>    <mo>=</mo>    <mrow>     <mrow>      <mo>&#x2211;</mo>      <msub>       <mi>E</mi>       <mn>1</mn>      </msub>     </mrow>     <mo>+</mo>     <mrow>      <mi>&#x3bb;</mi>      <mo>&#xb7;</mo>      <mfrac>       <mn>1</mn>       <msub>        <mi>Num</mi>        <mn>1</mn>       </msub>      </mfrac>     </mrow>    </mrow>   </mrow>   <mo>&#x201d;</mo>  </mrow>  <mo>,</mo> </mrow></math></maths></p><p id="p-0068" num="0000">where &#x3a3;E<sub>1 </sub>represents the sum of the projection distances of each point in the 1-st reference sphere, and Num<sub>1 </sub>represents the number of points in the 1-st reference sphere, but not limited thereto.</p><p id="p-0069" num="0062">Based on the similarity principle, the processor <b>314</b> may estimate the contour cost (denoted by J<sub>2</sub>) of the candidate triangle CT<b>2</b> (that is, the 2-nd candidate triangle) and the contour cost (denoted by J<sub>3</sub>) of the candidate triangle CT<b>3</b> (that is, the 3-rd candidate triangle) accordingly, and the details thereof will not be repeated.</p><p id="p-0070" num="0063">After obtaining the contour costs J<sub>1 </sub>to J<sub>3</sub>, the processor <b>314</b> may, for example, select the lowest one therefrom, and use the corresponding candidate triangle as the selected specific candidate triangle. For example, if the contour cost J<sub>1 </sub>is the lowest among the contour costs J<sub>1 </sub>to J<sub>3</sub>, the processor <b>314</b> may select the candidate triangle CT<b>1</b> as the specific candidate triangle; if the contour cost J<sub>2 </sub>is the lowest among the contour costs J<sub>1 </sub>to J<sub>3</sub>, the processor <b>314</b> may select the candidate triangle CT<b>2</b> as the specific candidate triangle; and if the contour cost J<sub>3 </sub>is the lowest among the contour costs J<sub>1 </sub>to J<sub>3</sub>, the processor <b>314</b> may select the candidate triangle CT<b>3</b> as the specific candidate triangle, but not limited thereto.</p><p id="p-0071" num="0064">After determining the specific candidate triangle, the processor <b>314</b> may execute Step S<b>540</b> to judge whether the specific point of the specific candidate triangle is a vertex of a previously formed reference triangle. If not, the processor <b>314</b> may continue to execute Step S<b>550</b> to update the considered first reference point p, second reference point m, and third reference point n to the vertices of the specific candidate triangle, increment i, and return to Step S<b>520</b>.</p><p id="p-0072" num="0065">In short, the processor <b>314</b> may use the vertices of the current specific candidate triangle as the new first reference point p, second reference point m, and third reference point n, and execute Steps S<b>520</b> to S<b>540</b> again. In this case, the new first reference point p, second reference point m, and third reference point n form a reference triangle T<b>2</b> (that is, the 2-nd reference triangle in the mesh patch MP), and the processor <b>314</b> determines multiple candidate triangles and a specific candidate triangle corresponding to the reference triangle T<b>2</b> according to the teachings of the foregoing embodiment. The operation will continue to repeat until no more other candidate triangles can be found.</p><p id="p-0073" num="0066">In an embodiment, if the judgement result of Step S<b>540</b> is yes, the processor <b>314</b> may continue to execute Step S<b>560</b> to judge whether there are other candidate triangles. If yes, Step S<b>580</b> may be continuously executed to obtain the other candidate triangles, and return to Step S<b>530</b>; and if not, Step S<b>570</b> may be executed to use the specific candidate triangle as the last one of the reference triangles, and judge that the reference triangles of the mesh patch MP are found.</p><p id="p-0074" num="0067">The concept will be further illustrated in conjunction with <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>. In a stage PH<b>1</b> of <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>, the processor <b>314</b> may determine the reference triangle T<b>1</b> based on previous teachings. In a stage PH<b>2</b>, the processor <b>314</b> may determine the corresponding specific candidate triangle based on the reference triangle T<b>1</b>. In <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>, assuming that the specific point of the specific candidate triangle determined in the stage PH<b>2</b> is not the vertex of the previously formed reference triangle, the processor <b>314</b> may use the vertex of the specific candidate triangle as the new first reference point p, second reference point m, and third reference point n to form a candidate triangle T<b>2</b>.</p><p id="p-0075" num="0068">In a stage PH<b>3</b>, the processor <b>314</b> may determine the corresponding specific candidate triangle based on the reference triangle T<b>2</b>. In <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>, assuming that the specific point of the specific candidate triangle determined in the stage PH<b>3</b> is not the vertex of the previously formed reference triangle, the processor <b>314</b> may use the vertex of the specific candidate triangle as the new first reference point p, second reference point m, and third reference point n to form a candidate triangle T<b>3</b>. Based on the above principle, the processor <b>314</b> may respectively obtain candidate triangles T<b>4</b> and T<b>5</b> in the stages PH<b>4</b> and P<b>5</b> accordingly.</p><p id="p-0076" num="0069">In a stage PH<b>6</b>, the processor <b>314</b> may determine the corresponding specific candidate triangle based on the reference triangle T<b>5</b>. In <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>, assuming that the specific point of the specific candidate triangle determined in the stage PH<b>6</b> is not the vertex of the previously formed reference triangle (for example, the same as one of the vertices of the reference triangle T<b>1</b>), and there are no other candidate triangles, the processor <b>314</b> may use the specific candidate triangle as the last one (that is, a candidate triangle T<b>6</b>) of the reference triangles of the mesh patch MP, and judge that the reference triangles of the mesh patch MP are found.</p><p id="p-0077" num="0070">It can be seen from <figref idref="DRAWINGS">FIG. <b>6</b>G</figref> that the mesh patch MP is formed by the reference triangles T<b>1</b> to T<b>6</b>, but not limited thereto. In other embodiments, the considered mesh patch MP may include more/less reference triangles according to the distribution of points in the point cloud patch PA, which is not limited to the form shown in <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>.</p><p id="p-0078" num="0071">Please refer to <figref idref="DRAWINGS">FIG. <b>4</b></figref> again. After determining the mesh patch MP, the processor <b>314</b> may find multiple first points not corresponding to the mesh patch MP and multiple second points corresponding to the mesh patch MP in the point cloud patch PA.</p><p id="p-0079" num="0072">In an embodiment, during the process of determining the first points/second points, the processor <b>314</b> may be configured to execute: projecting the mesh patch MP onto a specific projection plane PL corresponding to the point cloud patch PA to form a reference region on the specific projection plane PL; projecting the points in the point cloud patch PA onto the specific projection plane PL to form multiple projection points; finding multiple first projection points not located in the reference region from the projection points, and using points corresponding to the first projection points as the first points; and finding multiple second projection points in the reference region from the projection points, and using points corresponding to the second projection points as the second points.</p><p id="p-0080" num="0073">The concept will be further illustrated in conjunction with <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>. Please refer to <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, which is a schematic diagram of determining a first point and a second point according to an embodiment of the disclosure. In the embodiment, the processor <b>314</b> may execute the same operation on each reference triangle of the mesh patch MP to find the second point corresponding to the mesh patch MP. Therefore, the following description will be based on only one reference triangle Ti of the mesh patch MP.</p><p id="p-0081" num="0074">In <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, the processor <b>314</b> may project the reference triangle Ti onto the specific projection plane PL to form a projection region PR. After projecting each reference triangle of the mesh patch MP onto the specific projection plane PL, the projection region corresponding to each reference triangle may form the reference region.</p><p id="p-0082" num="0075">Afterwards, the processor <b>314</b> may project the points (shown as solid line circles) in the point cloud patch PA onto the specific projection plane PL to form multiple projection points (shown as dotted line circles). Next, the processor <b>314</b> may regard points not located in the reference region as the first projection points, and regard the points in the corresponding point cloud patch PA as the first points not corresponding to the mesh patch MP.</p><p id="p-0083" num="0076">In addition, the processor <b>314</b> may regard points located in the reference region as the second projection points (for example, the dotted line circles in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>), and regard points (for example, the solid line circles in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>) in the corresponding point cloud PA as the second points corresponding to the mesh patch MP.</p><p id="p-0084" num="0077">In Step S<b>430</b>, the processor <b>314</b> updates the point cloud patch PA to include the first points but not the second points. Roughly speaking, the method of the disclosure may replace the second points corresponding to the mesh patch MP with the mesh patch MP. In this case, the processor <b>314</b> may no longer record relevant information (for example, coordinates, color, etc.) of each second point in the form of a point cloud, but record information (for example, vertices and corresponding connectivity) of each reference triangle in the mesh patch MP.</p><p id="p-0085" num="0078">Please refer to <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, which is a schematic diagram of replacing the second point with a mesh patch according to <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>. In <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, it is assumed that the reference triangle Ti have vertices V<sub>1</sub>, V<sub>2</sub>, and V<sub>3 </sub>(whose coordinates are respectively, for example, (X<sub>V1</sub>, Y<sub>V1</sub>, Z<sub>V1</sub>) to (X<sub>V3</sub>, Y<sub>V3</sub>, Z<sub>V3</sub>), and the coordinates corresponding to multiple second points P<sub>1</sub>&#x2dc;-P of the reference triangle Ti (which are, for example, illustrated as circles located in the reference triangle Ti) are respectively (X<sub>P1</sub>, Y<sub>P1</sub>, Z<sub>P1</sub>) to (X<sub>Pn</sub>, Y<sub>Pn</sub>, Z<sub>Pn</sub>). In addition, a connectivity between the vertices V<sub>1</sub>, V<sub>2</sub>, and V<sub>3 </sub>may be expressed as (V<sub>1</sub>, V<sub>2</sub>, V<sub>3</sub>).</p><p id="p-0086" num="0079">After finding the second points P<sub>1</sub>&#x2dc;P<sub>n</sub>, the processor <b>314</b> may no longer record the relevant information of the second points P<sub>1</sub>&#x2dc;P<sub>n</sub>, but only record the relevant information (for example, vertices and connectivity) of the reference triangle Ti.</p><p id="p-0087" num="0080">However, for the first points not corresponding to the mesh patch MP, the processor <b>314</b> still needs to record the relevant information (for example, coordinates, color, etc.) of each first point. Since the information of each second point does not need to be recorded in the form of a point cloud, the processor <b>314</b> may remove the second point from the point cloud patch PA to update the point cloud patch PA to include the first points but not each second point.</p><p id="p-0088" num="0081">Next, in Step S<b>440</b>, the processor <b>314</b> generates a first bit stream ST<b>1</b> according to the (updated) point cloud patch PA and the mesh patch MP, and transmits the first bit stream ST<b>1</b>.</p><p id="p-0089" num="0082">In an embodiment, the processor <b>314</b> generates an occupancy map, a geometry map, and an attribute map according to the (updated) point cloud patch PA and the mesh patch MP, wherein the occupancy map includes first occupancy information and second occupancy information respectively corresponding to the point cloud patch PA and the mesh patch MP. The geometry map includes first geometry information and second geometry information respectively corresponding to the point cloud patch PA and the mesh patch MP. The attribute map includes first attribute information and second attribute information respectively corresponding to the point cloud patch PA and the mesh patch MP.</p><p id="p-0090" num="0083">Please refer to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, which is a schematic diagram of an occupancy map, a geometry map, and an attribute map according to an embodiment of the disclosure. In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, it is assumed that the processor <b>314</b> correspondingly generates an occupancy map <b>81</b>, a geometry map <b>82</b>, and an attribute map <b>83</b> after executing Step S<b>440</b>, which is only an example and is not intended to limit possible implementations of the disclosure.</p><p id="p-0091" num="0084">In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the processor <b>314</b> may adopt a conventional point cloud mechanism to record the relevant information of the first points in the point cloud patch PA in regions corresponding to the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b>. For example, a region <b>811</b> may record a bitmap representing each first point in the point cloud patch PA, a region <b>821</b> may record the coordinates of each first point in the point cloud patch PA, and a region <b>831</b> may record an attribute (for example, color, etc.) of each first point in the point cloud patch PA.</p><p id="p-0092" num="0085">In addition, the processor <b>314</b> may individually plan a first specific region <b>812</b>, a second specific region <b>822</b>, and a third specific region <b>832</b> corresponding to the mesh patch MP in the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b>. In an embodiment, the first specific region <b>812</b>, the second specific region <b>822</b>, and the third specific region <b>832</b> may respectively correspond to the second occupancy information, the second geometry information, and the second attribute information.</p><p id="p-0093" num="0086">In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the processor <b>314</b> may plan the first specific region <b>812</b> in the occupancy map <b>81</b>, wherein the first specific region <b>812</b> includes, for example, only bit <b>1</b>, which may be used to indicate that corresponding positions (that is, the second specific region <b>822</b> and the third specific region <b>832</b>) in the geometry map <b>82</b> and the attribute map <b>83</b> record geometry information and attribute information associated the mesh patch MP. For example, the second specific region <b>822</b> records the coordinates of each vertex of the mesh patch MP, and the third specific region <b>832</b> records the color of each vertex of the mesh patch MP, but not limited thereto.</p><p id="p-0094" num="0087">In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, it can be seen that there is a first relative position between the first specific region <b>812</b> and the occupancy map <b>81</b>, there is a second relative position between the second specific region <b>822</b> and the geometry map <b>82</b>, there is a third relative position between the third specific region <b>832</b> and the attribute map <b>83</b>, and the first relative position, the second relative position, and the third relative position correspond to each other.</p><p id="p-0095" num="0088">It should be understood that the position of each region in <figref idref="DRAWINGS">FIG. <b>8</b></figref> is only an example and is not intended to limit possible implementations of the disclosure.</p><p id="p-0096" num="0089">In this case, after the decoder <b>320</b> obtains the occupancy map <b>81</b>, the decoder <b>320</b> may know that the second specific region <b>822</b> in the geometry map <b>82</b> corresponds to the second geometry information according to the occupancy map <b>81</b>, and the third specific region <b>832</b> in the attribute map <b>83</b> corresponds to the second attribute information.</p><p id="p-0097" num="0090">In an embodiment, the second geometry information recorded by the second specific region <b>822</b> may indicate the coordinates of each vertex of each reference triangle (for example, the reference triangles T<b>1</b> to T<b>6</b> in <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>). In addition, the second attribute information recorded by the third specific region <b>832</b> may indicate the color of each vertex.</p><p id="p-0098" num="0091">In an embodiment, the processor <b>314</b> may first represent the coordinates of each vertex in each reference triangle in other ways, and then record the adjusted coordinates in the second specific region <b>822</b> to try to reduce the amount of data.</p><p id="p-0099" num="0092">Please refer to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, which is a schematic diagram of a recording manner of adjusted coordinates according to an embodiment of the disclosure. In the embodiment, the processor <b>314</b> may, for example, first obtain the bounding box BB of the point cloud patch PA, and divide the bounding box BB into multiple three-dimensional spaces, wherein each three-dimensional space has a corresponding origin position.</p><p id="p-0100" num="0093">In <figref idref="DRAWINGS">FIG. <b>9</b></figref>, each three-dimensional space is, for example, a cube with a side length M, and the origin position of each three-dimensional space is, for example, a position closest to a reference position OR of the bounding box BB (for example, the origin of the bounding box BB). For example, the coordinates of the origin position of a three-dimensional space <b>911</b> may be, for example, represented as (0, 0, 0), the coordinates of the origin position of a three-dimensional space <b>912</b> may be, for example, represented as (0, 0, M), and the coordinates of the origin position of a three-dimensional space <b>913</b> may be, for example, represented as (0, M, 0), but not limited thereto.</p><p id="p-0101" num="0094">Afterwards, the processor <b>314</b> may find a specific three-dimensional space corresponding to each reference triangle, and then adjust the coordinates of each vertex of each reference triangle based on the origin position of the specific three-dimensional space corresponding to each reference triangle. In an embodiment, it is assumed that the coordinates of a certain vertex of a certain reference triangle are (X, Y, Z), and the origin position of the corresponding specific three-dimensional space is (X0, Y0, Z0). In this case, the processor <b>314</b> may adjust the coordinates of the vertex to (X-X0, Y-Y0, Z-Z0).</p><p id="p-0102" num="0095">Taking the reference triangle Ti as an example, the processor <b>314</b> may find the three-dimensional space <b>912</b> where the reference triangle Ti is located as the corresponding specific three-dimensional space, and then adjust the coordinates of each of the vertices V<sub>1</sub>, V<sub>2</sub>, and V<sub>3 </sub>of the reference triangle Ti based on the origin position (that is, (X0, Y0, Z0)=(0, 0, M)) of the three-dimensional space <b>912</b>. In this case, the coordinates of each of the vertices V<sub>1</sub>, V<sub>2</sub>, and V<sub>3 </sub>may be adjusted to, for example, (X<sub>V1</sub>&#x2212;0, Y<sub>V1</sub>&#x2212;0, Z<sub>V1</sub>&#x2212;M), (X<sub>V2</sub>&#x2212;0, Y<sub>V2</sub>&#x2212;0, Z<sub>V2</sub>&#x2212;M), and (X<sub>V3</sub>&#x2212;0, Y<sub>V3</sub>&#x2212;0, Z<sub>V3</sub>&#x2212;M), but not limited thereto.</p><p id="p-0103" num="0096">After adjusting the coordinates of the vertices of each reference triangle based on the above manner, the processor <b>314</b> may record the same in the second attribute information (that is, the second specific region <b>822</b>) of the geometry map <b>82</b>, but not limited thereto. Thereby, the amount of data in the geometry map <b>82</b> can be correspondingly reduced.</p><p id="p-0104" num="0097">After generating the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b>, the processor <b>314</b> encodes the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b> into the first bit stream ST<b>1</b>, and transmits the first bit stream ST<b>1</b>.</p><p id="p-0105" num="0098">In an embodiment, the processor <b>314</b> may also be configured to execute: obtaining a connectivity between the vertices of each reference triangle; and encoding the connectivity between the vertices of each reference triangle into a second bit stream ST<b>2</b>, and transmitting the second bit stream ST<b>2</b>.</p><p id="p-0106" num="0099">In the embodiment of the disclosure, for the manner in which the processor <b>314</b> generates the first bit stream ST<b>1</b> and the second bit stream ST<b>2</b>, reference may be made to the relevant conventional encoding technology, and details are not described herein.</p><p id="p-0107" num="0100">In an embodiment, before executing Step S<b>430</b>, the processor <b>314</b> may first estimate a roughness PS of the point cloud patch PA, and judge whether the roughness PS is not higher than a roughness threshold (denoted by TH<sub>PS</sub>). If yes, the processor <b>314</b> may continue to execute Step S<b>430</b>. On the other hand, if the roughness PS is higher than the roughness threshold TH<sub>PS</sub>, the processor <b>314</b> may be configured to: maintain the point cloud patch PA to include the first point and the second point; generate the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b> only based on the point cloud patch PA, wherein the occupancy map <b>81</b> only includes the first occupancy information of the point cloud patch PA, the geometry map <b>82</b> only includes the first geometry information of the point cloud patch PA, and the attribute map <b>83</b> only includes the first attribute information of the point cloud patch PA; and encode the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b> into the first bit stream ST<b>1</b>, and transmit the first bit stream ST.</p><p id="p-0108" num="0101">That is, if the roughness of the point cloud patch PA is not higher than the roughness threshold TH<sub>PS</sub>, it means that the point cloud patch PA is relatively smooth. As mentioned earlier, the mesh based contour mechanism is suitable for presenting a relatively smooth image, so the processor <b>314</b> may then correspondingly execute Step S<b>430</b> (that is, the operation of replacing the corresponding second point with the mesh patch MP) and subsequent operations.</p><p id="p-0109" num="0102">On the other hand, if the roughness of the point cloud patch PA is higher than the roughness threshold TH<sub>PS</sub>, it means that the point cloud patch PA is relatively not smooth. At this time, processing the point cloud patch PA only based on the point cloud mechanism can achieve better image quality.</p><p id="p-0110" num="0103">In an embodiment, during the process of estimating the roughness PS of the point cloud patch PA, the processor <b>314</b> may be configured to: obtain a specific included angle between the normal vector and a reference normal vector of each point in the point cloud patch PA, wherein the reference normal vector of each point points from each point to the specific projection plane PL corresponding to the point cloud patch PA; and estimate the roughness PS of the point cloud patch PA based on the color and the coordinates of each point and the specific included angle of each point.</p><p id="p-0111" num="0104">Please refer to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, which is a schematic diagram of estimating roughness of a point cloud patch according to an embodiment of the disclosure. In <figref idref="DRAWINGS">FIG. <b>10</b></figref>, for a point <b>1001</b> in the point cloud patch PA, the processor <b>314</b> may be configured to obtain a normal vector VC<b>1</b> and a reference normal vector VC<b>2</b> of the point <b>1001</b>, wherein the reference normal vector VC<b>2</b> points from the point <b>1001</b> to the specific projection plane PL. Afterwards, the processor <b>314</b> may obtain a specific included angle AN between the normal vector VC<b>1</b> and the reference normal vector VC<b>2</b>. Next, the processor <b>314</b> may estimate the roughness PS of the point cloud patch PA based on the color, the coordinates, and the corresponding specific included angle of each point in the point cloud patch PA.</p><p id="p-0112" num="0105">In an embodiment, assuming that the color of each point in the point cloud patch PA may be represented by adopting an YUV color space, the roughness PS may be represented as:</p><p id="p-0113" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>PS</i>=(&#x3c3;<sub>Y1</sub>&#xd7;&#x3c9;<sub>Y1</sub>+&#x3c3;<sub>U</sub>&#xd7;&#x3c9;<sub>U</sub>+&#x3c3;<sub>V</sub>&#xd7;&#x3c9;<sub>V</sub>)+(&#x3c3;<sub>X</sub>&#xd7;&#x3c9;<sub>X</sub>+&#x3c3;<sub>Y2</sub>&#xd7;&#x3c9;<sub>Y2</sub>+&#x3c3;<sub>Z</sub>&#xd7;&#x3c9;<sub>Z</sub>)+(&#x3c3;<sub>&#x3b8;</sub>&#xd7;&#x3c9;<sub>&#x3b8;</sub>)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0114" num="0106">In an embodiment, &#x3c3;<sub>Y1 </sub>is, for example, a standard deviation of an Y value of each point in the point cloud patch PA, &#x3c3;<sub>U </sub>is, for example, a standard deviation of a U value of each point in the point cloud patch PA, &#x3c3;<sub>V </sub>is, for example, a standard deviation of a V value of each point in the point cloud patch PA, and &#x3c9;<sub>Y</sub>, &#x3c9;<sub>U</sub>, &#x3c9;<sub>V </sub>are weights respectively corresponding to &#x3c3;<sub>Y1</sub>, &#x3c3;<sub>U</sub>, and &#x3c3;<sub>V</sub>. In addition, &#x3c3;<sub>X </sub>is, for example, a standard deviation of an X coordinate of each point in the point cloud patch PA, &#x3c3;<sub>Z </sub>is, for example, a standard deviation of a Y coordinate of each point in the point cloud patch PA, &#x3c3;<sub>Z </sub>is, for example, a standard deviation of a Z coordinate of each point in the point cloud patch PA, and &#x3c9;<sub>X</sub>, &#x3c9;<sub>Y</sub>, and &#x3c9;<sub>Z </sub>are weights respectively corresponding to &#x3c3;<sub>X</sub>, &#x3c3;<sub>Y</sub>, and &#x3c3;<sub>Z</sub>. In addition, &#x3c3;<sub>&#x3b8;</sub> is, for example, a standard deviation of the specific included angle corresponding to each point in the point cloud patch PA, and &#x3c9;<sub>&#x3b8;</sub> is, for example, a weight of &#x3c3;<sub>&#x3b8;</sub>.</p><p id="p-0115" num="0107">In addition, although the above description is only based on the point cloud patch PA, in other embodiments, the processor <b>314</b> may perform the above operations on other point cloud patches of the considered three-dimensional content to replace second points in other point cloud patches with corresponding mesh patches (that is, update other point cloud patches to include only corresponding first points). Afterwards, the processor <b>314</b> may put the relevant information of the (updated) point cloud patches and the mesh patches into the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b> based on the above teachings.</p><p id="p-0116" num="0108">For example, assuming that the considered three-dimensional content further includes a point cloud patch PA&#x2032;, the processor <b>314</b> may replace a second point in the point cloud patch PA&#x2032; with a corresponding mesh patch MP&#x2032; based on the previous teaching, so that the point cloud patch PA&#x2032; is updated to include a corresponding first point but not the corresponding second point. After that, the processor <b>314</b> may respectively plan regions <b>811</b>&#x2032; to <b>831</b>&#x2032; in the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b>, wherein the region <b>811</b>&#x2032; may record a bitmap representing each first point in the point cloud patch PA&#x2032;, the region <b>821</b>&#x2032; may record coordinates of each first point in the point cloud patch PA&#x2032;, and the region <b>831</b>&#x2032; may record an attribute (for example, color, etc.) of each first point in the point cloud patch PA&#x2032;.</p><p id="p-0117" num="0109">In addition, the processor <b>314</b> may individually plan a first specific region <b>812</b>&#x2032;, a second specific region <b>822</b>&#x2032;, and a third specific region <b>832</b>&#x2032; corresponding to the mesh patch MP&#x2032; in the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b>.</p><p id="p-0118" num="0110">In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the first specific region <b>812</b>, for example, includes only bit <b>1</b>, which may be used to indicate that corresponding positions (that is, the second specific region <b>822</b>&#x2032; and the third specific region <b>832</b>&#x2032;) in the geometry map <b>82</b> and the attribute map <b>83</b> record geometry information and attribute information associated with the mesh patch MP&#x2032;. For example, the second specific region <b>822</b>&#x2032; records the coordinates of each vertex of the mesh patch MP&#x2032;, and the third specific region <b>832</b>&#x2032; records the color of each vertex of the mesh patch MP&#x2032;, but not limited thereto.</p><p id="p-0119" num="0111">In an embodiment, the encoder <b>310</b> may transmit the bit stream ST (which, for example, includes the first bit stream ST<b>1</b> and the second bit stream ST<b>2</b>) to the decoder <b>320</b>, so that the decoder <b>320</b> may restore the considered three-dimensional content accordingly.</p><p id="p-0120" num="0112">Please refer to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, which is a flowchart of a content patch decoding method according to an embodiment of the disclosure. The method of the embodiment may be executed by the decoder <b>320</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The following describes the details of each step in <figref idref="DRAWINGS">FIG. <b>11</b></figref> with the components shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0121" num="0113">First, in Step S<b>1110</b>, the transceiver <b>322</b> receives the bit stream ST. In Step S<b>1120</b>, the processor <b>324</b> obtains multiple information corresponding to a point cloud patch and a mesh patch based on the bit stream ST. In an embodiment, the information may include an occupancy map, a geometry map, and an attribute map, wherein the occupancy map includes first occupancy information and second occupancy information respectively corresponding to the point cloud patch and the mesh patch, the geometry map includes first geometry information and second geometry information respectively corresponding to the point cloud patch and the mesh patch, and the attribute map includes first attribute information and second attribute information respectively corresponding to the point cloud patch and the mesh patch.</p><p id="p-0122" num="0114">For ease of description, it is assumed below that the occupancy map, the geometry map, and the attribute map obtained by the processor <b>324</b> from the bit stream ST are the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b> corresponding to at least the point cloud patch PA and the mesh patch MP in the embodiment of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, but not limited thereto. In other embodiments, the processor <b>324</b> may also obtain occupancy maps, geometry maps and, attribute maps corresponding to other point cloud patches/mesh patches from the bit stream ST.</p><p id="p-0123" num="0115">In an embodiment, the processor <b>324</b> may obtain the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b> based on the first bit stream ST<b>1</b> in the bit stream ST, but not limited thereto.</p><p id="p-0124" num="0116">After that, in Step S<b>1130</b>, the processor <b>324</b> obtains the connectivity between the vertices of the mesh patch MP based on the bit stream ST. In an embodiment, the processor <b>324</b> may obtain the connectivity between the vertices of the mesh patch MP based on the second bit stream ST<b>2</b> in the bit stream ST, but not limited thereto.</p><p id="p-0125" num="0117">Next, in Step S<b>1140</b>, the processor <b>324</b> reconstructs the point cloud patch PA and the mesh patch MP based on the information (for example, the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b>) and the connectivity between the vertices.</p><p id="p-0126" num="0118">In an embodiment, the processor <b>324</b> may reconstruct the reference triangles (for example, the reference triangles T<b>1</b> to T<b>6</b> in <figref idref="DRAWINGS">FIG. <b>6</b>G</figref>) of the mesh patch MP in the three-dimensional space based on the second occupancy information (for example, content of the first specific region <b>812</b>), the second geometry information (for example, content of the second specific region <b>822</b>), the second attribute information (for example, content of the third specific region <b>832</b>), and the connectivity between the vertices of the mesh patch MP, wherein the reconstructed reference triangles form the reconstructed mesh patch MP in the three-dimensional space.</p><p id="p-0127" num="0119">In an embodiment, the processor <b>324</b> may be configured to: find the second specific region <b>822</b> and the third specific region <b>832</b> respectively in the geometry map <b>82</b> and the attribute map <b>83</b> based on the first specific region <b>812</b> indicated by the second occupancy information in the occupancy map, wherein the second specific region <b>822</b> and the third specific region <b>832</b> respectively indicate the second geometry information and the second attribute information; obtain the coordinates of each vertex of the reference triangle based on the second geometry information, and reconstruct each vertex of the reference triangle in the three-dimensional space accordingly; and obtain the color of each vertex of the reference triangle based on the second attribute information, and set the color of each vertex of the reference triangle in the three-dimensional space accordingly.</p><p id="p-0128" num="0120">In some embodiments, the coordinates of each vertex in the second geometry information may also be coordinates adjusted by the mechanism of <figref idref="DRAWINGS">FIG. <b>9</b></figref>. In this case, the processor <b>324</b> may reconstruct each vertex of the reference triangle in the three-dimensional space according to the coordinates of each vertex and the origin position of the corresponding specific three-dimensional space, but not limited thereto.</p><p id="p-0129" num="0121">In addition, the processor <b>324</b> may reconstruct the point cloud patch PA in the three-dimensional space based on the first occupancy information (for example, content of the region <b>811</b>), the first geometry information (for example, content of the region <b>821</b>), and the first attribute information (for example, content of the region <b>831</b>).</p><p id="p-0130" num="0122">In an embodiment, the processor <b>324</b> may find the regions <b>821</b> and <b>831</b> respectively in the geometry map <b>82</b> and the attribute map based on the region <b>811</b> indicated by the first occupancy information in the occupancy map <b>81</b>, wherein the region <b>821</b> and the region <b>831</b> respectively indicate the first geometry information and the first attribute information; obtain the coordinates of each first point based on the first geometry information, and reconstruct the first point in the three-dimensional space accordingly; and obtain the color of each first point based on the first attribute information, and set the color of each first point in the three-dimensional space accordingly.</p><p id="p-0131" num="0123">In addition, when the information of other point cloud patches (for example, the point cloud patch PA&#x2032;) and mesh patches (for example, the mesh patch MP&#x2032;) are also included in the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b>, the processor <b>324</b> may also reconstruct the point cloud patches and the mesh patches in the three-dimensional space based on the above teachings. After reconstructing the point cloud patches and the mesh patches in the three-dimensional space according to the information of each point cloud patch and mesh patch in the occupancy map <b>81</b>, the geometry map <b>82</b>, and the attribute map <b>83</b>, the considered three-dimensional content may be correspondingly reconstructed in the three-dimensional space.</p><p id="p-0132" num="0124">It has been verified that the three-dimensional content reconstructed through the embodiments of the disclosure can have better image quality as a whole, and defects such as discontinuous holes or noises are less likely to appear in some relatively smooth regions.</p><p id="p-0133" num="0125">In addition, compared with the conventional point cloud mechanism, the disclosure adds the information associated with the mesh patch into the occupancy map, the geometry map, and the attribute map, so the disclosure also provides a corresponding syntax design to implement the above technical means.</p><p id="p-0134" num="0126">Please refer to <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>12</b>B</figref>, which are schematic diagrams of a syntax design according to an embodiment of the disclosure. In <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> and <figref idref="DRAWINGS">FIG. <b>12</b>B</figref>, the shown syntactic design includes a number of parameters/variables, which will be individually described below.</p><p id="p-0135" num="0127">In the following embodiments, it is assumed that a tile of a considered current atlas tile is identified as tileID.</p><p id="p-0136" num="0128">In an embodiment, atdu_patch_mode[tileID][p] indicates a patch mode of a patch with an index p in the current atlas tile.</p><p id="p-0137" num="0129">I_MRAW and P_MRAW indicate that a mesh patch mode is used for I_TILE and P_TILE.</p><p id="p-0138" num="0130">asps_mesh_vertices_in_vertex_video_data_flag equal to 1 indicates that there is vertex information in vertex video data. asps_mesh_vertices_in_vertex_flag equal to 0 indicates that there is vertex information in patch data. If there is none, the value of asps_mesh_vertices_in_vertex_map_flag is inferred to be equal to 0.</p><p id="p-0139" num="0131">mrpdu_2d_pos_x[tileID][p] specifies an x coordinate of an upper left corner of a patch bounding box size of the mesh patch p in the current atlas tile, and mrpdu_2d_pos_x[tileID][p] is expressed as a multiple of PatchPackingBlockSize.</p><p id="p-0140" num="0132">mrpdu_2d_pos_y[tileID][p] specifies a y coordinate of the upper left corner of the patch bounding box size of the mesh patch p in the current atlas tile, and mrpdu_2d_pos_x[tileID][p] is expressed as a multiple of PatchPackingBlockSize.</p><p id="p-0141" num="0133">mrpdu_2d_size_x_minus1[tileID][p] plus 1 specifies a width value of the mesh patch with the index p in the current atlas tile.</p><p id="p-0142" num="0134">mrpdu_2d_size_y_minus1[tileID][p] plus 1 specifies a height value of the mesh patch with the index p in the current atlas tile.</p><p id="p-0143" num="0135">mrpdu_3d_offset_u[tileID][p] specifies an offset along a tangent axis to be applied to points in the reconstructed mesh patch in the mesh patch with the index p in the current atlas tile. The number of bits used to represent mrpdu_3d_offset_u[tileID][p] is (ath_raw_3d_offset_axis_bit_count_minus1+1).</p><p id="p-0144" num="0136">mrpdu_3d_offset_v[tileID][p] specifies an offset along a bi-tangent axis to be applied to the points in the reconstructed mesh patch in the mesh patch with the index p in the current atlas tile. The number of bits used to represent mrpdu_3d_offset_v[tileID][p] is (ath_raw_3d_offset_axis_bit_count_minus1+1).</p><p id="p-0145" num="0137">mrpdu_3d_offset_d[tileID][p] specifies an offset along a normal axis to be applied to the points in the reconstructed mesh patch in the mesh patch with the index p in the current atlas tile.</p><p id="p-0146" num="0138">The number of bits used to represent mrpdu_3d_offset_d[tileID][p] is (ath_raw_3d_offset_axis_bit_count_minus1+1).</p><p id="p-0147" num="0139">mrpdu_points_minus1[tileID][p] plus 1 specifies the number of points present in the mesh patch with the index p in the current atlas tile. The value of mrpdu_points_minus1[tileID][p] should be between 0 and ((mrpdu_2d_size_x_minus1[tileID][p]+1)&#xd7;(mrpdu_2d_size_y_minus1[tileID][p]+1)1)/3&#x2212;1.</p><p id="p-0148" num="0140">mrpdu_projection_id[tileID][patchIdx] specifies a projection plane of the mesh patch with the index p in the current atlas tile.</p><p id="p-0149" num="0141">mrpdu_orientation_index[tileID][patchIdx] specifies a connectivity orientation of the mesh patch with the index p in the current atlas tile.</p><p id="p-0150" num="0142">mrpdu_vertex_count_minus3[tileID][patchIdx] plus 3 specifies the number of vertices in the mesh patch with the index p in the current atlas tile.</p><p id="p-0151" num="0143">mrpdu_triangle_count[tileID][patchIdx] specifies the number of reference triangles in the mesh patch with the index p in the current atlas tile. When there is none, the value of mpdu_face_count[tileID][p] should be zero.</p><p id="p-0152" num="0144">mrpdu_face_vertex[tileID][p][i][k] specifies the k-th value of a vertex index of the i-th reference triangle among the reference triangles with the index p in the current atlas tile. The value of mrpdu_face_vertex[tileID][p][i][k] should be within the range of 0 to mrpdu_vert_count_minus3[tileID][p]+2.</p><p id="p-0153" num="0145">In summary, the encoder of the disclosure may find the corresponding mesh patch in a certain point cloud patch after obtaining the point cloud patch of the three-dimensional content. Afterwards, the encoder may replace the second point corresponding to the mesh patch with the mesh patch, and update the point cloud patch to include the first point not corresponding to the mesh patch but not the second point corresponding to the mesh patch. Then, the encoder may simultaneously put the occupancy information, the geometry information, and the attribute information of the mesh patch and the updated point cloud patch into the occupancy map, the geometry map, and the attribute map, and generate the bit stream accordingly.</p><p id="p-0154" num="0146">In addition, the decoder of the disclosure may reconstruct the point cloud patch and the mesh patch in the three-dimensional space after obtaining the occupancy map, the geometry map, and the attribute map, and the connectivity of each vertex in the mesh patch from the bit stream. In this way, the reconstructed point cloud patch and mesh patch can have better image quality.</p><p id="p-0155" num="0147">Finally, it should be noted that the above embodiments are only used to illustrate, but not to limit, the technical solutions of the disclosure. Although the disclosure has been described in detail with reference to the above embodiments, persons skilled in the art should understand that the technical solutions described in the above embodiments can still be modified or some or all of the technical features thereof can be equivalently replaced. However, the modifications or replacements do not cause the essence of the corresponding technical solutions to deviate from the scope of the technical solutions of the embodiments of the disclosure.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-math idrefs="MATH-US-00001" nb-file="US20230005189A1-20230105-M00001.NB"><img id="EMI-M00001" he="5.67mm" wi="76.20mm" file="US20230005189A1-20230105-M00001.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00002" nb-file="US20230005189A1-20230105-M00002.NB"><img id="EMI-M00002" he="8.81mm" wi="76.20mm" file="US20230005189A1-20230105-M00002.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-math idrefs="MATH-US-00003" nb-file="US20230005189A1-20230105-M00003.NB"><img id="EMI-M00003" he="6.01mm" wi="76.20mm" file="US20230005189A1-20230105-M00003.TIF" alt="embedded image " img-content="math" img-format="tif"/></us-math><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A content patch encoding method, suitable for an encoder, comprising:<claim-text>obtaining a point cloud patch, wherein the point cloud patch comprises a plurality of points;</claim-text><claim-text>determining a mesh patch in the point cloud patch based on the points, wherein the points comprise a plurality of first points and a plurality of second points corresponding to the mesh patch;</claim-text><claim-text>updating the point cloud patch to comprise the first points but not the second points; and</claim-text><claim-text>generate a first bit stream according to the point cloud patch and the mesh patch, and transmitting the first bit stream.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mesh patch comprises a plurality of reference triangles, and determining the mesh patch in the point cloud patch based on the points comprises:<claim-text>(a) obtaining a first reference point among the points, and finding a second reference point and a third reference point among the points accordingly;</claim-text><claim-text>(b) forming a plurality of vertices of an i-th reference triangle among the reference triangles with the first reference point, the second reference point, and the third reference point, and determining a plurality of candidate triangles based on a plurality of edges of the i-th reference triangle, wherein an initial value of i is 1, and a plurality of vertices of each of the candidate triangles comprise two of the first reference point, the second reference point, and the third reference point, and a specific point among the points;</claim-text><claim-text>(c) selecting a specific candidate triangle from the candidate triangles; and</claim-text><claim-text>(d) in response to judging that the specific point of the specific candidate triangle is not a vertex of any previously formed reference triangle, updating the first reference point, the second reference point, and the third reference point to the points of the specific candidate triangle, increment i, and return to (b).</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein after selecting the specific candidate triangle from the candidate triangles, the method further comprises:<claim-text>in response to judging that the specific point of the specific candidate triangle is a vertex of any previously formed reference triangle, using the specific candidate triangle as a last one of the reference triangles, and judging that the reference triangles of the mesh patch are found.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein obtaining the first reference point among the points, and finding the second reference point and the third reference point among the points accordingly comprises:<claim-text>using any one of the points of the point cloud patch as the first reference point;</claim-text><claim-text>determining a specified region based on the first reference point and a specified radius, wherein the specified radius is determined based on a bounding box, a quantization parameter, and a reference factor of the point cloud patch; and</claim-text><claim-text>finding the second reference point and the third reference point in the specified region.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein determining the candidate triangles based on the vertices of the i-th reference triangle comprises:<claim-text>determining a specific sphere based on the vertices of the i-th reference triangle;</claim-text><claim-text>moving the specific sphere respectively toward the edges to determine a plurality of reference spheres, wherein each of the reference spheres comprises at least two of the vertices of the i-th reference triangle; and</claim-text><claim-text>in response to judging that an j-th reference sphere among the reference spheres further comprises another point among the points, determining a j-th candidate triangle among the candidate triangles with two of the vertices of the i-th reference triangle and the another point, where 1&#x2264;j&#x2264;3.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, further comprising:<claim-text>in response to judging that the j-th reference sphere comprises only two of the vertices of the i-th reference triangle, adjusting a size of the j-th reference sphere until the adjusted j-th reference sphere comprises two of the vertices of the i-th reference triangle and another point among the points; and</claim-text><claim-text>determining the j-th candidate triangle among the candidate triangles with two of the vertices of the i-th reference triangle and the another point.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein selecting the specific candidate triangle from the candidate triangles comprises:<claim-text>estimating a contour cost of each of the candidate triangles, and selecting the specific candidate triangle from the candidate triangles accordingly, wherein the contour cost of the specific candidate triangle is lowest, wherein estimating the contour cost of each of the candidate triangles comprises:</claim-text><claim-text>projecting the points in the j-th reference sphere onto the j-th candidate triangle, and determining a projection distance of each of the points in the j-th reference sphere accordingly; and</claim-text><claim-text>estimating the contour cost of the j-th candidate triangle based on a projection distance of each of the points in the j-th reference sphere, a number of the points in the j-th reference sphere, and a reference factor.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein before updating the point cloud patch to comprise the first points but not the second points, the method further comprises:<claim-text>estimating a roughness of the point cloud patch, comprising:<claim-text>obtaining a specific included angle between a normal vector and a reference normal vector of each of the points, wherein the reference normal vector of each of the points points from each of the points to a specific projection plane corresponding to the point cloud patch; and</claim-text><claim-text>estimating the roughness of the point cloud patch based on a color and coordinates of each of the points and the specific included angle of each of the points; and</claim-text></claim-text><claim-text>in response to judging that the roughness of the point cloud patch is not higher than a roughness threshold, updating the point cloud patch to comprise the first points but not the second points.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein in response to judging that the roughness of the point cloud patch is higher than the roughness threshold, the method further comprises:<claim-text>maintaining the point cloud patch to comprise the first points and the second points;</claim-text><claim-text>generating an occupancy map, a geometry map, and an attribute map only based on the point cloud patch, wherein the occupancy map only comprises first occupancy information of the point cloud patch, the geometry map only comprises first geometry information of the point cloud patch, and the attribute map only comprises first attribute information of the point cloud patch; and</claim-text><claim-text>encoding the occupancy map, the geometry map, and the attribute map into the first bit stream, and transmitting the first bit stream.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein after determining the mesh patch in the point cloud patch based on the points, the method further comprises:<claim-text>projecting the mesh patch onto a specific projection plane corresponding to the point cloud patch to form a reference region on the specific projection plane;</claim-text><claim-text>projecting the points onto the specific projection plane to form a plurality of projection points;</claim-text><claim-text>finding a plurality of first projection points not located in the reference region from the projection points, and using the points corresponding to the first projection points as the first points; and</claim-text><claim-text>finding a plurality of second projection points located in the reference region from the projection points, and using the points corresponding to the second projection points as the second points.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the mesh patch comprises a plurality of reference triangles, each of the reference triangles comprises a plurality of vertices, and the method further comprises:<claim-text>obtaining a bounding box of the point cloud patch, and dividing the bounding box into a plurality of three-dimensional spaces, wherein each of the three-dimensional spaces has a corresponding origin position;</claim-text><claim-text>finding a specific three-dimensional space corresponding to each of the reference triangles among the three-dimensional spaces;</claim-text><claim-text>adjusting coordinates of each of the vertices of each of the reference triangles based on the origin position of the specific three-dimensional space corresponding to each of the reference triangles; and</claim-text><claim-text>recording the coordinates of each of the vertices of each of the reference triangles in second geometry information of a geometry map.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the first bit stream according to the point cloud patch and the mesh patch comprises:<claim-text>generating an occupancy map, a geometry map, and an attribute map based on the point cloud patch and the mesh patch, wherein the occupancy map comprises first occupancy information and second occupancy information respectively corresponding to the point cloud patch and the mesh patch, the geometry map comprises first geometry information and second geometry information respectively corresponding to the point cloud patch and the mesh patch, and the attribute map comprises first attribute information and second attribute information respectively corresponding to the point cloud patch and the mesh patch; and</claim-text><claim-text>encoding the occupancy map, the geometry map, and the attribute map into the first bit stream.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. A content patch decoding method, suitable for a decoder, comprising:<claim-text>receiving at least one bit stream;</claim-text><claim-text>obtaining a plurality of information corresponding to a point cloud patch and a mesh patch based on the at least one bit stream;</claim-text><claim-text>obtaining a connectivity between a plurality of vertices of the mesh patch based on the at least one bit stream; and</claim-text><claim-text>reconstructing the point cloud patch and the mesh patch based on the information and the connectivity between the vertices.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the information corresponding to the point cloud patch and the mesh patch comprise an occupancy map, a geometry map, and an attribute map, wherein the occupancy map comprises first occupancy information and second occupancy information respectively corresponding to the point cloud patch and the mesh patch, the geometry map comprises first geometry information and second geometry information respectively corresponding to the point cloud patch and the mesh patch, and the attribute map comprises first attribute information and second attribute information respectively corresponding to the point cloud patch and the mesh patch.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the at least one bit stream comprises a first bit stream, and obtaining the information based on the at least one bit stream comprises:<claim-text>obtaining the occupancy map, the geometry map, and the attribute map based on the first bit stream.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the at least one bit stream comprises a second bit stream, and obtaining the connectivity between the vertices of the mesh patch based on the at least one bit stream comprises:<claim-text>obtaining the connectivity between the vertices of the mesh patch based on the second bit stream.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the second occupancy information of the occupancy map indicates a first specific region in the occupancy map, the first specific region indicates that a second specific region in the geometry map corresponds to the second geometry information, and the first specific region indicates that a third specific region in the attribute map corresponds to the second attribute information.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The method according to <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein there is a first relative position between the first specific region and the occupancy map, there is a second relative position between the second specific region and the geometry map, there is a third relative position between the third specific region and the attribute map, and the first relative position, the second relative position, and the third relative position correspond to each other.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the mesh patch comprises a plurality of reference triangles corresponding to the vertices, the second geometry information indicates coordinates of each of the vertices, and the second attribute information indicates a color of each of the vertices.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the mesh patch comprises a plurality of reference triangles corresponding to the vertices, and reconstructing the point cloud patch and the mesh patch based on the information and the connectivity between the vertices comprises:<claim-text>reconstructing the reference triangles in a three-dimensional space based on the second occupancy information, the second geometry information, the second attribute information, and the connectivity between the vertices, wherein the reconstructed reference triangles form the reconstructed mesh patch in the three-dimensional space; and</claim-text><claim-text>reconstructing the point cloud patch in the three-dimensional space based on the first occupancy information, the first geometry information, and the first attribute information.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The method according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein reconstructing the reference triangles in the three-dimensional space based on the second occupancy information, the second geometry information, the second attribute information, and the connectivity between the vertices comprises:<claim-text>finding a second specific region and a third specific region respectively in the geometry map and the attribute map based on a first specific region indicated by the second occupancy information in the occupancy map, wherein the second specific region and the third specific region respectively indicate the second geometry information and the second attribute information;</claim-text><claim-text>obtaining coordinates of each of the vertices of the reference triangles based on the second geometry information, and reconstructing each of the vertices of the reference triangles in the three-dimensional space accordingly; and</claim-text><claim-text>obtaining a color of each of the vertices of the reference triangles based on the second attribute information, and setting the color of each of the vertices of the reference triangles in the three-dimensional space accordingly.</claim-text></claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The method according to <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the point cloud patch comprises a plurality of first points, and reconstructing the point cloud patch in the three-dimensional space based on the first occupancy information, the first geometry information, and the first attribute information comprises:<claim-text>finding a second region and a third region respectively in the geometry map and the attribute map based on a first region indicated by the first occupancy information in the occupancy map, wherein the second region and the third region respectively indicate the first geometry information and the first attribute information;</claim-text><claim-text>obtaining coordinates of each of the first points based on the first geometry information, and reconstructing the first points in the three-dimensional space accordingly; and</claim-text><claim-text>obtaining a color of each of the first points based on the first attribute information, and setting the color of each of the first points in the three-dimensional space accordingly.</claim-text></claim-text></claim></claims></us-patent-application>
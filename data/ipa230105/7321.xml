<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230007322A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230007322</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930295</doc-number><date>20220907</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2343</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>239</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>437</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>845</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>23439</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>2393</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>437</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>21</main-group><subgroup>8456</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">TECHNIQUES FOR COMPOSITE MEDIA STORAGE AND RETRIEVAL</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>17175338</doc-number><date>20210212</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>11463746</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>17930295</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>NETFLIX, INC.</orgname><address><city>Los Gatos</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>NEWTON</last-name><first-name>Christopher</first-name><address><city>Westlake Village</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>MOTION</last-name><first-name>Carenina Garcia</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>VISHWANATHAN</last-name><first-name>Vinod</first-name><address><city>San Ramon</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">One embodiment sets forth a technique that includes receiving a request for a range of data included in an encoded version of the media title that is stored across a set of files. The technique also includes determining, based on a file extent index, one or more files included in the set of files, wherein the file extent index maps an identifier for each file in the set to a given range of data that is stored in the file and included in the encoded version. The technique further includes retrieving the range of data from the file(s), wherein at least a portion of the retrieved range of data falls within the given range of data that is stored in each of the one or more files, and transmitting the range of data in a response to the request.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="128.27mm" wi="158.75mm" file="US20230007322A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="185.76mm" wi="150.54mm" orientation="landscape" file="US20230007322A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="190.92mm" wi="152.82mm" orientation="landscape" file="US20230007322A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="185.93mm" wi="148.84mm" orientation="landscape" file="US20230007322A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="201.59mm" wi="144.44mm" file="US20230007322A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="231.56mm" wi="148.42mm" orientation="landscape" file="US20230007322A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="244.09mm" wi="169.33mm" file="US20230007322A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="205.91mm" wi="113.62mm" file="US20230007322A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation of the co-pending U.S. patent application titled, &#x201c;TECHNIQUES FOR COMPOSITE MEDIA STORAGE AND RETRIEVAL,&#x201d; filed on Feb. 12, 2021 and having Ser. No. 17/175,338. The subject matter of the related application is hereby incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">Field of the Various Embodiments</heading><p id="p-0003" num="0002">Embodiments of the present disclosure relate generally to computer science and computer networks for streaming media, and more specifically, to techniques for composite media storage and retrieval.</p><heading id="h-0004" level="1">Description of the Related Art</heading><p id="p-0004" num="0003">A video streaming service is typically designed to provide users with access to one or more libraries of various media titles. To access a given media title, a user usually connects to the video streaming service via an endpoint device, such as a laptop computer, smart television, tablet computer, or similar device. The user can then select the given media title via a graphical user interface (GUI) that is displayed on the endpoint device and configured to allow users to make selections from one or more libraries of media titles. Upon selecting the given media title, the server machines that host the media title stream media content associated with the media title to the endpoint device. The media content generally includes frames of video, subtitle, and/or audio data encoded with specific bitrates, encoding formats, and/or other encoding settings. These encoding settings may additionally be varied in the streamed media content based on network conditions, user preferences, and/or other parameters. A streaming application executing on the endpoint device can request these frames as ranges of byte and/or time offsets from the server machines. While a given range of media content in the media title is played on the endpoint device, the streaming application can request and receive the next range of media content from the server machines to allow playback of the media title to proceed without interruption.</p><p id="p-0005" num="0004">In various streaming service implementations, different versions of a given media title oftentimes are streamed to different endpoint devices to accommodate content differences that exist in a given scene or other portion of the media title. For example, a feature-length film could include a number of scenes with on-screen text that provides information about the characters in the film, messages sent or received by various characters, content viewed by a given character on a computer or mobile device, or additional context for viewers of the film. Such on-screen text typically would be shown in the language spoken by the characters in the film and would be &#x201c;burned&#x201d; into the film (instead of being included in subtitles) to allow the production team to control the placement, font, size, and overall &#x201c;look&#x201d; of the text within the film. In such a scenario, each language into which the film is dubbed would require a different set of these particular scenes with localized on-screen text, thereby resulting in different versions of the film.</p><p id="p-0006" num="0005">Some legacy streaming applications are able to retrieve and playback only a single version of a media title from start to finish, instead of switching between versions at certain points during playback of a given media title. Continuing with the above example, a legacy streaming application could switch between files within an adaptive bitrate (ABR) ladder for a &#x201c;playback title&#x201d; representing a language-specific version of the film, but would not be able to switch between a first playback title that includes non-localized video content in the film and a second playback title that includes localized versions of a subset of video content in the film unless a user stopped playback of the film, manually changed the language setting for the film within the legacy streaming application, and subsequently resumed playback of the film with the new language setting.</p><p id="p-0007" num="0006">To accommodate these types of legacy streaming applications, a video streaming service may serve each version of a given media title using a separate file, which includes all of the video content required for complete playback of that version of the media title. Continuing with the above example, a feature-length film could include twenty scenes (or portions of scenes) with localized on-screen text, which could take up less than ten minutes of screen time out of a total runtime of more than three hours. The film also could have thirty localized versions of these scenes (or portions of scenes) to handle on-screen text in thirty different languages across all encoding bitrates and formats. Each set of localized scenes for a given language could then be packaged with the non-localized scenes in the film to produce a single localized file for a given combination of language, encoding bitrate, and encoding format that can be retrieved and played end-to-end using a legacy streaming application.</p><p id="p-0008" num="0007">One drawback of the above approach, however, is that storing full copies of individual versions of media titles to accommodate requests from legacy streaming applications involves duplicating video content that is common to multiple versions of the media title, which can consume substantial computational and storage resources. Continuing with the above example, the non-localized scenes in a feature-length film could consume 400 gigabytes (GB) of space across the set of encoding bitrates and formats, while a given set of localized scenes (or portions of scenes) needed across all of these encoding bitrates and formats could consume less than a few GB of space. Using the above approach, the small number of localized scenes specific to a given localized version of the film would be encoded and packaged with the non-localized video content into each video file. For thirty different languages, as in the above example, more than twelve terabytes (TB) of video content would have to be encoded and stored on various server machines to support all thirty localized versions of the film, even though the vast majority of the video content would be identical across the different localized versions.</p><p id="p-0009" num="0008">As the foregoing illustrates, what is needed in the art are more effective techniques for storing and retrieving video content for streaming to endpoint devices.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0010" num="0009">One embodiment sets forth a technique for accessing a media title for playback. The technique includes receiving from a client device a first request for a first range of data included in a first encoded version of the media title, wherein the first encoded version of the media title is stored across a first set of files. The technique also includes determining, based on a first file extent index, one or more files that are included in the first set of files and from which the first range of data is to be accessed, wherein, for each file included in the first set of files, the first file extent index maps an identifier for the file to a given range of data that is stored in the file and that is included in the first encoded version of the media title. The technique further includes retrieving the first range of data from the one or more files, wherein at least a portion of the first range of data retrieved from each of the one or more files falls within the given range of data that is stored in the file. The technique further includes transmitting the first range of data to the client device in a response to the first request.</p><p id="p-0011" num="0010">One technical advantage of the disclosed techniques relative to the prior art is that, with the disclosed techniques, duplication of video content across multiple versions of a media title is reduced. In that regard, the disclosed techniques enable a single copy of video content that is common to all versions of a given film to be stored, instead of replicating identical video content across multiple files. Thus, with the disclosed techniques, fewer computational and storage resources are consumed when encoding and storing multiple versions of a media title for streaming. Another technical advantage of the disclosed techniques relative to the prior art is that the disclosed techniques allow a given version of the media title to be created or modified in an efficient, modular manner, unlike prior art approaches that encode and package a given version of a media title from beginning to end. These technical advantages provide one or more technological advancements over prior art approaches.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0012" num="0011">So that the manner in which the above recited features of the various embodiments can be understood in detail, a more particular description of the inventive concepts, briefly summarized above, may be had by reference to various embodiments, some of which are illustrated in the appended drawings. It is to be noted, however, that the appended drawings illustrate only typical embodiments of the inventive concepts and are therefore not to be considered limiting of scope in any way, and that there are other equally effective embodiments.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a network infrastructure configured to implement one or more aspects of the various embodiments.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of a content server that may be implemented in conjunction with the network infrastructure of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to various embodiments.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of a control server that may be implemented in conjunction with the network infrastructure of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to various embodiments.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of an endpoint device that may be implemented in conjunction with the network infrastructure of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to various embodiments.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates how a request for media content is processed by the server application of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, according to various embodiments.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> illustrates an exemplar set of data structures that can be used when playing back a version of a media title, according to various embodiments.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> illustrates how a request for media content is processed using the exemplar set of data structures of <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, according to various embodiments.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram of method steps for accessing a media title for playback, according to various embodiments.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0021" num="0020">In the following description, numerous specific details are set forth to provide a more thorough understanding of the various embodiments. However, it will be apparent to one skilled in the art that the inventive concepts may be practiced without one or more of these specific details.</p><p id="p-0022" num="0021">A video streaming service delivers high-quality digital video content, such as movies and television shows, to viewers. To support legacy video streaming applications that play streaming content from beginning to end within a single video, different versions of a given media title can be stored in their entirety within different files. Each file can include a portion of video content that is specific to the corresponding version of the media title, as well as a (usually much larger) portion of video content that is the same across multiple versions of the media title. As described herein, a &#x201c;file&#x201d; includes video content encoded at different bitrates to support adaptive bitrate (ABR) streaming of the corresponding version of the media title. A legacy streaming application then plays a version of the media title by continuously requesting contiguous ranges of byte and/or time offsets from the video streaming service starting at the beginning of the corresponding file, playing the requested ranges of content in the order in which the ranges were received, and discontinuing playback when the end of the file is reached.</p><p id="p-0023" num="0022">For example, a video streaming service could offer <b>30</b> different localized versions of a feature length film. Each version of the feature length film could be dubbed with a corresponding language and include one or more scenes with on-screen text in that language. This on-screen text could provide information about the characters in the film, messages sent or received by various characters, content viewed by a given character on a computer or mobile device, or additional context for viewers of the film. Such on-screen text typically would be shown in the language spoken by the characters in the film and would be &#x201c;burned&#x201d; into the film (instead of being included in subtitles) to allow the production team to control the placement, font, size, and overall &#x201c;look&#x201d; of the text within the film. The localized scenes with on-screen text would traditionally be packaged with remaining scenes in the film to produce a single localized file for each localized version, which can be retrieved and played end-to-end on a legacy streaming video application. A server that delivers the film in multiple languages to client devices would therefore store multiple files that could occupy multiple TB of storage, even though the vast majority of the video content in the files is the same.</p><p id="p-0024" num="0023">To reduce resource overhead associated with encoding and storing duplicated content in different versions of a media title, the disclosed techniques store content related to multiple versions of the media title in one or more &#x201c;component&#x201d; files and/or segments within each file. These files include a single copy of each version of a scene (or another portion of video content) in the media title instead of replicating identical video content across multiple files. For example, a &#x201c;base&#x201d; version of a film that includes video content in the original language of the film could be stored in a single file. Localized versions of scenes (or other portions of video content) in the film could then be stored in multiple other files, where each file includes one or more data segments that store localized video content for a corresponding localized version of the film and each data segment includes a &#x201c;component&#x201d; of the localized video content (e.g., a consecutive number of seconds or minutes of video in the film). In another example, a single file could store the &#x201c;base&#x201d; version of the film as well as all localized versions of video content in the film. In a third example, a first file could store the &#x201c;base&#x201d; version of the film, and a second file could store all localized versions of video content in the film.</p><p id="p-0025" num="0024">The disclosed techniques also use a number of index structures with the files or segments to process requests from streaming video applications for content from the media title. The index structures include a number of file mappings that map identifiers for files that store video content for the media title to paths that can be used to locate the files in a filesystem. The index structures also include a file extent index that is used to retrieve video content for a given version of the media title when the video content is stored across multiple files and/or multiple non-contiguous segments within the same file. The file extent index includes an identifier for the corresponding version of the media title, metadata related to the version, and identifiers for files storing video content that is included in the version. Within the file extent index, each identifier for a file is mapped to a range of offsets in the file. The range of offsets represents a portion of video content that is to be retrieved from the file during playback of the version. The ordering of mappings between file identifiers and the corresponding ranges of offsets in the file extent index additionally reflects the order in which video content should be retrieved for end-to-end playback of the version of the media title.</p><p id="p-0026" num="0025">For example, the file extent index for a French version of a film could include a first identifier for the French version followed by three mappings. The mappings include a first mapping between a second identifier for an English &#x201c;base&#x201d; version of the film and a first range of byte offsets in a first file that includes the base version, followed by a second mapping between a third identifier for a second file that includes French versions of one or more scenes in the film and a second range of byte offsets in the second file, followed by a third mapping between the second identifier and a third range of byte offsets in the first file. During end-to-end playback of the French version of the film, a legacy streaming video application would request consecutive ranges of bytes of video content from a virtual &#x201c;file&#x201d; represented by the first identifier for the French version. A server would process the requests by matching the first identifier to the file extent index and using the mappings in the file extent to return data from the first range of byte offsets in the first file, followed by data from the second range of byte offsets in the second file, followed by data from the third range of byte offsets in the first file. In other words, the server would use the file extent index to piece together different ranges of data from multiple files and return the data in response to the requests, so that the data appears to be read in contiguous &#x201c;chunks&#x201d; from the same file from the perspective of the legacy streaming video application.</p><p id="p-0027" num="0026">The index structures further include a segment index that converts time offsets into byte offsets within a given file. This segment index can be used to process requests for video content that is specified in terms of time offset ranges (instead of byte offset ranges). These types of requests can be issued by a streaming video application to perform a &#x201c;scrub&#x201d; or &#x201c;seek&#x201d; operation that changes the point in time at which the media title is played.</p><p id="p-0028" num="0027">In some embodiments, the index structures can be used to efficiently create a new version of the media title and/or modify an existing version of the media title. For example, a new version of a film could be added to a video streaming service by populating one or more new files with video content that is specific to the new version, mapping an identifier for each new file to the path for the new file, and creating a new file extent index that includes mappings to byte ranges spanned by the video content in the new file(s) and additional mappings to byte ranges spanned by video content in one or more other files that include a &#x201c;base&#x201d; version of the film. The new file extent index could include a first mapping of a first file identifier to a first range of data spanned by a replacement version of a scene in the new version of the film instead of a second mapping of a second file identifier to a second range of data spanned by an original version of the scene from the &#x201c;base&#x201d; version of the film. During playback of the new version on an endpoint device, a server would process requests for ranges of content in the new version from the endpoint device using the new file extent index. Because the new file extent index causes the server to return data from the replacement version of the scene instead of from the original version of the scene, the new file(s) and new file extent index allow the original version of the scene to be substituted with the replacement version.</p><p id="p-0029" num="0028">One technical advantage of the disclosed techniques relative to the prior art is that, with the disclosed techniques, duplication of video content across multiple versions of a media title is reduced. In that regard, the disclosed techniques enable a single copy of video content that is common to all versions of a given film to be stored, instead of replicating identical video content across multiple files. Thus, with the disclosed techniques, fewer computational and storage resources are consumed when encoding and storing multiple versions of a media title for streaming. Another technical advantage of the disclosed techniques relative to the prior art is that the disclosed techniques allow a given version of the media title to be created or modified in an efficient, modular manner, unlike prior art approaches that encode and package a given version of a media title from beginning to end. These technical advantages provide one or more technological advancements over prior art approaches.</p><heading id="h-0008" level="1">System Overview</heading><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a network infrastructure configured to implement one or more aspects of the various embodiments. As shown, network infrastructure <b>100</b> includes one or more content servers <b>110</b>, a control server <b>120</b>, and one or more endpoint devices <b>115</b>, which are connected to one another and/or one or more cloud services <b>130</b> via a communications network <b>105</b>. Network infrastructure <b>100</b> is generally used to distribute content to content servers <b>110</b> and endpoint devices <b>115</b>.</p><p id="p-0031" num="0030">Each endpoint device <b>115</b> communicates with one or more content servers <b>110</b> (also referred to as &#x201c;caches&#x201d; or &#x201c;nodes&#x201d;) via network <b>105</b> to download content, such as textual data, graphical data, audio data, video data, and other types of data. The downloadable content, also referred to herein as a &#x201c;file,&#x201d; is then presented to a user of one or more endpoint devices <b>115</b>. In various embodiments, endpoint devices <b>115</b> may include computer systems, set top boxes, mobile computer, smartphones, tablets, console and handheld video game systems, digital video recorders (DVRs), DVD players, connected digital TVs, dedicated media streaming devices, (e.g., the Roku&#xae; set-top box), and/or any other technically feasible computing platform that has network connectivity and is capable of presenting content, such as text, images, video, and/or audio content, to a user.</p><p id="p-0032" num="0031">Network <b>105</b> includes any technically feasible wired, optical, wireless, or hybrid network that transmits data between or among content servers <b>110</b>, control server <b>120</b>, endpoint device <b>115</b>, cloud services <b>130</b>, and/or other components. For example, network <b>105</b> could include a wide area network (WAN), local area network (LAN), personal area network (PAN), WiFi network, cellular network, Ethernet network, Bluetooth network, universal serial bus (USB) network, satellite network, and/or the Internet.</p><p id="p-0033" num="0032">Each content server <b>110</b> may include one or more applications configured to communicate with control server <b>120</b> to determine the location and availability of various files that are tracked and managed by control server <b>120</b>. Each content server <b>110</b> may further communicate with cloud services <b>130</b> and one or more other content servers <b>110</b> to &#x201c;fill&#x201d; each content server <b>110</b> with copies of various files. In addition, content servers <b>110</b> may respond to requests for files received from endpoint devices <b>115</b>. The files may then be distributed from content server <b>110</b> or via a broader content distribution network. In some embodiments, content servers <b>110</b> may require users to authenticate (e.g., using a username and password) before accessing files stored on content servers <b>110</b>. Although only a single control server <b>120</b> is shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in various embodiments multiple control servers <b>120</b> may be implemented to track and manage files.</p><p id="p-0034" num="0033">In various embodiments, cloud services <b>130</b> may include an online storage service (e.g., Amazon&#xae; Simple Storage Service, Google&#xae; Cloud Storage, etc.) in which a catalog of files, including thousands or millions of files, is stored and accessed in order to fill content servers <b>110</b>. Cloud services <b>130</b> also may provide compute or other processing services. Although only a single instance of cloud services <b>130</b> is shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, in various embodiments multiple cloud services <b>130</b> and/or cloud service instances may be implemented.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a block diagram of content server <b>110</b> that may be implemented in conjunction with the network infrastructure of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to various embodiments. As shown, content server <b>110</b> includes, without limitation, a central processing unit (CPU) <b>204</b>, a system disk <b>206</b>, an input/output (I/O) devices interface <b>208</b>, a network interface <b>210</b>, an interconnect <b>212</b>, and a system memory <b>214</b>.</p><p id="p-0036" num="0035">CPU <b>204</b> is configured to retrieve and execute programming instructions, such as a server application <b>217</b>, stored in system memory <b>214</b>. Similarly, CPU <b>204</b> is configured to store application data (e.g., software libraries) and retrieve application data from system memory <b>214</b>. Interconnect <b>212</b> is configured to facilitate transmission of data, such as programming instructions and application data, between CPU <b>204</b>, system disk <b>206</b>, I/O devices interface <b>208</b>, network interface <b>210</b>, and system memory <b>214</b>. I/O devices interface <b>208</b> is configured to receive input data from I/O devices <b>216</b> and transmit the input data to CPU <b>204</b> via interconnect <b>212</b>. For example, I/O devices <b>216</b> may include one or more buttons, a keyboard, a mouse, and/or other input devices. I/O devices interface <b>208</b> is further configured to receive output data from CPU <b>204</b> via interconnect <b>212</b> and transmit the output data to I/O devices <b>216</b>.</p><p id="p-0037" num="0036">System disk <b>206</b> may include one or more hard disk drives, solid state storage devices, or similar storage devices. System disk <b>206</b> is configured to store non-volatile data such as files <b>218</b> (e.g., audio files, video files, subtitle files, application files, software libraries, etc.). Files <b>218</b> can then be retrieved by one or more endpoint devices <b>115</b> via network <b>105</b>. In some embodiments, network interface <b>210</b> is configured to operate in compliance with the Ethernet standard.</p><p id="p-0038" num="0037">System memory <b>214</b> includes server application <b>217</b>, which is configured to service requests received from endpoint device <b>115</b> and other content servers <b>110</b> for one or more files <b>218</b>. When server application <b>217</b> receives a request for a given file <b>218</b>, server application <b>217</b> retrieves the requested file <b>218</b> from system disk <b>206</b> and transmits file <b>218</b> to an endpoint device <b>115</b> or a content server <b>110</b> via network <b>105</b>. Files <b>218</b> include digital content items such as video files, audio files, and/or still images. In addition, files <b>218</b> may include metadata associated with such content items, user/subscriber data, etc. Files <b>218</b> that include visual content item metadata and/or user/subscriber data may be employed to facilitate the overall functionality of network infrastructure <b>100</b>. In alternative embodiments, some or all of files <b>218</b> may instead be stored in a control server <b>120</b>, or in any other technically feasible location within network infrastructure <b>100</b>.</p><p id="p-0039" num="0038">In one or more embodiments, server application <b>217</b> includes functionality to store video content that is unique to different versions of a media title in multiple byte ranges within one or more files <b>218</b>. Server application <b>217</b> also uses a number of index structures and mappings to retrieve the byte ranges in a particular order for each version of the media title during playback of the version on one or more endpoint devices <b>115</b>. As described in further detail with respect to <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>7</b></figref>, this technique for storing and retrieving content allows server application <b>217</b> to minimize duplication of content in files <b>218</b>. This technique further allows server application <b>217</b> to return, in response to each request from endpoint devices <b>115</b> for content from a given version of the media title, data that appears to be read in contiguous &#x201c;chunks&#x201d; from the same file, even when the data is stored across multiple files <b>218</b>.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a block diagram of control server <b>120</b> that may be implemented in conjunction with the network infrastructure <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to various embodiments. As shown, control server <b>120</b> includes, without limitation, a central processing unit (CPU) <b>304</b>, a system disk <b>306</b>, an input/output (I/O) devices interface <b>308</b>, a network interface <b>310</b>, an interconnect <b>312</b>, and a system memory <b>314</b>.</p><p id="p-0041" num="0040">CPU <b>304</b> is configured to retrieve and execute programming instructions, such as control application <b>317</b>, stored in system memory <b>314</b>. Similarly, CPU <b>304</b> is configured to store application data (e.g., software libraries) and retrieve application data from system memory <b>314</b> and a database <b>318</b> stored in system disk <b>306</b>. Interconnect <b>312</b> is configured to facilitate transmission of data between CPU <b>304</b>, system disk <b>306</b>, I/O devices interface <b>308</b>, network interface <b>310</b>, and system memory <b>314</b>. I/O devices interface <b>308</b> is configured to transmit input data and output data between I/O devices <b>316</b> and CPU <b>304</b> via interconnect <b>312</b>. System disk <b>306</b> may include one or more hard disk drives, solid state storage devices, and the like. System disk <b>306</b> is configured to store a database <b>318</b> of information associated with content servers <b>110</b>, cloud services <b>130</b>, and files <b>218</b>.</p><p id="p-0042" num="0041">System memory <b>314</b> includes a control application <b>317</b> configured to access information stored in database <b>318</b> and process the information to determine the manner in which specific files <b>218</b> will be replicated across content servers <b>110</b> included in the network infrastructure <b>100</b>. Control application <b>317</b> may further be configured to receive and analyze performance characteristics associated with one or more of content servers <b>110</b> and/or endpoint devices <b>115</b>. As noted above, in some embodiments, metadata associated with such visual content items, and/or user/subscriber data may be stored in database <b>318</b> rather than in files <b>218</b> stored in content servers <b>110</b>.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a block diagram of endpoint device <b>115</b> that may be implemented in conjunction with the network infrastructure of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, according to various embodiments. As shown, endpoint device <b>115</b> may include, without limitation, a CPU <b>410</b>, a graphics subsystem <b>412</b>, an I/O devices interface <b>414</b>, a mass storage unit <b>416</b>, a network interface <b>418</b>, an interconnect <b>422</b>, and a memory subsystem <b>430</b>.</p><p id="p-0044" num="0043">In some embodiments, CPU <b>410</b> is configured to retrieve and execute programming instructions stored in memory subsystem <b>430</b>. Similarly, CPU <b>410</b> is configured to store and retrieve application data (e.g., software libraries) residing in memory subsystem <b>430</b>. Interconnect <b>422</b> is configured to facilitate transmission of data, such as programming instructions and application data, between CPU <b>410</b>, graphics subsystem <b>412</b>, I/O devices interface <b>414</b>, mass storage unit <b>416</b>, network interface <b>418</b>, and memory subsystem <b>430</b>.</p><p id="p-0045" num="0044">In some embodiments, graphics subsystem <b>412</b> is configured to generate frames of video data and transmit the frames of video data to display device <b>450</b>. In some embodiments, graphics subsystem <b>412</b> may be integrated into an integrated circuit, along with CPU <b>410</b>. Display device <b>450</b> may comprise any technically feasible means for generating an image for display. For example, display device <b>450</b> may be fabricated using liquid crystal display (LCD) technology, cathode-ray technology, and light-emitting diode (LED) display technology. I/O devices interface <b>414</b> is configured to receive input data from user I/O devices <b>452</b> and transmit the input data to CPU <b>410</b> via interconnect <b>422</b>. For example, user I/O devices <b>452</b> may include one or more buttons, a keyboard, and/or a mouse or other pointing device. I/O devices interface <b>414</b> also includes an audio output unit configured to generate an electrical audio output signal. User I/O devices <b>452</b> includes a speaker configured to generate an acoustic output in response to the electrical audio output signal. In alternative embodiments, display device <b>450</b> may include the speaker. Examples of suitable devices known in the art that can display video frames and generate an acoustic output include televisions, smartphones, smartwatches, electronic tablets, and the like.</p><p id="p-0046" num="0045">A mass storage unit <b>416</b>, such as a hard disk drive or flash memory storage drive, is configured to store non-volatile data. A network interface <b>418</b> is configured to transmit and receive packets of data via network <b>105</b>. In some embodiments, network interface <b>418</b> is configured to communicate using the well-known Ethernet standard. Network interface <b>418</b> is coupled to CPU <b>410</b> via interconnect <b>422</b>.</p><p id="p-0047" num="0046">In some embodiments, memory subsystem <b>430</b> includes programming instructions and application data that include an operating system <b>432</b>, a user interface <b>434</b>, a playback application <b>436</b>, and a platform player <b>438</b>. Operating system <b>432</b> performs system management functions such as managing hardware devices including network interface <b>418</b>, mass storage unit <b>416</b>, I/O devices interface <b>414</b>, and graphics subsystem <b>412</b>. Operating system <b>432</b> also provides process and memory management models for user interface <b>434</b>, playback application <b>436</b>, and/or platform player <b>438</b>. User interface <b>434</b>, such as a window and object metaphor, provides a mechanism for user interaction with endpoint device <b>115</b>. Persons skilled in the art will recognize the various operating systems and user interfaces that are well-known in the art and suitable for incorporation into endpoint device <b>115</b>.</p><p id="p-0048" num="0047">In some embodiments, playback application <b>436</b> is configured to request and receive content from content server <b>110</b> via network interface <b>418</b>. Further, playback application <b>436</b> is configured to interpret the content and present the content via display device <b>450</b> and/or user I/O devices <b>452</b>. In so doing, playback application <b>436</b> may generate frames of video data based on the received content and then transmit those frames of video data to platform player <b>438</b>. In response, platform player <b>438</b> causes display device <b>450</b> to output the frames of video data for playback of the content on endpoint device <b>115</b>. In one embodiment, platform player <b>438</b> is included in operating system <b>432</b>.</p><heading id="h-0009" level="1">Composite Media Storage and Retrieval</heading><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates how a request <b>500</b> for media content is processed by server application <b>217</b> of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, according to various embodiments. As shown, request <b>500</b> includes an identifier <b>508</b> for a version of a media title and a range <b>510</b> of data to retrieve from the version. For example, identifier <b>508</b> could include a title, filename, numeric identifier, and/or another value that uniquely identifies the version. Range <b>510</b> could include a range of byte offsets, time offsets, and/or other types of offsets in the version.</p><p id="p-0050" num="0049">As mentioned above, each version of the media title may include a subset of video content that is specific to the version, while a majority of video content in the media title may be common to multiple versions of the media title. For example, the media title could include a number of different localized versions to support playback in multiple languages. Each localized version of the media title could include audio content in a corresponding language, as well as one or more scenes of video content that show onscreen text, graphics, and/or other types of localization in the same language. In another example, the media title could include different versions of scenes with sensitive content to meet criteria for different television, film, or content ratings for a given country.</p><p id="p-0051" num="0050">Server application <b>217</b> uses one or more file mappings <b>502</b> and/or a file extent index <b>504</b> to process request <b>500</b>. File mappings <b>502</b> and/or file extent index <b>504</b> may be stored in a relational database, key-value store, distributed filesystem, one or more flat files, and/or another type of data store or format.</p><p id="p-0052" num="0051">File mappings <b>502</b> include identifiers <b>512</b>(<b>1</b>)-<b>512</b>(X) for different versions of the media title. Each of identifiers <b>512</b>(<b>1</b>)-<b>512</b>(X) is referred to individually as identifier <b>512</b>. For example, each identifier <b>512</b> could include a title, filename, numeric identifier, and/or another value that uniquely identifies the corresponding version of the media title.</p><p id="p-0053" num="0052">File mappings <b>502</b> also include paths <b>522</b>(<b>1</b>)-<b>522</b>(X) for files <b>218</b>(<b>1</b>)-<b>218</b>(X) on system disk <b>206</b>. Each of paths <b>522</b>(<b>1</b>)-<b>522</b>(X) is referred to individually as path <b>522</b>, and each of files <b>218</b>(<b>1</b>)-<b>218</b>(X) is referred to individually as file <b>218</b>.</p><p id="p-0054" num="0053">More specifically, each of file mappings <b>502</b> includes a one-to-one mapping between a given identifier <b>512</b> for a version of the media title and a path <b>522</b> for a corresponding file <b>218</b> that stores video (or another type of) content for the media title. Within each file mapping <b>502</b>, identifier <b>512</b> acts as a key that can be used to retrieve path <b>522</b> for a corresponding file <b>218</b>.</p><p id="p-0055" num="0054">In one or more embodiments, server application <b>217</b> processes request <b>500</b> by performing a lookup of file mappings <b>502</b> using identifier <b>508</b>. When identifier <b>508</b> matches a given identifier <b>512</b> in file mappings <b>502</b>, server application <b>217</b> retrieves the requested range <b>510</b> of data from a particular file <b>218</b> at the corresponding path <b>522</b> to which the given identifier <b>512</b> is mapped. For example, server application <b>217</b> could match a value of &#x201c;111222333&#x201d; for identifier <b>508</b> to the following mapping included in file mappings <b>502</b>:<ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0000">    <ul id="ul0002" list-style="none">        <li id="ul0002-0001" num="0055">111222333/1/01/111222333.ismv<br/>Server application <b>217</b> would retrieve a value of &#x201c;/1/01/111222333.ismv&#x201d; for path <b>522</b> from the mapping and read data <b>524</b> that spans a byte range <b>510</b> (e.g., range of byte offsets) specified in request <b>500</b> from the corresponding file <b>218</b> at path <b>522</b>. Server application <b>217</b> would then return the retrieved data <b>524</b> in a response <b>506</b> to request <b>500</b>, thereby allowing the device (e.g., endpoint device <b>115</b>) from which request <b>500</b> was received to start or continue playback of the version of the media title stored in the &#x201c;111222333&#x201d; file <b>218</b>.</li>    </ul>    </li></ul></p><p id="p-0056" num="0056">Unlike file mappings <b>502</b>, file extent index <b>504</b> includes data that can be used to perform streaming or playback of a corresponding version of the media title from multiple files (or multiple non-contiguous segments within the same file). For example, file extent index <b>504</b> could be created for a version of the media title that includes alternative or additional scenes, which are substituted for or added to original versions of the scenes in a &#x201c;base&#x201d; version of the media title. In this example, the alternative or additional scenes could be stored in one or more files, and scenes from the base version of the media title could be stored in one or more other files.</p><p id="p-0057" num="0057">As shown, file extent index <b>504</b> includes an identifier <b>514</b> (e.g., a unique name or alphanumeric identifier) for the version of the media title, metadata <b>516</b> related to the version, and mappings of identifiers <b>518</b>(<b>1</b>)-<b>518</b>(Y) for one or more files <b>218</b> to ranges <b>520</b>(<b>1</b>)-<b>520</b>(Y) of data to be retrieved from the file(s) (e.g., a range denoted by a starting byte offset and an ending byte offset, a range denoted by a starting byte offset and an end represented by a number of bytes after the starting byte offset, etc.). Each of identifiers <b>518</b>(<b>1</b>)-<b>518</b>(Y) is referred to individually as identifier <b>518</b>, and each of ranges <b>520</b>(<b>1</b>)-<b>520</b>(Y) is referred to individually as range <b>520</b>. The ordering of mappings between identifiers <b>518</b>(<b>1</b>)-<b>518</b>(Y) and the corresponding ranges <b>520</b>(<b>1</b>)-<b>520</b>(Y) in file extent index <b>504</b> additionally reflects the order in which video content should be retrieved for end-to-end playback of the version of the media title.</p><p id="p-0058" num="0058">An example file extent index <b>504</b> includes the following representation:<ul id="ul0003" list-style="none">    <li id="ul0003-0001" num="0000">    <ul id="ul0004" list-style="none">        <li id="ul0004-0001" num="0059">111222111 1593204284, 46828784, ismv; 111222333:0:20000;</li>        <li id="ul0004-0002" num="0060">111222444:5000:46808784<br/>The above representation includes a value of &#x201c;111222111&#x201d; for identifier <b>514</b>, followed by three metadata <b>516</b> values. The first value of &#x201c;1593204284&#x201d; represents the modification time for the corresponding version of the media title, the second value of &#x201c;46828784&#x201d; represents the length in bytes of the version, and the third value of &#x201c;ismv&#x201d; represents a filename extension that can be used to construct a Hypertext Transfer Protocol (HTTP) response <b>506</b> header. Metadata <b>516</b> values are followed by two mappings of identifiers <b>518</b> to ranges <b>520</b>. The first mapping includes a value of &#x201c;111222333&#x201d; for identifier <b>518</b>, a beginning byte offset of 0 in the corresponding range <b>520</b>, and a value of &#x201c;20000&#x201d; for the number of bytes spanned by the corresponding range <b>520</b>. The second mapping includes a value of &#x201c;111222444&#x201d; for identifier <b>518</b>, a beginning byte offset of &#x201c;5000&#x201d; in the corresponding range <b>520</b>, and a value of &#x201c;46808784&#x201d; for the number of bytes spanned by the corresponding range <b>520</b>. This example file extent index <b>504</b> indicates that the first 20,000 bytes of the &#x201c;111222111&#x201d; version of the media title are retrieved from the first 20,000 bytes of the file mapped to the &#x201c;111222333&#x201d; identifier in file mappings <b>502</b>, and that the remaining 46,808,784 bytes of the &#x201c;111222111&#x201d; version are retrieved starting at the 5,000<sup>th </sup>byte of the file mapped to the &#x201c;111222444&#x201d; identifier in file mappings <b>502</b>.</li>    </ul>    </li></ul></p><p id="p-0059" num="0061">When identifier <b>508</b> in request <b>500</b> does not match any identifier <b>512</b> in file mappings <b>502</b>, server application <b>217</b> may match identifier <b>508</b> to identifier <b>514</b> in a given file extent index <b>504</b>. For example, server application <b>217</b> could perform a lookup of a database, key-value store, and/or another data store to retrieve a given file extent index <b>504</b> with a value of identifier <b>514</b> that matches the value of identifier <b>508</b> in request <b>500</b>. This lookup could be performed in conjunction with or independent of a lookup of file mappings <b>502</b> using the same identifier <b>508</b>.</p><p id="p-0060" num="0062">After identifier <b>508</b> is matched to identifier <b>514</b> in file extent index <b>504</b>, server application <b>217</b> uses mappings between one or more identifiers <b>518</b> to one or more ranges <b>520</b> in file extent index <b>504</b> and corresponding file mappings <b>502</b> between the same identifiers <b>512</b> and the corresponding paths <b>522</b> to retrieve data <b>524</b> in the requested range <b>510</b>. In other words, server application <b>217</b> uses file extent index <b>504</b> and file mappings <b>502</b> to piece together different ranges of data <b>524</b> from multiple files <b>218</b> and return data <b>524</b> in response <b>506</b> so that, to the device from which request <b>500</b> was received, the returned data <b>524</b> appears to be read in a contiguous range from the same file.</p><p id="p-0061" num="0063">The operation of server application <b>217</b> is illustrated using a value of &#x201c;111222111&#x201d; for identifier <b>508</b> in request <b>500</b>, the above example file extent index <b>504</b>, the above example file mapping of &#x201c;111222333/1/01/111222333.ismv,&#x201d; and an additional file mapping of &#x201c;111222444/1/01/111222444.ismv.&#x201d; First, server application <b>217</b> matches identifier <b>508</b> to the same value of &#x201c;111222111&#x201d; for identifier <b>514</b> in the example file extent index <b>504</b>. Next, server application <b>217</b> uses mappings of identifiers <b>518</b> to ranges <b>520</b> in the example file extent index <b>504</b> to determine one or more files <b>218</b> from which the requested range <b>510</b> of data <b>524</b> is to be extracted, as well as corresponding portions of data to be extracted from each file. Server application <b>217</b> also uses file mappings <b>502</b> associated with the file(s) to locate the file(s) on system disk <b>206</b>, retrieve the corresponding portions of data from the file(s), and return the retrieved data <b>524</b> in response <b>506</b>.</p><p id="p-0062" num="0064">Thus, if range <b>510</b> in request <b>500</b> includes the first 10,000 bytes of the version of the media title represented by the &#x201c;111222111&#x201d; identifier, server application <b>217</b> would use the first mapping in the example file extent index <b>504</b> to determine that the entire range <b>510</b> is to be read from the first 10,000 bytes of the file mapped to the &#x201c;111222333&#x201d; identifier <b>518</b> in the example file extent index <b>504</b>. Next, server application <b>217</b> would use the file mapping that includes the &#x201c;111222333&#x201d; identifier <b>512</b> to obtain a path of &#x201c;/1/01/111222333.ismv&#x201d; for the corresponding file and retrieve the first 10,000 bytes from the file. Server application <b>217</b> would then generate response <b>506</b> that includes the retrieved data <b>524</b> and transmit response <b>506</b> to the device or location from which request <b>500</b> was received.</p><p id="p-0063" num="0065">If range <b>510</b> in request <b>500</b> includes 10,000 bytes starting at the 20,000th byte of the media title represented by the &#x201c;111222111&#x201d; identifier, server application <b>217</b> would use the first and second mappings in the example file extent index <b>504</b> to determine that the entire range <b>510</b> is to be read from the file mapped to the &#x201c;111222444&#x201d; identifier <b>518</b> in the example file extent index <b>504</b>. Next, server application <b>217</b> would use the file mapping that includes the &#x201c;111222444&#x201d; identifier to obtain a path of &#x201c;/1/01/111222444.ismv&#x201d; for the corresponding file and retrieve 10,000 bytes from the file, starting at byte offset 5,000 in the file.</p><p id="p-0064" num="0066">If range <b>510</b> in request <b>500</b> includes 10,000 bytes starting at the 100,000th byte of the media title represented by the &#x201c;111222111&#x201d; identifier, server application <b>217</b> would use the mappings in the example file extent index <b>504</b> to determine that the entire range <b>510</b> is to be read from the file mapped to the &#x201c;111222444&#x201d; identifier <b>518</b> in the example file extent index <b>504</b>. Next, server application <b>217</b> would use the file mapping that includes the &#x201c;111222444&#x201d; identifier to obtain a path of &#x201c;/1/01/111222444.ismv&#x201d; for the corresponding file and retrieve 10,000 bytes from the file, starting at byte offset 85,000 in the file (since the first 20,000 bytes in the media title come from the file mapped to the &#x201c;111222333&#x201d; identifier and the starting point for the range from the file mapped to the &#x201c;111222444&#x201d; identifier is the 5,000th byte).</p><p id="p-0065" num="0067">In some embodiments, server application <b>217</b> uses segment indexes <b>530</b>(<b>1</b>)-<b>530</b>(X) for one or more files <b>218</b>(<b>1</b>)-<b>218</b>(X) to process request <b>500</b> when range <b>510</b> is specified in time offsets instead of byte offsets. For example, request <b>500</b> could include time offsets in range <b>510</b> when request <b>500</b> is used to &#x201c;seek&#x201d; or &#x201c;scrub&#x201d; to a different part of the media title during playback. Request <b>500</b> could also, or instead, include time offsets in range <b>510</b> when request <b>500</b> is received from a given playback application <b>436</b> that performs retrieval and playback of streaming content using time offsets instead of byte offsets. Each of segment indexes <b>530</b>(<b>1</b>)-<b>530</b>(X) is referred to individually as segment index <b>530</b> and includes a mapping of time offsets (e.g., timestamps) to byte offsets in individual segments <b>532</b>(<b>1</b>)-<b>532</b>(X) within the corresponding file <b>218</b>. Each segment index <b>530</b> may be stored at the beginning of the corresponding file <b>218</b> and/or in a separate file or location.</p><p id="p-0066" num="0068">More specifically, when request <b>500</b> includes a range <b>510</b> of time offsets, server application <b>217</b> may match identifier <b>508</b> to a corresponding identifier <b>512</b> in file mappings <b>502</b> and/or identifier <b>514</b> in file extent index <b>504</b>. If identifier <b>508</b> is the same as a given identifier <b>512</b> in file mappings <b>502</b>, server application <b>217</b> retrieves segment index <b>530</b> from file <b>218</b> at a corresponding path <b>522</b> to which the given identifier <b>512</b> is mapped. Server application <b>217</b> also uses mappings between time offsets and byte offsets in the retrieved segment index <b>530</b> to convert the time offsets in range <b>510</b> into byte offsets in file <b>218</b>. Server application <b>217</b> then retrieves data <b>524</b> spanning the byte offsets from file <b>218</b> and return data <b>524</b> in response <b>506</b> to request <b>500</b>.</p><p id="p-0067" num="0069">If identifier <b>508</b> matches identifier <b>514</b> in file extent index <b>504</b>, server application <b>217</b> uses file extent index <b>504</b> and one or more segment indexes <b>530</b> for one or more files <b>218</b> represented by one or more identifiers <b>518</b> in file extent index <b>504</b> to process request <b>500</b>. In particular, server application <b>217</b> uses segment indexes <b>530</b> to convert ranges <b>520</b> of byte offsets in file extent index <b>504</b> into ranges of time offsets for the corresponding files <b>218</b>. Server application <b>217</b> may optionally store mappings between byte offsets specified in ranges <b>520</b> within file extent index <b>504</b> and the corresponding time offsets in files <b>218</b> in file extent index <b>504</b> and/or another index structure. For example, server application <b>217</b> could annotate a given range <b>520</b> of byte offsets in file extent index <b>504</b> with a corresponding range <b>520</b> of time offsets in the version of the media title. After request <b>500</b> is received, server application <b>217</b> may use these ranges <b>520</b> of time offsets to identify one or more files <b>218</b> from which data spanning range <b>510</b> is to be retrieved. Server application <b>217</b> may then use segment indexes <b>530</b> for these file(s) to convert time offsets in range <b>510</b> into one or more ranges of bytes in the file(s), retrieve data <b>524</b> spanning the byte range(s) from the file(s), and return the retrieved data <b>524</b> in response <b>506</b>.</p><p id="p-0068" num="0070">The operation of server application <b>217</b> is illustrated using the example file extent index <b>504</b> and example file mappings <b>502</b> above, a value of &#x201c;111222111&#x201d; for identifier <b>508</b> in request <b>500</b>, and time offsets of 0:00:00 and 0:00:30 in range <b>510</b> within request <b>500</b>. First, server application <b>217</b> matches identifier <b>508</b> to the same value of &#x201c;111222111&#x201d; for identifier <b>514</b> in the example file extent index <b>504</b>. Server application <b>217</b> also retrieves, from file extent index <b>504</b> and/or one or more segment indexes <b>530</b> for the &#x201c;111222333&#x201d; and &#x201c;111222444&#x201d; files, mappings that convert the byte range starting at offset 0 and spanning 20,000 bytes for the &#x201c;111222333&#x201d; file to time offsets of 00:00:00 to 00:00:30 and the byte range beginning at byte offset 5,000 and spanning 46,808,784 bytes for the &#x201c;111222444&#x201d; file to time offsets of 00:00:31 to 03:00:00. Server application <b>217</b> then uses file mappings <b>502</b> to retrieve the first 20,000 bytes from the &#x201c;111222333&#x201d; file and return the retrieved data in response <b>506</b> to request <b>500</b>.</p><p id="p-0069" num="0071">If request <b>500</b> includes the same identifier <b>508</b> of &#x201c;111222111&#x201d; and time offsets of 00:00:00 and 00:01:00 in range <b>510</b>, server application <b>217</b> may use the mappings of byte ranges to time offsets in file extent index <b>504</b> and/or one or more segment indexes <b>530</b> to determine that range <b>510</b> spans both the &#x201c;111222333&#x201d; and &#x201c;111222444&#x201d; files. Server application <b>217</b> may retrieve the entire byte range of 0 to 20,000 from the &#x201c;111222333&#x201d; file, since the time offsets spanned by the first 20,000 bytes of the &#x201c;111222333&#x201d; file fall within the time offsets in range <b>510</b>. Server application <b>217</b> may also retrieve segment index <b>530</b> for the &#x201c;111222444&#x201d; file and use one or more mappings in the retrieved segment index <b>530</b> to convert the time offset of 00:01:00 from range <b>510</b> into a byte offset of 45,000 in the &#x201c;111222444&#x201d; file. Server application <b>217</b> may then generate response <b>506</b> that includes the first 20,000 bytes from the &#x201c;111222333&#x201d; file and additional data spanning the byte offsets of 5,000 and 45,000 from the &#x201c;111222444&#x201d; file.</p><p id="p-0070" num="0072"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> illustrates an exemplar set of data structures that can be used when playing back a version of a media title, according to various embodiments. As shown, these structures include two files <b>600</b>-<b>602</b> and a file extent index <b>628</b>.</p><p id="p-0071" num="0073">File <b>600</b> includes a number of portions <b>604</b>-<b>612</b>. The first portion <b>604</b> stores a segment index (SIDX) that maps time offsets in one or more versions of the media title to byte offsets in file <b>600</b>, and four subsequent portions <b>606</b>-<b>612</b> store four data segments S<b>1</b>, S<b>2</b>, S<b>3</b>, and S<b>4</b>. Data segments S<b>1</b>, S<b>2</b>, S<b>3</b>, and S<b>4</b> in portions <b>606</b>-<b>612</b> include encoded segments of video and/or other content in the version of the media title, which can be partially or wholly retrieved and delivered to playback application <b>436</b> on a given endpoint device <b>115</b> for playback on the same endpoint device <b>115</b>.</p><p id="p-0072" num="0074">Like file <b>600</b>, file <b>602</b> includes a number of portions <b>622</b>-<b>626</b>. The first portion <b>622</b> stores a SIDX (denoted as SIDX&#x2032;) that maps time offsets in one or more versions of the media title to byte offsets in file <b>602</b>, and two subsequent portions <b>624</b>-<b>626</b> store two data segments S<b>2</b>&#x2032; and S<b>4</b>&#x2032;. S<b>2</b>&#x2032; includes an alternative version of segment S<b>2</b>, and S<b>4</b>&#x2032; includes an alternative version of segment S<b>4</b>. For example, segments S<b>2</b>&#x2032; and S<b>4</b>&#x2032; could include localized French versions of English-language video content stored in segments S<b>2</b> and S<b>4</b>, respectively. In another example, segments S<b>2</b>&#x2032; and S<b>4</b>&#x2032; could include edited or audience-appropriate versions of original video content stored in segments S<b>2</b> and S<b>4</b>, respectively.</p><p id="p-0073" num="0075">In some embodiments, SIDX&#x2032; in portion <b>622</b> of file <b>602</b> includes mappings of time offsets in one or more versions of the media title to byte offsets in one or more corresponding files <b>600</b> and/or <b>602</b>. These mappings allow the alternative versions of video content in segments S<b>2</b>&#x2032; and S<b>4</b>&#x2032; to be overlaid onto &#x201c;base&#x201d; or original versions of video content in file <b>600</b> during playback of a version of the media title that replaces segments S<b>2</b> and S<b>4</b> with segments S<b>2</b>&#x2032; and S<b>4</b>&#x2032;, respectively. For example, SIDX&#x2032; in portion <b>622</b> could include mappings of time offsets in segment S<b>1</b> to byte offsets in portion <b>606</b>, followed by mappings of time offsets in segment S<b>2</b>&#x2032; to byte offsets in portion <b>624</b>, followed by mappings of time offsets in segment S<b>3</b> to byte offsets in portion <b>610</b>, followed by mappings of time offsets in segment S<b>4</b>&#x2032; to byte offsets in portion <b>626</b>.</p><p id="p-0074" num="0076">Because text in different languages can consume different amounts and/or regions of screen space in these scenes, alternative versions of video content stored in S<b>2</b>&#x2032; and S<b>4</b>&#x2032; can occupy different amounts of space than the original versions stored in S<b>2</b> and S<b>4</b>, respectively. In particular, byte offsets denoting the boundaries of portions <b>604</b>-<b>626</b> in files <b>600</b>-<b>602</b> are shown in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, and ranges of these byte offsets occupied by various portions <b>604</b>-<b>626</b> are described below. Each range is represented by a starting byte offset that is included in the range and an ending byte offset to which the range extends but does not include. Thus, an example range spanned by the byte offsets of 5,000 to 10,000 would be interpreted as 5,000 (inclusive) to 10,000 (exclusive).</p><p id="p-0075" num="0077">More specifically, byte offsets occupied by portions <b>604</b>-<b>626</b> indicate that the first 10,000 bytes of files <b>600</b>-<b>602</b> are reserved for the corresponding portions <b>604</b> and <b>622</b>, which allows SIDX mappings and/or other metadata to be stored in these portions. The byte offsets also indicate that S<b>1</b> in portion <b>606</b> spans the byte offsets of 10,000 to 20,000 in file <b>600</b>, S<b>2</b> in portion <b>608</b> spans the byte offsets of 20,000 to 26,000 in file <b>600</b>, S<b>3</b> in portion <b>610</b> spans the byte offsets of 26,000 to 35,000 in file <b>600</b>, and S<b>4</b> in portion <b>612</b> spans the byte offsets of 35,000 to 50,000 in file <b>600</b>. The byte offsets further indicate that S<b>2</b>&#x2032; in portion <b>624</b> spans the byte offsets of 10,000 to 23,000 in file <b>602</b> and that S<b>4</b>&#x2032; in portion <b>626</b> spans the byte offsets of 23,000 to 54,000 in file <b>602</b>. As a result, S<b>2</b>&#x2032; and S<b>4</b>&#x2032; are about twice the size of S<b>2</b> and S<b>4</b>, respectively.</p><p id="p-0076" num="0078">In turn, SIDX mappings stored in the SIDX of portion <b>604</b> and SIDX&#x2032; of portion <b>622</b> may reflect the different sizes of the corresponding segments. For example, the SIDX in portion <b>604</b> could map time offsets of 00:05:00 and 00:07:00 in the media title to the byte offsets of 20,000 and 26,000 spanned by S<b>2</b> in portion <b>606</b>, while the SIDX in portion <b>622</b> could map the same time offsets of 00:05:00 and 00:07:00 in the media title to the byte offsets of 10,000 and 23,000 spanned by S<b>2</b>&#x2032; in portion <b>624</b>.</p><p id="p-0077" num="0079">File extent index <b>628</b> includes a number of portions <b>630</b>-<b>642</b>, which store data that can be used to perform streaming or playback of a version of the media title from multiple files. For example, file extent index <b>628</b> could be used to process requests for content in a French version of the media title, which includes a non-localized English version of a first scene stored in S<b>1</b>, a French version of a second scene stored in S<b>2</b>&#x2032;, a non-localized version of a third scene stored in S<b>3</b>, and a French version of a fourth scene stored in S<b>4</b>&#x2032;. In another example, file extent index <b>628</b> could be used to process requests for content in a family-friendly version of the media title, which includes an original version of a first scene stored in S<b>1</b>, an edited version of a second scene stored in S<b>2</b>&#x2032;, an original version of a third scene stored in S<b>3</b>, and an edited version of a fourth scene stored in S<b>4</b>&#x2032;.</p><p id="p-0078" num="0080">More specifically, file extent index <b>628</b> includes a first portion <b>630</b> storing a unique identifier for the version of the media title, as well as a second portion <b>632</b> that stores metadata (e.g., modification time, length in bytes, filename extension, etc.) related to the version. The remaining five portions <b>634</b>-<b>642</b> store mappings that specify different ranges of data to be read during playback of the version. As described above, each mapping in portions <b>634</b>-<b>642</b> may include an identifier for a file, as well as a beginning and ending byte and/or time offset for a range of data that is stored in the file and included in the version of the media title. The ordering of the mappings in portions <b>634</b>-<b>642</b> additionally indicates the order in which video content should be retrieved for end-to-end playback of the version of the media title. In particular, the mappings in portions <b>634</b>-<b>642</b> specify that end-to-end playback of the version of the media title should involve retrieving SIDX&#x2032; stored in file <b>602</b> (e.g., to allow requests for data spanning time offsets in the version of the media title to be processed), followed by retrieving S<b>1</b> stored in byte offsets 10,000 up to (but not including) 20,000 from file <b>600</b>, followed by retrieving S<b>2</b>&#x2032; stored in byte offsets 10,000 up to (but not including) 23,000 from file <b>602</b>, followed by retrieving S<b>3</b> stored in byte offsets 26,000 up to (but not including) 35,000 from file <b>600</b>, and followed by retrieving S<b>4</b>&#x2032; stored in byte offsets 23,000 up to (but not including) 54,000 from file <b>602</b>.</p><p id="p-0079" num="0081"><figref idref="DRAWINGS">FIG. <b>6</b>B</figref> illustrates how a request for media content is processed using the exemplar set of data structures of <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, according to various embodiments. Request <b>650</b> includes a first portion <b>654</b> that specifies an identifier for a version of a media title, a second portion <b>656</b> that specifies a beginning byte offset of 15,000, and a third portion <b>658</b> that specifies an ending byte offset of 24,999.</p><p id="p-0080" num="0082">As shown, request <b>650</b> is processed by retrieving data spanning the range represented by the beginning and ending byte offsets in portions <b>656</b>-<b>658</b> from the version of the media title. To process request <b>650</b>, server application <b>217</b> matches the ID in portion <b>654</b> to the ID in portion <b>630</b> of file extent index <b>628</b>. Next, server application <b>217</b> uses file extent index <b>628</b> to identify one or more files from which the range of data is to be retrieved, as well as portions of the file(s) corresponding to the range of data.</p><p id="p-0081" num="0083">In particular, server application <b>217</b> uses mappings stored in portions <b>634</b>-<b>642</b> of file extent index <b>628</b> to convert the beginning and ending byte offsets in portions <b>656</b>-<b>658</b> of request <b>650</b> into offsets within one or more files <b>600</b>-<b>602</b>. First, server application <b>217</b> uses the byte range of 0 to 10,000 spanned by SIDX&#x2032; in the mapping stored in portion <b>634</b> and the byte range of 10,000 to 20,000 spanned by S<b>1</b> in the mapping stored in portion <b>636</b> to determine that the beginning offset of 15,000 in portion <b>656</b> of request <b>650</b> corresponds to the byte offset of 15,000 in file <b>600</b>. For example, server application <b>217</b> could determine that the 15,000th byte of content in the requested version of the media title lies beyond the 10,000 bytes spanned by SIDX&#x2032; in the mapping stored in portion <b>634</b>. Server application <b>217</b> could also determine that this 15,000th byte is 5,000 bytes after SIDX&#x2032; (e.g., by subtracting the 10,000 bytes spanned by SIDX&#x2032; from the requested byte offset of 15,000) and add 5,000 to the beginning offset of 10,000 for S<b>1</b> in the mapping stored in portion <b>636</b> to obtain an offset of 15,000 in file <b>600</b>. Since this offset of 15,000 in file <b>600</b> falls within the byte range stored in portion <b>636</b>, server application <b>217</b> would retrieve data starting from this offset.</p><p id="p-0082" num="0084">Server application <b>217</b> also determines that the ending offset of 24,999 in portion <b>658</b> is 10,000 bytes after the starting offset of 15,000 in portion <b>656</b>, thereby indicating that 10,000 bytes of content in the version of the media title are to be retrieved, starting at the 15,000th byte of content in the version of the media title. Server application <b>217</b> then uses mappings in portions <b>634</b>-<b>642</b> of file extent index <b>628</b> to identify a byte offset in a file that corresponds to 10,000 bytes after the 15,000th byte of content. For example, server application <b>217</b> could determine that 5,000 bytes lie between the byte offset of 15,000 in file <b>600</b>, which represents the 15,000th byte of content in the version of the media title, and the end of the byte range stored in portion <b>636</b>. Server application <b>217</b> would then determine that 5,000 more bytes are to be retrieved from one or more byte ranges stored in subsequent portions <b>638</b>-<b>642</b> of file extent index <b>628</b> to satisfy request <b>650</b>. In turn, server application <b>217</b> would use the byte range of 10,000-23,000 spanned by S<b>2</b>&#x2032; in the mapping stored in portion <b>638</b> to determine that the requested range ends in S<b>2</b>&#x2032; within file <b>602</b>, and that the remaining 5,000 bytes should be retrieved from byte offsets 10,000 to 14,999 in file <b>602</b>.</p><p id="p-0083" num="0085">Server application <b>217</b> then generates and transmits a response <b>652</b> to request <b>650</b> that includes content spanning the byte offsets of 15,000 to 24,999 in the version of the media title. As shown, the response includes an optional first portion <b>660</b> that includes the same identifier as portions <b>630</b> and <b>654</b>, a second portion <b>662</b> that includes 5,000 bytes spanning the byte offsets of 15,000 to 19,999 from S<b>1</b> in file <b>600</b>, and a third portion <b>664</b> that includes 5,000 bytes spanning the byte offsets of 10,000 to 14,999 from S<b>2</b>&#x2032; in file <b>602</b>. Response <b>652</b> may additionally be formatted so that the 10,000 bytes of data retrieved by server application <b>217</b> appear to be from a contiguous portion of a single file.</p><p id="p-0084" num="0086"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flow diagram of method steps for accessing a media title for playback, according to various embodiments. Although the method steps are described in conjunction with the systems of <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>6</b></figref>, persons skilled in the art will understand that any system configured to perform the method steps, in any order, is within the scope of the present invention.</p><p id="p-0085" num="0087">As shown, server application <b>217</b> receives <b>702</b> a request for a range of data included in an encoded version of a media title. For example, server application <b>217</b> could receive the request from a client device (e.g., endpoint device <b>115</b>) that provides streaming media functionality to an end user. The client device could include a legacy streaming video application, which requests ranges of data from a single file during playback of a media title instead of switching between files at certain points during the playback. The request could include an identifier (e.g., filename) for the file, a starting time or data offset for the range of data, and an ending time or data offset for the range of data. Alternatively, the request could specify a number of bytes (or seconds) of content to retrieve after the starting offset in lieu of the ending time or data offset.</p><p id="p-0086" num="0088">Next, server application <b>217</b> determines <b>704</b>, based on a file extent index, one or more files that are included in a set of files across which the encoded version of the media title is stored and from which the range of data is to be accessed. The set of files may overlap with other sets of files across which other encoded versions of the media title are stored. For example, multiple encoded versions of the media title could include a &#x201c;base&#x201d; or &#x201c;original&#x201d; version of content stored in one or more files, while each encoded version of the media title could include additional content that is specific to the version in the same file(s) and/or one or more different files. The file extent index includes the identifier for the encoded version of the media title and metadata related to the encoded version of the media title (e.g., a length of the encoded version, a modification time of the encoded version, a file extension to be included in a header for a response to the request, etc.). The file extent index also maps identifiers for the set of files to ranges of data stored in the files. Each range of data identifies at least a portion of the corresponding file to be included in the encoded version of the media title. In addition, the ordering of mappings between identifiers and the corresponding offset ranges in the file extent index reflects the order in which video content should be retrieved for end-to-end playback of the encoded version of the media title. Thus, the encoded version may be played from start to finish by retrieving the first range of data included in the first mapping within the file extent index from a first file represented by the first identifier in the first mapping, followed by retrieving the second range of data included in the second mapping within the file extent index from a second file represented by the second identifier in the second mapping, and so on.</p><p id="p-0087" num="0089">Server application <b>217</b> also retrieves <b>706</b> the range of data from the file(s) based on the file extent index and/or one or more segment indexes for the file(s). More specifically, server application <b>217</b> may use mappings in the file extent index and/or segment index(es) to convert a starting offset for the range of data specified in the request into a first offset within a file identified in the file extent index. In general, this conversion may be performed via one or more computations or comparisons involving the starting offset and the number of bytes spanned by one or more ranges of data included in the first file extent index. After these computations or comparisons are performed, server application <b>217</b> is able to identify the file in which the starting offset is found, as well as the first offset in the file to which the starting offset corresponds.</p><p id="p-0088" num="0090">For example, server application <b>217</b> could iteratively perform a summation of the number of bytes spanned by the first n ranges of data in mappings within the file extent index. Once the resulting sum is greater than the starting offset, server application <b>217</b> could identify the value of n that produced the sum and determine that the starting offset is located in a file represented by the nth mapping in the file extent index. Server application <b>217</b> could subtract the starting offset from the sum to obtain a &#x201c;difference&#x201d; value representing the number of bytes separating the first offset and the end of the range of data in the nth mapping. Server application <b>217</b> could then subtract the value from the end of the range of data in the nth mapping to obtain the first offset in the file from which the range of data specified in the request is to be retrieved. Alternatively, server application <b>217</b> could subtract the sum representing the number of bytes spanned by the first n&#x2212;1 ranges of data in the file extent index from the starting offset to obtain a value representing the number of bytes separating the first offset and the start of the range of data in the nth mapping. Server application <b>217</b> could then add the value to the start of the range of data in the nth mapping to obtain the first offset in the file from which the range of data specified in the request is to be retrieved.</p><p id="p-0089" num="0091">In another example, server application <b>217</b> could iteratively subtract the number of bytes spanned by each range of data in the file extent index from the starting offset, so that the nth iteration generates a value that is the result of subtracting the number of bytes spanned by the first n ranges of data in mappings within the file extent index from the starting offset. Using this iterative process, server application <b>217</b> could identify the lowest value of n that produces a negative number and determine that the starting offset is located in a file represented by the nth mapping in the file extent index. Because this negative number represents the numerical difference between the first offset and the end of the range of data in the nth mapping, server application <b>217</b> could calculate the first offset within the file that corresponds to the starting offset by summing this negative number and the end of the range of data in the nth mapping.</p><p id="p-0090" num="0092">After the starting offset for the range of data specified in the request is converted into a first offset within a file identified in the file extent index, server application <b>217</b> may retrieve the number of bytes spanned by the range of data from the file and/or one or more other files identified in the file extent index. If the range of data specified in the request falls within the range of data in the nth mapping representing the file, server application <b>217</b> could retrieve the entire range of requested data from the file, starting at the first offset. If the range of data specified in the request does not fall within the range of data in the nth mapping representing the file (e.g., if the requested range of data spans a greater number of bytes than the number of bytes separating the first offset and the end of the range of data in the nth mapping representing the file), server application <b>217</b> could retrieve a first portion of the requested range of data from the first offset to the end of the range of data in the nth mapping. Server application <b>217</b> could retrieve a second portion of the requested range of data from the beginning of the range of data in the n+1th mapping to the end of the requested range of data or the end of the range of data in the n+1th mapping, whichever occurs first. If the end of the requested range of data exceeds the end of the range of data in the n+1th mapping, server application <b>217</b> could retrieve additional portions of requested data from files represented by subsequent mappings in the file extent index until the entire requested range of data is obtained.</p><p id="p-0091" num="0093">When the request received in operation <b>702</b> specifies the range of data to be retrieved in terms of time offsets instead of integer offsets representing displacements of bytes (or other units of data) from the beginning of the encoded version of the media title, server application <b>217</b> uses mappings between time offsets and byte offsets in one or more segment indexes for the file(s) identified in operation <b>704</b> to convert a first time offset delineating the start of the range of data specified in the request into a first offset in a file represented by a mapping in the file extent index. For example, server application <b>217</b> could use segment indexes for all files represented by mappings in the file extent index to convert ranges of byte offsets in the file extent index into ranges of time offsets for the corresponding files. Server application <b>217</b> could optionally store these ranges of time offsets in the file extent index and/or another index structure. Server application <b>217</b> could then use these ranges of time offsets to identify one or more files from which data spanning the range specified in the request is to be retrieved. Server application <b>217</b> could further use one or more segment indexes for these file(s) to convert a starting and/or ending time offset in the requested range into a corresponding starting and/or ending offset in a file and retrieve data spanning the requested range(s) from the file(s).</p><p id="p-0092" num="0094">Finally, server application <b>217</b> transmits <b>708</b> the range of data in a response to the request. For example, server application <b>217</b> includes the retrieved data, an identifier for the encoded version of the media title, a file extension specified in metadata from the file extent index for the encoded version, and/or other data or metadata in the response. Server application <b>217</b> then transmits the response to the client device over a network connection.</p><p id="p-0093" num="0095">Server application <b>217</b> may continue processing <b>710</b> additional requests using operations <b>702</b>-<b>708</b>. For example, server application <b>217</b> could process each request for a version of a media title that is stored across multiple files (or multiple non-contiguous segments within the same file) using a file extent index for the version of the media title, one or more file mappings between identifiers for the files and locations (e.g., paths) of the files, and/or one or more segment indexes for the files. Using these mappings and index structures, server application <b>217</b> could retrieve one or more portions of the range of data specified in each request within one or more ranges of offsets mapped to one or more of the files identified in the file extent index.</p><p id="p-0094" num="0096">In sum, different versions of a media title are stored across multiple files and/or multiple segments within a given file. Each version of the media title may include one or more portions of content that are specific to the version (e.g., localized versions of scenes that include &#x201c;burned in&#x201d; text in different languages) and one or more portions that are shared with other versions of the media title (e.g., a base or default version of the media title). A request for a given version of the media title includes a range of data to be retrieved from video or other content for the version. This range can be specified in byte (or other data unit) offsets and/or time offsets within the video for the media title. When the requested version is stored across multiple files and/or non-contiguous segments, a file extent index for the version is used to retrieve the range of data in the request. The file extent index maps identifiers for files that store content for the version to ranges (e.g., specified in byte and/or time offsets) of data spanned by the content. The ordering of mappings between identifiers and the corresponding ranges of data in the file extent index additionally reflects the order in which video content should be retrieved for start-to-end playback of the version of the media title. To process the request, mappings in the file extent index and/or one or more segment indexes are used to convert one or more offsets that delineate the range of data to be retrieved into one or more corresponding offsets within files identified in the file extent index, and data that spans the range denoted by the corresponding offset(s) is retrieved from the corresponding files. The retrieved data is then returned in a response to the request for playback of the corresponding version of the media title on the client device from which the request was received.</p><p id="p-0095" num="0097">One technical advantage of the disclosed techniques relative to the prior art is that, with the disclosed techniques, duplication of video content across multiple versions of a media title is reduced. In that regard, the disclosed techniques enable a single copy of video content that is common to all versions of a given film to be stored, instead of replicating identical video content across multiple files. Thus, with the disclosed techniques, fewer computational and storage resources are consumed when encoding and storing multiple versions of a media title for streaming. Another technical advantage of the disclosed techniques relative to the prior art is that the disclosed techniques allow a given version of the media title to be created or modified in an efficient, modular manner, unlike prior art approaches that encode and package a given version of a media title from beginning to end. These technical advantages provide one or more technological advancements over prior art approaches.</p><p id="p-0096" num="0098">1. In some embodiments, a computer-implemented method for accessing a media title for playback comprises receiving from a client device a first request for a first range of data included in a first encoded version of the media title, wherein the first encoded version of the media title is stored across a first set of files, determining, based on a first file extent index, one or more files that are included in the first set of files and from which the first range of data is to be accessed, wherein, for each file included in the first set of files, the first file extent index maps an identifier for the file to a given range of data that is both stored in the file and is included in the first encoded version of the media title, retrieving the first range of data from the one or more files, wherein at least a portion of the first range of data retrieved from each of the one or more files falls within the given range of data that is stored in the file, and transmitting the first range of data to the client device in a response to the first request.</p><p id="p-0097" num="0099">2. The computer-implemented method of clause 1, further comprising receiving a second request for a second range of data that begins at a first time offset in the first encoded version of the media title, and retrieving the second range of data based on the first file extent index and a first segment index for a first file included in the first set of files, wherein the first segment index maps one or more time offsets in the first encoded version to one or more offsets in the first file.</p><p id="p-0098" num="0100">3. The computer-implemented method of clauses 1 or 2, wherein retrieving the second range of data based on the first file extent index and the first segment index comprises determining a first offset in the first file to which the first time offset is mapped in the first segment index, and retrieving, from the first file, at least a portion of the second range of data beginning at the first offset.</p><p id="p-0099" num="0101">4. The computer-implemented method of any of clauses 1-3, wherein retrieving the second range of data based on the first file extent index and the first segment index comprises determining, based on the first file extent index, that the second range of data begins in the first file and ends in a second file, retrieving, from the first file, a first portion of the second range of data beginning at a first offset to which the first time offset is mapped in the first segment index and ending at a second offset to which a first identifier for the first file is mapped in the first file extent index, and retrieving, from the second file, a second portion of the second range of data beginning at a third offset to which a second identifier for the second file is mapped in the first file extent index and ending at a fourth offset to which a second time offset delineating an end of the second range of data is mapped in a second segment index for the second file.</p><p id="p-0100" num="0102">5. The computer-implemented method of any of clauses 1-4, further comprising receiving a second request for a second range of data included in a second encoded version of the media title, wherein the second encoded version of the media title is stored across a second set of files that overlaps with the first set of files, determining, based on a second file extent index, one or more additional files that are included in the second set of files and from which the second range of data is to be accessed, wherein, for each additional file included in the second set of files, the second file extent index maps an identifier for the additional file to a given range of data that is both stored in the additional file and is included in the second encoded version of the media title, and retrieving the second range of data from the one or more additional files, wherein at least a portion of the second range of data retrieved from each of the one or more additional files falls within the given range of data that is stored in the additional file.</p><p id="p-0101" num="0103">6. The computer-implemented method of any of clauses 1-5, wherein retrieving the first range of data from the one or more files comprises converting a starting offset in the first range of data into a first offset in a first file included in the first set of files, and retrieving a first portion of the first range of data from the first file, wherein the first portion begins at the first offset in the first file.</p><p id="p-0102" num="0104">7. The computer-implemented method of any of clauses 1-6, wherein retrieving the first range of data from the one or more files further comprises retrieving a second portion of the first range of data from a second file, wherein the second portion ends at a second offset in the second file that corresponds to an end of the first range of data.</p><p id="p-0103" num="0105">8. The computer-implemented method of any of clauses 1-7, wherein converting the starting offset in the first range of data into the first offset in the first file comprises identifying the first file based on the starting offset and a number of bytes spanned by one or more ranges of data included in the first file extent index, and calculating the first offset based on a difference between the starting offset and the number of bytes spanned by the one or more ranges of data.</p><p id="p-0104" num="0106">9. The computer-implemented method of any of clauses 1-8, wherein the first set of files includes a first file that includes a first portion of the media title in a first language and a second file that includes the first portion of the media title in a second language.</p><p id="p-0105" num="0107">10. The computer-implemented method of any of clauses 1-9, wherein the first file extent index includes a length of the first encoded version of the media title.</p><p id="p-0106" num="0108">11. In some embodiments, a non-transitory computer readable medium stores instructions that, when executed by a processor, cause the processor to perform the steps of receiving from a client device a first request for a first range of data included in a first encoded version of a media title, wherein the first encoded version of the media title is stored across a first set of files, determining, based on a first file extent index and one or more file mappings between one or more file identifiers and one or more file locations, one or more files that are included in the first set of files and from which the first range of data is to be accessed, wherein, for each file included in the first set of files, the first file extent index maps an identifier for the file to a given range of data that is both stored in the file and is included in the first encoded version of the media title, retrieving the first range of data from the one or more files, wherein at least a portion of the first range of data retrieved from each of the one or more files falls within the given range of data that is stored in the file, and transmitting the first range of data to the client device in a response to the first request.</p><p id="p-0107" num="0109">12. The non-transitory computer readable medium of clause 11, wherein the instructions further cause the processor to perform the steps of receiving a second request for a second range of data that begins at a first time offset in the first encoded version of the media title, and retrieving the second range of data based on the first file extent index and a first segment index for a first file included in the first set of files, wherein the first segment index maps one or more time offsets in the first encoded version to one or more offsets in the first file.</p><p id="p-0108" num="0110">13. The non-transitory computer readable medium of clauses 11 or 12, wherein retrieving the second range of data based on the first file extent index and the first segment index comprises determining a first offset in the first file to which the first time offset is mapped in the first segment index, and retrieving, from the first file, at least a portion of the second range of data beginning at the first offset.</p><p id="p-0109" num="0111">14. The non-transitory computer readable medium of any of clauses 11-13, wherein the first file includes a first segment from which the at least a portion of the second range of data is retrieved and a second segment that stores content included in a second encoded version of the media title.</p><p id="p-0110" num="0112">15. The non-transitory computer readable medium of any of clauses 11-14, wherein the instructions further cause the processor to perform the steps of receiving a second request for a second range of data included in a second encoded version of the media title, and retrieving the second range of data from one or more additional files included in a second set of files based on a second file extent index for the second encoded version of the media title, wherein the second set of files overlaps with the first set of files.</p><p id="p-0111" num="0113">16. The non-transitory computer readable medium of any of clauses 11-15, wherein retrieving the first range of data from the one or more files comprises converting a starting offset in the first range of data into a first offset in a first file included in the first set of files, retrieving a first portion of the first range of data from the first file, wherein the first portion begins at the first offset in the first file, and retrieving a second portion of the first range of data from a second file that follows the first file in the first file extent index.</p><p id="p-0112" num="0114">17. The non-transitory computer readable medium of any of clauses 11-16, wherein converting the starting offset in the first range of data into the first offset in the first file comprises determining the first file based on a number of bytes spanned by one or more ranges of data included in the first file extent index, and calculating the first offset based on a difference between the starting offset and the number of bytes spanned by the one or more ranges of data.</p><p id="p-0113" num="0115">18. The non-transitory computer readable medium of any of clauses 11-17, wherein the given range of data is specified in one or more byte offsets within the first file extent index.</p><p id="p-0114" num="0116">19. The non-transitory computer readable medium of any of clauses 11-18, wherein the first file extent index includes at least one of a length of the first encoded version of the media title, a modification time of the first encoded version of the media title, or a file extension.</p><p id="p-0115" num="0117">20. In some embodiments, a computer-implemented method for retrieving a media title for playback comprises transmitting to a server machine a first request for a first range of data included in a first encoded version of the media title, wherein the first encoded version of the media title is stored across a first set of files, the first range of data resides in one or more files included in the first set of files, and, for each file included in the first set of files, a first file extent index maps an identifier for the file to a given range of data stored in the file, receiving the first range of data from the server machine in response to the first request, and causing media content corresponding to the first range of data to be output for playback.</p><p id="p-0116" num="0118">21. The computer-implemented method of clause 20, further comprising transmitting to the server machine a second request for a second range of data that begins at a first time offset in the first encoded version of the media title, wherein the first time offset is mapped to a first offset in a first file within a first segment index for the first file, and receiving the second range of data from the server machine in response to the second request.</p><p id="p-0117" num="0119">22. The computer-implemented method of clauses 20 or 21, wherein at least a portion of the second range of data is retrieved from the first file beginning at the first offset.</p><p id="p-0118" num="0120">23. The computer-implemented method of any of clauses 20-22, further comprising transmitting to the server machine a second request for a second range of data included in a second encoded version of the media title, wherein the second encoded version of the media title is stored across a second set of files that overlaps with the first set of files, the second range of data resides in one or more additional files included in the second set of files, and, for each additional file included in the second set of files, a second file extent index maps an identifier for the additional file to a given range of data stored in the additional file, and receiving the second range of data from the server machine in response to the second request.</p><p id="p-0119" num="0121">24. The computer-implemented method of any of clauses 20-23, wherein at least a portion of the first range of data is retrieved from a first file included in the first set of files beginning at a first offset corresponding to a starting offset in the first range of data.</p><p id="p-0120" num="0122">25. The computer-implemented method of any of clauses 20-24, wherein the first set of files includes a first file that includes an original version of a portion of the media title and a second file that includes an alternative version of the portion of the media title.</p><p id="p-0121" num="0123">26. The computer-implemented method of any of clauses 20-25, wherein the alternative version comprises at least one of an edit to the original version, a regional version of the portion, or a version that meets criteria for a content rating.</p><p id="p-0122" num="0124">Any and all combinations of any of the claim elements recited in any of the claims and/or any elements described in this application, in any fashion, fall within the contemplated scope of the present invention and protection.</p><p id="p-0123" num="0125">The descriptions of the various embodiments have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments.</p><p id="p-0124" num="0126">Aspects of the present embodiments may be embodied as a system, method or computer program product. Accordingly, aspects of the present disclosure may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a &#x201c;module,&#x201d; a &#x201c;system,&#x201d; or a &#x201c;computer.&#x201d; In addition, any hardware and/or software technique, process, function, component, engine, module, or system described in the present disclosure may be implemented as a circuit or set of circuits. Furthermore, aspects of the present disclosure may take the form of a computer program product embodied in one or more computer readable medium(s) having computer readable program code embodied thereon.</p><p id="p-0125" num="0127">Any combination of one or more computer readable medium(s) may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples (a non-exhaustive list) of the computer readable storage medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing. In the context of this document, a computer readable storage medium may be any tangible medium that can contain, or store a program for use by or in connection with an instruction execution system, apparatus, or device.</p><p id="p-0126" num="0128">Aspects of the present disclosure are described above with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems) and computer program products according to embodiments of the disclosure. It will be understood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine. The instructions, when executed via the processor of the computer or other programmable data processing apparatus, enable the implementation of the functions/acts specified in the flowchart and/or block diagram block or blocks. Such processors may be, without limitation, general purpose processors, special-purpose processors, application-specific processors, or field-programmable gate arrays.</p><p id="p-0127" num="0129">The flowchart and block diagrams in the figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present disclosure. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.</p><p id="p-0128" num="0130">While the preceding is directed to embodiments of the present disclosure, other and further embodiments of the disclosure may be devised without departing from the basic scope thereof, and the scope thereof is determined by the claims that follow.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computer-implemented method for accessing a media title for playback, the method comprising:<claim-text>receiving from a client device a first request for a first range of data included in a first encoded version of the media title;</claim-text><claim-text>determining, based on a first file extent index, one or more files from which the first range of data is to be accessed, wherein, for each file included in the one or more files, the first file extent index maps an identifier for the file to a given range of data that is stored in the file;</claim-text><claim-text>retrieving the first range of data from the one or more files; and</claim-text><claim-text>transmitting the first range of data to the client device in a response to the first request.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first encoded version of the media title is stored across a first set of files that includes the one or more files.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computer-implemented method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:<claim-text>receiving a second request for a second range of data that begins at a first time offset in the first encoded version of the media title; and</claim-text><claim-text>retrieving the second range of data based on the first file extent index and a first segment index for a first file included in the first set of files.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computer-implemented method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the first segment index maps one or more time offsets in the first encoded version to one or more offsets in the first file.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computer-implemented method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein retrieving the second range of data based on the first file extent index and the first segment index comprises:<claim-text>determining a first offset in the first file to which the first time offset is mapped in the first segment index; and</claim-text><claim-text>retrieving, from the first file, at least a portion of the second range of data beginning at the first offset.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein, the given range of data that is stored in each file included in the one or more files also is included in the first encoded version of the media title.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least a portion of the first range of data retrieved from each filed included in the one or more files falls within the given range of data that is stored in the file.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein retrieving the first range of data from the one or more files comprises:<claim-text>converting a starting offset in the first range of data into a first offset in a first file included in the one or more files; and</claim-text><claim-text>retrieving a first portion of the first range of data from the first file, wherein the first portion begins at the first offset in the first file.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computer-implemented method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein retrieving the first range of data from the one or more files further comprises retrieving a second portion of the first range of data from a second file included in the one or more files, wherein the second portion ends at a second offset in the second file that corresponds to an end of the first range of data.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computer-implemented method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein converting the starting offset in the first range of data into the first offset in the first file comprises:<claim-text>identifying the first file based on the starting offset and a number of bytes spanned by one or more ranges of data included in the first file extent index; and</claim-text><claim-text>calculating the first offset based on a difference between the starting offset and the number of bytes spanned by the one or more ranges of data.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The computer-implemented method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first set of files includes a first file that has a first portion of the media title in a first language and a second file that includes the first portion of the media title in a second language.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. One or more non-transitory computer readable media storing instructions that, when executed by one or more processors, cause the one or more processors to perform the operations of:<claim-text>receiving from a client device a first request for a first range of data included in a first encoded version of the media title;</claim-text><claim-text>determining, based on a first file extent index, one or more files from which the first range of data is to be accessed, wherein, for each file included in the one or more files, the first file extent index maps an identifier for the file to a given range of data that is stored in the file;</claim-text><claim-text>retrieving the first range of data from the one or more files; and</claim-text><claim-text>transmitting the first range of data to the client device in a response to the first request.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The one or more non-transitory computer readable media of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the first encoded version of the media title is stored across a first set of files that includes the one or more files.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The one or more non-transitory computer readable media of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising:<claim-text>receiving a second request for a second range of data that begins at a first time offset in the first encoded version of the media title; and</claim-text><claim-text>retrieving the second range of data based on the first file extent index and a first segment index for a first file included in the first set of files.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The one or more non-transitory computer readable media of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the first segment index maps one or more time offsets in the first encoded version to one or more offsets in the first file.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The one or more non-transitory computer readable media of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein retrieving the second range of data based on the first file extent index and the first segment index comprises:<claim-text>determining a first offset in the first file to which the first time offset is mapped in the first segment index; and</claim-text><claim-text>retrieving, from the first file, at least a portion of the second range of data beginning at the first offset.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The one or more non-transitory computer readable media of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein, the given range of data that is stored in each file included in the one or more files also is included in the first encoded version of the media title.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The one or more non-transitory computer readable media of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein at least a portion of the first range of data retrieved from each filed included in the one or more files falls within the given range of data that is stored in the file.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer readable medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein retrieving the first range of data from the one or more files comprises:<claim-text>converting a starting offset in the first range of data into a first offset in a first file included in the first set of files;</claim-text><claim-text>retrieving a first portion of the first range of data from the first file, wherein the first portion begins at the first offset in the first file; and</claim-text><claim-text>retrieving a second portion of the first range of data from a second file that follows the first file in the first file extent index.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The one or more non-transitory computer readable media of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein retrieving the first range of data from the one or more files further comprises retrieving a second portion of the first range of data from a second file included in the one or more files, wherein the second portion ends at a second offset in the second file that corresponds to an end of the first range of data.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The one or more non-transitory computer readable media of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein converting the starting offset in the first range of data into the first offset in the first file comprises:<claim-text>identifying the first file based on the starting offset and a number of bytes spanned by one or more ranges of data included in the first file extent index; and</claim-text><claim-text>calculating the first offset based on a difference between the starting offset and the number of bytes spanned by the one or more ranges of data.</claim-text></claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. A system, comprising:<claim-text>one or more memories that include instructions; and</claim-text><claim-text>one or more processors that are coupled to the one or more memories and, when executing the instructions, are configured to perform the operations of:<claim-text>receiving from a client device a first request for a first range of data included in a first encoded version of the media title,</claim-text><claim-text>determining, based on a first file extent index, one or more files from which the first range of data is to be accessed,</claim-text><claim-text>retrieving the first range of data from the one or more files, and</claim-text><claim-text>transmitting the first range of data to the client device in a response to the first request.</claim-text></claim-text></claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The system of <claim-ref idref="CLM-00022">claim 22</claim-ref>, wherein, for each file included in the one or more files, the first file extent index maps an identifier for the file to a given range of data that is stored in the file.</claim-text></claim></claims></us-patent-application>
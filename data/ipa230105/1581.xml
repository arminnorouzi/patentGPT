<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001582A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001582</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17931759</doc-number><date>20220913</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-047852</doc-number><date>20200318</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>16</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>1664</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>1653</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>25</class><subclass>J</subclass><main-group>9</main-group><subgroup>1679</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">CONTROL DEVICE, INSPECTION SYSTEM, CONTROL METHOD, AND STORAGE MEDIUM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/005498</doc-number><date>20210215</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17931759</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>KABUSHIKI KAISHA TOSHIBA</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TAKAHASHI</last-name><first-name>Hiromasa</first-name><address><city>Minato</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>SAITO</last-name><first-name>Masahiro</first-name><address><city>Yokohama</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>CHIBA</last-name><first-name>Yasunori</first-name><address><city>Yokohama</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>KABUSHIKI KAISHA TOSHIBA</orgname><role>03</role><address><city>Tokyo</city><country>JP</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A control device according to an embodiment receives first posture data of a posture of a first robot. The first robot includes a first manipulator and a first end effector. Furthermore, the control device sets the posture of the first robot based on the first posture data and causes the first robot to perform a first task on a first member. The first posture data is generated based on second posture data. The second posture data is of a posture when a second robot that includes a second manipulator and a second end effector performs a second task on the first member.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="218.69mm" wi="149.10mm" file="US20230001582A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="216.24mm" wi="158.75mm" file="US20230001582A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="212.09mm" wi="139.62mm" file="US20230001582A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="178.39mm" wi="163.49mm" file="US20230001582A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="247.73mm" wi="155.53mm" file="US20230001582A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="258.15mm" wi="158.50mm" orientation="landscape" file="US20230001582A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="232.92mm" wi="123.44mm" file="US20230001582A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="166.37mm" wi="145.71mm" file="US20230001582A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="195.41mm" wi="159.60mm" file="US20230001582A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="242.40mm" wi="151.13mm" file="US20230001582A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="128.10mm" wi="144.61mm" file="US20230001582A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="211.92mm" wi="91.95mm" file="US20230001582A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="222.25mm" wi="128.44mm" file="US20230001582A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="124.04mm" wi="147.40mm" file="US20230001582A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This is a continuation application of International Patent Application PCT/JP2021/005498, filed on Feb. 15, 2021. This application also claims the benefit of priority from Japanese Patent Application No. 2020-047852, filed on Mar. 18, 2020; the entire contents of which are incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">FIELD</heading><p id="p-0003" num="0002">Embodiments described herein relate generally to a control device, an inspection system, a control method, a and a storage medium.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">Various industrial robots are used in a production site. The posture in a task is taught to a robot before the robot is applied to a production line. It is desirable to reduce the time necessary for the teaching.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic view illustrating a production system to which a robot system according to an embodiment is applied;</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a perspective view illustrating a first robot;</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic view illustrating a second robot;</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> are schematic views illustrating operations of a production system according to the embodiment;</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref> are an example of data stored in a memory device;</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIGS. <b>6</b>A and <b>6</b>B</figref> are flowcharts illustrating processing of the production system according to the embodiment;</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a perspective view illustrating the internal structure of a detector tip;</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIGS. <b>8</b>A to <b>8</b>C</figref> are schematic views for describing an inspection method;</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating a specific example of a first task;</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a drawing for describing a calculation method of the tilt of the detector;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is an example of an image of detected information;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. <b>12</b>A to <b>12</b>C</figref> are examples of images of the detected information; and</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a drawing illustrating a configuration example of a processing device and a control device.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0018" num="0017">A control device according to an embodiment receives first posture data of a posture of a first robot. The first robot includes a first manipulator and a first end effector. Furthermore, the control device sets the posture of the first robot based on the first posture data and causes the first robot to perform a first task on a first member. The first posture data is generated based on second posture data. The second posture data is of a posture when a second robot that includes a second manipulator and a second end effector performs a second task on the first member.</p><p id="p-0019" num="0018">Embodiments of the invention will now be described with reference to the drawings.</p><p id="p-0020" num="0019">The drawings are schematic or conceptual; and the relationships between the thickness and width of portions, proportions of sizes among portions, etc., are not necessarily the same as the actual values. The dimensions and proportions may be illustrated differently among drawings, even when the same portion is illustrated.</p><p id="p-0021" num="0020">In the specification and drawings, components similar to those already described are marked with the same reference numerals; and a detailed description is omitted as appropriate.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic view illustrating a production system to which a robot system according to an embodiment is applied.</p><p id="p-0023" num="0022">The robot system <b>100</b> according to the embodiment includes a first robot <b>110</b>, a control device <b>120</b>, and a processing device <b>130</b>. The production system <b>300</b> includes the robot system <b>100</b> and a robot system <b>200</b>. The robot system <b>200</b> includes a second robot <b>210</b>, a control device <b>220</b>, and a processing device <b>230</b>. In the example, the production system <b>300</b> further includes a memory device <b>310</b>, a teaching device <b>320</b>, and a memory device <b>330</b>.</p><p id="p-0024" num="0023">The first robot <b>110</b> includes a first manipulator <b>111</b> and a first end effector <b>112</b>. For example, the first end effector <b>112</b> is mounted to the distal part of the first manipulator <b>111</b>. The first manipulator <b>111</b> is, for example, vertical articulated, horizontal articulated, or parallel link. The first manipulator <b>111</b> may be a combination of at least two manipulators selected from vertical articulated, horizontal articulated, and parallel link. The first robot <b>110</b> performs a first task corresponding to a function of the first end effector <b>112</b>.</p><p id="p-0025" num="0024">The control device <b>120</b> controls the first robot <b>110</b> by transmitting a command to the first robot <b>110</b>. For example, the control device <b>120</b> controls the posture of the first robot <b>110</b> by operating a driver included in the first manipulator <b>111</b>. Or, the control device <b>120</b> causes the first robot <b>110</b> to perform a first task by operating the first end effector <b>112</b>.</p><p id="p-0026" num="0025">Here, posture refers to the position and orientation corresponding to degrees of freedom of the robot. For example, the posture of a robot having six degrees of freedom is represented by the positions in three mutually-orthogonal directions (an X-direction, a Y-direction, and a Z-direction) and the angles (rolling, pitting, and yawing) around the directions.</p><p id="p-0027" num="0026">The processing device <b>130</b> transmits data used in the control of the first robot <b>110</b> to the control device <b>120</b>. Or, the processing device <b>130</b> receives data based on information acquired by the first robot <b>110</b> from the control device <b>120</b>. The processing device <b>130</b> processes various data as appropriate.</p><p id="p-0028" num="0027">The second robot <b>210</b> includes a second manipulator <b>211</b> and a second end effector <b>212</b>. For example, the second end effector <b>212</b> is mounted to the distal part of the second manipulator <b>211</b>. The second manipulator <b>211</b> is, for example, vertical articulated, horizontal articulated, or parallel link. The second manipulator <b>211</b> may be a combination of at least two manipulators selected from vertical articulated, horizontal articulated, and parallel link.</p><p id="p-0029" num="0028">The second robot <b>210</b> performs a second task corresponding to a function of the second end effector <b>212</b>. The function of the second end effector <b>212</b> is different from the function of the first end effector <b>112</b>. Therefore, the second task that is performed by the second robot <b>210</b> is different from the first task.</p><p id="p-0030" num="0029">The control device <b>220</b> controls the second robot <b>210</b> by transmitting a command to the second robot <b>210</b>. For example, the control device <b>220</b> controls the posture of the second robot <b>210</b> by operating a driver included in the second manipulator <b>211</b>. Or, the control device <b>220</b> operates the second end effector <b>212</b> to cause the second robot <b>210</b> to perform the first task.</p><p id="p-0031" num="0030">The processing device <b>230</b> transmits data used in the control of the second robot <b>210</b> to the control device <b>220</b>. Or, the processing device <b>230</b> receives data acquired by the second robot <b>210</b> from the control device <b>220</b>. The processing device <b>230</b> processes various data as appropriate.</p><p id="p-0032" num="0031">The memory device <b>310</b> stores data related to the robot systems <b>100</b> and <b>200</b>. For example, the processing device <b>130</b> accesses the memory device <b>310</b> and acquires data related to the first task, data of the member that is the object of the first task, etc. Similarly, the processing device <b>230</b> accesses the memory device <b>310</b> and acquires data related to the second task, data of the member that is the object of the second task, etc. The processing device <b>130</b> stores data related to the first robot <b>110</b> and the first task transmitted from the control device <b>120</b> in the memory device <b>310</b>. The processing device <b>230</b> stores data related to the second robot <b>210</b> and the second task transmitted from the control device <b>220</b> in the memory device <b>310</b>.</p><p id="p-0033" num="0032">The first robot <b>110</b> and the second robot <b>210</b> respectively perform the first task and the second task on the same member. For example, the second robot <b>210</b> performs the second task on a first member. Subsequently, the first robot <b>110</b> performs the first task on the same first member.</p><p id="p-0034" num="0033">The memory device <b>330</b> stores design data related to the first member. The design data includes, for example, computer-aided design (CAD) data. For example, the teaching device <b>320</b> generates the operation program of the second robot <b>210</b> by referring to the design data. The teaching device <b>320</b> performs a confirmation of the robot operation, a confirmation of interference, etc., by causing the generated operation program to operate in a simulator.</p><p id="p-0035" num="0034">The operation program includes data related to the posture of the second robot <b>210</b>. The data shows the posture of a control point of the second robot <b>210</b> when the second robot <b>210</b> performs the second task. Hereinafter, the data of the posture of the control point of the second robot <b>210</b> generated based on the design data is called the design posture data. The teaching device <b>320</b> stores the generated design posture data in the memory device <b>310</b>.</p><p id="p-0036" num="0035">When the second robot <b>210</b> performs the second task, the processing device <b>230</b> accesses the memory device <b>310</b> and acquires second posture data of the posture of the second robot <b>210</b>. For example, the design posture data is used as the second posture data. Or, the second posture data may be data of a posture taught using the second robot <b>210</b>.</p><p id="p-0037" num="0036">For example, in a workplace in which the second task is actually performed, a worker verifies whether or not problems occur in the workplace when the posture of the second robot <b>210</b> is set based on the design posture data. Specifically, it is confirmed whether or not there is a possibility that the second robot <b>210</b> may interfere with an article of the workplace or contact a worker when the posture of the second robot <b>210</b> is set based on the design posture data. When a problem may occur, the worker uses the second robot <b>210</b> to teach the posture of the second robot <b>210</b> to eliminate the problem. In such a case, the posture that is taught is stored in the memory device <b>310</b> as the second posture data.</p><p id="p-0038" num="0037">The processing device <b>130</b> acquires the second posture data and generates first posture data. The first posture data is of the posture when the first robot <b>110</b> performs the first task. The processing device <b>130</b> stores the first posture data that is generated in the memory device <b>310</b>. Or, the processing device <b>130</b> transmits the first posture data that is generated to the control device <b>120</b>. The control device <b>120</b> sets the posture of the first robot <b>110</b> based on the first posture data and causes the first robot <b>110</b> to perform the first task.</p><p id="p-0039" num="0038">The generation of the first posture data may be performed by the processing device <b>230</b>. In such a case, the first posture data that is generated is stored in the memory device <b>310</b> or transmitted to the processing device <b>130</b> by the processing device <b>230</b>.</p><p id="p-0040" num="0039">When the first task and the second task are performed on multiple spots of one first member, multiple sets of first posture data and multiple sets of second posture data that correspond to the multiple spots are prepared. The multiple sets of first posture data are generated respectively based on the multiple sets of second posture data. At least a portion of the multiple sets of second posture data is generated based on the design posture data. Other than using the design posture data, at least a portion of the multiple sets of second posture data may be generated based on actual teaching. For example, a portion of the multiple sets of second posture data is generated based on the design posture data; and another portion of the multiple sets of second posture data is generated based on actual teaching.</p><p id="p-0041" num="0040">The components of the production system <b>300</b> are connected to each other via wired communication, wireless communication, or a network.</p><p id="p-0042" num="0041">Effects of the embodiment will now be described.</p><p id="p-0043" num="0042">In the robot system <b>100</b> according to the embodiment, the control device <b>120</b> receives the first posture data. Then, the control device <b>120</b> sets the posture of the first robot <b>110</b> based on the first posture data and causes the first robot <b>110</b> to perform the first task. The first posture data is automatically generated by the processing device <b>130</b> or <b>230</b> based on the second posture data of the posture when the second robot <b>210</b> performs the second task. It is therefore unnecessary for a human to teach the posture when the first robot <b>110</b> performs the first task. According to the control device <b>120</b>, the time necessary for the human to teach the first robot <b>110</b> can be reduced.</p><p id="p-0044" num="0043">For example, in a production site, one product is produced by passing through multiple processes. In a production line that uses robots, different types of robots are used in each process. According to the production line, there are cases where one robot in one process performs a task on a specific spot of one member, and then another robot in another process performs a task on the same spot of the same member. By applying the invention according to the embodiment to such a production line, it is unnecessary to teach the posture in the task of the other robot. For example, the time necessary for teaching can be reduced, and the operation of the production line can be faster.</p><p id="p-0045" num="0044">As a reference example, there is a method in which the first posture data is generated based on the design data. For example, the teaching device <b>320</b> generates the operation program of the first robot <b>110</b> based on the design data. This method is effective when the second posture data corresponds to the design posture data. By using the first posture data based on the design data, the other robot can perform the task on the same spot as the task performed by the one robot.</p><p id="p-0046" num="0045">However, in practice, as described above, there are also cases where the design posture data is not employed, and the posture is taught in the workplace. In such a case, when the first posture data is generated based on the design posture data, the other robot cannot perform the task on the same spot as the task performed by the one robot. It is therefore favorable to generate the first posture data based on the second posture data. According to the embodiment, even when second posture data that is different from the design posture data is used, the other robot can perform the task on the same spot as the task performed by the one robot.</p><p id="p-0047" num="0046">Specific examples of the embodiment will now be described.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a perspective view illustrating the first robot. <figref idref="DRAWINGS">FIG. <b>3</b></figref> is a schematic view illustrating the second robot.</p><p id="p-0049" num="0048">Here, a case is described where the first manipulator <b>111</b> and the second manipulator <b>211</b> are vertical articulated with six degrees of freedom.</p><p id="p-0050" num="0049">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the first manipulator <b>111</b> includes six joints J<b>1</b><i>a </i>to J<b>1</b><i>f </i>and six links L<b>1</b><i>a </i>to L<b>1</b><i>f </i>that are alternately linked. The joints J<b>1</b><i>a </i>to J<b>1</b><i>f </i>are driven by not-illustrated drivers. The control device <b>120</b> drives the joints J<b>1</b><i>a </i>to J<b>1</b><i>f, </i>thereby adjusting the posture of the control point of the first robot <b>110</b>.</p><p id="p-0051" num="0050">As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the second manipulator <b>211</b> includes six joints J<b>2</b><i>a </i>to J<b>2</b><i>f </i>and the six links L<b>2</b><i>a </i>to L<b>2</b><i>f </i>that are alternately linked. The joints J<b>2</b><i>a </i>to J<b>2</b><i>f </i>are driven by not-illustrated drivers. The control device <b>220</b> drives the joints J<b>2</b><i>a </i>to J<b>2</b><i>f, </i>thereby adjusting the posture of the control point of the second robot <b>210</b>.</p><p id="p-0052" num="0051">The control point is the point of which the posture is controlled by the control device <b>120</b> or <b>220</b>. For example, the control point is set to any one point of the end effectors. When a workpiece or tool is held by the end effector, the control point may be set to any one point of the workpiece or tool. Hereinafter, &#x201c;the posture of the control point of the first robot <b>110</b>&#x201d; also is called simply &#x201c;the posture of the first robot <b>110</b>&#x201d;. Similarly, &#x201c;the posture of the control point of the second robot <b>210</b>&#x201d; also is called &#x201c;the posture of the second robot <b>210</b>&#x201d;.</p><p id="p-0053" num="0052">As one specific example, the first end effector <b>112</b> includes a detector <b>112</b><i>a </i>and a coating device <b>112</b><i>b </i>as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. The second end effector <b>212</b> includes a welding device. As illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the welding device includes a welding gun <b>212</b><i>a, </i>an upper electrode <b>212</b><i>b, </i>a raising/lowering part <b>212</b><i>c, </i>a lower electrode <b>212</b><i>d, </i>and a current supply part <b>212</b><i>e. </i></p><p id="p-0054" num="0053">The second end effector <b>212</b> performs spot welding on the first member. In other words, the second task is spot welding. The first end effector <b>112</b> transmits an ultrasonic wave toward the spot-welded weld portion and detects a reflected wave of the ultrasonic wave. In other words, the first task acquires information related to the weld portion.</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIGS. <b>4</b>A and <b>4</b>B</figref> are schematic views illustrating operations of the production system according to the embodiment.</p><p id="p-0056" num="0055">For example, the first task and the second task are performed on a first member <b>10</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref> by the robot systems <b>100</b> and <b>200</b>. The first member <b>10</b> includes steel plates <b>11</b> and <b>12</b>.</p><p id="p-0057" num="0056">For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>A</figref>, a transfer device T transfers the first member <b>10</b> to a position at which the second robot <b>210</b> is installed. The transfer device T stops at a preset position related to the second task. The second robot <b>210</b> performs spot welding of a first part P<b>1</b> and a second part P<b>2</b> of the first member <b>10</b>. Specifically, the second manipulator <b>211</b> operates so that the first part P<b>1</b> or the second part P<b>2</b> is positioned between the upper electrode <b>212</b><i>b </i>and the lower electrode <b>212</b><i>d. </i>The raising/lowering part <b>212</b><i>c </i>operates and moves the upper electrode <b>212</b><i>b </i>toward the lower electrode <b>212</b><i>d</i>. The first member <b>10</b> is clamped by the upper electrode <b>212</b><i>b </i>and the lower electrode <b>212</b><i>d. </i>The current supply part <b>212</b><i>e </i>intermittently supplies a current between the upper electrode <b>212</b><i>b </i>and the lower electrode <b>212</b><i>d. </i>The steel plates <b>11</b> and <b>12</b> are partially melted, mixed, and joined.</p><p id="p-0058" num="0057">The posture when the second robot <b>210</b> performs the spot welding is set based on the second posture data. For example, the second posture data includes the coordinates (P<sub>X2</sub>, P<sub>Y2</sub>, and P<sub>Z2</sub>) of the part at which the second robot <b>210</b> spot-welds and the angles (&#x3b1;<sub>J2a</sub>, &#x3b1;<sub>J2b</sub>, &#x3b1;<sub>J2c</sub>, &#x3b1;<sub>J2d</sub>, &#x3b1;<sub>J2e</sub>, and &#x3b1;<sub>J2f</sub>) of the joints J<b>2</b><i>a </i>to J<b>2</b><i>f</i>. When spot-welding the first part P<b>1</b>, the control device <b>220</b> refers to the second posture data of the posture when spot-welding the first part P<b>1</b>. When spot-welding the second part P<b>2</b>, the control device <b>220</b> refers to the second posture data of the posture when spot-welding the second part P<b>2</b>. For each spot weld, the control device <b>220</b> sets the posture of the second robot <b>210</b> based on the second posture data that is referred to.</p><p id="p-0059" num="0058">When the spot welding is completed, the transfer device T transfers the first member <b>10</b> to the position at which the first robot <b>110</b> is installed. The transfer device T stops at a position preset for the first task. As illustrated in <figref idref="DRAWINGS">FIG. <b>4</b>B</figref>, the first robot <b>110</b> acquires information related to the first and second parts P<b>1</b> and P<b>2</b> of the first member <b>10</b>. Specifically, the first manipulator <b>111</b> operates so that the coating device <b>112</b><i>b </i>faces the first part P<b>1</b>. The coating device <b>112</b><i>b </i>coats a couplant onto the first part P<b>1</b>. Then, the first manipulator <b>111</b> operates so that the tip of the detector <b>112</b><i>a </i>contacts the first part P<b>1</b>. The detector <b>112</b><i>a </i>transmits an ultrasonic wave that detects a reflected wave of the ultrasonic wave. For example, three-dimensional data of the intensity distribution of the reflected wave is acquired. The state of the first part P<b>1</b> is reflected in the data. The first robot <b>110</b> performs a similar operation on the second part P<b>2</b> as well.</p><p id="p-0060" num="0059">The posture when the first robot <b>110</b> acquires the data is set based on the first posture data. Similarly to the second posture data, the first posture data includes the coordinates (P<sub>X1</sub>, P<sub>Y1</sub>, and P<sub>Z1</sub>) of the part for which the first robot <b>110</b> acquires the data and the angles (&#x3b1;<sub>J1a</sub>, &#x3b1;<sub>J1b</sub>, &#x3b1;<sub>J1c</sub>, &#x3b1;<sub>J1d</sub>, &#x3b1;<sub>J1e</sub>, and &#x3b1;<sub>J1f</sub>) of the joints J<b>1</b><i>a </i>to J<b>1</b><i>f. </i></p><p id="p-0061" num="0060">When the first end effector <b>112</b> includes multiple devices, the first posture data is prepared for each of the devices. For example, when acquiring the information of the first part P<b>1</b>, the control device <b>120</b> refers to the first posture data of the posture when coating the couplant onto the first part P<b>1</b> and the first posture data of the posture when acquiring the information of the first part P<b>1</b>. This is similar when acquiring the information of the second part P<b>2</b>. When acquiring the information of the parts, the control device <b>120</b> sets the posture of the first robot <b>110</b> based on the first posture data that is referred to.</p><p id="p-0062" num="0061">The first posture data is generated using the second posture data. For example, the first posture data is generated by the processing device <b>230</b>. The processing device <b>230</b> refers to the second posture data, first structure data, and second structure data when generating the first posture data.</p><p id="p-0063" num="0062">The first structure data includes data of the structure of the first manipulator <b>111</b>. The first structure data further includes data of the relationship between the posture of the first robot <b>110</b> and the posture of the distal part of the first manipulator <b>111</b>. The data of the structure of the first manipulator <b>111</b> shows the lengths (&#x3b2;<sub>L1a</sub>, &#x3b2;<sub>L1b</sub>, &#x3b2;<sub>L1c</sub>,&#x3b2;<sub>L1d</sub>, and &#x3b2;<sub>L1e</sub>, and &#x3b2;<sub>L1f</sub>) of the links L<b>1</b><i>a </i>to L<b>1</b><i>f </i>included in the first manipulator <b>111</b>. The distal part of the first manipulator <b>111</b> corresponds to the part of the first manipulator <b>111</b> for which the posture is calculated using the angles (&#x3b1;<sub>J1a</sub>, &#x3b1;<sub>J1b</sub>, &#x3b1;<sub>J1c</sub>, &#x3b1;<sub>J1d</sub>, &#x3b1;<sub>J1e</sub>, &#x3b1;<sub>J1f</sub>) of the joints J<b>1</b><i>a </i>to J<b>1</b><i>f </i>and the lengths &#x3b2;<sub>L1a</sub>, &#x3b2;<sub>L1b</sub>, &#x3b2;<sub>L1c</sub>, <b>62</b> <sub>L1d</sub>, and &#x3b2;<sub>L1e</sub>, and &#x3b2;<sub>L1f</sub>) of the links L<b>1</b><i>a </i>to L<b>1</b><i>f. </i></p><p id="p-0064" num="0063">For example, the positional relationship is represented by the displacement of the posture of the control point of the first robot <b>110</b> with respect to the posture of the distal part of the first manipulator <b>111</b>. Specifically, the positional relationship is represented by the displacements (D<sub>X1</sub>, D<sub>Y1</sub>, and D<sub>Z1</sub>) of the positions in the X-direction, the Y-direction, and the Z-direction and the displacements (D<sub>&#x3b8;1</sub>, D<sub>&#x3a6;1</sub>, and D<sub>&#x3c8;1</sub>) of the angles around the directions.</p><p id="p-0065" num="0064">The second structure data includes data of the positional relationship between the control point of the second robot <b>210</b> and the distal part of the second manipulator <b>211</b>.</p><p id="p-0066" num="0065">The second structure data includes data of the structure of the second manipulator <b>211</b>. The second structure data further includes data of the relationship between the posture of the second robot <b>210</b> and the posture of the distal part of the second manipulator <b>211</b>. The data of the structure of the second manipulator <b>211</b> is of the lengths (&#x3b2;<sub>L2a</sub>, &#x3b2;<sub>L2b</sub>, &#x3b2;<sub>L2c</sub>,&#x3b2;<sub>L2d</sub>, and &#x3b2;<sub>L2e</sub>, and &#x3b2;<sub>L2f</sub>) of links L<b>2</b><i>a </i>to L<b>2</b><i>f </i>included in the second manipulator <b>211</b>. The distal part of the second manipulator <b>211</b> corresponds to the part of the second manipulator <b>211</b> of which the posture is calculated using the angles (&#x3b1;<sub>J2a</sub>, &#x3b1;<sub>J2b</sub>, &#x3b1;<sub>J2c</sub>, &#x3b1;<sub>J2d</sub>, &#x3b1;<sub>J2e</sub>, and &#x3b1;<sub>J2f</sub>) of the joints J<b>2</b><i>a </i>to J<b>2</b><i>f </i>and the lengths (&#x3b2;<sub>L2a</sub>, &#x3b2;<sub>L2b</sub>, &#x3b2;<sub>L2c</sub>,&#x3b2;<sub>L2d</sub>, and &#x3b2;<sub>L2e</sub>, and &#x3b2;<sub>L2f</sub>) of the links L<b>2</b><i>a </i>to L<b>2</b><i>f. </i></p><p id="p-0067" num="0066">For example, the positional relationship is represented by the displacement of the posture of the distal part of the second manipulator <b>211</b> with respect to the posture of the control point of the second robot <b>210</b>. Specifically, the positional relationship is represented by the displacements (D<sub>X2</sub>, D<sub>Y2</sub>, and D<sub>Z2</sub>) of the positions in the X-direction, the Y-direction, and the Z-direction and the displacements (D<sub>&#x3b8;2</sub>, D<sub>&#x3a6;2</sub>, and D<sub>104 2</sub>) of the angles around the directions.</p><p id="p-0068" num="0067">First, the processing device <b>230</b> uses the second posture data and the second structure data to calculate the posture of the second robot <b>210</b> when spot-welding a designated part. Then, the processing device <b>230</b> uses the first structure data and the calculated posture to calculate the posture of the distal part of the first manipulator <b>111</b> when positioning the tip of the first end effector <b>112</b> at the part to be spot-welded. The processing device <b>230</b> uses the calculated posture of the distal part of the first manipulator <b>111</b> and the lengths (&#x3b2;<sub>L1a</sub>, &#x3b2;<sub>L1b</sub>, &#x3b2;<sub>L1c</sub>,&#x3b2;<sub>L1d</sub>, and &#x3b2;<sub>L1e</sub>, and &#x3b2;<sub>L1f</sub>) of the links L<b>1</b><i>a </i>to L<b>1</b><i>f </i>to calculate the angles (&#x3b1;<sub>J1a</sub>, &#x3b1;<sub>J1b</sub>, &#x3b1;<sub>J1c</sub>, &#x3b1;<sub>J1d</sub>, &#x3b1;<sub>J1e</sub>, and &#x3b1;<sub>J1f</sub>) of the joints J<b>1</b><i>a </i>to J<b>1</b><i>f </i>by an inverse kinematics calculation. Thus, the first posture data is generated. The first posture data includes the angles of the joints J<b>1</b><i>a </i>to J<b>1</b><i>f </i>when the information of the spot-welded part is acquired. The processing device <b>230</b> stores the generated first posture data in the memory device <b>310</b>.</p><p id="p-0069" num="0068">The coordinates included in the first posture data and the coordinates included in the second posture data may be included in mutually-different coordinate systems or may be included in the same one coordinate system. A correction that corresponds to the different coordinate systems may be applied as appropriate when generating the coordinates of the second posture data based on the coordinates of the first posture data.</p><p id="p-0070" num="0069">The calculations described above may be omitted when the following conditions are satisfied. A first condition is that the lengths of the links L<b>1</b><i>a </i>to L<b>1</b><i>f </i>of the first manipulator <b>111</b> are respectively equal to the lengths of the links L<b>2</b><i>a </i>to L<b>2</b><i>f </i>of the second manipulator <b>211</b>. A second condition is that the positional relationship between the first robot <b>110</b> and the first member <b>10</b> in the first task is the same as the positional relationship between the second robot <b>210</b> and the first member <b>10</b> in the second task. A third condition is that the relationship between the posture of the first robot <b>110</b> and the posture of the distal part of the first manipulator <b>111</b> is the same as the relationship between the posture of the second robot <b>210</b> and the posture of the distal part of the second manipulator <b>211</b>. When these conditions are satisfied, the processing device <b>230</b> may generate the second posture data as-is as the first posture data and may store the first posture data in the memory device <b>310</b>.</p><p id="p-0071" num="0070">When the first end effector <b>112</b> includes multiple devices, the first structure data is prepared for each of the devices. The first structure data of each device is used to generate the first posture data when the task is performed using each device.</p><p id="p-0072" num="0071">The transfer device T includes, for example, at least one of a belt conveyor, a roller conveyor, an automated guided vehicle (AGV), or a raising/lowering device. The transfer device T may include multiple transfer mechanisms. For example, a transfer mechanism that transports the member to the position at which the first robot <b>110</b> is installed and another transfer mechanism that transports the member to the position at which the second robot <b>210</b> is installed may be included.</p><p id="p-0073" num="0072">The operation of the transfer device T may be controlled by the processing device <b>130</b> or <b>230</b> or may be controlled by another processing device. A higher-level processing device that manages the processing devices <b>130</b> and <b>230</b> may be provided, and the transfer device T may be controlled by the higher-level processing device.</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is an example of data stored in the memory device. For example, the memory device <b>310</b> stores the tables illustrated in <figref idref="DRAWINGS">FIGS. <b>5</b>A and <b>5</b>B</figref>. <figref idref="DRAWINGS">FIG. <b>5</b>A</figref> illustrates a table (a first table) including data related to the first task. <figref idref="DRAWINGS">FIG. <b>5</b>B</figref> illustrates a table (a second table) including data related to the second task.</p><p id="p-0075" num="0074">Each table includes the process ID, process name, previous process ID, member ID, member name, robot ID, robot name, coordinate, and joint angle. The coordinate indicates the coordinate of the control point of the robot when performing the process. The joint angle indicates the angles of the joints of the robot when performing the process. In the table illustrated in <figref idref="DRAWINGS">FIG. <b>5</b>A</figref>, the combination of one coordinate and one joint angle corresponds to one set of first posture data. In the table illustrated in <figref idref="DRAWINGS">FIG. <b>5</b>B</figref>, the combination of one coordinate and one joint angle corresponds to one set of second posture data.</p><p id="p-0076" num="0075">The processing device <b>230</b> refers to the first table when generating the first posture data. For each process, the processing device <b>230</b> extracts the previous process ID and refers to the second table. The processing device <b>230</b> searches for the process ID in the second table corresponding to the extracted previous process ID and extracts the second posture data associated with the process ID of the second table. The processing device <b>230</b> generates the first posture data based on the extracted second posture data. The generated first posture data is associated with the process ID corresponding to the extracted previous process ID and stored in the first table by the processing device <b>230</b>.</p><p id="p-0077" num="0076">When the first robot <b>110</b> performs the first task, the processing device <b>130</b> appropriately extracts the first posture data from the memory device <b>310</b> and transmits the first posture data to the control device <b>120</b>. The control device <b>120</b> sets the posture of the first robot <b>110</b> based on the received first posture data and causes the first task to be performed.</p><p id="p-0078" num="0077"><figref idref="DRAWINGS">FIGS. <b>6</b>A and <b>6</b>B</figref> are flowcharts illustrating processing of the production system according to the embodiment.</p><p id="p-0079" num="0078"><figref idref="DRAWINGS">FIG. <b>6</b>A</figref> illustrates processing performed before operating the production line. <figref idref="DRAWINGS">FIG. <b>6</b>B</figref> illustrates processing performed when operating the production line.</p><p id="p-0080" num="0079">As illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>A</figref>, based on the design data, the teaching device <b>320</b> generates the design posture data when the second robot <b>210</b> performs the second task (step S<b>1</b>). The second posture data is generated based on the design posture data (step S<b>2</b>). As described above, the second posture data may be generated based on the design posture data and may be generated separately from the design posture data.</p><p id="p-0081" num="0080">As illustrated in <figref idref="DRAWINGS">FIG. <b>6</b>B</figref>, the second robot <b>210</b> performs the second task in the posture indicated by the second posture data (step S<b>3</b>). The processing device <b>230</b> generates the first posture data based on the second posture data (step S<b>4</b>). The first robot <b>110</b> performs the first task in the posture indicated by the first posture data (step S<b>5</b>). Step S<b>4</b> may be performed before operating the production line after step S<b>2</b>.</p><p id="p-0082" num="0081"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a perspective view illustrating the internal structure of a detector tip.</p><p id="p-0083" num="0082">Operations of the robot system <b>100</b> will now be described in detail. Here, an example is described in which the robot system <b>100</b> is used as an inspection system inspecting a spot-welded weld portion.</p><p id="p-0084" num="0083">A matrix sensor <b>401</b> illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref> is located inside the detector <b>112</b><i>a </i>tip. The matrix sensor <b>401</b> includes multiple ultrasonic sensors <b>402</b>. The ultrasonic sensors <b>402</b> are, for example, transducers. The multiple ultrasonic sensors <b>402</b> are arranged along two directions (the X-direction and the Y-direction) that cross each other. In the example, the X-direction and the Y-direction are orthogonal. The X-direction and the Y-direction in which the multiple ultrasonic sensors <b>402</b> are arranged may or may not correspond to the X-direction and the Y-direction of the coordinate system of the position of the control point.</p><p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a state of inspecting the first member <b>10</b>. The first member <b>10</b> is made by spot-welding a steel plate <b>11</b> and a steel plate <b>12</b> at a weld portion <b>13</b>. A solidified portion <b>14</b> is formed at the weld portion <b>13</b> by a portion of the steel plate <b>11</b> and a portion of the steel plate <b>12</b> melting, mixing, and solidifying. Each of the ultrasonic sensors <b>402</b> transmits an ultrasonic wave US toward the first member <b>10</b> coated with a couplant <b>15</b> and detects (receives) a reflected wave RW from the first member <b>10</b>.</p><p id="p-0086" num="0085">In a more specific example as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, one ultrasonic sensor <b>402</b> transmits the ultrasonic wave US toward the weld portion <b>13</b>. A portion of the ultrasonic wave US is reflected by the upper or lower surface of the first member <b>10</b>, etc. Each of the multiple ultrasonic sensors <b>402</b> detects the reflected wave RW. The ultrasonic sensors <b>402</b> sequentially transmit the ultrasonic wave US; and each reflected wave RW is detected by the multiple ultrasonic sensors <b>402</b>.</p><p id="p-0087" num="0086">Each of the ultrasonic sensors <b>402</b> transmits a signal (a current) toward the control device <b>120</b> when detecting the reflected wave. The intensity of the signal corresponds to the intensity of the reflected wave. The control device <b>120</b> transmits data of the received signal intensity to the processing device <b>130</b>. The processing device <b>130</b> inspects the weld portion <b>13</b> based on the received data.</p><p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is schematic views for describing an inspection method.</p><p id="p-0089" num="0088">As illustrated in <figref idref="DRAWINGS">FIG. <b>8</b>A</figref>, a portion of the ultrasonic wave US is reflected by an upper surface <b>10</b><i>a </i>of the steel plate <b>11</b> or an upper surface <b>10</b><i>b </i>of the weld portion <b>13</b>. Another portion of the ultrasonic wave US enters the first member <b>10</b> and is reflected by a lower surface <b>10</b><i>c </i>of the steel plate <b>11</b> or a lower surface <b>10</b><i>d </i>of the weld portion <b>13</b>.</p><p id="p-0090" num="0089">The Z-direction positions of the upper surface <b>10</b><i>a, </i>the upper surface <b>10</b><i>b, </i>the lower surface <b>10</b><i>c, </i>and the lower surface <b>10</b><i>d </i>are different from each other. In other words, the distances in the Z-direction between the ultrasonic sensor <b>402</b> and these surfaces are different from each other. The peak of the intensity of the reflected wave is detected when the ultrasonic sensor <b>402</b> receives the reflected wave from these surfaces. Which surface reflected the ultrasonic wave US can be verified by calculating the time until each peak is detected after transmitting the ultrasonic wave US.</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIGS. <b>8</b>B and <b>8</b>C</figref> are graphs illustrating the relationship between the time after transmitting the ultrasonic wave US and the intensity of the reflected wave RW. Here, the intensity of the reflected wave RW is illustrated as an absolute value. The graph of <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> illustrates the reception result of the reflected wave RW from the upper surface <b>10</b><i>a </i>and the lower surface <b>10</b><i>c </i>of the steel plate <b>11</b>. The graph of <figref idref="DRAWINGS">FIG. <b>8</b>C</figref> illustrates the reception result of the reflected wave RW from the upper surface <b>10</b><i>b </i>and the lower surface <b>10</b><i>d </i>of the weld portion <b>13</b>.</p><p id="p-0092" num="0091">In the graph of <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>, a peak Pe<b>1</b> occurring first is based on the reflected wave RW from the upper surface <b>10</b><i>a. </i>A peak Pe<b>2</b> occurring second is based on the reflected wave RW from the lower surface <b>10</b><i>c. </i>The times at which the peak Pe<b>1</b> and the peak Pe<b>2</b> are detected correspond respectively to the Z-direction positions of the upper surface <b>10</b><i>a </i>and the lower surface <b>10</b><i>c </i>of the steel plate <b>11</b>. A time difference TD<b>1</b> between the time at which the peak Pe<b>1</b> is detected and the time at which the peak Pe<b>2</b> is detected corresponds to a distance Di<b>1</b> in the Z-direction between the upper surface <b>10</b><i>a </i>and the lower surface <b>10</b><i>c. </i></p><p id="p-0093" num="0092">Similarly, in the graph of <figref idref="DRAWINGS">FIG. <b>8</b>C</figref>, a peak Pe<b>3</b> occurring first is based on the reflected wave RW from the upper surface <b>10</b><i>b. </i>A peak Pe<b>4</b> occurring second is based on the reflected wave RW from the lower surface <b>10</b><i>d. </i>The times at which the peak Pe<b>3</b> and the peak Pe<b>4</b> are detected correspond respectively to the Z-direction positions of the upper surface <b>10</b><i>b </i>and the lower surface <b>10</b><i>d </i>of the weld portion <b>13</b>. A time difference TD<b>2</b> between the time at which the peak Pe<b>3</b> is detected and the time at which the peak Pe<b>4</b> is detected correspond to a distance Di<b>2</b> in the Z-direction between the upper surface <b>10</b><i>b </i>and the lower surface <b>10</b><i>d. </i></p><p id="p-0094" num="0093">The processing device <b>130</b> inspects whether or not multiple points at the weld portion <b>13</b> vicinity are welded based on the time difference of the adjacent peaks. There are cases where the upper surface <b>10</b><i>b </i>and the lower surface <b>10</b><i>d </i>of the weld portion <b>13</b> are tilted with respect to the upper surface <b>10</b><i>a </i>of the steel plate <b>11</b>. This is due to the weld portion <b>13</b> including the solidified portion <b>14</b>, shape deformation in the welding process, etc. In such a case, it is desirable for the ultrasonic waves US to be transmitted along a direction that is, on average, perpendicular to the upper surface <b>10</b><i>b </i>or the lower surface <b>10</b><i>d</i>. Thereby, the ultrasonic wave can be reflected more intensely at the upper surface <b>10</b><i>b </i>and the lower surface <b>10</b><i>d, </i>and the accuracy of the inspection can be increased.</p><p id="p-0095" num="0094"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart illustrating a specific example of the first task.</p><p id="p-0096" num="0095">First, the control device <b>120</b> refers to the first posture data of the posture of the first robot <b>110</b> when the couplant is coated using the coating device <b>112</b><i>b. </i>The control device <b>120</b> sets the posture of the first robot <b>110</b> based on the first posture data (step S<b>41</b>). The control device <b>120</b> causes the couplant to be coated onto the first member <b>10</b> from the coating device <b>112</b><i>b </i>(step S<b>42</b>). The control device <b>120</b> refers to the first posture data of the posture of the first robot <b>110</b> when the information is acquired using the detector <b>112</b><i>a. </i>The control device <b>120</b> sets the posture of the first robot <b>110</b> based on the first posture data (step S<b>43</b>). The control device <b>120</b> uses the detector <b>112</b><i>a </i>to acquire information of the spot-welded weld portion (step S<b>44</b>).</p><p id="p-0097" num="0096">The control device <b>120</b> transmits the acquired information to the processing device <b>130</b>. The processing device <b>130</b> processes the information and calculates the tilt of the detector <b>112</b><i>a </i>with respect to the first member <b>10</b> (step S<b>45</b>). The processing device <b>130</b> determines whether or not the tilt is less than a prescribed threshold (step S<b>46</b>). When the tilt is greater than the threshold, the control device <b>120</b> adjusts the posture of the first robot <b>110</b> to reduce the tilt (step S<b>47</b>). After the adjustment of the posture, step S<b>44</b> is re-performed.</p><p id="p-0098" num="0097">When the tilt is less than the threshold, the processing device <b>130</b> inspects the weld portion by using the information acquired in step S<b>44</b> directly before (step S<b>48</b>). Specifically, it is determined whether or not the first member <b>10</b> is appropriately welded at the weld portion. For example, the processing device <b>130</b> stores the inspection result in the memory device <b>310</b>.</p><p id="p-0099" num="0098">One specific example of a method for calculating the tilt will now be described.</p><p id="p-0100" num="0099"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a drawing for describing the calculation method of the tilt of the detector.</p><p id="p-0101" num="0100"><figref idref="DRAWINGS">FIGS. <b>11</b> and <b>12</b></figref> are examples of images of the detected information.</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is three-dimensional volume data depicted based on the detection result of the reflected wave. <figref idref="DRAWINGS">FIG. <b>12</b>A</figref> illustrates the surface of the weld portion <b>13</b> in the volume data illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. <figref idref="DRAWINGS">FIG. <b>12</b>B</figref> illustrates a Y-Z cross section at the weld portion <b>13</b> vicinity in the volume data illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. <figref idref="DRAWINGS">FIG. <b>12</b>C</figref> illustrates an X-Z cross section at the weld portion <b>13</b> vicinity in the volume data illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. In <figref idref="DRAWINGS">FIGS. <b>12</b>B and <b>12</b>C</figref>, the upper side is the surface of the weld portion <b>13</b>; and the data in the depth direction is shown downward. Parts of high luminance are parts of high ultrasonic wave reflection intensity. The ultrasonic wave is intensely reflected by the bottom surface of the weld portion <b>13</b>, the surfaces between the unjoined members, etc.</p><p id="p-0103" num="0102">The tilt of the detector <b>112</b><i>a </i>corresponds to the angle between a direction D<b>1</b> perpendicular to the weld portion <b>13</b> and a direction D<b>2</b> of the detector <b>112</b><i>a </i>illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>. This angle is represented by an angle &#x3b8;x around the X-direction and an angle &#x3b8;y around the Y-direction. The direction D<b>2</b> is perpendicular to the arrangement direction of the ultrasonic sensors <b>402</b>.</p><p id="p-0104" num="0103">As illustrated in <figref idref="DRAWINGS">FIG. <b>12</b>B</figref>, the angle Ox is calculated based on the detection result in the Y-Z cross section. As illustrated in <figref idref="DRAWINGS">FIG. <b>12</b>C</figref>, the angle &#x3b8;y is calculated based on the detection result in the X-Z cross section. The processing device <b>130</b> calculates the average of the three-dimensional luminance gradient of each cross section as the angles &#x3b8;x and &#x3b8;y. The processing device <b>130</b> stores the calculated angles &#x3b8;x and &#x3b8;y in the memory device <b>310</b> as the tilt of the detector <b>112</b><i>a. </i></p><p id="p-0105" num="0104"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a drawing illustrating a configuration example of the processing device and the control device.</p><p id="p-0106" num="0105">The control device <b>120</b>, the processing device <b>130</b>, the control device <b>220</b>, and the processing device <b>230</b> each include, for example, a central processing unit (CPU) <b>501</b>, main memory <b>502</b>, nonvolatile memory <b>503</b>, an I/O interface <b>504</b>, and a bus <b>505</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0107" num="0106">The bus <b>505</b> connects the CPU <b>501</b>, the main memory <b>502</b>, the nonvolatile memory <b>503</b>, and the I/O interface <b>504</b> to each other.</p><p id="p-0108" num="0107">The main memory <b>502</b> is accessible more quickly than the nonvolatile memory <b>503</b>. The main memory <b>502</b> includes, for example, random access memory (RAM). The nonvolatile memory <b>503</b> is used as a storage region of various data. The nonvolatile memory <b>503</b> includes, for example, read only memory (ROM), flash memory, an optical disk, a magnetic disk, a detachable memory device, or a combination of such memory. The I/O interface <b>504</b> is an interface device for connecting to other devices.</p><p id="p-0109" num="0108">Programs necessary for the processing of the control device <b>120</b>, the processing device <b>130</b>, the control device <b>220</b>, or the processing device <b>230</b> are stored in the nonvolatile memory <b>503</b>. For example, firmware programs and robot programs for causing the control device <b>120</b> or <b>220</b> to operate the first robot <b>110</b> or the second robot <b>210</b> are stored. The operation procedures of the robots are described in the robot programs. For example, in the control device <b>120</b> or <b>220</b>, the CPU <b>501</b> loads the firmware program from the nonvolatile memory <b>503</b> into the main memory <b>502</b>. The CPU <b>501</b> executes the robot program based on the loaded firmware program. The CPU <b>501</b> interprets the robot program and calculates the drive command for the driver of the first or second robot <b>110</b> or <b>210</b> based on the result. The calculated drive command is transmitted to the robot via the I/O interface <b>504</b>.</p><p id="p-0110" num="0109">The control device <b>120</b>, the processing device <b>130</b>, the control device <b>220</b>, and the processing device <b>230</b> each may have the configuration illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, or one device that has the configuration illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref> may function as at least two selected from the control device <b>120</b>, the processing device <b>130</b>, the control device <b>220</b>, and the processing device <b>230</b>. For example, one control device may function as the control devices <b>120</b> and <b>220</b>. One processing device may function as the processing devices <b>130</b> and <b>230</b>.</p><p id="p-0111" num="0110">The configuration illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref> is applicable to the teaching device <b>320</b> as well.</p><p id="p-0112" num="0111">The time necessary for a human to teach the first robot can be reduced by using the control method performed by the control device <b>120</b>, the robot system <b>100</b>, the inspection system, the production system <b>300</b>, or the control device <b>120</b> described above. Similar effects can be obtained by using a program that causes the control device of the robot system to perform the control method described above.</p><p id="p-0113" num="0112">The processing of the various data described above may be recorded, as a program that can be executed by a computer, in a magnetic disk (a flexible disk, a hard disk, etc.), an optical disk (CD-ROM, CD-R, CD-RW, DVD-ROM, DVD&#xb1;R, DVD&#xb1;RW, etc.), semiconductor memory, or another recording medium.</p><p id="p-0114" num="0113">For example, the data that is recorded in the recording medium can be read by the computer (or an embedded system).</p><p id="p-0115" num="0114">The recording format (the storage format) of the recording medium is arbitrary. For example, the computer reads the program from the recording medium and causes a CPU to execute the instructions recited in the program based on the program. In the computer, the acquisition (or the reading) of the program may be performed via a network.</p><p id="p-0116" num="0115">While certain embodiments of the inventions have been illustrated, these embodiments have been presented by way of example only, and are not intended to limit the scope of the inventions. These novel embodiments may be embodied in a variety of other forms; and various omissions, substitutions, modifications, etc., can be made without departing from the spirit of the inventions. These embodiments and their modifications are within the scope and spirit of the inventions, and are within the scope of the inventions described in the claims and their equivalents. The embodiments described above can be implemented in combination with each other.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A control device,<claim-text>the control device receiving first posture data of a posture of a first robot, the first robot including a first manipulator and a first end effector,</claim-text><claim-text>the control device setting the posture of the first robot based on the first posture data and causing the first robot to perform a first task on a first member,</claim-text><claim-text>the first posture data being generated based on second posture data of a posture when a second robot performs a second task on the first member,</claim-text><claim-text>the second robot including a second manipulator and a second end effector.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The control device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the control device receives a plurality of sets of the first posture data,</claim-text><claim-text>the control device sequentially sets the posture of the first robot based on the plurality of sets of first posture data, and</claim-text><claim-text>the control device causes the first robot to perform the first task at each of the postures.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The control device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein<claim-text>the plurality of sets of first posture data is generated respectively based on a plurality of sets of the second posture data,</claim-text><claim-text>a portion of the plurality of sets of second posture data is generated based on design posture data generated from design data of the first member, and</claim-text><claim-text>an other portion of the plurality of sets of second posture data is generated based on teaching to the second robot.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The control device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the first posture data is generated using the second posture data, first structure data, and second structure data,</claim-text><claim-text>the first structure data is of a relationship between a structure of the first manipulator, a posture of a distal part of the first manipulator and the posture of the first robot, and</claim-text><claim-text>the second structure data is of a relationship between a structure of the second manipulator, a posture of a distal part of the second manipulator, and the posture of the second robot.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The control device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the first end effector includes a detector,</claim-text><claim-text>an ultrasonic sensor is included in the detector,</claim-text><claim-text>the second end effector includes a welding device performing spot welding, and</claim-text><claim-text>in the first task, the first robot is caused to use the detector to acquire information of a weld portion that was spot-welded.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. An inspection system, comprising:<claim-text>the control device according to <claim-ref idref="CLM-00005">claim 5</claim-ref>; and</claim-text><claim-text>a processing device,</claim-text><claim-text>the information including a reflected wave intensity of an ultrasonic wave from the weld portion,</claim-text><claim-text>the processing device using the information to perform an inspection of the weld portion of a calculation of a tilt of the detector with respect to the weld portion.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The inspection system according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising:<claim-text>the first robot.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A control method, comprising:<claim-text>receiving first posture data of a posture of a first robot, the first robot including a first manipulator and a first end effector; and</claim-text><claim-text>setting the posture of the first robot based on the first posture data and causing the first robot to perform a first task on a first member,</claim-text><claim-text>the first posture data being generated based on second posture data of a posture when a second robot performs a second task on the first member,</claim-text><claim-text>the second robot including a second manipulator and a second end effector.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The control method according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein<claim-text>the first end effector includes a detector,</claim-text><claim-text>an ultrasonic sensor is included in the detector,</claim-text><claim-text>the second end effector includes a welding device performing spot welding, and</claim-text><claim-text>in the first task, the first robot is caused to use the detector to acquire information of a weld portion that was spot-welded.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. A non-transitory computer-readable storage medium storing a program, the program causing a computer to function as a control device,<claim-text>the control device receiving first posture data of a posture of a first robot,</claim-text><claim-text>the first robot including a first manipulator and a first end effector,</claim-text><claim-text>the control device setting the posture of the first robot based on the first posture data and causing the first robot to perform a first task on a first member,</claim-text><claim-text>the first posture data being generated based on second posture data of a posture when a second robot performs a second task on the first member,</claim-text><claim-text>the second robot including a second manipulator and a second end effector.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The storage medium according to <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein<claim-text>the first end effector includes a detector,</claim-text><claim-text>an ultrasonic sensor is included in the detector,</claim-text><claim-text>the second end effector includes a welding device performing spot welding, and</claim-text><claim-text>in the first task, the control device causes the first robot to use the detector to acquire information of a weld portion that was spot-welded.</claim-text></claim-text></claim></claims></us-patent-application>
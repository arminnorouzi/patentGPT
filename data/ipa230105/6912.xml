<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230006913A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230006913</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17806716</doc-number><date>20220613</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>43</main-group><subgroup>55</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>W</subclass><main-group>24</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>B</subclass><main-group>17</main-group><subgroup>309</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>43</main-group><subgroup>0864</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20220501</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>43</main-group><subgroup>55</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>W</subclass><main-group>24</main-group><subgroup>10</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20150115</date></cpc-version-indicator><section>H</section><class>04</class><subclass>B</subclass><main-group>17</main-group><subgroup>309</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>43</main-group><subgroup>0864</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">METHOD AND APPARATUS FOR CHANNEL ENVIRONMENT CLASSIFICATION</invention-title><us-related-documents><us-provisional-application><document-id><country>US</country><doc-number>63244083</doc-number><date>20210914</date></document-id></us-provisional-application><us-provisional-application><document-id><country>US</country><doc-number>63215796</doc-number><date>20210628</date></document-id></us-provisional-application></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Samsung Electronics Co., Ltd.</orgname><address><city>Suwon-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Lo</last-name><first-name>Caleb K.</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Jeon</last-name><first-name>Jeongho</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Ding</last-name><first-name>Haichuan</first-name><address><city>Casselberry</city><state>FL</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Cho</last-name><first-name>Joonyoung</first-name><address><city>Portland</city><state>OR</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Madadi</last-name><first-name>Pranav</first-name><address><city>Sunnyvale</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Ye</last-name><first-name>Qiaoyang</first-name><address><city>San Jose</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">UE capability for support of machine-learning (ML) based channel environment classification may be reported by a user equipment to a base station, where the channel environment classification classifies a channel environment of a channel between the UE and a base station based on one or more of UE speed or Doppler spread, UE trajectory, frequency selectivity or delay spread, coherence bandwidth, coherence time, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration. The user equipment may receive configuration for ML based channel environment classification, including at least enabling/disabling of ML based channel environment classification. When ML based channel environment classification is enabled, UE assistance information for ML based channel environment classification, and/or an indication of the channel environment (which may be a pre-defined channel environment associated with a lookup table), may be transmitted by the user equipment to the base station.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="153.67mm" wi="157.65mm" file="US20230006913A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="160.36mm" wi="159.68mm" file="US20230006913A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="153.92mm" wi="156.21mm" file="US20230006913A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="170.77mm" wi="151.89mm" file="US20230006913A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="194.06mm" wi="119.97mm" file="US20230006913A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="163.24mm" wi="120.48mm" file="US20230006913A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="114.81mm" wi="120.65mm" file="US20230006913A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="146.30mm" wi="120.65mm" file="US20230006913A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="246.97mm" wi="148.25mm" orientation="landscape" file="US20230006913A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="243.08mm" wi="113.37mm" orientation="landscape" file="US20230006913A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="244.69mm" wi="175.18mm" file="US20230006913A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="124.12mm" wi="121.50mm" file="US20230006913A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="149.52mm" wi="121.58mm" file="US20230006913A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="201.17mm" wi="121.58mm" file="US20230006913A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="220.56mm" wi="121.58mm" file="US20230006913A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="178.14mm" wi="121.41mm" file="US20230006913A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION AND CLAIM OF PRIORITY</heading><p id="p-0002" num="0001">This application claims priority to U.S. Provisional Patent Application No. 63/215,796 filed Jun. 28, 2021, and U.S. Provisional Patent Application No. 63/244,083 filed Sep. 14, 2021. The content of the above-identified patent documents is incorporated herein by reference.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">TECHNICAL FIELD</heading><p id="p-0003" num="0002">The present disclosure relates generally to use of channel environment classification in wireless communications, and more specifically to channel environment classification in terms of one or more of user equipment speed (e.g., Doppler spread), frequency selectivity (e.g., delay spread), or coherence bandwidth and/or coherence time.</p><heading id="h-0003" level="1">BACKGROUND</heading><p id="p-0004" num="0003">To meet the demand for wireless data traffic having increased since deployment of 4th Generation (4G) or Long Term Evolution (LTE) communication systems and to enable various vertical applications, efforts have been made to develop and deploy an improved 5<sup>th </sup>Generation (5G) and/or New Radio (NR) or pre-5G/NR communication system. Therefore, the 5G/NR or pre-5G/NR communication system is also called a &#x201c;beyond 4G network&#x201d; or a &#x201c;post LTE system.&#x201d; The 5G/NR communication system is considered to be implemented in higher frequency (mmWave) bands, e.g., 28 giga-Hertz (GHz) or 60 GHz bands, so as to accomplish higher data rates or in lower frequency bands, such as 6 GHz, to enable robust coverage and mobility support. To decrease propagation loss of the radio waves and increase the transmission distance, the beamforming, massive multiple-input multiple-output (MIMO), full dimensional MIMO (FD-MIMO), array antenna, an analog beam forming, large scale antenna techniques are discussed in 5G/NR communication systems.</p><p id="p-0005" num="0004">In addition, in 5G/NR communication systems, development for system network improvement is under way based on advanced small cells, cloud radio access networks (RANs), ultra-dense networks, device-to-device (D2D) communication, wireless backhaul, moving network, cooperative communication, coordinated multi-points (CoMP), reception-end interference cancellation and the like.</p><p id="p-0006" num="0005">The discussion of 5G systems and technologies associated therewith is for reference as certain embodiments of the present disclosure may be implemented in 5G systems, 6<sup>th </sup>Generation (6G) systems, or even later releases which may use terahertz (THz) bands. However, the present disclosure is not limited to any particular class of systems or the frequency bands associated therewith, and embodiments of the present disclosure may be utilized in connection with any frequency band. For example, aspects of the present disclosure may also be applied to deployment of 5G communication systems, 6G communications systems, or communications using THz bands.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0007" num="0006">UE capability for support of machine-learning (ML) based channel environment classification may be reported by a user equipment to a base station, where the channel environment classification classifies a channel environment of a channel between the UE and a base station based on one or more of UE speed or Doppler spread, UE trajectory, frequency selectivity or delay spread, coherence bandwidth, coherence time, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration. The user equipment may receive configuration for ML based channel environment classification, including at least enabling/disabling of ML based channel environment classification. When ML based channel environment classification is enabled, UE assistance information for ML based channel environment classification, and/or an indication of the channel environment (which may be a pre-defined channel environment associated with a lookup table), may be transmitted by the user equipment to the base station.</p><p id="p-0008" num="0007">In one embodiment, a user equipment (UE) includes a processor and a transceiver operatively coupled to the processor. The transceiver is configured to transmit a report of UE capability for support of machine-learning (ML) based channel environment classification, where the channel environment classification classifies a channel environment of a channel between the UE and a base station based on one or more of UE speed or Doppler spread, UE trajectory, frequency selectivity or delay spread, coherence bandwidth, coherence time, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration. The transceiver is configured to receive configuration for ML based channel environment classification, the configuration for ML based channel environment classification comprising at least enabling/disabling of ML based channel environment classification. When ML based channel environment classification is enabled, the transceiver is configured to one of transmit UE assistance information for ML based channel environment classification, or transmit an indication of the channel environment.</p><p id="p-0009" num="0008">In a second embodiment, a method performed by a user equipment (UE) includes transmitting a report of UE capability for support of machine-learning (ML) based channel environment classification, where the channel environment classification classifies a channel environment of a channel between the UE and a base station based on one or more of UE speed or Doppler spread, UE trajectory, frequency selectivity or delay spread, coherence bandwidth, coherence time, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration. The method also includes receiving configuration for ML based channel environment classification, the configuration for ML based channel environment classification comprising at least enabling/disabling of ML based channel environment classification. When ML based channel environment classification is enabled, the method further includes one of transmitting UE assistance information for ML based channel environment classification, or transmitting an indication of channel environment.</p><p id="p-0010" num="0009">In another embodiment, a base station includes a processor and a transceiver operatively coupled to the processor. The transceiver is configured to receive a report of user equipment (UE) capability for support of machine-learning (ML) based channel environment classification, where the channel environment classification classifies a channel environment of a channel between the UE and a base station based on one or more of UE speed or Doppler spread, UE trajectory, frequency selectivity or delay spread, coherence bandwidth, coherence time, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration. The transceiver is also configured to transmit configuration for ML based channel environment classification, the configuration for ML based channel environment classification comprising at least enabling/disabling of ML based channel environment classification. When ML based channel environment classification is enabled, either the processor is configured to perform model training based on the configuration and a received information on channel environment determined by the UE, or the transceiver is configured to receive UE assistance information for ML based channel classification. The transceiver is further configured to receive an indication of the channel environment.</p><p id="p-0011" num="0010">In any of the forgoing embodiments, the indication of the channel environment may be a pre-defined channel environment associated with a lookup table.</p><p id="p-0012" num="0011">In any of the forgoing embodiments, the configuration for ML based channel environment classification further may comprise one or more of a format for the indication, resources for the indication, periodicity of the indication, ML model to be used, updated ML model parameters, or whether model parameters received from the UE will be used.</p><p id="p-0013" num="0012">In any of the forgoing embodiments, the UE assistance information may comprise one of: an indication of one or more of UE speed, frequency selectivity, channel coherence time, channel coherence bandwidth, UE trajectory, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration; or an indication usable for performing model inference or includes model inference result if the UE performs model inference, wherein the model inference result further comprises one or more of an indication of a channel environment, a recommendation for a transmission mode, or a recommendation for BS handover.</p><p id="p-0014" num="0013">In any of the forgoing embodiments, the UE assistance information may comprise one of: periodic and triggered by UE-specific radio resource control (RRC) signaling; or aperiodic or semi-persistent and triggered by a downlink control information (DCI).</p><p id="p-0015" num="0014">In any of the forgoing embodiments, the configuration for ML based channel environment classification may be one of: broadcast as part of system information; or transmitted via UE-specific signaling.</p><p id="p-0016" num="0015">In any of the forgoing embodiments, the configuration for ML based channel environment classification may include enabling/disabling of channel environment-aware feedback, and wherein the transceiver is configured to transmit channel state information (CSI) reporting indicating channel environment when channel environment-aware feedback is enabled.</p><p id="p-0017" num="0016">Other technical features may be readily apparent to one skilled in the art from the following figures, descriptions, and claims.</p><p id="p-0018" num="0017">Before undertaking the DETAILED DESCRIPTION below, it may be advantageous to set forth definitions of certain words and phrases used throughout this patent document. The term &#x201c;couple&#x201d; and its derivatives refer to any direct or indirect communication between two or more elements, whether those elements are in physical contact with one another. The terms &#x201c;transmit,&#x201d; &#x201c;receive,&#x201d; and &#x201c;communicate,&#x201d; as well as derivatives thereof, encompass both direct and indirect communication. The terms &#x201c;include&#x201d; and &#x201c;comprise,&#x201d; as well as derivatives thereof, mean inclusion without limitation. The term &#x201c;or&#x201d; is inclusive, meaning and/or. The phrase &#x201c;associated with,&#x201d; as well as derivatives thereof, means to include, be included within, interconnect with, contain, be contained within, connect to or with, couple to or with, be communicable with, cooperate with, interleave, juxtapose, be proximate to, be bound to or with, have, have a property of, have a relationship to or with, or the like. The term &#x201c;controller&#x201d; means any device, system or part thereof that controls at least one operation. Such a controller may be implemented in hardware or a combination of hardware and software and/or firmware. The functionality associated with any particular controller may be centralized or distributed, whether locally or remotely. The phrase &#x201c;at least one of,&#x201d; when used with a list of items, means that different combinations of one or more of the listed items may be used, and only one item in the list may be needed. For example, &#x201c;at least one of: A, B, and C&#x201d; includes any of the following combinations: A, B, C, A and B, A and C, B and C, and A and B and C. Likewise, the term &#x201c;set&#x201d; means one or more. Accordingly, a set of items can be a single item or a collection of two or more items.</p><p id="p-0019" num="0018">Moreover, various functions described below can be implemented or supported by one or more computer programs, each of which is formed from computer readable program code and embodied in a computer readable medium. The terms &#x201c;application&#x201d; and &#x201c;program&#x201d; refer to one or more computer programs, software components, sets of instructions, procedures, functions, objects, classes, instances, related data, or a portion thereof adapted for implementation in a suitable computer readable program code. The phrase &#x201c;computer readable program code&#x201d; includes any type of computer code, including source code, object code, and executable code. The phrase &#x201c;computer readable medium&#x201d; includes any type of medium capable of being accessed by a computer, such as read only memory (ROM), random access memory (RAM), a hard disk drive, a compact disc (CD), a digital video disc (DVD), or any other type of memory. A &#x201c;non-transitory&#x201d; computer readable medium excludes wired, wireless, optical, or other communication links that transport transitory electrical or other signals. A non-transitory computer readable medium includes media where data can be permanently stored and media where data can be stored and later overwritten, such as a rewritable optical disc or an erasable memory device.</p><p id="p-0020" num="0019">Definitions for other certain words and phrases are provided throughout this patent document. Those of ordinary skill in the art should understand that in many if not most instances, such definitions apply to prior as well as future uses of such defined words and phrases.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0021" num="0020">For a more complete understanding of this disclosure and its advantages, reference is now made to the following description, taken in conjunction with the accompanying drawings, in which:</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an exemplary networked system utilizing one of input circular buffer aided artificial intelligence or machine learning or channel environment classification according to various embodiments of this disclosure;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an exemplary base station (BS) utilizing one of input circular buffer aided artificial intelligence or machine learning or channel environment classification according to various embodiments of this disclosure;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an exemplary electronic device for communicating in the networked computing system utilizing one of input circular buffer aided artificial intelligence or machine learning or channel environment classification according to various embodiments of this disclosure;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example flowchart for BS operation to support AI/ML techniques for DL channel coding according to embodiments of the present disclosure;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example flowchart for UE operation to support AI/ML techniques for DL channel coding according to embodiments of the present disclosure;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example flowchart for BS operation to support AI/ML techniques for UL channel coding according to embodiments of the present disclosure;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an example flowchart UE operation to support AI/ML techniques for UL channel coding according to embodiments of the present disclosure;</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> depict the configuration of the AI/ML encoder, with <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> depicting the overall architecture of a circular buffer aided AI/ML encoder, while <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> depicts the overall architecture of the kth neural network therein;</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> illustrate the operation of adding padding bits when input block length K is not a multiple of the input dimension &#x3ba; of the AI/ML encoder;</p><p id="p-0031" num="0030"><figref idref="DRAWINGS">FIG. <b>10</b></figref> depicts the operation of an input circular buffer aided encoding when L&#x2032;=L;</p><p id="p-0032" num="0031"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows an example flowchart for BS operation to support UE information on channel environments according to embodiments of the present disclosure;</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows an example flowchart for UE operation to support UE information on channel environments according to embodiments of the present disclosure;</p><p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows an example flowchart for BS operation to support BS determination of channel environment according to embodiments of the present disclosure;</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows an example flowchart for UE operation to support BS determination of channel environment according to embodiments of the present disclosure;</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>15</b></figref> depicts an example of a new MAC-CE for the UE assistance information report according to embodiments of the present disclosure;</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows an example flowchart for BS operation to support CSI feedback being aware of channel environment according to embodiments of the present disclosure; and</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>17</b></figref> shows an example flowchart for UE operation to support CSI feedback being aware of channel environment according to embodiments of the present disclosure.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><p id="p-0039" num="0038">The figures included herein, and the various embodiments used to describe the principles of the present disclosure are by way of illustration only and should not be construed in any way to limit the scope of the disclosure. Further, those skilled in the art will understand that the principles of the present disclosure may be implemented in any suitably arranged wireless communication system.</p><heading id="h-0007" level="1">REFERENCES</heading><p id="p-0040" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0039">[1] 3GPP, TS 38.212, 5G; NR; Multiplexing and channel coding</li>    <li id="ul0001-0002" num="0040">[2] 3GPP TS 38.214, 5g; NR; Physical layer procedures for data</li>    <li id="ul0001-0003" num="0041">[3] 3GPP, TS 38.331, 5G; NR; Radio Resource Control (RRC); Protocol specification.</li>    <li id="ul0001-0004" num="0042">[4] 3GPP, TS 38.211, 5G; NR; Physical channels and modulation.</li></ul></p><p id="p-0041" num="0043">The above-identified references are incorporated herein by reference.</p><p id="p-0042" num="0044">Abbreviations:</p><p id="p-0043" num="0045">ML Machine Learning</p><p id="p-0044" num="0046">AI Artificial Intelligence</p><p id="p-0045" num="0047">gNB Base Station (Next Generation NodeB)</p><p id="p-0046" num="0048">UE User Equipment</p><p id="p-0047" num="0049">NR New Radio</p><p id="p-0048" num="0050">3GPP 3rd Generation Partnership Project</p><p id="p-0049" num="0051">SIB System Information Block</p><p id="p-0050" num="0052">DCI Downlink Control Information</p><p id="p-0051" num="0053">UCI Uplink Control Information</p><p id="p-0052" num="0054">PDCCH Physical Downlink Control Channel</p><p id="p-0053" num="0055">PDSCH Physical Downlink Shared Channel</p><p id="p-0054" num="0056">PUSCH Physical Uplink Shared Channel</p><p id="p-0055" num="0057">PUCCH Physical Uplink Control Channel</p><p id="p-0056" num="0058">RRC Radio Resource Control</p><p id="p-0057" num="0059">DL Downlink</p><p id="p-0058" num="0060">UL Uplink</p><p id="p-0059" num="0061">LTE Long-Term Evolution</p><p id="p-0060" num="0062">BWP Bandwidth Part</p><p id="p-0061" num="0063">MAC-CE Medium Access Control&#x2014;Control Element</p><p id="p-0062" num="0064">SNR Signal to Noise Ratio</p><p id="p-0063" num="0065">TBS Transport Block Size</p><p id="p-0064" num="0066">BER Bit Error Rate</p><p id="p-0065" num="0067">BLER Block Error Rate</p><p id="p-0066" num="0068">BS Base Station</p><p id="p-0067" num="0069">CE Control Element</p><p id="p-0068" num="0070">CSI Channel State Information</p><p id="p-0069" num="0071">FDD Frequency Division Duplex</p><p id="p-0070" num="0072">IE Information Element</p><p id="p-0071" num="0073">MAC Medium Access Control</p><p id="p-0072" num="0074">OFDM Orthogonal Frequency Division Multiplexing</p><p id="p-0073" num="0075">RAN Radio Access Network</p><p id="p-0074" num="0076">O-RAN Open Radio Access Network</p><p id="p-0075" num="0077">RRC Radio Resource Control</p><p id="p-0076" num="0078">RRM Radio Resource Management</p><p id="p-0077" num="0079">RS Reference Signal</p><p id="p-0078" num="0080">TM Transmission Mode</p><p id="p-0079" num="0081">Channel coding is at the core of modern communication systems. Over the past few decades, the innovations in channel coding are powered by the mathematical insights of information theory and human ingenuity. The fifth generation communication system is expected to support various services with diverse requirements in throughput, delay, and reliability, and impose difference constraints, such as decoding complexity, reliability, and adaptability, on channel coding schemes. These newly emerging requirements will make existing handcrafted coding schemes, such as Turbo codes and LDPC codes, suboptimal as they are able to operate close to the Shannon limit only in some regimes (e.g., at long block length and additive white Gaussian Noise).</p><p id="p-0080" num="0082">AI/ML based channel codes, where the information bits are sequentially processed, have demonstrated great potentials to meet these challenges. Because of such sequential processing, the coded bits output by these AI/ML encoders will depend on both the information bits currently input to the encoder and the previously input information bits &#x201c;memorized&#x201d; by these AI/ML encoders.</p><p id="p-0081" num="0083">Due to the memory of these AI/ML encoder, the information bits located at the end of the input block will be encoded in a smaller number of coded bits in comparison to those bits located at the beginning of the input block. This will lead to unequal error protection of the input information bits, which can adversely affect system performance, particularly when the most important bits are located at the end of the input block. One solution to this problem is to add padding bit to the end of the input block. However, such padding operation will inevitably lead to a reduction in code rate, especially with a small input block length (e.g., in the Ultra-Reliable Low Latency Communication (URLLC)).</p><p id="p-0082" num="0084">The present disclosure describes a circular buffer aided AI/ML based channel coding scheme to address the problem of unequal error protection in AI/ML based channel codes without reducing the code rate. The overall framework to support this input circular buffer aided AI/ML techniques for channel coding operations in wireless communication systems and corresponding signaling details are also discussed in this disclosure.</p><p id="p-0083" num="0085">Communication over a randomly-varying wireless channel is subject to various impairments. For example, the speed of a mobile UE determines the Doppler spread for a transmitted signal; thus, the channel induces variations in the received signal quality over time. Also, mobility of a UE and/or reflectors affects the delay spread for a transmitted signal; in this case, the channel induces variations in the received signal quality over frequency.</p><p id="p-0084" num="0086">It may be advantageous to determine the statistics of the underlying randomly-varying wireless channel. For example, if the channel is varying rapidly in time, then a lower CSI estimation error can be obtained by utilizing an RS pattern that places RS on every other OFDM symbol, compared to an RS pattern that only places RS on the first OFDM symbol in a subframe. As another example, if the channel is varying slowly in time and frequency, then a larger throughput can be obtained by utilizing a TM that corresponds to spatial multiplexing, compared to a TM that corresponds to transmit diversity.</p><p id="p-0085" num="0087">The details of the algorithm for determining the statistics of the underlying randomly-varying wireless channel are typically left to the network.</p><p id="p-0086" num="0088">The present disclosure describes a framework for supporting AI/ML techniques for channel environment classification based on determining the statistics of the underlying randomly-varying wireless channel. The corresponding signaling details are discussed in this disclosure.</p><p id="p-0087" num="0089"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an exemplary networked system utilizing one of input circular buffer aided artificial intelligence or machine learning or channel environment classification according to various embodiments of this disclosure. The embodiment of the wireless network <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> is for illustration only. Other embodiments of the wireless network <b>100</b> could be used without departing from the scope of this disclosure.</p><p id="p-0088" num="0090">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the wireless network <b>100</b> includes a base station (BS) <b>101</b>, a BS <b>102</b>, and a BS <b>103</b>. The BS <b>101</b> communicates with the BS <b>102</b> and the BS <b>103</b>. The BS <b>101</b> also communicates with at least one Internet protocol (IP) network <b>130</b>, such as the Internet, a proprietary IP network, or another data network.</p><p id="p-0089" num="0091">The BS <b>102</b> provides wireless broadband access to the network <b>130</b> for a first plurality of user equipments (UEs) within a coverage area <b>120</b> of the BS <b>102</b>. The first plurality of UEs includes a UE <b>111</b>, which may be located in a small business (SB); a UE <b>112</b>, which may be located in an enterprise (E); a UE <b>113</b>, which may be located in a WiFi hotspot (HS); a UE <b>114</b>, which may be located in a first residence (R1); a UE <b>115</b>, which may be located in a second residence (R2); and a UE <b>116</b>, which may be a mobile device (M) like a cell phone, a wireless laptop, a wireless PDA, or the like. The BS <b>103</b> provides wireless broadband access to the network <b>130</b> for a second plurality of UEs within a coverage area <b>125</b> of the BS <b>103</b>. The second plurality of UEs includes the UE <b>115</b> and the UE <b>116</b>. In some embodiments, one or more of the BSs <b>101</b>-<b>103</b> may communicate with each other and with the UEs <b>111</b>-<b>116</b> using 5G, LTE, LTE Advanced (LTE-A), WiMAX, WiFi, NR, or other wireless communication techniques.</p><p id="p-0090" num="0092">Depending on the network type, other well-known terms may be used instead of &#x201c;base station&#x201d; or &#x201c;BS,&#x201d; such as node B, evolved node B (&#x201c;eNodeB&#x201d; or &#x201c;eNB&#x201d;), a 5G node B (&#x201c;gNodeB&#x201d; or &#x201c;gNB&#x201d;) or &#x201c;access point.&#x201d; For the sake of convenience, the term &#x201c;base station&#x201d; and/or &#x201c;BS&#x201d; are used in this disclosure to refer to network infrastructure components that provide wireless access to remote terminals. Also, depending on the network type, other well-known terms may be used instead of &#x201c;user equipment&#x201d; or &#x201c;UE,&#x201d; such as &#x201c;mobile station&#x201d; (or &#x201c;MS&#x201d;), &#x201c;subscriber station&#x201d; (or &#x201c;SS&#x201d;), &#x201c;remote terminal,&#x201d; &#x201c;wireless terminal,&#x201d; or &#x201c;user device.&#x201d; For the sake of convenience, the terms &#x201c;user equipment&#x201d; and &#x201c;UE&#x201d; are used in this patent document to refer to remote wireless equipment that wirelessly accesses a BS, whether the UE is a mobile device (such as a mobile telephone or smartphone) or is normally considered a stationary device (such as a desktop computer or vending machine).</p><p id="p-0091" num="0093">Dotted lines show the approximate extent of the coverage areas <b>120</b> and <b>125</b>, which are shown as approximately circular for the purposes of illustration and explanation only. It should be clearly understood that the coverage areas associated with BSs, such as the coverage areas <b>120</b> and <b>125</b>, may have other shapes, including irregular shapes, depending upon the configuration of the BSs and variations in the radio environment associated with natural and man-made obstructions.</p><p id="p-0092" num="0094">Although <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates one example of a wireless network <b>100</b>, various changes may be made to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. For example, the wireless network <b>100</b> could include any number of BSs and any number of UEs in any suitable arrangement. Also, the BS <b>101</b> could communicate directly with any number of UEs and provide those UEs with wireless broadband access to the network <b>130</b>. Similarly, each BS <b>102</b>-<b>103</b> could communicate directly with the network <b>130</b> and provide UEs with direct wireless broadband access to the network <b>130</b>. Further, the BS <b>101</b>, <b>102</b>, and/or <b>103</b> could provide access to other or additional external networks, such as external telephone networks or other types of data networks.</p><p id="p-0093" num="0095"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an exemplary base station (BS) utilizing one of input circular buffer aided artificial intelligence or machine learning or channel environment classification according to various embodiments of this disclosure. The embodiment of the BS <b>200</b> illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref> is for illustration only, and the BSs <b>101</b>, <b>102</b> and <b>103</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> could have the same or similar configuration. However, BSs come in a wide variety of configurations, and <figref idref="DRAWINGS">FIG. <b>2</b></figref> does not limit the scope of this disclosure to any particular implementation of a BS.</p><p id="p-0094" num="0096">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the BS <b>200</b> includes multiple antennas <b>280</b><i>a</i>-<b>280</b><i>n</i>, multiple radio frequency (RF) transceivers <b>282</b><i>a</i>-<b>282</b><i>n</i>, transmit (TX or Tx) processing circuitry <b>284</b>, and receive (RX or Rx) processing circuitry <b>286</b>. The BS <b>200</b> also includes a controller/processor <b>288</b>, a memory <b>290</b>, and a backhaul or network interface <b>292</b>.</p><p id="p-0095" num="0097">The RF transceivers <b>282</b><i>a</i>-<b>282</b><i>n </i>receive, from the antennas <b>280</b><i>a</i>-<b>280</b><i>n</i>, incoming RF signals, such as signals transmitted by UEs in the network <b>100</b>. The RF transceivers <b>282</b><i>a</i>-<b>282</b><i>n </i>down-convert the incoming RF signals to generate IF or baseband signals. The IF or baseband signals are sent to the RX processing circuitry <b>286</b>, which generates processed baseband signals by filtering, decoding, and/or digitizing the baseband or IF signals. The RX processing circuitry <b>286</b> transmits the processed baseband signals to the controller/processor <b>288</b> for further processing.</p><p id="p-0096" num="0098">The TX processing circuitry <b>284</b> receives analog or digital data (such as voice data, web data, e-mail, or interactive video game data) from the controller/processor <b>288</b>. The TX processing circuitry <b>284</b> encodes, multiplexes, and/or digitizes the outgoing baseband data to generate processed baseband or IF signals. The RF transceivers <b>282</b><i>a</i>-<b>282</b><i>n </i>receive the outgoing processed baseband or IF signals from the TX processing circuitry <b>284</b> and up-converts the baseband or IF signals to RF signals that are transmitted via the antennas <b>280</b><i>a</i>-<b>280</b><i>n. </i></p><p id="p-0097" num="0099">The controller/processor <b>288</b> can include one or more processors or other processing devices that control the overall operation of the BS <b>200</b>. For example, the controller/processor <b>288</b> could control the reception of forward channel signals and the transmission of reverse channel signals by the RF transceivers <b>282</b><i>a</i>-<b>282</b><i>n</i>, the RX processing circuitry <b>286</b>, and the TX processing circuitry <b>284</b> in accordance with well-known principles. The controller/processor <b>288</b> could support additional functions as well, such as more advanced wireless communication functions and/or processes described in further detail below. For instance, the controller/processor <b>288</b> could support beam forming or directional routing operations in which outgoing signals from multiple antennas <b>280</b><i>a</i>-<b>280</b><i>n </i>are weighted differently to effectively steer the outgoing signals in a desired direction. Any of a wide variety of other functions could be supported in the BS <b>200</b> by the controller/processor <b>288</b>. In some embodiments, the controller/processor <b>288</b> includes at least one microprocessor or microcontroller.</p><p id="p-0098" num="0100">The controller/processor <b>288</b> is also capable of executing programs and other processes resident in the memory <b>290</b>, such as a basic operating system (OS). The controller/processor <b>288</b> can move data into or out of the memory <b>290</b> as required by an executing process.</p><p id="p-0099" num="0101">The controller/processor <b>288</b> is also coupled to the backhaul or network interface <b>292</b>. The backhaul or network interface <b>292</b> allows the BS <b>200</b> to communicate with other devices or systems over a backhaul connection or over a network. The interface <b>292</b> could support communications over any suitable wired or wireless connection(s). For example, when the BS <b>200</b> is implemented as part of a cellular communication system (such as one supporting 6G, 5G, LTE, or LTE-A), the interface <b>292</b> could allow the BS <b>200</b> to communicate with other BSs over a wired or wireless backhaul connection. When the BS <b>200</b> is implemented as an access point, the interface <b>292</b> could allow the BS <b>200</b> to communicate over a wired or wireless local area network or over a wired or wireless connection to a larger network (such as the Internet). The interface <b>292</b> includes any suitable structure supporting communications over a wired or wireless connection, such as an Ethernet or RF transceiver.</p><p id="p-0100" num="0102">The memory <b>290</b> is coupled to the controller/processor <b>288</b>. Part of the memory <b>290</b> could include a RAM, and another part of the memory <b>290</b> could include a Flash memory or other ROM.</p><p id="p-0101" num="0103">As described in more detail below, base stations in a networked computing system can be assigned as synchronization source BS or a slave BS based on interference relationships with other neighboring BSs. In some embodiments, the assignment can be provided by a shared spectrum manager. In other embodiments, the assignment can be agreed upon by the BSs in the networked computing system. Synchronization source BSs transmit OSS to slave BSs for establishing transmission timing of the slave BSs.</p><p id="p-0102" num="0104">Although <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates one example of BS <b>200</b>, various changes may be made to <figref idref="DRAWINGS">FIG. <b>2</b></figref>. For example, the BS <b>200</b> could include any number of each component shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As a particular example, an access point could include a number of interfaces <b>292</b>, and the controller/processor <b>288</b> could support routing functions to route data between different network addresses. As another particular example, while shown as including a single instance of TX processing circuitry <b>284</b> and a single instance of RX processing circuitry <b>286</b>, the BS <b>200</b> could include multiple instances of each (such as one per RF transceiver). Also, various components in <figref idref="DRAWINGS">FIG. <b>2</b></figref> could be combined, further subdivided, or omitted and additional components could be added according to particular needs.</p><p id="p-0103" num="0105"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an exemplary electronic device for communicating in the networked computing system utilizing one of input circular buffer aided artificial intelligence or machine learning or channel environment classification according to various embodiments of this disclosure. The embodiment of the UE <b>116</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> is for illustration only, and the UEs <b>111</b>-<b>115</b> and <b>117</b>-<b>119</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> could have the same or similar configuration. However, UEs come in a wide variety of configurations, and <figref idref="DRAWINGS">FIG. <b>3</b></figref> does not limit the scope of the present disclosure to any particular implementation of a UE.</p><p id="p-0104" num="0106">As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the UE <b>116</b> includes an antenna <b>301</b>, a radio frequency (RF) transceiver <b>302</b>, TX processing circuitry <b>303</b>, a microphone <b>304</b>, and receive (RX) processing circuitry <b>305</b>. The UE <b>116</b> also includes a speaker <b>306</b>, a controller or processor <b>307</b>, an input/output (I/O) interface (IF) <b>308</b>, a touchscreen display <b>310</b>, and a memory <b>311</b>. The memory <b>311</b> includes an OS <b>312</b> and one or more applications <b>313</b>.</p><p id="p-0105" num="0107">The RF transceiver <b>302</b> receives, from the antenna <b>301</b>, an incoming RF signal transmitted by an gNB of the network <b>100</b>. The RF transceiver <b>302</b> down-converts the incoming RF signal to generate an IF or baseband signal. The IF or baseband signal is sent to the RX processing circuitry <b>305</b>, which generates a processed baseband signal by filtering, decoding, and/or digitizing the baseband or IF signal. The RX processing circuitry <b>305</b> transmits the processed baseband signal to the speaker <b>306</b> (such as for voice data) or to the processor <b>307</b> for further processing (such as for web browsing data).</p><p id="p-0106" num="0108">The TX processing circuitry <b>303</b> receives analog or digital voice data from the microphone <b>304</b> or other outgoing baseband data (such as web data, e-mail, or interactive video game data) from the processor <b>307</b>. The TX processing circuitry <b>303</b> encodes, multiplexes, and/or digitizes the outgoing baseband data to generate a processed baseband or IF signal. The RF transceiver <b>302</b> receives the outgoing processed baseband or IF signal from the TX processing circuitry <b>303</b> and up-converts the baseband or IF signal to an RF signal that is transmitted via the antenna <b>301</b>.</p><p id="p-0107" num="0109">The processor <b>307</b> can include one or more processors or other processing devices and execute the OS <b>312</b> stored in the memory <b>311</b> in order to control the overall operation of the UE <b>116</b>. For example, the processor <b>307</b> could control the reception of forward channel signals and the transmission of reverse channel signals by the RF transceiver <b>302</b>, the RX processing circuitry <b>305</b>, and the TX processing circuitry <b>303</b> in accordance with well-known principles. In some embodiments, the processor <b>307</b> includes at least one microprocessor or microcontroller.</p><p id="p-0108" num="0110">The processor <b>307</b> is also capable of executing other processes and programs resident in the memory <b>311</b>, such as processes for CSI reporting on uplink channel. The processor <b>307</b> can move data into or out of the memory <b>311</b> as required by an executing process. In some embodiments, the processor <b>307</b> is configured to execute the applications <b>313</b> based on the OS <b>312</b> or in response to signals received from gNBs or an operator. The processor <b>307</b> is also coupled to the I/O interface <b>309</b>, which provides the UE <b>116</b> with the ability to connect to other devices, such as laptop computers and handheld computers. The I/O interface <b>309</b> is the communication path between these accessories and the processor <b>307</b>.</p><p id="p-0109" num="0111">The processor <b>307</b> is also coupled to the touchscreen display <b>310</b>. The user of the UE <b>116</b> can use the touchscreen display <b>310</b> to enter data into the UE <b>116</b>. The touchscreen display <b>310</b> may be a liquid crystal display, light emitting diode display, or other display capable of rendering text and/or at least limited graphics, such as from web sites.</p><p id="p-0110" num="0112">The memory <b>311</b> is coupled to the processor <b>307</b>. Part of the memory <b>311</b> could include RAM, and another part of the memory <b>311</b> could include a Flash memory or other ROM.</p><p id="p-0111" num="0113">Although <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates one example of UE <b>116</b>, various changes may be made to <figref idref="DRAWINGS">FIG. <b>3</b></figref>. For example, various components in <figref idref="DRAWINGS">FIG. <b>3</b></figref> could be combined, further subdivided, or omitted and additional components could be added according to particular needs. As a particular example, the processor <b>307</b> could be divided into multiple processors, such as one or more central processing units (CPUs) and one or more graphics processing units (GPUs). Also, while <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates the UE <b>116</b> configured as a mobile telephone or smartphone, UEs could be configured to operate as other types of mobile or stationary devices.</p><p id="p-0112" num="0114">In one embodiment, the AI/ML techniques can be used for DL channel coding.</p><p id="p-0113" num="0115"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows an example flowchart for BS operation to support AI/ML techniques for DL channel coding according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is an example of a method <b>400</b> for operations at BS side to support AI/ML techniques for DL channel coding. In the process <b>400</b>, at operation <b>401</b>, a BS receives the UE capability information from a UE, including the support of AI/ML approach for channel coding. At operation <b>402</b>, the BS sends the configuration information to UE, which can include related configuration information for AI/ML decoders such as AI/ML model be used, the trained model parameters, input/output dimension of the AI/ML decoder, the input block length, how padding bits are handled and the presence of tailing bits. The AL/ML model parameters and indication approach are described below. In one embodiment, the AI/ML decoder can be configured to operate in specific scenarios which are determined by the type of physical channels (e.g., PDCCH, PUSCH, or PDSCH), the input block length, and the range of received signal-to-noise-ratio (SNR). In another embodiment, the AI/ML decoder can be enabled/disabled via control signaling. The enabling/disabling control message can be sent via DCI, MAC-CE, or RRC signaling. Regarding the model training operation, in one embodiment, the model parameters for cell-specific AI/ML decoder can be pre-trained at BS independent from UE or jointly with one or multiple UEs. In another embodiment, the model parameters for cell-specific AI/ML decoder can be trained at operator deployed test UE. In yet another embodiment, the model parameters for UE-specific AI/ML decoder can be trained/retrained on the fly at UEs using DL transmissions with signaling support. At operation <b>402</b>, the BS encodes the information bits based on the configuration (e.g., adding certain number of tailing bits before the first information bit as the input for the AI/ML based encoder), and performs the encoding based on the configuration as described below. At operation <b>404</b>, the BS transmits the DL channel carrying the encoded bits. At operation <b>405</b>, the BS receives assistance information from one or multiple UEs, such as a UE's preference on which AI/ML model to use for channel coding, requests for model retraining, measured loss value associated with the current AI/ML model, which may be in terms of BER, BLER, or any reliability measure, and loss function to be used for model retraining, etc. For example, UEs can request model training once the variations in channel conditions, such as the change in interference distribution and SNR, or certain level of performance degradations are detected.</p><p id="p-0114" num="0116">In one embodiment for operation <b>402</b>, the configuration from BS can also include a range of transmission block size (TBS) values for AI/ML channel coding/decoding method. For instance, a UE can be configured with a maximum DL TBS for which AI/ML-based channel decoding is used, and the UE assumes conventional non-AI/ML-based channel decoding for TBS greater than configured maximum TBS for AI/ML-based approach.</p><p id="p-0115" num="0117"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows an example flowchart for UE operation to support AI/ML techniques for DL channel coding according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example of a method <b>500</b> for operations at UE side to support AI/ML techniques for DL channel coding. At operation <b>501</b>, a UE reports capability information to BS, including support of AI/ML approach for channel coding. At operation <b>502</b>, the UE receives configuration information, such as AI/ML decoders to be used, the trained model parameters, input/output dimension of the AI/ML decoder, the input block length, how padding bits are handled, the presence of tailing bits, maximum TBS for AI/ML based approach, and the scenarios where the AI/ML decoders should be applied. At operation <b>503</b>, the UE receives the DL transmission, and perform the decoding based on the configuration. At operation <b>504</b>, the UE sends assistance information to BS, e.g., UE's preference on which AI/ML model to be used for channel coding, requests for model retraining, measured loss value associated with the current AI/ML model, which may be in terms of BER, BLER, or any reliability measure, and loss function to be used for model retraining, etc., as is subsequently described below.</p><p id="p-0116" num="0118">In one embodiment, UE receives enabling/disabling control message from BS via DCI, MAC-CE, or RRC signaling. According to the received indication, the UE performs decoding according to the configured AI/ML-based decoder or conventional non-AI/ML-based decoder with corresponding parameters. In the case of DCI, one additional bit field or existing bit field can be used to dynamically indicate the enabling/disabling of AI/ML-based approach regardless of the maximum TBS configured for AI/ML-based channel coding</p><p id="p-0117" num="0119">In one embodiment, the AI/ML techniques can be used for UL channel coding.</p><p id="p-0118" num="0120"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example flowchart for BS operation to support AI/ML techniques for UL channel coding according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is an example of a method <b>600</b> for operations at BS side to support AI/ML techniques for UL channel coding. At operation <b>601</b>, a BS receives the UE capability information from a UE, including the support of AI/ML approach for channel coding. At operation <b>602</b>, the BS sends configuration information to UE, which can include configuration information related to AI/ML encoder such as AI/ML model be used, the trained model parameters, input/output dimension of the AI/ML encoder, the input block length, how padding bits and tailing bits are handled, maximum TBS for AI/ML-based channel coding, and the conditions when AI/ML encoders should be applied. Cell-specific AI/ML encoders can be pre-trained at the BS or operator deployed test UEs using DL transmissions. Alternatively, UE-specific AI/ML encoders can be online trained/retrained at the UEs using UL transmissions. At operation <b>603</b>, the BS receives the UL transmission, and decodes the received signal based on the configuration.</p><p id="p-0119" num="0121">The BS can send enabling/disabling control message for AI/ML-based UL channel coding via DCI, MAC-CE, or RRC signaling. In the case of DCI, one additional bit field or existing bit field can be used in UL DCI types to dynamically indicate the enabling/disabling of AI/ML-based approach regardless of the maximum TBS configured for AI/ML-based channel coding.</p><p id="p-0120" num="0122">In one embodiment for operation <b>602</b>, the configuration from BS can also include a range of UL TBS values for AI/ML-based channel coding/decoding method. For instance, a UE can be configured with a maximum UL TBS for which AWL-based channel encoding is performed, and the UE assumes conventional non-AI/ML-based channel encoding for TBS greater than configured maximum TBS for AI/ML-based approach. This maximum TBS for AI/ML-based channel coding can be configured to be identical for both DL/UL or can be configured separately.</p><p id="p-0121" num="0123"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an example flowchart UE operation to support AI/ML techniques for UL channel coding according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>7</b></figref> is an example of a method <b>700</b> for operations at UE side to support AI/ML techniques for UL channel coding. At operation <b>701</b>, a UE reports its capability information to BS, including the support of AI/ML approach for channel coding. At operation <b>702</b>, the UE receives configuration information, including information related to AI/ML encoders such as AI/ML model be used, the trained model parameters, input/output dimension of the AI/ML encoder, the input block length, how padding bits and tailing bits are handled, the maximum TBS size for AI/ML-based channel coding, and the conditions when AI/ML encoders should be applied. At operation <b>703</b>, the UE encodes the information bits based on the configuration, e.g., adding certain number of tailing bits before the first information bits as the input for the AI/ML based encoder, and performs the encoding based on configuration as described below. At operation <b>704</b>, the UE transmits the UL channel carrying the encoded bits.</p><p id="p-0122" num="0124">In one embodiment, UE receives enabling/disabling control message from BS via DCI, MAC-CE, or RRC signaling. According to the received indication, the UE performs decoding according to the configured AI/ML-based decoder or conventional non-AI/ML-based decoder with corresponding parameters.</p><p id="p-0123" num="0125">For both UL/DL, the AI/ML-based approach can be applied only for encoder or decoder, or applied for both encoder and decoder. The training can be performed only at BS or at UE, or at both BS and UE. Either a UE, a BS, or both UE and BS can send assistance information to each other such as preference on which AI/ML model to be used for channel coding, requests for model retraining, measured loss value associated with the current AI/ML model, which may be in terms of BER, BLER, or any reliability measure, and loss function to be used for model retraining, etc.</p><p id="p-0124" num="0126">A circular input buffer aided encoding operation is defined. The configuration of the AI/ML encoder is presented in <figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref>. <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> depicts the overall architecture of a circular buffer aided AI/ML encoder, while <figref idref="DRAWINGS">FIG. <b>8</b>B</figref> depicts the overall architecture of the <img id="CUSTOM-CHARACTER-00001" he="3.56mm" wi="2.46mm" file="US20230006913A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>th neural network therein. The circular buffer aided AI/ML encoder <b>800</b> of <figref idref="DRAWINGS">FIG. <b>8</b>A</figref> includes neural networks <b>801</b>, <b>802</b> and <b>803</b>, where neural network <b>803</b> is the <img id="CUSTOM-CHARACTER-00002" he="3.56mm" wi="2.46mm" file="US20230006913A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>th neural network depicted in greater detail in <figref idref="DRAWINGS">FIG. <b>8</b>B</figref>. The <img id="CUSTOM-CHARACTER-00003" he="3.56mm" wi="2.46mm" file="US20230006913A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>th neural network <b>803</b> includes extraction layers <b>804</b>, <b>805</b> and <b>806</b> and mapping layers <b>807</b>, <b>808</b> and <b>809</b>.</p><p id="p-0125" num="0127">The configuration and operation of an input circular buffer aided AI/ML encoder <b>800</b> with rate &#x3ba;/<img id="CUSTOM-CHARACTER-00004" he="3.56mm" wi="3.89mm" file="US20230006913A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> and memory length L, respectively. The memory length L implies that the output of the AI/ML encoder is not only determined by the current input but also affected by the previous L inputs. The value of L can be directly calculated based on the AI/ML model or determined via experiments/simulations. For example, if the AI/ML encoder is built with J convolutional layers with the same kernel size ke, L can be directly obtained as ke<sup>j</sup>. If the AI/ML, encoder is built with recurrent layers, L can be obtained via experiments/simulations. The bit sequence input for channel coding is denoted as c<sub>0</sub>, c<sub>1</sub>, c<sub>2</sub>, c<sub>3</sub>, . . . , c<sub>K&#x2212;1</sub>, where K is the number of bits to encode. c<sub>0</sub>, c<sub>1</sub>, c<sub>2</sub>, c<sub>3</sub>, . . . , c<sub>K&#x2212;1 </sub>are grouped into n vectors of size &#x3ba;&#xd7;1, denoted as x(0), x(1), x(2), . . . , x(n&#x2212;1), and input to the AI/ML based encoder, where n is the smallest integer with n&#x3ba;&#x2265;K.</p><p id="p-0126" num="0128"><figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref> illustrate the operation of adding padding bits when input block length K is not a multiple of the input dimension &#x3ba; of the AI/ML encoder. If K is not a multiple of &#x3ba;, padding is performed before input of x(0), x(1), x(2), . . . , x(n&#x2212;1) to the AI/ML encoder, as shown in <figref idref="DRAWINGS">FIGS. <b>9</b>A and <b>9</b>B</figref>. In one embodiment, padding bits can be allocated only to a single vector selected among x(0), x(1), x(2), . . . , x(n&#x2212;1). For example, in padding scheme <b>901</b>, as shown in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>, where &#x3ba;=4, the 2 padding bits are allocated to x(n&#x2212;1), and x(n&#x2212;1) will consist of 2 information bits and 2 padding bits. In another embodiment, padding bits can be distributed among multiple vectors. For example, in padding scheme <b>902</b>, as shown in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, one of the padding bits can be allocated to x(n&#x2212;1), and the other padding bit can be allocated to x(n&#x2212;2). In this case, both x(n&#x2212;1) and x(n&#x2212;2) will consist of 3 information bits and one padding bit.</p><p id="p-0127" num="0129">The AI/ML based encoder <b>800</b> generates an output vector of length <img id="CUSTOM-CHARACTER-00005" he="3.56mm" wi="3.89mm" file="US20230006913A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/> with <img id="CUSTOM-CHARACTER-00006" he="3.56mm" wi="3.56mm" file="US20230006913A1-20230105-P00003.TIF" alt="custom-character" img-content="character" img-format="tif"/> neural networks, such as neural networks <b>801</b>, <b>802</b>, and <b>803</b>, for each input vector of length &#x3ba;, where the <img id="CUSTOM-CHARACTER-00007" he="3.56mm" wi="2.46mm" file="US20230006913A1-20230105-P00001.TIF" alt="custom-character" img-content="character" img-format="tif"/>-th neural network outputs a vector of length <img id="CUSTOM-CHARACTER-00008" he="3.89mm" wi="4.91mm" file="US20230006913A1-20230105-P00004.TIF" alt="custom-character" img-content="character" img-format="tif"/> for every &#x3ba; input bits so that <img id="CUSTOM-CHARACTER-00009" he="4.23mm" wi="6.35mm" file="US20230006913A1-20230105-P00005.TIF" alt="custom-character" img-content="character" img-format="tif"/><img id="CUSTOM-CHARACTER-00010" he="3.89mm" wi="4.91mm" file="US20230006913A1-20230105-P00006.TIF" alt="custom-character" img-content="character" img-format="tif"/>=<img id="CUSTOM-CHARACTER-00011" he="3.56mm" wi="3.89mm" file="US20230006913A1-20230105-P00002.TIF" alt="custom-character" img-content="character" img-format="tif"/>. In one embodiment, one of these neural networks, such as neural network <b>801</b>, can be an identity mapping which generates the systematic output of the encoder. The <img id="CUSTOM-CHARACTER-00012" he="3.56mm" wi="2.46mm" file="US20230006913A1-20230105-P00007.TIF" alt="custom-character" img-content="character" img-format="tif"/>-th neural network consists of <img id="CUSTOM-CHARACTER-00013" he="3.56mm" wi="4.23mm" file="US20230006913A1-20230105-P00008.TIF" alt="custom-character" img-content="character" img-format="tif"/> feature extraction layers, such as feature extraction layers <b>804</b>, <b>805</b>, and <b>806</b>, and <img id="CUSTOM-CHARACTER-00014" he="3.56mm" wi="4.23mm" file="US20230006913A1-20230105-P00009.TIF" alt="custom-character" img-content="character" img-format="tif"/> mapping layers, such as feature extraction layers <b>807</b>, <b>808</b>, and <b>809</b>. Each of the <img id="CUSTOM-CHARACTER-00015" he="3.56mm" wi="4.23mm" file="US20230006913A1-20230105-P00010.TIF" alt="custom-character" img-content="character" img-format="tif"/> feature extraction layers, such as feature extraction layer <b>804</b>, can be a convolutional layer with the number of filters f<sub>j</sub>, kernel size ke<sub>j</sub>, stride s<sub>j </sub>and the number of padding elements pd<sub>j</sub>, a layer of <img id="CUSTOM-CHARACTER-00016" he="3.56mm" wi="4.91mm" file="US20230006913A1-20230105-P00011.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>,j </sub>(j&#x2208;{1, . . . , <img id="CUSTOM-CHARACTER-00017" he="3.56mm" wi="4.23mm" file="US20230006913A1-20230105-P00012.TIF" alt="custom-character" img-content="character" img-format="tif"/>}) recurrent units (e.g., gated recurrent units (GRU), recurrent neural network (RNN), long short-term memory (LSTM)), or any other type of layer. Each of the <img id="CUSTOM-CHARACTER-00018" he="3.56mm" wi="4.23mm" file="US20230006913A1-20230105-P00013.TIF" alt="custom-character" img-content="character" img-format="tif"/> mapping layers, such as mapping layer <b>807</b>, can be a fully connected layer with <img id="CUSTOM-CHARACTER-00019" he="3.56mm" wi="4.91mm" file="US20230006913A1-20230105-P00014.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>,j </sub>neurons, a quantization layer, or any other type of layer. The first feature extraction layer <b>804</b> accepts a length <img id="CUSTOM-CHARACTER-00020" he="3.89mm" wi="7.79mm" file="US20230006913A1-20230105-P00015.TIF" alt="custom-character" img-content="character" img-format="tif"/> vector as input and the last feature extraction layer <b>806</b> output a vector of length <img id="CUSTOM-CHARACTER-00021" he="3.89mm" wi="2.79mm" file="US20230006913A1-20230105-P00016.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>F</sub><sub><sub2>A</sub2></sub><sub>,out</sub>, where <img id="CUSTOM-CHARACTER-00022" he="3.89mm" wi="7.79mm" file="US20230006913A1-20230105-P00017.TIF" alt="custom-character" img-content="character" img-format="tif"/>=(n+L&#x2032;&#x2212;1)&#x3ba; if the first feature extraction layer <b>804</b> is a convolutional layer and <img id="CUSTOM-CHARACTER-00023" he="3.89mm" wi="7.79mm" file="US20230006913A1-20230105-P00018.TIF" alt="custom-character" img-content="character" img-format="tif"/>=&#x3ba; if the first feature extraction layer <b>804</b> is a recurrent layer. <img id="CUSTOM-CHARACTER-00024" he="3.56mm" wi="4.57mm" file="US20230006913A1-20230105-P00019.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>,out</sub>=<img id="CUSTOM-CHARACTER-00025" he="3.56mm" wi="4.91mm" file="US20230006913A1-20230105-P00020.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>,in</sub>, where <img id="CUSTOM-CHARACTER-00026" he="3.56mm" wi="4.91mm" file="US20230006913A1-20230105-P00021.TIF" alt="custom-character" img-content="character" img-format="tif"/><sub>,in </sub>is the length of the input vector of the first mapping layer <b>807</b>. The last mapping layer <b>809</b> output a vector of length <img id="CUSTOM-CHARACTER-00027" he="3.56mm" wi="7.79mm" file="US20230006913A1-20230105-P00022.TIF" alt="custom-character" img-content="character" img-format="tif"/> as the encoding results of the <img id="CUSTOM-CHARACTER-00028" he="3.56mm" wi="2.79mm" file="US20230006913A1-20230105-P00023.TIF" alt="custom-character" img-content="character" img-format="tif"/>-th neural network. For example, <img id="CUSTOM-CHARACTER-00029" he="3.56mm" wi="7.79mm" file="US20230006913A1-20230105-P00024.TIF" alt="custom-character" img-content="character" img-format="tif"/>=(n+l&#x2032;&#x2212;1)<img id="CUSTOM-CHARACTER-00030" he="3.89mm" wi="4.91mm" file="US20230006913A1-20230105-P00025.TIF" alt="custom-character" img-content="character" img-format="tif"/> if the <img id="CUSTOM-CHARACTER-00031" he="3.56mm" wi="2.79mm" file="US20230006913A1-20230105-P00026.TIF" alt="custom-character" img-content="character" img-format="tif"/>-th neural network is built with convolutional neural networks (CNNs) and <img id="CUSTOM-CHARACTER-00032" he="3.56mm" wi="7.79mm" file="US20230006913A1-20230105-P00027.TIF" alt="custom-character" img-content="character" img-format="tif"/>=<img id="CUSTOM-CHARACTER-00033" he="3.89mm" wi="4.91mm" file="US20230006913A1-20230105-P00028.TIF" alt="custom-character" img-content="character" img-format="tif"/> if the <img id="CUSTOM-CHARACTER-00034" he="3.56mm" wi="2.79mm" file="US20230006913A1-20230105-P00029.TIF" alt="custom-character" img-content="character" img-format="tif"/>-th neural network is built with RNNs. In one embodiment, the elements of the vector output from the last mapping layer <b>809</b> can be continuous-valued. In another embodiment, the elements of the vector output from the last mapping layer <b>809</b> can be quantized to discrete values.</p><p id="p-0128" num="0130">Before input to the encoder, the last L&#x2032;&#x2212;1 vectors x(n&#x2212;L&#x2032;&#x2212;2), . . . , x(n&#x2212;1) are added to the beginning of the sequence x(0), x(1), x(2), . . . , x(n&#x2212;1) to obtain the sequence x(n&#x2212;L&#x2032;&#x2212;2), . . . , x(n&#x2212;1), x(0), x(1), x(2), . . . , x(n&#x2212;1). L&#x2032; is determined by the memory length of the AI/ML based encoder. In one embodiment, L&#x2032; can be set to L&#x2212;1 if L is exactly known, for example, via directly calculation if the AI/ML based encoder is built with CNNs or through experiments/simulations if the AI/ML based encoder is built with RNNs. In another embodiment, L&#x2032; can be set to {circumflex over (L)}&#x2212;1 or n&#x2212;1, where {circumflex over (L)} is an upper bound on the memory length of the AI/ML encoder. x(n&#x2212;L&#x2032;&#x2212;2), . . . , x(n&#x2212;1), x(0), x(1), x(2), . . . , x(n&#x2212;1) are either sequentially or simultaneously input to the AI/ML encoder. For example, x(n&#x2212;L&#x2032;&#x2212;2), . . . , x(n&#x2212;1), x(0), x(1), x(2), . . . , x(n&#x2212;1) are sequentially input to the AI/ML encoder if the AI/ML encoder is built with RNNs and simultaneously input to the AI/ML encoder if the AI/ML encoder is built with CNNs. After AI/ML based encoding, the last n&#x2212;1 vectors y(L), . . . , y(n+L&#x2212;2) are taken from y(0), . . . , y(n+L&#x2212;2) as the output of the AI/ML based encoder. In comparison to the normal AI/ML based encoder, the input bits will have balanced contribution and protection when the input circular buffer aided AI/ML encoder is used, as shown in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, which depicts the operation of an input circular buffer aided encoding when L&#x2032;=L.</p><p id="p-0129" num="0131">Information content for AI/ML model parameters</p><p id="p-0130" num="0132">The AI/ML model parameters related to channel coding (e.g., at operations <b>502</b>, <b>502</b>, <b>602</b>, or <b>702</b>) can include one or multiple of the following information.</p><p id="p-0131" num="0133">Enabling/disabling of ML approach for different physical channels and block sizes</p><p id="p-0132" num="0134">In one embodiment, the configuration information can include whether AI/ML techniques for certain physical channels and block sizes is enabled or disabled. One or multiple physical channel and block size combinations can be predefined. For example, there can be K predefined combinations, with index 1, 2, . . . , K corresponding to one combination such as &#x201c;PDSCH and less than 1000 bits&#x201d;, &#x201c;PDCCH and less than 500 bits&#x201d;, etc., respectively. The configuration can indicate the indexes of the combinations which are enabled, or there can be a Boolean parameter to enable or disable the AI/ML approach for each combination.</p><p id="p-0133" num="0135">ML Model to be Used</p><p id="p-0134" num="0136">In one embodiment, the configuration information can include which AI/ML model to be used for certain operation/use case. For example, there can be M predefined ML models, with index 1, 2, . . . , M corresponding to one ML model defined by the configuration of the encoder and/or decoder. In one example, the ML model can be associated with L&#x2032;, including the case where L&#x2032;=0. Alternatively, L&#x2032; can be separately indicated. TABLE 1 provides an example of this embodiment. One or more columns in TABLE 1 can be optional and directly sent, instead of being indicated through the table index, in different embodiments.</p><p id="p-0135" num="0000"><tables id="TABLE-US-00001" num="00001"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 1</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Example of configurations of the ML models.</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="28pt" align="center"/><colspec colname="2" colwidth="119pt" align="left"/><colspec colname="3" colwidth="126pt" align="left"/><tbody valign="top"><row><entry>Model</entry><entry>Encoder</entry><entry>Decoder</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row><row><entry>1</entry><entry>Systematic output, continuous-valued</entry><entry>Systematic components, continuous-</entry></row><row><entry/><entry>output, number of neural networks,</entry><entry>valued input, number of neural networks,</entry></row><row><entry/><entry>the configuration of each neural</entry><entry>the configuration of each neural network</entry></row><row><entry/><entry>network (e.g., number of</entry><entry>(e.g., number of convolutional layers for</entry></row><row><entry/><entry>convolutional layers for each neural</entry><entry>each neural network, kernel size and</entry></row><row><entry/><entry>network, kernel size and stride for</entry><entry>stride for each convolutional layer,</entry></row><row><entry/><entry>each convolutional layer, number of</entry><entry>number of fully connected layers,</entry></row><row><entry/><entry>fully connected layers, number of</entry><entry>number of neurons in each layer), etc.</entry></row><row><entry/><entry>neurons in each layer), etc.</entry></row><row><entry>2</entry><entry>No systematic output, L&#x2032;, discretized</entry><entry>No systematic component, L&#x2032;, discretized</entry></row><row><entry/><entry>output, number of neural networks,</entry><entry>input, number of neural networks, the</entry></row><row><entry/><entry>the configuration of each neural</entry><entry>configuration of each neural network</entry></row><row><entry/><entry>network (e.g., number of</entry><entry>(number of convolutional layers for each</entry></row><row><entry/><entry>convolutional layers for each neural</entry><entry>neural network, kernel size and stride for</entry></row><row><entry/><entry>network, kernel size and stride for</entry><entry>each convolutional layer, deinterleaver,</entry></row><row><entry/><entry>each convolutional layer, interleaved</entry><entry>number of fully connected layers,</entry></row><row><entry/><entry>input, number of fully connected</entry><entry>number of neurons in each layer), etc.</entry></row><row><entry/><entry>layers, number of neurons in each</entry></row><row><entry/><entry>layer), etc.</entry></row><row><entry>3</entry><entry>Systematic output, L&#x2032;, discretized</entry><entry>Systematic components, L&#x2032;, discretized</entry></row><row><entry/><entry>output, number of neural networks,</entry><entry>input, number of neural networks, the</entry></row><row><entry/><entry>the configuration of each neural</entry><entry>configuration of each neural network</entry></row><row><entry/><entry>network (e.g., number of recurrent</entry><entry>(e.g., number of recurrent layers, number</entry></row><row><entry/><entry>layers, number of GRUs in each</entry><entry>of GRUs in each recurrent layer, number</entry></row><row><entry/><entry>recurrent layer, number of fully</entry><entry>of fully connected layers, number of</entry></row><row><entry/><entry>connected layers, number of neurons</entry><entry>neurons in each layer), etc.</entry></row><row><entry/><entry>in each layer), etc.</entry></row><row><entry>. . .</entry><entry>. . .</entry><entry>. . .</entry></row><row><entry>M</entry><entry>No systematic output, continuous-</entry><entry>No systematic components, continuous-</entry></row><row><entry/><entry>valued output, number of neural</entry><entry>valued input, number of neural networks,</entry></row><row><entry/><entry>networks, the configuration of each</entry><entry>the configuration of each neural network</entry></row><row><entry/><entry>neural network (e.g., number of</entry><entry>(e.g., number of recurrent layers, number</entry></row><row><entry/><entry>recurrent layers, number of LSTM</entry><entry>of LSTM units in each recurrent layer,</entry></row><row><entry/><entry>units in each recurrent layer, number</entry><entry>number of fully connected layers,</entry></row><row><entry/><entry>of fully connected layers, number of</entry><entry>number of neurons in each layer), etc.</entry></row><row><entry/><entry>neurons in each layer), etc.</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0136" num="0137">Model Parameters</p><p id="p-0137" num="0138">The configuration information can include the model parameters of ML algorithms. In another embodiment, the parameters of the ML model can be either directly sent or indicated through the index in a predefined table. For example, there can be K predefined operation modes, where each mode corresponding to certain operation/use case (e.g., the physical channel and block sizes combination) with certain ML model. One or more modes can be configured. TABLE 2 provides an example of this embodiment, where the configuration information can include one or multiple mode indexes to enable the parameter settings of ML encoder/decoder. One or more columns in TABLE 2 can be optional in different embodiments.</p><p id="p-0138" num="0000"><tables id="TABLE-US-00002" num="00002"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 2</entry></row></thead><tbody valign="top"><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Example of AI/ML operation modes, where different operations/use cases,</entry></row><row><entry>ML models and/or corresponding key model parameters can be predefined</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="4"><colspec colname="1" colwidth="28pt" align="center"/><colspec colname="2" colwidth="91pt" align="left"/><colspec colname="3" colwidth="28pt" align="center"/><colspec colname="4" colwidth="112pt" align="left"/><tbody valign="top"><row><entry/><entry/><entry>ML</entry><entry/></row><row><entry>Mode</entry><entry>Operation/use case</entry><entry>model</entry><entry>Parameters</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row><row><entry>1</entry><entry>PDSCH, less than 1000 bits</entry><entry>2</entry><entry>Weights and bias for connection</entry></row><row><entry/><entry/><entry/><entry>between neurons in different layers,</entry></row><row><entry/><entry/><entry/><entry>activation function, etc.</entry></row><row><entry>2</entry><entry>PDSCH, larger than 1000</entry><entry>3</entry><entry>Weights and bias for connection</entry></row><row><entry/><entry>bits</entry><entry/><entry>between neurons in different layers,</entry></row><row><entry/><entry/><entry/><entry>activation function, etc.</entry></row><row><entry>3</entry><entry>PDCCH, less than 500 bits</entry><entry>M</entry><entry>Weights and bias for connection</entry></row><row><entry/><entry/><entry/><entry>between neurons in different layers,</entry></row><row><entry/><entry/><entry/><entry>activation function, etc.</entry></row><row><entry>. . .</entry><entry>. . .</entry><entry>. . .</entry><entry>. . .</entry></row><row><entry>K</entry><entry>PUCCH, larger than 500 bits</entry><entry>1</entry><entry>Weights and bias for connection</entry></row><row><entry/><entry/><entry/><entry>between neurons in different layers,</entry></row><row><entry/><entry/><entry/><entry>activation function, etc.</entry></row><row><entry namest="1" nameend="4" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0139" num="0139">Signaling Method</p><p id="p-0140" num="0140">In one embodiment, part of or all the configuration information can be broadcasted as a part of cell-specific information, for example by system information such as master information block (MIB), system information block 1 (SIB1) or other SIBs. For example, the configuration information for AI/ML approaches for channel coding can be carried as part of SIB3 and/or SIB4. Alternatively, a new SIB can be introduced for the indication of configuration information. For example, the enabling/disabling of ML approach, ML model and/or model parameters for certain physical channels and block sizes can be broadcasted. In other examples, multiple modes can be configured. In another example, the updates of model parameters can be broadcasted. In yet another example, the configuration information of neighboring cells, e.g., the enabling/disabling of ML approach, ML model and/or model parameters for certain physical channels and block sizes of neighboring cells, can be indicated as part of the system information, e.g., in MIB, SIB1, SIB3, SIB4 or other SIBs. In another embodiment, part of or all the configuration information can be sent by UE-specific signaling. The configuration information can be common among all configured DL/UL bandwidth parts (BWPs) or can be BWP-specific. For example, the UE-specific radio resource control (RRC) signaling, such as an information element (IE) PDSCH-ServingCellConfig or an IE PDSCH-Config in IE BWP-DownlinkDedicated, can include configuration of enabling/disabling ML approach for channel coding, which ML model to be used and/or model parameters. In yet another embodiment, part of or all the configuration information can be sent by group-specific signaling. A UE group-specific radio network temporary identifier (RNTI) can be configured, e.g., using value 0001-FFEF or the reserved value FFF0-FFFD. The group-specific RNTI can be configured via UE-specific RRC signaling.</p><p id="p-0141" num="0141">UE Assistance Information</p><p id="p-0142" num="0142">The UE assistance information related to AI/ML techniques (e.g., at operations <b>405</b> or <b>504</b>) can include one or multiple of the information, such as hybrid automatic repeat request acknowledgement (HARQ-ACK) feedback, CSI report, and/or new information such as UE's preference on which AI/ML model to be used for channel coding, requests for model retraining, and loss function to be used for model retraining, etc.</p><p id="p-0143" num="0143">For connected mode UEs, the report of the assistance information can be via PUCCH and/or PUSCH. A new UCI type, a new PUCCH format and/or a new MAC CE can be defined for the assistance information report.</p><p id="p-0144" num="0144">Regarding the triggering method, in one embodiment, the report can be triggered periodically, e.g., via UE-specific RRC signaling. In another embodiment, the report can be semi-persistence or aperiodic. For example, the report can be triggered by the DCI, where a new field (e.g., 1-bit triggering field) can be introduced to the DCI for the report triggering. In one example, an IE similar to IE CSI-ReportConfig can be introduced for the report configuration of UE assistance information to support AI/ML based channel coding. In yet another embodiment, the report can be triggered via certain event. For example, the UE can report its preference on DL AI/ML based channel code selection in case of measured reference signal received power (RSRP) going below a certain threshold. Whether UE should report its preference on AI/ML model selection can additionally depend on the configuration, e.g., configuration via RRC signaling regarding whether the UE needs to report the updates on its preferred AI/ML model. TABLE 3 provides an example of the IE for the configuration of UE assistance information report, where whether the report is periodic or semi-persistence or aperiodic, the resources for the report transmission, and/or report contents can be included. For the &#x2018;model-channelcoding&#x2019;, the UE assistance information report is given as an example that a set of AI/ML based channel coding schemes are predefined, and UE can report one of this via the index L1, L2, etc. However, other methods for report of UE's preference on AI/ML based channel coding schemes are not excluded.</p><p id="p-0145" num="0000"><tables id="TABLE-US-00003" num="00003"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 3</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>Example of IE for configuration of UE assistance information report for support of</entry></row><row><entry>AI/ML based channel coding.</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="left"/><tbody valign="top"><row><entry>MlReport-ReportConfig ::=&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportConfigId&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;&#x2003;&#x2003;&#x2003;MlReport-ReportConfigId,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportConfigType &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CHOICE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;periodic &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003; SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;MlReport-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;pucch-MlReport-ResourceList &#x2003;&#x2003; SEQUENCE&#x2003;&#x2003;&#x2003;(SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofBWPs)) OF PUCCH-MlReport-Resource</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;semiPersistentOnPUCCH&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;MlReport-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;pucch-MlReport-ResourceList &#x2003;&#x2002;&#x2003;SEQUENCE&#x2003;&#x2003;&#x2003;(SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofBWPs)) OF PUCCH-MlReport-Resource</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;semiPersistentOnPUSCH &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;ENUMERATED</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;{sl5, sl10, sl20, sl40, sl80, sl160, sl320},</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;reportSlotOffsetList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE&#x2003;(SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofUL-Allocations)) OF INTEGER(0..32),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;p0alpha&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;P0-PUSCH-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;AlphaSetId</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;aperiodic &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;reportSlotOffsetList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE&#x2003;&#x2003;&#x2003;(SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofUL-Allocations)) OF INTEGER(0..32)</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;}</entry></row><row><entry>&#x2003;&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportQuantity &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CHOICE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;none &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;NULL, </entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;model-channelcoding &#x2003;&#x2003;&#x2003;&#x2003; ENUMERATED {L1, L2, ...}</entry></row><row><entry>&#x2003;&#x2003;&#x2003;},</entry></row><row><entry>MlReport-ReportPeriodicityAndOffset ::= &#x2002;CHOICE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots4 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..3),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots5 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..4),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots8 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..7),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots10 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;INTEGER(0..9),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots16 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;INTEGER(0..15),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots20 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;INTEGER(0..19),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots40 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;INTEGER(0..39),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots80 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;INTEGER(0..79),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots160 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..159),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;slots320 &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..319)</entry></row><row><entry>} </entry></row><row><entry>PUCCH-mIReport-Resource ::= &#x2003;&#x2003;&#x2003;&#x2002;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;uplinkBandwidthPartId &#x2003;&#x2003;&#x2003;&#x2003;BWP-Id,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;pucch-Resource &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;PUCCH-Resourceld</entry></row><row><entry>}</entry></row><row><entry>}</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0146" num="0145">In one embodiment, a channel environment can be classified in terms of UE speed (or, similarly, Doppler spread) and/or frequency selectivity (or, similarly, delay spread). In another embodiment, a channel environment can be classified in terms of coherence bandwidth and/or coherence time. As an example, one possible categorization can be done for four classes comprising of low Doppler spread-low delay spread class, high Doppler spread-low delay spread case, low Doppler spread-high delay spread case, and high Doppler spread-high delay spread case.</p><p id="p-0147" num="0146">Multiple channel environment classes can be defined with the above-mentioned attributes or in conjunction with other parameters such as RRM metrics, such as RSRP, RSRQ, and SINR. The channel environment classification can be done according to any combination of attributes aforementioned.</p><p id="p-0148" num="0147">In one embodiment, the framework for supporting AI/ML techniques for channel environment classification can include model training at a UE or a network entity or outside of the network (e.g., via offline training), and model inference operations at a UE.</p><p id="p-0149" num="0148"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows an example flowchart for BS operation to support UE information on channel environments according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is an example of a method <b>1100</b> for operations at a BS to support AI/ML techniques for channel environment classification where a UE sends information on a particular channel environment. At operation <b>1101</b>, the BS receives UE capability information from the UE, including the support of an ML approach for channel environment classification. At operation <b>10102</b>, the BS sends configuration information to the UE, which can include ML-related configuration information such as enabling/disabling of an ML approach for channel environment classification, an ML model to be used, trained model parameters, and/or whether model parameter updates reported by the UE will be used or not; this information will be described below. Also, the BS may send configuration information for the UE to provide channel environment reports to the BS, which can contain the UL report channel format, resource, aperiodic/periodic/semi-persistent configuration, periodicity, etc., as presented later with exemplary configuration IEs (Information Elements). At operation <b>1103</b>, the BS receives information on a channel environment from the UE, where the message can work as a recommendation to the BS for making any operational decisions such as scheduling or any kinds of adaptation. In one example, information can consist of an index to a pre-defined lookup table of channel environments. In another example, information can consist of a value for the DL RS density in time and/or frequency. In yet another example, information can consist of a recommendation for handover to another BS, a recommendation for transmission mode, a recommendation for scheduled time/frequency resource, a recommendation for MIMO beamforming adjustment from the current served beams, etc., along with the feedback on the inferred channel environment classification.</p><p id="p-0150" num="0149"><figref idref="DRAWINGS">FIG. <b>12</b></figref> shows an example flowchart for UE operation to support UE information on channel environments according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is an example of a method <b>1200</b> for operations at a UE to support AI/ML techniques for channel environment classification where the UE sends information on a particular channel environment. At operation <b>1201</b>, the UE reports capability information to a BS, including the support of an ML approach for channel environment classification. At operation <b>1202</b>, the UE receives configuration information from the BS, which can include ML-related configuration information such as enabling/disabling of an ML approach for channel environment classification, an ML model to be used, trained model parameters, and/or whether model parameter updates reported by the UE will be used or not; this information will be described below. Also, the UE may receive configuration information for the UE to send channel environment reports to the BS, which can contain the UL report channel format, resource, aperiodic/periodic/semi-persistent configuration, periodicity, etc., as presented later along with exemplary configuration IEs. At operation <b>1203</b>, the UE performs model training, or receives model parameters from a network entity. In one embodiment, model training can be performed at the UE. Alternatively, model training can be performed at another network entity (e.g., the O-RAN defined RAN Intelligent Controller), and trained model parameters can be sent to the UE. In yet another embodiment, model training can be performed offline (e.g., model training is performed outside of the network), and the trained model parameters can be sent to the UE by the network entity, or may be stored inside the UE. At operation <b>1204</b>, the UE sends information on a channel environment to the BS, which the UE may obtain through ML inference operations based on the ML model parameters. The message can work as a recommendation to the BS for making any operational decisions such as scheduling or any kinds of adaptation. In one example, information can consist of an index to a pre-defined lookup table of channel environments. In another example, information can consist of a value for the DL RS density in time and/or frequency. In yet another example, information can consist of a recommendation for handover to another BS, a recommendation for transmission mode, a recommendation for scheduled time/frequency resource, a recommendation for MIMO beamforming adjustment from the current served beams, etc., along with the feedback on the inferred channel environment classification.</p><p id="p-0151" num="0150">As an operation example, a UE can be configured with possible categories for channel environment classification, and a method for classification. In order for the BS to have reasonable expectation on the performance of UE inference on the channel environment classification, the network can configure a UE with an AI/ML model and related parameters for channel environment classification. Alternatively, the performance of UE inference can be UE's own implementation without configuring AI/ML model and related parameters. In one example, UE's own implemented algorithm can be tested to be verified to meet a certain performance requirement.</p><p id="p-0152" num="0151">In another embodiment, the framework for supporting AI/ML techniques for channel environment classification can include model training at a BS or a network entity or outside of the network (e.g., via offline training), and model inference operations at the BS or a network entity.</p><p id="p-0153" num="0152"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows an example flowchart for BS operation to support BS determination of channel environment according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>13</b></figref> is an example of a method <b>1300</b> for operations at a BS to support AI/ML techniques for channel environment classification where the BS determines a particular channel environment. At operation <b>1301</b>, the BS receives UE capability information from a UE, including the support of an ML approach for channel environment classification. At operation <b>1302</b>, the BS sends configuration information to the UE, which can include ML-related configuration information such as enabling/disabling of an ML approach for channel environment classification, an ML model to be used, trained model parameters, and/or whether model parameter updates reported by the UE will be used or not; this information will be described below. At operation <b>1303</b>, the BS performs model training, or receives model parameters from a network entity. In one embodiment, model training can be performed at the BS. Alternatively, model training can be performed at another network entity (e.g., the O-RAN defined RAN Intelligent Controller), and trained model parameters can be sent to the BS. In yet another embodiment, model training can be performed offline (e.g., model training is performed outside of the network), and the BS may receive the trained model parameters from a network entity or may have them stored in memory inside the BS. At operation <b>1304</b>, the BS receives assistance information from the UE; the assistance information can include information to be used for model inference, which will be described below. At operation <b>1305</b>, the BS performs model inference or receives a model inference result from a network entity. At operation <b>1306</b>, the BS sends configuration information to the UE. In one example, a configuration message can include an index to a pre-defined lookup table for a transmission mode. In another example, a configuration message can include an index to a pre-defined lookup table for an RS pattern. In yet another example, information can consist of a BS handover command, a recommendation for transmission mode, a recommendation for scheduled time/frequency resource, a recommendation for MIMO beamforming adjustment from the current served beams, etc., along with the feedback on the inferred channel environment classification.</p><p id="p-0154" num="0153"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows an example flowchart for UE operation to support BS determination of channel environment according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is an example of a method <b>1400</b> for operations at a UE to support AI/ML techniques for channel environment classification where a BS determines a particular channel environment. At operation <b>1401</b>, the UE reports capability information to the BS, including the support of an ML approach for channel environment classification. At operation <b>1402</b>, the UE receives configuration information from the BS, which can include ML-related configuration information such as enabling/disabling of an ML approach for channel environment classification, an ML model to be used, trained model parameters, and/or whether model parameter updates reported by the UE will be used or not; this information will be described below. At operation <b>1403</b>, the UE sends assistance information to the BS; the assistance information can include information to be used for model inference, which will be described below. At operation <b>1404</b>, the UE receives configuration information from the BS. In one example, a configuration message can include an index to a pre-defined lookup table for a transmission mode. In another example, a configuration message can include an index to a pre-defined lookup table for an RS pattern. In yet another example, information can consist of a BS handover command, a recommendation for transmission mode, a recommendation for scheduled time/frequency resource, a recommendation for MIMO beamforming adjustment from the current served beams, etc., along with the feedback on the inferred channel environment classification.</p><p id="p-0155" num="0154">The index of an indicated channel environment can be used to retrieve a pre-defined channel environment from a lookup table. One example of a pre-defined channel environment is a &#x201c;low-speed rural&#x201d; environment, where the coherence time and the coherence bandwidth are both large. Another example of a pre-defined channel environment is a &#x201c;high-speed urban&#x201d; environment, where the coherence time and the coherence bandwidth are both small. The geographical characteristics, such as rural or urban, can be known by the network from the serving cell location or positioning method. In yet another example, the environmental attributes can be more specific to the given area. For instance, the environment can be elevation of UE in an urban area, UE mobility, multi-path delay spread, type of conveyance such as vehicle or high speed train, etc., and/or UE moving trajectory.</p><p id="p-0156" num="0155">The UE channel environment can be reported via the PUCCH and/or the PUSCH. A new UCI type, a new PUCCH format and/or a new MAC CE can be defined for the UE channel environment report. The report can be based on an indexing of pre-configured category of channel environments along with other attributes related to the channel environment as exemplified earlier.</p><p id="p-0157" num="0156">In one embodiment, the UE channel environment report can be triggered periodically, e.g., via UE-specific RRC signaling. In another embodiment, the UE channel environment report can be semi-persistent or aperiodic. For example, the UE channel environment report can be triggered by the DCI, where a new field (e.g., 1-bit triggering field) can be introduced to the DCI for report triggering. In one example, an IE similar to the CSI-ReportConfig IE can be introduced for configuring the UE channel environment report. In another embodiment, the report can be triggered only when there is an environmental change. For instance, after an initial report is made on the channel environment classification, the second and the following reports are sent if there is a change on the inferred channel environment from the previous report.</p><p id="p-0158" num="0157">The capability of UE to determine channel environment can be integrated with various use cases, where the UE can be configured to take actions based on the channel environment and communicate that with BS. An example of the signaling for a specific use case of CSI feedback is explained in detail in the embodiment below.</p><p id="p-0159" num="0158">The UE channel environment report can also include recommendations for particular use cases. One example of a recommendation is the DL RS pattern, e.g., the time/frequency density of DL RS. Another example of a recommendation is the DL transmission mode, e.g. spatial multiplexing, transmit diversity, etc. Yet another example of a recommendation concerns handover to another BS, a recommendation for transmission mode, a recommendation for scheduled time/frequency resource, a recommendation for MIMO beamforming adjustment from the current served beams, etc., along with the feedback on the inferred channel environment classification.</p><p id="p-0160" num="0159">The BS can utilize the channel environment report, which can include recommendations for particular use cases, to adapt the BS' transmission and/or reception parameters. For example, the BS can increase the temporal density of DL RS if the coherence time of the channel decreases. In another example, the BS can switch the DL transmission mode from transmit diversity to spatial multiplexing if the coherence time and the coherence bandwidth of the channel increases. In yet another example, the BS can issue a BS handover command, change transmission mode, change time/frequency resource for scheduling, update MIMO beam directions, etc.</p><p id="p-0161" num="0160">TABLE 4 provides an example of the IE for configuring the UE channel environment report, where whether the report is periodic or semi-persistent or aperiodic, the resources for the report transmission, and/or report contents can be included. For the &#x2018;Chan-Env&#x2019;, a set of UE channel environments is predefined in this example; the UE can report one of these channel environments via the index E1, E2, etc.</p><p id="p-0162" num="0000"><tables id="TABLE-US-00004" num="00004"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 4</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>An example of IE for configuration of UE channel environment report</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="left"/><tbody valign="top"><row><entry>ChEnvReport-ReportConfig ::=&#x2003;&#x2003;&#x2003; SEQUENCE {</entry></row><row><entry>&#x2003;reportConfigId&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ChEnvReport-ReportConfigId,</entry></row><row><entry>&#x2003;reportConfigType&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;&#x2009;CHOICE {</entry></row><row><entry>&#x2003;&#x2003;periodic&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotConfig&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;ChEnvReport-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;pucch-ChEnvReport-ResourceList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;SEQUENCE&#x2003;&#x2003;&#x2003;(SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofBWPs))&#x2003;OF&#x2003;PUCCH-ChEnvReport-Resource</entry></row><row><entry>&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;semiPersistentOnPUCCH&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotConfig&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;ChEnvReport-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;pucch-ChEnvReport-ResourceList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE&#x2003;(SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofBWPs))&#x2003;OF&#x2003;PUCCH-ChEnvReport-Resource</entry></row><row><entry>&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;semiPersistentOnPUSCH&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotConfig&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ENUMERATED {sl5,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;sl10, sl20, sl40, sl80, sl160, sl320},</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotOffsetList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE (SIZE (1..</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;maxNrofUL-Allocations))&#x2003;OF&#x2003;INTEGER(0..32),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;p0alpha&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;P0-PUSCH-AlphaSetId</entry></row><row><entry>&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;aperiodic&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotOffsetList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE&#x2003;(SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofUL-Allocations)) OF INTEGER(0..32)</entry></row><row><entry>&#x2003;&#x2003;&#x2003;}</entry></row><row><entry>&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportQuantity&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;CHOICE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;none&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;NULL,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;Chan-Env &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ENUMERATED {El, E2, ...}</entry></row><row><entry>&#x2003;&#x2003;&#x2003;}, </entry></row><row><entry>ChEnvReport-ReportPeriodicityAndOffset ::=&#x2003;&#x2003;&#x2003;&#x2003;CHOICE {</entry></row><row><entry>&#x2003;&#x2003;slots4&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..3),</entry></row><row><entry>&#x2003;&#x2003;slots5&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..4),</entry></row><row><entry>&#x2003;&#x2003;slots8&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..7),</entry></row><row><entry>&#x2003;&#x2003;slots10&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;&#x2003;&#x2003;INTEGER(0..9),</entry></row><row><entry>&#x2003;&#x2003;slotsl6&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;&#x2003;&#x2003;INTEGER(0..15),</entry></row><row><entry>&#x2003;&#x2003;slots20&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;&#x2003;&#x2003;INTEGER(0..19),</entry></row><row><entry>&#x2003;&#x2003;slots40&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;&#x2003;&#x2003;INTEGER(0..39),</entry></row><row><entry>&#x2003;&#x2003;slots80&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;&#x2003;&#x2003;INTEGER(0..79),</entry></row><row><entry>&#x2003;&#x2003;slotsl60&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..159),</entry></row><row><entry>&#x2003;&#x2003;slots320&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..319)</entry></row><row><entry>}</entry></row><row><entry>PUCCH-ChEnvReport-Resource ::=&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;SEQUENCE {</entry></row><row><entry>&#x2003;uplinkBandwidthPartId&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;BWP-Id,</entry></row><row><entry>&#x2003;pucch-Resource&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;PUCCH-ResourceId</entry></row><row><entry>}</entry></row><row><entry>}</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0163" num="0161">The UE assistance information report offers several advantages over relying on existing signaling. For example, a BS can use SRS to estimate the UL (and DL, depending on reciprocity) channel from a UE. The minimum periodicity of SRS is 2 milliseconds (ms), though; in contrast, the spacing between consecutive DMRS can be configured to be less than 1 ms. Thus, a UE can perform finer-grained measurements of the DL channel using received DMRS, compared to a BS measuring the UL channel using received SRS.</p><p id="p-0164" num="0162">As another example, a UE can report local information that may not be available to a BS. A UE can use the UE's camera(s) to detect an oncoming vehicle that will cross the UE's line-of-sight with a BS in T seconds. A UE can then report this information to a BS and make a pre-emptive recommendation for a transmission mode switch in T seconds (e.g., switching to a relatively robust mode such as transmit diversity).</p><p id="p-0165" num="0163">The UE assistance information related to AI/ML techniques for channel environment classification (e.g., at operations <b>1304</b>, <b>1403</b>) can include one or multiple of the following information available at the UE, e.g., through UE's estimation based on the DL signals: UE speed (or, similarly, Doppler spread), frequency selectivity (or, similarly, delay spread), channel coherence time, channel coherence bandwidth, UE trajectory, radio resource management (RRM) metrics, block error rate, throughput, UE acceleration, etc. The assistance information can be used for model inference, e.g., when inference is performed at the BS or a network entity. Alternatively, the assistance information can include the model inference result if inference is performed at the UE. For example, the UE can perform inference and obtain an inferred channel environment. In another example, the UE can perform inference and obtain an inferred transmission mode (e.g., switching to transmit diversity, switching to spatial multiplexing). As another example, the UE can perform inference and obtain an inferred BS handover recommendation.</p><p id="p-0166" num="0164">The UE assistance information can be reported via the PUCCH and/or the PUSCH. A new UCI type, a new PUCCH format and/or a new MAC CE can be defined for the UE assistance information report.</p><p id="p-0167" num="0165"><figref idref="DRAWINGS">FIG. <b>15</b></figref> depicts an example of a new MAC-CE for the UE assistance information report according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>15</b></figref> shows an example of a new MAC CE for the UE assistance information report, where the Block Error Rate, UE Trajectory, Estimated DL Delay Spread, and Estimated DL Doppler Spread fields each have a length of 8 bits; the Recommended Transmission Mode field has a length of 7 bits; and the IR field consists of a single bit that is set to 1 when the Recommended Transmission Mode field is present.</p><p id="p-0168" num="0166">In one embodiment, the UE assistance information report can be triggered periodically, e.g., via UE-specific RRC signaling. In another embodiment, the UE assistance information report can be semi-persistent or aperiodic. For example, the UE assistance information report can be triggered by the DCI, where a new field (e.g., 1-bit triggering field) can be introduced to the DCI for report triggering. In one example, an IE similar to the CSI-ReportConfig IE can be introduced for configuring the UE assistance information report to support AI/ML techniques for channel environment classification.</p><p id="p-0169" num="0167">TABLE 5 provides an example of the IE for configuring the UE assistance information report, where whether the report is periodic or semi-persistent or aperiodic, the resources for the report transmission, and/or report contents can be included. For the &#x2018;Coherence-bw&#x2019;, a set of coherence bandwidths are predefined in this example; the UE can report one of these coherence bandwidths via the index BW1, BW2, etc.</p><p id="p-0170" num="0000"><tables id="TABLE-US-00005" num="00005"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 5</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>An example of IE for configuration of UE assistance information report for support</entry></row><row><entry>of AI/ML techniques for channel environment classification</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="140pt" align="left"/><colspec colname="2" colwidth="119pt" align="left"/><tbody valign="top"><row><entry>MlChEnvReport-ReportConfig ::=</entry><entry>SEQUENCE {</entry></row><row><entry>&#x2003;reportConfigId</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;MlChEnvReport-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportConfigId,</entry><entry/></row><row><entry>&#x2003;reportConfigType</entry><entry>&#x2003;CHOICE {</entry></row><row><entry>&#x2003;&#x2003;periodic</entry><entry>&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotConfig</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;MlChEnvReport-</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;pucch-MIChEnvReport-ResourceList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE (SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofBWPs))&#x2003;&#x2003;OF&#x2003;&#x2003;PUCCH-MlChEnvReport-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;Resource</entry></row><row><entry>&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;semiPersistentOnPUCCH&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotConfig&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;MlChEnvReport-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;pucch-MlChEnvReport-ResourceList &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;SEQUENCE (SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofBWPs) )&#x2003;&#x2002;OF&#x2003;&#x2003;PUCCH-MlChEnvReport-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;Resource</entry></row><row><entry>&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;semiPersistentOnPUSCH&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotConfig&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ENUMERATED {sl5,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;sl10, sl20, sl40, sl80, sl160, sl320},</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotOffsetList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE (SIZE (1..</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;maxNrofUL-Allocations)) OF INTEGER(0..32),</entry></row><row><entry>&#x2003;&#x2003;&#x2003;p0alpha&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;P0-PUSCH-AlphaSetId</entry></row><row><entry>&#x2003;&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;aperiodic&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;reportSlotOffsetList&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE (SIZE</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..maxNrofUL-Allocations)) OF INTEGER(0..32)</entry></row><row><entry>&#x2003;&#x2003;}</entry></row><row><entry>&#x2003;},</entry></row><row><entry>&#x2003;&#x2003;reportQuantity&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CHOICE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;none&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;NULL,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;Coherence-bw&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ENUMERATED {BW1, BW2, ...}</entry></row><row><entry>&#x2003;&#x2003;},</entry></row><row><entry>MlChEnvReport-ReportPeriodicityAndOffset ::= CHOICE {</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="140pt" align="left"/><colspec colname="2" colwidth="119pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;slots4</entry><entry>&#x2003;INTEGER(0..3),</entry></row><row><entry>&#x2003;&#x2003;slots5</entry><entry>&#x2003;INTEGER(0..4),</entry></row><row><entry>&#x2003;&#x2003;slots8</entry><entry>&#x2003;INTEGER(0. .7),</entry></row><row><entry>&#x2003;&#x2003;slots10</entry><entry>&#x2003;INTEGER(0. .9),</entry></row><row><entry>&#x2003;&#x2003;slotsl6</entry><entry>&#x2003;INTEGER(0. .15),</entry></row><row><entry>&#x2003;&#x2003;slots20</entry><entry>&#x2003;INTEGER(0. .19),</entry></row><row><entry>&#x2003;&#x2003;slots40</entry><entry>&#x2003;INTEGER(0. .39),</entry></row><row><entry>&#x2003;&#x2003;slots80</entry><entry>&#x2003;INTEGER(0. .79),</entry></row><row><entry>&#x2003;&#x2003;slotsl60</entry><entry>&#x2003;INTEGER(0. .159),</entry></row><row><entry>&#x2003;&#x2003;slots320</entry><entry>&#x2003;INTEGER(0. .319)</entry></row><row><entry>}</entry><entry/></row><row><entry>PUCCH-mlChEnvReport-Resource :: =</entry><entry>SEQUENCE {</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="133pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;uplinkBandwidthPartId</entry><entry>BWP-Id,</entry></row><row><entry>&#x2003;&#x2003;pucch-Resource</entry><entry>PUCCH-ResourceId</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="259pt" align="left"/><tbody valign="top"><row><entry>}</entry></row><row><entry>}</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0171" num="0168">In one embodiment, part of or all the configuration information for channel environment classification can be broadcast as part of cell-specific information, for example via system information such as MIB, SIB1 or other SIBs. Alternatively, a new SIB can be introduced for the indication of configuration information for channel environment classification. For example, the enabling/disabling of an ML approach, an ML model and/or model parameters for channel environment classification can be broadcast. TABLE 6 provides an example of sending the configuration information for channel environment classification via SIB1, where K classifiers are predefined and one classifier can be configured. In another example, updates of classifier parameters can be broadcast.</p><p id="p-0172" num="0000"><tables id="TABLE-US-00006" num="00006"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 6</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>An example of IE SIB1 modification for configuration of ML/AI techniques for</entry></row><row><entry>channel environment classification</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>SIB1 ::=&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="98pt" align="left"/><colspec colname="2" colwidth="35pt" align="left"/><colspec colname="3" colwidth="133pt" align="left"/><tbody valign="top"><row><entry>&#x2003;cellselectionInfo</entry><entry/><entry>SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;q-RxLevMin</entry><entry/><entry>&#x2003;Q-RxLevMin,</entry></row><row><entry>&#x2003;&#x2003;q-RxLevMinOffset</entry><entry/><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER (1..8)</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL,</entry><entry>-- Need S</entry><entry/></row><row><entry>&#x2003;&#x2003;q-RxLevMinSUL</entry><entry/><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;Q-RxLevMin</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL,</entry><entry>-- Need R</entry><entry/></row><row><entry>&#x2003;&#x2003;q-QualMin</entry><entry/><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;Q-QualMin</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL,</entry><entry>-- Need S</entry><entry/></row><row><entry>&#x2003;&#x2003;q-QualMinOffset</entry><entry/><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER (1..8)</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL</entry><entry>-- Need S</entry><entry/></row><row><entry>&#x2003;&#x2003;}</entry><entry/><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="98pt" align="left"/><colspec colname="2" colwidth="168pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL,</entry><entry>-- Cond Standalone</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="3"><colspec colname="1" colwidth="98pt" align="left"/><colspec colname="2" colwidth="35pt" align="left"/><colspec colname="3" colwidth="133pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;chan-env-classifier</entry><entry/><entry>INTEGER (1..K)</entry></row><row><entry>&#x2003;nonCriticalExtension</entry><entry/><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE{ }</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL</entry><entry/><entry/></row><row><entry>}</entry></row><row><entry namest="1" nameend="3" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0173" num="0169">In another embodiment, part of or all the configuration information for channel environment classification can be sent by UE-specific signaling. TABLE 7 provides an example of configuration for channel environment classification via the IE PDSCH-ServingCellConfig. In this example, the ML approach for channel environment classification is enabled or disabled via a BOOLEAN parameter, and the ML model/algorithm to be used is indicated via an index from 1 to K. In one example, the combination of an ML model and the parameters to be used for the model can be predefined, with each index from 1 to K corresponding to a certain ML model and a set of model parameters. Alternatively, one or multiple ML models/algorithms can be predefined, and a set of parameters in the IE can indicate the corresponding values for the model parameters.</p><p id="p-0174" num="0000"><tables id="TABLE-US-00007" num="00007"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 7</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>An example of IE PDSCH-ServingCellConfig modification for configuration of</entry></row><row><entry>ML/AI techniques for channel environment classification (boldface indicates modification)</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>PDSCH-ServingCellConfig ::= &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;codeBlockGroupTransmission&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SetupRelease { PDSCH-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CodeBlockGroupTransmission }&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL, &#x2003;-- Need</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;M</entry></row><row><entry>&#x2003;xOverhead &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;ENUMERATED { xOh6,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;xOh12, xOh18 }&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL,&#x2003;&#x2003;--</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;Need S</entry></row><row><entry>&#x2003;. . . ,</entry></row><row><entry>&#x2003;[ [</entry></row><row><entry>&#x2003;maxMIMO-Layers &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER (1. .8)</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL, &#x2003;-- Need M </entry></row><row><entry>&#x2003;processingType2Enabled&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;BOOLEAN</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL&#x2009; &#x2003;-- Need M</entry></row><row><entry>&#x2003;] ],</entry></row><row><entry>&#x2003;[ [</entry></row><row><entry>&#x2003;pdsch-CodeBlockGroupTransmissionList-rl6 SetupRelease&#x2003;{&#x2003;PDSCH-</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CodeBlockGroupTransmissionList-r16&#x2003; } &#x2003;&#x2003;OPTIONAL&#x2003;&#x2003; --</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;Need M</entry></row><row><entry>&#x2003;] ]</entry></row><row><entry>&#x2003;processingType2Enabled &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;BOOLEAN</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL&#x2009; &#x2003;-- Need M</entry></row><row><entry><b>&#x2003;pdsch-ChanEnvClass &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</b></entry></row><row><entry><b>&#x2003;&#x2003;mlEnabled &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;BOOLEAN</b></entry></row><row><entry><b>&#x2003;&#x2003;mlAlgo&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER (1...K)</b></entry></row><row><entry><b>&#x2003;&#x2003;}</b></entry></row><row><entry>}</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0175" num="0170">In one embodiment, the framework for integrating the capability of UE to determine its channel environment with a use case is explained in detail for the example use case of CSI feedback. One of the key components of a MIMO transmission scheme is CSI acquisition at the base station or gNB. In FDD systems, the CSI is acquired using the CSI-RS transmission from gNB, and CSI calculation and feedback from mobile station or UE.</p><p id="p-0176" num="0171">There have been various studies to reduce the CSI feedback overhead, i.e., the number of bits to report the CSI. In particular, algorithms that leverage the temporal correlation of channel for optimizing the channel estimation and/or CSI feedback benefit from being aware of the channel environment. The focus of this embodiment is on signaling required to enable this in the case where BS is aware of the capability of UE to support the determination of channel environment as described in main embodiments.</p><p id="p-0177" num="0172"><figref idref="DRAWINGS">FIG. <b>16</b></figref> shows an example flowchart for BS operation to support CSI feedback being aware of channel environment according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>16</b></figref> illustrates the example of method <b>1600</b>, for integrating the determination of channel environment with CSI feedback mechanism. In operation <b>1601</b>, BS sends the CSI-RS configuration information to the UE by CSI-Reportconfig IE during which in one embodiment where the inference for determination of channel environment happens at the UE, the CSI-Reportconfig IE may include an additional field chan-env-classifier as illustrated in TABLE 8 that configures a particular classifier from pre-determined set of K classifiers.</p><p id="p-0178" num="0000"><tables id="TABLE-US-00008" num="00008"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 8</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>An example of IE CSI-ReportConfig modification for configuration of channel</entry></row><row><entry>environment classification aware CSI feedback (boldface indicates modification)</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>CSI-ReportConfig : : =&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;reportConfigId &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CSI-ReportConfigId,</entry></row><row><entry>&#x2003;carrier &#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;ServCellIndex OPTIONAL, --</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;Need S</entry></row><row><entry>&#x2003;resourcesForChannelMeasurement&#x2002;&#x2003;CSI-ReportConfigId,</entry></row><row><entry>&#x2003;csi-IM-ResourcesForInterference&#x2003;&#x2003;CSI-ReportConfigId, OPTIONAL,</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;-- Need R</entry><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>&#x2003;nzp-CSI-RS-ResourcesForInterference &#x2003;&#x2002;CSI-ReportConfigId,</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL, -- Need R</entry><entry/></row><row><entry>&#x2003;reportConfigType</entry><entry>CHOICE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;periodic</entry><entry>&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CSI-</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;pucch-CSI-ResourceList</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {SIZE</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..MAXNrofBWPs)) OF PUCCH-CSI-Resource</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;},</entry><entry/></row><row><entry>&#x2003;&#x2003;&#x2003;semiPersistentOnPUCCH</entry><entry>&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CSI-</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset,</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;pucch-CSI-ResourceList</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {SIZE (1..</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;MAXNrofBWPs)) OF PUCCH-CSI-Resource</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;},</entry><entry/></row><row><entry>&#x2003;&#x2003;&#x2003;semiPersistentOnPUSCH</entry><entry>&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ENUMERATED {s15,</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;s110, s120, s140, s180, s1160, s1320},</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotOffsetList</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {SIZE</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..MAXNrofUL-Allocations)) OF</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..32)</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;p0alpha</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;P0-PUSCH-AlphaSetId</entry></row><row><entry>&#x2003;&#x2003;&#x2003;},</entry><entry/></row><row><entry>&#x2003;&#x2003;&#x2003;aperiodic</entry><entry>&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotOffsetList</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {SIZE</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="266pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..MAXNrofUL-Allocations)) OF</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..32)</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;},</entry><entry>CHOICE {</entry></row><row><entry>reportQuantity</entry><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="133pt" align="left"/><colspec colname="2" colwidth="133pt" align="left"/><tbody valign="top"><row><entry>&#x2003;none</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RI-PMI-CQI</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RI-i1</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RI-iI-CQI</entry><entry>SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;pdsch-BundleSizeForCSI</entry><entry>ENUMERATED {n2, n4} OPTIONAL,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;-- Need S</entry><entry/></row><row><entry>&#x2003;},</entry><entry/></row><row><entry>&#x2003;cri-RI-CQI</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RSRP</entry><entry>NULL,</entry></row><row><entry>&#x2003;ssb-Index-RSRP</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RI-LI-PMI-CQI</entry><entry>NULL</entry></row><row><entry>},</entry><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="112pt" align="left"/><colspec colname="2" colwidth="154pt" align="left"/><tbody valign="top"><row><entry><b>chan-env-classifier</b></entry><entry><b>INTEGER (1..K)</b></entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0179" num="0173">In yet another embodiment where inference happens at the BS, the CSI-Reportconfig IE may include an additional field chan-env-result as illustrated in TABLE 9 that conveys the inference result to the UE. In operation <b>1602</b>, BS receives the CSI feedback report determined by the UE based on the particular channel environment. In the case where inference for determination of channel environment happens at UE, this CSI feedback will include the channel environment classification information.</p><p id="p-0180" num="0000"><tables id="TABLE-US-00009" num="00009"><table frame="none" colsep="0" rowsep="0" pgwide="1"><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="center"/><thead><row><entry namest="1" nameend="1" rowsep="1">TABLE 9</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row><row><entry>An example of IE CSI-ReportConfig modification for configuration of channel</entry></row><row><entry>environment classification aware CSI feedback (boldface indicates modification)</entry></row><row><entry namest="1" nameend="1" align="center" rowsep="1"/></row></thead><tbody valign="top"><row><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><tbody valign="top"><row><entry>CSI-ReportConfig :: =&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;reportConfigId&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2002;CSI-ReportConfigId,</entry></row><row><entry>&#x2003;carrier&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ServCellIndex OPTIONAL, --</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;Need S</entry></row><row><entry>&#x2003;resourcesForChannelMeasurement &#x2003;&#x2002;CSI-ReportConfigId,</entry></row><row><entry>&#x2003;csi-IM-ResourcesForInterference &#x2003;&#x2003;CSI-ReportConfigId, OPTIONAL,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;-- Need R</entry></row><row><entry>&#x2003;nzp-CSI-RS-ResourcesForInterference &#x2003;&#x2002;CSI-ReportConfigId,</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="147pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;OPTIONAL, -- Need R</entry><entry/></row><row><entry>&#x2003;reportConfigType</entry><entry>CHOICE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;periodic</entry><entry>&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CSI-</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="147pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;pucch-CSI-ResourceList</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {SIZE</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..MAXNrofBWPs)) OF PUCCH-CSI-Resource</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="147pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;},</entry><entry/></row><row><entry>&#x2003;&#x2003;&#x2003;semiPersistentOnPUCCH</entry><entry>&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CSI-</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ReportPeriodicityAndOffset,</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="147pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;pucch-CSI-ResourceList</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {SIZE (1..</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;MAXNrofBWPs)) OF PUCCH-CSI-Resource</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="147pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;},</entry><entry/></row><row><entry>&#x2003;&#x2003;&#x2003;semiPersistentOnPUSCH</entry><entry>&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotConfig</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;ENUMERATED {s15,</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;s110, s120, s140, s180, s1160, s1320},</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="147pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotOffsetList</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {SIZE</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..MAXNrofUL-Allocations)) OF</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..32)</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="147pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;p0alpha</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;P0-PUSCH-AlphaSetId</entry></row><row><entry>&#x2003;&#x2003;&#x2003;},</entry><entry/></row><row><entry>&#x2003;&#x2003;&#x2003;aperiodic</entry><entry>&#x2003;&#x2003;&#x2003;SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;reportSlotOffsetList</entry><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;SEQUENCE {SIZE</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="1"><colspec colname="1" colwidth="273pt" align="left"/><tbody valign="top"><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;(1..MAXNrofUL-Allocations)) OF</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;INTEGER(0..32)</entry></row><row><entry>&#x2003;&#x2003;&#x2003;},</entry></row><row><entry>reportQuantity&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;CHOICE {</entry></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="126pt" align="left"/><colspec colname="2" colwidth="147pt" align="left"/><tbody valign="top"><row><entry>&#x2003;none</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RI-PMI-CQI</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RI-i1</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RI-iI-CQI</entry><entry>SEQUENCE {</entry></row><row><entry>&#x2003;&#x2003;pdsch-BundleSizeForCSI</entry><entry>ENUMERATED {n2, n4} OPTIONAL,</entry></row><row><entry>&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;&#x2003;-- Need S</entry><entry/></row><row><entry>&#x2003;},</entry><entry/></row><row><entry>&#x2003;cri-RI-CQI</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RSRP</entry><entry>NULL,</entry></row><row><entry>&#x2003;ssb-Index-RSRP</entry><entry>NULL,</entry></row><row><entry>&#x2003;cri-RI-LI-PMI-CQI</entry><entry>NULL</entry></row><row><entry>},</entry><entry/></row></tbody></tgroup><tgroup align="left" colsep="0" rowsep="0" cols="2"><colspec colname="1" colwidth="98pt" align="left"/><colspec colname="2" colwidth="175pt" align="left"/><tbody valign="top"><row><entry><b>chan-env-result</b></entry><entry><b>INTEGER</b></entry></row><row><entry namest="1" nameend="2" align="center" rowsep="1"/></row></tbody></tgroup></table></tables></p><p id="p-0181" num="0174"><figref idref="DRAWINGS">FIG. <b>17</b></figref> shows an example flowchart for UE operation to support CSI feedback being aware of channel environment according to embodiments of the present disclosure. <figref idref="DRAWINGS">FIG. <b>17</b></figref> illustrates an example of method <b>1700</b> for integrating the determination of channel environment with CSI feedback mechanism. In operation <b>1701</b>, UE receives the CSI-RS configuration information from the BS during which in one embodiment where the inference for determination of channel environment happens at the UE, the CSI-Reportconfig IE may include an additional field chan-env-classifier as illustrated in TABLE 8 that configures a particular classifier from pre-determined set of K classifiers. In yet another embodiment where inference happens at the BS, the CSI-Reportconfig IE may include an additional field chan-env-result as illustrated in TABLE 9 that conveys the inference result to the UE. In operation <b>1702</b>, UE sends the CSI feedback report determined to the BS based on the particular channel environment. In one embodiment, UE might use different AI/ML models for different channel environments or in another embodiment UE might use different algorithms. In the case where inference for determination of channel environment happens at UE, this CSI feedback will include the channel environment classification information.</p><p id="p-0182" num="0175">Although this disclosure has been described with an exemplary embodiment, various changes and modifications may be suggested to one skilled in the art. It is intended that this disclosure encompass such changes and modifications as fall within the scope of the appended claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A user equipment (UE), comprising:<claim-text>a processor; and</claim-text><claim-text>a transceiver operatively coupled to the processor, the transceiver configured to<claim-text>transmit a report of UE capability for support of machine-learning (ML) based channel environment classification, wherein the channel environment classification classifies a channel environment of a channel between the UE and a base station based on one or more of UE speed or Doppler spread, UE trajectory, frequency selectivity or delay spread, coherence bandwidth, coherence time, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration, and</claim-text><claim-text>receive configuration for ML based channel environment classification, the configuration for ML based channel environment classification comprising at least enabling/disabling of ML based channel environment classification,</claim-text></claim-text><claim-text>wherein, when ML based channel environment classification is enabled, the transceiver is configured to one of transmit UE assistance information for ML based channel environment classification, or transmit an indication of the channel environment.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The user equipment of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the indication of the channel environment is a pre-defined channel environment associated with a lookup table.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The user equipment of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the configuration for ML based channel environment classification further comprises one or more of a format for the indication, resources for the indication, periodicity of the indication, ML model to be used, updated ML model parameters, or whether model parameters received from the UE will be used.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The user equipment of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the UE assistance information comprises one of<claim-text>an indication of one or more of UE speed, frequency selectivity, channel coherence time, channel coherence bandwidth, UE trajectory, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration, or</claim-text><claim-text>an indication usable for performing model inference or includes model inference result if the UE performs model inference, wherein the model inference result further comprises one or more of an indication of a channel environment, a recommendation for a transmission mode, or a recommendation for BS handover.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The user equipment of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the UE assistance information comprises one of<claim-text>periodic and triggered by UE-specific radio resource control (RRC) signaling, or</claim-text><claim-text>aperiodic or semi-persistent and triggered by a downlink control information (DCI).</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The user equipment of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the configuration for ML based channel environment classification may be one of<claim-text>broadcast as part of system information, or</claim-text><claim-text>transmitted via UE-specific signaling.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The user equipment of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the configuration for ML based channel environment classification includes enabling/disabling of channel environment-aware feedback, and wherein the transceiver is configured to transmit channel state information (CSI) reporting indicating channel environment when channel environment-aware feedback is enabled.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A method performed by a user equipment (UE), comprising:<claim-text>transmitting a report of UE capability for support of machine-learning (ML) based channel environment classification, wherein the channel environment classification classifies a channel environment of a channel between the UE and a base station based on one or more of UE speed or Doppler spread, UE trajectory, frequency selectivity or delay spread, coherence bandwidth, coherence time, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration;</claim-text><claim-text>receiving configuration for ML based channel environment classification, the configuration for ML based channel environment classification comprising at least enabling/disabling of ML based channel environment classification; and</claim-text><claim-text>when ML based channel environment classification is enabled, one of transmitting UE assistance information for ML based channel environment classification, or transmitting an indication of channel environment.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the indication of channel environment is a pre-defined channel environment associated with a lookup table.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the configuration for ML based channel environment classification further comprises one or more of a format for the indication, resources for the indication, periodicity of the indication, ML model to be used, updated ML model parameters, or whether model parameters received from the UE will be used.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the UE assistance information comprises one of<claim-text>comprises an indication of one or more of UE speed, frequency selectivity, channel coherence time, channel coherence bandwidth, UE trajectory, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration, or</claim-text><claim-text>information usable for performing model inference or includes model inference result if the UE performs model inference, wherein the model inference result further comprises one or more of an indication of a channel environment, a recommendation for a transmission mode, or a recommendation for BS handover.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the UE assistance information comprises one of<claim-text>periodic and triggered by UE-specific radio resource control (RRC) signaling, or</claim-text><claim-text>aperiodic or semi-persistent and triggered by a downlink control information (DCI).</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the configuration for ML based channel environment classification may be one of<claim-text>broadcast as part of system information, or</claim-text><claim-text>transmitted via UE-specific signaling.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the configuration for ML based channel environment classification includes enabling/disabling of channel environment-aware feedback, and wherein the method further comprises:<claim-text>transmitting channel state information (CSI) reporting indicating channel environment when channel environment-aware feedback is enabled.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. A base station (BS), comprising:<claim-text>a processor; and</claim-text><claim-text>a transceiver operatively coupled to the processor, the transceiver configured to<claim-text>receive a report of user equipment (UE) capability for support of machine-learning (ML) based channel environment classification, wherein the channel environment classification classifies a channel environment of a channel between the UE and a base station based on one or more of UE speed or Doppler spread, UE trajectory, frequency selectivity or delay spread, coherence bandwidth, coherence time, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration, and</claim-text><claim-text>transmit configuration for ML based channel environment classification, the configuration for ML based channel environment classification comprising at least enabling/disabling of ML based channel environment classification,</claim-text></claim-text><claim-text>wherein, when ML based channel environment classification is enabled, one of<claim-text>the processor is configured to perform model training based on the configuration and a received information on channel environment determined by the UE, or the transceiver is configured to receive UE assistance information for ML based channel classification, and</claim-text></claim-text><claim-text>wherein the transceiver is configured to receive an indication of the channel environment.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The base station of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the indication of the channel environment comprises a pre-defined channel environment associated with a lookup table.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The base station of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the configuration for ML based channel environment classification further comprises one or more of a format for the indication, resources for the indication, periodicity of the indication, ML model to be used, updated ML model parameters, or whether model parameters received from the UE will be used.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The base station of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the UE assistance information comprises one of<claim-text>an indication of one or more of UE speed, frequency selectivity, channel coherence time, channel coherence bandwidth, UE trajectory, radio resource management (RRM) metrics, block error rate, throughput, or UE acceleration, or</claim-text><claim-text>information usable for performing model inference or includes model inference result if the UE performs model inference, wherein the model inference result further comprises one or more of an indication of a channel environment, a recommendation for a transmission mode, or a recommendation for BS handover.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The base station of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the UE assistance information comprises one of<claim-text>periodic and triggered by UE-specific radio resource control (RRC) signaling, or</claim-text><claim-text>aperiodic or semi-persistent and triggered by a downlink control information (DCI).</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The base station of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the configuration for ML based channel environment classification may be one of<claim-text>broadcast as part of system information, or</claim-text><claim-text>transmitted via UE-specific signaling.</claim-text></claim-text></claim></claims></us-patent-application>
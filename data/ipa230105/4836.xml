<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004837A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004837</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17756373</doc-number><date>20201116</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-217439</doc-number><date>20191129</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>04</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><invention-title id="d2e61">INFERENCE DEVICE, INFERENCE METHOD AND INFERENCE PROGRAM</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Tokyo Electron Limited</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>TSUTSUI</last-name><first-name>Takuro</first-name><address><city>Hokkaido</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/042564</doc-number><date>20201116</date></document-id><us-371c12-date><date>20220524</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An inference device, an inference method, and an inference program that can realize high precision inference regardless of an application target are provided. An inference device includes: an acquisition section configured to acquire a time series data group measured in accordance with processing of a target object in a predetermined processing unit of a manufacturing process; and an inference section configured to tune respective output data that is output by processing the acquired time series data group using a plurality of network sections that have been machine-learned in advance and to output an inference result by combining the respective tuned output data; wherein the inference section is configured to tune the respective output data using a correction parameter corresponding to an error included in the inference result.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="110.91mm" wi="158.75mm" file="US20230004837A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="231.31mm" wi="162.56mm" orientation="landscape" file="US20230004837A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="232.75mm" wi="148.59mm" file="US20230004837A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="231.82mm" wi="142.16mm" file="US20230004837A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="246.89mm" wi="165.18mm" orientation="landscape" file="US20230004837A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="220.98mm" wi="153.50mm" orientation="landscape" file="US20230004837A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="241.22mm" wi="163.32mm" orientation="landscape" file="US20230004837A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="234.27mm" wi="166.37mm" file="US20230004837A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="246.80mm" wi="166.37mm" file="US20230004837A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="245.03mm" wi="166.37mm" file="US20230004837A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="248.16mm" wi="162.31mm" file="US20230004837A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="231.65mm" wi="162.56mm" file="US20230004837A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="247.57mm" wi="161.80mm" orientation="landscape" file="US20230004837A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="242.32mm" wi="157.73mm" file="US20230004837A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="249.60mm" wi="166.71mm" orientation="landscape" file="US20230004837A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="246.46mm" wi="162.14mm" file="US20230004837A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="249.26mm" wi="166.71mm" orientation="landscape" file="US20230004837A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present disclosure relates to an inference device, an inference method, and an inference program.</p><heading id="h-0002" level="1">BACKGROUND ART</heading><p id="p-0003" num="0002">Conventionally, in the field of various manufacturing processes, inference techniques are known for inferring, from measurement data (a data set of multiple types of time series data, hereinafter referred to as a &#x201c;time series data group&#x201d;) measured during processing a target object, the state of the target object after processing and an event in a process during the processing.</p><p id="p-0004" num="0003">As an example, in a semiconductor manufacturing process, a virtual measurement technique for inferring the state of a wafer after processing and an abnormality detection technique for inferring the presence or absence of an abnormality in the process during processing are known.</p><p id="p-0005" num="0004">On the other hand, models used in these inference techniques (e.g., virtual measurement models, abnormality detection models) need to generate and optimize models on a process-by-process basis to realize more precise inference, which requires cost and time.</p><p id="p-0006" num="0005">With respect to the above, if a model that achieves high-precision inference for a specific process can be applied to other processes of the same type, the cost and time required to optimize the model can be reduced.</p><heading id="h-0003" level="1">PRIOR ART DOCUMENT</heading><heading id="h-0004" level="1">Patent Document</heading><p id="p-0007" num="0006">[Patent Document 1] Japanese Laid-open Patent Publication No. 2006-163517</p><heading id="h-0005" level="1">SUMMARY OF THE INVENTION</heading><heading id="h-0006" level="1">Problem to be Solved by the Invention</heading><p id="p-0008" num="0007">The present disclosure provides an inference device, an inference method, and an inference program that can realize high precision inference regardless of an application target.</p><heading id="h-0007" level="1">Means for Solving the Problem</heading><p id="p-0009" num="0008">An inference device according to one aspect of the present disclosure has the following configuration, for example.</p><p id="p-0010" num="0009">That is, the inference device includes:</p><p id="p-0011" num="0010">an acquisition section configured to acquire a time series data group measured in accordance with processing of a target object in a predetermined processing unit of a manufacturing process; and</p><p id="p-0012" num="0011">an inference section configured to tune respective output data that is output by processing the acquired time series data group using a plurality of network sections that have been machine-learned in advance and to output an inference result by combining the respective tuned output data;</p><p id="p-0013" num="0012">wherein the inference section is configured to tune the respective output data using a correction parameter corresponding to an error included in the inference result.</p><heading id="h-0008" level="1">Effects of the Invention</heading><p id="p-0014" num="0013">According to the present disclosure, it is possible to provide an inference device, an inference method, and an inference program that can realize high precision inference regardless of an application target.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0009" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of an overall configuration of a system to which a virtual measurement device is applied;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a first diagram illustrating an example of predetermined processing units of a semiconductor manufacturing process;</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a second diagram illustrating an example of predetermined processing units of a semiconductor manufacturing process;</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an example of time series data groups to be acquired;</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram illustrating an example of a hardware configuration of virtual measurement devices;</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of a functional configuration of a learning section of a virtual measurement device;</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a first diagram illustrating a specific example of processing of a branch section;</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a second diagram illustrating a specific example of the processing of the branch section;</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a third diagram illustrating a specific example of the processing of the branch section;</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating a specific example of processing of a normalization section included in each network section;</p><p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a fourth diagram illustrating a specific example of the processing of the branch section;</p><p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating an example of a functional configuration of an inference section of the virtual measurement device;</p><p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart illustrating a flow of virtual measurement processing performed by the virtual measurement device;</p><p id="p-0028" num="0027"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a first diagram illustrating an example of a functional configuration of the inference section with a fine-tuning function of the virtual measurement device;</p><p id="p-0029" num="0028"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating a flow of fine-tuning processing by the virtual measurement device; and</p><p id="p-0030" num="0029"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a second diagram illustrating an example of a functional configuration of an inference section with a fine-tuning function of the virtual measurement device.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0010" level="1">DESCRIPTION OF THE EMBODIMENTS</heading><p id="p-0031" num="0030">In the following, each embodiment will be described with reference to the accompanying drawings. In each of the following embodiments, a case will be described in which, for a specific semiconductor manufacturing process as a target, a time series data group measured in accordance with wafer processing is used to generate</p><p id="p-0032" num="0031">a virtual measurement model that infers a state of a wafer after processing; or</p><p id="p-0033" num="0032">an abnormality detection model that infers the presence or absence of an abnormality in the process. At this time, in each of the following embodiments, a model that realizes high-precision inference is generated by performing multifaceted analysis by processing a time series data group using a plurality of network sections.</p><p id="p-0034" num="0033">In each of the following embodiments, by adding a fine-tuning function to the generated model, when the model is applied to other semiconductor manufacturing processes of the same type, errors (errors included in the inference result) caused by individual differences between processes are reduced by using the fine-tuning function.</p><p id="p-0035" num="0034">Thereby, according to each of the following embodiments, it is possible to provide an inference device, an inference method, and an inference program that can realize high precision inference regardless of an application target. As a result, cost and time can be reduced compared to a case where a new model is generated for another semiconductor manufacturing process for optimization.</p><p id="p-0036" num="0035">In the first embodiment of each of the embodiments, a case will be described in which a virtual measurement model is generated as a model based on a time series data group, and a correction matrix is used as a fine-tuning function. In the second embodiment, a case will be described in which a neural network is used instead of the correction matrix as a fine-tuning function will be described. Further, in the third embodiment, a case will be described in which, as a model based on a time series data group, an abnormality detection model is generated instead of the virtual measurement model.</p><p id="p-0037" num="0036">In the following embodiments and the accompanying drawings, elements having substantially the same functional configurations are referred to by the same numerals, and a duplicate description thereof will be omitted.</p><heading id="h-0011" level="1">First Embodiment</heading><p id="p-0038" num="0037">&#x3c;Application Example of Inference Device&#x3e;</p><p id="p-0039" num="0038">First, an application example of a virtual measurement device (inference device) with a fine-tuning function added to a virtual measurement model will be described. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of an overall configuration of a system to which a virtual measurement device is applied.</p><p id="p-0040" num="0039">As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a system <b>100</b>A includes a semiconductor manufacturing process A, time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n, an inspection data acquisition device <b>150</b>A, and a virtual measurement device <b>160</b>A. In the system <b>100</b>A, for the semiconductor manufacturing process A that is a particular process, a virtual measurement model is generated to realize high-precision inference.</p><p id="p-0041" num="0040">A system <b>100</b>B includes a semiconductor manufacturing process B, time series data acquisition devices <b>140</b>B_<b>1</b> to <b>140</b>B_n, an inspection data acquisition device <b>150</b>B, and a virtual measurement device <b>160</b>B. In the system <b>100</b>B, the semiconductor manufacturing process B is another process similar to the semiconductor manufacturing process A, and in the present embodiment, the semiconductor manufacturing process B is a target to which a virtual measurement device (inference device) with a fine-tuning function added to the virtual measurement model generated in the system <b>100</b>A is applied.</p><p id="p-0042" num="0041">In the system <b>100</b>A, the semiconductor manufacturing process A processes a target object (a wafer <b>110</b>A before processing) in a predetermined processing unit <b>120</b>A to generate a result (a wafer <b>130</b>A after processing). It should be noted that that the processing unit <b>120</b>A is an abstract concept and will be described in detail later. The wafer <b>110</b>A before processing refers to a wafer (substrate) before being processed in the processing unit <b>120</b>A, and the wafer <b>130</b>A after processing refers to a wafer (substrate) after being processed in the processing unit <b>120</b>A.</p><p id="p-0043" num="0042">Further, in the system <b>100</b>A, the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n respectively measure the time series data in accordance with the processing of the wafer <b>110</b>A before processing. The time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n measure kinds of measurement items different from each other. It should be noted that the number of measurement items measured by each of the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n may be one or more. The time series data measured in accordance with the processing of the wafer <b>110</b>A before processing includes not only a time series data measured during the processing of the wafer <b>110</b>A before processing but also a time series data measured during pre-processing and post-processing that are performed before and after the processing of the wafer <b>110</b>A before processing. These processing may include pre-processing and post-processing performed without a wafer (substrate).</p><p id="p-0044" num="0043">A time series data group measured by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n is stored as learning data (input data) in a learning data storage section <b>163</b>A of the virtual measurement device <b>160</b>A.</p><p id="p-0045" num="0044">In the system <b>100</b>A, the inspection data acquisition device <b>150</b>A inspects predetermined inspection items (e.g., an ER (Etch Rate)) of the wafer <b>130</b>A after processing processed in the processing unit <b>120</b>A to acquire inspection data. The inspection data acquired by the inspection data acquisition device <b>150</b>A is stored in the learning data storage section <b>163</b>A of the virtual measurement device <b>160</b>A as learning data (labeled data).</p><p id="p-0046" num="0045">In addition, in the system <b>100</b>A, a virtual measurement program including a learning program and an inference program is installed in the virtual measurement device <b>160</b>A. When the virtual measurement program is executed, the virtual measurement device <b>160</b>A functions as a learning section <b>161</b>A and an inference section <b>162</b>A.</p><p id="p-0047" num="0046">The learning section <b>161</b>A performs machine learning by using the time series data group measured by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and the inspection data acquired by the inspection data acquisition device <b>150</b>A.</p><p id="p-0048" num="0047">Specifically, a plurality of network sections included in the learning section <b>161</b>A are used to process the time series data group, and machine learning is performed for the plurality of network sections so that the combined result of respective output data output from the plurality of network sections approaches the inspection data.</p><p id="p-0049" num="0048">The inference section <b>162</b>A acquires the time series data group measured in accordance with the processing of a new target object (wafer before processing) and inputs it to the plurality of network sections for which machine learning has been performed. Accordingly, the inference section <b>162</b>A infers, based on the time series data acquired in accordance with the processing of the new wafer before processing, the inspection data of the wafer after processing and outputs the inference result (virtual measurement data).</p><p id="p-0050" num="0049">As described above, by processing the time series data group measured in accordance with the processing of the target object using the plurality of network sections, the virtual measurement device <b>160</b>A enables to analyze the time series data group from various aspects. As a result, a virtual measurement model (inference section <b>162</b>A) that realizes high-precision inference can be generated compared to a case where the time series data group is processed using one network section.</p><p id="p-0051" num="0050">On the other hand, in the system <b>100</b>B, the semiconductor manufacturing process B is the same type of process as the semiconductor manufacturing process A of the system <b>100</b>A. Further, in the system <b>100</b>B, the time series data acquisition devices <b>140</b>B_<b>1</b> to <b>140</b>B_n and the inspection data acquisition device <b>150</b>B correspond to the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and the inspection data acquisition device <b>150</b>A, respectively.</p><p id="p-0052" num="0051">Further, in the system <b>100</b>B, the virtual measurement device <b>160</b>B (inference device) corresponds to the virtual measurement device <b>160</b>A of the system <b>100</b>A. However, in the case of the virtual measurement device <b>160</b>B of the system <b>100</b>B, the learning section <b>161</b>A is not included. Also, instead of the inference section <b>162</b>A, an inference section <b>162</b>B with a fine-tuning function is included (a virtual measurement program that does not include a learning program but includes an inference program similar to the inference program installed in the virtual measurement device <b>160</b>A is installed).</p><p id="p-0053" num="0052">In a case of the virtual measurement device <b>160</b>B of the system <b>100</b>B, rather than generating a new virtual measurement model and performing machine learning by using the time series data group for optimization, the virtual measurement model (inference section <b>162</b>A) generated in the virtual measurement device <b>160</b>A of the system <b>100</b>A is applied.</p><p id="p-0054" num="0053">Here, the semiconductor manufacturing process A and the semiconductor manufacturing process B are the same type of process as described above, but have individual differences. Therefore, even if the virtual measurement model (the inference section <b>162</b>A) generated in the virtual measurement device <b>160</b>A is applied as it is, the inference result (virtual measurement data) includes an error.</p><p id="p-0055" num="0054">Thus, in a case of the virtual measurement device <b>160</b>B (the inference device), an inference section having a fine-tuning function added to the virtual measurement model (the inference section <b>162</b>A) generated in the virtual measurement device <b>160</b>A is generated. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the inference section <b>162</b>B with a fine-tuning function included in the virtual measurement device <b>160</b>B is an example of the inference section having a fine-tuning function added to the virtual measurement model (the inference section <b>162</b>A) generated in the virtual measurement device <b>160</b>A.</p><p id="p-0056" num="0055">To the inference section <b>162</b>B with a fine-tuning function, while the virtual measurement model (the inference section <b>162</b>A) generated in the virtual measurement device <b>160</b>A is applied (see the dashed line <b>170</b>), a fine-tuning function is added to reduce an error caused by an individual difference (error included in the inference result).</p><p id="p-0057" num="0056">Specifically, the inference section <b>162</b>B with a fine-tuning function updates correction parameters (parameters included in a correction matrix used when tuning respective output data, details are described below) so as to reduce an error between</p><p id="p-0058" num="0057">an inference result (virtual measurement data) that is output by processing a time series data group using a plurality of network sections included in the generated virtual measurement model and combining respective output data output from the plurality of network sections after tuning; and</p><p id="p-0059" num="0058">inspection data acquired by the inspection data acquisition device <b>150</b>B.</p><p id="p-0060" num="0059">As a result, the virtual measurement device <b>160</b>B can realize a model generated in the virtual measurement device <b>160</b>A and to which a virtual measurement model (inference section <b>162</b>A) is applied to realize high-precision inference, which is a model capable of high-precision inference even for the semiconductor manufacturing process B that is an application target.</p><p id="p-0061" num="0060">&#x3c;Predetermined Processing Unit for Semiconductor Manufacturing Processes&#x3e;</p><p id="p-0062" num="0061">Next, the predetermined processing units <b>120</b>A and <b>120</b>B of the semiconductor manufacturing process A and B will be described. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a first diagram illustrating an example of predetermined processing units of a semiconductor manufacturing process. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a semiconductor manufacturing device <b>200</b>, which is an example of a substrate processing device, includes a plurality of chambers (one example of a plurality of processing spaces, in the example of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, chamber A to chamber C), in which a wafer is processed in each chamber.</p><p id="p-0063" num="0062">Here, <b>2</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a case where a plurality of chambers are defined as processing units <b>120</b>A and <b>120</b>B. In this case, the wafers <b>110</b>A and <b>110</b>B before processing refer to wafers before being processed in the chamber A, and the wafers <b>130</b>A and <b>130</b>B after processing refer to wafers after being processed in the chamber C.</p><p id="p-0064" num="0063">The time series data group measured in accordance with the processing of the wafers <b>110</b>A and <b>110</b>B before processing in the processing units <b>120</b>A and <b>120</b>B in <b>2</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>2</b></figref> includes:</p><p id="p-0065" num="0064">a time series data group measured in accordance with processing in the chamber A (first processing space);</p><p id="p-0066" num="0065">a time series data group measured in accordance with processing in the chamber B (second processing space); and</p><p id="p-0067" num="0066">a time series data group measured in accordance with processing in in the chamber C (third processing space).</p><p id="p-0068" num="0067">On the other hand, <b>2</b><i>b </i>of <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a case where one chamber (&#x201c;chamber B&#x201d; in the example of <b>2</b><i>b </i>of <figref idref="DRAWINGS">FIG. <b>2</b></figref>) is defined as the processing units <b>120</b>A and <b>120</b>B. In this case, the wafers <b>110</b>A and <b>110</b>B before processing refer to wafers before being processed in the chamber B (wafers after being processed in the chamber A). Also, the wafers <b>130</b>A and <b>130</b>B after processing refer to wafers after being processed in the chamber B (wafers before being processed in the chamber C).</p><p id="p-0069" num="0068">In the processing units <b>120</b>A and <b>120</b>B of <b>2</b><i>b </i>of <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the time series data group measured in accordance with the processing of the wafers <b>110</b>A and <b>110</b>B before processing includes the time series data group measured in accordance with the processing of the wafers <b>110</b>A and <b>110</b>B before processing in the chamber B.</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a second diagram illustrating an example of predetermined processing units of a semiconductor manufacturing process. Similar to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the semiconductor manufacturing device <b>200</b> includes a plurality of chambers, and a wafer is processed in each chamber.</p><p id="p-0071" num="0070">Here, <b>3</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a case where processing (referred to as &#x201c;wafer processing&#x201d;) excluding pre-processing and post-processing among the processing contents in the chamber B is defined as the processing units <b>120</b>A and <b>120</b>B. In this case, the wafers <b>110</b>A and <b>110</b>B before processing refer to wafers before wafer processing is performed (wafers after pre-processing is performed) and the wafers <b>130</b>A and <b>130</b>B after processing refer to wafers after wafer processing is performed (wafers before post-processing is performed).</p><p id="p-0072" num="0071">Also, in the processing units <b>120</b>A and <b>120</b>B of <b>3</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the time series data group measured in accordance with the processing of the wafers <b>110</b>A and <b>110</b>B before processing includes the time series data group measured in accordance with the wafer processing of the wafers <b>110</b>A and <b>110</b>B before processing in the chamber B.</p><p id="p-0073" num="0072">In the example of <b>3</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, in a case in which pre-processing, wafer processing (the present processing), and post-processing are performed in the same chamber (in the chamber B), the wafer processing is described as the wafer processing units <b>120</b>A and <b>120</b>B. However, in a case in which each processing is performed in a different chamber (e.g., when pre-processing is performed in the chamber A, wafer processing is performed in the chamber B, and post-processing is performed in the chamber C), each processing for the corresponding chamber may be the processing units <b>120</b>A and <b>120</b>B.</p><p id="p-0074" num="0073">On the other hand, <b>3</b><i>b </i>of <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a case where the processing of one recipe (in the example of <b>3</b><i>b </i>of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, &#x201c;Recipe III&#x201d;) included in the wafer processing among the processing contents in the chamber B is defined as the processing units <b>120</b>A and <b>120</b>B. In this case, the wafers <b>110</b>A and <b>110</b>B before processing refer to wafers before the processing of recipe III is performed (wafers after the processing of recipe II is performed). Also, the wafers <b>130</b>A and <b>130</b>B after processing refer to wafers after the processing of recipe III is performed (wafers before the processing of recipe IV (not illustrated) is performed).</p><p id="p-0075" num="0074">Also, in the processing units <b>120</b>A and <b>120</b>B of <b>3</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the time series data group measured in accordance with the processing of the wafers <b>110</b>A and <b>110</b>B before processing includes the time series data group measured in accordance with the wafer processing with the recipe III in the chamber B.</p><p id="p-0076" num="0075">&#x3c;Example of Time series Data Group&#x3e;</p><p id="p-0077" num="0076">Next, a specific example of the time series data groups acquired by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>B_<b>1</b> to <b>140</b>B_n will be described. <figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an example of the time series data groups to be acquired. Incidentally, in the example of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, for the simplicity of the explanation, the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>B_<b>1</b> to <b>140</b>B_n respectively measure one-dimensional data. However, one time series data acquisition device may measure two-dimensional data (a data set of multiple types of one-dimensional data).</p><p id="p-0078" num="0077">Of these, <b>4</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>4</b></figref> represents a time series data group of a case in which the processing units <b>120</b>A and <b>120</b>B are defined by one of <b>2</b><i>b </i>of <figref idref="DRAWINGS">FIG. <b>2</b>, <b>3</b></figref><i>a </i>of <figref idref="DRAWINGS">FIGS. <b>3</b>, and <b>3</b></figref><i>b </i>of <figref idref="DRAWINGS">FIG. <b>3</b></figref>. In this case, the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>B_<b>1</b> to <b>140</b>B_n acquire the time series data measured in accordance with the processing in the chamber B, respectively. The time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n acquire the time series data measured in the same time zone as a time series data group. Similarly, the time series data acquisition devices <b>140</b>B_<b>1</b> to <b>140</b>B_n acquire the time series data measured in the same time zone as a time series data group.</p><p id="p-0079" num="0078">On the other hand, <b>4</b><i>b </i>of <figref idref="DRAWINGS">FIG. <b>4</b></figref> represents a time series data group of a case in which the processing units <b>120</b>A and <b>120</b>B are defined by <b>2</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>2</b></figref>. In this case, the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_<b>3</b> and <b>140</b>B_<b>1</b> to <b>140</b>B_<b>3</b>, for example, acquire the time series data group <b>1</b> measured in accordance with wafer processing in the chamber A. Also, the time series data acquisition devices <b>140</b>A_n&#x2212;2 and <b>140</b>B_n&#x2212;2 acquire, for example, the time series data group <b>2</b> measured in accordance with the wafer processing in the chamber B. Also, the time series data acquisition devices <b>140</b>A_n&#x2212;1 to <b>140</b>A_n and <b>140</b>B_n&#x2212;1 to <b>140</b>B_n, for example, acquire the time series data group <b>3</b> measured in accordance with the wafer processing in the chamber C.</p><p id="p-0080" num="0079">In <b>4</b><i>a </i>of <figref idref="DRAWINGS">FIG. <b>4</b></figref>, a case is described in which the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>B_<b>1</b> to <b>140</b>B_n acquire time series data within the same time range measured in accordance with the processing of a wafer before processing in the chamber B as a time series data group. However, the time series data acquisition deices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>B_<b>1</b> to <b>140</b>B_n may acquire, as a time series data group, time series data of different time ranges measured in accordance with the processing of a wafer before processing in the chamber B.</p><p id="p-0081" num="0080">Specifically, the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>E_<b>1</b> to <b>140</b>E_n may acquire, as the time series data group <b>1</b>, a plurality of sets of time series data measured during executing the pre-processing. The time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>E_<b>1</b> to <b>140</b>E_n may acquire, as the time series data group <b>2</b>, a plurality of sets of time series data measured during executing the wafer processing. Further, the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>E_<b>1</b> to <b>140</b>E_n may acquire, as the time series data group <b>3</b>, a plurality of sets of time series data measured during executing the post-processing.</p><p id="p-0082" num="0081">Similarly, the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>B_<b>1</b> to <b>140</b>E_n may acquire a plurality of sets of time series data measured during executing the recipe I as the time series data group <b>1</b>. The time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>B_<b>1</b> to <b>140</b>B_n may acquire a plurality of sets of time series data measured during executing the recipe II as the time series data group <b>2</b>. Further, the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n and <b>140</b>B_<b>1</b> to <b>140</b>B_n may acquire a plurality of sets of time series data measured during executing the recipe III as the time series data group <b>3</b>.</p><p id="p-0083" num="0082">&#x3c;Hardware Configuration of Virtual Measurement Device&#x3e;</p><p id="p-0084" num="0083">Next, a hardware configuration of the virtual measurement devices <b>160</b>A and <b>160</b>B will be described. FIG. is a diagram illustrating an example of a hardware configuration of the virtual measurement devices. As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the virtual measurement devices <b>160</b>A and <b>160</b>B each includes a CPU (central processing unit) <b>501</b>, a ROM (read only memory) <b>502</b>, and a RAM (random access memory) <b>503</b>. The virtual measurement device <b>160</b> also includes a GPU (Graphics Processing Unit) <b>504</b>. The processors (processing circuit, processing circuitry) such as the CPU <b>501</b> and the GPU <b>504</b> and the memories such as the ROM <b>502</b> and the RAM <b>503</b> form a computer.</p><p id="p-0085" num="0084">The virtual measurement device <b>160</b> further includes an auxiliary storage device <b>505</b>, a display device <b>506</b>, an operating device <b>507</b>, an I/F (interface) device <b>508</b>, and a drive device <b>509</b>. The hardware parts of the virtual measurement device <b>160</b> are connected to one another through a bus <b>510</b>.</p><p id="p-0086" num="0085">The CPU <b>501</b> is an arithmetic device that executes various types of programs (e.g., a virtual measurement program) installed in the auxiliary storage device <b>505</b>.</p><p id="p-0087" num="0086">The ROM <b>502</b> is a nonvolatile memory and functions as a main memory device. The ROM <b>502</b> stores various types of programs, data, and the like necessary for the CPU <b>501</b> to execute the various types of programs installed in the auxiliary storage device <b>505</b>. Specifically, the ROM <b>502</b> stores boot programs and the like such as BIOS (basic input/output system) and EFI (extensible firmware interface).</p><p id="p-0088" num="0087">The RAM <b>503</b> is a volatile memory such as a DRAM (dynamic random access memory) or an SRAM (static random access memory) and functions as a main memory device. The RAM <b>503</b> provides a work area to which the various types of program installed in the auxiliary storage device <b>505</b> are loaded when executed by the CPU <b>501</b>.</p><p id="p-0089" num="0088">The GPU <b>504</b> is an arithmetic device for image processing, and when a virtual measurement program is executed by the CPU <b>501</b>, the GPU <b>504</b> performs high-speed calculation by parallel processing on various image data (in the present embodiment, a time series data group). The GPU <b>504</b> is equipped with an internal memory (CPU memory), and temporarily holds information necessary for performing parallel processing on various image data.</p><p id="p-0090" num="0089">The auxiliary storage device <b>505</b> stores various types of programs, and various types of data used when the various types of program are executed by the CPU <b>501</b>.</p><p id="p-0091" num="0090">The display device <b>506</b> is a display device that displays an internal state of the virtual measurement devices <b>160</b>A and <b>160</b>B. The operating device <b>507</b> is an input device that is used by an administrator of the virtual measurement devices <b>160</b>A and <b>160</b>B to input various types of instructions to the virtual measurement devices <b>160</b>A and <b>160</b>B. The I/F device <b>508</b> is a connection device for connecting to a non-illustrated network for performing communication.</p><p id="p-0092" num="0091">The drive device <b>509</b> is a device for setting a recording medium <b>520</b>. Here, the recording medium <b>520</b> includes a medium for optically, electrically, or magnetically recording information, such as a CD-ROM, a flexible disk, a magneto-optical disk, or the like. The recording medium <b>520</b> may also include a semiconductor memory or the like that electrically records information, such as a ROM, a flash memory, or the like.</p><p id="p-0093" num="0092">The various types of programs to be installed in the auxiliary storage device <b>505</b> are installed by the drive device <b>509</b> reading the various types of programs recorded in the recording medium <b>520</b> upon the recording medium <b>520</b> being set in the drive device <b>509</b>, for example. Alternatively, the various types of program to be installed in the auxiliary storage device <b>505</b> may be installed upon being downloaded from a network.</p><p id="p-0094" num="0093">&#x3c;Functional Configuration of Learning Section&#x3e;</p><p id="p-0095" num="0094">Next, a functional configuration of the learning section <b>161</b>A of the virtual measurement device <b>160</b>A in the system <b>100</b>A will be described. <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram illustrating an example of the functional configuration of the learning section of the virtual measurement device. The learning section <b>161</b>A includes a branch section <b>610</b>, a first network section <b>620</b>_<b>1</b> to an Mth network section <b>620</b>_M, a coupling section <b>630</b>, and a comparison section <b>640</b>.</p><p id="p-0096" num="0095">The branch section <b>610</b> reads out the time series data group from the learning data storage section <b>163</b>A. The branch section <b>610</b> processes the read-out time series data group so that the time series data group is processed using a plurality of network sections from the first network section <b>620</b>_<b>1</b> to the Mth network section <b>620</b>_M.</p><p id="p-0097" num="0096">The first network section <b>620</b>_<b>1</b> to the Mth network section <b>620</b>_M are configured based on a convolution neural network (CNN) and have a plurality of layers.</p><p id="p-0098" num="0097">Specifically, the first network section <b>620</b>_<b>1</b> includes a first layer <b>620</b>_<b>1</b> to an Nth layer <b>620</b>_<b>1</b>N. Similarly, the second network section <b>620</b>_<b>2</b> includes a first layer <b>620</b>_<b>21</b> to an Nth layer <b>620</b>_<b>2</b>N. Hereinafter, a similar configuration is included, and the Mth network section <b>620</b>_M includes a first layer <b>620</b>_M<b>1</b> to an Nth layer <b>620</b>_MN.</p><p id="p-0099" num="0098">In each layer of the first layer <b>620</b>_<b>1</b> to the Nth layer <b>620</b>_<b>1</b>N of the first network section <b>620</b>_<b>1</b>, various processes such as a normalization process, a convolution process, an activation process, and a pooling process are performed. Further, similar various processes are performed in each layer of the second network section <b>620</b>_<b>2</b> to the Mth network section <b>620</b>_M.</p><p id="p-0100" num="0099">The coupling section <b>630</b> combines respective output data from the output data output from the Nth layer <b>620</b>_<b>1</b>N of the first network section <b>620</b>_<b>1</b> to the output data output from the Nth layer <b>620</b>_MN of the Mth network section <b>620</b>_M and outputs the combined result to the comparison section <b>640</b>.</p><p id="p-0101" num="0100">The comparison section <b>640</b> compares the combined result output from the coupling section <b>630</b> with the inspection data (labeled data) read from the learning data storage section <b>163</b>A and calculates the error. In the learning section <b>161</b>A, mechanical learning is performed for the first network section <b>620</b>_<b>1</b> to the Mth network section <b>620</b>_M and the coupling section <b>630</b> so that the error calculated by the comparison section <b>640</b> satisfies a predetermined condition.</p><p id="p-0102" num="0101">Thus, the model parameters of the respective layers of the first network section <b>620</b>_<b>1</b> to the Mth network section <b>620</b>_M and the model parameters of the coupling section <b>630</b> are optimized.</p><p id="p-0103" num="0102">&#x3c;Details of Processing of Each Section of the Learning Section&#x3e;</p><p id="p-0104" num="0103">Next, the details of processing of each section (here, in particular, the branch section <b>610</b>) of the learning section <b>161</b>A of the virtual measurement device <b>160</b>A in the system <b>100</b>A will be described with reference to a specific example.</p><p id="p-0105" num="0104">(1) Detail 1 of Processing of Branch Section</p><p id="p-0106" num="0105"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a first diagram illustrating a specific example of processing of the branch section. In the case of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the branch section <b>610</b> generates the time series data group <b>1</b> (the first time series data group) by processing the time series data group measured by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n according to a first criterion and inputs it to the first network section <b>620</b>_<b>1</b>.</p><p id="p-0107" num="0106">Also, the branch section <b>610</b> generates the time series data group <b>2</b> (the second time series data group) by processing the time series data group measured by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n according to a second criterion and inputs it to the second network section <b>620</b>_<b>2</b>.</p><p id="p-0108" num="0107">As described above, by processing the time series data groups according to different criteria to be processed with divided respective different network sections to perform machine learning, the time series data groups can be analyzed in a multifaceted manner. As a result, it is possible to generate a virtual measurement model (inference section <b>162</b>A) that realizes high-precision inference compared to a case in which a time series data group is input to one network section and machine learning is performed.</p><p id="p-0109" num="0108">In the example of <figref idref="DRAWINGS">FIG. <b>7</b></figref>, a case is described in which two kinds of time series data groups are generated by processing a time series data group according to two kinds of criteria. However, by processing a time series data group according to three kinds or more of criteria, three kinds or more of time series data groups may be generated.</p><p id="p-0110" num="0109">(2) Detail 2 of Processing of Branch Section</p><p id="p-0111" num="0110">Next, another processing of the branch section <b>610</b> will be described in detail. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a second diagram illustrating a specific example of the processing of the branch section. In a case of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the branch section <b>610</b> divides a time series data group measured by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n into groups according to a data type. Therefore, the branch section <b>610</b> generates the time series data group <b>1</b> (the first time series data group) and the time series data group <b>2</b> (the second time series data group). The branch section <b>610</b> inputs the generated time series data group <b>1</b> to the third network section <b>620</b>_<b>3</b> and inputs the generated time series data group <b>2</b> to the fourth network section <b>620</b>_<b>4</b>.</p><p id="p-0112" num="0111">As described above, by dividing the time series data group into a plurality of groups according to a data type and by processing using different network sections to perform machine learning, the time series data group can be analyzed in a multifaceted manner. As a result, it is possible to generate a virtual measurement model (inference section <b>162</b>A) that realizes high-precision inference compared to a case in which a time series data group is input to one network section and machine learning is performed.</p><p id="p-0113" num="0112">In the example of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, a time series data group is divided into groups according to a difference in data type based on a difference in the time series data acquisition device <b>140</b>A_<b>1</b> to <b>140</b>A_n. However, a time series data group may be divided into groups according to a time range in which data is acquired. For example, in a case in which the time series data group is a time series data group measured in accordance with processing by a plurality of recipes, the time series data group may be divided into groups according to the time range for each recipe.</p><p id="p-0114" num="0113">(3) Detail 3 of Processing of Branch Section</p><p id="p-0115" num="0114">Next, another processing of the branch section <b>610</b> will be described in detail. <figref idref="DRAWINGS">FIG. <b>9</b></figref> is a third diagram illustrating a specific example of the processing of the branch section. In a case of <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the branch section <b>610</b> inputs the time series data group acquired by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n to both the fifth network section <b>620</b>_<b>5</b> and the sixth network section <b>620</b>_<b>6</b>. Then, different processings (normalization processes) are performed for the same time series data group by the fifth network section <b>620</b>_<b>5</b> and the sixth network section <b>620</b>_<b>6</b>.</p><p id="p-0116" num="0115"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram illustrating a specific example of processing of a normalization section included in each network section. As illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, each layer of the fifth network section <b>620</b>_<b>5</b> includes a normalization section, a convolutional section, an activation function section, and a pooling section.</p><p id="p-0117" num="0116">The example of <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates that, of each layer included in the fifth network section <b>620</b>_<b>5</b>, a first layer <b>620</b>_<b>51</b> includes a normalization section <b>1001</b>, a convolutional section <b>1002</b>, an activation function section <b>1003</b>, and a pooling section <b>1004</b>.</p><p id="p-0118" num="0117">Of these, the normalization section <b>1001</b> performs a first normalization process on the time series data group input by the branch section <b>610</b> and generates a normalized time series data group <b>1</b> (first time series data group).</p><p id="p-0119" num="0118">Similarly, the example of <figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates that, of each layer included in the sixth network section <b>620</b>_<b>6</b>, a first layer <b>620</b>_<b>61</b> includes a normalization section <b>1011</b>, a convolutional section <b>1012</b>, an activation function section <b>1013</b>, and a pooling section <b>1014</b>.</p><p id="p-0120" num="0119">Of these, the normalization section <b>1011</b> performs a second normalization process on the time series data group input by the branch section <b>610</b> and generates a second normalized time series data group <b>2</b> (second time series data group).</p><p id="p-0121" num="0120">As described above, by performing machine learning with a configuration of processing a time series data group using a plurality of network sections each of which includes a normalization section that performs a normalization process using a different method, the time series data group can be analyzed in a multifaceted manner. As a result, it is possible to generate a virtual measurement model (inference section <b>162</b>A) that realizes high-precision inference compared to a case in which a time series data group is input to one network section that performs one normalization process and machine learning is performed.</p><p id="p-0122" num="0121">(4) Detail 4 of Processing of Branch Section</p><p id="p-0123" num="0122">Next, another processing of the branch section <b>610</b> will be described in detail. <figref idref="DRAWINGS">FIG. <b>11</b></figref> is a fourth diagram illustrating a specific example of processing of the branch section. In a case of <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the branch section <b>610</b> inputs the time series data group <b>1</b> (the first time series data group) measured in accordance with the processing in the chamber A to the seventh network section <b>620</b>_<b>7</b> among the time series data groups measured by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n.</p><p id="p-0124" num="0123">The branch section <b>610</b> inputs the time series data group <b>2</b> (the second time series data group) measured in accordance with the processing in the chamber B to the eighth network section <b>620</b>_<b>8</b> among the time series data groups measured by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n.</p><p id="p-0125" num="0124">As described above, by performing machine learning with a configuration of using different network sections to process respective time series data groups measured in accordance with the processing in the different chambers (the first processing space and the second processing space), the time series data groups space) can be analyzed in a multifaceted manner. As a result, it is possible to generate a virtual measurement model (inference section <b>162</b>A) that realizes high-precision inference compared to a case in which machine learning is performed by inputting respective time series data groups to one network section.</p><p id="p-0126" num="0125">&#x3c;Function Configuration of Inference Section of Virtual Measurement Device&#x3e;</p><p id="p-0127" num="0126">Next, a functional configuration of the inference section <b>162</b>A of the virtual measurement device <b>160</b>A in the system <b>100</b>A will be described. <figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram illustrating an example of the functional configuration of the inference section of the virtual measurement device. As illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the inference section <b>162</b>A of the virtual measurement device <b>160</b>A includes a branch section <b>1210</b>, a first network section <b>1220</b>_<b>1</b> to a Mth network section <b>1220</b>_M, and a coupling section <b>1230</b>.</p><p id="p-0128" num="0127">The branch section <b>1210</b> acquires a time series data group newly measured by the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_N. The branch section <b>1210</b> performs control so that the acquired time series data group is processed using the first network section <b>1220</b>_<b>1</b> to the Mth network section <b>1220</b>_M.</p><p id="p-0129" num="0128">The first network section <b>1220</b>_<b>1</b> to the Mth network section <b>1220</b>_M are formed by machine learning performed by the learning section <b>161</b>A and optimizing model parameters of respective layers of the first network section <b>20</b>_<b>1</b> to the Mth network section <b>620</b>_M.</p><p id="p-0130" num="0129">The coupling section <b>1230</b> is formed by the coupling section <b>630</b> for which machine learning is performed by the learning section <b>161</b>A and model parameters are optimized. The coupling section <b>1230</b> combines the respective output data from the output data output from the Nth layer <b>1220</b>_<b>1</b>N of the first network section <b>1220</b>_<b>1</b> to the output data output from the Nth layer <b>1220</b>_MN of the Mth network section <b>1220</b>_M and outputs the virtual measurement data.</p><p id="p-0131" num="0130">&#x3c;Flow of Virtual Measurement Processing&#x3e;</p><p id="p-0132" num="0131">Next, the entire flow of virtual measurement processing by the virtual measurement device <b>160</b>A in the system <b>100</b>A will be described. <figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart illustrating a flow of virtual measurement processing performed by the virtual measurement device.</p><p id="p-0133" num="0132">In step S<b>1301</b>, the learning section <b>161</b>A acquires a time series data group and inspection data as learning data.</p><p id="p-0134" num="0133">In step S<b>1302</b>, the learning section <b>161</b>A performs machine learning with the time series data group as input data and the inspection data as labeled data of the acquired learning data.</p><p id="p-0135" num="0134">In step S<b>1303</b>, the learning section <b>161</b>A determines whether or not to continue machine learning. In a case of acquiring further learning data to continue the machine learning (in the case of YES in step S<b>1303</b>), the processing returns to step S<b>1301</b>. Meanwhile, in a case of ending the machine learning (in the case of NO in step S<b>1303</b>), the processing proceeds to step S<b>1304</b>.</p><p id="p-0136" num="0135">In step S<b>1304</b>, the inference section <b>162</b>A generates the first network section <b>1220</b>_<b>1</b> to the Mth network section <b>1220</b>_M by reflecting the model parameters optimized by the machine learning.</p><p id="p-0137" num="0136">In step S<b>1305</b>, the inference section <b>162</b>A inputs a time series data group measured in accordance with the processing of a new wafer <b>110</b>A before processing and infers virtual measurement data.</p><p id="p-0138" num="0137">In step S<b>1306</b>, the inference section <b>162</b>A outputs the inferred virtual measurement data.</p><p id="p-0139" num="0138">&#x3c;Functional Configuration of Inference Section with Fine-Tuning Function of Virtual Measurement Device&#x3e;</p><p id="p-0140" num="0139">Next, a functional configuration of the inference section <b>162</b>B with a fine-tuning function of the virtual measurement device <b>160</b>B in the system <b>100</b>B will be described. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating an example of the functional configuration of the inference section with a fine-tuning function of the virtual measurement device.</p><p id="p-0141" num="0140">As illustrated in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the inference section <b>162</b>B with a fine-tuning function of the virtual measurement device <b>160</b>B includes a branch section <b>1210</b> that functions as an acquisition section. Further, the inference section <b>162</b>B with a fine-tuning function of the virtual measurement device <b>160</b>B includes a first network section <b>1220</b>_<b>1</b> to a Mth network section <b>1220</b>_M, a coupling section <b>1410</b>, an individual tuning section <b>1420</b>, a fine-tuning section <b>1430</b>, and a comparison section <b>1440</b>, which function as an inference section.</p><p id="p-0142" num="0141">Of these, since the branch section <b>1210</b> is the same as the branch section <b>1210</b> of the inference section <b>162</b>A and has been described with reference to <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the description thereof will be omitted here. The first network section <b>1220</b>_<b>1</b> to the Mth network section <b>1220</b>_M are the same as the first network section <b>1220</b>_<b>1</b> to the Mth network section <b>1220</b>_M of the inference section <b>162</b>A.</p><p id="p-0143" num="0142">Specifically, the first network section <b>1220</b>_<b>1</b> to the Mth network section <b>1220</b>_M are formed by machine learning performed by the learning section <b>161</b>A and optimizing model parameters of respective layers of the first network section <b>20</b>_<b>1</b> to the Mth network section <b>620</b>_M.</p><p id="p-0144" num="0143">The coupling section <b>1410</b> is formed by the coupling section <b>630</b> for which machine learning is performed by the learning section <b>161</b>A and model parameters are optimized. However, in a case of the coupling section <b>1410</b>, the respective output data from the output data output from the Nth layer <b>1220</b>_<b>1</b>N of the first network section <b>1220</b>_<b>1</b> to the output data output from the Nth layer <b>1220</b>_MN of the Mth network section <b>1220</b>_M are output without being combined.</p><p id="p-0145" num="0144">The individual tuning section <b>1420</b> multiplies the respective output data output from the coupling section <b>1410</b> by a factor (referred to as the &#x201c;individual sensitivity&#x201d;) corresponding to the individual difference between the processing unit <b>120</b>A of the semiconductor manufacturing process A and the processing unit <b>120</b>B of the semiconductor manufacturing process B.</p><p id="p-0146" num="0145">The fine-tuning section <b>1430</b> multiplies the respective output data, by which the individual sensitivity is multiplied by the individual tuning section <b>1420</b>, a correction matrix to calculate virtual measurement data that is the scalar quantity.</p><p id="p-0147" num="0146">The comparison section <b>1440</b> acquires the virtual measurement data output by the fine-tuning section <b>1430</b> and acquires inspection data for the wafer <b>130</b>B after processing. The comparison section <b>1440</b> calculates the difference between the acquired virtual measurement data and the inspection data and sends a notification to the fine-tuning section <b>1430</b>.</p><p id="p-0148" num="0147">Thus, in the inference section <b>162</b>B with a fine-tuning function, the fine-tuning section <b>1430</b> updates the correction parameters (P<sub>1 </sub>to P<sub>M</sub>) based on the inspection data for the wafer <b>130</b>B after processing for a predetermined period of time in the semiconductor manufacturing process B. The fine-tuning section <b>430</b> of the inference section <b>162</b>B with the fine-tuning function continues to update the correction parameters (P<sub>1 </sub>to P<sub>M</sub>) until the difference between the virtual measurement data and the inspection data is equal to or less than a predetermined threshold value.</p><p id="p-0149" num="0148">This enables the fine-tuning section <b>1430</b> to reduce errors (errors included in the inference result) caused by the individual difference between the processing unit <b>120</b>A of the semiconductor manufacturing process A and the processing unit <b>120</b>B of the semiconductor manufacturing process B.</p><p id="p-0150" num="0149">In a case of the inference section <b>162</b>B with a fine-tuning function, the cost and time can be reduced compared to a case where, with time series data group measured in the semiconductor manufacturing process B as added data and a virtual measurement model is optimized by re-learning.</p><p id="p-0151" num="0150">&#x3c;Flow of Fine-Tuning Processing&#x3e;</p><p id="p-0152" num="0151">Next, a flow of fine-tuning processing performed by the virtual measurement device <b>160</b>B in the system <b>100</b>B will be described. <figref idref="DRAWINGS">FIG. <b>15</b></figref> is a flowchart illustrating a flow of fine-tuning processing by the virtual measurement device.</p><p id="p-0153" num="0152">In step S<b>1501</b>, the branch section <b>1210</b> of the inference section <b>162</b>B with a fine-tuning function acquires a time series data group measured in accordance with the processing of a new wafer <b>110</b>B before processing in the processing unit <b>120</b>B of the semiconductor manufacturing process B. The first to Mth network sections <b>1220</b>_<b>1</b> to <b>1220</b>_M of the inference sections <b>162</b>B with a fine-tuning function process the acquired time series data group. Accordingly, the respective output data are output from the final layers of the first to Mth network sections <b>1220</b>_<b>1</b> to <b>1220</b>_M.</p><p id="p-0154" num="0153">In step S<b>1502</b>, the individual tuning section <b>1420</b> of the inference section <b>162</b>B with a fine-tuning function tunes the respective output data by multiplying the respective output data output from the final layers of the first to Mth network sections <b>1220</b>_<b>1</b> to <b>1220</b>_M by the individual sensitivity.</p><p id="p-0155" num="0154">In step S<b>1503</b>, the fine-tuning section <b>1430</b> of the inference section <b>162</b>B with a fine-tuning function multiplies the respective output data, by which the individual sensitivity is multiplied, by the correction matrix to calculate the virtual measurement data.</p><p id="p-0156" num="0155">In step S<b>1504</b>, the inference section <b>162</b>B with a fine-tuning function acquires inspection data for the post-processed wafer <b>130</b>B and sends a notification to the comparison section <b>1440</b>. Also, the comparison section <b>1440</b> compares the virtual measurement data output from the fine-tuning unit <b>1430</b> with the reported inspection data and calculates the difference (error included in the inference result).</p><p id="p-0157" num="0156">In step S<b>1505</b>, the comparison section <b>1440</b> of the inference section <b>162</b>B with a fine-tuning function determines whether or not it is necessary to update the correction parameters by determining whether or not the difference is equal to or less than the predetermined threshold value based on the comparison result.</p><p id="p-0158" num="0157">In a case of determining in step S<b>1505</b> that the difference exceeds the predetermined threshold value and it is necessary to update the correction parameters (in the case of YES in step S<b>1505</b>), the processing proceeds to step S<b>1506</b>.</p><p id="p-0159" num="0158">In step S<b>1506</b>, the fine-tuning section <b>1430</b> of the inference section <b>162</b>B with a fine-tuning function updates correction parameters (P<sub>1 </sub>to P<sub>M</sub>) of the correction matrix in accordance with the difference (error included in the inference result) calculated by the comparison section <b>1440</b>. Thereafter, the processing proceeds to step S<b>1507</b>.</p><p id="p-0160" num="0159">Meanwhile, in a case of determining in step S<b>1505</b> that the difference is equal to or less than the predetermined threshold value and it is not necessary to update the correction parameters (in the case of NO in Step S<b>1505</b>), the processing proceeds directly to step S<b>1507</b>.</p><p id="p-0161" num="0160">In step S<b>1507</b>, the inference section <b>162</b>B with a fine-tuning function determines whether to end the fine-tuning processing. In a case of determining in step S<b>1507</b> not to end the fine-tuning processing (in the case of NO in step S<b>1507</b>), the processing returns to step S<b>1501</b>.</p><p id="p-0162" num="0161">Meanwhile, in a case of determining in step S<b>1507</b> to end the fine-tuning processing (in the case of YES in step S<b>1507</b>), the fine-tuning processing ends.</p><p id="p-0163" num="0162">&#x3c;Summary&#x3e;</p><p id="p-0164" num="0163">As is obvious from the above description, the virtual measurement device <b>160</b>A</p><p id="p-0165" num="0164">acquires a time series data group measured in accordance with the processing of a target in a predetermined processing unit of a manufacturing process; and</p><p id="p-0166" num="0165">performs machine learning for respective network sections so that the combined result of respective output data output from the respective network sections by processing the acquired time series data group using the plurality of network sections approaches inspection data of a result object obtained by processing the target object.</p><p id="p-0167" num="0166">As described above, multifaceted analysis can be performed by processing a time series data group using a plurality of network sections. As a result, the virtual measurement device <b>160</b>A can generate a virtual measurement model that realizes high-precision inference.</p><p id="p-0168" num="0167">Also, the virtual measurement device <b>160</b>B (inference device)</p><p id="p-0169" num="0168">uses a plurality of network sections included in the generated virtual measurement model to process a time series data group measured in accordance with the processing of a target in a predetermined processing unit of another manufacturing process to output respective output data;</p><p id="p-0170" num="0169">combines the respective output data after being fine-tuned using correction parameters to infer virtual measurement data; and</p><p id="p-0171" num="0170">updates the correction parameters according to an error included in the inferred virtual measurement data.</p><p id="p-0172" num="0171">As described above, when applying a virtual measurement model generated using a time series data group to another manufacturing process at a predetermined processing unit of a manufacturing process, the virtual measurement device <b>160</b>B adds a function to fine-tune respective output data that is output from a plurality of network sections.</p><p id="p-0173" num="0172">This enables to reduce errors (errors included in an inference result) due to individual differences between processes when applying the virtual measurement model to other manufacturing processes. That is, according to the first embodiment, an inference device, an inference method, and an inference program that can realize high-precision inference regardless of an application target can be provided.</p><heading id="h-0012" level="1">Second Embodiment</heading><p id="p-0174" num="0173">In the above-described first embodiment, respective output data output from the final layers of the respective network sections are fine-tuned using an individual sensitivity and a correction matrix. However, the method of fine-tuning the respective output data by the inference section with a fine-tuning function is not limited thereto. For example, a network section for fine-tuning may be used to fine-tune the respective output data.</p><p id="p-0175" num="0174"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a second diagram illustrating an example of a functional configuration of an inference section with a fine-tuning function of the virtual measurement device. For the difference from <figref idref="DRAWINGS">FIG. <b>14</b></figref>, in a case of the inference section <b>1600</b>B with a fine-tuning function illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, a fine-tuning network section <b>1610</b> is included.</p><p id="p-0176" num="0175">The fine-tuning network section <b>1610</b> is configured based on a convolutional neural network and outputs virtual measurement data by inputting respective output data output from the coupling section <b>1410</b>.</p><p id="p-0177" num="0176">The fine-tuning network section <b>1610</b> updates the correction parameters that are model parameters of the fine-tuning network section <b>1610</b> based on the difference reported from the comparison section <b>1440</b> in accordance with the output of the virtual measurement data.</p><p id="p-0178" num="0177">Thus, in the inference section <b>1600</b>B with a fine-tuning function, the fine-tuning network section <b>1610</b> updates the correction parameters based on the inspection data for the wafer <b>130</b>B after processing for a predetermined period of time in the semiconductor manufacturing process B. At this time, the model parameters of the first network section <b>1220</b>_<b>1</b> to the Mth network section <b>1220</b>_M are be maintained in a fixed state. Then, the fine-tuning network section <b>16100</b> of the inference section <b>1600</b>B with a fine-tuning function continues to update the correction parameters until the difference between the virtual measurement data and the inspection data is equal to or less than a predetermined threshold value.</p><p id="p-0179" num="0178">This enables the fine-tuning network section <b>1610</b> to reduce an error (an error included in an inference result) caused by an individual difference between the processing unit <b>120</b>A of the semiconductor manufacturing process A and the processing unit <b>120</b>B of the semiconductor manufacturing process B.</p><p id="p-0180" num="0179">In a case of the inference section <b>1600</b>B with a fine-tuning function, the possibility of overfitting can be reduced compared to a case in which a virtual measurement model is newly generated and it is optimized using a time series data group measured in the semiconductor manufacturing process B.</p><heading id="h-0013" level="1">Third Embodiment</heading><p id="p-0181" num="0180">In the first and second embodiments described above, a virtual measurement model generated by the virtual measurement device <b>160</b>A is applied to another semiconductor manufacturing process B. However, the model applied to another semiconductor manufacturing process B is not limited to the virtual measurement model.</p><p id="p-0182" num="0181">In a third embodiment, a case is described in which the virtual measurement devices <b>160</b>A and <b>160</b>B described in the first and second embodiments are read as the abnormality detection devices <b>160</b>A and <b>160</b>B and an abnormality detection model generated by the abnormality detection device <b>160</b>A is applied to another semiconductor manufacturing process B.</p><p id="p-0183" num="0182">In a case of the abnormality detection device <b>160</b>A, the learning section <b>161</b>A performs machine learning on an abnormality detection model (inference section <b>162</b>A) with a time series data group as input data and an event (information indicating the presence or absence of an abnormality) as labeled data. The abnormality detection model (inference section <b>162</b>A) has a similar configuration to the virtual measurement model (inference section <b>162</b>A), and differs only in learning data used for machine learning.</p><p id="p-0184" num="0183">In a case of the abnormality detection device <b>160</b>A, examples of the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n that output a time series data group used for machine learning include:</p><p id="p-0185" num="0184">an emission spectroscopy analyzer that outputs OES (Optical Emission Spectrometry) data, which is a time series data group;</p><p id="p-0186" num="0185">a process data acquisition device that outputs process data such as temperature data or pressure data, which is a time series data group; and</p><p id="p-0187" num="0186">a radio-frequency power supply device for plasma that outputs RF data, which is time series data.</p><p id="p-0188" num="0187">Also, in a case of the abnormality detection device <b>160</b>B (inference device), the inference section <b>1600</b>B with a fine-tuning function inputs the time series data group and infers information indicating the presence or absence of an abnormality.</p><p id="p-0189" num="0188">In a case of the abnormality detection device <b>160</b>B, examples of the time series data acquisition devices <b>140</b>A_<b>1</b> to <b>140</b>A_n that output a time series data group used for inference include:</p><p id="p-0190" num="0189">an emission spectroscopy analyzer that outputs OES (Optical Emission Spectrometry) data, which is a time series data group;</p><p id="p-0191" num="0190">a process data acquisition device that outputs process data such as temperature data or pressure data, which is a time series data group; and</p><p id="p-0192" num="0191">a radio-frequency power supply device for plasma that outputs RF data, which is time series data.</p><p id="p-0193" num="0192">&#x3c;Summary&#x3e;</p><p id="p-0194" num="0193">As is obvious from the above description, the abnormality detection device <b>160</b>A</p><p id="p-0195" num="0194">acquires a time series data group (OES data, process data, RF data) measured in accordance with the processing of a target in a predetermined processing unit of a manufacturing process; and</p><p id="p-0196" num="0195">performs machine learning for respective network sections so that the combined result of respective output data output from the respective network sections by processing the acquired time series data group using the plurality of network sections approaches an invent (information indicating the presence or absence of an abnormality) that occurs in accordance with the processing of the target.</p><p id="p-0197" num="0196">In this way, by processing a time series data group using a plurality of network sections, it is possible to perform multifaceted analysis. As a result, the abnormality detection device <b>160</b>A can generate an abnormality detection model that realizes high-precision inference.</p><p id="p-0198" num="0197">Also, the abnormality detection device <b>160</b>B (inference device)</p><p id="p-0199" num="0198">uses a plurality of network sections included in the generated abnormality detection model to process a time series data group (OES data, process data, RF data) measured in accordance with the processing of a target object in a predetermined processing unit of another manufacturing process to output respective output data;</p><p id="p-0200" num="0199">combines the respective output data after being fine-tuned using correction parameters to infer information indicating the presence or absence of an abnormality; and</p><p id="p-0201" num="0200">updates the correction parameters according to an error included in the inferred information indicating the presence or absence of an abnormality.</p><p id="p-0202" num="0201">As described above, when applying an anomality detection model generated using a time series data group to another manufacturing process at a predetermined processing unit of a manufacturing process, the anomality detection device <b>160</b>B adds a function to fine-tune respective output data that is output from a plurality of network sections.</p><p id="p-0203" num="0202">This enables to reduce errors (errors included in an inference result) due to individual differences between processes when applying the virtual measurement model to other manufacturing processes. That is, according to the third embodiment, an inference device, an inference method, and an inference program that can realize high-precision inference regardless of an application target can be provided.</p><heading id="h-0014" level="1">Other Embodiments</heading><p id="p-0204" num="0203">In the above-described first and second embodiments, a case is described in which an individual sensitivity and a correction matrix or a network section for fine-tuning are used as a method of fine-tuning each output data. However, the method of fine-tuning respective output data is not limited thereto, and, for example, a generalized linear mixed model, Gaussian process regression analysis, Kalman filter, or the like may be used.</p><p id="p-0205" num="0204">In the third embodiment described above, the abnormality detection device acquires OES data, process data, or RF data output from an emission spectroscopic analyzer, a process data acquisition device, or a radio-frequency power supply device for plasma in accordance with the processing of a target object. However, the combination of data acquired by the abnormality detection device is not limited thereto. Any one of data may be acquired, or a combination of two data may be acquired.</p><p id="p-0206" num="0205">In each of the above-described embodiments, the inference sections <b>162</b>B and <b>1600</b>B with a fine-tuning function include the first to Mth network sections <b>1220</b>_<b>1</b> to <b>1220</b>_M. However, the inference sections <b>162</b>B and <b>1600</b>B with a fine-tuning function are not required to include all of first to Mth network sections <b>1220</b>_<b>1</b> to <b>1220</b>_M, but include at least two or more of the network sections.</p><p id="p-0207" num="0206">In each of the above-described embodiments, a machine learning algorithm of each network section of the learning section <b>161</b>A is described as being configured based on a convolutional neural network. However, the machine learning algorithm of each network section of the learning section <b>161</b>A is not limited to a convolutional neural network, and may be configured based on other machine learning algorithms.</p><p id="p-0208" num="0207">In each of the embodiments described above, the virtual measurement device or the abnormality detection device <b>160</b>A functions as the learning section <b>161</b>A and the inference section <b>162</b>A. However, a device functioning as the learning section <b>161</b>A need not be integral with a device functioning as the inference section <b>162</b>A, but may be configured separately. That is, the virtual measurement device or the abnormality detection device <b>160</b>A may function as the learning section <b>161</b>A not including the inference section <b>162</b>A, or may function as the inference section <b>162</b>A not including the learning section <b>161</b>A.</p><p id="p-0209" num="0208">In each of the embodiments described above, a virtual measurement device (or an abnormality detection device) in which a fine-tuning function is added to a virtual measurement model (or an abnormality detection model) generated in the system <b>100</b>A is to applied to the system <b>100</b>B. However, the application target to which the virtual measurement device (or the abnormal detection device), to which a fine-tuning function is added, is applied is not limited to other systems, but may be the own system.</p><p id="p-0210" num="0209">For example, in a case where the degree of change is small, such as a case where a part of a process recipe is changed, a fine-tuning function may be added to a virtual measurement model (or an abnormal detection model) generated by the own system.</p><p id="p-0211" num="0210">Alternatively, it may be applied when the accuracy of a virtual measurement model (or an abnormality detection model) generated by the own system decreases, for example, when a maintenance work such as parts replacement is performed on a device in the own system, or when the environment inside a device changes due to consumption of parts of the device in the own system.</p><p id="p-0212" num="0211">The present invention is not limited to configurations illustrated here, such as combinations with other elements in the configurations and the like described in the above embodiments. These respects can be changed without departing from the spirit of the present invention, and can be determined appropriately in accordance with the application form.</p><p id="p-0213" num="0212">The present application is based on and claims priority to Japanese Patent Application No. 2019-217439, filed on Nov. 29, 2019, the entire contents of the Japanese Patent Application are hereby incorporated herein by reference.</p><heading id="h-0015" level="1">DESCRIPTION OF THE REFERENCE NUMERALS</heading><p id="p-0214" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0213"><b>100</b>A, <b>100</b>B: System</li>    <li id="ul0001-0002" num="0214"><b>110</b>A, <b>110</b>B: Wafer before processing</li>    <li id="ul0001-0003" num="0215"><b>120</b>A, <b>120</b>B: Processing Unit</li>    <li id="ul0001-0004" num="0216"><b>130</b>A, <b>130</b>B: Wafer after processing</li>    <li id="ul0001-0005" num="0217"><b>140</b>A_<b>1</b> to <b>140</b>A_n: Time series data acquisition device</li>    <li id="ul0001-0006" num="0218"><b>140</b>B_<b>1</b> to <b>140</b>B_n: Time series data acquisition device</li>    <li id="ul0001-0007" num="0219"><b>150</b>A, <b>150</b>B: Inspection data acquisition device</li>    <li id="ul0001-0008" num="0220"><b>160</b>A, <b>160</b>B: Virtual measurement device</li>    <li id="ul0001-0009" num="0221"><b>161</b>A: Learning section</li>    <li id="ul0001-0010" num="0222"><b>162</b>A: Inference section</li>    <li id="ul0001-0011" num="0223"><b>162</b>B: Inference section with fine-tuning function</li>    <li id="ul0001-0012" num="0224"><b>200</b>: Semiconductor manufacturing device</li>    <li id="ul0001-0013" num="0225"><b>610</b>: Branch section</li>    <li id="ul0001-0014" num="0226"><b>620</b>_<b>1</b>: First network section</li>    <li id="ul0001-0015" num="0227"><b>620</b>_<b>11</b> to <b>620</b>_<b>1</b>N: First Layer to Nth Layer</li>    <li id="ul0001-0016" num="0228"><b>620</b>_<b>2</b>: Second network section</li>    <li id="ul0001-0017" num="0229"><b>620</b>_<b>21</b> to <b>620</b>_<b>2</b>N: First Layer to Nth Layer</li>    <li id="ul0001-0018" num="0230"><b>620</b>_M: Mth network section</li>    <li id="ul0001-0019" num="0231"><b>620</b>_M<b>1</b> to <b>620</b>_MN: First Layer to Nth Layer</li>    <li id="ul0001-0020" num="0232"><b>630</b>: Coupling section</li>    <li id="ul0001-0021" num="0233"><b>640</b>: Comparison section</li>    <li id="ul0001-0022" num="0234"><b>1001</b>, <b>1011</b>: Normalization section</li>    <li id="ul0001-0023" num="0235"><b>1004</b>, <b>1014</b>: Pooling section</li>    <li id="ul0001-0024" num="0236"><b>1210</b>: Branch section</li>    <li id="ul0001-0025" num="0237"><b>1220</b>_<b>1</b>: First network section</li>    <li id="ul0001-0026" num="0238"><b>1220</b>_<b>11</b> to <b>1220</b>_<b>1</b>N: First layer to Nth layer</li>    <li id="ul0001-0027" num="0239"><b>1220</b> <b>2</b>: Second network section</li>    <li id="ul0001-0028" num="0240"><b>1220</b>_<b>21</b> to <b>1220</b>_<b>2</b>N: First layer to Nth layer</li>    <li id="ul0001-0029" num="0241"><b>1220</b>_M: Mth Network section</li>    <li id="ul0001-0030" num="0242"><b>1220</b>_M<b>1</b> to <b>1220</b>_MN: First layer to Nth layer</li>    <li id="ul0001-0031" num="0243"><b>1240</b>: Coupling section</li>    <li id="ul0001-0032" num="0244"><b>1410</b>: Coupling section</li>    <li id="ul0001-0033" num="0245"><b>1420</b>: Individual tuning section</li>    <li id="ul0001-0034" num="0246"><b>1430</b>: Fine-tuning section</li>    <li id="ul0001-0035" num="0247"><b>1440</b>: Comparison section</li>    <li id="ul0001-0036" num="0248"><b>1600</b>B: Inference section with fine-tuning function</li>    <li id="ul0001-0037" num="0249"><b>1610</b>: Fine-tuning network section</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An inference device comprising:<claim-text>a memory; and</claim-text><claim-text>a processor that is coupled to the memory and that is configured to;</claim-text><claim-text>acquire a time series data group measured in accordance with processing of a target object in a predetermined processing unit of a manufacturing process;</claim-text><claim-text>function as a machine-learned version of a plurality of network sections and a machine-learned version of a coupling section, the plurality of network sections being configured to process the acquired time series data group to output respective output data, the coupling section being configured to combine the respective output data to output a combined result, and the plurality of network sections and the coupling section being machine-learned such that the combined result output from the coupling section approaches inspection data that is obtained from a resultant object obtained by processing the target object; and</claim-text><claim-text>tune the respective output data that is output by processing the acquired time series data group using the machine-learned version of the plurality of network sections and that is not combined by the machine-learned version of the coupling section, and output an inference result by combining the respective tuned output data;</claim-text><claim-text>wherein the processor is configured to tune the respective output data using a correction parameter corresponding to an error included in the inference result.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The inference device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to update the correction parameter so as to reduce the error included in the inference result in a state in which model parameters of the machine-learned version of the plurality of network sections is fixed.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The inference device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,<claim-text>wherein the processor is configured to generate a first time series data group and a second time series data group by processing the acquired time series data group according to a first criterion and a second criterion, respectively, and to process the generated first time series data group and the second time series data group using the machine-learned version of the plurality of networks sections.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The inference device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>,<claim-text>wherein the processor is configured to divide the acquired time series data group into groups according to a data type or a time range and to process the respective divided groups using the machine-learned version of the plurality of network sections.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The inference device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the processor is configured to process the acquired time series data group using the machine-learned version of the plurality of network sections, each of which includes a normalization section that performs a normalization process using a different method.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The inference device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the processor is configured to:<claim-text>divide the acquired time series data group into<claim-text>a first time series data group that is measured in accordance with the processing of the target object in a first processing space of the predetermined processing unit, and</claim-text><claim-text>a second time series data group that is measured in accordance with the processing of the target object in a second processing space; and</claim-text></claim-text><claim-text>process the first time series data group and the second time series data group using the machine-learned version of the plurality of network sections.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The inference device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the time series data group is data measured in accordance with processing in a substrate processing device.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. An inference method comprising:<claim-text>acquiring a time series data group measured in accordance with processing of a target object in a predetermined processing unit of a manufacturing process;</claim-text><claim-text>processing the acquired time series data group by using a machine-learned version of a plurality of network sections and a machine-learned version of a coupling section, the plurality of network sections being configured to process the acquired time series data group too output respective output data, the coupling section being configured to combine the respective output data to output a combined result, and the plurality of network sections and the coupling section being machine-learned such that the combined result output from the coupling section approaches inspection data that is obtained from a resultant object obtained by processing the target object; and</claim-text><claim-text>tuning the respective output data that is output by processing the acquired time series data group using the machine-learned version of the plurality of network sections and that is not combined by the machine-learned version of the coupling section, and outputting an inference result by combining the respective tuned output data;</claim-text><claim-text>wherein the respective output data are tuned using a correction parameter corresponding to an error included in the inference result.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A non-transitory recording computer readable medium storing an inference program that causes a computer to execute:<claim-text>acquiring a time series data group measured in accordance with processing of a target object in a predetermined processing unit of a manufacturing process;</claim-text><claim-text>processing the acquired time series data group by using a machine-learned version of a plurality of network sections and a machine-learned version of a coupling section, the plurality of network sections being configured to process the acquired time series data group to output respective output data, the coupling section being configured to combine the respective output data to output a combined result, and the plurality of network sections and the coupling section being machine-learned such that the combined result output from the coupling section approaches inspection data that is obtained from a resultant object obtained by processing the target object; and</claim-text><claim-text>tuning the respective output data that is output by processing the acquired time series data group using the machine-learned version of the plurality of network sections and that is not combined by the machine-learned version of the coupling section, and outputting an inference result by combining the respective tuned output data;</claim-text><claim-text>wherein the respective output data are tuned using a correction parameter corresponding to an error included in the inference result.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005149A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005149</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17930720</doc-number><date>20220909</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2020-065268</doc-number><date>20200331</date></priority-claim><priority-claim sequence="02" kind="national"><country>JP</country><doc-number>2020-219603</doc-number><date>20201228</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>13</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>22</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>0014</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>90</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>13</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>10</main-group><subgroup>22</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>0414</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>502</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>4417</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>A</section><class>61</class><subclass>B</subclass><main-group>6</main-group><subgroup>542</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30068</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10028</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10024</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20220101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>V</subclass><main-group>2201</main-group><subgroup>03</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30196</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>30204</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10116</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>2207</main-group><subgroup>10064</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e79">INFORMATION PROCESSING DEVICE, RADIOGRAPHY APPARATUS, INFORMATION PROCESSING METHOD, AND INFORMATION PROCESSING PROGRAM</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>PCT/JP2021/011505</doc-number><date>20210319</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17930720</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>FUJIFILM CORPORATION</orgname><address><city>Tokyo</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>NAKAYAMA</last-name><first-name>Hiroki</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>ODA</last-name><first-name>Yoshinari</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>NOBUYAMA</last-name><first-name>Lisako</first-name><address><city>Kanagawa</city><country>JP</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A CPU acquires a distance image or a visible light image captured by a TOF camera or a visible light camera that has, as an imageable region, a region including an irradiation region which is a space in which a breast of a subject imaged by a mammography apparatus is irradiated with radiation emitted from a radiation source and detects whether or not a foreign object other than an object to be imaged is present in the irradiation region on the basis of the distance image or the visible light image.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="94.06mm" wi="158.75mm" file="US20230005149A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="143.09mm" wi="146.56mm" file="US20230005149A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="246.38mm" wi="151.21mm" file="US20230005149A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="246.21mm" wi="113.54mm" file="US20230005149A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="214.04mm" wi="162.90mm" file="US20230005149A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="250.95mm" wi="114.47mm" file="US20230005149A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="240.54mm" wi="134.87mm" file="US20230005149A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="241.47mm" wi="110.24mm" file="US20230005149A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="248.16mm" wi="150.45mm" file="US20230005149A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="229.62mm" wi="139.87mm" file="US20230005149A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="249.77mm" wi="153.08mm" file="US20230005149A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="235.37mm" wi="162.48mm" file="US20230005149A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="216.75mm" wi="162.39mm" file="US20230005149A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="251.12mm" wi="137.75mm" file="US20230005149A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="251.04mm" wi="151.21mm" orientation="landscape" file="US20230005149A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="248.92mm" wi="162.56mm" file="US20230005149A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="249.60mm" wi="152.40mm" file="US20230005149A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="239.86mm" wi="163.66mm" file="US20230005149A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="159.17mm" wi="132.93mm" file="US20230005149A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="227.92mm" wi="158.50mm" orientation="landscape" file="US20230005149A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="181.61mm" wi="163.49mm" file="US20230005149A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="249.85mm" wi="141.65mm" file="US20230005149A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="249.77mm" wi="152.40mm" file="US20230005149A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="240.45mm" wi="161.63mm" file="US20230005149A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application is a continuation application of International Application No. PCT/JP2021/011505, filed on Mar. 19, 2021, the disclosure of which is incorporated herein by reference in its entirety. Further, this application claims priority from Japanese Patent Application No. 2020-065268, filed on Mar. 31, 2020, and Japanese Patent Application No. 2020-219603, filed on Dec. 28, 2020, the disclosures of which are incorporated herein by reference in their entireties.</p><?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">1. Technical Field</heading><p id="p-0003" num="0002">The present disclosure relates to an information processing device, a radiography apparatus, an information processing method, and an information processing program.</p><heading id="h-0004" level="1">2. Description of the Related Art</heading><p id="p-0004" num="0003">In capture of a radiographic image by a radiography apparatus, in a case in which a radiographic image is captured in a state in which a foreign object, such as a part other than an object to be imaged in a subject, enters an irradiation region of radiation emitted from a radiation source, it may be necessary to re-capture a radiographic image. Therefore, in the capture of the radiographic image, a user checks an irradiation range of the radiation indicated by visible light to check whether or not a foreign object is present in the irradiation region of the radiation. For example, JP2018-157941A discloses a technique that indicates an irradiation field of radiation with visible light.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">As described above, the foreign object that has entered the irradiation region of the radiation is detected in the related art. However, in the technique according to the related art, in some cases, it is not sufficient to detect the foreign object that has entered the irradiation region of the radiation. For example, in some cases, after the user checks positioning, the subject moves, and a part of the subject other than the object to be imaged enters the irradiation region. The technique according to the related art is not capable of responding to this case, and re-imaging may be required.</p><p id="p-0006" num="0005">The present disclosure has been made in consideration of the above circumstances, and an object of the present disclosure is to provide an information processing device, a radiography apparatus, an information processing method, and an information processing program that can appropriately detect whether or not a foreign object other than an object to be imaged is present in an irradiation region of radiation.</p><p id="p-0007" num="0006">According to a first aspect of the present disclosure, there is provided an information processing device comprising: at least one processor; and a memory that stores commands executable by the processor. The processor acquires a captured image captured by an imaging device that has, as an imageable region, a region including an irradiation region which is a space in which an object to be imaged by a radiography apparatus is irradiated with radiation emitted from a radiation source and detects whether or not a foreign object other than the object to be imaged is present in the irradiation region on the basis of the captured image.</p><p id="p-0008" num="0007">According to a second aspect of the present disclosure, in the information processing device according to the first aspect, the processor may acquire information indicating the irradiation region and detect whether or not the foreign object is present in the irradiation region indicated by the information.</p><p id="p-0009" num="0008">According to a third aspect of the present disclosure, in the information processing device according to the first aspect or the second aspect, the processor may derive a space between the object to be imaged and the radiation source in the irradiation region as a detection region and detect whether or not the foreign object is present in the derived detection region.</p><p id="p-0010" num="0009">According to a fourth aspect of the present disclosure, in the information processing device according to the third aspect, the radiography apparatus may be a mammography apparatus that captures a radiographic image of a breast of a subject, and the detection region may be a space between a compression member that compresses the breast and the radiation source in the irradiation region.</p><p id="p-0011" num="0010">According to a fifth aspect of the present disclosure, in the information processing device according to the third aspect or the fourth aspect, the imaging device may be a distance image capture device that captures a distance image indicating a distance to the object to be imaged as the captured image.</p><p id="p-0012" num="0011">According to a sixth aspect of the present disclosure, in the information processing device according to the fifth aspect, the processor may detect whether or not the foreign object is present in the detection region using an image corresponding to the detection region in the distance image.</p><p id="p-0013" num="0012">According to a seventh aspect of the present disclosure, in the information processing device according to the sixth aspect, the processor may detect whether or not the foreign object is present in the detection region on the basis of a distance between the imaging device and each position in the detection region derived on the basis of a position of the detection region and a distance between the imaging device and the object to be imaged indicated by the image corresponding to the detection region in the distance image.</p><p id="p-0014" num="0013">According to an eighth aspect of the present disclosure, in the information processing device according to any one of the fifth to seventh aspects, the distance image capture device may capture the distance image using a time-of-flight (TOF) method.</p><p id="p-0015" num="0014">According to a ninth aspect of the present disclosure, in the information processing device according to any one of the first to fourth aspects, the imaging device may be a visible light image capture device that captures a visible light image of the object to be imaged as the captured image.</p><p id="p-0016" num="0015">According to a tenth aspect of the present disclosure, in the information processing device according to the first aspect, the radiography apparatus may be a mammography apparatus that captures a radiographic image of a breast compressed by a compression member, and the imaging device may be a visible light image capture device that captures a visible light image of the object to be imaged as the captured image. The processor may detect whether or not the foreign object is present on the basis of a chipping of an image of the compression member in the captured image.</p><p id="p-0017" num="0016">According to an eleventh aspect of the present disclosure, in the information processing device according to the tenth aspect, the processor may detect whether or not the foreign object is present on the basis of a chipping of a subject on the breast in the image of the compression member.</p><p id="p-0018" num="0017">According to a twelfth aspect of the present disclosure, in the information processing device according to the tenth aspect or the eleventh aspect, the processor may use an image of an edge portion of the compression member as the image of the compression member.</p><p id="p-0019" num="0018">According to a thirteenth aspect of the present disclosure, in the information processing device according to the twelfth aspect, the processor may acquire compression member information indicating a type of the compression member and estimate at least one of a position or a size of the image of the edge portion included in the captured image on the basis of the compression member information.</p><p id="p-0020" num="0019">According to a fourteenth aspect of the present disclosure, in the information processing device according to the twelfth aspect or the thirteenth aspect, the edge portion of the compression member may have a color different from a color of at least one of a compression surface, which compresses the breast, in the compression member or an imaging table on which the breast is placed, and the processor may extract the image of the edge portion of the compression member from the captured image on the basis of the color of the edge portion.</p><p id="p-0021" num="0020">According to a fifteenth aspect of the present disclosure, in the information processing device according to the twelfth aspect or the thirteenth aspect, the edge portion of the compression member may be processed to be distinguishable from an image of a compression surface, which compresses the breast, in the compression member in the captured image, and the processor may extract the image of the edge portion from the captured image.</p><p id="p-0022" num="0021">According to a sixteenth aspect of the present disclosure, in the information processing device according to the fifteenth aspect, the edge portion of the compression member may be highlighted by at least one of a phosphorescent material or a fluorescent material.</p><p id="p-0023" num="0022">According to a seventeenth aspect of the present disclosure, in the information processing device according to any one of the tenth to sixteenth aspects, the processor may detect whether or not the foreign object is present on the basis of a chipping of an image of a region corresponding to a type of the imaging in an image of the compression member.</p><p id="p-0024" num="0023">According to an eighteenth aspect of the present disclosure, in the information processing device according to the first aspect, the radiography apparatus may be a mammography apparatus that captures a radiographic image of a breast compressed by a compression member, and the imaging device may be a visible light image capture device that captures, as the captured image, a visible light image obtained by capturing a projection image projected onto an irradiation surface of the compression member, which is irradiated with the radiation, by an image projection device.</p><p id="p-0025" num="0024">According to a nineteenth aspect of the present disclosure, in the information processing device according to the eighteenth aspect, the projection image projected onto the irradiation surface may be projected within a range of an irradiation field of the radiation.</p><p id="p-0026" num="0025">According to a twentieth aspect of the present disclosure, in the information processing device according to the eighteenth aspect or the nineteenth aspect, the projection image projected onto the irradiation surface may be projected within a range of an irradiation field of the radiation in a state in which visible light is not emitted by an irradiation field projection device that projects the range of the irradiation field of the radiation with the visible light.</p><p id="p-0027" num="0026">According to a twenty-first aspect of the present disclosure, in the information processing device according to any one of the eighteenth to twentieth aspects, the processor may detect whether or not the foreign object is present on the basis of an image of a region corresponding to an inside of an irradiation field of the radiation in the captured image.</p><p id="p-0028" num="0027">According to a twenty-second aspect of the present disclosure, in the information processing device according to any one of the eighteenth to twenty-first aspects, the processor may detect whether or not the foreign object is present on the basis of a comparison result between the projection image and the captured image.</p><p id="p-0029" num="0028">According to a twenty-third aspect of the present disclosure, in the information processing device according to any one of the eighteenth to twenty-first aspects, the processor may control the image projection device such that the projection image is projected onto a region including an irradiation field of the radiation.</p><p id="p-0030" num="0029">According to a twenty-fourth aspect of the present disclosure, in the information processing device according to the twenty-third aspect, the processor may derive a size and position of the irradiation field on the irradiation surface of the compression member according to a height of the compression member and perform control to project the projection image according to the derived size and position of the irradiation field.</p><p id="p-0031" num="0030">According to a twenty-fifth aspect of the present disclosure, in the information processing device according to the first aspect, the radiography apparatus may be a mammography apparatus that captures a radiographic image of a breast compressed by a compression member, and the imaging device may be a visible light image capture device that captures, as the captured image, an image of a state in which a range of an irradiation field of the radiation is projected onto the compression member by an irradiation field projection device that projects the range of the irradiation field of the radiation with visible light.</p><p id="p-0032" num="0031">According to a twenty-sixth aspect of the present disclosure, in the information processing device according to any one of the first to twenty-fifth aspects, in a case in which it is detected that the foreign object is present, the processor may prohibit the emission of the radiation by the radiation source.</p><p id="p-0033" num="0032">According to a twenty-seventh aspect of the present disclosure, in the information processing device according to any one of the first to twenty-sixth aspects, in a case in which it is detected that the foreign object is present, the processor may output a warning related to the foreign object.</p><p id="p-0034" num="0033">According to a twenty-eighth aspect of the present disclosure, in the information processing device according to any one of the first to twenty-seventh aspects, a plurality of the imaging devices may be provided, and an imageable region of all of the plurality of imaging devices, which is a combination of the imageable regions of each of the plurality of imaging devices, may include the irradiation region.</p><p id="p-0035" num="0034">According to a twenty-ninth aspect of the present disclosure, there is provided a radiography apparatus comprising: the information processing device according to the present disclosure; and an imaging device.</p><p id="p-0036" num="0035">Further, in order to achieve the above object, according to a thirtieth aspect of the present disclosure, there is provided an information processing method executed by a computer. The information processing method comprises: acquiring a captured image captured by an imaging device that has, as an imageable region, a region including an irradiation region which is a space in which an object to be imaged by a radiography apparatus is irradiated with radiation emitted from a radiation source; and detecting whether or not a foreign object other than the object to be imaged is present in the irradiation region on the basis of the captured image.</p><p id="p-0037" num="0036">According to a thirty-first aspect of the present disclosure, there is provided an information processing program that causes a computer to execute a process comprising: acquiring a captured image captured by an imaging device that has, as an imageable region, a region including an irradiation region which is a space in which an object to be imaged by a radiography apparatus is irradiated with radiation emitted from a radiation source; and detecting whether or not a foreign object other than the object to be imaged is present in the irradiation region on the basis of the captured image.</p><p id="p-0038" num="0037">According to the present disclosure, it is possible to appropriately detect whether or not a foreign object other than an object to be imaged is present in an irradiation region of radiation.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0039" num="0038">Exemplary embodiments according to the technique of the present disclosure will be described in detail based on the following figures, wherein:</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic diagram illustrating an example of an overall configuration of a radiography system according to a first embodiment,</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a side view illustrating an example of the outward appearance of a mammography apparatus according to the first embodiment,</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram illustrating an irradiation region of radiation,</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram illustrating an imageable region of a TOF camera,</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram illustrating an example of a configuration of a console according to the first embodiment,</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a functional block diagram illustrating an example of a functional configuration of the console according to the first embodiment,</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>7</b>A</figref> is a diagram illustrating a detection region,</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> is a diagram illustrating a case in which a foreign object is present in the detection region,</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example of the flow of a foreign object detection process of a console according to the first embodiment,</p><p id="p-0049" num="0048"><figref idref="DRAWINGS">FIG. <b>9</b>A</figref> is a diagram illustrating a case in which a foreign object is present between the detection region and the TOF camera,</p><p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>9</b>B</figref> is a diagram illustrating an aspect in which an imageable region of the TOF camera and the irradiation region are matched with each other,</p><p id="p-0051" num="0050"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a side view illustrating an example of the outward appearance of a mammography apparatus according to a second embodiment,</p><p id="p-0052" num="0051"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart illustrating an example of the flow of a foreign object detection process of a console according to the second embodiment,</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a side view illustrating an example of the outward appearance of a mammography apparatus according to a third embodiment,</p><p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a diagram illustrating an imageable region of a visible light camera,</p><p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a diagram illustrating an example of a visible light image captured by the visible light camera,</p><p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a functional block diagram illustrating an example of a functional configuration of a console according to the third embodiment,</p><p id="p-0057" num="0056"><figref idref="DRAWINGS">FIG. <b>16</b></figref> is a diagram illustrating an example of a visible light image captured by the visible light camera in a case in which a foreign object is present in the irradiation region,</p><p id="p-0058" num="0057"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart illustrating an example of the flow of a foreign object detection process of the console according to the third embodiment,</p><p id="p-0059" num="0058"><figref idref="DRAWINGS">FIG. <b>18</b></figref> is a diagram illustrating a state of the mammography apparatus in CC imaging and MLO imaging,</p><p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an example of the flow of a foreign object detection process of the console according to Modification Example 1,</p><p id="p-0061" num="0060"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a side view illustrating an example of the outward appearance of a mammography apparatus according to a fourth embodiment,</p><p id="p-0062" num="0061"><figref idref="DRAWINGS">FIG. <b>21</b></figref> is a diagram illustrating a projection image projected onto a projection surface,</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>22</b></figref> is a diagram illustrating an example of a visible light image captured by the visible light camera,</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>23</b></figref> is a functional block diagram illustrating an example of a functional configuration of a console according to the fourth embodiment,</p><p id="p-0065" num="0064"><figref idref="DRAWINGS">FIG. <b>24</b></figref> is a diagram illustrating the position and size of an irradiation field on a projection surface,</p><p id="p-0066" num="0065"><figref idref="DRAWINGS">FIG. <b>25</b></figref> is a diagram illustrating an example of a visible light image captured by the visible light camera in a case in which a foreign object is present in the irradiation region,</p><p id="p-0067" num="0066"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a flowchart illustrating an example of the flow of a foreign object detection process of the console according to the fourth embodiment,</p><p id="p-0068" num="0067"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a side view illustrating an example of the outward appearance of the mammography apparatus according to the fourth embodiment,</p><p id="p-0069" num="0068"><figref idref="DRAWINGS">FIG. <b>28</b></figref> is a diagram illustrating an example of information for supporting positioning which is displayed on a display unit, and</p><p id="p-0070" num="0069"><figref idref="DRAWINGS">FIG. <b>29</b></figref> is a diagram illustrating an aspect in which an irradiation region is included in an imageable region of a plurality of TOF cameras.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading><p id="p-0071" num="0070">Hereinafter, embodiments of the invention will be described in detail with reference to the drawings. In addition, each of the embodiments does not limit the invention.</p><heading id="h-0008" level="1">First Embodiment</heading><p id="p-0072" num="0071">First, an example of an overall configuration of a radiography system according to this embodiment will be described. <figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram illustrating an example of the overall configuration of a radiography system <b>1</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the radiography system <b>1</b> according to this embodiment comprises a mammography apparatus <b>10</b> and a console <b>12</b>. The mammography apparatus <b>10</b> according to this embodiment is an example of a radiography apparatus according to the present disclosure. Further, the console <b>12</b> according to this embodiment is an example of an information processing device according to the present disclosure.</p><p id="p-0073" num="0072">First, the mammography apparatus <b>10</b> according to this embodiment will be described. <figref idref="DRAWINGS">FIG. <b>2</b></figref> is a side view illustrating an example of the outward appearance of the mammography apparatus <b>10</b> according to this embodiment. In addition, <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an example of the outward appearance of the mammography apparatus <b>10</b> as viewed from the right side of a subject.</p><p id="p-0074" num="0073">The mammography apparatus <b>10</b> according to this embodiment irradiates a breast of the subject as an object with radiation R (for example, X-rays) to capture a radiographic image of the breast. In addition, the mammography apparatus <b>10</b> may be an apparatus that images the breast of the subject not only in a state in which the subject is standing up (standing state) but also in a state in which the subject is sitting on, for example, a chair (including a wheelchair) (sitting state).</p><p id="p-0075" num="0074">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the mammography apparatus <b>10</b> according to this embodiment comprises a control unit <b>20</b>, a storage unit <b>22</b>, and an interface (I/F) unit <b>24</b> which are provided in an imaging table <b>30</b>. The control unit <b>20</b> controls the overall operation of the mammography apparatus <b>10</b> under the control of the console <b>12</b>. The control unit <b>20</b> comprises a central processing unit (CPU), a read only memory (ROM), and a random access memory (RAM) which are not illustrated. For example, various programs including an imaging processing program which is executed by the CPU and is used to perform control related to the capture of radiographic images are stored in the ROM in advance. The RAM temporarily stores various kinds of data.</p><p id="p-0076" num="0075">For example, image data of the radiographic image captured by a radiation detector <b>28</b> and various other kinds of information are stored in the storage unit <b>22</b>. Specific examples of the storage unit <b>22</b> include a hard disk drive (HDD) and a solid state drive (SSD). The I/F unit <b>24</b> transmits and receives various kinds of information to and from the console <b>12</b> using wireless communication or wired communication. The image data of the radiographic image captured by the radiation detector <b>28</b> in the mammography apparatus <b>10</b> is transmitted to the console <b>12</b> through the I/F unit <b>24</b> by wireless communication or wired communication.</p><p id="p-0077" num="0076">In addition, an operation unit <b>26</b> is provided as a plurality of switches in, for example, the imaging table <b>30</b> of the mammography apparatus <b>10</b>. Further, the operation unit <b>26</b> may be provided as a touch panel switch or may be provided as a foot switch that is operated by the user's feet.</p><p id="p-0078" num="0077">The radiation detector <b>28</b> detects the radiation R transmitted through the breast which is the object. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the radiation detector <b>28</b> is disposed in the imaging table <b>30</b>. In the mammography apparatus <b>10</b> according to this embodiment, in a case in which imaging is performed, the breast of the subject is positioned on an imaging surface <b>30</b>A of the imaging table <b>30</b> by a user such as a doctor or a radiology technician.</p><p id="p-0079" num="0078">The radiation detector <b>28</b> detects the radiation R transmitted through the breast of the subject and the imaging table <b>30</b>, generates a radiographic image on the basis of the detected radiation R, and outputs image data indicating the generated radiographic image. The type of the radiation detector <b>28</b> according to this embodiment is not particularly limited. For example, the radiation detector <b>28</b> may be an indirect-conversion-type radiation detector that converts the radiation R into light and converts the converted light into charge or a direct-conversion-type radiation detector that directly converts the radiation R into charge.</p><p id="p-0080" num="0079">A radiation emitting unit <b>37</b> comprises a radiation source <b>37</b>R having a radiation tube (not illustrated) that emits the radiation R to the imaging table <b>30</b>. Further, the radiation emitting unit <b>37</b> comprises a collimator <b>33</b>. The control unit <b>20</b> controls the collimator <b>33</b> such that an irradiation region <b>70</b> of the radiation R is set as illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref> and an irradiation field <b>71</b> of the radiation R on the imaging surface <b>30</b>A of the imaging table <b>30</b> is defined. <figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of the irradiation region <b>70</b> of the radiation R emitted from the radiation source <b>37</b>R in a state in which a breast WB of a subject W imaged by the mammography apparatus <b>10</b> is compressed by a compression plate <b>40</b>. The irradiation region <b>70</b> is a space in which an object to be imaged by the mammography apparatus <b>10</b> is irradiated with the radiation R emitted from the radiation source <b>37</b>R. In addition, the size and shape of the irradiation field <b>71</b> according to this embodiment are determined according to, for example, the size of an detection surface (not illustrated) of the radiation detector <b>28</b> or the size of the breast WB as the object to be imaged. The control unit <b>20</b> controls the collimator <b>33</b> according to the size and shape of the irradiation field <b>71</b>. For example, in this embodiment, the irradiation field <b>71</b> has a rectangular shape. Therefore, the irradiation region <b>70</b> according to this embodiment is a region having a rectangular pyramid shape which has a focus of the radiation tube (not illustrated) of the radiation source <b>37</b>R as the apex and the irradiation field <b>71</b> as the base.</p><p id="p-0081" num="0080">In addition, in this embodiment, the object to be imaged is the breast WB of the subject. However, the object to be imaged is not limited to the breast WB and includes objects, such as markers, whose images are approved to be included in a radiographic image. Further, in this embodiment, for example, the compression plate <b>40</b> which is approved to be disposed in the imaging region of the radiographic image in the capture of the radiographic image is also regarded as the object to be imaged. Furthermore, an object which is other than the object to be imaged and enters the irradiation region <b>70</b> is referred to as a &#x201c;foreign object&#x201d;. Examples of the foreign object include the head WH and hands (not illustrated) of the subject W and objects other than the subject W.</p><p id="p-0082" num="0081">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the radiation emitting unit <b>37</b> is provided in an arm portion <b>32</b> together with the imaging table <b>30</b> and a compression unit <b>36</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a face guard <b>38</b> for protecting the subject from the radiation R emitted from the radiation source <b>37</b>R is attachably and detachably attached at a position of the arm portion <b>32</b> near the subject below the radiation emitting unit <b>37</b>.</p><p id="p-0083" num="0082">In addition, a time-of-flight (TOF) camera <b>39</b> is provided at a position of the arm portion <b>32</b> which is away from the subject below the radiation emitting unit <b>37</b>. The TOF camera <b>39</b> is a camera that captures a distance image indicating a distance to the object to be imaged using a TOF method. The TOF camera <b>39</b> according to this embodiment is an example of an imaging device and a distance image capture device according to the present disclosure. Specifically, the TOF camera <b>39</b> emits light, such as infrared rays, to the object to be imaged and measures the distance between the TOF camera <b>39</b> and the object to be imaged on the basis of the time until reflected light is received or a phase change between the emitted light and the received light. In the distance image captured by the TOF camera <b>39</b>, each pixel has distance information indicating the distance between the TOF camera <b>39</b> and the object to be imaged. Further, the distance image means an image from which the distance to the object to be imaged can be derived. Furthermore, as illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the TOF camera <b>39</b> according to this embodiment is disposed in a state in which the entire irradiation region <b>70</b> is included in an imageable region <b>72</b>. Therefore, the distance image captured by the TOF camera <b>39</b> includes an image corresponding to the irradiation region <b>70</b>. In addition, in the TOF camera <b>39</b> according to this embodiment, the imageable region <b>72</b> is defined by the design.</p><p id="p-0084" num="0083">Further, as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the mammography apparatus <b>10</b> according to this embodiment comprises the arm portion <b>32</b>, a base <b>34</b>, and a shaft portion <b>35</b>. The arm portion <b>32</b> is held by the base <b>34</b> to be movable in an up-down direction (Z-axis direction). The shaft portion <b>35</b> connects the arm portion <b>32</b> to the base <b>34</b>. In addition, the arm portion <b>32</b> can be relatively rotated with respect to the base <b>34</b>, using the shaft portion <b>35</b> as a rotation axis.</p><p id="p-0085" num="0084">Each of the arm portion <b>32</b> and the compression unit <b>36</b> can be relatively rotated with respect to the base <b>34</b>, using the shaft portion <b>35</b> as a rotation axis. In this embodiment, gears (not illustrated) are provided in each of the shaft portion <b>35</b>, the arm portion <b>32</b>, and the compression unit <b>36</b>. Each gear is switched between an engaged state and a disengaged state to connect each of the arm portion <b>32</b> and the compression unit <b>36</b> to the shaft portion <b>35</b>. One or both of the arm portion <b>32</b> and the compression unit <b>36</b> connected to the shaft portion <b>35</b> are rotated integrally with the shaft portion <b>35</b>.</p><p id="p-0086" num="0085">The compression unit <b>36</b> is provided with a compression plate driving unit (not illustrated) that moves a compression plate <b>40</b> in the up-down direction (Z-axis direction). The compression plate <b>40</b> according to this embodiment has a function of compressing the breast of the subject. A support portion <b>46</b> of the compression plate <b>40</b> is attachably and detachably attached to the compression plate driving unit and is moved in the up-down direction (Z-axis direction) by the compression plate driving unit to compress the breast of the subject between the compression plate <b>40</b> and the imaging table <b>30</b>. The compression plate <b>40</b> according to this embodiment is an example of a compression member according to the present disclosure.</p><p id="p-0087" num="0086">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the compression plate <b>40</b> according to this embodiment includes a bottom portion <b>43</b>, a wall portion <b>44</b>, and the support portion <b>46</b> and has a recessed shape in a cross-sectional view in which the bottom portion <b>43</b> that comes into contact with the breast of the subject is surrounded by the wall portion <b>44</b>.</p><p id="p-0088" num="0087">In addition, there are a plurality of types of compression plates <b>40</b> that can be attached to the mammography apparatus <b>10</b>. In this example, the compression plate <b>40</b> compresses the entire breast. However, the present disclosure is not limited thereto. For example, a compression plate <b>40</b> that compresses a portion of the breast may be used. In other words, the compression plate <b>40</b> may be smaller than the breast. For example, as the compression plate <b>40</b>, a compression plate <b>40</b> is known which is used for so-called spot imaging that captures a radiographic image of only a region in which a lesion is present. Further, other types of compression plates <b>40</b> include, for example, a compression plate corresponding to the size of the breast, a compression plate for axillary imaging, and a compression plate for magnification imaging. Furthermore, although the compression plate <b>40</b> is referred to as a &#x201c;compression plate&#x201d; for convenience, it is not limited to a compression plate using a plate-shaped member. For example, the compression plate <b>40</b> may be a compression plate using a film-shaped member.</p><p id="p-0089" num="0088">Meanwhile, the console <b>12</b> according to this embodiment has a function of controlling the mammography apparatus <b>10</b> using, for example, an imaging order and various kinds of information acquired from a radiology information system (RIS) <b>2</b> or the like through a wireless communication local area network (LAN) or the like and instructions input by the user through an operation unit <b>56</b> or the like.</p><p id="p-0090" num="0089">For example, the console <b>12</b> according to this embodiment is a server computer. As illustrated in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the console <b>12</b> comprises a control unit <b>50</b>, a storage unit <b>52</b>, an I/F unit <b>54</b>, the operation unit <b>56</b>, and a display unit <b>58</b>. The control unit <b>50</b>, the storage unit <b>52</b>, the I/F unit <b>54</b>, the operation unit <b>56</b>, and the display unit <b>58</b> are connected to each other through a bus <b>59</b>, such as a system bus or a control bus, such that they can transmit and receive various kinds of information.</p><p id="p-0091" num="0090">The control unit <b>50</b> according to this embodiment controls the overall operation of the console <b>12</b>. The control unit <b>50</b> comprises a CPU <b>50</b>A, a ROM <b>50</b>B, and a RAM <b>50</b>C. For example, various programs including a foreign object detection processing program <b>51</b> executed by the CPU <b>50</b>A are stored in the ROM <b>50</b>B in advance. The RAM <b>50</b>C temporarily stores various kinds of data. The CPU <b>50</b>A according to this embodiment is an example of a processor according to the present disclosure, and the ROM <b>50</b>B according to this embodiment is an example of a memory according to the present disclosure. Further, the foreign object detection processing program <b>51</b> according to this embodiment is an example of an information processing program according to the present disclosure.</p><p id="p-0092" num="0091">For example, the image data of the radiographic image captured by the mammography apparatus <b>10</b> and various other kinds of information are stored in the storage unit <b>52</b>. An HDD or an SSD is given as a specific example of the storage unit <b>52</b>.</p><p id="p-0093" num="0092">The operation unit <b>56</b> is used by the user to input, for example, instructions which are related to the capture of a radiographic image or the like and include an instruction to emit the radiation R, various kinds of information, or the like. The operation unit <b>56</b> is not particularly limited. Examples of the operation unit <b>56</b> include various switches, a touch panel, a touch pen, and a mouse. The display unit <b>58</b> displays various kinds of information. In addition, the operation unit <b>56</b> and the display unit <b>58</b> may be integrated into a touch panel display.</p><p id="p-0094" num="0093">The I/F unit <b>54</b> transmits and receives various kinds of information to and from the mammography apparatus <b>10</b> and the RIS <b>2</b> using wireless communication or wired communication. In the radiography system <b>1</b> according to this embodiment, the console <b>12</b> receives the image data of the radiographic image captured by the mammography apparatus <b>10</b> from the mammography apparatus <b>10</b> through the I/F unit <b>54</b>, using wireless communication or wired communication.</p><p id="p-0095" num="0094">In addition, <figref idref="DRAWINGS">FIG. <b>6</b></figref> is a functional block diagram illustrating an example of the functional configuration of the console <b>12</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the console <b>12</b> comprises a first acquisition unit <b>60</b>, a second acquisition unit <b>62</b>, and a detection unit <b>64</b>. For example, in the console <b>12</b> according to this embodiment, the CPU <b>50</b>A of the control unit <b>50</b> executes the foreign object detection processing program <b>51</b> stored in the ROM <b>50</b>B to function as the first acquisition unit <b>60</b>, the second acquisition unit <b>62</b>, and the detection unit <b>64</b>.</p><p id="p-0096" num="0095">The first acquisition unit <b>60</b> has a function of acquiring information indicating the irradiation region <b>70</b>. In addition, the method by which the first acquisition unit <b>60</b> acquires the information indicating the irradiation region <b>70</b> is not limited. The irradiation region <b>70</b> is determined according to the setting of the collimator <b>33</b> and the distance between the radiation source <b>37</b>R and the imaging surface <b>30</b>A of the imaging table <b>30</b>. The setting of the collimator <b>33</b> and the distance between the radiation source <b>37</b>R and the imaging surface <b>30</b>A can be checked by the mammography apparatus <b>10</b>. Therefore, for example, first, the control unit <b>20</b> of the mammography apparatus <b>10</b> derives the irradiation region <b>70</b> on the basis of the setting of the collimator <b>33</b> and the distance between the radiation source <b>37</b>R and the imaging surface <b>30</b>A. Then, the first acquisition unit <b>60</b> may acquire the information indicating the irradiation region <b>70</b> derived by the control unit <b>20</b> from the mammography apparatus <b>10</b>. Further, the present disclosure is not limited to this embodiment. For example, the console <b>12</b> may acquire information indicating the setting of the collimator <b>33</b> and information indicating the distance between the radiation source <b>37</b>R and the imaging surface <b>30</b>A. Then, the console <b>12</b> may derive the information indicating the irradiation region <b>70</b> using the acquired information. The first acquisition unit <b>60</b> may acquire the derived information indicating the irradiation region <b>70</b>. The information indicating the irradiation region <b>70</b> acquired by the first acquisition unit <b>60</b> is output to the detection unit <b>64</b>.</p><p id="p-0097" num="0096">The second acquisition unit <b>62</b> has a function of acquiring the distance image captured by the TOF camera <b>39</b>. For example, the second acquisition unit <b>62</b> according to this embodiment acquires image data indicating the distance image captured by the TOF camera <b>39</b> from the TOF camera <b>39</b> through the I/F unit <b>24</b> and the I/F unit <b>54</b>. The distance image acquired by the second acquisition unit <b>62</b> is output to the detection unit <b>64</b>.</p><p id="p-0098" num="0097">The detection unit <b>64</b> has a function of detecting whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> on the basis of the distance image. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, the detection unit <b>64</b> according to this embodiment derives a space between the object to be imaged and the radiation source <b>37</b>R as a detection region <b>74</b> in the irradiation region <b>70</b> and detects whether or not a foreign object is present in the derived detection region <b>74</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>A</figref>, specifically, the detection region <b>74</b> according to this embodiment is a space from an upper surface (a surface facing the radiation source <b>37</b>R) of the bottom portion <b>43</b> of the compression plate <b>40</b> to the radiation source <b>37</b>R in the irradiation region <b>70</b>. More specifically, the detection region <b>74</b> is a space from the upper surface of the bottom portion <b>43</b> of the compression plate <b>40</b> that compresses the breast WB to the radiation source <b>37</b>R in the irradiation region <b>70</b>. Therefore, the detection region <b>74</b> is determined according to a height H of the breast WB compressed by the compression plate <b>40</b>, a thickness of the bottom portion <b>43</b> of the compression plate <b>40</b>, and the irradiation region <b>70</b>. As described above, since the detection region <b>74</b> according to this embodiment is determined by the height H of the breast WB compressed by the compression plate <b>40</b>, the size of the detection region <b>74</b> changes depending on the breast WB and a compressed state of the breast WB. In addition, in this embodiment, it is assumed that the thickness of the bottom portion <b>43</b> is ignored for convenience since the thickness of the bottom portion <b>43</b> is relatively small.</p><p id="p-0099" num="0098">For example, first, the detection unit <b>64</b> according to this embodiment acquires the thickness H of the breast WB compressed by the compression plate <b>40</b> in order to derive the detection region <b>74</b>. Further, the method by which the detection unit <b>64</b> acquires the thickness H of the breast WB is not limited. For example, a detection unit that detects the amount of movement of the compression plate <b>40</b> by the compression plate driving unit (not illustrated) provided in the compression unit <b>36</b> of the compression plate <b>40</b> may be provided, and the detection unit <b>64</b> may acquire the thickness of the breast WB derived from the amount of movement of the compression plate <b>40</b> detected by the detection unit. Furthermore, for example, a sensor or the like for detecting the height from the imaging surface <b>30</b>A to the compression plate <b>40</b>, that is, the thickness H of the breast WB may be provided in the mammography apparatus <b>10</b> or the like, and the detection unit <b>64</b> may acquire the thickness H detected by the sensor. Moreover, for example, a marker or the like may be provided on a region which does not overlap the breast WB, such as an end portion of the compression plate <b>40</b>, the distance between the TOF camera <b>39</b> and the marker may be measured on the basis of an image of the marker included in the distance image, and the distance between the TOF camera <b>39</b> and the marker may be subtracted from the distance between the TOF camera <b>39</b> and the imaging surface <b>30</b>A to acquire the thickness H of the breast WB.</p><p id="p-0100" num="0099">The detection unit <b>64</b> subtracts the thickness H of the breast WB from the distance between the radiation source <b>37</b>R and the imaging surface <b>30</b>A to derive the distance between the radiation source <b>37</b>R and the bottom portion <b>43</b>. In addition, the detection unit <b>64</b> extracts a rectangular pyramid that has the radiation source <b>37</b>R as the apex, the bottom portion <b>43</b> as the base, and the length of a perpendicular line as the distance between the radiation source <b>37</b>R and the bottom portion <b>43</b> to derive the detection region <b>74</b> in the irradiation region <b>70</b>.</p><p id="p-0101" num="0100">Further, the detection unit <b>64</b> detects whether or not a foreign object is present in the detection region <b>74</b> on the basis of the distance between each position in the detection region <b>74</b> derived on the basis of the position of the detection region <b>74</b> and the TOF camera <b>39</b> and an image corresponding to the detection region <b>74</b> in the distance image acquired from the TOF camera <b>39</b>. Specifically, since the position where the TOF camera <b>39</b> is disposed, specifically, the three-dimensional coordinates of the TOF camera <b>39</b> are known in advance, the distance between a position in the detection region <b>74</b> and the TOF camera <b>39</b> is obtained. More specifically, it is possible to obtain a pixel value (hereinafter, referred to as a pixel value of the detection region <b>74</b>) in a case in which a position in the detection region <b>74</b> is represented by a distance image. In a case in which an object is present in the detection region <b>74</b>, the pixel value of a pixel indicating the distance to the object in the distance image is any of the pixel values of each position in the detection region <b>74</b>.</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>7</b>B</figref> illustrates an example of a state in which the head WH of the subject W enters the detection region <b>74</b> as the foreign object. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>, the pixel value of the image corresponding to the detection region <b>74</b> in the distance image captured by the TOF camera <b>39</b> is a pixel value in which the distance measured by infrared rays reflected by the head WH in the detection region <b>74</b> has been reflected. Therefore, the detection unit <b>64</b> compares the pixel value of the image corresponding to the detection region <b>74</b> in the distance image acquired from the TOF camera <b>39</b> with the pixel value of each position in the detection region <b>74</b>. In a case in which the pixel value of the image corresponding to the detection region <b>74</b> in the distance image is any of the pixel values of each position in the detection region <b>74</b>, the detection unit <b>64</b> determines that a foreign object is present in the detection region <b>74</b>. In this case, the detection unit <b>64</b> outputs a detection result indicating that a foreign object is present. On the other hand, in a case in which the pixel value of the image corresponding to the detection region <b>74</b> in the distance image acquired from the TOF camera <b>39</b> is not any of the pixel values of each position in the detection region <b>74</b>, the detection unit <b>64</b> determines that a foreign object is absent in the detection region <b>74</b>. In addition, in this embodiment, in a case in which it is determined that a foreign object is absent in the detection region <b>74</b>, the detection unit <b>64</b> does not output the detection result. However, unlike this embodiment, the detection unit <b>64</b> may output a detection result indicating that a foreign object is absent.</p><p id="p-0103" num="0102">Next, the operation of the console <b>12</b> according to this embodiment will be described with reference to the drawings.</p><p id="p-0104" num="0103">In the console <b>12</b> according to this embodiment, the CPU <b>50</b>A of the control unit <b>50</b> executes the foreign object detection processing program <b>51</b> stored in the ROM <b>50</b>B to perform a foreign object detection process whose example is illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. <figref idref="DRAWINGS">FIG. <b>8</b></figref> is a flowchart illustrating an example of the flow of the foreign object detection process performed in the console <b>12</b> according to this embodiment. In addition, the timing when the CPU <b>50</b>A performs the foreign object detection process is not limited and may be any timing. For example, the CPU <b>50</b>A performs the foreign object detection process at the timing when the movement of the compression plate <b>40</b> is stopped, the timing when an instruction to emit the radiation R is received, or the like.</p><p id="p-0105" num="0104">In Step S<b>100</b> of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the first acquisition unit <b>60</b> acquires the information indicating the irradiation region <b>70</b> as described above. Then, in Step S<b>102</b>, the detection unit <b>64</b> acquires the thickness H of the breast WB as described above. Then, in Step S<b>104</b>, the detection unit <b>64</b> derives the detection region <b>74</b> on the basis of the information indicating the irradiation region <b>70</b> and the thickness H of the breast WB as described above.</p><p id="p-0106" num="0105">Then, in Step S<b>106</b>, the detection unit <b>64</b> converts the distance from the TOF camera <b>39</b> to each position in the detection region <b>74</b> into the pixel value of the distance image. Specifically, the detection unit <b>64</b> converts the distance between the TOF camera <b>39</b> and each position in the detection region <b>74</b> into the pixel value of the distance image to derive the pixel value of each position in the detection region <b>74</b>. Then, in Step S<b>108</b>, the second acquisition unit <b>62</b> acquires the distance image from the TOF camera <b>39</b> as described above.</p><p id="p-0107" num="0106">Then, in Step S<b>110</b>, the detection unit <b>64</b> compares the pixel value of the image corresponding to the detection region <b>74</b> in the distance image acquired from the TOF camera <b>39</b> with the pixel value of each position of the detection region <b>74</b> as described above. Then, in Step S<b>112</b>, the detection unit <b>64</b> determines whether or not a foreign object is present in the detection region <b>74</b>. As described above, in a case in which the pixel value of the image corresponding to the detection region <b>74</b> in the distance image is any of the pixel values of each position of the detection region <b>74</b>, the detection unit <b>64</b> determines that a foreign object is present in the detection region <b>74</b>. In a case in which the detection unit <b>64</b> determines that a foreign object is present, the determination result in Step S<b>112</b> is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>114</b>.</p><p id="p-0108" num="0107">In Step S<b>114</b>, the detection unit <b>64</b> outputs the detection result indicating that a foreign object is present and an instruction to respond to the foreign object. In addition, the output destination of the detection result and the like is not particularly limited and may be the display unit <b>58</b> of the console <b>12</b> or the display unit (not illustrated) of the mammography apparatus <b>10</b>. Further, the detection result and the like may be output to a plurality of output destinations. Furthermore, the instruction to respond to the foreign object is not limited. An example of the instruction is an instruction to prohibit the emission of the radiation R by the radiation source <b>36</b>R. Moreover, an example of the instruction is an instruction to output information for warning the user that a foreign object is present in the detection region <b>74</b>. In a case in which the warning is issued in this way, a warning method is not limited. For example, in addition to displaying the warning on the display unit <b>58</b>, the warning may be issued by sound, light, or the like. In addition, the present disclosure is not limited to this embodiment. For example, the detection unit <b>64</b> may further output information indicating the position, size, and the like of the foreign object present in the detection region <b>74</b>. The position, size, and the like of the foreign object can be specified from the position of a pixel corresponding to the pixel value of the detection region <b>74</b> among the pixels of the image corresponding to the detection region <b>74</b> in the distance image. Further, the type of the foreign object may be determined on the basis of the position, size, and the like of the detected foreign object, and information indicating the determined type of the foreign object may be output. Furthermore, a method for determining the type of the foreign object on the basis of the position, size, and the like of the detected foreign object is not particularly limited. Image analysis, such as template matching, using an image indicating the foreign object on the basis of the assumed foreign object or a trained model that has been trained by machine learning using images indicating various assumed foreign objects may be used.</p><p id="p-0109" num="0108">In a case in which the process in Step S<b>114</b> ends in this way, the foreign object detection process illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> ends. In addition, in a case in which the detection unit <b>64</b> determines that a foreign object is absent, the determination result in Step S<b>112</b> is &#x201c;No&#x201d;, and the foreign object detection process illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref> ends.</p><p id="p-0110" num="0109">As described above, in the console <b>12</b> according to this embodiment, it is possible to detect whether or not a foreign object is present in the detection region <b>74</b> on the basis of the distance image captured by the TOF camera <b>39</b>. Therefore, according to the console <b>12</b> of this embodiment, even after positioning is ended by the user or even in a case in which it is difficult for the user to see the irradiation region <b>70</b> of the radiation R, it is possible to appropriately detect whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> of the radiation R.</p><p id="p-0111" num="0110">In addition, in the foreign object detection process, in a case in which a foreign object <b>80</b> is present between the detection region <b>74</b> and the TOF camera <b>39</b> as illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>A</figref>, the infrared rays emitted from the TOF camera <b>39</b> do not reach a shadow region of the foreign object <b>80</b>. Therefore, even in a case in which a foreign object is present in a region which is a shadow of the foreign object <b>80</b> in the detection region <b>74</b>, it may be difficult to detect the foreign object. In this case, as in the case in which it is detected whether or not a foreign object is present in the detection region <b>74</b>, it may be detected whether or not a foreign object is present in the region between the detection region <b>74</b> and the TOF camera <b>39</b>. In a case in which it is detected that a foreign object is present, information or a warning indicating the fact may be output.</p><p id="p-0112" num="0111">Further, in the above-described embodiment, the aspect in which the irradiation region <b>70</b> of the radiation source <b>37</b>R is different from the imageable region <b>72</b> of the TOF camera <b>39</b> has been described. However, as illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, the imageable region <b>72</b> of the TOF camera <b>39</b> may be substantially the same as the irradiation region <b>70</b> of the radiation source <b>37</b>R. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>9</b>B</figref>, a mirror <b>82</b> provided in the mammography apparatus <b>10</b> reflects the infrared rays emitted from the TOF camera <b>39</b> and the infrared rays, which have been reflected by the object to be imaged or a foreign object and returned to the TOF camera <b>39</b>, such that the imageable region <b>72</b> is substantially the same as the irradiation region <b>70</b>. In addition, the mirror <b>82</b> may be retracted outside the irradiation region <b>70</b> in a case in which a radiographic image is captured. Further, in a case in which a material that transmits the radiation R, for example, a filter used to capture a radiographic image is used as the mirror <b>82</b>, the radiographic image may be captured while the material or the filter is disposed in the irradiation region <b>70</b> without being retracted.</p><heading id="h-0009" level="1">Second Embodiment</heading><p id="p-0113" num="0112">In the first embodiment, the aspect has been described in which it is detected whether or not a foreign object is present in the detection region <b>74</b> using the distance image captured by the TOF camera <b>39</b>. In contrast, in this embodiment, an aspect will be described in which it is detected whether or not a foreign object is present in the detection region <b>74</b> using a visible light image captured by a visible light camera. In addition, for a mammography apparatus <b>10</b> and a console <b>12</b> according to this embodiment, the detailed description of the same configurations and operations as those in the first embodiment will not be repeated.</p><p id="p-0114" num="0113"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a side view illustrating an example of the outward appearance of the mammography apparatus <b>10</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the mammography apparatus <b>10</b> according to this embodiment comprises a visible light camera <b>31</b> instead of the TOF camera <b>39</b> comprised in the mammography apparatus <b>10</b> according to the first embodiment.</p><p id="p-0115" num="0114">The visible light camera <b>31</b> is a so-called general camera and captures a visible light image. The visible light camera <b>31</b> according to this embodiment is an example of the imaging device and a visible light image capture device according to the present disclosure. Specifically, the visible light camera <b>31</b> receives visible light reflected by the object to be imaged and captures a visible light image on the basis of the received visible light. As illustrated in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the visible light camera <b>31</b> according to this embodiment is provided in the vicinity of the collimator <b>33</b> of the radiation emitting unit <b>37</b>, and an imageable region of the visible light camera <b>31</b> includes the detection region <b>74</b>.</p><p id="p-0116" num="0115">Since the overall configuration (see <figref idref="DRAWINGS">FIG. <b>5</b></figref>) of the console <b>12</b> according to this embodiment is the same as that in the first embodiment, the description of the overall configuration will not be repeated. On the other hand, since the functional configuration of the console <b>12</b> is different from that in the first embodiment, the functional configuration will be described. The console <b>12</b> according to this embodiment comprises a first acquisition unit <b>60</b>, a second acquisition unit <b>62</b>, and a detection unit <b>64</b>, similarly to the console <b>12</b> (see <figref idref="DRAWINGS">FIG. <b>6</b></figref>) according to the first embodiment.</p><p id="p-0117" num="0116">The function of the first acquisition unit <b>60</b> is the same as that in the first embodiment. On the other hand, the function of the second acquisition unit <b>62</b> is different from that in the first embodiment. The second acquisition unit <b>62</b> according to this embodiment has a function of acquiring the visible light image captured by the visible light camera <b>31</b>. For example, the second acquisition unit <b>62</b> according to this embodiment acquires image data indicating the visible light image captured by the visible light camera <b>31</b> from the visible light camera <b>31</b> through the I/F unit <b>24</b> and the I/F unit <b>54</b>. The visible light image acquired by the second acquisition unit <b>62</b> is output to the detection unit <b>64</b>.</p><p id="p-0118" num="0117">Further, the detection unit <b>64</b> according to this embodiment has a function of detecting whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> on the basis of the visible light image. For example, the detection unit <b>64</b> according to this embodiment derives a space between the object to be imaged and the radiation source <b>37</b>R as the detection region <b>74</b> in the irradiation region <b>70</b> and detects whether or not a foreign object is present in the derived detection region <b>74</b>, similarly to the detection unit <b>64</b> according to the first embodiment.</p><p id="p-0119" num="0118">In this embodiment, a visible light image captured by the visible light camera <b>31</b> in a case in which a foreign object is absent in the detection region <b>74</b> is obtained as a reference visible light image in advance. In addition, a device for storing the reference visible light image is not limited. For example, the reference visible light image may be stored in the storage unit <b>22</b> of the mammography apparatus <b>10</b> or the storage unit <b>52</b> of the console <b>12</b>. The detection unit <b>64</b> compares an image corresponding to the detection region <b>74</b> in the visible light image acquired from the visible light camera <b>31</b> with an image corresponding to the detection region <b>74</b> in the reference visible light image. Specifically, a difference between the pixel values of each image is derived to perform the comparison. In a case in which a foreign object is present in the detection region <b>74</b>, the image corresponding to the detection region <b>74</b> in the visible light image acquired from the visible light camera <b>31</b> includes the image of the foreign object. Therefore, there is a large difference between the pixel value of the pixel corresponding to the image of the foreign object and the pixel value of the pixel at the same position in the reference visible light image. Therefore, the detection unit <b>64</b> determines that a foreign object is present in the detection region <b>74</b> in a case in which there is a region in which a predetermined number or more of pixels, in which the absolute value of the difference between the pixel value of the image corresponding to the detection region <b>74</b> in the visible light image acquired from the visible light camera <b>31</b> and the pixel value of the image corresponding to the detection region <b>74</b> in the reference visible light image is larger than a foreign object detection threshold value, are continuous.</p><p id="p-0120" num="0119">In addition, since the operation of the console <b>12</b> according to this embodiment, specifically, the foreign object detection process is different from that in the first embodiment, the foreign object detection process performed by the console <b>12</b> according to this embodiment will be described.</p><p id="p-0121" num="0120"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart illustrating an example of the flow of the foreign object detection process performed in the console <b>12</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the foreign object detection process according to this embodiment includes processes in Steps S<b>107</b> to S<b>111</b> instead of Steps S<b>106</b> to S<b>110</b> in the foreign object detection process (see <figref idref="DRAWINGS">FIG. <b>8</b></figref>) according to the first embodiment.</p><p id="p-0122" num="0121">In Step S<b>107</b>, the detection unit <b>64</b> acquires the reference visible light image as described above. Then, in Step S<b>109</b>, the second acquisition unit <b>62</b> acquires a visible light image from the visible light camera <b>31</b> as described above. Then, in Step S<b>111</b>, the detection unit <b>64</b> compares the visible light image with the reference visible light image as described above. Then, in Step S<b>112</b>, the detection unit <b>64</b> determines whether or not a foreign object is present in the detection region <b>74</b> on the basis of the comparison result in Step S<b>111</b>.</p><p id="p-0123" num="0122">As described above, in the console <b>12</b> according to this embodiment, it is possible to detect whether or not a foreign object is present in the detection region <b>74</b> on the basis of the visible light image captured by the visible light camera <b>31</b>. Therefore, according to the console <b>12</b> of this embodiment, even after positioning is ended by the user or even in a case in which it is difficult for the user to see the irradiation region <b>70</b> of the radiation R, it is possible to appropriately detect whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> of the radiation R.</p><p id="p-0124" num="0123">In addition, the first embodiment and this embodiment may be combined. In other words, it may be detected whether or not a foreign object is present in the irradiation region <b>70</b> using the distance image captured by the TOF camera <b>39</b> and the visible light image captured by the visible light camera <b>31</b>. In this case, for example, in a case in which at least one of the detection result using the distance image captured by the TOF camera <b>39</b> or the detection result using the visible light image captured by the visible light camera <b>31</b> shows that a foreign object is present, the detection unit <b>64</b> may give an instruction to respond to the foreign object and the like (see Step S<b>114</b> of the foreign object detection process in <figref idref="DRAWINGS">FIG. <b>8</b></figref>). Further, for example, the irradiation region <b>70</b> may be imaged in different directions by the TOF camera <b>39</b> and the visible light camera <b>31</b>, and a foreign object may be detected in different directions.</p><heading id="h-0010" level="1">Third Embodiment</heading><p id="p-0125" num="0124">In this embodiment, another aspect will be described in which it is detected whether or not a foreign object is present in the irradiation region <b>70</b> of the radiation R using the visible light image captured by the visible light camera <b>31</b>. In addition, for a mammography apparatus <b>10</b> and a console <b>12</b> according to this embodiment, the detailed description of the same configurations and operations as those in the first and second embodiments will not be repeated.</p><p id="p-0126" num="0125"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a side view illustrating an example of the outward appearance of the mammography apparatus <b>10</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the mammography apparatus <b>10</b> according to this embodiment is different from the mammography apparatus <b>10</b> (see <figref idref="DRAWINGS">FIG. <b>10</b></figref>) according to the second embodiment in the position where the visible light camera <b>31</b> is provided. As illustrated in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the visible light camera <b>31</b> according to this embodiment is provided on the side of the radiation emitting unit <b>37</b> which faces the subject W. As illustrated in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the imageable region <b>72</b> of the visible light camera <b>31</b> according to this embodiment includes the irradiation region <b>70</b> and also includes a region in which the compression plate <b>40</b> is provided. Further, for the imageable region <b>72</b> of the visible light camera <b>31</b> according to this embodiment, a region which is close to the chest wall in the breast WB of the subject W is defined as the imageable region.</p><p id="p-0127" num="0126"><figref idref="DRAWINGS">FIG. <b>14</b></figref> illustrates an example of a visible light image <b>90</b> captured by the visible light camera <b>31</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the visible light image <b>90</b> captured by the visible light camera <b>31</b> includes an image corresponding to the compression plate <b>40</b>. Specifically, since the bottom portion <b>43</b> of the compression plate <b>40</b> according to this embodiment is made of a transparent material, a breast image <b>92</b> of the breast WB is included in a bottom portion region <b>91</b> of the visible light image <b>90</b> which corresponds to the bottom portion <b>43</b> of the compression plate <b>40</b>. Further, as illustrated in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the visible light image <b>90</b> includes an edge image <b>94</b> corresponding to an edge portion of the compression plate <b>40</b>. In addition, in this embodiment, the edge image <b>94</b> is an image including the wall portion <b>44</b> of the bottom portion <b>43</b>. As described above, in this embodiment, the image of the wall portion <b>44</b> of the compression plate <b>40</b> is applied as the edge image <b>94</b>. Therefore, it is preferable that the wall portion <b>44</b> of the compression plate <b>40</b> is more likely to be included in the visible light image <b>90</b> than the bottom portion <b>43</b>. For example, it is preferable that the bottom portion <b>43</b> and the wall portion <b>44</b> are processed to be distinguishable from each other in the visible light image <b>90</b>. In other words, it is preferable that the edge portion of the compression plate <b>40</b> is more highlighted than the surroundings. The wall portion <b>44</b> may be made of a material that is likely to be included in the visible light image <b>90</b>. Specifically, at least one of a material having a color different from that of the imaging table <b>30</b> or the breast WB, a phosphorescent material, or a fluorescent material may be used as the material forming the wall portion <b>44</b>. Further, for example, the side of the wall portion <b>44</b> of the compression plate <b>40</b> which faces the radiation source <b>37</b>R may be configured to be likely to be included in the visible light image <b>90</b>. Specifically, at least one of a material having a color different from that of the imaging table <b>30</b> or the breast WB, a phosphorescent material, or a fluorescent material may be applied or attached to a surface of the wall portion <b>44</b> which faces the radiation source <b>37</b>R. In addition, various methods, such as painting, member attachment, the coloring of the material forming the compression member, and surface treatment, can be adopted. Even in a case in which the bottom portion <b>43</b> and the wall portion <b>44</b> are made of materials having the same color, the apparent colors thereof may change depending on the thickness thereof.</p><p id="p-0128" num="0127">Since the overall configuration (see <figref idref="DRAWINGS">FIG. <b>5</b></figref>) of the console <b>12</b> according to this embodiment is the same as that in the first and second embodiments, the description of the overall configuration will not be repeated. On the other hand, since the functional configuration of the console <b>12</b> is different from that in the first and second embodiments, the functional configuration will be described. <figref idref="DRAWINGS">FIG. <b>15</b></figref> is a functional block diagram illustrating an example of the functional configuration of the console <b>12</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the console <b>12</b> according to this embodiment is different from the console <b>12</b> (see <figref idref="DRAWINGS">FIG. <b>6</b></figref>) according to each of the above-described embodiments in that it comprises a third acquisition unit <b>66</b> instead of the first acquisition unit <b>60</b>.</p><p id="p-0129" num="0128">The third acquisition unit <b>66</b> has a function of acquiring compression member information indicating the type of the compression plate <b>40</b> attached to the compression unit <b>36</b>. As described above, there are a plurality of types of compression plates <b>40</b> including a compression plate <b>40</b> used for spot imaging that can be attached to the mammography apparatus <b>10</b>. The size of the bottom portion <b>43</b> of the compression plate <b>40</b> according to this embodiment is determined according to the type of the compression plate <b>40</b>. Therefore, the position and size of the edge image <b>94</b> included in the visible light image <b>90</b> are determined according to the type of the compression plate <b>40</b> attached to the compression unit <b>36</b>.</p><p id="p-0130" num="0129">For example, a compression plate identifier (not illustrated) for identifying the type of the compression plate <b>40</b> is provided on the side of the support portion <b>46</b> of the compression plate <b>40</b> which is attached to the compression unit <b>36</b> according to this embodiment. Further, the compression unit <b>36</b> is provided with an identifier sensor (not illustrated). The identifier sensor reads the compression plate identifier provided in the support portion <b>46</b> of the compression plate <b>40</b>. The third acquisition unit <b>66</b> acquires the compression plate identifier read by the identifier sensor as the compression member information through the I/F unit <b>24</b> and the I/F unit <b>54</b>. The compression member information acquired by the third acquisition unit <b>66</b> is output to the detection unit <b>64</b>.</p><p id="p-0131" num="0130">In addition, the method by which the third acquisition unit <b>66</b> according to this embodiment acquires the compression member information is not limited to the above-described aspect. For example, in a case in which the type of the compression plate <b>40</b> used for imaging is determined for each type of imaging, the third acquisition unit <b>66</b> may acquire the type of imaging as the compression member information from an imaging menu or the like.</p><p id="p-0132" num="0131">Further, the detection unit <b>64</b> according to this embodiment has a function of detecting whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> on the basis of the visible light image, similarly to the detection unit <b>64</b> according to the second embodiment. However, the content of a process required for the detection is different.</p><p id="p-0133" num="0132">In a case in which a foreign object enters the irradiation region <b>70</b> as described above, the foreign object may be present from the outside of the irradiation region <b>70</b> to the inside of the irradiation region <b>70</b> like the head WH of the subject W described with reference to <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>. In a case in which the foreign object is present from the outside of the irradiation region <b>70</b> to the inside of the irradiation region <b>70</b>, the foreign object is present beyond the edge portion of the compression plate <b>40</b>. In this case, as illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, a foreign object image <b>96</b> corresponding to the foreign object included in the visible light image <b>90</b> is present on the edge image <b>94</b>. In other words, the edge image <b>94</b> included in the visible light image <b>90</b> in a case in which a foreign object is present is chipped by the foreign object image <b>96</b>. Therefore, the detection unit <b>64</b> according to this embodiment extracts the edge image <b>94</b> from the visible light image <b>90</b> and determines that a foreign object is present in the irradiation region <b>70</b> in a case in which the extracted edge image <b>94</b> is chipped. On the other hand, the detection unit <b>64</b> extracts the edge image <b>94</b> from the visible light image <b>90</b>, and determines that a foreign object is absent in the irradiation region <b>70</b> in a case in which the extracted edge image <b>94</b> is not chipped.</p><p id="p-0134" num="0133">In addition, since the operation of the console <b>12</b> according to this embodiment, specifically, the foreign object detection process is different from that in the first and second embodiments, the foreign object detection process performed by the console <b>12</b> according to this embodiment will be described.</p><p id="p-0135" num="0134"><figref idref="DRAWINGS">FIG. <b>17</b></figref> is a flowchart illustrating an example of the flow of the foreign object detection process performed in the console <b>12</b> according to this embodiment.</p><p id="p-0136" num="0135">In Step S<b>200</b>, the second acquisition unit <b>62</b> acquires the visible light image <b>90</b> from the visible light camera <b>31</b> as described above. Then, in Step S<b>202</b>, the third acquisition unit <b>66</b> acquires the compression member information as described above.</p><p id="p-0137" num="0136">Then, in Step S<b>204</b>, the detection unit <b>64</b> extracts the edge image <b>94</b> from the visible light image <b>90</b> acquired in Step S<b>200</b> on the basis of the compression member information acquired in Step S<b>202</b> as described above. In addition, the specific method by which the detection unit <b>64</b> extracts the edge image <b>94</b> from the visible light image <b>90</b> is not particularly limited. For example, the detection unit <b>64</b> may apply the existing image processing for edge detection to extract the edge image <b>94</b>. Further, for example, the detection unit <b>64</b> stores typical pattern data of the edge image <b>94</b> as a template in advance and derives similarity to pattern data while searching for the visible light image <b>90</b> with a template. Then, the detection unit <b>64</b> may apply template matching, in which the edge image <b>94</b> is considered to be present at a position where the similarity is equal to or greater than a reference value and is the maximum, to extract the edge image <b>94</b>.</p><p id="p-0138" num="0137">Further, for example, in a case in which the wall portion <b>44</b> of the compression plate <b>40</b> has a color different from that of the surroundings as described above or in a case in which a phosphorescent material is used, the color of the edge image <b>94</b> included in the visible light image <b>90</b> is known in advance. Therefore, a region that has a known color and is formed by a predetermined number or more of pixels may be extracted as the edge image <b>94</b>. In addition, the detection unit <b>64</b> according to this embodiment estimates the shape and size of the edge image <b>94</b> according to the type of the compression plate <b>40</b> indicated by the compression member information and uses the estimated shape and size to extract the edge image <b>94</b>. The estimation of the shape and size of the edge image <b>94</b> according to the type of the compression plate <b>40</b> indicated by the compression member information makes it possible to extract the edge image <b>94</b> with higher accuracy and to reduce a processing load on an extraction process.</p><p id="p-0139" num="0138">Then, in Step S<b>206</b>, the detection unit <b>64</b> determines whether or not the edge image <b>94</b> extracted in Step S<b>204</b> is chipped. For example, the detection unit <b>64</b> according to this embodiment compares the edge image <b>94</b> with a reference edge image to determine whether or not the edge image <b>94</b> is chipped. In this embodiment, the visible light image <b>90</b> or the edge image <b>94</b> captured by the visible light camera <b>31</b> in a case in which a foreign object is absent in the irradiation region <b>70</b> is obtained as the reference edge image in advance. In addition, a device that stores the reference edge image is not limited. For example, the reference edge image may be stored in the storage unit <b>22</b> of the mammography apparatus <b>10</b> or the storage unit <b>52</b> of the console <b>12</b>. The detection unit <b>64</b> compares the edge image <b>94</b> extracted in Step S<b>204</b> with the reference edge image. Specifically, the comparison is performed by deriving a difference between the pixel values of the extracted edge image <b>94</b> and the reference edge image. More specifically, in a case in which there is a region in which a predetermined number or more of pixels, in which the absolute value of the difference between the pixel value of the extracted edge image <b>94</b> and the pixel value of the reference edge image is larger than a chipping detection threshold value, are continuous, it is determined that the edge image <b>94</b> is chipped. Further, the method by which the detection unit <b>64</b> determines whether or not the edge image <b>94</b> is chipped is not particularly limited. For example, the reference edge image may not be used, and the detection unit <b>64</b> may determine that the edge image <b>94</b> is chipped in a case in which a line that is the outer circumference of the compression plate <b>40</b> recognized by the edge image <b>94</b> is broken by a predetermined number of pixels or more.</p><p id="p-0140" num="0139">In a case in which the edge image <b>94</b> is not chipped, the determination result in Step S<b>206</b> is &#x201c;No&#x201d;, and the process proceeds to Step S<b>210</b>. This corresponds to a case in which a foreign object is absent in the irradiation region <b>70</b>. On the other hand, in a case in which the edge image <b>94</b> is chipped, the determination result in Step S<b>206</b> is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>208</b>. This corresponds to a case in which a foreign object is present in the irradiation region <b>70</b>.</p><p id="p-0141" num="0140">In Step S<b>208</b>, the detection unit <b>64</b> outputs the detection result indicating that a foreign object is present and an instruction to respond to the foreign object, as in S<b>114</b> of the foreign object detection process (see <figref idref="DRAWINGS">FIGS. <b>8</b> and <b>11</b></figref>) according to the first and second embodiments and then proceeds to Step S<b>210</b>.</p><p id="p-0142" num="0141">In Step S<b>210</b>, the detection unit <b>64</b> determines whether or not to end the foreign object detection process that is being performed. The detection unit <b>64</b> according to this embodiment determines to end the foreign object detection process in a case in which end conditions are satisfied. An example of the end conditions is a case in which the user inputs an instruction to emit the radiation R using the operation unit <b>56</b> or the like. Further, an example of the end conditions is a case in which the user inputs an instruction to end the foreign object detection process using the operation unit <b>56</b> or the like. In a case in which the end conditions are not satisfied, the determination result in Step S<b>210</b> is &#x201c;No&#x201d;, and the process returns to Step S<b>200</b>. Then, the processes in Steps S<b>200</b> to S<b>208</b> are repeated. For example, the user who has recognized that a foreign object is present in the irradiation region <b>70</b> corrects the posture of the subject W such that the foreign object does not enter the irradiation region <b>70</b>. Therefore, the above-described process is repeated to continue to determine whether or not a foreign object is present in the irradiation region <b>70</b>.</p><p id="p-0143" num="0142">On the other hand, in a case in which the end conditions are satisfied, the determination result in Step S<b>210</b> is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>212</b>. In Step S<b>212</b>, the detection unit <b>64</b> determines whether or not an instruction to respond to the foreign object is being given. Specifically, it is determined whether or not the process in Step S<b>208</b> has been performed. In a case in which the process in Step S<b>208</b> has not been performed, that is, in a case in which a foreign object is absent in the irradiation region <b>70</b>, the determination result in Step S<b>212</b> is &#x201c;No&#x201d;, and the foreign object detection process illustrated in <figref idref="DRAWINGS">FIG. <b>17</b></figref> is ended. On the other hand, in a case in which the process in Step S<b>208</b> has been performed, that is, in a case in which a foreign object is present in the irradiation region <b>70</b>, the determination result in Step S<b>212</b> is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>214</b>.</p><p id="p-0144" num="0143">In Step S<b>214</b>, the detection unit <b>64</b> cancels the instruction to respond to the foreign object given in Step S<b>208</b>. For example, in a case in which the detection unit <b>64</b> outputs information for warning the user that a foreign object is present in the detection region <b>74</b> as the instruction to respond to the foreign object, the output of the information for warning is stopped to cancel the warning. In a case in which the process in Step S<b>214</b> ends, the foreign object detection process illustrated in <figref idref="DRAWINGS">FIG. <b>17</b></figref> ends.</p><p id="p-0145" num="0144">As described above, the console <b>12</b> according to this embodiment detects whether or not a foreign object is present in the irradiation region <b>70</b> on the basis of the chipping of the image of the compression plate <b>40</b> included in the visible light image <b>90</b> captured by the visible light camera <b>31</b>, particularly, the chipping of the edge image <b>94</b>. Therefore, according to the console <b>12</b> of this embodiment, even after positioning is ended by the user or even in a case in which it is difficult for the user to see the irradiation region <b>70</b> of the radiation R, it is possible to appropriately detect whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> of the radiation R.</p><p id="p-0146" num="0145">In addition, this embodiment is not limited to the above-described aspect. For example, the following modification examples can be applied.</p><heading id="h-0011" level="1">Modification Example 1</heading><p id="p-0147" num="0146">In this modification example, instead of detecting whether or not the entire edge image <b>94</b> is chipped, the detection unit <b>64</b> detects whether or not a region of the edge image <b>94</b>, which is likely to be chipped in a case in which a foreign object enters the irradiation region <b>70</b>, is chipped.</p><p id="p-0148" num="0147">In a case in which a foreign object enters the irradiation region <b>70</b>, it often enters the irradiation region <b>70</b> from the chest wall side of the subject W like the head WH of the subject W illustrated in <figref idref="DRAWINGS">FIG. <b>7</b>B</figref>. Therefore, as illustrated in <figref idref="DRAWINGS">FIG. <b>16</b></figref>, in many cases, the foreign object image <b>96</b> corresponding to the foreign object is included in the visible light image <b>90</b> at a position corresponding to the chest wall side of the subject W. Therefore, the detection unit <b>64</b> according to this modification example detects whether or not a region of the edge image <b>94</b> which corresponds to a side on the chest wall side of the subject W is chipped.</p><p id="p-0149" num="0148">In addition, the region of the edge image <b>94</b>, which is likely to be chipped in a case in which a foreign object enters the irradiation region <b>70</b>, differs depending on the type of radiography. The mammography apparatus <b>10</b> can perform at least two types of imaging as the type of radiography. Specifically, the mammography apparatus <b>10</b> can perform at least two types of imaging, that is, cranio-caudal (CC) imaging in which an imaging direction is a cranio-caudal direction and medio-lateral oblique (MLO) imaging in which the imaging direction is a medio-lateral oblique direction on the breast WB.</p><p id="p-0150" num="0149"><figref idref="DRAWINGS">FIG. <b>18</b></figref> illustrates an example of the state of the imaging table <b>30</b>, the arm portion <b>32</b>, and the radiation source <b>37</b>R in the CC imaging and the MLO imaging. As illustrated in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, in a case in which the CC imaging is performed, the imaging surface <b>30</b>A is adjusted to face the upper side (the head WH of the subject W) of the mammography apparatus <b>10</b> in a state in which it faces the radiation source <b>37</b>R. Therefore, the radiation R is emitted from the radiation source <b>37</b>R to the breast WB in a direction from the head WH to the foot of the subject W, and the CC imaging is performed.</p><p id="p-0151" num="0150">In a case in which the CC imaging is performed, as described above, the foreign object image <b>96</b> corresponding to the foreign object is often included in the visible light image <b>90</b> at a position corresponding to the chest wall side of the subject W. Therefore, the detection unit <b>64</b> according to this modification example detects whether or not the region of the edge image <b>94</b>, which corresponds to the side on the chest wall side of the subject W, is chipped in a case in which the CC imaging is performed.</p><p id="p-0152" num="0151">On the other hand, as illustrated in <figref idref="DRAWINGS">FIG. <b>18</b></figref>, in a case in which the MLO imaging is performed, the arm portion <b>32</b> is rotated up to a predetermined angle within the range of, for example, 45 degrees or more and less than 90 degrees in a negative direction or a positive direction with respect to the case in which the CC imaging is performed to be inclined with respect to the cranio-caudal direction of the subject W. Specifically, in a case in which the left breast is imaged, the arm portion <b>32</b> is inclined in the positive direction, with the imaging surface <b>30</b>A and the radiation source <b>37</b>R facing each other, such that the imaging surface <b>30</b>A is inclined to the right.</p><p id="p-0153" num="0152">In a case in which the left breast is imaged in the MLO imaging, the compression plate <b>40</b> is maintained in a state in which the left side is the upper side and the right side is the lower side as illustrated in <figref idref="DRAWINGS">FIG. <b>18</b></figref>. In addition, the left and right sides in this modification example correspond to the left and right sides of the subject W that faces the imaging table <b>30</b>. In general, a foreign object tends to enter the irradiation region from the upper side of the inclined imaging table <b>30</b>. Therefore, a foreign object tends to enter the irradiation region from a side which is the upper side of the compression plate <b>40</b>. In a case in which the MLO imaging is performed on the left breast WB, the foreign object image <b>96</b> included in the visible light image <b>90</b> is often included at a position corresponding to the left side of the subject W in addition to the position corresponding to the chest wall side of the subject W. Therefore, the detection unit <b>64</b> according to this modification example detects whether or not the regions of the edge image <b>94</b> corresponding to each of the chest wall side and the left side of the subject W are chipped in a case in which the MLO imaging is performed on the left breast WB.</p><p id="p-0154" num="0153">Further, in a case in which the right breast is imaged, the arm portion <b>32</b> is inclined in the negative direction, with the imaging surface <b>30</b>A and the radiation source <b>37</b>R facing each other, such that the imaging surface <b>30</b>A is inclined to the left. Therefore, the radiation R is emitted from the radiation source <b>37</b>R to the breast WB in a direction from the center of the body of the subject W to the outside (in a direction from a space between the breasts WB of the subject W to the arm), and the MLO imaging is performed.</p><p id="p-0155" num="0154">In a case in which the right breast is imaged in the MLO imaging, the compression plate <b>40</b> is maintained in a state in which the right side is the upper side and the left side is the lower side as illustrated in <figref idref="DRAWINGS">FIG. <b>18</b></figref>. Therefore, contrary to the case of the left breast WB described above, in a case in which the MLO imaging is performed on the right breast WB, the foreign object image <b>96</b> included in the visible light image <b>90</b> is often included at a position corresponding to the right side of the subject W in addition to the position corresponding to the chest wall side of the subject W. Therefore, the detection unit <b>64</b> according to this modification example detects whether or not the regions of the edge image <b>94</b> corresponding to each of the chest wall side and the right side of the subject W are chipped in a case in which the MLO imaging is performed on the right breast WB.</p><p id="p-0156" num="0155"><figref idref="DRAWINGS">FIG. <b>19</b></figref> is a flowchart illustrating an example of the flow of the foreign object detection process performed in the console <b>12</b> according to this modification example. The foreign object detection process according to this modification example illustrated in <figref idref="DRAWINGS">FIG. <b>19</b></figref> is different from the foreign object detection process (see <figref idref="DRAWINGS">FIG. <b>17</b></figref>) according to the above-described embodiment in that it comprises processes in Steps S<b>203</b>A and S<b>203</b>B after Step S<b>202</b> and comprises processes in Steps S<b>204</b>A to S<b>204</b>C instead of Step S<b>204</b>.</p><p id="p-0157" num="0156">As illustrated in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, in Step S<b>203</b>A, the detection unit <b>64</b> determines whether or not the type of imaging is the CC imaging. In addition, the method by which the detection unit <b>64</b> determines whether or not the type of imaging is the CC imaging is not particularly limited. For example, the type of imaging may be specified with reference to an imaging menu. Further, for example, since the angle of the arm portion <b>32</b> is different between the CC imaging and the MLO imaging, it may be determined whether or not the type of imaging is the CC imaging on the basis of the angle of the arm portion <b>32</b>.</p><p id="p-0158" num="0157">In a case in which the type of imaging is the CC imaging, the determination result in Step S<b>203</b>A is &#x201c;Yes&#x201d; and the process proceeds to Step S<b>204</b>A. As described above, in Step S<b>204</b>A, the detection unit <b>64</b> detects whether or not the region of the edge image <b>94</b> corresponding to a side on the chest wall side of the subject W is chipped and then proceeds to Step S<b>206</b>.</p><p id="p-0159" num="0158">On the other hand, in a case in which the type of imaging is not the CC imaging, that is, in a case in which the type of imaging is the MLO imaging, the determination result in Step S<b>203</b>A is &#x201c;No&#x201d; and the process proceeds to Step S<b>203</b>B. In Step S<b>203</b>B, the detection unit <b>64</b> determines whether or not the left breast WB is imaged. In a case in which the left breast WB is imaged, the determination result in Step S<b>203</b>B is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>204</b>B.</p><p id="p-0160" num="0159">As described above, in Step S<b>204</b>B, the detection unit <b>64</b> detects whether or not the regions of the edge image <b>94</b> corresponding to sides on the chest wall side and the left side of the subject W are chipped and then proceeds to Step S<b>206</b>.</p><p id="p-0161" num="0160">On the other hand, in a case in which the left breast WB is not imaged in Step S<b>203</b>B, that is, in a case in which the right breast WB is imaged, the determination result is &#x201c;No&#x201d;, and the process proceeds to Step S<b>204</b>C. As described above, in Step S<b>204</b>C, the detection unit <b>64</b> detects whether or not the regions of the edge image <b>94</b> corresponding to the sides on the chest wall side and the right side of the subject W are chipped and then proceeds to Step S<b>206</b>.</p><p id="p-0162" num="0161">As described above, according to this modification example, the entire edge image <b>94</b> is not used to detect whether or not a foreign object is present in the irradiation region <b>70</b>. Therefore, it is possible to more quickly perform the foreign object detection process and to reduce the processing load.</p><p id="p-0163" num="0162">In addition, in a case in which a phosphorescent material is used for the edge portion of the compression plate <b>40</b>, it is preferable that the edge portion is irradiated with light for a predetermined period of time at a predetermined time interval to store the light, for example, in a state in which the subject W is not compressed by the compression plate <b>40</b>, a state in which the radiation R is not emitted, and a state in which a compression thickness is not applied to the compression plate <b>40</b>. Further, in a case in which light is emitted such that the phosphorescent material of the edge portion stores light, it is preferable that the compression plate <b>40</b> is located at a position away from the radiation source <b>37</b>R. In other words, it is preferable to reduce the height of the compression plate <b>40</b>.</p><p id="p-0164" num="0163">Further, in this embodiment, the aspect has been described in which the chipping of the edge image <b>94</b> included in the visible light image <b>90</b> captured by the visible light camera <b>31</b> is detected to detect whether or not a foreign object is present in the irradiation region <b>70</b>. However, as described above, the edge portion of the compression plate <b>40</b> corresponds to the wall portion <b>44</b> and has a different height from the bottom portion <b>43</b>. Therefore, it is also possible to detect the image of the edge portion from the distance image captured by the TOF camera <b>39</b> in the first embodiment. Therefore, instead of the visible light image <b>90</b>, the distance image captured by the TOF camera <b>39</b> may be applied to this embodiment.</p><heading id="h-0012" level="1">Fourth Embodiment</heading><p id="p-0165" num="0164">In this embodiment, another aspect in which it is detected whether or not a foreign object is present in the irradiation region <b>70</b> of the radiation R using the visible light image <b>90</b> captured by the visible light camera <b>31</b> will be described. In addition, for a mammography apparatus <b>10</b> and a console <b>12</b> according to this embodiment, the detailed description of the same configurations and operations as those in the first to third embodiments will not be repeated.</p><p id="p-0166" num="0165"><figref idref="DRAWINGS">FIG. <b>20</b></figref> is a side view illustrating an example of the outward appearance of the mammography apparatus <b>10</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>20</b></figref>, in the mammography apparatus <b>10</b> according to this embodiment, the visible light camera <b>31</b> is provided at the same position as that in the mammography apparatus <b>10</b> (see <figref idref="DRAWINGS">FIG. <b>12</b></figref>) according to the third embodiment. Further, in the mammography apparatus <b>10</b> according to this embodiment, a projector <b>29</b> is provided at a position of the arm portion <b>32</b> that is away from the subject W below the radiation emitting unit <b>37</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>21</b></figref>, the projector <b>29</b> according to this embodiment has a function of projecting a projection image <b>98</b> onto an irradiation surface of the compression plate <b>40</b> which is irradiated with the radiation R. Specifically, the projector <b>29</b> according to this embodiment has a function of projecting the projection image <b>98</b> onto a surface (hereinafter, referred to as a projection surface <b>43</b>A) of the bottom portion <b>43</b> of the compression plate <b>40</b> which is irradiated with the radiation R. The projector <b>29</b> according to this embodiment is an example of an image projection device according to the present disclosure.</p><p id="p-0167" num="0166">In addition, it is preferable that the projection surface <b>43</b>A of the compression plate <b>40</b> is in a state in which the projection image <b>98</b> is easily displayed thereon. For example, in a case in which light is incident on the projection surface <b>43</b>A, most of the light (for example, 90%) may be transmitted, and a portion (for example, 10%) thereof may be specularly reflected by a surface of an object such that an incident angle is equal to a reflection angle. Further, for example, a surface of the bottom portion <b>43</b> of the compression plate <b>40</b> which faces the radiation source <b>37</b>R may be roughened to form the projection surface <b>43</b>A. In addition, for example, a specular reflection sheet may be attached to the surface of the compression plate <b>40</b> to form the projection surface <b>43</b>A. Furthermore, in a case in which the projection surface <b>43</b>A is a smooth surface such as in a case in which a specular reflection sheet is attached, a surface of the compression plate <b>40</b> that comes into contact with the subject W, such as the breast WB, may be the projection surface <b>43</b>A.</p><p id="p-0168" num="0167"><figref idref="DRAWINGS">FIG. <b>22</b></figref> illustrates an example of a visible light image <b>90</b> captured by the visible light camera <b>31</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>22</b></figref>, the visible light image <b>90</b> captured by the visible light camera <b>31</b> includes the projection image <b>98</b>. In addition, strictly speaking, the visible light image <b>90</b> includes an image including the projection image <b>98</b> displayed on the projection surface <b>43</b>A. However, for convenience of explanation, the image including the projection image <b>98</b> is also referred to as the projection image <b>98</b>. The projection image <b>98</b> included in the visible light image <b>90</b> according to this embodiment is an example of an image of a region corresponding to the inside of an irradiation field of radiation according to the present disclosure.</p><p id="p-0169" num="0168">Since the console <b>12</b> according to this embodiment has the same overall configuration (see <figref idref="DRAWINGS">FIG. <b>5</b></figref>) as that in each of the above-described embodiments, the description of the overall configuration will not be repeated. Meanwhile, since the functional configuration of the console <b>12</b> is different from that in each of the above-described embodiments, the functional configuration will be described. <figref idref="DRAWINGS">FIG. <b>23</b></figref> is a functional block diagram illustrating an example of the functional configuration of the console <b>12</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>23</b></figref>, the console <b>12</b> according to this embodiment is different from the console <b>12</b> (see <figref idref="DRAWINGS">FIG. <b>6</b></figref> and the like) according to each of the above-described embodiments in that it further comprises a projection control unit <b>68</b>.</p><p id="p-0170" num="0169">The projection control unit <b>68</b> has a function of controlling the projector <b>29</b> such that the projection image <b>98</b> is projected onto a region including the irradiation field <b>71</b> of the radiation R. In addition, for example, in this embodiment, the projection image <b>98</b> projected onto the projection surface <b>43</b>A of the compression plate <b>40</b> by the projector <b>29</b> has the same position and size as the range of the irradiation field <b>71</b> of the radiation R on the projection surface <b>43</b>A of the compression plate <b>40</b>. Specifically, as illustrated in <figref idref="DRAWINGS">FIG. <b>21</b></figref>, the position and size of the projection image <b>98</b> are the same as the cross section of the irradiation region <b>70</b> on the projection surface <b>43</b>A in a case in which the irradiation region <b>70</b> is blocked by the bottom portion <b>43</b>.</p><p id="p-0171" num="0170">Therefore, the projection control unit <b>68</b> performs control to make the projection image <b>98</b> on the projection surface <b>43</b>A have the same position and size as the range of the irradiation field <b>71</b> of the radiation R on the projection surface <b>43</b>A (hereinafter, simply referred to as &#x201c;the range of the irradiation field <b>71</b>&#x201d;). As described above, the size and shape of the irradiation field <b>71</b> are determined according to, for example, the size of the detection surface (not illustrated) of the radiation detector <b>28</b> or the size of the breast WB to be imaged. Therefore, as illustrated in <figref idref="DRAWINGS">FIG. <b>24</b></figref>, the size and position of the range of the irradiation field <b>71</b> are determined according to the position of the radiation source <b>37</b>R, a distance h_s between the radiation source <b>37</b>R and the detection surface of the radiation detector <b>28</b> which is a so-called source image distance (SID), a height h_c of the compression plate <b>40</b> corresponding to the thickness of the breast WB, and a distance h_d between the imaging surface <b>30</b>A of the imaging table <b>30</b> and the detection surface of the radiation detector <b>28</b>.</p><p id="p-0172" num="0171">Specifically, assuming that the position of the radiation source <b>37</b>R is (x<sub>0</sub>, y<sub>0</sub>, z<sub>0</sub>) and the coordinates of four corners of a region irradiated with the radiation R on the detection surface of the radiation detector <b>28</b> are (xd<sub>n</sub>, yd<sub>n</sub>, zd<sub>n</sub>) (n=1 to 4), the coordinates (xc<sub>n</sub>, yc<sub>n</sub>, zc<sub>n</sub>) of the projection image <b>98</b> on the projection surface <b>43</b>A can be derived by the following Expression (1).</p><p id="p-0173" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?>(<i>xc</i><sub>n</sub><i>,yc</i><sub>n</sub><i>,zc</i><sub>n</sub>)=(<i>xd</i><sub>n</sub>+(<i>xd</i><sub>n</sub><i>&#x2212;x</i><sub>0</sub>))(<i>h</i>_<i>c+h</i>_<i>d</i>)/<i>h</i>_<i>s, </i>(<i>yd</i><sub>n</sub>+(<i>yd</i><sub>n</sub><i>&#x2212;y</i><sub>0</sub>))(<i>h</i>_<i>c+h</i>_<i>d</i>)/<i>h</i>_<i>s, </i>(<i>zd</i><sub>n</sub>+(<i>zd</i><sub>n</sub><i>&#x2212;z</i><sub>0</sub>))(<i>h</i>_<i>c+h</i>_<i>d</i>)/<i>h</i>_<i>s</i>) &#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0174" num="0172">In addition, in the above-described Expression (1), the thickness of the bottom portion <b>43</b> of the compression plate <b>40</b> is ignored. However, more accurately, a value obtained by adding the thickness of the bottom portion <b>43</b> to the height h_c of the compression plate <b>40</b> is used. Further, in a case in which a specular reflection sheet or the like for displaying the projection image <b>98</b> as described above is provided on the projection surface <b>43</b>A of the bottom portion <b>43</b>, a value obtained by further adding the thickness of the specular reflection sheet or the like to the compression plate <b>40</b> is used.</p><p id="p-0175" num="0173">Therefore, the projection control unit <b>68</b> according to this embodiment derives the position and size of the projection image <b>98</b> on the projection surface <b>43</b>A using the above-described Expression (1). In addition, for example, the SID or the coordinates of the radiation source <b>37</b>R required for using the above-described Expression (1) is included in the information indicating the irradiation region <b>70</b> acquired by the first acquisition unit.</p><p id="p-0176" num="0174">The projection control unit <b>68</b> controls the projector <b>29</b> such that the projection image <b>98</b> is projected at the derived position and with the derived size on the projection surface <b>43</b>A. Specifically, the projection control unit <b>68</b> outputs projection image projection information indicating the position and size of the projection image <b>98</b> to the projector <b>29</b> through the I/F unit <b>54</b>. The projector <b>29</b> projects the projection image <b>98</b> on the basis of the projection image projection information input from the console <b>12</b>. In addition, the method by which the projector <b>29</b> projects the projection image <b>98</b> on the basis of the projection image projection information is not particularly limited. For example, a projection image <b>98</b> corresponding to the size and position of the detection surface of the radiation detector <b>28</b> or the imaging surface <b>30</b>A of the imaging table <b>30</b> may be prepared in advance. Then, the prepared projection image <b>98</b> may be trimmed on the basis of the projection image projection information to generate projection image data for projecting a desired projection image <b>98</b>. Further, for example, projection image data of a plurality of projection images <b>98</b> corresponding to each of a plurality of assumed positions and sizes may be prepared in advance, and projection image data of a projection image <b>98</b> corresponding to the projection image projection information may be selected from the prepared projection image data.</p><p id="p-0177" num="0175">The type of the projection image <b>98</b> is not particularly limited. It is preferable that the projection image <b>98</b> has a single color, particularly, a single color different from that of the imaging surface <b>30</b>A of the imaging table <b>30</b>.</p><p id="p-0178" num="0176">Further, in this embodiment, as described above, the projection image <b>98</b> has the same position and size as the range of the irradiation field <b>71</b>. However, the position and size of the projection image <b>98</b> are not particularly limited as long as the projection image <b>98</b> includes the range of the irradiation field <b>71</b>. In addition, in a case in which the size of the projection image <b>98</b> is larger than the range of the irradiation field <b>71</b>, it is preferable that the projection image <b>98</b> includes an image indicating the range of the irradiation field <b>71</b>.</p><p id="p-0179" num="0177">Further, the detection unit <b>64</b> according to this embodiment has a function of detecting whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> on the basis of the visible light image <b>90</b> acquired by the second acquisition unit. However, the content of the process required for the detection is different. <figref idref="DRAWINGS">FIG. <b>25</b></figref> illustrates an example of a visible light image <b>90</b> captured by the visible light camera <b>31</b> in a state in which the projection image <b>98</b> is projected onto the projection surface <b>43</b>A and a foreign object enters the irradiation region <b>70</b>. As illustrated in <figref idref="DRAWINGS">FIG. <b>25</b></figref>, a foreign object image <b>96</b> appears on the projection image <b>98</b> included in the visible light image <b>90</b>. Therefore, the detection unit <b>64</b> according to this embodiment detects whether or not the foreign object image <b>96</b> is present on the projection image <b>98</b> included in the visible light image <b>90</b>. In a case in which the foreign object image <b>96</b> is present on the projection image <b>98</b>, it is determined that a foreign object is present in the irradiation region <b>70</b>. On the other hand, in a case in which the foreign object image <b>96</b> is not present on the projection image <b>98</b> included in the visible light image <b>90</b>, the detection unit <b>64</b> determines that a foreign object is absent in the irradiation region <b>70</b>. In addition, in practice, distortion occurs in the visible light image <b>90</b> captured by the visible light camera <b>31</b> due to a lens of the visible light camera <b>31</b>. Therefore, it is preferable that the detection unit <b>64</b> detects whether or not a foreign object is present in the irradiation region <b>70</b>, considering the distortion caused by the lens.</p><p id="p-0180" num="0178">Even in a case in which the foreign object image <b>96</b> appears on the visible light image <b>90</b>, a foreign object may not be present in the irradiation region <b>70</b>. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>25</b></figref>, in a case in which the visible light image <b>90</b> is larger than the range of the irradiation field <b>71</b>, even though the foreign object image <b>96</b> appears in a region other than the region corresponding to the range of the irradiation field <b>71</b> in the visible light image <b>90</b>, a foreign object is not present in the irradiation region <b>70</b>. Therefore, as described above, in this embodiment, the detection unit <b>64</b> makes the projection image <b>98</b> on the projection surface <b>43</b>A have the same size as the range of the irradiation field <b>71</b> and detects whether or not the foreign object image <b>96</b> is present on the projection image <b>98</b> included in the visible light image <b>90</b>, which makes it possible to detect whether or not a foreign object is present in the irradiation region <b>70</b> with higher accuracy.</p><p id="p-0181" num="0179">In addition, since the operation of the console <b>12</b> according to this embodiment, specifically, the foreign object detection process is different from that in each of the above-described embodiments, the foreign object detection process performed by the console <b>12</b> according to this embodiment will be described.</p><p id="p-0182" num="0180"><figref idref="DRAWINGS">FIG. <b>26</b></figref> is a flowchart illustrating an example of the flow of the foreign object detection process performed in the console <b>12</b> according to this embodiment. The foreign object detection process according to this embodiment illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref> is different from the foreign object detection process (see <figref idref="DRAWINGS">FIG. <b>17</b></figref>) according to the third embodiment in that it comprises processes in Steps S<b>194</b> and S<b>196</b> before Step S<b>200</b>.</p><p id="p-0183" num="0181">As illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref>, in a case in which the foreign object detection process starts, first, the projection control unit <b>68</b> determines whether or not to start the projection of the projection image <b>98</b> in Step S<b>194</b>. For example, in this embodiment, the projector <b>29</b> starts the projection of the visible light image <b>90</b> in a case in which predetermined projection start conditions are satisfied. The projection start conditions are not particularly limited. For example, it is preferable that it is detected whether or not a foreign object is present in the irradiation region <b>70</b> after the positioning of the subject W is completed. Therefore, an example of the projection start conditions is a case in which the positioning of the subject W is completed. In this case, the aspect of determining that the positioning of the subject W has been completed is not particularly limited. For example, it is determined that the positioning of the subject W has been completed in a case in which a predetermined time has elapsed since the stop of the movement of the compression plate <b>40</b> in a direction in which the breast WB is compressed or since a movement speed was equal to or less than a threshold speed or in a case in which a predetermined time has elapsed since the height of the compression plate <b>40</b> was not changed. Further, an example of the projection start conditions is a case in which the user inputs an instruction to start projection using the operation unit <b>56</b> or the like.</p><p id="p-0184" num="0182">The determination result in Step S<b>194</b> is &#x201c;No&#x201d; until the projection start conditions are satisfied. On the other hand, in a case in which the projection start conditions are satisfied, the determination result in Step S<b>194</b> is &#x201c;Yes&#x201d;, and the process proceeds to Step S<b>196</b>.</p><p id="p-0185" num="0183">In Step S<b>196</b>, the projection control unit <b>68</b> derives the position and size of the range of the irradiation field <b>71</b> on the projection surface <b>43</b>A as described above. The projection control unit <b>68</b> according to this embodiment derives the coordinates of the projection image <b>98</b> on the projection surface <b>43</b>A which corresponds to the position and size of the range of the irradiation field <b>71</b> using the above-described Expression (1).</p><p id="p-0186" num="0184">Then, in Step S<b>198</b>, the projection control unit <b>68</b> controls the projector <b>29</b> such that the projection image <b>98</b> is projected according to the position and size of the range of the irradiation field <b>71</b> derived in Step S<b>196</b> as described above. Further, in some cases, the projector <b>29</b> projects an image corresponding to another purpose, in addition to the purpose of detecting a foreign object. For example, in some cases, the projector <b>29</b> projects an image or the like, which indicates a skin line of the breast WB in a case in which ideal positioning is performed, onto the projection surface <b>43</b>A of the compression plate <b>40</b> in order to support the positioning of the subject W. As described above, in a case in which the projector <b>29</b> projects another image onto the projection surface <b>43</b>A, the projection control unit <b>68</b> performs control to end the projection of other images and to switch to the projection of the projection image <b>98</b>. Further, the mammography apparatus <b>10</b> comprises an irradiation field projection device (see <figref idref="DRAWINGS">FIG. <b>27</b></figref>) for displaying the range of the irradiation field <b>71</b> with visible light. In a case in which visible light is emitted from the irradiation field projection device to the projection surface <b>43</b>A, the projection control unit <b>68</b> controls the irradiation field projection device such that the emission of the visible light is stopped.</p><p id="p-0187" num="0185">The visible light image <b>90</b> acquired by the second acquisition unit <b>62</b> in the next Step S<b>200</b> is changed to the state illustrated in <figref idref="DRAWINGS">FIG. <b>22</b></figref> or the state illustrated in <figref idref="DRAWINGS">FIG. <b>25</b></figref> by the process in Step S<b>198</b>.</p><p id="p-0188" num="0186">Further, as illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref>, the foreign object detection process according to this embodiment is different from the foreign object detection process (see <figref idref="DRAWINGS">FIG. <b>17</b></figref>) according to the third embodiment in that it comprises a process in Step S<b>207</b> instead of Steps S<b>204</b> and S<b>206</b>.</p><p id="p-0189" num="0187">In Step S<b>207</b>, the detection unit <b>64</b> determines whether or not a foreign object is present in the irradiation region <b>70</b>. As described above, the detection unit <b>64</b> according to this embodiment determines whether or not a foreign object is present in the irradiation region <b>70</b> according to whether or not the foreign object image <b>96</b> is present on the projection image <b>98</b> included in the visible light image <b>90</b> acquired in Step S<b>200</b>. In addition, the specific method by which the detection unit <b>64</b> determines whether or not the foreign object image <b>96</b> is present on the projection image <b>98</b> included in the visible light image <b>90</b> is not particularly limited. For example, a visible light image <b>90</b> (see <figref idref="DRAWINGS">FIG. <b>22</b></figref>) captured by the visible light camera <b>31</b> in a state in which a foreign object is absent in the irradiation region <b>70</b> may be used as a reference projection image, and a projection image included in the reference projection image may be compared with the projection image <b>98</b> included in the visible light image <b>90</b> acquired in Step S<b>200</b>. In this case, a device that stores the reference projection image is not limited. For example, the reference projection image may be stored in the storage unit <b>22</b> of the mammography apparatus <b>10</b> or the storage unit <b>52</b> of the console <b>12</b>. Specifically, the detection unit <b>64</b> derives a difference between the pixel value of the projection image <b>98</b> included in the visible light image <b>90</b> and the pixel value of the projection image included in the reference projection image to perform comparison. More specifically, in a case in which there is a region in which a predetermined number or more of pixels in which the absolute value of the difference between the pixel value of the projection image <b>98</b> included in the visible light image <b>90</b> and the pixel value of the projection image included in the reference projection image is larger than a foreign object detection threshold value are continuous, it is determined that a foreign object is present in the irradiation region <b>70</b>.</p><p id="p-0190" num="0188">Further, as illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref>, the foreign object detection process according to this embodiment is different from the foreign object detection process (see <figref idref="DRAWINGS">FIG. <b>17</b></figref>) according to the third embodiment in that it comprises a process in Step S<b>216</b> after Step S<b>214</b>. In Step S<b>216</b>, the projection control unit <b>68</b> controls the projector <b>29</b> such that the projection of the projection image <b>98</b> is ended. In response to this control, the projector <b>29</b> ends the projection of the projection image <b>98</b>. In a case in which the process in Step S<b>216</b> ends, the foreign object detection process illustrated in <figref idref="DRAWINGS">FIG. <b>26</b></figref> ends.</p><p id="p-0191" num="0189">As described above, the console <b>12</b> according to this embodiment directs the projector <b>29</b> to project the projection image <b>98</b> onto the projection surface <b>43</b>A of the compression plate <b>40</b> and acquires the visible light image <b>90</b> obtained by capturing the projection image <b>98</b> projected onto the projection surface <b>43</b>A using the visible light camera <b>31</b>. The console <b>12</b> detects whether or not a foreign object is present in the irradiation region <b>70</b> according to whether or not the foreign object image <b>96</b> is present on the projection image <b>98</b> included in the acquired visible light image <b>90</b>. Therefore, according to the console <b>12</b> of this embodiment, even after positioning is ended by the user or even in a case in which it is difficult for the user to see the irradiation region <b>70</b> of the radiation R, it is possible to appropriately detect whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> of the radiation R.</p><p id="p-0192" num="0190">In addition, as illustrated in <figref idref="DRAWINGS">FIG. <b>20</b></figref>, the mammography apparatus <b>10</b> according to this embodiment comprises a visible light source <b>37</b>V, and visible light V which has been emitted from the visible light source <b>37</b>V and reflected by the mirror <b>27</b> is projected to indicate the irradiation field <b>71</b>. In a case in which the projector <b>29</b> projects the projection image <b>98</b> onto the projection surface <b>43</b>A of the compression plate <b>40</b> and the visible light image <b>90</b> obtained by capturing the projection image <b>98</b> projected onto the projection surface <b>43</b>A is acquired by the visible light camera <b>31</b>, the irradiation by the visible light source <b>37</b>V is stopped, which makes it possible to more clearly acquire the visible light image <b>90</b>.</p><p id="p-0193" num="0191">Further, in the above-described embodiment, the aspect in which the visible light image <b>90</b> obtained by capturing the projection image <b>98</b> projected from the projector <b>29</b> is used has been described. However, in a case in which the mammography apparatus <b>10</b> comprises an irradiation field projection device that indicates the range of the irradiation field <b>71</b> with visible light, the visible light image <b>90</b> obtained by capturing the visible light indicating the range of the irradiation field <b>71</b> may be used instead of the projection image <b>98</b>. Specifically, a visible light image <b>90</b> obtained by imaging a state in which visible light is emitted to the projection surface <b>43</b>A by the irradiation field projection device may be used.</p><p id="p-0194" num="0192"><figref idref="DRAWINGS">FIG. <b>27</b></figref> is a side view illustrating an example of the outward appearance of the mammography apparatus <b>10</b> according to this embodiment. As illustrated in <figref idref="DRAWINGS">FIG. <b>27</b></figref>, the mammography apparatus <b>10</b> according to this embodiment comprises a collimator <b>21</b>, a mirror <b>27</b>, and a visible light source <b>37</b>V instead of the projector <b>29</b> of the mammography apparatus <b>10</b> (see <figref idref="DRAWINGS">FIG. <b>20</b></figref>) according to the above-described embodiment. The collimator <b>21</b>, the mirror <b>27</b>, and the visible light source <b>37</b>V according to this embodiment are an example of an irradiation field projection device according to the present disclosure.</p><p id="p-0195" num="0193">In a case in which a voltage is applied to the visible light source <b>37</b>V, the visible light source <b>37</b>V is turned on to generate the visible light V and emits the generated visible light V. For example, in the mammography apparatus <b>10</b> according to this embodiment, the visible light source <b>37</b>V is provided outside the irradiation region <b>70</b> of the radiation R.</p><p id="p-0196" num="0194">The mirror <b>27</b> reflects the visible light V emitted from the visible light source <b>37</b>V to the imaging surface <b>30</b>A of the imaging table <b>30</b> such that the irradiation field <b>71</b> of the radiation R is indicated by the visible light. The mirror <b>27</b> transmits the radiation R emitted from the radiation source <b>37</b>R.</p><p id="p-0197" num="0195">The collimator <b>21</b> has a function of limiting the irradiation field <b>71</b> of the radiation R and the visible light. As illustrated in <figref idref="DRAWINGS">FIG. <b>27</b></figref>, the collimator <b>21</b> is provided between the mirror <b>27</b> and the imaging table <b>30</b>. The irradiation field <b>71</b> is limited according to an opening portion of the collimator <b>21</b>.</p><p id="p-0198" num="0196">In the case of the mammography apparatus <b>10</b> illustrated in <figref idref="DRAWINGS">FIG. <b>27</b></figref>, the projection control unit <b>68</b> of the console <b>12</b> may perform control to direct the visible light source <b>37</b>V to emit visible light corresponding to the range of the irradiation field <b>71</b>, instead of performing control to direct the projector <b>29</b> to project the projection image <b>98</b>.</p><p id="p-0199" num="0197">Further, the visible light image <b>90</b> captured by the visible light camera <b>31</b> in a state in which the projection surface <b>43</b>A is irradiated with the visible light from the visible light source <b>37</b>V includes an image (hereinafter, referred to as a &#x201c;light irradiation field image&#x201d;) corresponding to a region irradiated with the visible light in the projection surface <b>43</b>A, instead of the projection image <b>98</b> included in the visible light image <b>90</b>. Therefore, instead of detecting whether or not the foreign object image <b>96</b> is present on the projection image <b>98</b> included in the visible light image <b>90</b>, the detection unit <b>64</b> can detect whether or not the foreign object image <b>96</b> is present on the light irradiation field image included in the visible light image <b>90</b> to detect whether or not a foreign object is present in the irradiation region <b>70</b>.</p><p id="p-0200" num="0198">As described above, the console <b>12</b> according to each of the above-described embodiments comprises the CPU <b>50</b>A as at least one processor and the ROM <b>50</b>B storing the commands that can be executed by the CPU <b>50</b>A. The CPU <b>50</b>A acquires the distance image or the visible light image captured by the TOF camera <b>39</b> or the visible light camera <b>31</b> that has an imageable region (<b>72</b>) as a region including the irradiation region <b>70</b> which is a space in which the radiation source <b>37</b>R emits the radiation R to the breast WB of the subject imaged by the mammography apparatus <b>10</b> and detects whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> on the basis of the distance image or the visible light image.</p><p id="p-0201" num="0199">As described above, the console <b>12</b> according to each of the above-described embodiments can detect whether or not a foreign object is present in the detection region <b>74</b> on the basis of the distance image captured by the TOF camera <b>39</b> or the visible light image captured by the visible light camera <b>31</b>. Therefore, according to the console <b>12</b> of each of the above-described embodiments, even in a case in which the subject W moves after positioning is completed by the user or even in a case in which it is difficult for the user to see the irradiation region <b>70</b> of the radiation R, it is possible to appropriately detect whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> of the radiation R. As a result, according to the console <b>12</b> of the above-described embodiments, it is possible to appropriately detect whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> of the radiation R.</p><p id="p-0202" num="0200">Further, according to the console <b>12</b> of each of the above-described embodiments, it is possible to appropriately detect whether or not a foreign object other than the object to be imaged is present in the irradiation region <b>70</b> of the radiation R. Therefore, it is possible to prevent a foreign object from being included in the radiographic image captured by the mammography apparatus <b>10</b>. This makes it possible to suppress re-imaging caused by so-called image loss.</p><p id="p-0203" num="0201">In addition, in each of the above-described embodiments, even in a case in which it is detected that a foreign object is present in the irradiation region <b>70</b>, a radiographic image may be captured. Therefore, in a case in which a radiographic image is captured after it is detected that a foreign object is present in the irradiation region <b>70</b>, it is preferable that the detection unit <b>64</b> of the console <b>12</b> further detects whether or not the foreign object is included in the captured radiographic image. In this case, the detection unit <b>64</b> may detect the foreign object image included in the radiographic image on the basis of the position of the foreign object image <b>96</b> detected from the distance image or the visible light image <b>90</b>. For example, the detection unit <b>64</b> may detect whether or not the foreign object image is included in the radiographic image using computer-aided diagnosis (CAD). Further, in a case in which the foreign object image is included in the radiographic image, it is preferable to perform, for example, a process of warning the user of the fact.</p><p id="p-0204" num="0202">In addition, the detection result of the detection unit <b>64</b> showing that a foreign object is present in the irradiation region <b>70</b> may be accumulated as foreign object detection result information, and advice or the like may be given to the user who positions the subject W on the basis of the accumulated foreign object detection result information. For example, the position of the foreign object image, the type of imaging, information indicating the user, information indicating the subject W, and the like may be accumulated as the foreign object detection result information to be associated with the visible light image <b>90</b> or the distance image including the foreign object image. The accumulated foreign object detection result information is analyzed and a statistical process is performed to extract the condition that a foreign object is likely to enter the irradiation region <b>70</b>, for example, for each user, each type of imaging, and each condition related to the subject W. Further, the console <b>12</b> may display information for supporting positioning by the user on the display unit <b>58</b> according to the extracted condition that a foreign object is likely to enter the irradiation region. In this case, <figref idref="DRAWINGS">FIG. <b>28</b></figref> illustrates an example of the information for supporting the positioning which is displayed on the display unit <b>58</b>. In the example illustrated in <figref idref="DRAWINGS">FIG. <b>28</b></figref>, an example is illustrated in which a schematic diagram <b>99</b>A and advice information <b>99</b>B that correspond to a typical foreign object corresponding to the extraction result are displayed as the information for supporting the positioning on the display unit <b>58</b>. The schematic diagram <b>99</b>A is a diagram obtained by superimposing a foreign object image on a breast schema diagram, a skin line image of the breast WB extracted from a radiographic image, a general breast diagram, or the like. Further, the advice information <b>99</b>B is information for presenting, to the user, a position or the like where a foreign object tends to be present on the basis of the extraction result. In a case in which the user performs positioning, the information for supporting the positioning which is illustrated in <figref idref="DRAWINGS">FIG. <b>28</b></figref> is displayed on the display unit <b>58</b> or the like, which makes it possible to further prevent a foreign object from entering the irradiation region <b>70</b>.</p><p id="p-0205" num="0203">In addition, in each of the above-described embodiments, the aspect has been described in which it is detected whether or not a foreign object is present in the irradiation region <b>70</b> on the basis of the captured image captured by one imaging device. However, a plurality of imaging devices may be used, and the captured images captured by each of the plurality of imaging devices may be used. For example, as illustrated in <figref idref="DRAWINGS">FIG. <b>29</b></figref>, two imaging devices of TOF cameras <b>39</b><sub>1 </sub>and <b>39</b><sub>2 </sub>may be used. In this case, an imageable region <b>72</b> of all of the TOF cameras <b>39</b><sub>1 </sub>and <b>39</b><sub>2 </sub>which is a combination of an imageable region <b>72</b><sub>1 </sub>of the TOF camera <b>39</b><sub>1 </sub>and an imageable region <b>72</b><sub>2 </sub>of the TOF camera <b>39</b><sub>2 </sub>may include the irradiation region <b>70</b>. Therefore, this configuration is effective for a case in which only one of the imageable region <b>72</b><sub>1 </sub>of the TOF camera <b>39</b><sub>1 </sub>and the imageable region <b>72</b><sub>2 </sub>of the TOF camera <b>39</b><sub>2 </sub>is not capable of including the irradiation region <b>70</b>. In the case of the example illustrated in <figref idref="DRAWINGS">FIG. <b>29</b></figref>, for example, a distance image captured by the TOF camera <b>39</b><sub>1 </sub>and a distance image captured by the TOF camera <b>39</b><sub>2 </sub>are registered and combined into one distance image, which makes it possible to detect whether or not a foreign object is present in the irradiation region <b>70</b> as in the first embodiment.</p><p id="p-0206" num="0204">Further, in the first embodiment, the aspect has been described in which the TOF camera <b>39</b> is provided on the side close to the compression unit <b>36</b> in the radiation emitting unit <b>37</b> of the mammography apparatus <b>10</b>. In the second embodiment, the aspect has been described in which the visible light camera <b>31</b> is provided in the vicinity of the collimator <b>33</b>. However, the position where each of the TOF camera <b>39</b> and the visible light camera <b>31</b> is provided is not limited to these aspects. Each of the TOF camera <b>39</b> and the visible light camera <b>31</b> may be disposed in a state in which the irradiation region <b>70</b> is included in the imageable region (imageable region <b>72</b>) as described above, and the positions thereof are not limited. For example, the TOF camera <b>39</b> may be provided on the side close to the face guard <b>38</b> in the radiation emitting unit <b>37</b>. Further, for example, the TOF camera <b>39</b> or the visible light camera <b>31</b> may be provided outside the mammography apparatus <b>10</b>. Furthermore, for example, in the case where both the TOF camera <b>39</b> and the visible light camera <b>31</b> are provided, the TOF camera <b>39</b> and the visible light camera <b>31</b> may be provided side by side at the same position or may be provided at different positions.</p><p id="p-0207" num="0205">Furthermore, in each of the above-described embodiments, the aspect in which the distance image is captured by the TOF method using the TOF camera has been described as an example of the aspect of capturing the distance image. However, the distance image capture device for capturing the distance image is not limited to the TOF camera. For example, the following aspect may be used: a distance image capture device that irradiates an object to be imaged with infrared light having a pattern and captures a distance image corresponding to reflected light from the object to be imaged is used, and a structured light method is applied to capture the distance image. Further, for example, a depth-from-defocus (DFD) method that restores the distance on the basis of the degree of blurring of an edge region in the distance image may be applied. In the case of this aspect, for example, an aspect is known which uses a distance image captured by a monocular camera using a color aperture filter.</p><p id="p-0208" num="0206">Further, in the first and second embodiments, the aspect has been described in which the mammography apparatus <b>10</b> is applied as an example of the radiography apparatus according to the present disclosure. However, the radiography apparatus according to the first and second embodiments is not limited to the mammography apparatus. For example, a radiography apparatus for performing general imaging may be applied.</p><p id="p-0209" num="0207">Further, in each of the above-described embodiments, the aspect in which the console <b>12</b> is an example of the information processing device according to the present disclosure has been described. However, devices other than the console <b>12</b> may have the functions of the information processing device according to the present disclosure. In other words, for example, the mammography apparatus <b>10</b> or an external device other than the console <b>12</b> may have some or all of the functions of the first acquisition unit <b>60</b>, the second acquisition unit <b>62</b>, and the detection unit <b>64</b>.</p><p id="p-0210" num="0208">In addition, in each of the above-described embodiments, for example, the following various processors can be used as the hardware structure of processing units performing various processes such as the first acquisition unit <b>60</b>, the second acquisition unit <b>62</b>, and the detection unit <b>64</b>. The various processors include, for example, a programmable logic device (PLD), such as a field programmable gate array (FPGA), that is a processor whose circuit configuration can be changed after manufacture and a dedicated electric circuit, such as an application specific integrated circuit (ASIC), that is a processor having a dedicated circuit configuration designed to perform a specific process, in addition to the CPU that is a general-purpose processor which executes software (program) to function as various processing units as described above.</p><p id="p-0211" num="0209">One processing unit may be configured by one of the various processors or a combination of two or more processors of the same type or different types (for example, a combination of a plurality of FPGAs or a combination of a CPU and an FPGA). In addition, a plurality of processing units may be configured by one processor.</p><p id="p-0212" num="0210">A first example of the configuration in which a plurality of processing units are configured by one processor is an aspect in which one processor is configured by a combination of one or more CPUs and software and functions as a plurality of processing units. A representative example of this aspect is a client computer or a server computer. A second example of the configuration is an aspect in which a processor that implements the functions of the entire system including a plurality of processing units using one integrated circuit (IC) chip is used. A representative example of this aspect is a system-on-chip (SoC). As such, various processing units are configured by using one or more of the various processors as a hardware structure.</p><p id="p-0213" num="0211">In addition, specifically, an electric circuit (circuitry) obtained by combining circuit elements, such as semiconductor elements, can be used as the hardware structure of the various processors.</p><p id="p-0214" num="0212">Further, in each of the above-described embodiments, the aspect in which the foreign object detection processing program <b>51</b> is stored (installed) in the storage unit <b>52</b> in advance has been described. However, the present disclosure is not limited thereto. The foreign object detection processing program <b>51</b> may be recorded on a recording medium, such as a compact disc read only memory (CD-ROM), a digital versatile disc read only memory (DVD-ROM), or a universal serial bus (USB) memory, and then provided. In addition, the foreign object detection processing program <b>51</b> may be downloaded from an external device through the network.</p><p id="p-0215" num="0213">The disclosure of JP2020-065268 filed Mar. 31, 2020 and JP2020-219603 filed Dec. 28, 2020 are incorporated herein by reference in their entirety.</p><p id="p-0216" num="0214">All of the documents, the patent applications, and the technical standards described in the specification are incorporated by reference herein to the same extent as it is specifically and individually stated that individual documents, patent applications, and technical standards are incorporated by reference.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An information processing device comprising:<claim-text>at least one processor; and</claim-text><claim-text>a memory that stores commands executable by the processor,</claim-text><claim-text>wherein the processor acquires a captured image captured by an imaging device that has, as an imageable region, a region including an irradiation region which is a space in which an object to be imaged by a radiography apparatus is irradiated with radiation emitted from a radiation source and detects whether or not a foreign object other than the object to be imaged is present in a detection region which is a space between the object to be imaged and the radiation source within the irradiation region on the basis of the captured image.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the radiography apparatus is a mammography apparatus that captures a radiographic image of a breast of a subject, and</claim-text><claim-text>the detection region is a space between a compression member that compresses the breast and the radiation source in the irradiation region.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the imaging device is a distance image capture device that captures a distance image indicating a distance to the object to be imaged as the captured image.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The information processing device according to <claim-ref idref="CLM-00003">claim 3</claim-ref>,<claim-text>wherein the processor detects whether or not the foreign object is present in the detection region using an image corresponding to the detection region in the distance image.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The information processing device according to <claim-ref idref="CLM-00004">claim 4</claim-ref>,<claim-text>wherein the processor detects whether or not the foreign object is present in the detection region on the basis of a distance between the imaging device and each position in the detection region derived on the basis of a position of the detection region and a distance between the imaging device and the object to be imaged indicated by the image corresponding to the detection region in the distance image.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The information processing device according to <claim-ref idref="CLM-00003">claim 3</claim-ref>,<claim-text>wherein the distance image capture device captures the distance image using a time-of-flight (TOF) method.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the imaging device is a visible light image capture device that captures a visible light image of the object to be imaged as the captured image.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the radiography apparatus is a mammography apparatus that captures a radiographic image of a breast compressed by a compression member,</claim-text><claim-text>the imaging device is a visible light image capture device that captures a visible light image of the object to be imaged as the captured image, and</claim-text><claim-text>the processor detects whether or not the foreign object is present on the basis of a chipping of an image of the compression member in the captured image.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The information processing device according to <claim-ref idref="CLM-00008">claim 8</claim-ref>,<claim-text>wherein the processor detects whether or not the foreign object is present on the basis of a chipping of a subject on the breast in the image of the compression member.</claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The information processing device according to <claim-ref idref="CLM-00008">claim 8</claim-ref>,<claim-text>wherein the processor uses an image of an edge portion of the compression member as the image of the compression member.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The information processing device according to <claim-ref idref="CLM-00010">claim 10</claim-ref>,<claim-text>wherein the processor acquires compression member information indicating a type of the compression member and estimates at least one of a position or a size of the image of the edge portion included in the captured image on the basis of the compression member information.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The information processing device according to <claim-ref idref="CLM-00010">claim 10</claim-ref>,<claim-text>wherein the edge portion of the compression member has a color different from a color of at least one of a compression surface, which compresses the breast, in the</claim-text><claim-text>compression member or an imaging table on which the breast is placed, and the processor extracts the image of the edge portion of the compression member from the captured image on the basis of the color of the edge portion.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The information processing device according to <claim-ref idref="CLM-00010">claim 10</claim-ref>,<claim-text>wherein the edge portion of the compression member is processed to be distinguishable from an image of a compression surface, which compresses the breast, in the compression member in the captured image, and</claim-text><claim-text>the processor extracts the image of the edge portion from the captured image.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The information processing device according to <claim-ref idref="CLM-00013">claim 13</claim-ref>,<claim-text>wherein the edge portion of the compression member is highlighted by at least one of a phosphorescent material or a fluorescent material.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The information processing device according to <claim-ref idref="CLM-00008">claim 8</claim-ref>,<claim-text>wherein the processor detects whether or not the foreign object is present on the basis of a chipping of an image of a region corresponding to a type of the imaging in the image of the compression member.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the radiography apparatus is a mammography apparatus that captures a radiographic image of a breast compressed by a compression member, and</claim-text><claim-text>the imaging device is a visible light image capture device that captures, as the captured image, a visible light image obtained by capturing a projection image projected onto an irradiation surface of the compression member, which is irradiated with the radiation, by an image projection device.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The information processing device according to <claim-ref idref="CLM-00016">claim 16</claim-ref>,<claim-text>wherein the projection image projected onto the irradiation surface is projected within a range of an irradiation field of the radiation.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The information processing device according to <claim-ref idref="CLM-00016">claim 16</claim-ref>,<claim-text>wherein the projection image projected onto the irradiation surface is projected within a range of an irradiation field of the radiation in a state in which visible light is not emitted by an irradiation field projection device that projects the range of the irradiation field of the radiation with the visible light.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The information processing device according to <claim-ref idref="CLM-00016">claim 16</claim-ref>,<claim-text>wherein the processor detects whether or not the foreign object is present on the basis of an image of a region corresponding to an inside of an irradiation field of the radiation in the captured image.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The information processing device according to <claim-ref idref="CLM-00016">claim 16</claim-ref>,<claim-text>wherein the processor detects whether or not the foreign object is present on the basis of a comparison result between the projection image and the captured image.</claim-text></claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The information processing device according to <claim-ref idref="CLM-00016">claim 16</claim-ref>,<claim-text>wherein the processor controls the image projection device such that the projection image is projected onto a region including an irradiation field of the radiation.</claim-text></claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The information processing device according to <claim-ref idref="CLM-00021">claim 21</claim-ref>,<claim-text>wherein the processor derives a size and position of the irradiation field on the irradiation surface of the compression member according to a height of the compression member and performs control to project the projection image according to the derived size and position of the irradiation field.</claim-text></claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein the radiography apparatus is a mammography apparatus that captures a radiographic image of a breast compressed by a compression member, and</claim-text><claim-text>the imaging device is a visible light image capture device that captures, as the captured image, an image of a state in which a range of an irradiation field of the radiation is projected onto the compression member by an irradiation field projection device that projects the range of the irradiation field of the radiation with visible light.</claim-text></claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein, in a case in which it is detected that the foreign object is present, the processor prohibits the emission of the radiation by the radiation source.</claim-text></claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein, in a case in which it is detected that the foreign object is present, the processor outputs a warning related to the foreign object.</claim-text></claim-text></claim><claim id="CLM-00026" num="00026"><claim-text><b>26</b>. The information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>,<claim-text>wherein a plurality of the imaging devices are provided, and</claim-text><claim-text>an imageable region of all of the plurality of imaging devices, which is a combination of the imageable regions of each of the plurality of imaging devices, includes the irradiation region.</claim-text></claim-text></claim><claim id="CLM-00027" num="00027"><claim-text><b>27</b>. A radiography apparatus comprising:<claim-text>the information processing device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>; and</claim-text><claim-text>the imaging device.</claim-text></claim-text></claim><claim id="CLM-00028" num="00028"><claim-text><b>28</b>. An information processing method executed by a computer, the information processing method comprising:<claim-text>acquiring a captured image captured by an imaging device that has, as an imageable region, a region including an irradiation region which is a space in which an object to be imaged by a radiography apparatus is irradiated with radiation emitted from a radiation source; and</claim-text><claim-text>detecting whether or not a foreign object other than the object to be imaged is present in a detection region which is a space between the object to be imaged and the radiation source within the irradiation region on the basis of the captured image.</claim-text></claim-text></claim><claim id="CLM-00029" num="00029"><claim-text><b>29</b>. A non-transitory computer-readable storage medium storing an information processing program that causes a computer to execute a process comprising:<claim-text>acquiring a captured image captured by an imaging device that has, as an imageable region, a region including an irradiation region which is a space in which an object to be imaged by a radiography apparatus is irradiated with radiation emitted from a radiation source; and</claim-text><claim-text>detecting whether or not a foreign object other than the object to be imaged is present in a detection region which is a space between the object to be imaged and the radiation source within the irradiation region on the basis of the captured image.</claim-text></claim-text></claim></claims></us-patent-application>
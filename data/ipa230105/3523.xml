<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230003524A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230003524</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17940894</doc-number><date>20220908</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>19172787.4</doc-number><date>20190506</date></priority-claim><priority-claim sequence="02" kind="regional"><country>EP</country><doc-number>19172787.4</doc-number><date>20190506</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>C</subclass><main-group>15</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>C</subclass><main-group>1</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>01</class><subclass>L</subclass><main-group>31</main-group><subgroup>107</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>66</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>66</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>C</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>15</main-group><subgroup>006</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>1</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>31</main-group><subgroup>107</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>S</subclass><main-group>17</main-group><subgroup>66</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20170101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>7</main-group><subgroup>66</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e79">AUTOMATIC LOCATING OF TARGET MARKS</invention-title><us-related-documents><division><relation><parent-doc><document-id><country>US</country><doc-number>16868162</doc-number><date>20200506</date></document-id><parent-status>PENDING</parent-status></parent-doc><child-doc><document-id><country>US</country><doc-number>17940894</doc-number></document-id></child-doc></relation></division></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>HEXAGON TECHNOLOGY CENTER GMBH</orgname><address><city>Heerbrugg</city><country>CH</country></address></addressbook><residence><country>CH</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>WALSER</last-name><first-name>Andreas</first-name><address><city>St.Gallen</city><country>CH</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>BESTLER</last-name><first-name>Simon</first-name><address><city>Langenargen</city><country>DE</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>HEXAGON TECHNOLOGY CENTER GMBH</orgname><role>03</role><address><city>Heerbrugg</city><country>CH</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A target reflector search device. This device comprises an emitting unit for emitting an emission fan, a motorized device for moving the emission fan over a spatial region, and a receiving unit for reflected portions of the emission fan within a fan-shaped acquisition region, and a locating unit for determining a location of the reflection. An optoelectronic detector of the receiving unit is formed as a position-resolving optoelectronic detector having a linear arrangement of a plurality of pixels, each formed as an SPAD array, and the receiving unit comprises an optical system having an imaging fixed-focus optical unit, wherein the optical system and the optoelectronic detector are arranged and configured in such a way that portions of the optical radiation reflected from a point in the acquisition region are expanded on the sensitivity surface of the optoelectronic detector in such a way that blurry imaging takes place.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="113.11mm" wi="154.43mm" file="US20230003524A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="207.35mm" wi="156.46mm" file="US20230003524A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="202.69mm" wi="153.59mm" file="US20230003524A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="205.23mm" wi="154.60mm" file="US20230003524A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="200.91mm" wi="155.62mm" file="US20230003524A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="178.48mm" wi="136.91mm" file="US20230003524A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="188.13mm" wi="134.03mm" orientation="landscape" file="US20230003524A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="186.01mm" wi="92.37mm" file="US20230003524A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="215.31mm" wi="101.52mm" orientation="landscape" file="US20230003524A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="174.75mm" wi="110.74mm" orientation="landscape" file="US20230003524A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="221.91mm" wi="150.62mm" file="US20230003524A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading><p id="p-0002" num="0001">This application claims priority to European Patent Application No. 19172793.2, filed on May 6, 2019 and European Patent Application No. 19172787.4, filed on May 6, 2019. The foregoing patent applications are herein incorporated by reference.</p><heading id="h-0002" level="1">FIELD OF THE INVENTION</heading><p id="p-0003" num="0002">The present invention generally relates to automatic locating of target marks. A first aspect of the invention, which is described hereinafter, relates to a target reflector search device and a method for automatic target acquisition, and especially also to a surveying device, which is designed for automatically locating reflective target marks. A second aspect of the invention which is described further below relates to a method and a device for automatic image-based location of a target marker.</p><heading id="h-0003" level="1">BRIEF SUMMARY OF THE INVENTION</heading><p id="p-0004" num="0003">The first aspect of some aspects of the present invention relates to automatic locating of reflective target marks for a surveying device by means of an optical-electronic device. Such automatic target locators, also referred to as ATR (Automatic Target Recognition) or Power Search are known, for example, from CH 676042, EP 1 329 691, U.S. Pat. No. 6,031,606, EP 1 422 499, or EP 1 876 416. These target reflector search devices automatically scan their surroundings using a searchlight fan for retroreflective objects, which can then be automatically targeted as a result by the surveying device for exact geodetic surveying.</p><p id="p-0005" num="0004">It is a problem of the first aspect of some embodiments of the present invention to improve such a target reflector search device, a target finder, or a target acquisition unit&#x2014;especially in a surveying device, for example, a total station, but also in a theodolite, tachymeter, laser scanner, laser tracker, laser leveler, or similarly constructed devices.</p><p id="p-0006" num="0005">A faster and/or more accurate acquisition of reflective targets can especially be sought out in this case, in particular wherein a distance to the target is also to be ascertained in addition to a two-dimensional direction. The possibilities for differentiating spurious reflections and actual measurement targets are also to be further improved and automated as much as possible in this case.</p><p id="p-0007" num="0006">These problems are solved according to some aspects of the invention by the features of the independent claims and/or these solutions are refined by the features of the dependent claims.</p><p id="p-0008" num="0007">In this case, a light fan is emitted by the target finder, which can be formed as a separate unit or can be integrated into a surveying device. For example, a light line or laser line aligned in a first direction, which extends over a predetermined angle range and is preferably continuous or at least essentially continuous, is emitted, preferably essentially along a straight line. This emission of the light fan can be performed here, for example, using a corresponding beamforming, imaging refractive, catadioptric, or diffractive optical unit, which forms the emitted light (for example, from one single or from multiple semiconductor light sources such as LEDs or lasers) into a line, are formed. Alternatively, the emission of the light fan can also be performed using a scanning movement of a deflecting element. In addition to a continuous emission, a time-pulsed emission of the light can also be performed here.</p><p id="p-0009" num="0008">This light fan is movable in this case in a second direction, which does not coincide with the first direction, for example, essentially or substantially orthogonally to a longitudinal direction of the light fan. In one embodiment, the light fan can be rotated or pivoted here in the second direction by an angle range, preferably by up to 360&#xb0;. For example, in this case the light source and/or its optical unit can be moved, or a deflection unit for the emitted light (for example, a mirror or a prism) can be moved. A solid angle range can thus be scanned using the light fan, for example, a conical or pyramidal solid angle range or an (often symmetrical) spherical zone. During the movement of the light fan, a current location of the movement can be acquired or measured in this case using an encoder or another sensor unit, in particular at least in the second direction.</p><p id="p-0010" num="0009">In one embodiment of a surveying device designed like a theodolite in its geometry (for example, a total station or a laser scanner), the emitting unit for the light fan can be arranged here in such a way that the light fan is rotatable with the surveying device&#x2014;especially around the standing axis.</p><p id="p-0011" num="0010">Thus, for example, the emitting unit can be arranged in the upper structure, the alidade (i.e., for example, on the base or in one of the supports), or also on or in the telescope body or telescope, so that the light fan is moved with this part of the surveying device. The light fan can optionally also be movable around the tilt axis&#x2014;for example, if it is emitted on or in the telescope. In one special embodiment, the light fan can also be emitted essentially coaxially through the telescope, for example. A direction of the emitted light fan can be determined in this case using the angle encoders of the corresponding theodolite axes.</p><p id="p-0012" num="0011">If at least a part of the emitted light fan is incident on a reflective and/or retroreflective object, at least a part of the emitted light is thus reflected and can be detected using a receiving unit of the target finder. The receiving unit comprises in this case a receiving optical unit and an optoelectronic detector, and can be formed, for example, coaxial or biaxial in relation to the emitting unit in this case. A field of view of the receiving unit is configured or formed here in such a way that it coincides with the emitted light fan or covers it&#x2014;at least essentially or also exactly. For example, this can be performed using an optical system having a corresponding arrangement and formation of optical components, such as lenses, screens, diffractive structures, etc.</p><p id="p-0013" num="0012">The optoelectronic detector is position-resolving in this case and is especially arranged and configured or formed in such a way that a position resolution can be carried out using it within the light fan, i.e., for example, along the projected laser line along the first direction.</p><p id="p-0014" num="0013">Upon movement of the light fan over a spatial region, an analysis unit can thus ascertain a location of a reflecting target within this scanned spatial region in the first direction on the basis of the location resolution and in the second direction on the basis of an associated direction of the movement.</p><p id="p-0015" num="0014">In one embodiment, the light fan can also be used to ascertain at least a rough distance to the reflecting target. Exact surveying of the distance with geodetic accuracy, i.e., surveying with the full measurement accuracy of the actual surveying device, is not important in this case. However, a distance can be ascertained at least roughly&#x2014;in relation to the measurement accuracy of the surveying device, i.e., for example, approximately at an accuracy in the range of centimeters&#x2014;by means of the target reflector search device. For example, this can be performed using an analysis of a runtime of the light from the target acquisition unit to the reflecting target and back. For example, the light fan is emitted in the form of amplitude-modulated or time-interval-modulated light pulses and a time difference is ascertained between the emission of the light fan pulse and the reception of a reflected portion or component of the light fan pulse, whereby a distance value is ascertained from this runtime on the basis of the of the propagation speed of the light. To carry out such a determination of the distance, the receiving unit is designed accordingly to be able to acquire such runtimes in the range of nanoseconds or less.</p><p id="p-0016" num="0015">In order to be able to cover the spatial region with sufficiently high resolution using a family of light fans during rapid movement of the light fan in the second direction, a corresponding rapid analysis of the receiving unit is to be endeavored. Moreover, the analysis of the optoelectronic detector in the first direction has to be able to be carried out with a sufficiently high position resolution to also be able to cover the first direction with a resolution sufficient for this purpose. Multiple reflections can also certainly occur in practice within one of the light fans simultaneously, which are to be recognized accordingly and separated as much as possible by the analysis unit. These requirements&#x2014;especially when considered together&#x2014;can only be fulfilled inadequately using conventional CCD or CMOS sensors or also PSDs as optoelectronic detectors.</p><p id="p-0017" num="0016">The first aspect of some aspects of the present invention especially relates to a target reflector search device, which is designed for automatic locating of at least one (in particular retro-) reflective target mark by a geodetic surveying device. This device comprises in this case an emitting unit, which emits optical radiation in the form of an emission fan oriented in a first direction to illuminate the target mark. This emission fan can preferably be formed as a plane in this case, so that the projection in the search space is formed linear, especially as a straight line, and, for example, having an opening angle of approximately +/&#x2212;5 to +/&#x2212;20&#xb0; in the first fan direction and is formed orthogonally thereto as a preferably collimated light line having an opening angle at least less than +/&#x2212;1&#xb0;, preferably narrower than +/&#x2212;0.05&#xb0;. In one embodiment, in the case of a positioned total station as a surveying device, the alignment of the emission fan can be, for example, essentially parallel to the standing axis (i.e., in regular operation essentially vertical) and can in particular extend over an angle range of, for example, approximately +/&#x2212;20&#xb0; in relation to a horizontal direction.</p><p id="p-0018" num="0017">Furthermore, a motorized device is provided for moving the emission fan along a second direction. This can be configured or formed as a dedicated part of the device or also as part of the surveying device. It is designed to move the emission fan over a spatial region along the second direction and to acquire a value of the second direction. The second direction does not coincide with the first direction in this case and is preferably oriented essentially orthogonally to the first direction. For example, in the above-mentioned total station, the movement can be formed as a rotation over an angle range around a vertically oriented standing axis, thus preferably, for example, a substantially horizontal pivot of the emission fan over the spatial region to be acquired, especially by up to 360&#xb0;.</p><p id="p-0019" num="0018">The device according to some aspects of the invention also comprise a receiving unit in this case, which receives reflected portions or components of the optical radiation of the emission fan as reflections using an optoelectronic detector. The reflections from the reflective target mark are to be acquired especially in this case&#x2014;in practice, however, often unfortunately not only these but rather also undesired interfering reflections from other reflectively acting objects in the spatial region are received. This reception takes place in this case within a fan-shaped acquisition region, which is also referred to as a reception fan. The reception region is moved along with the emission fan in this case and can be formed in such a way that it essentially corresponds to the alignment and dimensions of the emission fan or comprises it.</p><p id="p-0020" num="0019">The device moreover comprises a locating unit, which determines a position of the reflection using an analysis of the receiving unit and on the basis of the values of the second direction. This position in the spatial region can especially be provided in this case as coordinates in a coordinate system of the target reflector search device or in the coordinate system of the surveying device, for example, as a location of the target reflector in the first and second directions, in the above example thus, for example, in the form of a horizontal location and a vertical location of the target reflector.</p><p id="p-0021" num="0020">According to the first aspect of some aspects of the present invention, in this case the optoelectronic detector is designed as a position-resolving optoelectronic detector having a linear arrangement of multiple photosensitive pixels or sensor elements. The pixels are each formed in this case as SPAD (Single Photon Avalanche Photodiodes) array acquisition units, which are each formed per pixel having multiple Single Photon Avalanche Photodiodes (SPADs) operated in the Geiger mode and interconnected to form a common output signal. Such SPADs are also referred to as MPPC (Multi Pixel Photon Counter) or SPM (Semiconductor Photomultiplier) or in general as Semiconductor Photomultiplier and are described, for example, in function and exemplary embodiments, inter alia in US 2016/0005913, US 2017/0242136, US 2016/0181293, US 2013/0099346, WO 2014/180487, and U.S. Pat. No. 9,087,936.</p><p id="p-0022" num="0021">The detector comprises in this case a preferably linear juxtaposition of at least more than at least two such pixels, which can be formed as individual components or jointly as a monolithic component. According to the invention, however, one hundred or more pixels are not used in this case, but rather a comparatively small number of pixels, for example, in relation to classic CCD lines or cameras, i.e., for example, approximately fewer than 33 pixels, preferably fewer than 17 pixels, especially, for example, approximately 5 to 16 pixels. The sensitivity surfaces of these pixels are preferably at least approximately continuously juxtaposed in the linear arrangement in this case, i.e., for example, having a distance between the sensitivity surfaces of the pixels of less than 20% of the sensitivity surface dimension in the linear direction, preferably of less than 10% or even less, down to a distance of zero or approximately zero. In one exemplary embodiment, a pixel formed as an SPAD array can be formed with respect to the order of magnitude as an at least approximately square pixel having approximately 1 mm edge length. During the analysis thereof, an amplifier stage, especially a TIA, can usually be omitted in relation to conventional APDs. A higher bandwidth, in particular in the range &#x3e;1 GHz, is also implementable in comparison to CMOS-based or CCD-based systems. Therefore, inter alia, the SNR may be improved and/or a better suppression of ambient light may be achieved, for example, of sunlight on a construction site. In comparison to classic photosensors, very high amplitude dynamics may also be achieved by nonlinear compression of the signal. In contrast to an integrated signal of a CMOS or CCD sensor, a SiPM supplies a direct time signal in real-time and enables a picosecond resolution of a received light pulse, which is also advantageous, for example, for a precise distance measurement.</p><p id="p-0023" num="0022">The multiple individual single photon avalanche photodiodes of a pixel formed as an SPAD array are interconnected in this case to form a single output signal per pixel. For example, the photodiodes can each be provided with a series resistor and these series circuits can then be connected in parallel to form one pixel output signal.</p><p id="p-0024" num="0023">The receiving unit also comprises an optical system having an imaging fixed-focus optical unit, for example, having at least one optical lens or lens group. In one embodiment, for example, using an imaging single lens, the entire object space of the fan-shaped reception region can be imaged in an image space or in an image plane.</p><p id="p-0025" num="0024">The optical system and the optoelectronic detector are arranged and formed in this case in such a way that portions or components of the optical radiation reflected from the acquisition region are expanded on the sensitivity surface of the optoelectronic detector in such a way that blurry imaging takes place. The arrangement and design of the optical system and the detector are thus embodied according to the invention in such a way that light from one point in the acquisition region, differing from optimum focusing, is incident on a non-minimal surface region on the detector. Expressed in reverse, an acquisition region imaged in the object space of one of the pixels is formed in this case in such a way that it partially overlaps with the acquisition region of an adjacent pixel.</p><p id="p-0026" num="0025">In an alternative embodiment, the receiving optical unit can be designed in such a way that a diffuser plate is arranged in the image plane or focal plane, for example, as a thin microlens array or hologram having high transmission. In this case, the sensitivity surface of the optoelectronic detector can be located directly behind the diffuser plate. This arrangement of the optical system and the detector can especially be designed according to the invention in this case in such a way that light from a point in the acquisition region is sharply imaged in the focal plane, but occupies a certain surface region on the detection surface of the optoelectronic detector, which is larger than the sharp imaging. In other words, the edge zones of the acquisition regions of two adjacent pixels thus partially overlap. In this way, for example, advantages can be provided with respect to controlling background light, reducing or preventing an edge drop of the brightness, and/or avoiding virtual intermediate imaging of the sensor surface in the object space.</p><p id="p-0027" num="0026">The position of the reflection in the first direction is thus determined using an analysis of the optoelectronic detector and on the basis of the associated, in particular chronologically associated, second direction. The determined position can then be provided to the surveying device, which as a result can exactly target this position using its telescope or laser target axis and can survey it in a known manner.</p><p id="p-0028" num="0027">The optical system can be formed in this case in one embodiment having a detector offset to the front or rear by a defined offset in relation to a focal plane of the imaging optical unit. In particular, the pixels can thus be arranged defocused in this case in relation to the focus or focal point of the optical unit. Especially, for example, the imaging optical unit and the pixels can be formed and arranged in such a way that light from one point from an object space located in front of the imaging optical unit illuminates a surface on the SPAD array line located behind the imaging optical unit, wherein this surface is intentionally larger than the minimal circle of confusion caused by the quality of the optical system. In particular, in one embodiment, this surface can be at least approximately equal to or larger than a sensitivity surface of one of the pixels. In other words, the photosensitive region of the linear detector can be arranged defocused in such a way that incident electromagnetic radiation is distributed essentially homogeneously over a coherent sensitivity region of the pixels.</p><p id="p-0029" num="0028">In a further embodiment, a microlens array can be arranged in or somewhat in front of the focal plane of the wide-angle receiving optical unit of the receiving unit. This microlens array is formed having a number of cylindrical rod lenses continuously abutting one another, which expand the acquisition region in a defined manner in the direction of the laser fan. The pixels of the SPAD array line are placed behind this astigmatic microlens array viewed from the object space. A received light bundle of the receiving objective, which is imaging as such, is thus slightly expanded in the first direction immediately before the detection surface of the SPAD array line. The light from one point from the object space located in front of the imaging optical unit thus illuminates an elliptical surface on the SPAD array line located behind the imaging optical unit. In this case, this surface is intentionally designed as larger than the circle of confusion of the point transfer function of the imaging receiving objective.</p><p id="p-0030" num="0029">In one embodiment, the optical system of the receiving unit can in this case comprise a single slit aperture, which delimits the image field on the fan-shaped acquisition region, between the imaging optical unit and the detector. In one embodiment, in this case this is especially a slit aperture defining a field of view, in which the gap is sufficiently wide that an angle range of at least the width of the aperture angle of the emission light fan can be seen in the first fan direction, i.e., a type of field aperture or field-of-view aperture. In this case, the optical system can also comprise a preferably narrowband spectral filter, which is primarily transmissive to a specific wavelength of the light emitted by the target illuminator (for example, in the infrared range). In another embodiment, the slit aperture can also be designed in this case in such a way that a diffraction at the gap (or the gaps) of the slit aperture is utilized for the spectral separation of a specific wavelength of target illuminator light on the detector.</p><p id="p-0031" num="0030">For example, the optical unit can be formed and arranged in this case in such a way that focusing of an object space of the imaging optical unit takes place in (or at least essentially on a region around) a plane of the slit aperture, and the pixels are arranged defocused at a defined distance behind the plane of the slit aperture&#x2014;i.e., in the so-called back focus. In this case, in particular the defined distance can be selected in such a way that a circle of confusion of the defocusing essentially corresponds to a width of the pixels orthogonal to the pixel row arrangement (and/or the aperture slit direction or fan direction), or the defined distance can be selected in such a way that a circle of confusion due to the defocusing essentially corresponds to a height of one of the pixels in the pixel row arrangement (and/or the fan direction or aperture slit direction).</p><p id="p-0032" num="0031">The optical system can additionally or alternatively also be formed having an optical diffuser element between the imaging optical unit and the detector. Such a diffuser element can especially be in this case a diffusely light-transmissive optical component, for example, formed as a spreading disk or matte disk, as opal glass or milky transition glass, as a cylindrical microlens array, but also a structured spreading disk having light guide structure or a holographic spreading plate.</p><p id="p-0033" num="0032">In one embodiment, the formation and arrangement of the optical system and the detector can be carried out in such a way that the reflected component of the optical radiation from one point from the fan-shaped reception region is received by more than one of the pixels, in particular is always received by more than one of the pixels. The intentionally blurry imaging of the point on the detector thus causes expansion of the point on the detector, so that light from this point&#x2014;especially if the imaged point comes to rest in a region of the transition between two pixels on the detector&#x2014;is acquired by more than one of the pixels. In one embodiment, the design can especially be performed in such a way, for example, that light of the point which does not go beyond half of one pixel of the detector is also at least partially always received by an adjacent pixel. In this case, an individual or common optical diffuser can be provided in front of each of the pixels, which, even in the case of an only partially illuminated pixel, distributes the light essentially over the entire sensitivity surface of the pixel&#x2014;i.e., over the multiple photodiodes of the SPAD array of the pixel&#x2014;preferably at least approximately homogeneously.</p><p id="p-0034" num="0033">In other words, the position-resolving optoelectronic detector can comprise an optical, practically loss-free beam expander in this case, which is formed and arranged in such a way that the reflected electromagnetic radiation from an object space point illuminates a surface on the sensor element, in particular wherein the optical unit is formed having a beam expander in front of each of the pixels.</p><p id="p-0035" num="0034">Observed in the reverse direction, a region or sector of the acquisition region associated with one of the pixels (i.e., the region of the object space from which light emitted there is detectable by this pixel) can be formed at least partially overlapping with that of an adjacent pixel, preferably, for example, overlapping by approximately 5% to 50%.</p><p id="p-0036" num="0035">In one embodiment of the invention, in this case the analysis of the locating unit can be formed in such a way that a position in the first direction&#x2014;i.e., along the fan-shaped acquisition region&#x2014;is produced using an interpolated analysis, which is ascertained in dependence on a reception intensity, of the electrical output signals of multiple pixels. For example, using a reception intensity-barycenter formation (or centroid or center of gravity of the intensity) based on the output signals of a plurality of the pixels, or using averaging according to a mathematical function, for example, linear averaging, of an intermediate position between two pixels on the basis of a signal strength at the pixel outputs thereof. The locating unit is thus especially formed in this case so as to ascertain a position resolution in the first direction which exceeds the number of the pixels, so that more positions are resolved along the reception fans than pixels are provided. In this case, for example, a first reception intensity from a first pixel and a second reception intensity from a second pixel located adjacent can be ascertained. The ascertainment can preferably run in parallel for all of the pixels in this case, i.e., for example, having an individual electronic reception channel in each case for each of the pixels, which are analyzed in parallel and not sequentially. In this case, especially one item of information about the point in time of the incidence of a reception light pulse, and also one item of information about the intensity of the reception light pulse, can be ascertained per pixel. A distance of the reflector can be ascertained in this case on the basis of the point in time via a time-of-flight (TOF) analysis. With sufficiently different points in time for the adjacent first and second pixels, it can be assumed that they originate from different reflection sources staggered in the distance and are therefore not to be considered to be coherent. In the case of identical or at least essentially identical point in time at first and second pixels, it can be assumed that this involves the same reflection from the same reflector. A coherent observation can thus be performed, in which weighting is performed on the basis of the reception intensity at the first and second pixels, on the basis of which a location of the reflection, especially the center of the reflection, between the optical axes of the beam path of the first and second pixels is ascertained as the position of the reflection. This can also be performed similarly in the case of two adjacent pixels in the second direction (having an observation of the points in time in each case in relation to the emission of the associated emission fan pulse), whereby a location of the reflection in the second direction between the adjacent emission fans can also be ascertained. It is also possible to similarly expand over more than two illuminated pixels and/or emission fans arranged in succession.</p><p id="p-0037" num="0036">In one embodiment, the locating unit can also be formed in this case in such a way that the analysis in the second direction is performed with a barycenter formation or average value formation dependent on the reception intensity based on the output signals of the individual pixels with adjacent values of the second direction. A position resolution can thus be ascertained in the second direction which exceeds the number of the acquired second directions, so that more positions are resolved along the second direction along the movement of the reception fan than reception fan pulses were emitted&#x2014;i.e., for example, also a second direction associated with the reflection, which is located between the second directions in which the light fan pulses were emitted or from which they were received, respectively. To also still be able to reliably locate small reflector marks at long distances, the object space has to be scanned as continuously as possible. In one embodiment for covering such cases, the light fans are to have a certain minimum width (or a minimum aperture angle) in the second direction in this case, or alternatively in the case of narrow light fans, a sufficiently tight scanning density of the object space is required, wherein the scanning density is primarily determined by the pulse rate of the emission fan and the speed of the movement in the first direction, and/or the pulse rate has to be selected to be correspondingly high to achieve a desired scanning speed. For example, typical surveying reflectors appear very small in the angle at long distances from the instrument, for example, in the order of magnitude of approximately 0.0035&#xb0;. So as not to miss such small targets, the emission unit has to acquire the object space in the second direction preferably continuously or at least with a resolution in the above-mentioned magnitude. The emission fans are therefore accordingly emitted at emission rates of several kilohertz, for example, 50 kHz or greater.</p><p id="p-0038" num="0037">In one embodiment of the invention, the locating unit can be formed having a distance measuring unit which ascertains at least one distance measured value for each of the pixels and/or for each reflection, in particular using a runtime measurement or phase measurement of pulses of the emitted optical radiation of the emission fan. Both runtime measurement and also phase measurement can be measured, for example, by means of the waveform digitization technology known to a person skilled in the art. In this case, a distance can be ascertained in particular for a reflection of the optical radiation and can be provided as part of the position. In addition, the reflectance can be derived from the measured signal amplitude and distance as a characteristic parameter of the reflecting target object. In any case, a depth in the distance direction can also be ascertained in this case on the basis of a chronological duration of a reflection and/or pulse expansion of the received reflection. In this regard, the SPADs used in the pixels according to the invention can provide advantages with the reception characteristics thereof, especially with regard to the time, sensitivity, and overload behavior thereof. In the case of SPAD arrays, for example, the high electrical signal bandwidth thereof of 1 to 2 GHz is particularly advantageous, using which a time resolution in the picosecond range is achievable, and also the robustness thereof against overload, for example, in sunlight.</p><p id="p-0039" num="0038">In one embodiment, the locating unit can be designed in such a way that an extension in the first direction is ascertained as a height and/or an extension in the second direction is ascertained as a width of a respective spatially coherent reflection, which is provided as an item of information about a dimension or spatial extension of the reflector and/or the potential target mark as additional information for the position. In this case, for example, the position can be provided as the barycenter, centroid or center point of the reflection (especially the received light intensity barycenter or the center point of the area of the reflection resulting with height and width) and its height and width. The area of the reflection can also be ascertained in this case having an inclination in relation to the first and second direction, for example, having a height and/or width and also an associated inclination in relation to the first or second direction&#x2014;for example, of an oblong reflector strip, which is inclined in relation to the first direction, on a warning vest, etc. Optionally or alternatively, multiple positions&#x2014;for example, corner points or a contour&#x2014;can also be ascertained for a coherent reflection, at which the intensity of the reflection exceeds a threshold value, wherein the threshold value can be fixed or dynamically tracked. In this case, the described analysis of the position(s) having a resolution between the pixels is especially also applied.</p><p id="p-0040" num="0039">According to the invention, the analysis unit can be designed in such a way that the first position in the first direction, the second position in the second direction, the height in the first direction, the width in the second direction, the distance on the basis of an item of signal runtime information, and an intensity of the reflection are ascertained as a spatial intensity profile of the reflection, and/or are therefore accordingly provided and/or analyzed. The reflection can thus be characterized according to the invention, for example, in its spatial direction, distance, extension, and intensity, whereby a more detailed analysis and/or classification and/or identification of the reflection, and also possibly with respect to its source, i.e., the nature of the reflector, can also be ascertained and provided.</p><p id="p-0041" num="0040">The analysis unit can determine, for example, a spatial <b>6</b>D profile of the reflection having first position, second position, distance, height, width, and intensity of acquired reflections, and can ascertain an automatic target mark recognition and/or target mark identification by way of the correspondingly configured analysis unit on the basis of this profile for each received reflection. In one embodiment, the analysis unit can thus be formed, for example, in such a way that a uniqueness solution of retro targets such as prisms and reflector tapes, cat's eyes, . . . is ascertained using an analysis of the distance and intensity values, for example, on the basis of a comparison to known or stored data and characteristic values of reflection sources, on the basis of artificial intelligence systems or neuronal networks trained accordingly by machine learning, etc. During the analysis, a distance and/or depth staggering of reflections can also be taken into consideration in this case to differentiate reflection sources.</p><p id="p-0042" num="0041">The first aspect of some aspects of the present invention also relate to a geodetic surveying device having a device for automatic target acquisition and/or target search such as the one described here, especially, for example, a geodetic surveying device in the form of a total station. However, a surveying device in the form of a theodolite, a tachymeter, a laser scanner, a rotation laser, or a laser tracker can also represent an embodiment of the invention. In this case, the device, in particular jointly with a telescope or a targeting device or also a base body of the surveying device, can be arranged to be rotatable, for example, around a&#x2014;preferably at least essentially vertical&#x2014;standing axis of the geodetic surveying device as the second direction. In particular, the target reflector search device can be housed, for example, in the support of the geodetic surveying device, thus especially rotatable around the standing axis but stationary in the tilt axis.</p><p id="p-0043" num="0042">Some aspects of the invention also relate to a corresponding method for automatically locating a position of a reflective target mark, especially as described above and in particular using a device described here or a geodetic surveying device. In this case, at least emitting of optical radiation in the form of an emission fan, moving of the emission fan over a spatial region, and receiving of a reflection of a component of the optical radiation of the emission fan within a fan-shaped reception region take place. Using an analysis of a fan-shaped reception region using an optical detector, a determination of the position of the reflection on the basis of the analysis and an associated location of the movement then take place.</p><p id="p-0044" num="0043">According to some aspects of the invention, in this case the optical detector is analyzed as a position-resolving optical detector having a linear arrangement of a plurality of pixels, which pixels are each formed as SPAD arrays, and the receiving is performed using an optical system having an imaging and direction-resolving optical unit. In this case, the optical system is formed and arranged in such a way that a blurry image or projection, which is expanded in relation to a focused image, of the reflection is performed on the acquisition region on the position-resolving optical detector. Using such an embodiment, on the basis of an analysis of a reception intensity over more than one pixel of the detector, a position resolution of the position of the reflection can be ascertained which is greater than the physical position resolution on the basis of the number of the pixels of the detector.</p><p id="p-0045" num="0044">In this case, the determination of the position can especially be performed using an ascertainment of an intensity barycenter of the reflection on the position-resolving optical detector over a plurality of the pixels having a position resolution which is higher than the interval between two pixels. The determination of the position can additionally or alternatively also be performed using an ascertainment of an intensity barycenter of the reflection over multiple adjacent emission fans having a position resolution which is higher than the angle interval between two emission fans. In other words, a special aspect of many of the embodiments of the invention set forth here can also be considered that in one embodiment, the target search can be carried out faster in the spatial region in this case, in particular using a smaller number of emissions of emission fans and analyses of pixels. During the analysis, in this case, an ascertainment of a distance to a reflection can also be performed on the basis of a signal runtime of an optical pulse of the emission fan. An ascertainment of an extension of a reflection in the spatial region can also be ascertained during the analysis of the detector, in particular over multiple adjacent emission fans.</p><p id="p-0046" num="0045">In this case, an analysis of a spatial intensity profile of reflections can also be performed, in particular in a position of an intensity barycenter of the reflection, in an extension of the reflection, and in a distance of the reflection. An automatic recognition and/or classification of the reflection can be performed in this case on the basis of the spatial intensity profile, especially a differentiation of spatial intensity profiles of a surveying reflector from spatial intensity profiles of possible interfering reflections.</p><p id="p-0047" num="0046">The invention can be at least partially executed in this case by an electronic control unit which is at least partially programmable, for example, having a digital computer or comparable components. The first aspect of the present invention therefore also relates to an embodiment in the form of a computer program product having program code, which is stored on a physical data carrier or provided as an electromagnetic wave (for example, as a data signal transmitted by means of radio), and is designed for execution on a digital computer. According to the invention, such program code can especially comprise a sequence of instructions in this case, which are designed to carry out a parallel analysis of multiple pixels of a linear position-resolving detector, in particular with respect to a reception point in time and a reception intensity of at least one optical pulse, for multiple adjacent light fans covering a spatial region to be searched. In this case, the program code can analyze a spatial intensity profile for a reflection over a plurality of pixels and/or light fans, especially using a position of an intensity barycenter of the reflection in the spatial region, an extension of the reflection in the spatial region, a distance of the reflection in the spatial region, and/or an intensity of the reflection. In this case, the program code, in particular using a comparison of known reference profiles and/or a machine learning or artificial intelligence approach from a corresponding available software framework, can carry out a recognition and/or classification of the reflection, especially a recognition and differentiation of a reflection of a measurement reflector from a possible interfering reflection.</p><p id="p-0048" num="0047">The second aspect of the invention relates to a method and a device for automatic image-based location of a target marker and is described below.</p><p id="p-0049" num="0048">Methods for automatically locating or identifying target markers by means of an optoelectronic device or automatic target marker locator, e.g. in the context of a coordinative industrial or geodetic survey, are known in principle from the prior art, e.g. from WO 2011/098131 or EP 0815468. Examples of coordinative surveying devices are tachymeters or laser trackers, with which points in the space that are marked with the target marker, e.g. as part of a plumb rod, are measured with high accuracy. A target marker can have a retro-reflective unit (e.g. cubic prism), which is sighted with an optical measuring beam of the measuring device, in particular a laser beam. The laser beam is reflected back over a parallel path to the surveying device, by which the reflected beam is detected. In this case an emission or reception direction of the beam is determined, for example using sensors for angle measurement, which are assigned to a deflection mirror or a sighting unit of the system. In addition, with the detection of the beam a distance from the measuring device to the target point is determined, e.g. using time-of-flight or phase difference measurement, so that from the direction and distance the coordinates of the point are measured.</p><p id="p-0050" num="0049">Surveying devices according to the prior art can be additionally implemented with an optical image acquisition unit in the form of an overview camera with a two-dimensional, light-sensitive array, such as a CCD or CID camera or a CMOS-array based camera, or a camera equipped with a pixel array sensor and an image processing unit, such as described in WO 2005/059473. The measuring device and the camera can be mounted one on the other, in particular, such that their positions relative to each other cannot be changed. For example, the camera is rotatable together with a laser tracker about its essentially vertical axis, but also pivotable up and down independently of the laser tracker, and therefore arranged, in particular, separately from the optics of the laser beam. Further, the camera&#x2014;depending on the particular application, for example&#x2014;can be designed to be pivotable about only one axis. In alternative designs the camera is installed in a common housing with the laser optics in an integrated design.</p><p id="p-0051" num="0050">In addition, in modern surveying devices, on a spatially resolving sensor of a separate ATR camera, a deviation of the received measuring beam from a zero position is determined. The output signal of the sensor is generated by means of one or more photosensitive surfaces (PSD) and depends on the respective position of the light focus. By means of a downstream or integrated electronics, the output signal can be evaluated and the focal point can be determined. The process of determining the position of the focal point of the impinging light spot can be performed very rapidly and with a very high resolution. However, using the PSD only allows one focal point of the light distribution to be determined, rather than a distribution of multiple light spots. This measurable deviation allows a difference in position between the center of a retro-reflector and the point of incidence of the laser beam on the reflector to be determined, and the alignment of the laser beam to be corrected or tracked in accordance with this deviation, in such a way that the deviation on the sensor is reduced, in particular to &#x201c;zero&#x201d;, and so that the beam is aligned in the direction of the reflector center and thus highly accurately onto the target marker. Tracking the laser beam alignment allows continuous target tracking of the target marker and continuous determination of the distance and position of the target point relative to the measuring device. The tracking can be implemented by changing the alignment of the motorized movable deflection mirror provided for deflecting the laser beam and/or by pivoting the targeting unit, which has the beam-guiding laser optics.</p><p id="p-0052" num="0051">The target tracking described must be preceded by location of the target marker, so that the laser beam can be connected to the reflector. For this purpose, a detection unit with another position-sensitive sensor (PSD) with a relatively large field of view can be additionally arranged on the surveying device. In addition, additional lighting devices are integrated in generic coordinate measuring devices, with which the target or reflector is illuminated, in particular with a defined wavelength which differs from the wavelength of the distance measuring devices. The lighting devices can be used to illuminate the target and the detection unit can be used to capture an image of the target with an illuminated reflector. By imaging the specific (wavelength-specific) reflection on the sensor, the reflection position in the image can be resolved and thus an angle relative to the direction of acquisition of the camera and a direction to the target or reflector can be determined. A design of a laser tracker with such a target seeking unit is known from WO 2010/148525, for example.</p><p id="p-0053" num="0052">A major disadvantage of conventional target location methods and target markers is, in particular, their insufficient robustness against incorrect identification of the target marker, for example in the case of multiple target markers located in the field of view, or of reflective or self-illuminating interfering objects which are incorrectly identified as target markers. In addition, in some known systems from the prior art, the complicated transmission of the target marker identities from the respective target marker to the surveying device has proved to be a disadvantage. In systems of the prior art which provide target location, therefore, there is a relatively high level of uncertainty as to the correct assignment of an object recognized as a target marker.</p><p id="p-0054" num="0053">US 2017/0122734 discloses a method of locating or identifying target markers, in which a light pattern of optical radiation emitted by the target is detected in an image. To this end, disadvantageously the field of view of the light-sensing image sensor of the surveying device must be moved relative to the target marker (so that the image background is blurred and thus becomes distinguishable from the light pattern), and the exposure time of the one image must be matched to the light pattern. In addition, with the method presented there, locating a target which is moving relative to the surveying device, and thus the image sensor, is difficult if not impossible.</p><p id="p-0055" num="0054">An object of some aspects of the second aspect of the present invention therefore is to provide an improved method for automatically locating target markers.</p><p id="p-0056" num="0055">In particular, a more robust and/or faster detection of target markers, especially of a plurality of target markers in the measurement environment, can be sought.</p><p id="p-0057" num="0056">This object is achieved by the implementation of the characterizing features of the independent claims. Features that extend the invention in alternative or advantageous ways are contained in the dependent claims and the description, including the description of the figures. All embodiments of the invention presented or otherwise disclosed in this document can be combined, unless expressly stated otherwise.</p><p id="p-0058" num="0057">Some aspects of the invention relate to a method for automatically locating at least one target marker. In the context of the method, radiation is emitted from the target marker, wherein by means of modulation, in particular phase modulation, the radiation recurrently has a characteristic signature.</p><p id="p-0059" num="0058">In addition, a first image sequence is recorded with a first frame rate in order to detect target marker radiation, e.g. by means of a target-finding camera of a surveying device, which forms a surveying system with the target marker.</p><p id="p-0060" num="0059">Further steps involve carrying out a statistical evaluation of the first image sequence by reference to the signature and calculating a quality function, wherein the value of the quality function indicates a probability that target-marker radiation is detected in a given pixel, and identifying pixels with which target-marker radiation is likely detected, based on the value (associated with the pixel) of the quality function. A quality function related to the known signature is thus used to determine pixels in a first series of images, which have a specific probability of having registered target-marker radiation.</p><p id="p-0061" num="0060">Furthermore, the method involves recording a second image sequence with a second frame rate which is different, and preferably (very much) higher, than the first frame rate, and evaluating intensity signals of the second image sequence for said identified pixels. These intensity signals are used to identify target marker radiation based on the signature. In other words, a further series of images is also recorded with a different frame rate and from this, a correspondence with the stored signature is tested for the pixels previously identified using the quality function, which are suitable for closer examination or further examination, based on the intensity.</p><p id="p-0062" num="0061">This two-stage method allows, among other things, a comparatively low threshold to be set in the first test stage (i.e. based on the first image sequence), thus ensuring that in any event all target-marker radiation is classified positively and no target marker is &#x201c;overlooked&#x201d; or incorrectly &#x201c;rejected&#x201d;. For example, pixels deemed to be identified are already those in which the value of the quality function (or a probability determined from it) indicates a minimum probability of only 50% for target-marker radiation detection (in other words, an uncertainty of 50% is accepted). Due to the second, more detailed test stage, it can be accepted that even non-target-marker radiation is (provisionally) classified as target-marker radiation, since this is then correctly rejected using the second image sequence and ultimately, only genuine target-marker radiation is identified as such.</p><p id="p-0063" num="0062">The design of such a quality function, which allows signal changes caused by target-marker radiation to be distinguished from those from other light sources, depends in particular on the combination of image acquisition rate during this first image sequence and the modulation frequencies of the target-marker radiation. For example, the target-marker radiation can be selected such that a characteristic digital modulation pattern is repeated with the image acquisition rate during this first image sequence, but the pattern is alternately transmitted in inverted form. In the recorded image sequence, pixels that belong to target markers have alternately a high signal and a low signal in the following image. Pixels that do not belong to target markers have only a far lower probability of showing such a signature. In this case, the quality function can be a statistical function that compares the signal characteristic of a pixel within the acquired image sequence with the ideal theoretical signal characteristic, which corresponds to the acquisition of the characteristic target-marker radiation with the image acquisition rate used.</p><p id="p-0064" num="0063">Optionally, the second image sequence is recorded with a second field of view, which is smaller than a first field of view of the recording of the first image sequence, wherein a position of the at least one second field of view corresponds to the respective said pixel, in particular wherein the at least one second field of view corresponds to a region of pixels, for example, of approximately 20&#xd7;20 pixels, around a given identified pixel.</p><p id="p-0065" num="0064">The two evaluation stages can thus firstly cover a large area of the environment for the target location with the first field of view, and secondly the use of the smaller second field of view (limitation of the number of active pixels of the image sensor) allows the second recording to be performed at a very high frame rate without the need to place particularly high demands on the image recording device (image processing capacities). For example, both image sequences can thus be recorded with a conventional digital camera, which can produce small image segments at rates in the kilohertz range, but can only record full images at a much lower rate.</p><p id="p-0066" num="0065">The evaluation of the first and/or second image sequence is preferably carried out by means of difference images. This means that images from a particular image series are compared with each other and thereby, so to speak, the temporal profile of the values of a particular pixel is determined. By forming differences between the respective values of directly temporally adjacent images pixel-by-pixel, a value profile based on difference images is created for each pixel, which highlights pixels with values that vary during the image sequence duration more strongly than those which are temporally static. This evaluation with regard to the signature based on difference images is thus advantageous for the detection of modulated target-marker radiation.</p><p id="p-0067" num="0066">Optionally, in the frequency domain the signature has a first spectral component adjusted to the first frame rate, and a second component adjusted to the second frame rate. Alternatively or additionally, in the time domain the signature has a start and/or end indicator (i.e. a signature component used for signaling the start and/or end of the signature).</p><p id="p-0068" num="0067">Another option is to record the first and/or second image sequence over a period in which the emission of the signature is repeated multiple times. This means that images of a particular series of images are recorded over at least a period of time which corresponds to a multiple of the sequence of the signature (including any pauses set between two repetitions).</p><p id="p-0069" num="0068">As a further option, the radiation has a wavelength in the near-infrared IR-A range, e.g. the radiation wavelength is 850 nm. As an alternative or in addition, the target-marker radiation is used for data transmission, so that a small number of user data items can be transmitted from the target marker to another device, for example.</p><p id="p-0070" num="0069">Optionally, the second frame rate is at least ten times as high as the first frame rate, wherein the first frame rate, for example, is in the range between 45 Hz and 65 Hz and/or the second frame rate is at least 1 kHz, in particular at least 2 kHz.</p><p id="p-0071" num="0070">Another preferred option is to record the first and second image sequences without synchronization to the emission of the target-marker radiation. The recording of a particular image sequence can thus optionally be started at any time, for example, without having to take into account the start of the emission of the target-marker radiation (and vice versa), wherein optionally the emission is started by an external communication signal, e.g. optically or via radio frequency. Alternatively, in addition to the modulated target-marker radiation, the target marker can also transmit synchronization signals on a further communication channel separate from or independent of the target-marker radiation, for example at a defined radio frequency. This allows the camera to acquire target-marker radiation synchronously by means of this additional signal transmission.</p><p id="p-0072" num="0071">In a further extension of the method, a direction (e.g. in the form of polar and azimuth angles) to the target marker is determined by means of the first and/or second sequence of images based on respective identified pixels, wherein in addition a deviation of the direction from a nominal direction (e.g. zero or central direction) is optionally determined.</p><p id="p-0073" num="0072">In a further extension of the method, as part of the method the identified pixels for which target-marker radiation is identified are used to automatically track the target marker based on the identified target marker radiation.</p><p id="p-0074" num="0073">Some aspects of the invention also relate to a target marker locator, having an evaluation electronics and a spatially-resolving optoelectronic sensor, e.g. integrated in a digital camera, designed as a CCD or CMOS sensor, as a two-dimensional photodetector array or as a dynamic vision sensor, for example, for detecting target-marker radiation having a known characteristic signature.</p><p id="p-0075" num="0074">The target marker locator is designed to use the sensor to record a first image sequence with a first frame rate and to statistically evaluate the first image sequence by means of the evaluation electronics. As part of the statistical evaluation, a quality function is determined, the value of which indicates a probability that target-marker radiation is detected in a given pixel, for which purpose the signature is stored in the evaluation electronics, and based on the quality function to identify pixels with which target-marker radiation is likely detected.</p><p id="p-0076" num="0075">Furthermore, the target marker locator is designed to use the sensor to record a second image sequence with a second frame rate, which is different, in particular higher, than the first frame rate, and using the evaluation electronics to evaluate intensity signals from the second image sequence for said identified pixels and to identify target-marker radiation using the intensity signals and based on the stored signature.</p><p id="p-0077" num="0076">The target locator, which can be designed as a separate unit or integrated into a surveying device, e.g. a tachymeter or a laser tracker, optionally has a long-pass filter that can be switched off and/or a near-infrared corrected lens. As an additional option, the sensor is part of an overview camera of such a surveying device.</p><p id="p-0078" num="0077">Optionally, the evaluation electronics is designed to determine a direction to the target marker on the basis of a position of an identified pixel on the sensor. Preferably, the evaluation module is designed to control an alignment of the target marker locator, in particular continuously, based on a deviation from a pixel zero position, so that the deviation is reduced, in particular, to zero.</p><p id="p-0079" num="0078">Some aspects of the invention further relate to a target marker having a modulatable, in particular near-infrared, beam source designed for emitting target marker radiation, wherein by means of modulation, in particular phase modulation, the target-marker radiation recurrently has a characteristic, in particular multi-level, signature.</p><p id="p-0080" num="0079">In addition, some aspects of the invention relates to a surveying system with a target marker locator according to the invention and a target marker according to the invention.</p><p id="p-0081" num="0080">The invention can be implemented at least in part by an electronic control and evaluation unit, which is at least partially programmable, for example with a digital computer or comparable components. Therefore, the second aspect of the second aspect of the present invention also relates to an embodiment in the form of a computer program product with program code, which is stored on a physical data medium or provided as an electromagnetic wave (e.g. as a data signal transmitted by radio) and is designed for execution on a digital computer.</p><p id="p-0082" num="0081">Some aspects of the invention therefore offer the advantage of a robust, reliable automatic target marker location, wherein different target markers are uniquely identified. By means of the at least two different evaluation stages (i.e., for example, a first coarse selection step and a second fine selection step), on the one hand all target markers in the environment are reliably detected, and on the other hand, incorrect identifications are avoided. The use of different frame rates allows a quasi-synchronous sampling to be provided without having to perform true synchronization, in particular in embodiments with a multi-level signature, which therefore has a code component that is tailored to the first frame rate, and another code component that is tailored to the second frame rate. Alternatively, in the case of embodiments with an independent additional synchronization channel, as described above, by means of the same, images can also be acquired with true synchronization.</p><p id="p-0083" num="0082">Another advantage of the robust camera-based detection of self-illuminating target markers by analysis of their transmitted signals at different camera frame rates is that a large field of view can be provided (e.g. with the first series of images), so that a large area of the environment is covered and a rapid identification of a target marker is also possible. For example, it can also be used to locate targets during continuous motion of the target locator. For example, the method can be implemented with a conventional overview camera, e.g. of a surveying device.</p><p id="p-0084" num="0083">If the second field of view is selectively limited to pixels or regions of interest identified in the first method section, the image data volume and thus the processing effort are advantageously kept to a minimum. In addition, the use of difference images enables a further acceleration of the processing and a significant reduction of the memory requirements compared to the use of directly recorded images.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF SUMMARY OF THE DRAWINGS</heading><p id="p-0085" num="0084">The method according to the invention and the device according to some aspects of the invention are described solely by way of example in greater detail hereafter on the basis of specific exemplary embodiments schematically illustrated in the drawings, wherein further advantages of the invention are also discussed. In the specific figures:</p><p id="p-0086" num="0085"><figref idref="DRAWINGS">FIG. <b>1</b></figref> shows a schematic illustration of a first exemplary embodiment of the first aspect of the first aspect of the present invention in a geodetic surveying device;</p><p id="p-0087" num="0086"><figref idref="DRAWINGS">FIG. <b>2</b></figref> shows a second exemplary embodiment of the first aspect of the present invention in a geodetic surveying device;</p><p id="p-0088" num="0087"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows a first schematic illustration of an exemplary structure of an embodiment of the invention;</p><p id="p-0089" num="0088"><figref idref="DRAWINGS">FIG. <b>4</b></figref> shows a second schematic illustration of an exemplary structure of an embodiment of the invention;</p><p id="p-0090" num="0089"><figref idref="DRAWINGS">FIG. <b>5</b></figref> shows a third schematic illustration of an exemplary structure of an embodiment of the invention;</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows a fourth schematic illustration of an exemplary structure of an embodiment of the invention;</p><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an illustration of an example of an acquisition of a target mark search in one embodiment of the invention;</p><p id="p-0093" num="0092"><figref idref="DRAWINGS">FIG. <b>8</b><i>a </i></figref>and <figref idref="DRAWINGS">FIG. <b>8</b><i>b </i></figref>each show an illustration of an example of an embodiment of an acquisition according to the invention during a target mark search;</p><p id="p-0094" num="0093"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows embodiments of a method according to the invention in the form of a block diagram;</p><p id="p-0095" num="0094"><figref idref="DRAWINGS">FIG. <b>10</b></figref> shows a schematic representation of an embodiment of the second aspect of the present invention with a geodetic surveying device with automatic target marker locator for identifying a target marker;</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows an example of a sequence of a target location method according to the invention;</p><p id="p-0097" num="0096"><figref idref="DRAWINGS">FIGS. <b>12</b><i>a</i>, <b>12</b><i>b </i>and <b>12</b><i>c </i></figref>show a further exemplary representation of a target location method according to the invention; and</p><p id="p-0098" num="0097"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows a further extension of the target location method according to the invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0099" num="0098">The illustrations in the figures are used solely for illustration and, if not explicitly indicated otherwise, are not to be considered to be exactly to scale. Identical or functionally similar features are provided, if practical, with the same reference signs throughout and are differentiated if necessary with a letter as an index. The illustrated schemes each show the basic technical structure, which can be supplemented or modified by a person skilled in the art in accordance with general principles. The terms essentially, substantially, or at least approximately express in this case that a feature is preferably formed, but does not necessarily have to be 100% exactly or exactly as literally described, but rather that minor deviations are also permissible&#x2014;not only with respect to unavoidable practical inaccuracies and tolerances, but rather especially, for example, insofar as the technical effect essential for the invention is substantially maintained in this case.</p><p id="p-0100" num="0099"><figref idref="DRAWINGS">FIG. <b>1</b></figref> schematically shows one possible example of an application using an embodiment of an automatic target search device <b>14</b><i>s </i>according to the invention in a geodetic surveying device <b>14</b>. In this case, one or more surveying reflectors&#x2014;in the example shown, for example, a reflector <b>10</b> as a measurement point in the surroundings of the device <b>14</b>&#x2014;are to be found and surveyed automatically using the positioned device <b>14</b>. The reflector <b>10</b> can be formed as a surveying reflector&#x2014;for example, as a triple prism on a surveyor's rod or pole (also having an operating unit <b>18</b> connected via a radio signal <b>16</b> here)&#x2014;which is moved by a user <b>17</b> to different measuring positions. In this case, the device according to the invention in or on the surveying device <b>14</b> scans its surroundings for light reflections <b>9</b> to locate the reflector <b>10</b>. The reflector <b>10</b> can therefore be targeted using the target axis <b>15</b> of the surveying device <b>14</b> to exactly survey the reflector <b>10</b> using a laser distance meter in the direction of the target axis <b>15</b>. In this case, the locating of the reflector <b>10</b> to be surveyed is preferably to take place as rapidly and reliably as possible. During the searching (also referred to as scanning) of the surroundings, however, in general not only the reflection <b>9</b> from the desired surveyor's rod <b>19</b> is acquired, but rather also other reflections <b>9</b> from reflective objects possibly located in the surroundings, such as further reflectors in use, buildings <b>12</b>, vehicles <b>60</b>, headlights, cat's eyes, boundary posts, traffic signs, safety vests of workers, machines, etc.</p><p id="p-0101" num="0100">The scanning or searching for reflections <b>9</b> is performed in this case using a modulated, preferably pulsed emission of a fan <b>13</b> of optical radiation in the visible or invisible spectral range and an acquisition and analysis of reflections <b>9</b> of a part of this optical radiation from the location of the reflector <b>9</b>. For example, a light fan <b>13</b> in the form of a straight laser line having an aperture angle, for example, of approximately +/&#x2212;20&#xb0; is emitted by the surveying device <b>14</b>, and this light fan <b>13</b> is rotated over the spatial region <b>22</b> to be searched. The emission fan <b>13</b> is in this case preferably an essentially continuous and essentially homogeneous light fan <b>13</b>, for example, by a light beam being emitted as a fan preferably spanning a plane, which spans a straight line in the viewing direction on the object.</p><p id="p-0102" num="0101">In one embodiment, the light fan <b>13</b> can be, for example, aligned essentially vertically and can be rotated or pivoted, preferably by up to 360&#xb0;, for example, jointly with a targeting or telescope unit of the surveying device <b>14</b> essentially horizontally around the standing axis of the device <b>14</b> by a motorized drive unit over a spatial region <b>22</b> to be searched. The invention can, however, also be designed in other embodiments having other alignments of the light fan <b>13</b> and/or pivot planes of the movement of the light fan <b>13</b>, also by less than 360&#xb0;. Using a preferably pulsed emission of the light fan <b>13</b>, higher optical peak powers can be emitted in this case while maintaining ocular safety, whereby stronger reflections <b>9</b> are also obtained and an improvement of the SNR is achievable. In this case, a bundle of multiple emission fans <b>13</b> or a family of fan bundles more or less results, which cover the spatial region <b>22</b> to be searched. In particular in consideration of an emission of the emission fan <b>13</b> in the form of chronological light pulses having pulse widths of a few nanoseconds, the spatial region <b>22</b> is thus scanned using a bundle of discrete fans. With correspondingly faster scanning and/or with a corresponding ratio of the scanning to the movement, however, in this case a quasi-continuous scanning of the spatial region <b>22</b> to be searched can also be performed. According to the invention, in the emission of the emission fan <b>13</b>, not only simple single pulse sequences, but rather also more complex types of modulation, for example, coded pulse sequences, pulse amplitude modulation, phase modulation, etc. are applicable. As already mentioned above with respect to the coverage of the search space <b>22</b>, in this case the rate of the distance measurements is preferably to be at least 50 kHz or more, for example, also 500 kHz or even more to achieve both an acceptable rotational velocity of the movement of the emission fan <b>13</b> and also a sufficient coverage of the search space <b>22</b>.</p><p id="p-0103" num="0102">Jointly with the emission fan <b>13</b>, in this case a fan-shaped reception region <b>20</b> of the device according to the invention is also moved along, which preferably essentially corresponds in size and spatial location approximately to the emission fan <b>13</b> or comprises it. In one embodiment, reception region <b>20</b> of the reception fan can be formed approximately 3 to 10 times wider than the width of the emission fan <b>13</b> transversely to the fan direction, for example. In this case, according to the invention the reception region <b>20</b> is formed having a position-resolving optoelectronic sensor element or detector <b>11</b>, so that a first location of the reflection <b>9</b> can be acquired or analyzed along the reception region fan <b>20</b>&#x2014;i.e., in the vertical direction in the above example.</p><p id="p-0104" num="0103">The fan-shaped reception region or reception fan <b>20</b> is preferably designed in this case in such a way that it essentially covers the same angle range as the emission fan <b>13</b>, in particular for greater distances of several meters, which are typical in matters of surveying, or several dozen or even hundreds of meters and more, in particular in road construction.</p><p id="p-0105" num="0104">Using the position resolution according to the invention of the optical receiver or detector, in this case the reception fan <b>20</b> is divided during the analysis into multiple fan segments <b>20</b><i>a</i>, <b>20</b><i>b</i>, <b>20</b><i>c </i>etc. In other words, the position resolution is achieved using segmenting of the reception fan <b>20</b> along its alignment into multiple regions or segments <b>20</b><i>a</i>, <b>20</b><i>b</i>, <b>20</b><i>c</i>, . . . , by a position-resolving electro-optical detector <b>11</b> being formed having a linear arrangement of a plurality of pixels <b>1</b>, in particular more than two pixels. The number of the pixels <b>1</b> in the present invention in this case is also especially less than 100, in particular less than 64 or 32 pixels, however. For example, an embodiment of a detector <b>11</b> according to the invention can comprise, approximately, 5 to 16 pixels. These pixels are juxtaposed along a preferably straight line in the fan direction, wherein a distance between the sensitivity surfaces of the pixels should as much as possible be kept at zero or at least relatively small in relation to the size of the sensitivity surface of the pixel, preferably not greater than approximately 10%.</p><p id="p-0106" num="0105">According to the invention, in this case the arrangement of an optical system of the receiving unit and the position-resolving electro-optical detector <b>11</b> is formed in such a way that the regions or fan segments <b>20</b><i>a</i>, <b>20</b><i>b</i>, . . . , which are each acquired by one pixel, overlap. These segments <b>20</b><i>a</i>, <b>20</b><i>b</i>, . . . are at least essentially equally large in this case. In other words&#x2014;as also symbolically shown in the beam path&#x2014;the projections of the sensitivity surfaces of the pixels overlap in the object plane in this case.</p><p id="p-0107" num="0106">The pixels according to the invention are formed in this case in such a way that each of the pixels is formed as an SPAD array. Such an SPAD array comprises in this case a plurality of single photon avalanche photodiodes (SPADs) operated in the Geiger mode, which are interconnected to form a common output signal for the pixel, in particular using a parallel circuit of SPADs each provided with a series resistor&#x2014;which form the SPAD array. In other words, the pixels according to the invention thus each only have a single output signal per pixel but are internally constructed having multiple photodiodes per pixel. Instead of a juxtaposition of multiple individual pixels, a single, specially designed producer-specific SPM diode pixel array can also be applied, for example, in the form of an Original Equipment Manufacturer (OEM) product.</p><p id="p-0108" num="0107">According to the invention, in this case the electrical and digital signal analysis of the position resolution are performed not only solely using an analysis of a single pixel as such, i.e., using a simple association of a reflection <b>9</b> with a single one of the pixels, but rather the position resolution in the fan direction is greater according to the invention than the physical resolution of the detector <b>11</b> on the basis of the number of the existing pixels <b>1</b>. Using the overlap according to the invention of the sectors or regions <b>20</b><i>a</i>, <b>20</b><i>b</i>, . . . , a reflection <b>9</b> from a reflector <b>10</b> within the acquisition region is at least partially received by a plurality of pixels, wherein an intermediate position dependent on the reception intensity between the pixels is ascertained, especially by a relative ratio of the reception intensity from the pixels to an intermediate position being analyzed, or a location of a barycenter or a maximum value of the reflection <b>9</b> being physically formed and analyzed accordingly as an intermediate position.</p><p id="p-0109" num="0108">In one embodiment according to the invention, in this case the analysis of the output signals of the pixels can take place in parallel, i.e., over multiple acquisition channels, especially each having one channel per pixel. In particular, in this case each of the pixels can be analyzed using a separate A/D converter channel, wherein the cycling of the A/D converter channels is preferably synchronized.</p><p id="p-0110" num="0109">A first location <b>41</b>, as a first coordinate of the first direction from which the reflection <b>9</b> was received, is determinable&#x2014;at least roughly&#x2014;as described above using the analysis of the position-resolving detector. A second location <b>42</b> of the object <b>10</b> causing or triggering the reflection <b>9</b> as a second coordinate in the direction from which the reflection was received results from the location of the movement of the emission fan <b>13</b> in the spatial region <b>22</b> at the appointed time of the respective light fan pulse <b>13</b><i>a</i>, <b>13</b><i>b</i>, <b>13</b><i>c</i>, . . . , as illustrated by way of example in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. In this case, for example, an angle encoder in the device <b>14</b> can acquire the alignment of the movement of the emission fan <b>13</b>, especially at the point in time of the emission of the emission fan <b>13</b>, at the point in time of the reception of the reflection <b>9</b>, or at the point in time of the reflection (i.e., approximately half of the time between emission and reception). In the example shown, the drive and angle encoder <b>14</b><i>h </i>of the surveying device <b>14</b>, which are formed to rotate the device <b>14</b> in relation to its deployment <b>14</b><i>u </i>around the standing axis H (or alternatively possibly also around the tilt axis V) can be used for the movement and determination of the second location. The target acquisition device <b>14</b><i>s </i>according to the invention can be formed in this case, for example, in the support <b>14</b><i>b </i>of the surveying device <b>14</b>, which is only movable in a single axis, or also in the telescope body <b>14</b><i>t</i>, which is also movable in two axes with the target axis <b>15</b>.</p><p id="p-0111" num="0110">Using the detector according to the invention having SPAD array, in some embodiments it is also possible to dispense with varying the emission power of the pulses of the emission fan <b>13</b>, as often has to be applied in the prior art, for example, in the form of an emission of a double pulse&#x2014;for example, in the form of an emission of a weaker pulse directly followed by stronger pulse&#x2014;to manage the restricted signal dynamic range of the prior art system.</p><p id="p-0112" num="0111">Therefore, according to the invention, position coordinates of the object <b>10</b> causing or triggering the reflection <b>9</b> are ascertained in two dimensions, in the above example thus in a horizontal location (as a second location <b>42</b> of the present alignment of the emission/reception fan) and a vertical location (as a first location <b>41</b> in or between the sectors <b>20</b><i>a</i>, <b>20</b><i>b</i>, <b>20</b><i>c</i>, . . . of the reception fan) of the reflection <b>9</b> in the coordinate system of the device <b>14</b>. In embodiments having non-vertical alignment of the target search fans and/or non-horizontal movement of the fans, the position coordinates can be converted accordingly on the basis of the geometrical relationships provided in this case.</p><p id="p-0113" num="0112">Using the modulated pulse emission, not only can the above-mentioned higher peak power be achieved. A discrete point in time for the emission of the light fan <b>13</b> also results in this case, and therefore a discrete light fan in a discrete direction of the movement in the second direction. Moreover, a distance <b>43</b> between device <b>14</b> and reflection object <b>9</b> can be derived using a distance measuring unit on the basis of a runtime and/or phasing of the light fan light pulse <b>13</b><i>a</i>, <b>13</b><i>b</i>, . . . , from the emission at the device <b>14</b>, to the reflection <b>9</b> at the object <b>10</b>, and back to the device <b>14</b> on the basis of the propagation speed of the light&#x2014;or multiple distances <b>43</b>, if multiple reflections occur. The above-mentioned position coordinates of the reflection <b>9</b> can thus be supplemented by a third dimension in the form of a distance value <b>43</b>. The distance measuring unit <b>23</b> can especially be formed in this case in such a way that it can also accordingly analyze multiple distances <b>43</b> in a multi-target case, in which for a single emission light pulse, multiple reflections staggered in the distance thereof are received from multiple targets. In one embodiment, in this case especially a parallel analysis can be formed using one respective dedicated distance measuring unit <b>23</b> per pixel.</p><p id="p-0114" num="0113">A comparatively shorter pulse duration can often effectuate a comparatively more discrete or accurate determination of the position, in particular of the radial position in the distance direction, wherein a minimum required emitted pulse energy, peak power of the emitting element, etc., are often limiting here in a known manner. In practical embodiments, an engineering consideration of all parameters and effects on effectiveness, costs, utility, etc. has to be carried out here during the design.</p><p id="p-0115" num="0114">In the case of an analog acquisition and/or acquisition digitized with sufficient resolution (of at least greater than two or more) of an intensity or amplitude of the reflection <b>9</b> on the optoelectronic detector, in addition to the three position coordinates, a fourth characteristic value can be associated with a respective reflection <b>9</b> and/or its source <b>10</b>.</p><p id="p-0116" num="0115">In one embodiment according to the invention, furthermore, in addition to the position, a spatial extension of a coherent reflection <b>9</b> can be ascertained, for example, approximately in the form of a height in the first direction and a width in the second direction, and/or in one or two extensions of a reflection <b>9</b> in another spatial direction. On the basis of such an extension, for example, essentially punctiform reflections <b>9</b> due to surveying prisms <b>10</b> can be differentiated from, for example, oblong-shaped reflections <b>9</b><i>b </i>of reflectors on warning vests of workers <b>17</b>, from large-area reflections on windowpanes or the like, automatically on the basis of the extensions by a correspondingly formed analysis unit. In the ascertainment of the extension, the distance information of the distance measuring unit can preferably also be taken into consideration in this case, whereby a differentiation of reflections can also be performed on the basis of the depth staggering thereof. For example, in this case a triple prism <b>10</b> can also be automatically recognized by an analysis unit in front of a reflective glass pane in the background.</p><p id="p-0117" num="0116">In one example of an embodiment of an analysis of the target finder according to the invention, for example, in a locating unit <b>27</b>, an item of more than three-dimensional information can thus be acquired for an acquired reflection in this case. For example, an item of four-dimensional information having vertical position <b>41</b>, horizontal position <b>42</b>, distance <b>43</b>, and intensity and, derivable therefrom, a reflectance of the target object <b>10</b>. In this case, a reflection <b>9</b> acquired here in many cases is not only associated with one single discrete, two-dimensional or three-dimensional spatial coordinate, which may be determined, for example, in an intensity center or an intensity barycenter of the reflection <b>9</b>. Rather, in one embodiment of the invention a positional or spatial reflection profile of the reflection <b>9</b> can be ascertained and analyzed. For example, to analyze, for example, in the first and second directions, a clustering of intensity values of reflections <b>9</b> can be performed, or also a clustering of the intensity or the reflectance in three dimensions&#x2014;having first direction, second direction, and distance&#x2014;wherein such an intensity cluster is ascertained with at least one (2D or 3D) position, preferably also with a (2D or 3D) extension by an analysis unit. Therefore, for example, a reflection profile in the positional neighborhood of a potential reflector <b>10</b> can be ascertained, especially, for example, in the case of a reflection source <b>10</b> of non-negligible extension, for example, a reflector strip on clothing, a window, etc. Such an analysis in a target search unit according to the invention also provides advantages in the case of non-negligible optical influences of the air such as flickers, mist, fog, etc.&#x2014;or in the case of partially diffuse reflections, blooming, etc.&#x2014;especially also with respect to a recognition and differentiation of discrete, specific surveying reflectors <b>10</b> in greatly varying surroundings and surrounding conditions.</p><p id="p-0118" num="0117">A four-dimensional or higher-dimensional profile of the surroundings of the surveying device <b>14</b> can thus be derived, which can be produced by corresponding algorithms&#x2014;which can be produced in a classic manner and/or with incorporation of machine learning and artificial intelligence according to the rules of the art&#x2014;and provide an analysis of the profile, which is formed in such a way that it recognizes potential target reflectors <b>10</b>, differentiates them from potential interference signals and spurious signals, and locates them in a known coordinate system. For example, with such a profile or cluster, an interpolation of a reflection center as the location of the reflection can also be performed, for example, in the form of a computed center point, barycenter, centroid, expected value, etc. During the analysis, a spatial extension of the profile or cluster of a reflection <b>9</b> can in this case also be taken into consideration to differentiate external targets (such as security vests, traffic signs, glass or painted surfaces, headlights, cat's eyes, etc.) to exclude spurious targets, wherein preferably a possible depth staggering of reflections <b>9</b> can also be taken into consideration to suppress spurious reflections.</p><p id="p-0119" num="0118">A user <b>17</b> having the reflector <b>10</b> can in this case also operate the surveying device <b>14</b> remotely using an operating unit <b>18</b> via a radio connection <b>16</b>. In an optional embodiment, in this case the device <b>14</b> can carry out a rough determination of a rough direction to the reflector <b>10</b> by means of the radio connection, for example, to restrict the search region <b>22</b> of the automatic target finder according to the invention to defined surroundings with respect to this rough direction and/or to identify the reflector <b>10</b> and/or to differentiate it from other reflections <b>9</b>, which could potentially be confused with the reflector <b>10</b> of the user <b>17</b>. To determine this rough direction, for example, rough radio locating of the mobile operating unit <b>18</b> can be performed, for example, using diversity receiving using multiple antennas from which a probable direction to the received radio emitter may be derived. Such approaches are also known, inter alia, in the (planned) specifications of radio connections such as Bluetooth (for example, &#x3e;5.0), WLAN, mobile radio, etc. A consideration of a directional characteristic of a radio antenna moved along during the movement of the device <b>14</b>, for example, also during the movement of the light fan <b>13</b> (for example, in the second direction) can also be used to derive a rough direction to the operating unit, for example, on the basis of a directional dependence of the reception signal strength and/or phasing. This rough direction can then be refined by means of the target finder according to the invention, and/or a reflection <b>9</b> from the reflector <b>10</b> can thus be differentiated from other reflections <b>9</b>. The operating unit <b>18</b> can also determine its rough position itself by means of a GPS receiver or locating in a mobile radio network, and can provide this via the radio connection as the starting point for the target search according to the invention, from the exact or at least roughly known deployment of the device <b>14</b>.</p><p id="p-0120" num="0119"><figref idref="DRAWINGS">FIG. <b>3</b></figref> shows an example of a schematic sectional illustration of an embodiment of a target reflector search device <b>14</b><i>s </i>according to the invention, in which a position of the object <b>10</b> triggering a reflection <b>9</b> is determinable in a locating unit <b>27</b> using an analysis of the receiving unit <b>40</b> and the second direction <b>42</b> and preferably a distance <b>43</b>. In this case, the emitting unit <b>8</b> emits an emission fan <b>13</b> (located in the plane of the sheet). This light fan <b>13</b> is projected by means of a light source <b>12</b> and an emission optical unit into the surroundings to be searched, and can be moved between or during the emission of the light fan <b>13</b>, preferably motorized and equipped with an encoder <b>14</b><i>m</i>. Light-reflecting targets <b>10</b> encountered in the surroundings in this case, for example, the surveying reflector <b>10</b> shown, reflect a component <b>21</b> of the light of the emission fan <b>13</b> in this case back to the target reflector search device <b>14</b><i>s </i>according to the invention. A receiving unit <b>40</b> is formed there in such a way that this light <b>21</b> reflected from the targets <b>10</b> is acquired by the photosensitive detector <b>11</b>, which provides corresponding electrical signals for further analysis. In this case, the receiving unit <b>40</b> is formed in such a way that it also covers a fan-shaped reception region <b>20</b>, which preferably essentially overlaps with the emission fan <b>13</b>. According to the invention, the receiving unit <b>40</b> comprises an imaging optical unit <b>4</b> in this case, which is preferably designed as a fixed-focus optical unit. A correspondingly formed and arranged aperture <b>7</b>, for example, formed as a slit aperture, restricts a field of view of the receiving unit <b>40</b> in this case to the reception fan <b>20</b>, for example, wherein the aperture <b>7</b> can be arranged in the focal plane of the fixed-focus optical unit <b>4</b>.</p><p id="p-0121" num="0120">The photosensitive detector <b>11</b> is formed and arranged in this case in such a way that it is designed to be position-resolving along the reception fan <b>20</b>. In this case, multiple discrete pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e </i>are arranged along an image of the reception fan <b>20</b> in the object space toward the image space&#x2014;i.e., behind the optical unit <b>4</b> viewed from the outside&#x2014;so that the reception fan <b>20</b> is resolved along the fan into multiple reception segments <b>20</b><i>a</i>, <b>20</b><i>b</i>, <b>20</b><i>c</i>, <b>20</b><i>d</i>, <b>20</b><i>e</i>. According to the invention, an imaging optical unit <b>4</b> is applied in this case, but the photosensitive detector <b>11</b> is intentionally arranged outside the optimum imaging depth of field of the optical unit <b>4</b>, as it is with the blurry image <b>21</b><i>b </i>of the reflected light component <b>21</b>. According to the invention, for example, this is precisely not as would be the case, for example, in the case of an image sensor of an imaging camera or in classic applications of an imaging optical unit <b>4</b>.</p><p id="p-0122" num="0121">In one embodiment according to the invention, in this case the number of the pixels <b>1</b>, i.e., the number of the individually readable photosensitive sensors for the position resolution along the fan <b>20</b> can be kept small. According to the invention, hundreds of pixels <b>1</b> are thus not necessarily provided for the position resolution, but rather only a few pixels <b>1</b>&#x2014;for example, approximately 5 to 25 pixels, especially approximately 5 to 15, or, for example, approximately 10 pixels are sufficient&#x2014;wherein each of these pixels <b>1</b> is formed in this case as an SPAD array, however. Such a pixel <b>1</b> in the form of a single SPAD array comprises in this case a plurality (for example, approximately 100 to 10,000 units) of photosensitive cells operated in the Geiger mode, which are interconnected to form a single, common output of the pixel <b>1</b>. According to the invention, an analog analysis of the respective outputs of the pixels <b>1</b> is performed in this case, preferably a parallel analysis of all pixels <b>1</b>, which can be executed in one embodiment as a simultaneous or at least essentially simultaneous or quasi-simultaneous analysis. The analog analysis can also be performed with application of an analog-to-digital converter in this case, which provides a value-discrete analog representation, in particular having a resolution of more than two, especially at least 16, at least 128, or preferably even more value quantification steps.</p><p id="p-0123" num="0122">The individual pixels <b>1</b> also each comprise in this case, as SPAD arrays <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e</i>, a correspondingly larger sensitivity surface than a single semiconductor photodiode of comparably high electronic signal bandwidth. For example, an SPAD array having a sensitivity surface of approximately 1&#xd7;1 mm can have a signal bandwidth in the gigahertz range (GHz), which is not achieved in classic photodiodes at comparable size.</p><p id="p-0124" num="0123">In one embodiment according to the invention, the analysis of the outputs of the pixels is performed in this case using a distance measuring unit <b>23</b> having sampling frequency which is sufficiently high to carry out a runtime measurement of emitted light pulses of the emission fan <b>13</b>. This distance measuring unit <b>23</b> has in this case a distance resolution at least in the decimeter range, preferably in the centimeter range, for example, at least having a sampling rate or sampling frequency of greater than 1 MHz, for example, in the range of approximately 80 MHz or more.</p><p id="p-0125" num="0124">The position resolution and/or angle resolution of the reception fan in the first direction <b>41</b> achieved according to the invention using the reception fan longitudinal direction position determination unit <b>24</b> on the basis of the signals of the few pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e </i>exceeds in this case the fundamental resolution provided by the number of the pixels <b>1</b>, which results as the total acquisition fan angle by number of pixels <b>1</b>. Using the defocusing, beamforming or beam expansion, and parallel analog analysis according to the invention, a position resolution along the reception fan <b>20</b> can be achieved in this case which exceeds that of the number of the provided pixels <b>1</b>. In this case, the analog signals, which correspond to the reception intensity per pixel <b>1</b>, are analyzed as weightings over multiple juxtaposed pixels, wherein it is concluded, on the basis of the ratios of the intensities at intermediate positions of the point of incidence of the reflected light between the pixels <b>1</b>, which intermediate positions improve the position resolution. Such an intermediate position can be ascertained in this case, for example, by interpolation, barycenter formation, expected value computation, trained artificial intelligence systems, model formations, in any case also specifically for different types or classes of measurement targets or interfering reflections, etc. In addition to the intermediate position, a possible extension of the received reflection over multiple pixels can also be acquired in this case.</p><p id="p-0126" num="0125">During the signal analysis of the pixels <b>1</b>, not only the value of the analog outputs of the pixels <b>1</b>, but rather, using the distance measuring unit <b>23</b>, additionally also the incidence time, or in other words the runtime or the distance <b>43</b> dependent on this runtime to the reflection target <b>10</b>, can be taken into consideration, whereby a distance staggering of reflections <b>9</b> is ascertainable, and it is thus possible to prevent, for example, a measurement reflector <b>10</b> in front of a mirrored glass pane from being acquired as a single reflection <b>9</b>, but rather the reflections <b>9</b> and the background reflection can be differentiated by the analysis unit as separate reflections <b>9</b> using the system according to the invention on the basis of this depth staggering. Multiple reflections <b>9</b> can thus not only be differentiated on the basis of the depth staggering thereof and optimally also assisted by intensity profiles of the reflections <b>9</b> (for example, a bar graph of a frequency density of the analog values over direction and/or time) and/or on the basis of a reflectance of the source of the reflection <b>9</b> derived therefrom, but rather optionally also identified and/or classified, for example, as a measurement reflector <b>10</b>.</p><p id="p-0127" num="0126">The intensity profiles can in this case not only be analyzed along the first direction <b>41</b> of the reception fan <b>20</b>, but rather also additionally or alternatively in the second direction <b>42</b> of the movement of the reception fan <b>20</b> over a spatial region <b>22</b>, for example, on the basis of a position measurement of a movement of the target search device <b>14</b><i>s </i>according to the invention. The locating unit <b>27</b> is preferably formed in this case in such a way that it ascertains an intensity profile of the reflections <b>9</b> in two dimensions, i.e., for example&#x2014;in the first direction <b>41</b> and second direction <b>42</b>&#x2014;in the first direction <b>41</b> and distance <b>43</b>&#x2014;and/or in the second direction <b>42</b> and distance <b>43</b>&#x2014;or also in three dimensions, thus&#x2014;in the first direction <b>41</b>, second direction <b>42</b>, and distance <b>42</b>&#x2014;and is analyzed by the locating unit <b>27</b>. The analysis can in particular be performed in this case in such a way that the analog values obtained from the pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e </i>more or less as a fourth dimension, are analyzed as a spatial profile&#x2014;for example, via first direction <b>41</b>, second direction <b>42</b>, and/or distance <b>43</b> (or runtime). In this case, spatially coherent intensity clusters can especially be identified and delimited from one another. In this case, these intensity clusters can be formed in particular in such a way that these clusters represent reflectances, especially in that a distance influence is subtracted from the intensity values, or the reception signals are scaled over the respective associated distance values thereof. Such a reflectance usually represents a characteristic target object value in this case, on the basis of which a target object <b>10</b> can be identified and/or classified. For these intensity and/or reflectivity clusters, a location (for example, in the form of a position of a barycenter or an expected value of the cluster) and/or a spatial extension (for example, in the form of an extension, dimension, or standard deviation of the cluster), and/or a geometric shape of the cluster (for example, a point, a line, a surface, and the position thereof and possibly a location of the shape in space) can be ascertained by the analysis unit <b>23</b>, on the basis of which the reflections <b>9</b> associated with the clusters can be recognized and possibly also identified and/or classified. In addition to analytical and modeling analyses, in this case approaches from the field of machine learning and/or artificial intelligence can also be implemented. In this case, training data from typically occurring reflectors such as measurement reflectors <b>10</b>, but also spurious reflections, for example, from safety vests, headlights, glass panes, mirrors, cat's eyes, etc. can also be recorded and/or virtually simulated, in particular under variable surrounding conditions, etc.</p><p id="p-0128" num="0127">A detail of a further embodiment according to the invention is shown in a simplified manner in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, which uses, for example, an optical diffuser or a microlens array <b>3</b><i>a</i>, <b>3</b><i>b </i>in the beam path of the reception fan <b>20</b>. The exemplary illustration of only two pixels <b>1</b> is not to be understood as restrictive here, but rather is to be viewed as a detail, since a device according to the invention preferably comprises more than two pixels <b>1</b> (but also not hundreds of pixels <b>1</b>). In this case, the pixels <b>1</b><i>a </i>and <b>1</b><i>b </i>are again formed in the form of SPAD arrays <b>2</b> which are symbolized by way of example in the form of the schematic illustration <b>2</b> and the surface pattern of the SPAD array as an array grid and also one common electrical output per pixel. Of the light <b>21</b> of the reflection incident on the reception unit within the reception fan <b>20</b> of a fan-shaped light pulse emitted by the emitting unit, a first component <b>21</b><i>a </i>of A % is received by the first pixel <b>1</b><i>a </i>in this case, which results at the pixel output in the analog intensity value <b>5</b><i>a</i>, at a point in time which corresponds to the distance-dependent runtime of the light pulse. A second component <b>21</b><i>b </i>of B % received by the first pixel <b>1</b><i>b</i>, which results in the analog intensity value <b>5</b><i>b </i>at the pixel output, also at the same point in time, which corresponds to the distance-dependent runtime of the light pulse <b>21</b>. In this case, the optical unit <b>4</b> of the receiving unit is formed and arranged according to the invention in such a way that a point within the reception fan <b>20</b> in the object space is imaged on a non-negligibly small surface on the arrangement of the photosensitive pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>. This can be performed as explained above using an intentionally defocused arrangement of the pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, alternatively or additionally, however, in this case a diffuser or microlens array <b>3</b><i>a</i>, <b>3</b><i>b </i>shown here can also be arranged behind the imaging optical unit <b>4</b>, in particular in front of the pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>. In addition to a single continuous microlens array or diffuser <b>3</b><i>a</i>, <b>3</b><i>b </i>for all pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, a separate diffuser <b>3</b><i>a </i>or <b>3</b><i>b </i>can also be applied in this case for each of the pixels <b>1</b><i>a </i>or <b>1</b><i>b</i>, respectively, which distributes incident light <b>21</b><i>a</i>, <b>21</b><i>b </i>essentially uniformly&#x2014;in particular more uniformly than without this diffuser&#x2014;over the sensitivity surface of the respective pixel <b>1</b><i>a</i>, <b>1</b><i>b</i>. Light <b>21</b><i>a </i>or <b>21</b><i>b</i>, which is incident on a portion of the pixel <b>1</b><i>a </i>or <b>1</b><i>b</i>, is preferably distributed in this case by the diffuser <b>3</b><i>a </i>or <b>3</b><i>b </i>over a larger region of the pixel <b>1</b><i>a </i>or <b>1</b><i>b</i>, in particular over the entire SPAD array of the pixel <b>1</b><i>a </i>or <b>1</b><i>b</i>, respectively.</p><p id="p-0129" num="0128">The respective segments <b>20</b><i>a </i>and <b>20</b><i>b </i>of the reception fan <b>20</b> associated with the pixels <b>1</b><i>a </i>and <b>1</b><i>b </i>partially overlap in this case. In this case, an analysis of the location of the incident reflection <b>21</b> between the two pixels <b>1</b><i>a </i>and <b>1</b><i>b </i>can be ascertained on the basis of the intensity percentages A % and B %. In the example shown, for example, the spatial position <b>6</b> of the incidence of imaged reflection <b>21</b> along the juxtaposition of the pixels (of which <b>1</b><i>a </i>and <b>1</b><i>b </i>are partially shown here) can be ascertained, for example, by an interpolation being performed on the basis of intensity distribution <b>5</b><i>a </i>and <b>5</b><i>b</i>. In addition to a solely computational interpolation, a lookup table, machine learning, etc. can also be applied in this case. A location of the reflection <b>21</b> within the reception fan <b>20</b> is thus ascertained with a positional resolution which is greater than that which would result solely from the number of the pixels <b>1</b> for this acquisition region <b>20</b>.</p><p id="p-0130" num="0129">In this case, a chronological separation of positionally overlapping reception signals <b>5</b><i>a</i>, <b>5</b><i>b </i>can particularly advantageously be applied during the analysis. During this, only signals over adjoining pixels <b>1</b><i>a</i>, <b>1</b><i>b </i>are interpolated in the case of which the signals <b>5</b><i>a</i>, <b>5</b><i>b </i>were received practically simultaneously on the time axis (for example, with a time delay of &#x3c;10 ns)&#x2014;and thus (at least highly probably) originate from the same reflective object <b>10</b>. In this manner, different reflective objects <b>10</b>&#x2014;even if they are closely staggered in the direction of viewing&#x2014;may be automatically differentiated in the scope of the analysis in a comparably simple manner by the locating unit <b>27</b> described elsewhere.</p><p id="p-0131" num="0130">In other words, in a receiving unit <b>40</b> according to the invention, the fan-shaped reception region <b>20</b> is divided using a position-resolving detector <b>11</b> having a row of pixels <b>1</b> into a plurality of segments <b>20</b>, <b>20</b><i>b</i>, . . . . In this case, each of the pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, . . . is associated with one of the segments <b>20</b><i>a</i>, <b>20</b><i>b</i>, . . . . An acquisition region <b>20</b><i>a</i>, <b>20</b><i>b </i>of one of the pixels <b>1</b><i>a</i>, <b>1</b><i>b </i>thus forms one of the segments <b>20</b><i>a</i>, <b>20</b><i>b </i>in each case. According to the invention, the receiving unit <b>40</b> is formed in this case in such a way that these acquisition regions <b>20</b><i>a</i>, <b>20</b><i>b </i>of adjacent pixels <b>1</b><i>a</i>, <b>1</b><i>b </i>partially overlap in the object space in front of the imaging optical unit <b>4</b>. A reflection <b>9</b> in the overlapping region of these acquisition regions <b>20</b><i>a</i>, <b>20</b><i>b </i>of two pixels <b>1</b><i>a</i>, <b>1</b><i>b </i>results in this case in an output signal at both participating pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>. In this case, the light <b>21</b> is divided differently between the two pixels <b>1</b><i>a</i>, <b>1</b><i>b </i>in accordance with the position of the light reflection <b>21</b> in the overlap region, in particular the received intensity <b>21</b><i>a</i>, <b>21</b><i>b </i>of the light at the pixel <b>1</b><i>a</i>, <b>1</b><i>b </i>is dependent on the surface component of the reflection <b>21</b> which is acquired by the respective pixel <b>1</b><i>a</i>, <b>1</b><i>b</i>. Using an analog output signal of the pixel <b>1</b><i>a</i>, <b>1</b><i>b</i>, which is dependent on the received intensity <b>5</b>, in this case a position <b>6</b> of the reflection <b>21</b> from the target object <b>10</b> between the two adjacent pixels <b>1</b><i>a</i>, <b>1</b><i>b </i>is ascertainable according to the invention. Moreover, an item of information about the reflectance and/or extension of the object <b>10</b>, from which the light <b>21</b> reflected by its reflection <b>9</b> originates, can be derived in an overall view of the intensity over both pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>. This item of information can then be used to derive whether and/or with which probability the reflection originates from a surveying target mark <b>10</b> having specific and/or known reflectance or whether it is another type of undesired interfering reflection.</p><p id="p-0132" num="0131">In this case, optionally not only a runtime of the light signals from the target finder <b>14</b><i>s </i>to the reflection <b>9</b> and back can be ascertained using the specific pulsed emission of the emission fan <b>13</b>. This also enables an evaluation&#x2014;and therefore also an electrical and/or numeric suppression or subtraction&#x2014;of possible bias or interference signals, for example, due to ambient light, possible active light sources in the acquisition region, base emissions of the surroundings, etc., which are received outside the time of the pulse reception and/or are received essentially constantly. A differential image analysis of the acquired spatial region <b>20</b> can thus also be performed, for example. Thus, for example, a chronological derivative of the reception signals can be analyzed, for example, by corresponding numeric filtering or analysis of the analog, preferably digitized signals and/or using an electrical high-pass filtering of the analog output signals of the pixels, a dynamic bias control, etc.</p><p id="p-0133" num="0132">An example of an acquisition device according to the invention is shown once again in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. The optoelectronic detector <b>11</b> is formed as a position-resolving optoelectronic detector <b>11</b> having a line of SPAD array pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e</i>, if and is arranged and formed jointly with an imaging optical unit <b>4</b> in this case in such a way that a point from the fan-shaped reception region <b>20</b> (which is also indicated here in its cross section) is imaged blurred on the pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e</i>, <b>1</b><i>f</i>. The detector <b>11</b> (or the output signals of its pixels <b>1</b>) are analyzed by a position determination unit <b>24</b> for the position resolution in the fan longitudinal direction, a distance measuring unit <b>23</b>, and a locating unit <b>27</b> as described.</p><p id="p-0134" num="0133">Reflective targets <b>10</b>, thus in particular a retroreflective target mark to be located, are located in this case especially within the hyperfocal distance, i.e., in a range of the finite object distance at which&#x2014;in accordance with typically fixed-focus design of the optical system&#x2014;objects <b>10</b> located in infinity can also still just be imaged with acceptable blurriness. The so-called depth of field then extends from half the hyperfocal distance up to infinity. According to the invention, however, sharp imaging of reflections <b>9</b> from the objects <b>10</b> which are located in the range of the depth of field is intentionally omitted. Instead, for example, using a defined axial displacement <b>38</b> of the detector <b>11</b>, a blurry image of a reflection from the target object is generated from the actually sharply imaged focal plane.</p><p id="p-0135" num="0134">The above-mentioned lower limit of the object distance often does not represent a significant obstacle in the scope of the first aspect of the present invention, since it is per se designed for an analysis of a blurry image and therefore an even greater level of blurriness only displays minor negative effects with respect to reception signal strength and directional resolution. Moreover, at close range a greater part of the divergent, fan-shaped acquisition region is typically used than at long range, whereby the relative resolution can be at least partially compensated for again. Such a close range (for example, of a few meters) is also not used or is only used rarely in many surveying devices.</p><p id="p-0136" num="0135">In one example of an embodiment, for example, as shown for imaging from the infinite (or imaging equivalent thereto within the depth of field range of a fixed-focus optical unit), the image distance can be set approximately identically to the focal length f of the optical unit. According to the invention, in this example an imaging optical unit <b>4</b> can thus be used, in relation to which the optoelectronic detector <b>11</b> is intentionally arranged by a defined distance <b>38</b> in relation to the focal length f, i.e., in a defined manner in the back focus (or alternatively also in the front focus).</p><p id="p-0137" num="0136">In an example shown hereafter, an intentionally dimensioned blurriness, which is preferably different in the first and second directions, is explicitly introduced in a comparable manner by means of an optical diffuser <b>3</b> in the beam path&#x2014;which can be arranged in front of, in, or behind the image plane&#x2014;which exceeds the minimal blurriness which would actually be achievable using the imaging optical unit <b>4</b>, especially by a multiple of the technically achievable minimal blurriness. In the design of the imaging optical unit <b>4</b>, the requirement for the imaging optical unit <b>4</b> can thus also be shifted away from the sharpest possible imaging and more toward a correct position imaging. In another embodiment, the accurate position imaging can also be performed using a corresponding position calibration of the receiving unit, in particular an arithmetic calibration of the analysis of the detector <b>11</b>.</p><p id="p-0138" num="0137">Additionally or alternatively, in this case an optical beam expander or diffuser <b>3</b>&#x2014;indicated in this figure by way of example in front of one of the pixels&#x2014;can be attached in front of the detector <b>11</b> or in front of its pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e</i>, <b>1</b><i>f</i>, which causes a blurry distribution of the light incident from the imaging optical unit <b>4</b> on a larger surface than its point of incidence. In one embodiment, in this case the optical system <b>39</b> can preferably be designed in such a way that this surface of the light bundle has a greater extension in the first direction (in the fan direction) than transversely thereto. The detector and the optical system <b>39</b> associated with it are thus designed and arranged in such a way that according to the invention a bundle cross section at the point of incidence in the detector plane is used which is larger than a minimal circle of confusion, as would classically be used in imaging or photographic systems. In one embodiment, for example, in this case a circle of confusion or more generally a beam bundle cross section can be formed, which is in particular larger in the first direction than one of the pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e</i>, <b>1</b><i>f. </i></p><p id="p-0139" num="0138">In one embodiment, the optical beam expander <b>3</b> can be formed having a microlens array. This microlens array can be formed, for example, using many cylindrical lens rods, typically approximately 100 &#x3bc;m wide, and can be arranged in such a way that it asymmetrically expands the light bundle incident from the reflector target <b>10</b> and shaped by the receiving objective <b>4</b> directly before the array made of pixels <b>1</b>. For example, the light spot in the detector plane can thus be expanded to a size of, for example, approximately 2.2 mm&#xd7;0.9 mm on the sensitivity surface of the detector <b>11</b>, wherein the SPAD pixels <b>1</b> of the detector <b>11</b>, having a size of approximately 1 mm&#xd7;1 mm, are arranged without spacing in a line. Using the blurry, expanded imaging according to the invention, not only can a subpixel interpolation be carried out to increase the resolution during the analysis of the detector <b>11</b>, (using which the technology-related larger pixels <b>1</b> and the resolution thus limited of a detector <b>11</b> of reasonable structural size may be at least partially compensated for). Using the blurry, expanded imaging, according to the invention it is also possible that all microcells of an SPAD pixel <b>1</b> are illuminated at least essentially homogeneously&#x2014;whereby, for example, a collapse of the effective usable dynamics of the SPAD pixel <b>1</b> due to illumination of only a part of the available microcells can also be prevented or at least reduced. Especially in this case, using an embodiment according to the invention having an optical system having asymmetrical beam expansion, both a loss of received light can be avoided and also a pixel interpolation over more than one single pixel <b>1</b> can advantageously be enabled.</p><p id="p-0140" num="0139">In this case, the field-of-view of the detector <b>11</b> can be limited further to the desired reception fan <b>20</b> using a slit aperture <b>7</b>. For example, in an embodiment having back focus, in this case a slit aperture <b>7</b> restricting the field-of-view of the detector <b>11</b> can be arranged in the beam path between imaging optical unit <b>4</b> and detector <b>11</b>, especially, for example, approximately in the range of the focal length f.</p><p id="p-0141" num="0140"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example of an embodiment according to the invention having an optical beam expander <b>3</b> having diffuser plate, hologram, or micro-optical lens array, etc., which causes blurry imaging of the object space in spite of the imaging optical unit <b>4</b>, so that light reflected from an object <b>10</b> from the object space is expanded in such a way that it is acquired by more than one single pixel <b>1</b>. In this case, as shown here, a continuous diffuser <b>3</b> can be applied for multiple pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e</i>, <b>1</b><i>f</i>, <b>1</b><i>g </i>of the detector <b>11</b>, or alternatively an individual diffuser can be applied for each of the pixels <b>1</b><i>a</i>, <b>1</b><i>b</i>, <b>1</b><i>c</i>, <b>1</b><i>d</i>, <b>1</b><i>e</i>, <b>1</b><i>f</i>, <b>1</b><i>g</i>. Especially in the case of a solely randomly scattering diffuser <b>3</b> for multiple pixels <b>1</b>, this diffuser <b>3</b> can also be arranged in the sharply imaged focal plane of the optical unit <b>4</b>, in that the optical properties of the diffuser <b>3</b> effectuate the blurry imaging toward the detector <b>11</b>. A front focus or back focus arrangement is thus not absolutely required, but it is optionally also additionally possible&#x2014;especially if the diffuser <b>3</b> is used to distribute the received light more homogeneously over the sensitivity surface of a pixel <b>1</b>. An advantageous expansion or forming of the light bundle reflected from the object space and imaged can also be achieved by means of specially adapted holograms or astigmatic microlens arrays, for example, using a corresponding light forming plate introduced into the beam path. To keep the structural length of the receiving unit small, in this case the optical light forming plate can be arranged in front focus arrangement.</p><p id="p-0142" num="0141">The light forming of an optical system according to the invention can especially be formed in such a way that the light bundles assume an oblong elliptical (as indicated in this figure) or rectangular extension on the pixel plane. By means of such micro-optical components, with corresponding design, the radiation reflected from the target object can be used optimally, i.e., essentially without loss.</p><p id="p-0143" num="0142"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows a sketch of two adjacent emission fans <b>13</b><i>a </i>and <b>13</b><i>b </i>(or the respective associated reception fans, respectively), wherein the angle distance thereof in the second direction <b>42</b> is shown disproportionately wide for the sake of clarity (see, for example, values typical in practice mentioned elsewhere).</p><p id="p-0144" num="0143">The light fans <b>13</b><i>a </i>and <b>13</b><i>b </i>shown comprise in this case reflections <b>9</b><i>a</i>, <b>9</b><i>b</i>, <b>9</b><i>c</i>, <b>9</b><i>d</i>, which are acquired by the position-resolving detector of the target search device according to the invention in a blurry image, and of which in each case a first location is ascertained in the first direction <b>41</b> as described, for example, as an angular position within the fan <b>13</b> in relation to its optical axis <b>43</b>&#x2014;as also indicated, for example, with the segmenting of the fan <b>13</b><i>b</i>. Furthermore, a distance measuring device is connected to the detector, which determines a distance <b>43</b> for each of the reflections <b>9</b><i>a</i>, <b>9</b><i>b</i>, <b>9</b><i>c</i>, <b>9</b><i>d </i>on the basis of a run-time measurement between emission and reception of the light of the emission fan <b>13</b>. The second location in the direction <b>42</b> of a reflection <b>9</b> results with the association of a reflection <b>9</b> with one of the emission fans <b>13</b><i>a</i>, <b>13</b><i>b </i>during the movement of the emission direction of the emission fans <b>13</b>. For example, in this case spherical coordinates of the position or object result, at which the reflection <b>9</b> occurs, for example, having polar angle (=first location in <b>41</b>), azimuth angle (=second location in <b>42</b>), and radius (=distance in <b>43</b>), which can also be converted in a known manner to other coordinate systems, however, in particular to a coordinate system of the surveying device. On the basis of these three coordinates, the reflections <b>9</b> may generally be differentiated well, so that a differentiation of different reflection objects (also referred to here as clusters) may be carried out automatically by a locating unit on the basis of these locations, in particular on the basis of the distance information (or in other words the point in time of the incidence of the reflection <b>9</b>).</p><p id="p-0145" num="0144">In addition to this position, a geometrical extension or size of the reflection <b>9</b> can optionally also be determined, for example, if the reflection <b>9</b> occurs in the three dimensions in a geometrically coherent manner (as a cluster) over a plurality of emission fans <b>13</b> or over multiple pixels of the detector, a size and/or shape of the reflecting object can be determined therefrom. An actual extension of the reflective object can be determined from a measured apparent height in the first direction and a corresponding apparent width in the second direction of a reflection <b>9</b> or cluster with the aid of the measurement distance <b>43</b>.</p><p id="p-0146" num="0145">In addition to these geometrical considerations, in addition an intensity of the reflection <b>9</b> can also be determined, which can also be incorporated into observations. In this case, for example, a location of the position of the reflection <b>9</b> can be ascertained on the basis of a maximum, barycenter, or another evaluation function of the intensity of the reflection <b>9</b>, in first location, second location, and/or distance. Using the intensity of the reflection <b>9</b>, especially in combination with the other above-mentioned analyses, a reflectance of the reflective object <b>10</b> can also be ascertained as already described, which can represent a further criterion for differentiating the reflections <b>9</b><i>a</i>, <b>9</b><i>b</i>, <b>9</b><i>c</i>, <b>9</b><i>d </i>and also especially for classifying the object <b>10</b> triggering the reflection <b>9</b>, especially for differentiating a surveying reflector <b>10</b> from an interference reflection <b>9</b><i>c</i>, <b>9</b><i>d </i>or for automatically selecting a specific reflector type. The reflectance is illustrated here by patterns of different brightness of the reflections <b>9</b><i>a</i>, <b>9</b><i>b</i>, <b>9</b><i>c</i>, <b>9</b><i>d</i>. The ascertained items of information with respect to position and/or extension can optionally also be taken into consideration in addition in the classification of the objects <b>10</b>.</p><p id="p-0147" num="0146">In the example shown, in this case the reflections <b>9</b><i>a </i>and <b>9</b><i>b </i>may be recognized as geometrically coherent (=cluster)&#x2014;and thus originating from a single reflection object&#x2014;on the basis of the location thereof in distance <b>43</b>, first direction <b>41</b>, and the proximity thereof in the emission fans <b>13</b><i>a </i>and <b>13</b><i>b </i>in the second direction <b>42</b>. Jointly with the high reflectance thereof (and/or the small geometrical extension of the reflection), in this case this is a surveying triple prism <b>10</b> (at least with very high probability). This surveying triple prism <b>10</b> is thus in the distance <b>43</b> associated with the reflection <b>9</b><i>a</i>, <b>9</b><i>b</i>, of the first direction determined for this reflection <b>9</b><i>a</i>, <b>9</b><i>b </i>and for this distance on the basis of the analysis of the blurry imaging of a plurality of pixels of the detector. In the second direction <b>42</b>, the object <b>10</b> is to be located in the direction of the emission fan <b>13</b><i>a</i>, since the reception signal for this reflection already becomes weaker again in the emission fan <b>13</b><i>b </i>and has thus already exceeded its maximum. Alternatively, the second direction <b>42</b> could also be interpolated between the emission fans, in particular with respect to the determined intensity&#x2014;especially upon use of emission fans which are comparatively narrow in the second direction <b>42</b>, however, in such a way it is often not necessary to determine a sufficiently accurate location in the second direction as a transfer value for a subsequent fine targeting of the object <b>10</b> using the surveying device. This at least rough location of the position of the surveying reflector <b>10</b> ascertained by the target search device can then, for example, be transferred automatically to an automatic targeting device of the surveying device, which then automatically (exactly) targets it, surveys it, and provides its geodetic coordinates.</p><p id="p-0148" num="0147">In one embodiment according to the invention, in this case the analysis can especially be performed on the basis of the distance <b>43</b>, the location in the first direction <b>41</b> (=vertical angle), and the intensity (and/or the reflectance derived therefrom) of the reflection, in particular since all of these items of information are ascertained directly from the output signals of the SPAD array pixels <b>1</b> of the position-resolving detector <b>11</b> according to the invention. A rapid and optionally also at least partially parallel analysis of the pixel signals for these items of information can thus be performed, and especially also the combination thereof can be carried out to recognize, differentiate, and classify targets&#x2014;preferably online, i.e., just-in-time for each of the fans directly upon reception of the reflection signals. A primary analysis in a distance (=time), vertical angle, intensity, space, or diagram can thus more or less be carried out. The horizontal angle of the second direction <b>42</b> can then first be incorporated after completion of the above analysis, wherein the second direction <b>42</b> can also be supplied by the surveying device.</p><p id="p-0149" num="0148">In <figref idref="DRAWINGS">FIG. <b>8</b><i>a</i></figref>, an example of an acquisition and analysis according to the invention during the target search is shown&#x2014;in the scope of the limited possibilities here of a two-dimensional black-and-white illustration. In this case, the searched spatial region is shown more or less as a panoramic image <b>30</b>. In this case, the resolution of the spatial region <b>22</b> is represented by the described analysis of the longitudinal direction of the detector <b>11</b> in the first direction <b>41</b> in the image <b>30</b> in the vertical direction, and the resolution of the spatial region <b>22</b> is represented by the adjacent emission fans <b>13</b><i>a</i>, <b>13</b><i>b</i>, . . . in the second direction <b>42</b> in the image <b>30</b> in the horizontal direction. In a non-orthogonal or non-levelled embodiment, the acquisition could if needed also be converted to the representation shown. In this case, the relatively low resolution in the form of the clearly recognizable individual grid (appearing square in this example, but generally not necessarily) of the image <b>30</b> obviously stands out. This low resolution may appear disadvantageous and inaccurate at first view, but, inter alia, enables faster scanning of the spatial region <b>22</b> than would be the case at higher resolutions. The grids represent the reception intensity in its brightness here, wherein lighter regions represent stronger reflections and black regions represent no reflections. In this case, however, the distance <b>43</b> associated respectively with the reflection <b>9</b> and ascertained by the distance measuring unit is preferably also to be taken into consideration, since, for example, only a comparatively weak reflection will be received even from a very bright reflector <b>9</b> at long distances <b>43</b>. This can be performed, for example, by an analysis of a distance-scaled brightness of the reflector <b>10</b>, or in other words by an analysis of a reflector-specific reflectivity in 3D space. The simplified 2D representation can be considered here to be solely by way of example and/or as an already distance-scaled 2D representation of the reflectivity or reflectance. Spatial regions from which reflections were received are thus shown in the form of image regions or clusters <b>9</b> represented as light. Such a cluster <b>9</b> can be defined, for example, as a spatially coherent region (i.e., not only in the two dimensions <b>41</b>, <b>42</b> shown, but rather additionally also in the distance <b>43</b>), in which a received reflection intensity and/or a reflectance ascertained in this direction is greater than a static or dynamically adapted threshold value.</p><p id="p-0150" num="0149">According to the invention, one&#x2014;or in the case of a multitarget case possibly also multiple&#x2014;distances are ascertained for each reflection <b>9</b> region shown as light using the distance measuring unit, whereby the illustration <b>30</b> shown actually would also have a spatial depth, which may not be reasonably represented here, however. The light regions would thus also be staggered into the plane of the sheet in this case. Therefore, for example, a region only visible here as a single cluster <b>9</b> could also result in multiple depth-staggered spatial clusters in the distance <b>43</b>, which are each to be considered as an independent cluster as such. For example, in the case of a reflective glass pane in the background of a measurement reflector or the like.</p><p id="p-0151" num="0150">Furthermore, on the basis of the measured extension <b>33</b> and/or <b>34</b> of a reflection <b>9</b> in one or over multiple emission fans, and also with incorporation of the respective associated distance <b>43</b>, an actual width <b>33</b> and/or height <b>34</b> of the target reflectors <b>10</b> can be ascertained. For example, on the basis of the geometrical relationships known in this case, a width and/or height (or a geometrical extension of the target reflector in general location) can also be computed or at least estimated in specific measurement units. Such a width and/or height are often characteristic features of the target objects to be located and represent relevant measured variables in the target mark recognition.</p><p id="p-0152" num="0151">During the data analysis, the depth staggering of the reflectors <b>10</b> and the interference reflections <b>9</b> is preferably taken into consideration. The distance measuring unit, especially if it is formed as a waveform digitizer (WFD), already generically provides depth-staggered brightness values of the reception signals, for example, one brightness value in the form of a signal amplitude is acquired and provided per pixel over a time axis (which accordingly corresponds to the signal runtime of a distance axis). If brightness values of adjacent pixels have equal associated distance <b>43</b> in this case (thus have equivalent locations on the time axis), the location thereof in the first direction <b>41</b> (and/or in the second direction <b>42</b>) can thus be interpolated between the pixels, and thus a reception direction (or location) of the reflection <b>9</b> in the first direction <b>41</b> can be ascertained. In the case of differing distances <b>43</b>, it is to be presumed that the reflections <b>9</b> originate from different objects, so that an interpolation in the first direction <b>41</b> and/or second direction <b>42</b> is not expedient.</p><p id="p-0153" num="0152">Furthermore, an associated reflectance can be ascertained in each case on the basis of the received reflection intensities to the target reflectors <b>10</b> or reflective objects, especially in consideration of the respective associated distance. On the basis of these data, the analysis unit can identify and/or classify reflection targets, in this case especially reflective foreign objects can be robustly differentiated from surveying targets, especially in consideration of respective characteristic reflectances. For the located reflectors, in this case in consideration of the intensity or brightness distribution, the location and thus the directions to the reflectors are determinable. All of these computations can be computed in this case by the analysis unit <b>27</b>, preferably in real time during the scanning of the search space.</p><p id="p-0154" num="0153">In one embodiment, in this case an objective and complete computation of a 2D or 3D intensity image&#x2014;as shown in <figref idref="DRAWINGS">FIG. <b>8</b><i>a </i></figref>to illustrate one embodiment variant of the analysis&#x2014;can also be omitted in the target recognition. An embodiment having an analysis carried out essentially online during the acquisition can thus be formed. Similarly as also explained in conjunction with <figref idref="DRAWINGS">FIG. <b>8</b><i>b</i></figref>, for example, for each of the emitted emission fans <b>13</b>, a plurality of the time axes (or distance axes, respectively), which are each generated with a distance measuring unit associated with one of the pixels <b>1</b> for this emission fan <b>13</b>, can be processed and analyzed. This analysis and computation are formed in this case in such a way that one or more signals of reflections <b>9</b>A, <b>9</b>B are located on the time axis. This can be performed continuously and from laser emission to laser emission, wherein corresponding signals are compared. In this case, especially the expected signal strength and simultaneously the target object width can be checked. Signal parameters of the received signals can be compared to one (of multiple) configured reflector models for correspondence in this case to find a target object <b>10</b>. Multiple target objects can certainly be located in this case along the distance/time axis <b>43</b>, which are differentiable according to the invention on the basis of the different distance information and/or reflectivity, for example, a reflector in front of a traffic sign, etc. On the basis of the majority of detector pixels <b>1</b>, in this case the targets can also be located in the vertical direction, along the fan direction, and also spatially separated during the analysis in the case of multiple targets.</p><p id="p-0155" num="0154">In other words, the 3D space is more or less successively scanned for reflectors in a fan-like manner, including depth acquisition, continuously analyzed by computer during this, and located target objects <b>10</b> are classified and stored. A user can optionally establish in this case which target classes or target types are to be located, stored, or approached. The performed analysis can then optionally also be visualized for a user, for example, the found target objects can be overlaid as an overlay in a camera image or the reflector targets can be marked on a tablet PC in a construction plan, a map, or a CAD model for the purpose of visualization. In one embodiment, such a 2D intensity image, or preferably a 3D intensity image, can also be provided to a local or remote user for visualization of a station overview and/or for interaction with a target selection unit, for example, on a display screen, but optionally also via an augmented-reality (AR) or virtual-reality (VR) display unit.</p><p id="p-0156" num="0155">According to the invention, in this case the determination of a position or location <b>31</b> or location of a reflection <b>9</b> in the spatial region is carried out not only with an analysis of a single pixel <b>1</b>, but rather the reception intensity of the pixels <b>1</b> located adjacent in the first and/or second direction is also considered. For example, an intensity barycenter or center point of a reflection <b>9</b>, i.e., of a spatially coherent cluster <b>9</b> of multiple pixels <b>1</b>, can be determined as position <b>31</b> of the reflection, whereby the position <b>31</b> ascertained in this case has a resolution which is greater than the pixel resolution of the acquired image <b>30</b>. Therefore, with corresponding engineering design of the parameters of a target recognition system according to the invention, the position <b>31</b> of a target reflector <b>10</b> in the spatial region can be produced with sufficient accuracy that this reflector can be automatically targeted by the surveying device for subsequent surveying.</p><p id="p-0157" num="0156">Special embodiments of the invention can in this case also provide additional functionalities for an improved recognition of target reflectors <b>10</b> and the differentiation thereof from interference reflections <b>9</b>. In addition to the sensitivity advantages of the pixels <b>1</b> used according to the invention, which are each formed as an SPAD array (for example, with respect to sensitivity, overload behavior, time measurement properties, etc.), the reflection acquisition according to the invention&#x2014;as is apparent from the illustration shown here&#x2014;can also be determined as a two-dimensional extension <b>33</b>, <b>34</b> of the reflection <b>9</b> (and/or if needed also as a three-dimensional extension of the reflection <b>9</b> in consideration of the distance <b>43</b>, which unfortunately cannot be represented here). Inferences can thus be computed about a probable type or class of reflection sources, for example, using a comparison of the cluster <b>9</b>, <b>10</b> to a modeling of a reflection to be expected of a known target reflector in the corresponding distance of the cluster <b>9</b>, <b>10</b>, or using a correspond trained artificial intelligence system, neuronal network, rule-based classification, or a mixed form thereof. Thus, for example, an oblong reflection <b>9</b> of a reflector strip on a sign or a large-area but weakly reflecting glass pane <b>35</b> can be differentiated from a punctiform triple prism <b>10</b> reflecting at high intensity.</p><p id="p-0158" num="0157">A classification is in this case, for example, on the basis of a reflectance determined by the device according to the invention of the object causing or triggering the reflection <b>9</b> with those which are known from the target objects <b>10</b> used in the surveying. Triple prisms in surveying have, for example&#x2014;scaled to a scattering white surface&#x2014;a reflectance of approximately 1 million, planar retroreflectors made of plastic (cat's eyes) have a reflectance of approximately 30,000, reflective films of approximately 1000, etc. The gradations of these reflectivities of the above examples thus comprise in this case at least approximately one order of magnitude or more, whereby these can be acquired, resolved with sufficient accuracy, and also differentiated using the SPAD arrays used according to the invention. A reliable classification of the reflective markings and reflective targets typically used in surveying and in construction can therefore be carried out on the basis of the reflectances thus ascertained.</p><p id="p-0159" num="0158">In the example shown in <figref idref="DRAWINGS">FIG. <b>8</b><i>a</i></figref>, in addition to diverse interference reflections, inter alia, for example, a surveying reflector <b>10</b> on a surveyor's rod and the warning vest <b>9</b> of the worker holding the surveyor's rod can be seen.</p><p id="p-0160" num="0159">For a recognition of triple prisms, in one embodiment especially also a parallax adapted to the dimension of the triple prism used between emission and reception fans in the target search unit can be used in this case. The signal of targets, the reflection of which is incident with a parallel offset in the receiver&#x2014;which parallel offset essentially corresponds to the parallax typical in these triple prisms&#x2014;is heightened in relation to other targets typically reflecting without parallax. With correspondingly formed embodiments of the devices having such parallax between emission axis and reception axis, for example, simple reflective objects can only overcome the sensor parallax from approximately 20 m and generate a reception signal at all. Retroreflectors having beam offset, in contrast, overcome the parallax at all distances. Especially together with the significantly higher reflectances of triple prisms in contrast to interference reflections and/or the specific point shape thereof in contrast to often larger-area interference reflections, the analysis unit can thus also carry out a robust, automatic specific recognition of surveying reflectors in the associated first and second directions thereof, and also ascertain the distance thereof.</p><p id="p-0161" num="0160">With multiple repeated scans of the spatial region, in addition mechanical dithering can occur, for example, in the form of a geometrical offset of the emitted fans in the second direction in a location between two of the fans emitted during the prior pass and/or an offset of the acquisition regions of the pixels in relation to the prior pass in the first direction&#x2014;whereby the achievable resolution may be further improved. For this purpose, for example, the movement axes of the surveying device and/or the emission points in time of the light fans can be controlled accordingly. For example, this can be performed, inter alia, after a first rough scan of the entire spatial region for a portion of potential interest of the entire spatial region.</p><p id="p-0162" num="0161">In modern geodetic surveying devices, such as total stations, theodolites, tachymeters, or laser trackers, the movement in the second direction <b>42</b> can usually take place at quite high speed, for example, a pivot around the standing axis at up to 120&#xb0;/second. A target search device according to the invention therefore has to have a correspond high laser firing rate and also a correspondingly high measurement rate on the reception side when emitting the emission fan to also be able to use these speeds and in this case be able to scan the second direction continuously&#x2014;or also with multiple overlaps&#x2014;for surveying targets using the light fans. For example, an assumed measurement rate of 75 kHz divides a horizontal search region of 360&#xb0; into sectors of the width 0.0016&#xb0;. Using a typical width of the laser fan assumed here in the second direction of 0.013&#xb0;, each reflection point <b>9</b> can thus be measured approximately 8 times. In one embodiment of the invention, these and even higher scanning speeds and analyses can certainly be processed in real-time using current analysis means. However, in order to save electric power and current and/or avoid excessive heat development of the electronic processing unit&#x2014;especially, for example, with battery-operated instruments&#x2014;optionally or alternatively the above-described method of mechanical dithering using repeated scans can be used, a measurement rate aperiodic with respect to a revolution can be used, or first a rough scan at a lower measurement rate (for example, for approximately 1-fold coverage of the scanning region) followed by a measurement&#x2014;in particular only focused on potential target reflectors recognized in this case&#x2014;at higher measurement rate.</p><p id="p-0163" num="0162">A diagram having exemplary reception signals of a target reflector search device <b>14</b><i>s </i>according to the invention is shown in <figref idref="DRAWINGS">FIG. <b>8</b><i>b</i></figref>. Therein, multiple, by way of example five here, SPAD array pixels <b>1</b><i>a</i>-<i>e </i>of the linear arrangement of the position-resolving detector <b>11</b> are plotted, which are arranged here in a vertical direction V (as the first direction <b>41</b>, in which the emission fan <b>13</b> is aligned) in the image region of the imaging optical unit <b>4</b>. A time axis <b>43</b> D,(t) is associated with each of these pixels <b>1</b><i>a</i>-<i>e </i>in this case, along which, for each of the pixels <b>1</b><i>a</i>-<i>e</i>, in each case the received light intensity of possible reflections <b>10</b> of an emission fan light pulse emitted in this Hz direction <b>42</b> is plotted. The time axis D,(t) <b>43</b> is in this case, in accordance with the signal runtime of the light pulse plotted thereon, also simultaneously to be considered a distance axis as a measure of a distance to the position of the reflection <b>10</b> proportional to the runtime. The second direction <b>42</b> is indicated in this case as a horizontal axis with Hz, in which the emission fan <b>13</b> is moved between the light pulses of the individual emission light fans. With each laser pulse, in this case a diagram as shown results at new Hz angle <b>42</b>, having the dimensions distance D <b>43</b> &#x26; V angle <b>41</b>. For the sake of clarity, only one diagram for one of the emission fans <b>13</b> of this emission fan family is shown in the Hz direction <b>42</b> here, however. In this case, the time axis D,(t) <b>43</b> is also to be considered in accordance with the signal runtime of the light pulse plotted thereon as a distance axis, on which a measure of a distance, proportional to the runtime, to a position of the reflection <b>9</b> is plotted. The curves shown of the reflections <b>9</b><i>a </i>and <b>9</b><i>b </i>on the time axes D,(t) <b>43</b> of the individual pixels <b>1</b><i>a</i>-<i>e </i>can be acquired in this case using an analog-to-digital converter at the output signal of the respective pixel <b>1</b> as a waveform of the reception intensity over time.</p><p id="p-0164" num="0163">It can be seen in this case that, in accordance with the blurry imaging according to the invention, according to the invention the acquisition regions of the individual pixels <b>1</b><i>a</i>-<i>e </i>partially overlap in the object space, so that a reflection <b>9</b><i>a</i>, <b>9</b><i>b </i>from a location in the object space is (at least proportionally) received by more than one of the pixels <b>1</b><i>a</i>-<b>1</b><i>e</i>. In the example shown, two reflections <b>9</b><i>a </i>and <b>9</b><i>b </i>occur, which have the same location Hz in the second direction <b>42</b> here&#x2014;since they belong to the same emission fan <b>13</b>&#x2014;but have both a different vertical location V in the first direction <b>41</b> and also a different distance D <b>43</b>.</p><p id="p-0165" num="0164">In this case, in one embodiment of the analysis, it can be presumed that intensity pulses A,B at different pixels <b>1</b><i>a</i>-<i>e</i>, which have (at least substantially or essentially) the same location on the time axis D,(t) <b>43</b>, originate from the same reflection source <b>10</b>. Therefore, in the example shown, the pulses A<b>2</b>, A<b>3</b>, A<b>4</b> can be evaluated together, wherein a location of the reflection source in the V direction <b>41</b> is ascertainable on the basis of a distribution of the intensities (i.e., for example, the level of the pulses) of the pulses A<b>2</b>, A<b>3</b>, A<b>4</b> occurring at this point in time at the pixels <b>2</b>, <b>3</b>, <b>4</b>. Therefore, the V location <b>41</b> of the reflection source of the reflection <b>9</b>A is ascertained with a resolution which can also be between the pixels <b>1</b><i>a</i>-<i>e </i>(and/or the associated optical axes thereof), whereby an association of the location of the reflection source with a single one of the pixels does not solely take place, but rather a resolution of the location of the reflection source in the direction V <b>41</b> is achievable, which exceeds the number of the pixels <b>1</b><i>a</i>-<i>e. </i></p><p id="p-0166" num="0165">In the example shown, a second reflection <b>9</b>B furthermore occurs at a distance RetB different from the above-mentioned distance RetA. This is also acquired according to the invention by a plurality of the pixels <b>1</b><i>a</i>-<i>e</i>, wherein the analysis thereof not only results in a different distance D <b>43</b>, but rather also a different location in the direction V <b>41</b>&#x2014;in this case between the pixels <b>1</b><i>c</i>, <b>1</b><i>d</i>, and <b>1</b><i>e</i>, especially a V location between the pixels <b>1</b><i>c</i>-<b>1</b><i>e </i>which is approximately at one-fourth of the distance between the direction of pixel <b>1</b><i>d </i>in the direction of pixel <b>1</b><i>c</i>. This analysis was already explained above.</p><p id="p-0167" num="0166">It is to be noted here with respect to the location Hz in the second direction <b>42</b> that it does not necessarily have to be identical in its final analysis for the reflections RetA, RetB shown, but rather that the pulses A<b>2</b>, A<b>3</b>, A<b>4</b> B<b>3</b>, B<b>4</b>, B<b>5</b> shown can in any case also be distributed over multiple Hz diagrams of multiple emission fans <b>13</b> in the second direction <b>42</b>, and the final location of the reflection in the second direction <b>42</b> is ascertained, as already explained, on the basis of a barycenter, peak value, or the like of the received intensity over multiple emission fans&#x2014;so that in any case an intermediate position between two emission fans <b>13</b> can also be ascertained in the direction Hz <b>42</b>.</p><p id="p-0168" num="0167">In one embodiment, the diagram in <figref idref="DRAWINGS">FIG. <b>8</b><i>b </i></figref>can also be considered as a side view or as a section orthogonal to the plane of the drawing of <figref idref="DRAWINGS">FIG. <b>8</b><i>a</i></figref>. In this case, the V axis <b>41</b> and the Hz axis <b>42</b> correspond to the two image coordinates of <figref idref="DRAWINGS">FIG. <b>8</b><i>b </i></figref>and the D,(t) axis <b>43</b> extends orthogonally to the plane of the sheet. The heights of the waveforms A<b>2</b>, A<b>3</b>, A<b>4</b> and B<b>3</b>, B<b>4</b>, B<b>5</b> of the reflections <b>9</b><i>a</i>, <b>9</b>B from <figref idref="DRAWINGS">FIG. <b>8</b><i>b </i></figref>are represented in this case by corresponding brightnesses of the pixels in <figref idref="DRAWINGS">FIG. <b>8</b><i>a </i></figref>(wherein in the embodiments shown here, the number of the pixels <b>1</b> of the detector <b>11</b> is not equal in the different examples of <figref idref="DRAWINGS">FIG. <b>8</b><i>a </i></figref>and <figref idref="DRAWINGS">FIG. <b>8</b><i>b</i></figref>).</p><p id="p-0169" num="0168"><figref idref="DRAWINGS">FIG. <b>9</b></figref> shows a block diagram of an embodiment of a method according to the invention or a process according to the invention, especially to be executed automatically during targeting of target objects, for example, in a geodetic surveying device.</p><p id="p-0170" num="0169">In block <b>50</b>, an emission of an emission fan of optical radiation is performed, preferably in the form of a time-modulated, in particular pulsed projection of a laser line.</p><p id="p-0171" num="0170">In block <b>51</b>, a movement of the emission fan is performed in different directions over a spatial region to be searched, in particular a rotation of the emission fan around an axis, so that the spatial region is covered by a fan bundle thus resulting.</p><p id="p-0172" num="0171">In block <b>52</b>, a reception of a reflection of one of the emission fans is performed in a fan-shaped reception region. Using an imaging optical unit, in this case a projection of the reception region is performed on a position-resolving optical detector, which is formed using a linear arrangement of a plurality of pixels each formed as SPAD arrays. The projection is performed in this case using an optical system which is formed in such a way that blurry imaging of the object space, which is expanded in relation to a focused image, is performed on the position-resolving optical detector&#x2014;especially wherein the reflection of light of the emission fan on reflective objects in the object space is acquired by more than one of the pixels.</p><p id="p-0173" num="0172">In block <b>53</b>, a determination of a distance, a signal strength, and a position of the reflection is performed on the basis of the direction of the emission fan in the spatial region using an analysis of the position-resolving optical detector, wherein the position is performed using a determination of a location of an intensity-barycenter (or center of gravity or centroid) of the blurry image of the reflection on the detector over a plurality of the pixels. In this case, especially a runtime distance measuring unit can be formed for determining the one distance for each of the reflections, preferably respectively individually for each of the pixels. The direction of the emission fan in the spatial region can be acquired using an angle encoder as the second direction. In particular, a reflectance of the source of the reflection can be determined in this case on the basis of the signal strength and the distance.</p><p id="p-0174" num="0173">The above steps can especially be performed continuously or quasi-continuously in this case, in any case also at least partially in parallel&#x2014;in particular for each of the emission fans.</p><p id="p-0175" num="0174">In a further step, the ascertained values can be relayed to the surveying device&#x2014;especially a location&#x2014;rough in the geodetic scale&#x2014;of the object, which triggers the reflection in the first direction, the second direction, and the distance. In this case, a recognition, classification, and/or filtering of the objects can preferably be performed, for example, on the basis of the reflectance, geometrical dimension, etc. thereof. In particular, on the basis of this ascertained position of the target object, the surveying device can approach this position using a high-precision automatic target acquisition device and as a result automatically ascertain the coordinates of the target object with geodetic accuracy, i.e., in particular accuracy to seconds of an angle and millimeters, and provide them as the surveying result.</p><p id="p-0176" num="0175">In one example of an embodiment of an application of the first aspect of the present invention, for example, the target search unit can ascertain rough coordinates (in the geodetic scale) for the searched target objects, for example, a rough direction in the first and second directions, for example as two angles Hz and V in the coordinate system of the surveying device. This is performed by means of a distance measuring unit which is formed to receive transient signals of the emitting unit and ascertain at least one amplitude (intensity) and a runtime for a reflection from a target. The amplitude can be converted in this case into a reflectivity, as a target property, and can be compared, for example, to a threshold value preconfigured for a searched reflector target.</p><p id="p-0177" num="0176">In this case, more than one reflection can certainly also occur on the distance and/or time axis for one of the pixels, which reflections are well separated, however, using a distance measuring unit of the target search device, which measures at least to approximately 1 to 5 cm accuracy, in the reception signal and are accordingly separable from one another during the analysis on the basis of the location thereof on the time axis. In one embodiment, for example, the amplitudes of the incident reflections can be measured continuously, i.e., for each of the emission fans emitted in a different second direction or from laser emission to laser emission. In this case, in a simply designed embodiment, for example, an angular position of the movement of the emission fan in the second direction can be acquired, at which the intensity of a reflection decreases again after an increase&#x2014;which represents only one example for ascertaining a maximum of the reflection in the second direction of a pivot of the emission fan. In this case, as a further criterion moreover a predetermined requirement for the reflectivity ascertained for this reflection can be used as a condition for an acquisition of this reflection as a target. In the case of such an acquisition of a reflection of a target, the surveying instrument can then fix this angle, i.e., stop the movement of the axis system in the second direction and align the target axis of the surveying device on the target thus found.</p><p id="p-0178" num="0177">Using the multiple pixels of the position-resolving linear detector, which are provided in the first direction, for example, the vertical direction, according to the invention, in particular in combination with multiple distance measuring units each associated with one pixel and operating in parallel&#x2014;as described&#x2014;an at least roughly resolved alignment in the first direction along the emission fan is also ascertainable. Therefore, for example, an angle coordinate of the reflection in the vertical direction can be ascertained, for example, from a set angle on the first axis system of the surveying instrument supporting the target acquisition unit and the deposition measured by the target acquisition unit, which is ascertained via the irradiated pixels as described. The surveying device can then roughly align its two axis systems on the target thus found, or its coordinates in the first and second directions, respectively, and survey this target, for example, by the control being transferred to an automatic target recognition (ATR) of the surveying device.</p><p id="p-0179" num="0178"><figref idref="DRAWINGS">FIG. <b>10</b></figref> schematically shows a surveying device <b>101</b>, e.g. a theodolite or a total station, with an automatic target marker locator <b>102</b> and two target markers <b>103</b> and <b>105</b>, with which target points can be marked in the measuring environment, e.g. for geodetic surveying purposes. In the example, the target markers <b>103</b>, <b>105</b> have retro-reflectors <b>113</b> for this purpose, which can be sighted and measured by the surveying device <b>101</b> using a measuring beam which is not shown, so that the direction (based on the sighting direction) and distance (e.g. by time-of-flight or phase difference measurement) to the retro-reflector <b>123</b> and thus to the target can be determined with high accuracy.</p><p id="p-0180" num="0179">To perform the measurement, the measuring beam must first be aligned to the target marker <b>103</b>, <b>105</b>, i.e. the latter must be located. This can be carried out manually by a user, which is relatively time-consuming, or in some prior-art surveying devices automatically, e.g. using large-area illumination with target seeking radiation and detection thereof with an optical imaging unit with a large field of view. The optical imaging unit is designed as a camera, for example, which is either fixed relative to a telescope of the surveying device <b>101</b> or is pivotable freely about one or two axes, wherein the relative angles between the viewing direction of the camera and the telescope are measured. The central issue here is that associated offset angles with respect to the viewing direction of the telescope can be calculated for each pixel of the camera.</p><p id="p-0181" num="0180">One of the problems with this approach is that when multiple target markers <b>103</b>, <b>105</b> are present in the measuring environment, as shown, the surveying device <b>101</b> cannot distinguish which target marker <b>103</b> or <b>105</b> has been located. In addition, under certain circumstances it is also possible that extraneous light sources <b>120</b>, which emit extraneous radiation <b>121</b>, are incorrectly registered as a target marker. Thus, with prior-art methods confusion arises, which causes measured points to be assigned incorrectly, for example. Although techniques for the unambiguous identification of target markers <b>103</b>, <b>105</b> are known from the prior art, these are not sufficiently robust and/or require disproportionate additional effort.</p><p id="p-0182" num="0181">The second aspect of the present invention proposes a method in which a respective target marker <b>103</b>, <b>105</b> emits target marker radiation <b>104</b><i>a</i>, <b>106</b><i>a</i>, which is modulated in such a manner that it repeatedly exhibits a signature <b>104</b>, <b>106</b> characteristic of the respective active target marker <b>103</b>, <b>105</b>, wherein a phase-coded signature <b>104</b>, <b>106</b> is advantageously used in each case to minimize the effect of amplitude fluctuation and/or radiation interruptions. For this purpose, a respective target marker <b>103</b>, <b>105</b>, as shown, has e.g. a light source <b>122</b>, for example a high-power LED with a wide emission angle. The wavelength of the target-marker radiation <b>104</b><i>s</i>, <b>106</b><i>s </i>is preferably in the near-infrared range, e.g. it is 850 nm. The emission of the target-marker radiation <b>104</b><i>s</i>, <b>106</b><i>s </i>is started at the target marker <b>103</b>, <b>105</b> by a user or by remote control, e.g. from the surveying device <b>101</b>, i.e. by an external communication signal for the target marker <b>103</b>, <b>105</b>.</p><p id="p-0183" num="0182">The target marker locator <b>102</b> is designed according to the invention in such a manner that ambient radiation is detected by means of a spatially-resolving optoelectronic sensor and an evaluation unit (not shown here). In the example of one embodiment, for example, a commercially available camera chip <b>112</b> (e.g. with a CCD or CMOS-matrix image sensor) can be used (or an RGB camera sensitive to NIR, if applicable), which provides a resolution of approximately 1.4 &#x3bc;m/pixel with approx. 10 megapixels and a field of view of approx. 4 mm by 5 mm. A target-seeking camera according to the invention is therefore e.g. a fast CCD or CMOS camera with or without a (modified) Bayer mask. Alternatively, the sensor is designed as a two-dimensional photodetector array or as a Dynamic Vision Sensor (event-based camera). As an alternative to the illustration, the target marker locator is a separate or separable unit.</p><p id="p-0184" num="0183">Optionally, the target marker locator <b>102</b> or a camera of the target marker locator <b>102</b> has a long-pass filter that can be switched off. As an additional option, the device <b>102</b> has a near-infrared corrected lens. Also, a target marker location camera can be an overview camera, e.g. the same overview camera as is already available in some prior-art surveying devices <b>101</b> anyway. As a further option, in addition to the signature <b>104</b>, <b>106</b> the target-marker radiation <b>104</b><i>s</i>, <b>106</b><i>s </i>also contains useful data (e.g. information about the target marker or sensor data), which can be read out by the surveying device <b>101</b>. In other words, the radiation <b>104</b><i>s</i>, <b>106</b><i>s </i>can be used for data transmission in addition to the identification by means of a signature.</p><p id="p-0185" num="0184">Radiation detected by the sensor is evaluated in such a way, e.g. by means of an image processing system or evaluation electronics, that a respective target-marker radiation <b>104</b><i>s</i>, <b>106</b><i>s </i>is reliably detected by means of the unique signature <b>104</b>, <b>106</b> known to the evaluation unit, and thus the target-marker radiation <b>104</b><i>s</i>, <b>106</b><i>s </i>or target marker <b>103</b>, <b>105</b> is reliably identified and thus also, for example, extraneous light radiation <b>121</b> or a foreign object <b>120</b> is reliably rejected. The method according to the invention will be explained in further detail by way of example by reference to the following figures.</p><p id="p-0186" num="0185"><figref idref="DRAWINGS">FIG. <b>11</b></figref> shows an example of a sequence of the method <b>107</b> for locating a target marker <b>103</b>, <b>105</b> on the basis of its radiation <b>104</b><i>s</i>, <b>106</b><i>s </i>or, more precisely, on the basis of the unique signature <b>104</b>, <b>106</b> transmitted therewith (see <figref idref="DRAWINGS">FIG. <b>10</b></figref>).</p><p id="p-0187" num="0186">In step <b>108</b>, a first series of images is recorded, which takes place at a first frame rate. For example, the first frame rate is 45 or 65 Hz, which is advantageous in terms of target-marker radiation that is generated by mains-powered light sources. Preferably, the first frame rate and signature of the target marker radiation are tailored to each other by matching the modulation rate of the radiation to the first frame rate. Preferably, the recording of the first series of images takes long enough to ensure that the recurrently emitted signature is also detected multiple times/repeatedly. The following target marker location becomes more robust by multiple detection of the signal sequence.</p><p id="p-0188" num="0187">Images from the first image sequence are analyzed in step <b>109</b>. In this first evaluation stage, a statistical evaluation of pixels is carried out, wherein a quality function is determined with regard to a given known signature of the target marker radiation. The value of the quality function for a particular pixel indicates a probability that target-marker radiation is detected with this pixel. Thus, in step <b>110</b>, a statistical test is performed on the basis of a plurality of consecutively recorded images to determine whether one or which pixel(s) has/have a signal characteristic corresponding to the stored signature. In the example, symbol <b>111</b> represents pixels that are unlikely to have detected target-marker radiation, and symbol <b>112</b> represents pixels for which the test result or the quality function value suggests that the temporal profile of the pixel signal is produced by the signature, and thus target-marker radiation is detected with them.</p><p id="p-0189" num="0188">In this case, a relatively high degree of uncertainty is preferably permitted at this first test stage <b>110</b>, i.e. such pixels which have tested positive with a probability of 50%, for example, are also permitted in the target-marker radiation class <b>112</b>. The primary objective of this evaluation stage is that no target-marker radiation is &#x201c;lost&#x201d;. The quality threshold is therefore chosen to be low, so that all target markers in the measuring environment are detected. In this step, it is accepted that some artifacts, e.g. interference radiation <b>121</b> (see <figref idref="DRAWINGS">FIG. <b>10</b></figref>), will possibly also be incorrectly tested as &#x201c;positive&#x201d;, i.e. pixels will be identified as detecting target-marker radiation although this is actually not the case.</p><p id="p-0190" num="0189">In order to classify the target markers robustly, i.e. to exclude artifacts classified as possible target markers, in step <b>113</b> a further image series is recorded with a different frame rate, preferably with a considerably higher frame rate (e.g. 10 times the first frame rate and/or in the range of several kilohertz). Here also, the frame rate and signature are preferably tailored to each other, for which the signature, for example, has a component tailored to the first frame rate and a component tailored to the second signature.</p><p id="p-0191" num="0190">Afterwards, an evaluation (step <b>114</b>) of intensity signals of the second image sequence is performed (at least) for those pixels that are identified as target marker pixels in the first evaluation stage. In step <b>115</b>, the intensity signal of the pixel is checked for correspondence with a stored signature and if the evaluation is positive, it is confirmed (field <b>117</b>) that the pixel has actually detected target-marker radiation and the corresponding target marker is thus identified and located. Otherwise, the pixel is classified as an artifact or discarded (field <b>116</b>). A preferably high frame rate of several hundred or thousand hertz enables a detailed intensity signal to be created, so that in the second test <b>115</b> radiation signature can be distinguished from non-signature with high certainty.</p><p id="p-0192" num="0191">It is advantageous that due to the first test stage <b>110</b> the recording of the second image sequence is able to be limited to the identified pixels. This means that the pixels that are considered as potential &#x201c;target-marker radiation candidates&#x201d;, which are determined in the first part of the method, are optionally used as a (center of a) region of interest for which (and only for which) the second image series is then recorded.</p><p id="p-0193" num="0192">The images from the second image sequence are recorded with a narrowed field of view, which is smaller than the first field of view of the first image sequence (the first field of view is preferably the maximum field of view of the image sensor or target locator, e.g. 5 megapixels, to ensure that the largest possible area of the environment is covered and/or that all existing target markers are detected as far as possible). The position of the second field of view depends on a particular pixel selected on the basis of the first series of images. The identified pixels thus specify, for example, where in the image the segment is located (compared to the first images). The segment can be limited to the identified pixel or pixels, or else a pixel region around such pixels is recorded, e.g. a region (or region of interest) of 20&#xd7;20 pixels.</p><p id="p-0194" num="0193">The advantage of such a small second field of view is that it results in considerably less data compared to a full image. This enables faster processing and/or the frame rate for the second image series can be increased even further, which can be advantageous for robust detection of the target-marker radiation. For example, with regard to tailoring the modulation rate and frame rate, signatures can be implemented with &#x201c;high&#x201d; modulation, which enable more robust identification of signatures.</p><p id="p-0195" num="0194"><figref idref="DRAWINGS">FIGS. <b>12</b><i>a</i>-<b>12</b><i>c </i></figref>show a further exemplary representation of a target location method according to the invention.</p><p id="p-0196" num="0195"><figref idref="DRAWINGS">FIG. <b>12</b><i>a </i></figref>shows a first image sequence <b>118</b> created at a first frame rate R<b>1</b> along a time axis t, the individual images <b>119</b> in the example being difference images, which are created pixel-by-pixel from two or more consecutively recorded images in each case.</p><p id="p-0197" num="0196">In the first difference images <b>119</b>, which are produced by forming the difference between the images recorded with the image sensor, four pixels P<b>1</b>-P<b>4</b> are identified as examples, the signals S of which will be examined in greater detail (wherein a black-to-white change is intended to illustrate a difference). The remaining pixels in the example have also been exposed, but for the sake of simplicity it will be assumed that these other pixels do not show any changes at all during the period of the image series in question.</p><p id="p-0198" num="0197">The lower part of <figref idref="DRAWINGS">FIG. <b>12</b><i>a </i></figref>illustrates symbolically that the signals S of the pixels P<b>1</b>-P<b>4</b> are analyzed with regard to the known signatures <b>104</b>, <b>106</b>, and a quality function G is derived for each pixel P<b>1</b>-P<b>4</b>. The quality function G is used to test whether a given pixel has (probably) detected target-marker radiation. In the example, to do so it is tested whether the quality function exceeds a defined threshold value Gd or not. In the example, the detected signal for pixel P<b>4</b> does not have sufficient resemblance (similarity) with either of the two signatures and is therefore classified as an artifact. The other three pixels P<b>1</b>-P<b>3</b>, on the other hand, are classified into the class &#x201c;target marker radiation&#x201d; by virtue of their value of the quality function G and are identified as pixels P<b>1</b>-P<b>3</b>, which have (presumably) acquired target marker radiation. As already described above, the threshold for the class &#x201c;target marker radiation&#x201d; is set to a low value in order to reliably include any possible target marker radiation, and the classification is therefore considered as a &#x201c;rough&#x201d; or preliminary classification.</p><p id="p-0199" num="0198"><figref idref="DRAWINGS">FIG. <b>12</b><i>b </i></figref>illustrates how a second sequence of images <b>120</b> is created for the three pixel &#x201c;candidates&#x201d; P<b>1</b>-P<b>3</b> which have entered the second &#x201c;round&#x201d;, in the example again in the form of difference images <b>121</b>. In this case, as shown by the hatching, the maximum field of view is not used, rather radiation is only detected selectively for the pixels P<b>1</b>-P<b>3</b>. The recording with a selectively restricted second field of view can be carried out sequentially for the individual pixels or regions of interest (i.e. first align field of view on/around pixel P<b>1</b>, then on pixel P<b>2</b>, etc.). The second frame rate R<b>2</b> in this case is, as indicated, much higher than the first frame rate R<b>1</b>.</p><p id="p-0200" num="0199">The intensity I derived from the difference images <b>121</b> for each individual pixel P<b>1</b>-P<b>3</b> is then analyzed with regard to the signatures <b>104</b>, <b>106</b> (shown in the lower part of <figref idref="DRAWINGS">FIG. <b>12</b><i>b</i></figref>). In the example, a correspondence of the intensity I of pixel P<b>1</b> with the signature <b>104</b> is determined and correspondence of the intensity I of pixel P<b>2</b> with the signature <b>106</b> (value in each case above a defined threshold value T). P<b>1</b> is therefore recognized as belonging to the signature <b>104</b> or the (total) signal of pixel P<b>1</b> as being caused by the signature <b>104</b>, and P<b>2</b> is assigned to the signature <b>106</b> accordingly. Radiation of the target marker <b>103</b> is thus identified with the pixel P<b>1</b> (cf. <figref idref="DRAWINGS">FIG. <b>1</b></figref>) and radiation of the target marker <b>105</b> with the pixel P<b>2</b>.</p><p id="p-0201" num="0200">By contrast, for pixel P<b>3</b> no correspondence of the intensity signal I with either of the two stored signatures <b>104</b> or <b>106</b> is determined (value with regard to both signature <b>104</b> and signature <b>106</b> below the threshold value T). Thus, with the second &#x201c;finer&#x201d; test stage, which is based on the second image sequence, this sensor signal of pixel P<b>3</b> was able to be &#x201c;weeded out&#x201d; as an artifact.</p><p id="p-0202" num="0201"><figref idref="DRAWINGS">FIGS. <b>12</b><i>a</i>, <b>12</b><i>b </i></figref>thus represent a further example of the procedure according to the invention, in which a large field of view is first used to cover a broad measuring environment region and a &#x201c;pre-test&#x201d; with regard to target-marker radiation is carried out with comparatively few images <b>119</b>, in order then to perform a robust targeted test on the remaining segments of the measuring environment with a high temporal coverage using a dense image sequence <b>120</b>.</p><p id="p-0203" num="0202">The use of difference images <b>121</b> while using a phase-coded signature <b>104</b>, <b>106</b> has the advantage that an analysis with regard to target signature is thereby possible even without prior synchronization, wherein optionally a given signature <b>104</b>, <b>106</b> has a start and/or end pointer which indicates the start and/or end of the signature, e.g. in the manner of so-called &#x201c;framing bits&#x201d;. For example, it is thus not necessary that the recording of the first and/or second image sequence and the emission of the target-marker radiation or the signatures <b>104</b>, <b>106</b> are started synchronously or, expressed more generally, the proposed method eliminates the need for complex communication between the target marker and the target marker locator. If, for example, the emission of the target-marker radiation is started manually as mentioned above, any communication at all between the target marker and the target marker locator can be omitted. In addition, it is thus possible to eliminate bit errors as a result of slightly different clock frequencies of the target marker and the receiver purely on the receiver side, without communication between the two.</p><p id="p-0204" num="0203">As shown in <figref idref="DRAWINGS">FIGS. <b>12</b><i>a </i>and <b>12</b><i>b </i></figref>at the bottom, according to the respective frame rate R<b>1</b>, R<b>2</b> for the first test stage (<figref idref="DRAWINGS">FIG. <b>12</b><i>a</i></figref>), the &#x201c;low-frequency&#x201d; component <b>104</b><i>a</i>, <b>106</b><i>a </i>of the signature <b>104</b>, <b>106</b> is used primarily or exclusively for the test, whereas in the second test stage (<figref idref="DRAWINGS">FIG. <b>3</b><i>b</i></figref>) the &#x201c;high-frequency&#x201d; component <b>104</b><i>b</i>, <b>106</b><i>b </i>of the signature <b>104</b>, <b>106</b> is used.</p><p id="p-0205" num="0204">As shown schematically in <figref idref="DRAWINGS">FIG. <b>12</b><i>c</i></figref>, contrary to the greatly simplified representation of <figref idref="DRAWINGS">FIG. <b>12</b><i>b</i></figref>, the second field of view Z is preferably not limited only to a pixel P<b>1</b> identified using the first image sequence, but also comprises a region Z or a number of pixels around it. As shown in the example, the identified pixel P<b>1</b> does not need to be located in the center of the region and the second field of view Z does not need to be square.</p><p id="p-0206" num="0205">For example, in the case of moving target markers, the first image sequence is optionally used to determine a direction of motion and also speed for a respective detected radiation, and the position and size (shape) of the field of view is adjusted on the basis of these parameters. If, for example, the determined target marker speed is relatively high, the field of view is also set relatively large, if the radiation on the sensor is moving &#x201c;upwards&#x201d;, the field of view around the pixel P<b>1</b> is extended or shifted &#x201c;upwards&#x201d; as shown. Thus, the second field of view is optimally adjusted to the movement of the radiation source/target marker.</p><p id="p-0207" num="0206"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows a further extension of the method. In the example, the position of those respective pixels which are clearly identified in step <b>117</b> (see <figref idref="DRAWINGS">FIG. <b>11</b></figref>) as pixels of a target marker <b>103</b> is used to determine a direction to the respective target marker <b>103</b>, e.g. in the form of polar and azimuthal angles (wherein the direction can be determined not just after step <b>117</b>, but also, for example, directly after the identification of potential target marker pixels; see step <b>12</b> in <figref idref="DRAWINGS">FIG. <b>11</b></figref>). For example, the evaluation unit of the surveying device <b>101</b> (see <figref idref="DRAWINGS">FIG. <b>10</b></figref>) is thus designed to determine a direction to the target marker based on the position of the identified pixel. This is optionally used to control, for example, based on a deviation of the pixel from a central pixel/sensor position (a zero point of the image sensor), an alignment of the target marker locator <b>102</b> or surveying device <b>101</b> in such a manner that the deviation is corrected. In other words, using the optionally determined direction to the target <b>103</b>, the surveying device <b>101</b> can be aligned centrally to the target marker <b>103</b>.</p><p id="p-0208" num="0207">Alternatively or in addition, in the case of a moving target marker <b>103</b>, the position or positions of the relevant pixel on the sensor is/are used to continuously track the moving target marker <b>103</b>, wherein based on the temporal change of the pixel position, an (at least coarse) speed of the target marker, at least normal to the viewing direction, is also determined. The target locator <b>102</b> in these embodiments is therefore used not only for target location, but also for tracking the target marker <b>103</b>. Especially in the case of a target locator <b>102</b> with a very large field of view (overview camera), it is also possible to track multiple target markers <b>103</b> at the same time, or to switch very quickly between the tracking of multiple target markers <b>103</b> even if they are moving in different directions.</p><p id="p-0209" num="0208">The figures above represent only possible exemplary embodiments schematically. Unless otherwise noted, the different approaches can also be combined with each other as well as with known methods and devices.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for automatically locating at least one target marker, comprising:<claim-text>emission of radiation by the target marker, wherein by means of modulation, the radiation recurrently has a characteristic signature;</claim-text><claim-text>recording a first image sequence with a first frame rate;</claim-text><claim-text>statistically evaluating the first image sequence by reference to the signature with determination of a quality function, wherein the value of the quality function specifies a probability that target marker radiation is detected in a respective pixel;</claim-text><claim-text>identifying pixels with which target marker radiation is likely detected, based on the associated value of the quality function;</claim-text><claim-text>recording a second image sequence with a second frame rate, different from the first frame rate;</claim-text><claim-text>evaluating intensity signals of the second image sequence for said identified pixels; and</claim-text><claim-text>identifying the target marker radiation using the intensity signals on the basis of the signature.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the recording of the second image sequence is carried out with at least one second field of view which is smaller than a first field of view of the recording of the first image sequence, wherein a position of the at least one second field of view corresponds to the respective identified pixel.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the signature has at least one of:<claim-text>a first component adjusted to the first frame rate, and a second component adjusted to the second frame rate, and</claim-text><claim-text>a start or end indicator.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the second frame rate is at least ten times as high as the first frame rate, or</claim-text><claim-text>the first frame rate is in the range between 45 Hz and 65 Hz or the second frame rate is at least 1 kHz.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the recording of the first and second image sequence is not synchronized with the emission of the target marker radiation or is synchronized via a separate, independent communication channel.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the evaluation of the first or second image sequence is carried out by means of difference images; or</claim-text><claim-text>the recording of the first or second image sequence takes place over a period in which the emission of the signature is repeated multiple times.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the quality function is dependent on the first frame rate.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>an automatic tracking of the target marker is carried out on the basis of the identified target marker radiation or by means of the first or second image sequence, on the basis of identified pixels a direction to the target marker is determined.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. A target marker locator comprising:<claim-text>a spatially-resolving optoelectronic sensor for detecting target marker radiation having a known characteristic signature, wherein the spatially-resolving optoelectronic records a first image sequence with a first frame rate and record a second image sequence with a second frame rate different from the first frame rate; and</claim-text><claim-text>evaluation electronics configured to:<claim-text>statistically evaluate the first image sequence, wherein a quality function is determined, the value of which indicates a probability that target marker radiation is detected in a respective pixel, for which purpose the signature is stored in the evaluation electronics,</claim-text><claim-text>based on the associated value of the quality function to identify pixels with which target marker radiation is likely detected,</claim-text><claim-text>evaluate intensity signals of the second image sequence for said identified pixels, and</claim-text><claim-text>to identify target marker radiation from the intensity signals based on the signature.</claim-text></claim-text></claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The target marker locator of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the target marker locator has a long-pass filter that can be switched off, a near-infrared-corrected lens, or<claim-text>the sensor is part of an overview camera.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The target marker locator of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the evaluation electronics is further configured to determine a direction to the target marker based on a position of an identified pixel on the sensor.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The target marker locator of <claim-ref idref="CLM-00009">claim 9</claim-ref>, further comprising a modulatable beam source for emitting target marker radiation, wherein the modulation of the modulatable beam source causes the target marker radiation to have a characteristic multi-level signature.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The target marker locator of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the modulatable beam source is a near-infrared beam source</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The target marker locator of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the modulation is phase modulation.</claim-text></claim></claims></us-patent-application>
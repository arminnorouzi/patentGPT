<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001790A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001790</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17774016</doc-number><date>20201110</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>JP</country><doc-number>2019-201004</doc-number><date>20191105</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>K</subclass><main-group>35</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>02</class><subclass>B</subclass><main-group>27</main-group><subgroup>01</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>02</class><subclass>B</subclass><main-group>27</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>02</class><subclass>B</subclass><main-group>30</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>K</subclass><main-group>35</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>02</class><subclass>B</subclass><main-group>27</main-group><subgroup>0101</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>02</class><subclass>B</subclass><main-group>27</main-group><subgroup>0093</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200101</date></cpc-version-indicator><section>G</section><class>02</class><subclass>B</subclass><main-group>30</main-group><subgroup>30</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190501</date></cpc-version-indicator><section>B</section><class>60</class><subclass>K</subclass><main-group>2370</main-group><subgroup>1529</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190501</date></cpc-version-indicator><section>B</section><class>60</class><subclass>K</subclass><main-group>2370</main-group><subgroup>31</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190501</date></cpc-version-indicator><section>B</section><class>60</class><subclass>K</subclass><main-group>2370</main-group><subgroup>334</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20190501</date></cpc-version-indicator><section>B</section><class>60</class><subclass>K</subclass><main-group>2370</main-group><subgroup>347</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>02</class><subclass>B</subclass><main-group>2027</main-group><subgroup>0129</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">HEAD-UP DISPLAY, HEAD-UP DISPLAY SYSTEM, AND MOVABLE BODY</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>KYOCERA CORPORATION</orgname><address><city>Kyoto-shi, Kyoto</city><country>JP</country></address></addressbook><residence><country>JP</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KUSAFUKA</last-name><first-name>Kaoru</first-name><address><city>Setagaya-ku, Tokyo</city><country>JP</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>OGURA</last-name><first-name>Kenji</first-name><address><city>Ritto-shi, Shiga</city><country>JP</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>TADAUCHI</last-name><first-name>Ryo</first-name><address><city>Otsu-shi, Shiga</city><country>JP</country></address></addressbook></inventor></inventors></us-parties><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/JP2020/041872</doc-number><date>20201110</date></document-id><us-371c12-date><date>20220503</date></us-371c12-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A first input unit in a head-up display obtains a distance to an object. A second input unit obtains a user's eye position. An optical system projects, into the user's field of view, a virtual image of an image displayed on a display panel. A processor causes the display panel to display a parallax image. An optical element causes a first image displayed on the display panel to reach the user's first eye and a second image on the display panel to reach the user's second eye. The processor causes the display panel to display an image element in the parallax image as at least partially superimposed on the object. The processor performs first control to fix, in response to the distance to the object greater than or equal to a predetermined first distance, parallax of the image element to a value other than 0 corresponding to the first distance.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="181.61mm" wi="146.13mm" file="US20230001790A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="209.80mm" wi="141.48mm" orientation="landscape" file="US20230001790A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="209.80mm" wi="142.83mm" orientation="landscape" file="US20230001790A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="215.82mm" wi="146.30mm" orientation="landscape" file="US20230001790A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="200.66mm" wi="149.86mm" orientation="landscape" file="US20230001790A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="215.56mm" wi="138.77mm" orientation="landscape" file="US20230001790A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="221.23mm" wi="151.30mm" orientation="landscape" file="US20230001790A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="225.13mm" wi="154.52mm" orientation="landscape" file="US20230001790A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="213.36mm" wi="151.30mm" orientation="landscape" file="US20230001790A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="223.94mm" wi="152.32mm" file="US20230001790A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="240.03mm" wi="158.07mm" orientation="landscape" file="US20230001790A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="234.02mm" wi="156.29mm" orientation="landscape" file="US20230001790A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="216.49mm" wi="142.07mm" orientation="landscape" file="US20230001790A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="201.00mm" wi="154.26mm" orientation="landscape" file="US20230001790A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="219.29mm" wi="151.55mm" orientation="landscape" file="US20230001790A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="224.45mm" wi="149.69mm" orientation="landscape" file="US20230001790A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">FIELD</heading><p id="p-0002" num="0001">The present disclosure relates to a head-up display, a head-up display system, and a movable body.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">A known technique is described in, for example, Patent Literature 1.</p><heading id="h-0003" level="1">CITATION LIST</heading><heading id="h-0004" level="1">Patent Literature</heading><p id="p-0004" num="0000"><ul id="ul0001" list-style="none">    <li id="ul0001-0001" num="0003">Patent Literature 1: Japanese Unexamined Patent Application Publication No. 2009-008722</li></ul></p><heading id="h-0005" level="1">BRIEF SUMMARY</heading><p id="p-0005" num="0004">A head-up display according to an aspect of the present disclosure includes a first input unit, a second input unit, a display panel, an optical system, a processor, and an optical element. The first input unit obtains first positional information about a position of an object including a distance to the object. The second input unit obtains second positional information about a position of at least a first eye or a second eye of a user. The optical system projects, into a field of view of the user, a virtual image of an image displayed on the display panel. The processor causes the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image. The optical element causes, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user. The processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information. The processor performs first control to fix, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</p><p id="p-0006" num="0005">A head-up display system according to another aspect of the present disclosure includes a first detector, a second detector, and a head-up display. The first detector detects first positional information about a position of an object including a distance to the object. The second detector detects second positional information about a position of at least a first eye or a second eye of a user. The head-up display includes a first input unit, a second input unit, a display panel, an optical system, a processor, and an optical element. The first input unit obtains the first positional information from the first detector. The second input unit obtains the second positional information from the second detector. The optical system projects, into a field of view of the user, a virtual image of an image displayed on the display panel. The processor causes the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image. The optical element causes, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user. The processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information. The processor fixes, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</p><p id="p-0007" num="0006">A movable body according to another aspect of the present disclosure includes a head-up display system. The head-up display system includes a first detector, a second detector, and a head-up display. The first detector detects first positional information about a position of an object including a distance to the object. The second detector detects second positional information about a position of at least a first eye or a second eye of a user. The head-up display includes a first input unit, a second input unit, a display panel, an optical system, a processor, and an optical element. The first input unit obtains the first positional information from the first detector. The second input unit obtains the second positional information from the second detector. The optical system projects, into a field of view of the user, a virtual image of an image displayed on the display panel. The processor causes the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image. The optical element causes, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user. The processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information. The processor fixes, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0008" num="0007">The objects, features, and advantages of the present disclosure will become more apparent from the following detailed description and the drawings.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a diagram of an example head-up display (HUD) system mounted on a movable body.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a schematic diagram of a display device shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a diagram of an example display panel shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> viewed in the depth direction.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a diagram of an example parallax barrier shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> viewed in the depth direction.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a diagram describing the relationship between a virtual image and a user's eyes shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a diagram showing an area viewable with a left eye in the virtual image for the display panel.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a diagram showing an area viewable with a right eye in the virtual image for the display panel.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a diagram describing switching of a display of subpixels in response to a change in the positions of the user's eyes.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a diagram describing a method for displaying a parallax image when an object is located at an optimum viewing distance.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a diagram describing a method for displaying a parallax image when an object is located at a distance between a first distance and a second distance.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a diagram describing a method for displaying a parallax image when an object is located at a distance greater than or equal to the first distance.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a diagram describing an example image element superimposed on an object viewable by the user when the object is located at a distance greater than or equal to the first distance.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart of a method for displaying a parallax image.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is a schematic diagram of a HUD system including a liquid crystal shutter as a parallax barrier.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is an example operating state of the liquid crystal shutter.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0024" num="0023">As a head-up display (HUD) with the structure that forms the basis of a HUD according to one or more embodiments of the present disclosure, a known HUD causes images having parallax between them to reach the left and right eyes of a user and projects a virtual image in the field of view of the user to be viewed as a three-dimensional (3D) image with depth.</p><p id="p-0025" num="0024">The HUD that displays a 3D image as a virtual image in the field of view of a user may display a 3D image superimposed at the position of an object within the field of view. In this case, the HUD displays, at the position at which the object is viewable from the user, an image having parallax corresponding to the distance to the object. The processing load in superimposing a 3D image on an object is to be low.</p><p id="p-0026" num="0025">In response to this, one or more aspects of the present disclosure are directed to a HUD, a HUD system, and a movable body that reduce the processing load associated with displaying a 3D image superimposed on an object.</p><p id="p-0027" num="0026">One or more embodiments of the present disclosure will now be described with reference to the drawings. The drawings used herein are schematic and are not drawn to scale relative to the actual size of each component.</p><heading id="h-0008" level="2">Structure of HUD System</heading><p id="p-0028" num="0027">As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a HUD system <b>100</b> according to an embodiment of the present disclosure includes a first detector <b>1</b>, a second detector <b>2</b>, and a HUD <b>3</b>. The HUD system <b>100</b> may be mounted on a movable body <b>20</b>. In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, x-direction refers to an interocular direction, or the direction along a line passing through a left eye <b>311</b> and a right eye <b>31</b><i>r </i>of a user <b>30</b>, z-direction refers to the front-rear direction as viewed from the user <b>30</b>, and y-direction refers to the height direction perpendicular to x-direction and z-direction. The same definition applies to x-, y-, and z-directions in <figref idref="DRAWINGS">FIGS. <b>5</b> to <b>11</b></figref> referred to below.</p><heading id="h-0009" level="2">First Detector</heading><p id="p-0029" num="0028">The HUD system <b>100</b> includes the first detector <b>1</b> to detect positional information about an object <b>40</b> located in front of the user <b>30</b> (z-direction). The positional information about the object <b>40</b> includes information about the distance from the movable body <b>20</b> or the user <b>30</b> to the object <b>40</b>. The first detector <b>1</b> outputs the positional information about the object <b>40</b> to the HUD <b>3</b> as first positional information. The first detector <b>1</b> may be a distance measuring device. The distance measuring device may include, for example, a stereo camera, an infrared radar, a millimeter wave radar, and a lidar. The distance measuring device may be a device that calculates distances based on images captured with multiple single-lens cameras. The first detector <b>1</b> may be a composite device including multiple distance measuring devices.</p><p id="p-0030" num="0029">The stereo camera includes multiple cameras that have parallax between them and cooperate with one another. The stereo camera includes at least two cameras. The stereo camera can capture an image of an object from multiple viewpoints using multiple cameras that cooperate with one another. The stereo camera can detect the distance to an object based on information about the arrangement of the multiple cameras and the parallax of the object included in an image captured by each of the cameras.</p><p id="p-0031" num="0030">The lidar may use a pulsed laser beam to scan space and detect reflected light from an object. The lidar can detect the direction in which the object is present by detecting the direction in which the laser beam is reflected off the object. The lidar can detect the distance to the object by measuring the time taken for the laser beam to be reflected off the object and return. The lidar may be referred to as LiDAR (light detection and ranging or laser imaging detection and ranging).</p><p id="p-0032" num="0031">In one embodiment, the first detector <b>1</b> may be fixed in a front portion of the movable body <b>20</b> to have its direction of measurement being frontward from the movable body <b>20</b>. As shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the first detector <b>1</b> may be installed, for example, in an interior space of the movable body <b>20</b>. The first detector <b>1</b> may detect the position of the object <b>40</b> frontward from the movable body <b>20</b> through, for example, a windshield. In other embodiments, the first detector <b>1</b> may be fixed to a front bumper, a fender grille, a side fender, a light module, or a hood of the movable body <b>20</b>.</p><p id="p-0033" num="0032">The first detector <b>1</b> can detect the positions of various objects <b>40</b> located external to the movable body <b>20</b>. For the movable body <b>20</b> being a vehicle, the first detector <b>1</b> can detect, as objects <b>40</b>, another vehicle traveling ahead, pedestrians, road signs, and obstacles on the road. The first detector <b>1</b> can output positional information about an object <b>40</b>. The positional information about the object <b>40</b> can be expressed in the Cartesian coordinate system with the origin defined at any position of either the first detector <b>1</b> or the movable body <b>20</b>. The position of the object <b>40</b> can be expressed in the polar coordinate system with the origin defined at any position of either the first detector <b>1</b> or the movable body <b>20</b>.</p><p id="p-0034" num="0033">The first detector <b>1</b> may be used commonly by a system other than the HUD system <b>100</b>. For the movable body <b>20</b> being a vehicle, for example, the first detector <b>1</b> may be used commonly by a system for, for example, brake control, inter-vehicle control with a preceding vehicle, or monitoring of the surrounding environment of the movable body <b>20</b>.</p><heading id="h-0010" level="2">Second Detector</heading><p id="p-0035" num="0034">The HUD system <b>100</b> includes the second detector <b>2</b> to detect the positions of eyes <b>31</b> of the user <b>30</b> observing a 3D image. The eyes <b>31</b> of the user <b>30</b> include the left eye <b>311</b> (first eye) and the right eye <b>31</b><i>r </i>(second eye) of the user <b>30</b>. The left eye <b>311</b> and the right eye <b>31</b><i>r </i>of the user <b>30</b> are herein collectively referred to as the eyes <b>31</b> without being distinguished from each other. The second detector <b>2</b> outputs the detected positions of the eyes <b>31</b> of the user <b>30</b> to the HUD <b>3</b>. For the HUD system <b>100</b> mounted on the movable body <b>20</b>, the user <b>30</b> may be a driver of the movable body <b>20</b>. The second detector <b>2</b> may include an imaging device or a sensor. The second detector <b>2</b> outputs positional information about the eyes <b>31</b> of the user <b>30</b> to the HUD <b>3</b> as second positional information.</p><p id="p-0036" num="0035">For the HUD system <b>100</b> mounted on a vehicle as the movable body <b>20</b>, the second detector <b>2</b> may be attached to a rearview mirror or to a nearby component. The second detector <b>2</b> may be attached to, for example, an instrument cluster. The second detector <b>2</b> may be attached to a center panel. The second detector <b>2</b> may be attached to a support of the steering wheel at the center of the steering wheel. The second detector <b>2</b> may be attached to a dashboard.</p><p id="p-0037" num="0036">For the second detector <b>2</b> including an imaging device such as a camera, the imaging device captures an image of a subject. The imaging device includes an image sensor. The image sensor may include, for example, a charge-coupled device (CCD) image sensor or a complementary metal-oxide semiconductor (CMOS) image sensor. The imaging device is arranged to have the face of the user <b>30</b> being at the position of the subject. The second detector <b>2</b> may detect the position of at least one of the left eye <b>311</b> or the right eye <b>31</b><i>r </i>of the user <b>30</b>. For example, the second detector <b>2</b> may define a predetermined position as the origin and detect the direction and the amount of displacement of the positions of the eyes <b>31</b> from the origin. The second detector <b>2</b> may detect the position of at least one of the left eye <b>311</b> or the right eye <b>31</b><i>r </i>using an image captured with the imaging device. The second detector <b>2</b> may detect, with two or more imaging devices, the position of at least one of the left eye <b>311</b> or the right eye <b>31</b><i>r </i>as the coordinates in a 3D space.</p><p id="p-0038" num="0037">The second detector <b>2</b> may include no camera and may be connected to an external camera. The second detector <b>2</b> may include an input terminal for receiving signals from an external imaging device. The external imaging device may be directly connected to the input terminal. The external imaging device may be connected to the input terminal indirectly through a shared network. The second detector <b>2</b> including no camera may detect the position of at least one of the left eye <b>311</b> or the right eye <b>31</b><i>r </i>from an image signal input into the input terminal.</p><p id="p-0039" num="0038">For the second detector <b>2</b> including a sensor, the sensor may be an ultrasonic sensor or an optical sensor. The second detector <b>2</b> may detect the position of the head of the user <b>30</b> with the sensor, and detect the position of at least one of the left eye <b>311</b> or the right eye <b>31</b><i>r </i>based on the position of the head. The second detector <b>2</b> may detect, with one sensor or two or more sensors, the position of at least one of the left eye <b>311</b> or the right eye <b>31</b><i>r </i>as the coordinates in a 3D space.</p><p id="p-0040" num="0039">The second detector <b>2</b> may detect, based on a detection result of the position of at least one of the left eye <b>311</b> or the right eye <b>31</b><i>r</i>, the moving distances of the left eye <b>311</b> and the right eye <b>31</b><i>r </i>in the direction in which the eyes are aligned.</p><p id="p-0041" num="0040">The first detector <b>1</b> and the second detector <b>2</b> can communicate with the HUD <b>3</b> in a wired or wireless manner or through a communication network such as a controller area network (CAN).</p><heading id="h-0011" level="2">HUD</heading><p id="p-0042" num="0041">The HUD <b>3</b> in one embodiment includes a reflector <b>4</b>, an optical member <b>5</b>, and a display device <b>6</b>. The reflector <b>4</b> and the optical member <b>5</b> are included in an optical system in the HUD <b>3</b>. The optical system in the HUD <b>3</b> may include optical elements such as a lens and a mirror, in addition to the reflector <b>4</b> and the optical member <b>5</b>. In another embodiment, the optical system in the HUD <b>3</b> may include a lens instead of or in addition to the reflector <b>4</b>.</p><p id="p-0043" num="0042">The reflector <b>4</b> reflects image light emitted from the display device <b>6</b> toward a predetermined area on the optical member <b>5</b>. The predetermined area reflects image light toward the eyes <b>31</b> of the user <b>30</b>. The predetermined area may be defined by the direction in which the eyes <b>31</b> of the user <b>30</b> are located relative to the optical member <b>5</b> and the direction in which image light is incident on the optical member <b>5</b>. The reflector <b>4</b> may be a concave mirror. The optical system including the reflector <b>4</b> may have a positive refractive index.</p><p id="p-0044" num="0043">The reflector <b>4</b> may include a drive <b>15</b> (refer to <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The reflector <b>4</b> may adjust the angle of the reflective surface with the drive <b>15</b>. The drive <b>15</b> may adjust the direction in which image light is reflected toward the optical member <b>5</b> in accordance with the positions of the eyes <b>31</b> detected by the second detector <b>2</b>. The drive <b>15</b> may adjust the direction in which image light is reflected toward the optical member <b>5</b> based on the first positional information detected by the first detector <b>1</b> and the second positional information detected by the second detector <b>2</b>.</p><p id="p-0045" num="0044">The optical member <b>5</b> reflects image light emitted from the display device <b>6</b> and reflected by the reflector <b>4</b> toward the left eye <b>311</b> and the right eye <b>31</b><i>r </i>of the user <b>30</b>. For example, the movable body <b>20</b> may include a windshield as the optical member <b>5</b>. The optical member <b>5</b> may include a plate-like combiner for a HUD inside the windshield. The HUD <b>3</b> directs light emitted from the display device <b>6</b> to the left eye <b>311</b> and the right eye <b>31</b><i>r </i>of the user <b>30</b> along an optical path P. The user <b>30</b> can view light reaching the eyes along the optical path P as a virtual image.</p><p id="p-0046" num="0045">The arrangement and the structure of the optical system in the HUD <b>3</b> including the reflector <b>4</b> and the optical member <b>5</b> determine the position of a virtual image plane on which image light emitted from the display device <b>6</b> forms a virtual image. In the present embodiment, the virtual image plane may be at a distance of 7.5 m from the eyes <b>31</b> of the user <b>30</b> frontward from the user <b>30</b>.</p><heading id="h-0012" level="2">Display Device</heading><p id="p-0047" num="0046">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the display device <b>6</b> may include a first input unit <b>7</b>, a second input unit <b>8</b>, an illuminator <b>9</b>, a display panel <b>10</b>, a parallax barrier <b>11</b> as an optical element, a controller <b>12</b>, a memory <b>13</b>, and an output unit <b>14</b>.</p><p id="p-0048" num="0047">The first input unit <b>7</b> can receive the first positional information about the position of the object <b>40</b> including a distance to the object <b>40</b> detected by the first detector <b>1</b>. The second input unit <b>8</b> can receive the second positional information about the eyes <b>31</b> of the user <b>30</b> detected by the second detector <b>2</b>.</p><p id="p-0049" num="0048">The first input unit <b>7</b> can communicate with the first detector <b>1</b>, and the second input unit <b>8</b> can communicate with the second detector <b>2</b>, in accordance with the communication schemes used by the respective detectors. The first input unit <b>7</b> and the second input unit <b>8</b> each include an interface for wired or wireless communication. The first input unit <b>7</b> and the second input unit <b>8</b> may each include a connector for wired communication, such as an electrical connector or an optical connector. The first input unit <b>7</b> and the second input unit <b>8</b> may each include an antenna for wireless communication. The first input unit <b>7</b> and the second input unit <b>8</b> may share either some or all of their components.</p><p id="p-0050" num="0049">The output unit <b>14</b> outputs a drive signal to the drive <b>15</b>, which adjusts the orientation of the reflector <b>4</b>. The output unit <b>14</b> may use a physical connector and wireless communication. In one embodiment, the output unit <b>14</b> may be connected to a vehicle network such as a CAN. The drive <b>15</b> is controlled by the controller <b>12</b> through the output unit <b>14</b>.</p><p id="p-0051" num="0050">The illuminator <b>9</b> may illuminate the display panel <b>10</b> with planar illumination light. The illuminator <b>9</b> may include a light source, a light guide plate, a diffuser plate, and a diffuser sheet. The illuminator <b>9</b> emits, from its light source, illumination light that then spreads uniformly for illuminating the surface of the display panel <b>10</b> using, for example, the light guide plate, the diffuser plate, or the diffuser sheet. The illuminator <b>9</b> may emit the uniform light toward the display panel <b>10</b>.</p><p id="p-0052" num="0051">The display panel <b>10</b> may be, for example, a transmissive liquid crystal display panel. The display panel <b>10</b> is not limited to a transmissive liquid crystal panel, and may be a self-luminous display panel. The self-luminous display panel may include an organic electroluminescent (EL) display and an inorganic EL display. For the display panel <b>10</b> being a self-luminous display panel, the display device <b>6</b> may not include the illuminator <b>9</b>.</p><p id="p-0053" num="0052">As shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the display panel <b>10</b> includes a planar active area A including multiple divisional areas. The divisional areas are areas with reference signs P<b>1</b> to P<b>12</b> in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The active area A can display a parallax image. The parallax image includes a left eye image and a right eye image (described later). The right eye image has parallax with respect to the left eye image. One of the left eye image and the right eye image is a first image. The other of the left eye image and the right eye image is a second image. In <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref>, the divisional areas are defined in u-direction and in v-direction orthogonal to u-direction. The direction orthogonal to u-direction and v-direction is referred to as w-direction. The u-direction may be referred to as a horizontal direction. The v-direction may be referred to as a vertical direction. The w-direction direction may be referred to as a depth direction. The same definition as in <figref idref="DRAWINGS">FIGS. <b>2</b> and <b>3</b></figref> applies to u-, v- and w-directions in <figref idref="DRAWINGS">FIGS. <b>4</b>, <b>14</b>, and <b>15</b></figref>.</p><p id="p-0054" num="0053">Each divisional area corresponds to a subpixel. Thus, the active area A includes multiple subpixels arranged in a lattice in u-direction and v-direction.</p><p id="p-0055" num="0054">Each subpixel has one of the colors red (R), green (G), and blue (B). One pixel may be a set of three subpixels with R, G, and B. A pixel may be referred to as a picture element. For example, multiple subpixels included in one pixel may be arranged in u-direction. Multiple subpixels having the same color may be arranged, for example, in v-direction.</p><p id="p-0056" num="0055">The multiple subpixels arranged in the active area A form multiple subpixel groups Pg under control by the controller <b>12</b>. The subpixel groups Pg are arranged repeatedly in u-direction. Each subpixel group Pg may be aligned with or shifted from the corresponding subpixel group Pg in v-direction. For example, the subpixel groups Pg are repeatedly arranged in v-direction at positions shifted by one subpixel in u-direction from the corresponding subpixel group Pg in adjacent rows. The subpixel groups Pg each include multiple subpixels in predetermined rows and columns. More specifically, the subpixel groups Pg each include (2&#xd7;n&#xd7;b) subpixels P<b>1</b> to PN (N=2&#xd7;n&#xd7;b), which are consecutively arranged in b rows in v-direction and in (2&#xd7;n) columns in u-direction. In the example shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, n is 6, and b is 1. The active area A in <figref idref="DRAWINGS">FIG. <b>3</b></figref> includes the subpixel groups Pg each including 12 subpixels P<b>1</b> to P<b>12</b> consecutively arranged in one row in v-direction and in 12 columns in u-direction. In the example shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, some of the subpixel groups Pg are denoted by reference signs.</p><p id="p-0057" num="0056">Each subpixel group Pg is the smallest unit controllable by the controller <b>12</b> to display an image. The subpixels included in each subpixel group Pg are identified using identification information P<b>1</b> to PN (N=2&#xd7;n&#xd7;b). The subpixels P<b>1</b> to PN (N=2&#xd7;n&#xd7;b) included in each subpixel group Pg with the same identification information are controlled by the controller <b>12</b> substantially at the same time. Being substantially at the same time is not limited to being exactly at the same time. For example, the subpixels P<b>1</b> to PN controlled substantially at the same time may include the subpixels being controlled using the same clocks. For example, the controller <b>12</b> can switch the image to be displayed by the multiple subpixels P<b>1</b> from the left eye image to the right eye image substantially at the same time in all the subpixel groups Pg.</p><p id="p-0058" num="0057">As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the parallax barrier <b>11</b> is planar along the active area A. The parallax barrier <b>11</b> is separate from the active area A by a gap g, or a distance. The parallax barrier <b>11</b> may be located opposite to the illuminator <b>9</b> from the display panel <b>10</b>. The parallax barrier <b>11</b> may be located between the display panel <b>10</b> and the illuminator <b>9</b>.</p><p id="p-0059" num="0058">The parallax barrier <b>11</b> defines the traveling direction of image light emitted from the multiple subpixels. As shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the parallax barrier <b>11</b> includes multiple light-reducing portions <b>11</b><i>b </i>extending in a predetermined direction for reducing image light. The light-reducing portions <b>11</b><i>b </i>define, between adjacent light-reducing portions <b>11</b><i>b</i>, transmissive portions <b>11</b><i>a </i>that are strip areas extending in a predetermined direction in the plane of the parallax barrier <b>11</b>. The transmissive portions <b>11</b><i>a </i>have a higher light transmittance than the light-reducing portions <b>11</b><i>b</i>. The transmissive portions <b>11</b><i>a </i>may have a light transmittance 10 or more times, or specifically 100 or more times, or more specifically 1000 or more times the light transmittance of the light-reducing portions <b>11</b><i>b</i>. The light-reducing portions <b>11</b><i>b </i>have a lower light transmittance than the transmissive portions <b>11</b><i>a</i>. The light-reducing portions <b>11</b><i>b </i>may block image light.</p><p id="p-0060" num="0059">The transmissive portions <b>11</b><i>a </i>and the light-reducing portions <b>11</b><i>b </i>extend in a predetermined direction along the active area A. The transmissive portions <b>11</b><i>a </i>and the light-reducing portions <b>11</b><i>b </i>are arranged alternately in a direction orthogonal to the predetermined direction. For example, the predetermined direction is along a diagonal of one subpixel when the display panel <b>10</b> and the parallax barrier <b>11</b> are viewed in the depth direction (w-direction). For example, the predetermined direction may be the direction that crosses t subpixels in v-direction while crossing s subpixels in u-direction (s and t are relatively prime positive integers) when the display panel <b>10</b> and the parallax barrier <b>11</b> are viewed in the depth direction (w-direction). The predetermined direction may be v-direction. The predetermined direction corresponds to the direction in which the subpixel groups Pg are arranged. In the example in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, each subpixel group Pg is shifted from the corresponding subpixel group Pg by one subpixel in u-direction and by one subpixel in v-direction. Thus, s is 1, and t is 1.</p><p id="p-0061" num="0060">The parallax barrier <b>11</b> may be formed from a film or a plate. In this case, the light-reducing portions <b>11</b><i>b </i>are parts of the film or plate. The transmissive portions <b>11</b><i>a </i>may be slits in the film or plate. The film may be formed from resin or another material. The plate may be formed from resin, metal, or another material. The parallax barrier <b>11</b> may be formed from a material other than a film or a plate. The parallax barrier <b>11</b> may include abase formed from a light-reducing material or a material containing an additive with light-reducing properties.</p><p id="p-0062" num="0061">Image light emitted from the active area A on the display panel <b>10</b> partially transmits through the transmissive portions <b>11</b><i>a </i>and is reflected by the reflector <b>4</b> to reach the optical member <b>5</b>. The image light is reflected by the optical member <b>5</b> and reaches the eyes <b>31</b> of the user <b>30</b>. This allows the eyes <b>31</b> of the user <b>30</b> to view a first virtual image V<b>1</b> in the active area A frontward from the optical member <b>5</b>. A plane on which the first virtual image V<b>1</b> is projected is referred to as a virtual image plane Sv. Being frontward herein refers to the direction in which the optical member <b>5</b> is located as viewed from the user <b>30</b>. Being frontward is typically the direction of movement of the movable body <b>20</b>. As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the user <b>30</b> views an appearing image with a second virtual image V<b>2</b> that is a virtual image of the parallax barrier <b>11</b> defining the direction of image light from the first virtual image V<b>1</b>.</p><p id="p-0063" num="0062">The user <b>30</b> thus views the image appearing as the first virtual image V<b>1</b> through the second virtual image V<b>2</b>. In reality, the user <b>30</b> does not view the second virtual image V<b>2</b> that is the virtual image of the parallax barrier <b>11</b>. However, the second virtual image V<b>2</b> is hereafter referred to as appearing at the position at which the virtual image of the parallax barrier <b>11</b> is formed and as defining the traveling direction of image light from the first virtual image V<b>1</b>. Areas in the first virtual image V<b>1</b> viewable by the user <b>30</b> with image light reaching the position of the left eye <b>311</b> of the user <b>30</b> are hereafter referred to as left viewable areas VaL. Areas in the first virtual image V<b>1</b> viewable by the user <b>30</b> with image light reaching the position of the right eye <b>31</b><i>r </i>of the user <b>30</b> are hereafter referred to as right viewable areas VaR.</p><p id="p-0064" num="0063">A virtual image barrier pitch VBp and a virtual image gap Vg are determined to satisfy Formula 1 and Formula 2 below using an optimum viewing distance Vd.</p><p id="p-0065" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>E:Vd</i>=(<i>n&#xd7;VHp</i>):<i>Vg</i>&#x2003;&#x2003;(1)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0066" num="0000"><br/><?in-line-formulae description="In-line Formulae" end="lead"?><i>Vd:VBp</i>=(<i>Vdv+Vg</i>):(2&#xd7;<i>n&#xd7;VHp</i>)&#x2003;&#x2003;(2)<?in-line-formulae description="In-line Formulae" end="tail"?></p><p id="p-0067" num="0000">The virtual image barrier pitch VBp is the interval in x-direction at which the light-reducing portions <b>11</b><i>b </i>projected as the second virtual image V<b>2</b> are arranged in a direction corresponding to u-direction. The virtual image gap Vg is the distance between the second virtual image V<b>2</b> and the first virtual image V<b>1</b>. The optimum viewing distance Vd is the distance between the virtual image V<b>2</b> of the parallax barrier <b>11</b> and the position of the left eye <b>311</b> or the right eye <b>31</b><i>r </i>of the user <b>30</b> indicated by the positional information obtained from the second detector <b>2</b>. An interocular distance E is the distance between the left eye <b>311</b> and the right eye <b>31</b><i>r</i>. The interocular distance E may be, for example, 61.1 to 64.4 mm, as calculated through studies conducted by the National Institute of Advanced Industrial Science and Technology. VHp is the horizontal length of each subpixel of the virtual image. VHp is the length of one subpixel of the first virtual image V<b>1</b> in a direction corresponding to x-direction.</p><p id="p-0068" num="0064">As described above, the left viewable areas VaL shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> are defined on the virtual image plane Sv and viewable with the left eye <b>311</b> of the user <b>30</b> when image light transmitted through the transmissive portions <b>11</b><i>a </i>of the parallax barrier <b>11</b> reaches the left eye <b>311</b> of the user <b>30</b>. As described above, the right viewable areas VaR are defined on the virtual image plane Sv and viewable with the right eye <b>31</b><i>r </i>of the user <b>30</b> when image light transmitted through the transmissive portions <b>11</b><i>a </i>of the parallax barrier <b>11</b> reaches the right eye <b>31</b><i>r </i>of the user <b>30</b>.</p><p id="p-0069" num="0065"><figref idref="DRAWINGS">FIG. <b>6</b></figref> shows an example array of subpixels of the first virtual image V<b>1</b> as viewed with the left eye <b>311</b> of the user <b>30</b> using the parallax barrier <b>11</b> with an aperture ratio of 50%. The subpixels on the first virtual image V<b>1</b> are denoted by the same reference signs P<b>1</b> through P<b>12</b> as the subpixels shown in <figref idref="DRAWINGS">FIG. <b>3</b></figref>. The parallax barrier <b>11</b> with an aperture ratio of 50% includes the transmissive portions <b>11</b><i>a </i>and the light-reducing portions <b>11</b><i>b </i>each having the same width in the interocular direction (x-direction). The first virtual image V<b>1</b> includes left light-reducing areas VbL with light reduced by the second virtual image V<b>2</b>. The left light-reducing areas VbL are less viewable with the left eye <b>311</b> of the user <b>30</b> when image light is reduced by the light-reducing portions <b>11</b><i>b </i>on the parallax barrier <b>11</b>.</p><p id="p-0070" num="0066"><figref idref="DRAWINGS">FIG. <b>7</b></figref> shows an example array of subpixels of the first virtual image V<b>1</b> viewed with the right eye <b>31</b><i>r </i>of the user <b>30</b> when the virtual image of the parallax barrier <b>11</b> located as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is viewed with the left eye <b>311</b> of the user <b>30</b>. The first virtual image V<b>1</b> includes right light-reducing areas VbR with light reduced by the second virtual image V<b>2</b>. The right light-reducing areas VbR are less viewable with the right eye <b>31</b><i>r </i>of the user <b>30</b> when image light is reduced by the light-reducing portions <b>11</b><i>b </i>on the parallax barrier <b>11</b>.</p><p id="p-0071" num="0067">With the parallax barrier <b>11</b> having an aperture ratio of 50%, the left viewable areas VaL match the right light-reducing areas VbR, and the right viewable areas VaR match the left light-reducing areas VbL. With the parallax barrier <b>11</b> having an aperture ratio of less than 50%, the left viewable areas VaL are included in the right light-reducing areas VbR, and the right viewable areas VaR are included in the left light-reducing areas VbL. Thus, the right viewable areas VaR are not viewable with the left eye <b>311</b>. The left viewable areas VaL are not easily viewable with the right eye <b>31</b><i>r. </i></p><p id="p-0072" num="0068">In the example shown in <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref>, each left viewable area VaL includes the virtual image of the entire area of each of the subpixels P<b>2</b> to P<b>5</b> arranged in the active area A and a major area of each of the subpixels P<b>1</b> and P<b>6</b> arranged in the active area A. The virtual image portions of the subpixels P<b>7</b> to P<b>12</b> arranged in the active area A are less easily viewable with the left eye <b>311</b> of the user <b>30</b>. Each right viewable area VaR includes the virtual image of the entire area of each of the subpixels P<b>8</b> to P<b>11</b> arranged in the active area A and a major area of each of the subpixels P<b>7</b> and P<b>12</b> arranged in the active area A. The virtual image portions of the subpixels P<b>1</b> to P<b>6</b> arranged in the active area A are less easily viewable with the right eye <b>31</b><i>r </i>of the user <b>30</b>. The controller <b>12</b> can cause the subpixels P<b>1</b> to P<b>6</b> to display the left eye image. The controller <b>12</b> can cause the subpixels P<b>7</b> to P<b>12</b> to display the right eye image. This allows the left eye <b>311</b> of the user <b>30</b> to mainly view the virtual image portions of the left eye image on the left viewable areas VaL and allows the right eye <b>31</b><i>r </i>to mainly view the virtual image portions of the right eye image on the right viewable areas VaR. As described above, the right eye image and the left eye image are parallax images having parallax between them. The user <b>30</b> can thus view the right eye image and the left eye image as a 3D image.</p><p id="p-0073" num="0069">The memory <b>13</b> may include any storage device such as a random-access memory (RAM) or a read-only memory (ROM). The memory <b>13</b> can store programs for various processes, information obtained from the first input unit <b>7</b> and the second input unit <b>8</b>, and information resulting from conversion performed by the controller <b>12</b>. For example, the memory <b>13</b> stores positional information about the object <b>40</b> obtained by the first input unit <b>7</b>. The memory <b>13</b> may store image elements <b>41</b> to be displayed as parallax images. The image elements <b>41</b> include text, graphics, and an animation combining text and graphics.</p><p id="p-0074" num="0070">The controller <b>12</b> may be connected to each of the components of the HUD system <b>100</b> to control these components. The controller <b>12</b> may be, for example, a processor. The controller <b>12</b> may include one or more processors. The processors may include a general-purpose processor that reads a specific program to perform a specific function, and a processor dedicated to specific processing. The dedicated processor may include an application-specific integrated circuit (ASIC). The processors may include a programmable logic device (PLD). The PLD may include a field-programmable gate array (FPGA). The controller <b>12</b> may be either a system on a chip (SoC) or a system in a package (SiP) in which one or more processors cooperate with other components.</p><p id="p-0075" num="0071">The controller <b>12</b> causes the display panel <b>10</b> to display the right eye image and the left eye image having parallax between them. The controller <b>12</b> can change, based on the positions of the eyes <b>31</b> of the user <b>30</b>, the area in which the left eye image appears and the area in which the right eye image appears on the display panel <b>10</b>. The controller <b>12</b> switches the image to be displayed by the subpixels on the display panel <b>10</b> between the right eye image and the left eye image.</p><p id="p-0076" num="0072">With the left viewable areas VaL of the first virtual image V<b>1</b> viewable with the left eye <b>311</b> of the user <b>30</b> located as shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the controller <b>12</b> causes the subpixels P<b>1</b> to P<b>6</b> to be viewable. With the right viewable areas VaR of the first virtual image V<b>1</b> viewable with the right eye <b>31</b><i>r </i>of the user <b>30</b> located as shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref>, the controller <b>12</b> causes the subpixels P<b>7</b> to P<b>12</b> to be viewable. Thus, with the first virtual image V<b>1</b> viewed by the user <b>30</b> in the state in <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref>, the controller <b>12</b> causes the subpixels P<b>1</b> to P<b>6</b> to display the left eye image and the subpixels P<b>7</b> to P<b>12</b> to display the right eye image. In another embodiment, the controller <b>12</b> can cause the subpixels P<b>2</b> to P<b>5</b> to display the left eye image and cause the subpixels P<b>8</b> to P<b>11</b> to display the right eye image. The controller <b>12</b> can cause the other subpixels P<b>1</b>, P<b>6</b>, P<b>7</b>, and P<b>12</b> to display a black image with a luminance value of 0. This structure can reduce crosstalk effectively.</p><p id="p-0077" num="0073">A change in the positions of the eyes <b>31</b> of the user <b>30</b> changes the range of the subpixels P<b>1</b> to P<b>12</b> used to display the virtual image viewable with the left eye <b>311</b> and the right eye <b>31</b><i>r </i>of the user <b>30</b>. The controller <b>12</b> determines the subpixels to display the left eye image and the subpixels to display the right eye image among the subpixels P<b>1</b> to P<b>12</b> in each subpixel group Pg in accordance with the positions of the eyes <b>31</b> of the user <b>30</b>. The controller <b>12</b> causes the subpixels determined for the left eye image to display the left eye image. The controller <b>12</b> causes the subpixels determined for the right eye image to display the right eye image.</p><p id="p-0078" num="0074">For example, the eyes <b>31</b> of the user <b>30</b> observing the first virtual image V<b>1</b> as shown in <figref idref="DRAWINGS">FIGS. <b>6</b> and <b>7</b></figref> may move relatively to the left. This causes the second virtual image V<b>2</b> that is a virtual image of the parallax barrier <b>11</b> to appear to move to the right. This will be described with reference to <figref idref="DRAWINGS">FIG. <b>8</b></figref>. In <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the dot-and-dash lines indicate virtual image portions at the boundaries between the transmissive portions <b>11</b><i>a </i>and the light-reducing portions <b>11</b><i>b </i>of the parallax barrier <b>11</b> with an aperture ratio of 50% as viewed with the left eye <b>311</b> and the right eye <b>31</b><i>r</i>. For example, the virtual image portions at the boundaries between the transmissive portions <b>11</b><i>a </i>and the light-reducing portions <b>11</b><i>b </i>of the parallax barrier <b>11</b> may move to the right as viewed from the user <b>30</b> as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. This causes the left viewable areas VaL and the right viewable areas VaR to also move to the right.</p><p id="p-0079" num="0075">In the example shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, each left viewable area VaL includes the entire area of each of the subpixels P<b>3</b> to P<b>6</b> and a major area of each of the subpixels P<b>2</b> and P<b>7</b>. Each right viewable area VaR includes the entire area of each of the subpixels P<b>9</b> to P<b>12</b> and a major area of each of the subpixels P<b>8</b> and P<b>1</b>. The controller <b>12</b> can thus cause the subpixels P<b>2</b> to P<b>7</b> on the display panel <b>10</b> to display the left eye image. The controller <b>12</b> can cause the subpixels P<b>1</b> and P<b>8</b> to P<b>12</b> on the display panel <b>10</b> to display the right eye image.</p><p id="p-0080" num="0076">The controller <b>12</b> can change the distance to an image element <b>41</b> viewable by the user <b>30</b> by varying the parallax of the image element <b>41</b>. The image element <b>41</b> is included in a parallax image including a left eye image and a right eye image to appear on the display panel <b>10</b>. Examples of the image element <b>41</b> include text, graphics, and an animation combining text and graphics. The parallax image may include one or more image elements <b>41</b> to be viewable at different distances from the user <b>30</b>.</p><p id="p-0081" num="0077">An image element <b>41</b> is displayed in a manner associated with the object <b>40</b> detectable by the first detector <b>1</b> in the field of view of the user <b>30</b>. For the object <b>40</b> being a preceding vehicle traveling ahead of the movable body <b>20</b>, the image element <b>41</b> may be text information indicating the speed of the object <b>40</b>. For the object <b>40</b> decelerating, the image element <b>41</b> may be graphics showing an alert for a decreasing distance to the preceding vehicle that is decelerating. The image element <b>41</b> displayed in a manner associated with the object <b>40</b> may be at least partially superimposed on the object <b>40</b> and displayed at substantially the same distance as the object <b>40</b>. The image element <b>41</b> superimposed on the object <b>40</b> in real space can provide visually augmented reality.</p><p id="p-0082" num="0078">The controller <b>12</b> causes the controller <b>12</b> to display a target image element <b>41</b> included in the left eye image and the right eye image with intended parallax between these images. The parallax refers to the angular difference in the direction of gaze between the left eye <b>311</b> and the right eye <b>31</b><i>r </i>of a human viewing the object <b>40</b>. The parallax can also be referred to as the angle of convergence. The parallax of the image element <b>41</b> corresponds to the angle of convergence when a left image element <b>421</b> displayed on the left eye image is viewed with the left eye <b>311</b> and a right image element <b>42</b><i>r </i>displayed on the right eye image is viewed with the right eye <b>31</b><i>r</i>. The controller <b>12</b> may obtain an image including text or graphics prestored in the memory <b>13</b>. The controller <b>12</b> may calculate, in real time, the parallax based on the distance to the object <b>40</b>, and may set the parallax between the left image element <b>421</b> and the right image element <b>42</b><i>r </i>of the image element <b>41</b> to appear on the display panel <b>10</b>. The operation of the controller <b>12</b> for displaying the image element <b>41</b> will be described below.</p><heading id="h-0013" level="2">Displaying Image Element</heading><p id="p-0083" num="0079">With the HUD <b>3</b>, the left eye image and the right eye image displayed in the active area A of the display panel <b>10</b> are projected onto the virtual image plane Sv. The left eye image and the right eye image projected on the virtual image plane Sv have parallax between them and thus are viewed as a 3D image in the field of view of the user <b>30</b> with a dimension in z-direction (front-rear direction) in accordance with the parallax. A method used by the HUD <b>3</b> according to one or more embodiments of the present disclosure for displaying the image element <b>41</b> in accordance with the distance to the object <b>40</b> will now be described with reference to <figref idref="DRAWINGS">FIGS. <b>9</b> to <b>11</b></figref>. <figref idref="DRAWINGS">FIGS. <b>9</b> to <b>11</b></figref> are diagrams viewed in y-direction, with the object <b>40</b>, the image element <b>41</b>, the left image element <b>421</b>, and the right image element <b>42</b><i>r </i>being viewed from the front for ease of explanation.</p><p id="p-0084" num="0080">In <figref idref="DRAWINGS">FIG. <b>9</b></figref>, the object <b>40</b> is located exactly at a second distance from the user <b>30</b> in z-direction. The second distance is the optimum viewing distance Vd. A portion of the object <b>40</b> viewed by the user <b>30</b> is located on the virtual image plane Sv. To display the image element <b>41</b> at the second distance, the controller <b>12</b> may set the angle of convergence in viewing the left image element <b>421</b> in the left eye image and the right image element <b>42</b><i>r </i>in the right eye image in the parallax image to match a convergence angle A, which is the angle of convergence in viewing a point on the virtual image plane Sv. In this case, the position at which a virtual image of the image element <b>41</b> is actually projected matches the position at which the image element <b>41</b> viewed with the angle of convergence and appearing on the virtual image plane Sv, thus allowing the user <b>30</b> to view the image with minimum discomfort.</p><p id="p-0085" num="0081">In <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the object <b>40</b> is located at a distance greater than or equal to the second distance but less than a first distance from the user <b>30</b> frontward in z-direction. In this case, the controller <b>12</b> displays the left image element <b>421</b> and the right image element <b>42</b><i>r </i>at different positions on the virtual image plane Sv in accordance with the parallax. The left image element <b>421</b> is an image viewed from the left at a smaller angle with z-direction than for the image element <b>41</b> viewed from a position at the optimum viewing distance Vd. The right image element <b>42</b><i>r </i>is an image viewed from the right at a smaller angle with z-direction than the image element <b>41</b> viewed from a position at the optimum viewing distance Vd. The user <b>30</b> thus perceives the image element <b>41</b> appearing at the intersection between the direction of gaze in which the left eye <b>311</b> views the left image element <b>421</b> and the direction of gaze in which the right eye <b>31</b><i>r </i>views the right image element <b>42</b><i>r</i>. The angle of convergence with which the left eye <b>311</b> and the right eye <b>31</b><i>r </i>view a point on the image element <b>41</b> is referred to as a convergence angle &#x3b8;<b>1</b>. The convergence angle &#x3b8;<b>1</b> is smaller than the convergence angle A used for viewing a point on the virtual image plane Sv. The left image element <b>421</b> and the right image element <b>42</b><i>r </i>having parallax between them are projected on the virtual image plane Sv in this manner to allow the user <b>30</b> to view the image element <b>41</b> as appearing frontward from the virtual image plane Sv.</p><p id="p-0086" num="0082">Constantly calculating and updating the parallax for the parallax image including the image element <b>41</b> to reflect all the positions of the object <b>40</b> may increase the processing load of the HUD <b>3</b>. For the object <b>40</b> at a distance greater than or equal to a predetermined first distance that is greater than the second distance, as noticed by the inventors, the parallax of the image element <b>41</b> may be fixed to a value of parallax corresponding to the first distance. With the parallax fixed to the value of parallax corresponding to the first distance, the image element <b>41</b> superimposed on the object <b>40</b> can be perceived with the cognition of the human brain as appearing at substantially the same distance as the object <b>40</b>. This perception occurs seemingly due to the human brain that automatically merges the object <b>40</b> with the image element <b>41</b>, superimposed on the object <b>40</b>, having the parallax different from the parallax for the object <b>40</b>, and views the image element <b>41</b> as appearing at substantially the same distance as the object <b>40</b>. An experiment conducted by the inventors has confirmed this phenomenon using at least the first distance set to 12.5 m and the second distance to 7.5 m. When, for example, the image element <b>41</b> with the parallax corresponding to the distance of 12.5 m is superimposed on the object <b>40</b> located at a distance of 70 m from the user <b>30</b>, the image element <b>41</b> appears to be at the same distance as the object <b>40</b>. The experiment shows that the difference in the angle of convergence does not cause the outline of the image element <b>41</b> to appear double, blurred, or with any similar phenomenon.</p><p id="p-0087" num="0083">Thus, with the distance from the user <b>30</b> to the object <b>40</b> being greater than or equal to the first distance, the controller <b>12</b> performs first control for fixing the parallax of the image element <b>41</b> at least partially superimposed on the object <b>40</b> to the parallax corresponding to the first distance as shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>. The HUD <b>3</b> thus allows the user <b>30</b> to perceive, with the cognition of the human brain, the image element <b>41</b> to be located substantially at the same distance as the object <b>40</b>. In the example of <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the user <b>30</b> perceives the image element <b>41</b> to be at the position of the object <b>40</b>, rather than at an image display position <b>43</b> corresponding to the distance based on parallax.</p><p id="p-0088" num="0084">The parallax of the image element <b>41</b> is not zero at the first distance. More specifically, the structure according to one or more embodiments of the present disclosure differs from any other structure that fixes the parallax to 0 in areas corresponding to large distances and having almost no parallax. The parallax of the image element <b>41</b> is set to a sufficiently large value of parallax to allow the image element <b>41</b> to be perceived readily by a human when the image element <b>41</b> is not superimposed on the object <b>40</b>. The angle of convergence at which a point on the left image element <b>421</b> in the left eye image is viewed with the left eye <b>311</b> and a point on the right image element <b>42</b><i>r </i>in the right eye image is viewed with the right eye <b>31</b><i>r </i>is fixed to a convergence angle &#x3b8;<b>2</b> that is smaller than the convergence angle &#x3b8;<b>1</b>. The convergence angle &#x3b8;<b>2</b> is used in viewing a point located at the first distance.</p><p id="p-0089" num="0085">A display example of the image element <b>41</b> in one embodiment will now be described with reference to <figref idref="DRAWINGS">FIG. <b>12</b></figref>. <figref idref="DRAWINGS">FIG. <b>12</b></figref> shows, as an example of the object <b>40</b>, a preceding vehicle <b>45</b> traveling ahead at a distance greater than the first distance. The first detector <b>1</b> obtains positional information including the distance to the preceding vehicle <b>45</b> in chronological order and transmits the information to the controller <b>12</b>. The preceding vehicle <b>45</b> may start decelerating. In response to receiving, from the first detector <b>1</b>, information about any decreasing distance to the preceding vehicle <b>45</b>, the controller <b>12</b> determines that the preceding vehicle <b>45</b> is decelerating. To alert the user <b>30</b>, the controller <b>12</b> controls the display panel <b>10</b> to display an image element <b>41</b> carrying a message indicating the deceleration of the preceding vehicle <b>45</b> superimposed on the preceding vehicle <b>45</b> in the field of view of the user <b>30</b>. The image element <b>41</b> may be displayed using text, graphics, or both. The image element <b>41</b> may be displayed together with an animation, such as movement, blinking, shape changing, or two or more of these items. The image element <b>41</b> is a parallax image with the parallax corresponding to the first distance. The image element <b>41</b> is perceived with the cognition of the brain of the user <b>30</b> as being at the same distance as the preceding vehicle <b>45</b>. As the distance to the preceding vehicle <b>45</b> viewed from the user <b>30</b> changes, the image element <b>41</b> is perceived to follow the changes in the preceding vehicle <b>45</b>.</p><heading id="h-0014" level="2">Procedure for Displaying Image Element</heading><p id="p-0090" num="0086">A method for displaying a parallax image with the controller <b>12</b> in the HUD <b>3</b> will be described with reference to <figref idref="DRAWINGS">FIG. <b>13</b></figref>. The controller <b>12</b> performs the procedure in the flowchart shown in <figref idref="DRAWINGS">FIG. <b>13</b></figref>.</p><p id="p-0091" num="0087">The controller <b>12</b> obtains, from the first input unit <b>7</b>, first positional information about the object <b>40</b> viewed frontward by the user <b>30</b> through the optical member <b>5</b> (step S<b>01</b>).</p><p id="p-0092" num="0088">The controller <b>12</b> obtains second positional information about the positions of the eyes <b>31</b> of the user <b>30</b> from the second input unit <b>8</b> (step S<b>02</b>). Step S<b>02</b> may be performed before step S<b>01</b>. Step S<b>02</b> may be performed in parallel with step S<b>01</b>.</p><p id="p-0093" num="0089">The controller <b>12</b> determines whether the distance to the object <b>40</b> is greater than the first distance based on the first positional information (step S<b>03</b>). The first distance is, for example, 12.5 m. The first distance may be greater than 12.5 m.</p><p id="p-0094" num="0090">When the controller <b>12</b> determines that the distance to the object <b>40</b> is greater than or equal to the first distance in step S<b>03</b> (Yes in step S<b>03</b>), the first control is performed (step S<b>04</b>). In the first control, the controller <b>12</b> fixes the parallax of the image element <b>41</b> to the parallax corresponding to the first distance. The parallax corresponding to the first distance is a value of parallax greater than 0.</p><p id="p-0095" num="0091">When the controller <b>12</b> determines that the distance to the object <b>40</b> is less than the first distance in step S<b>03</b> (No in step S<b>03</b>), second control is performed (step S<b>05</b>). In the second control, the controller <b>12</b> controls the parallax of the image element <b>41</b> to be the parallax corresponding to the distance to the object <b>40</b>. When, for example, the distance to the object <b>40</b> is 10 m, the controller <b>12</b> sets the parallax between the left image element <b>421</b> and the right image element <b>42</b><i>r </i>to the parallax used in viewing a point at a distance of 10 m ahead.</p><p id="p-0096" num="0092">When the distance to the object <b>40</b> is less than the second distance in step S<b>05</b>, the controller <b>12</b> displays the image element <b>41</b> in front of the user <b>30</b> from the virtual image plane Sv. The second distance is the optimum viewing distance Vd. The second distance may be greater than 7.5 m and less than the first distance. The controller <b>12</b> can also perform processing different from step S<b>05</b> when the distance to the object <b>40</b> is less than the second distance. For example, the controller <b>12</b> may fix the parallax of the image element <b>41</b> to the parallax corresponding to the second distance when the distance to the object <b>40</b> is less than the second distance.</p><p id="p-0097" num="0093">The controller <b>12</b> generates an image element <b>41</b> to be superimposed on the object <b>40</b> (step S<b>06</b>). For example, the controller <b>12</b> determines the image element <b>41</b> to be displayed based on, for example, the distance to the object <b>40</b> and its changes included in the positional information about the object <b>40</b> obtained in step S<b>01</b>. The controller <b>12</b> may receive an instruction from another device included in the movable body <b>20</b> for the image element <b>41</b> to be displayed. The controller <b>12</b> determines the display position of the image element <b>41</b> on the display panel <b>10</b> based on the positional information about the object <b>40</b> obtained in step S<b>01</b> and the positional information about the eyes <b>31</b> of the user <b>30</b> obtained in step S<b>02</b>. The controller <b>12</b> causes the image element <b>41</b> to be at least partially superimposed on the object <b>40</b> viewed by the user <b>30</b>. The controller <b>12</b> may drive the drive <b>15</b> through the output unit <b>14</b> to adjust the display position of the image element <b>41</b> as appropriate. The controller <b>12</b> sets the parallax of the image element <b>41</b> based on the parallax determined in step S<b>04</b> or in step S<b>05</b>. The controller <b>12</b> can merge one or more image elements <b>41</b> into a parallax image.</p><p id="p-0098" num="0094">The controller <b>12</b> causes the display panel <b>10</b> to display the parallax image resulting from the merging (step S<b>07</b>). This causes the image element <b>41</b> superimposed on the object <b>40</b> to appear in the field of view of the user <b>30</b>. The image element <b>41</b> is perceived by the user <b>30</b> as being at the same distance as the object <b>40</b>.</p><p id="p-0099" num="0095">In the HUD system <b>100</b> according to one or more embodiments of the present disclosure described above, the controller <b>12</b> performs control not to fix the parallax of the image element <b>41</b> when the distance to the object <b>40</b> is greater than or equal to the first distance. The HUD system <b>100</b> can thus reduce the processing load for the merging and display of a 3D image superimposed on the object <b>40</b>. A 3D display device is known to cause discomfort and visual fatigue when the difference is large between the distance to the display surface on which the image is actually displayed (the virtual image plane Sv herein) and the distance to the display image perceived by the user <b>30</b> with the parallax between the two eyes. The HUD <b>3</b> according to one or more embodiments of the present disclosure does not have a large difference between the second distance corresponding to the distance to the virtual image plane Sv and the first distance, thus reducing such discomfort and visual fatigue.</p><p id="p-0100" num="0096">The display device <b>6</b> according to the above embodiment includes the parallax barrier <b>11</b> as an optical element that causes the left eye image and the right eye image displayed on the display panel <b>10</b> to reach the left eye <b>311</b> and the right eye <b>31</b><i>r </i>of the user <b>30</b>. However, the optical element is not limited to the parallax barrier <b>11</b>. The parallax barrier <b>11</b> may be replaced by, for example, a liquid crystal shutter or a lenticular lens. <figref idref="DRAWINGS">FIG. <b>14</b></figref> shows an example display device <b>6</b>A including a liquid crystal shutter <b>16</b> in place of the parallax barrier <b>11</b>. The structure and the operation of the display device <b>6</b>A will now be described with reference to <figref idref="DRAWINGS">FIGS. <b>14</b> and <b>15</b></figref>.</p><p id="p-0101" num="0097">As shown in <figref idref="DRAWINGS">FIG. <b>14</b></figref>, the liquid crystal shutter <b>16</b> is controlled by the controller <b>12</b>. The display device <b>6</b>A has the same structure as the display device <b>6</b> shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, except that the parallax barrier <b>11</b> is replaced by the liquid crystal shutter <b>16</b>. As shown in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, the liquid crystal shutter <b>16</b> may have the structure similar to the display panel <b>10</b>. The liquid crystal shutter <b>16</b> includes multiple pixels P. The liquid crystal shutter <b>16</b> can control the light transmittance of each pixel P. The multiple pixels P included in the liquid crystal shutter correspond to the multiple subpixels included in the display panel <b>10</b>. The multiple pixels P in the liquid crystal shutter <b>16</b> differ from the subpixels in the display panel <b>10</b> in that the pixels P have no color components. When the user <b>30</b> views a first virtual image V<b>1</b> of the display panel <b>10</b> and a second virtual image V<b>2</b> of the liquid crystal shutter <b>16</b> superimposed on each other, the pixels P in the liquid crystal shutter <b>16</b> may be in the same shape and the same size as the subpixels in the display panel <b>10</b>.</p><p id="p-0102" num="0098">The liquid crystal shutter <b>16</b> includes multiple transmissive portions <b>16</b><i>a </i>and multiple light-reducing portions <b>16</b><i>b </i>as controlled by the controller <b>12</b>. The transmissive portions <b>16</b><i>a </i>may have the same light transmittance as the transmissive portions <b>11</b><i>a </i>in the parallax barrier <b>11</b>, and the light-reducing portions <b>16</b><i>b </i>may have the same light transmittance as the light-reducing portions <b>11</b><i>b </i>in the parallax barrier <b>11</b>. The transmissive portions <b>16</b><i>a </i>and the light-reducing portions <b>16</b><i>b </i>are defined in correspondence with the pixels in the liquid crystal shutter <b>16</b>. For the optical element including the liquid crystal shutter <b>16</b>, the boundaries between the transmissive portions <b>16</b><i>a </i>and the light-reducing portions <b>16</b><i>b </i>may be staggered along the shapes of the pixels P. The boundaries between the transmissive portions <b>16</b><i>a </i>and the light-reducing portions <b>16</b><i>b </i>of the liquid crystal shutter <b>16</b> can be changed dynamically to reduce crosstalk. When the positions of the eyes <b>31</b> of the user <b>30</b> change relative to x-direction, the controller <b>12</b> can switch between the transmissive portions <b>16</b><i>a </i>and the light-reducing portions <b>16</b><i>b </i>of the liquid crystal shutter <b>16</b>, instead of switching the image for each subpixel in the display panel <b>10</b>. For example, the controller <b>12</b> may control the liquid crystal shutter <b>16</b> and cause the highest proportion of image light to travel from the subpixels P<b>1</b> to P<b>6</b> displaying the left eye image to the left eye <b>311</b> of the user <b>30</b>. For example, the controller <b>12</b> may control the liquid crystal shutter <b>16</b> and cause the highest proportion of image light to travel from the subpixels P<b>7</b> to P<b>12</b> displaying the right eye image to the right eye <b>31</b><i>r </i>of the user <b>30</b>.</p><p id="p-0103" num="0099">Although the embodiments of the present disclosure have been described with reference to the drawings and examples, those skilled in the art can easily make various modifications or alterations based on one or more embodiments of the present disclosure. Such modifications or alterations also fall within the scope of the present disclosure. For example, the functions of the components or steps are reconfigurable unless any contradiction arises. Multiple components or steps may be combined into a single unit or step, or a single component or step may be divided into separate units or steps. The embodiments of the present disclosure can also be implemented as a method or a program implementable by a processor included in the device, or as a storage medium storing the program. The method, program, and storage medium also fall within the scope of the present disclosure.</p><p id="p-0104" num="0100">In the present disclosure, the first, the second, or others are identifiers for distinguishing the components. The identifiers of the components distinguished with the first, the second, and others in the present disclosure are interchangeable. For example, the first input unit may be interchangeable with the second input unit. The identifiers are to be interchanged together. The components for which the identifiers are interchanged are also to be distinguished from one another. The identifiers may be eliminated. The components without such identifiers can be distinguished with reference numerals. The identifiers such as the first and the second in the present disclosure alone should not be used to determine the order of components or to suggest the existence of smaller or larger number identifiers.</p><p id="p-0105" num="0101">In the present disclosure, x-direction, y-direction, and z-direction are used for ease of explanation and may be interchangeable with one another. The Cartesian coordinate system including axes in x-direction, y-direction, and z-direction is used to describe the structures according to the present disclosure. The positional relationship between the components in the present disclosure is not limited to being orthogonal. The same applies to u-direction, v-direction, and w-direction.</p><p id="p-0106" num="0102">The movable body according to one or more embodiments of the present disclosure includes a vehicle, a vessel, or an aircraft. The vehicle according to one or more embodiments of the present disclosure includes, but is not limited to, an automobile or an industrial vehicle, and may also include a railroad vehicle, a community vehicle, or a fixed-wing aircraft traveling on a runway. The automobile includes, but is not limited to, a passenger vehicle, a truck, a bus, a motorcycle, or a trolley bus, and may also include another vehicle traveling on a road. The industrial vehicle includes an agricultural vehicle or a construction vehicle. The industrial vehicle includes, but is not limited to, a forklift or a golf cart. The agricultural vehicle includes, but is not limited to, a tractor, a cultivator, a transplanter, a binder, a combine, or a lawn mower. The construction vehicle includes, but is not limited to, a bulldozer, a scraper, a power shovel, a crane vehicle, a dump truck, or a road roller. The vehicle includes a man-powered vehicle. The classification of the vehicle is not limited to the above. For example, the automobile may include an industrial vehicle traveling on a road, and one type of vehicle may fall within multiple classes. The vessel according to one or more embodiments of the present disclosure includes a jet ski, a boat, or a tanker. The aircraft according to one or more embodiments of the present disclosure includes a fixed-wing aircraft or a rotary-wing aircraft.</p><p id="p-0107" num="0103">The present disclosure may be implemented in the following forms.</p><p id="p-0108" num="0104">A head-up display according to one or more embodiments of the present disclosure includes a first input unit, a second input unit, a display panel, an optical system, a processor, and an optical element. The first input unit obtains first positional information about a position of an object including a distance to the object. The second input unit obtains second positional information about a position of at least a first eye or a second eye of a user. The optical system projects, into a field of view of the user, a virtual image of an image displayed on the display panel. The processor causes the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image. The optical element causes, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user. The processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information. The processor performs first control to fix, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</p><p id="p-0109" num="0105">A head-up display system according to one or more embodiments of the present disclosure includes a first detector, a second detector, and ahead-up display. The first detector detects first positional information about a position of an object including a distance to the object. The second detector detects second positional information about a position of at least a first eye or a second eye of a user. The head-up display includes a first input unit, a second input unit, a display panel, an optical system, a processor, and an optical element. The first input unit obtains the first positional information from the first detector. The second input unit obtains the second positional information from the second detector. The optical system projects, into a field of view of the user, a virtual image of an image displayed on the display panel. The processor causes the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image. The optical element causes, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user. The processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information. The processor fixes, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</p><p id="p-0110" num="0106">A movable body according to one or more embodiments of the present disclosure includes a head-up display system. The head-up display system includes a first detector, a second detector, and a head-up display. The first detector detects first positional information about a position of an object including a distance to the object. The second detector detects second positional information about a position of at least a first eye or a second eye of a user. The head-up display includes a first input unit, a second input unit, a display panel, an optical system, a processor, and an optical element. The first input unit obtains the first positional information from the first detector. The second input unit obtains the second positional information from the second detector. The optical system projects, into a field of view of the user, a virtual image of an image displayed on the display panel. The processor causes the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image. The optical element causes, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user. The processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information. The processor fixes, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</p><p id="p-0111" num="0107">The structure according to the embodiments of the present disclosure can reduce the processing load for displaying a 3D image superimposed on an object.</p><p id="p-0112" num="0108">Although the embodiments of the present disclosure have been described in detail, the present disclosure is not limited to the above embodiments, and may be modified or changed variously without departing from the spirit and scope of the present disclosure. The components described in the above embodiments may be entirely or partially combined as appropriate unless any contradiction arises.</p><heading id="h-0015" level="1">REFERENCE SIGNS LIST</heading><p id="p-0113" num="0000"><ul id="ul0002" list-style="none">    <li id="ul0002-0001" num="0109"><b>1</b> first detector</li>    <li id="ul0002-0002" num="0110"><b>2</b> second detector</li>    <li id="ul0002-0003" num="0111"><b>3</b> head-up display (HUD)</li>    <li id="ul0002-0004" num="0112"><b>4</b> reflector (optical system)</li>    <li id="ul0002-0005" num="0113"><b>5</b> optical member (optical system)</li>    <li id="ul0002-0006" num="0114"><b>6</b> display device</li>    <li id="ul0002-0007" num="0115"><b>7</b> first input unit</li>    <li id="ul0002-0008" num="0116"><b>8</b> second input unit</li>    <li id="ul0002-0009" num="0117"><b>9</b> illuminator</li>    <li id="ul0002-0010" num="0118"><b>10</b> display panel</li>    <li id="ul0002-0011" num="0119"><b>11</b> parallax barrier (optical element)</li>    <li id="ul0002-0012" num="0120"><b>11</b><i>a </i>transmissive portion</li>    <li id="ul0002-0013" num="0121"><b>11</b><i>b </i>light-reducing portion</li>    <li id="ul0002-0014" num="0122"><b>12</b> controller</li>    <li id="ul0002-0015" num="0123"><b>13</b> memory</li>    <li id="ul0002-0016" num="0124"><b>14</b> output unit</li>    <li id="ul0002-0017" num="0125"><b>15</b> drive</li>    <li id="ul0002-0018" num="0126"><b>16</b> liquid crystal shutter (optical element)</li>    <li id="ul0002-0019" num="0127"><b>16</b><i>a </i>transmissive portion</li>    <li id="ul0002-0020" num="0128"><b>16</b><i>b </i>light-reducing portion</li>    <li id="ul0002-0021" num="0129"><b>20</b> movable body</li>    <li id="ul0002-0022" num="0130"><b>30</b> user</li>    <li id="ul0002-0023" num="0131"><b>31</b> eye</li>    <li id="ul0002-0024" num="0132"><b>311</b> left eye (first eye)</li>    <li id="ul0002-0025" num="0133"><b>31</b><i>r </i>right eye (second eye)</li>    <li id="ul0002-0026" num="0134"><b>40</b> object</li>    <li id="ul0002-0027" num="0135"><b>41</b> image element</li>    <li id="ul0002-0028" num="0136"><b>421</b> left image element</li>    <li id="ul0002-0029" num="0137"><b>42</b><i>r </i>right image element</li>    <li id="ul0002-0030" num="0138"><b>43</b> image display position corresponding to distance based on parallax</li>    <li id="ul0002-0031" num="0139"><b>45</b> preceding vehicle (object)</li>    <li id="ul0002-0032" num="0140"><b>100</b> head-up display (HUD) system</li>    <li id="ul0002-0033" num="0141">A active area</li>    <li id="ul0002-0034" num="0142">Sv virtual image plane</li>    <li id="ul0002-0035" num="0143">V<b>1</b> first virtual image</li>    <li id="ul0002-0036" num="0144">V<b>2</b> second virtual image</li>    <li id="ul0002-0037" num="0145">VaL left viewable area</li>    <li id="ul0002-0038" num="0146">VbL left light-reducing portion</li>    <li id="ul0002-0039" num="0147">VaR right viewable area</li>    <li id="ul0002-0040" num="0148">VbR right light-reducing portion</li></ul></p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A head-up display, comprising:<claim-text>a first input unit configured to obtain first positional information about a position of an object, the first positional information including a distance to the object;</claim-text><claim-text>a second input unit configured to obtain second positional information about a position of at least a first eye or a second eye of a user;</claim-text><claim-text>a display panel;</claim-text><claim-text>an optical system configured to project, into a field of view of the user, a virtual image of an image displayed on the display panel;</claim-text><claim-text>a processor configured to cause the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image; and</claim-text><claim-text>an optical element configured to cause, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user,</claim-text><claim-text>wherein the processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information, and the processor performs first control to fix, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The head-up display according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>in response to the distance to the object being greater than or equal to the first distance, the processor causes the image element to be perceived by the user, with cognition of a human brain, as being substantially at a same distance as the object.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The head-up display according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>in response to the distance to the object being between a second distance at which a virtual image of an image displayed on the display panel is projected by the optical system and the first distance greater than the second distance, the processor performs second control to set the parallax of the image element to a value of parallax corresponding to the distance to the object.</claim-text></claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The head-up display according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein<claim-text>the second distance is greater than 7.5 m.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The head-up display according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein<claim-text>the first distance is greater than 12.5 m.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. A head-up display system, comprising:<claim-text>a first detector configured to detect first positional information about a position of an object, the first positional information including a distance to the object;</claim-text><claim-text>a second detector configured to detect second positional information about a position of at least a first eye or a second eye of a user; and</claim-text><claim-text>a head-up display including<claim-text>a first input unit configured to obtain the first positional information from the first detector,</claim-text><claim-text>a second input unit configured to obtain the second positional information from the second detector,</claim-text><claim-text>a display panel,</claim-text><claim-text>an optical system configured to project, into a field of view of the user, a virtual image of an image displayed on the display panel,</claim-text><claim-text>a processor configured to cause the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image, and</claim-text><claim-text>an optical element configured to cause, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user,</claim-text></claim-text><claim-text>wherein the processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information, and the processor fixes, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. A movable body, comprising:<claim-text>a head-up display system including</claim-text><claim-text>a first detector configured to detect first positional information about a position of an object, the first positional information including a distance to the object,</claim-text><claim-text>a second detector configured to detect second positional information about a position of at least a first eye or a second eye of a user, and</claim-text><claim-text>a head-up display including<claim-text>a first input unit configured to obtain the first positional information from the first detector,</claim-text><claim-text>a second input unit configured to obtain the second positional information from the second detector,</claim-text><claim-text>a display panel,</claim-text><claim-text>an optical system configured to project, into a field of view of the user, a virtual image of an image displayed on the display panel,</claim-text><claim-text>a processor configured to cause the display panel to display a parallax image including a first image and a second image having parallax between the first image and the second image, and</claim-text><claim-text>an optical element configured to cause, through the optical system, the first image displayed on the display panel to reach the first eye of the user and the second image displayed on the display panel to reach the second eye of the user,</claim-text></claim-text></claim-text><claim-text>wherein the processor causes the display panel to display an image element included in the parallax image as being at least partially superimposed on the object viewable by the user based on the first positional information and the second positional information, and the processor fixes, in response to the distance to the object being greater than or equal to a predetermined first distance, parallax of the image element to a value of parallax greater than 0 corresponding to the first distance.</claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230005980A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230005980</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17671794</doc-number><date>20220215</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0086573</doc-number><date>20210701</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>01</class><subclass>L</subclass><main-group>27</main-group><subgroup>146</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>27</main-group><subgroup>14643</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>27</main-group><subgroup>14627</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>27</main-group><subgroup>14621</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>27</main-group><subgroup>1463</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>01</class><subclass>L</subclass><main-group>27</main-group><subgroup>14636</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">IMAGE SENSOR</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SAMSUNG ELECTRONICS CO., LTD.</orgname><address><city>Suwon-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Boseong</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Bumsuk</first-name><address><city>Hwaseong-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>PARK</last-name><first-name>Hyeyeon</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>BAE</last-name><first-name>Jeongmin</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Yunki</first-name><address><city>Hwaseong-si</city><country>KR</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An image sensor includes: a substrate, having first and second surfaces opposing each other in a first direction, on which a plurality of unit pixels are arranged, the plurality of unit pixels including a normal pixel, an autofocusing pixel, and a compensation pixel in a direction, parallel to the first surface; a photodiode disposed in the substrate in each of the plurality of unit pixels; and a device isolation layer disposed between the plurality of unit pixels. The unit pixels include color filters, separated from each other by a grid, and microlenses disposed on the color filters. The compensation pixel is disposed on one side of the autofocusing pixel and includes a compensation microlens, smaller than a normal microlens included in the normal pixel, and a transparent color filter separated from adjacent color filters by a compensation grid smaller than a normal grid included in the normal pixel.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="142.07mm" wi="106.26mm" file="US20230005980A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="159.77mm" wi="108.29mm" file="US20230005980A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="182.29mm" wi="117.77mm" file="US20230005980A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="192.70mm" wi="139.02mm" file="US20230005980A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="192.28mm" wi="139.28mm" file="US20230005980A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="160.19mm" wi="133.94mm" orientation="landscape" file="US20230005980A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="191.85mm" wi="138.94mm" file="US20230005980A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="192.11mm" wi="138.94mm" file="US20230005980A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="179.83mm" wi="139.02mm" file="US20230005980A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="188.47mm" wi="151.13mm" orientation="landscape" file="US20230005980A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="189.65mm" wi="138.94mm" file="US20230005980A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="160.19mm" wi="132.76mm" orientation="landscape" file="US20230005980A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="190.67mm" wi="139.02mm" file="US20230005980A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="160.19mm" wi="132.08mm" orientation="landscape" file="US20230005980A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00014" num="00014"><img id="EMI-D00014" he="187.54mm" wi="149.01mm" orientation="landscape" file="US20230005980A1-20230105-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00015" num="00015"><img id="EMI-D00015" he="206.25mm" wi="118.96mm" orientation="landscape" file="US20230005980A1-20230105-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00016" num="00016"><img id="EMI-D00016" he="187.71mm" wi="148.76mm" orientation="landscape" file="US20230005980A1-20230105-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00017" num="00017"><img id="EMI-D00017" he="206.67mm" wi="124.46mm" orientation="landscape" file="US20230005980A1-20230105-D00017.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00018" num="00018"><img id="EMI-D00018" he="160.19mm" wi="122.26mm" orientation="landscape" file="US20230005980A1-20230105-D00018.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00019" num="00019"><img id="EMI-D00019" he="160.27mm" wi="137.84mm" orientation="landscape" file="US20230005980A1-20230105-D00019.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00020" num="00020"><img id="EMI-D00020" he="160.10mm" wi="119.80mm" orientation="landscape" file="US20230005980A1-20230105-D00020.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00021" num="00021"><img id="EMI-D00021" he="160.27mm" wi="120.14mm" orientation="landscape" file="US20230005980A1-20230105-D00021.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00022" num="00022"><img id="EMI-D00022" he="160.02mm" wi="123.95mm" orientation="landscape" file="US20230005980A1-20230105-D00022.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00023" num="00023"><img id="EMI-D00023" he="160.19mm" wi="123.53mm" orientation="landscape" file="US20230005980A1-20230105-D00023.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00024" num="00024"><img id="EMI-D00024" he="187.54mm" wi="148.67mm" file="US20230005980A1-20230105-D00024.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00025" num="00025"><img id="EMI-D00025" he="179.83mm" wi="145.80mm" file="US20230005980A1-20230105-D00025.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">This application claims benefit of priority to Korean Patent Application No. 10-2021-0086573, filed on Jul. 1, 2021, in the Korean Intellectual Property Office, the disclosure of which is incorporated herein by reference in its entirety.</p><heading id="h-0002" level="1">BACKGROUND</heading><heading id="h-0003" level="1">1. Field</heading><p id="p-0003" num="0002">Embodiments relate to an image sensor.</p><heading id="h-0004" level="1">2. Description of the Related Art</heading><p id="p-0004" num="0003">An image sensor may be implemented as a semiconductor-based sensor receiving light to generate an electrical signal therefrom, and may include a pixel array having a plurality of unit pixels, circuits for driving the pixel array and generating an image, and the like. The plurality of unit pixels may include a photodiode for generating a charge in response to external light, a pixel circuit for converting the charge generated by the photodiode into an electrical signal, and the like. The image sensor may be widely applied to smartphones, tablet personal computers (PCs), laptop computers, televisions, vehicles, or the like, in addition to cameras for capturing an image or a video. Recently, research into the generation of images having high image quality as well as research into improvements of autofocusing performance has been conducted.</p><heading id="h-0005" level="1">SUMMARY</heading><p id="p-0005" num="0004">According to an embodiment, an image sensor includes: a substrate, having a first surface and a second surface opposing each other in a first direction, on which a plurality of unit pixels are arranged, the plurality of unit pixels including at least one normal pixel, at least one autofocusing pixel, and at least one compensation pixel arranged parallel to the first surface; a photodiode disposed in the substrate in each of the plurality of unit pixels; and a device isolation layer disposed between the plurality of unit pixels, wherein: the plurality of unit pixels includes color filters, disposed on the first surface and separated from each other by a grid, and microlenses disposed on the color filters, the normal pixel includes a normal microlens, and the compensation pixel is disposed on one side of the autofocusing pixel and includes a transparent color filter and a compensation microlens, which is smaller than the normal microlens.</p><p id="p-0006" num="0005">According to an embodiment, an image sensor includes: a substrate; a pixel array including a plurality of pixel groups arranged parallel to an upper surface of the substrate; and a logic circuit configured to obtain pixel signals from the pixel array, wherein: each of the plurality of pixel groups includes a plurality of unit pixels forming at least one of an autofocusing pixel, a compensation pixel, and a normal pixel, which are respectively defined by a device isolation layer extending in a first direction, perpendicular to the upper surface of the substrate, each unit pixel includes: a photodiode disposed in the substrate; a color filter disposed on the upper surface of the substrate and separated from an adjacent color filter by a grid; and a microlens disposed on the color filter, the autofocusing pixel includes a pair of unit pixels, and the compensation pixel is configured to compensate for a signal output from the autofocusing pixel, and includes a compensation microlens, smaller than the microlens included in adjacent pixels, and a transparent color filter.</p><p id="p-0007" num="0006">According to an embodiment, an image sensor includes: a substrate, having a first surface and a second surface opposing each other in a first direction; unit pixels on the first surface; a photodiode in the substrate in each of the unit pixels; and a device isolation layer between the unit pixels, wherein: the unit pixels form an autofocusing pixel, a normal pixel, and a compensation pixel, each unit pixel has a color filter, which is separated from an adjacent color filter by a grid, and a microlens on the color filter, the autofocusing pixel includes a pair of unit pixels disposed side by side in a second direction and sharing a microlens and a color filter, and the compensation pixel is configured to compensate for a signal output from the autofocusing pixel, has a structure different from a structure of the normal pixel, is disposed on one side of the autofocusing pixel in the second direction, and includes a transparent color filter.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF DRAWINGS</heading><p id="p-0008" num="0007">Features will become apparent to those of skill in the art by describing in detail example embodiments with reference to the attached drawings in which:</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic block diagram of an image sensor according to an example embodiment.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a circuit diagram of a pixel circuit of an image sensor according to an example embodiment.</p><p id="p-0011" num="0010"><figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref> are plan views illustrating pixel groups included in an image sensor according to an example embodiment.</p><p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a cross-sectional view illustrating an image sensor according to an example embodiment.</p><p id="p-0013" num="0012"><figref idref="DRAWINGS">FIGS. <b>5</b> to <b>7</b></figref> are plan views illustrating pixels groups included in image sensors according to example embodiments, respectively.</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a plan view illustrating a pixel array included in an image sensor according to an image sensor.</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIGS. <b>9</b> to <b>12</b></figref> are diagrams illustrating image sensors according to example embodiments, respectively.</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref> are a plan view and a cross-sectional view illustrating a pixel array included in an image sensor according to an example embodiment, respectively.</p><p id="p-0017" num="0016"><figref idref="DRAWINGS">FIGS. <b>15</b> and <b>16</b></figref> are a plan view and a cross-sectional view illustrating a pixel array included in an image sensor according to an example embodiment, respectively.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIGS. <b>17</b>A to <b>17</b>F</figref> are cross-sectional views illustrating a process of forming an image sensor according to an example embodiment.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIGS. <b>18</b> and <b>19</b></figref> are schematic diagrams of an electronic device including an image sensor according to an example embodiment.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is a schematic block diagram of an image sensor according to an example embodiment.</p><p id="p-0021" num="0020">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, an image sensor <b>1</b> according to an example embodiment may include a pixel array <b>10</b>, a logic circuit <b>20</b>, and the like.</p><p id="p-0022" num="0021">The pixel array <b>10</b> may include a plurality of unit pixels PX arranged in an array of a plurality of rows and a plurality of columns. Each of the unit pixels PX may include at least one photoelectric conversion element for generating a charge in response to light, and a pixel circuit for generating a pixel signal that corresponds to the charge generated by the photoelectric conversion element.</p><p id="p-0023" num="0022">The photoelectric conversion element may include a photodiode formed of a semiconductor material, and/or an organic photodiode formed of an organic material. Each of the unit pixels PX may include a single photoelectric conversion element, and a photoelectric conversion element included in a unit pixel PX may receive light to generate charges.</p><p id="p-0024" num="0023">The plurality of unit pixels PX may include at least one normal pixel, at least one autofocusing pixel, and at least one compensation pixel. Each of the normal pixel, the autofocusing pixel, and the compensation pixel may include a photodiode receiving light to generate charges.</p><p id="p-0025" num="0024">The autofocusing pixel may be a pixel allowing the image sensor <b>1</b> to perform an autofocusing function.</p><p id="p-0026" num="0025">The compensation pixel may be a pixel for preventing crosstalk which may occur in the autofocusing pixel.</p><p id="p-0027" num="0026">Each of the plurality of unit pixels PX included in the image sensor <b>1</b> may include a photodiode. When each of the unit pixels PX includes a single photoelectric conversion element, each of the unit pixels PX may include a pixel circuit for processing charges generated by the photoelectric conversion element. The pixel circuit may include a transmission transistor, a driving transistor, a select transistor, and a reset transistor. Accordingly, a pixel circuit corresponding to each of the unit pixels PX may include a transmission transistor, a driving transistor, a select transistor, and a reset transistor.</p><p id="p-0028" num="0027">In another implementation, the plurality of unit pixels PX included in the image sensor <b>1</b> may share a floating diffusion region in units of pixel groups or smaller units. Accordingly, at least some of the photoelectric conversion elements may share some of the driving transistors, the select transistor, and the reset transistor.</p><p id="p-0029" num="0028">The logic circuit <b>20</b> may include circuits for controlling the pixel array <b>10</b>. As an example, the logic circuit <b>20</b> may include a row driver <b>21</b>, a readout circuit <b>22</b>, a column driver <b>23</b>, a control logic <b>24</b>, and the like.</p><p id="p-0030" num="0029">The row driver <b>21</b> may drive the pixel array <b>10</b> in units of rows. As an example, the row driver <b>21</b> may generate a transmission control signal controlling a transmission transistor of the pixel circuit, a reset control signal controlling the reset transistor, a select control signal controlling the select transistor, or the like, and may input the generated signal to the pixel array <b>10</b> in units of rows.</p><p id="p-0031" num="0030">The readout circuit <b>22</b> may include a correlated double sampler (CDS), an analog-to-digital converter (ADC), and the like. The correlated double samplers may be connected to the unit pixels PX through column lines. The correlated double samplers may receive pixel signals from unit pixels PX, connected to a row line selected by a row line select signal of the row driver <b>21</b>, to perform correlated double sampling. The pixel signal may be received via the column lines. The analog-to-digital converter may convert the pixel signal, detected by the correlated double sampler, into a digital pixel signal and may transmit the digital pixel signal to the column driver <b>23</b>.</p><p id="p-0032" num="0031">The column driver <b>23</b> may include a latch or buffer circuit in which a digital pixel signal may temporarily stored, an amplifier circuit, and the like, and may process a digital pixel signal received from the readout circuit <b>22</b>. The row driver <b>21</b>, the readout circuit <b>22</b>, and the column driver <b>23</b> may be controlled by the control logic <b>24</b>. The control logic <b>24</b> may include a timing controller for controlling operation timings of the row driver <b>21</b>, the readout circuit <b>22</b>, and the column driver <b>23</b>, and the like.</p><p id="p-0033" num="0032">Among the unit pixels PX, unit pixels PX disposed in the same position in a horizontal direction may share the same column line. As an example, unit pixels PX disposed in the same position in a vertical direction may be simultaneously selected by the row driver <b>21</b> and may output a pixel signal through column lines. The readout circuit <b>22</b> may simultaneously obtain a pixel signal from the unit pixels PX selected by the row driver <b>21</b> through column lines. The pixel signal may include a reset voltage and a pixel voltage, and the pixel voltage may be a voltage in which charges generated in response to light in each of the unit pixels PX are reflected on the reset voltage.</p><p id="p-0034" num="0033">In other implementations, the image sensor may further include other components and may be driven in various manners.</p><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a circuit diagram of a pixel circuit of an image sensor according to an example embodiment.</p><p id="p-0036" num="0035">Referring to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a plurality of unit pixels PX included in an image sensor <b>1</b> according to an example embodiment may be grouped by two. A pixel circuit, corresponding to each of the grouped unit pixels PX, may include a plurality of semiconductor devices for processing charges generated by photodiodes PD<b>1</b> and PD<b>2</b>, together with the photodiodes PD<b>1</b> and PD<b>2</b> corresponding to the plurality of unit pixels PX.</p><p id="p-0037" num="0036">As an example, a pixel circuit may include first and second photodiodes PD<b>1</b> and PD<b>2</b>, first and second transmission transistors TX<b>1</b> and TX<b>2</b>, a reset transistor RX, a select transistor SX, and a driving transistor DX. The first and second photodiodes PD<b>1</b> and PD<b>2</b> included in the pixel circuit may share a floating diffusion region FD, the reset transistor RX, the select transistor SX, and the driving transistor DX. Gate electrodes of the first and second transmission transistors TX<b>1</b> and TX<b>2</b>, the reset transistor RX, and the select transistor SX may be connected to driving signal lines TG<b>1</b>, TG<b>2</b>, RG, and SG, respectively.</p><p id="p-0038" num="0037">In other implementations, the pixel circuit may be designed in various manners. As an example, the pixel circuit may include semiconductor devices for processing charges, generated by a photodiode, in units of the unit pixels PX.</p><p id="p-0039" num="0038">Referring again to <figref idref="DRAWINGS">FIG. <b>2</b></figref>, one pixel circuit may generate a first electric signal from the charges generated by the photodiodes PD<b>1</b> and PD<b>2</b> and may output the first electrical signal to a first column line, and another pixel circuit may generate a second electrical signal from the charges generated by the photodiodes PD<b>1</b> and PD<b>2</b> and may output the second electrical signal to a second column line. Two or more pixel circuits disposed to be adjacent to each other may share a single first column line. Similarly, two or more different pixel circuits disposed to be adjacent to each other may share a single second column line. Pixel circuits disposed to be adjacent to each other may share some semiconductor devices.</p><p id="p-0040" num="0039">The first and second transmission transistors TX<b>1</b> and TX<b>2</b> may be connected to the first and second transfer gates TG<b>1</b> and TG<b>2</b> and the first and second photodiodes PD<b>1</b> and PD<b>2</b>, respectively. The first and second transmission transistors TX<b>1</b> and TX<b>2</b> may share the floating diffusion region FD. The first and second photodiodes PD<b>1</b> and PD<b>2</b> may generate charges in proportion to the amount of externally incident light, and may accumulate the charges in each photodiode.</p><p id="p-0041" num="0040">The first and second transmission transistors TX<b>1</b> and TX<b>2</b> may sequentially transmit the charges, accumulated in the first and second photodiodes PD<b>1</b> and PD<b>2</b>, to the floating diffusion region FD, respectively. Different signals may be applied to the first and second transfer gates TG<b>1</b> and TG<b>2</b> to transmit the charges, generated by one of the first and second photodiodes PD<b>1</b> and PD<b>2</b>, to the floating diffusion region FD. Accordingly, the floating diffusion region FD may accumulate the charges generated by one of the first and second photodiodes PD<b>1</b> and PD<b>2</b>.</p><p id="p-0042" num="0041">The reset transistor RX may periodically reset the charges accumulated in the floating diffusion region FD. For example, electrodes of the reset transistor RX may be connected to the floating diffusion region FD and a power supply voltage VDD. When the reset transistor RX is turned on, the charges accumulated in the floating diffusion region FD may be discharged due to a potential difference from the power supply voltage VDD to reset the floating diffusion region FD and a voltage of the floating diffusion region FD may be the same as the power supply voltage VDD.</p><p id="p-0043" num="0042">An operation of the driving transistor DX may be controlled depending on the amount of the charges accumulated in the floating diffusion region FD. The driving transistor DX may serve as a source-follower buffer amplifier in combination with a current source disposed outside the unit pixel PX. As an example, the driving transistor DX may amplify a potential change caused by the accumulation of the charges in the floating diffusion region FD, and may output the amplified potential change to an output line Vout.</p><p id="p-0044" num="0043">The select transistor SX may select unit pixels PX to be read in units of rows. When the select transistor SX is turned on, an electrical signal output from the driving transistor DX may be transmitted to the select transistor SX.</p><p id="p-0045" num="0044">The image sensor <b>1</b> may provide an autofocusing function in at least one of pixel groups including a plurality of unit pixels sharing the floating diffusion region FD, based on the pixel circuit illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>. As an example, the image sensor <b>1</b> may provide an autofocusing function for one direction using the first photodiode PD<b>1</b> and the second photodiode PD<b>2</b>.</p><p id="p-0046" num="0045">In further detail, the logic circuit may provide an autofocusing function for a horizontal direction using a first pixel signal obtained after the first transmission transistor TX<b>1</b> is turned on and a second pixel signal obtained after the second transmission transistor TX<b>2</b> is turned on.</p><p id="p-0047" num="0046"><figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref> are plan views illustrating pixel groups included in an image sensor according to an example embodiment.</p><p id="p-0048" num="0047"><figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref> illustrate pixel groups PG corresponding to a single color filter array included in image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> according to example embodiments and configurations thereof.</p><p id="p-0049" num="0048">Referring to <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, the image sensor <b>100</b>-<b>1</b> may include a normal pixel PX<b>1</b>, an autofocusing pixel PX<b>2</b>, and a compensation pixel PXC. A pair of unit pixels PX may be included in the autofocusing pixel PX<b>2</b>. Unit pixels PX may be grouped as a pixel group PG (e.g., four unit pixels arranged in a 2-by-2 matrix may form a pixel group PG). Each pixel group PG may include a chromatic (R, G, or B) color filter CF and a transparent (W) color filter CF. The transparent (W) color filter CF may be included in the compensation pixel PXC. A device isolation layer DTI may define each unit pixel PX. A grid GR may be disposed on the device isolation layer DTI, the grid GR including a normal grid GRN (separating one color filter from another, adjacent color filter CF) and a compensation grid GRC (surrounding the transparent color filter CF included in the compensation pixel PXC). Microlenses ML may include a normal microlens ML<b>1</b>, a compensation microlens MLC, and an autofocusing microlens ML<b>2</b>. The normal microlens ML<b>1</b> may be included in the normal pixel PX<b>1</b>. The compensation microlens MLC may be included in the compensation pixel PXC. The autofocusing microlens ML<b>2</b> may be shared by the pair of unit pixels PX included in the autofocusing pixel PX<b>2</b>.</p><p id="p-0050" num="0049">One color filter array may correspond to four pixel groups PG, and each of the pixel groups PG may have a color filter CF having a predetermined color disposed thereover in a first direction (e.g., a Z direction).</p><p id="p-0051" num="0050">To summarize and further describe <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, and also referring to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, in the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b>, each of the pixel groups PG may include a plurality of unit pixels PX arranged in a 2-by-2 array. Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>3</b>B</figref>, each of the pixel groups PG may include a chromatic color filter and a transparent color filter. As an example, in each of the pixel groups PG, the chromatic color filter and the transparent color filter may be alternately arranged in a second direction (for example, an X direction), perpendicular to a first direction, and a third direction (e.g., a Y direction), perpendicular to the first direction and the second direction.</p><p id="p-0052" num="0051">A plurality of unit pixels PX, included in each pixel group PG, may be defined by a device isolation layer DTI disposed therebetween, and a grid GR may be disposed on the device isolation layer DTI. Each of the plurality of unit pixels PX, separated by the device isolation layer DTI, may include a photodiode and a microlens ML disposed on the color filter CF. The microlens ML may be disposed in an uppermost portion of the unit pixels PX in the first direction, such that light is incident.</p><p id="p-0053" num="0052">The plurality of unit pixels PX included in the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> may include at least one normal pixel PX<b>1</b> and at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC. The normal pixel PX<b>1</b> and the compensation pixel PXC may be pixels for generating an image using an obtained pixel signal, and the autofocusing pixel PX<b>2</b> may a pixel for autofocusing a subject using a phase difference of incident light. The compensation pixel PXC may be a pixel for preventing crosstalk which may occur in the autofocusing pixel PX<b>2</b>.</p><p id="p-0054" num="0053">The autofocusing pixel PX<b>2</b> may include a pair of unit pixels PX arranged side by side in the second direction or the third direction. The image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref> may include an autofocusing pixel PX<b>2</b> including two unit pixels PX arranged side by side in the third direction. On the other hand, the image sensor <b>100</b>-<b>2</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref> may include an autofocusing pixel PX<b>2</b> including two unit pixels PX arranged side by side in the second direction. The compensation pixel PXC may be disposed on one side of the autofocusing pixel PX<b>2</b> in a direction in which two unit pixels PX included in the autofocusing pixel PX<b>2</b> are arranged.</p><p id="p-0055" num="0054">Referring to <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, a pair of unit pixels PX included in the autofocusing pixel PX<b>2</b> may be included in a single pixel group PG. On the other hand, referring to <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>, a pair of unit pixels PX included in the autofocusing pixel PX<b>2</b> may be included across two pixel groups PG adjacent to each other.</p><p id="p-0056" num="0055">In the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b>, each of the pixel groups PG may include a chromatic color filter CF, having at least one of green (G), red (R), and blue (B) colors, and a transparent (W) color filter CF. As an example, the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> may include green (G), red (R), blue (B), and transparent (W) color filters CF.</p><p id="p-0057" num="0056">The image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> may include a single color filter array for each of the pixel groups PG arranged in a 2-by-2 array. As an example, the pixel groups PG including the green (G) color filter may be disposed alternately with the pixel groups PG including the red (R) or blue (B) color filter in the second direction (for example, an X direction) and the third direction (e.g., a Y direction). However, in the autofocusing pixel PX<b>2</b> performing an autofocusing function, chromatic color filters CF having the same color may be disposed to be adjacent to each other, unlike other unit pixels PX, to use a phase difference of light incident on a pair of unit pixels adjacent to each other.</p><p id="p-0058" num="0057">In other words, among the pixel groups PG, a pixel group PG including only a normal pixel PX<b>1</b> and a compensation pixel PXC may include two transparent color filters CF, not adjacent to each other, and two chromatic color filters CF, not adjacent to each other.</p><p id="p-0059" num="0058">In the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> according to example embodiments, the normal pixel PX<b>1</b> may include a normal microlens ML<b>1</b>, disposed on the chromatic or transparent color filter CF, and a normal grid GRN separating one color filter from another, adjacent color filter CF. The autofocusing pixel PX<b>2</b> may include an autofocusing microlens ML<b>2</b>, shared by a pair of unit pixels PX included in the autofocusing pixel PX<b>2</b>, and a normal grid GRN. The compensation pixel PXC may include a compensation microlens MLC, disposed on the transparent color filter CF, and a compensation grid GRC.</p><p id="p-0060" num="0059">In general, in an image sensor that includes a transparent color filter, a unit pixel that is disposed on one side of an autofocusing pixel may include the transparent color filter. In this case, an autofocusing function of the image sensor performed by the autofocusing pixel may be affected by the unit pixel including the transparent color filter. For example, a unit pixel including a chromatic color filter may be disposed around one of a pair of unit pixels included in the autofocusing pixel, and another unit pixel including the transparent color filter may be disposed around the other of the pair of unit pixels included in the autofocusing pixel. In such a structure, the pair of unit pixels included in the autofocusing pixel may generate an asymmetrical output, which may cause crosstalk to occur in the autofocusing pixel and thereby deteriorate an autofocusing function of an image sensor.</p><p id="p-0061" num="0060">By comparison, in the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> according to example embodiments, the unit pixel PX that is adjacent to the autofocusing pixel PX<b>2</b> and includes the transparent color filter CF may be formed as the compensation pixel PXC to address the above issue. That is, the compensation pixel PXC may include the compensation microlens MLC, having a size smaller than a size of the normal microlens ML<b>1</b> included in the normal pixel PX<b>1</b>, to compensate for or prevent the asymmetrical output generated in the pair of unit pixels PX included in the autofocusing pixel PX<b>2</b>. Accordingly, the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> may perform an improved autofocusing function, as compared with the case in which the compensation pixel PXC is not included.</p><p id="p-0062" num="0061">Additionally, with respect to the above, the compensation microlens MLC included in the compensation pixel PXC has a size that is smaller than a size of the normal microlens ML<b>1</b>, which could cause a loss in sensitivity of the compensation pixel PXC. However, in the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> according to example embodiments, the compensation grid GRC surrounding the transparent color filter CF (included in the compensation pixel PXC) may be formed to be smaller than a normal grid, so that an area of an opening of a pixel may be increased to significantly reduce loss in sensitivity.</p><p id="p-0063" num="0062"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a cross-sectional view illustrating an image sensor according to an example embodiment.</p><p id="p-0064" num="0063"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a cross-sectional view of the image sensor <b>100</b>-<b>1</b>, illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, taken along line I-I&#x2032;.</p><p id="p-0065" num="0064">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the image sensor <b>100</b>-<b>1</b> may include a substrate <b>110</b> having a first surface <b>111</b> and a second surface <b>112</b> opposing each other, a photodiode PD disposed in the substrate <b>110</b> in each of a plurality of unit pixels PX, and a device isolation layer DTI disposed between the plurality of unit pixels PX.</p><p id="p-0066" num="0065">The plurality of unit pixels PX may include at least one normal pixel PX<b>1</b>, at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC arranged in a direction that is parallel to the first surface <b>111</b> (e.g., a Y direction).</p><p id="p-0067" num="0066">In the normal pixel PX<b>1</b>, a color filter CF, a light transmitting layer <b>130</b>, and normal microlenses ML<b>1</b> may be sequentially disposed. As an example, in the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the color filter CF included in the normal pixel PX<b>1</b> may be a blue (B) color filter.</p><p id="p-0068" num="0067">Light, incident through the normal microlens ML<b>1</b>, may be incident on the photodiode PD included in the normal pixel PX<b>1</b>. As described above, the normal pixel PX<b>1</b> may generate an image using a corresponding normal microlens ML<b>1</b> and a corresponding photodiode PD.</p><p id="p-0069" num="0068">In the autofocusing pixel PX<b>2</b>, a color filter CF corresponding to the autofocusing pixel PX<b>2</b>, a light transmitting layer <b>130</b>, and an autofocusing microlens ML<b>2</b> may be sequentially disposed on the first surface <b>111</b> of the substrate <b>110</b>. As an example, in the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the color filter CF included in the autofocusing pixel PX<b>2</b> may be a green (G) color filter, and the autofocusing microlens ML<b>2</b> may have a shape extending in a third direction (e.g., a Y direction) to correspond to the autofocusing pixel PX<b>2</b>.</p><p id="p-0070" num="0069">In the compensation pixel PXC, a transparent color filter CF, a light transmitting layer <b>130</b>, and a compensation microlens MLC may be sequentially disposed on the first surface <b>111</b> of the substrate <b>110</b>. The compensation microlens MLC may have a size, e.g., an area in a plan view, that is smaller than a size of the normal microlens ML<b>1</b>. As an example, the compensation microlens MLC may have the same refractive index as the normal microlens ML<b>1</b> and have a diameter that is smaller than a diameter of the normal microlens ML<b>1</b>.</p><p id="p-0071" num="0070">Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>4</b></figref> together, the color filters CF included in the image sensor <b>100</b>-<b>1</b> may be separated from each other by the grid GR disposed on the device isolation layer DTI. The grid GR may include a metal or a transparent material. In <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the image sensor <b>100</b>-<b>1</b> is illustrated as an example of a grid GR including a transparent material.</p><p id="p-0072" num="0071">Among grids GR included in the image sensor <b>100</b>-<b>1</b>, some grids GR may have different sizes. For example, in the image sensor <b>100</b>-<b>1</b>, grids GR may include a normal grid GRN and a compensation grid GRC.</p><p id="p-0073" num="0072">In other implementations, the image sensor <b>100</b>-<b>1</b> may include grids GR having various sizes.</p><p id="p-0074" num="0073">Referring to <figref idref="DRAWINGS">FIGS. <b>3</b>A and <b>4</b></figref>, the transparent color filter CF included in the compensation pixel PXC may be separated from other, adjacent color filters CF by the compensation grid GRC. The color filter CF, included in the normal pixel PX<b>1</b> and the autofocusing pixel PX<b>2</b>, may be separated from other, adjacent color filters CF by a normal grid GRN having a size greater than a size of the compensation grid GRC. As an example, the compensation grid GRC may have a length shorter than a length of the normal grid GRN in all directions.</p><p id="p-0075" num="0074">A size of a grid GR disposed between two different types of adjacent pixels may correspond to a size of a smaller microlens ML, among microlenses ML included in the two different types of adjacent pixels. As an example, a grid GR disposed between the compensation pixel PXC and the normal pixel PX<b>1</b> may correspond to a size of a compensation microlens MLC, which has a smaller size, among the compensation and normal microlenses MLC and ML<b>1</b>. Accordingly, the compensation grid GRC may be disposed between the compensation pixel PXC and the normal pixel PX<b>1</b>.</p><p id="p-0076" num="0075">Due to a difference in size between the grids GR, the opening of the normal pixel PX<b>1</b> may be smaller than the opening of the compensation pixel PXC. For example, in a direction parallel to the third direction (e.g., a Y direction), the color filter CF included in the normal pixel PX<b>1</b> may have a length that is shorter than a length of the color filter CF included in the compensation pixel PXC. Thus, in the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the color filter CF included in the normal pixel PX<b>1</b> may have a length L<b>1</b> and the color filter CF included in the compensation pixel PXC may have a length Lc that is greater than L<b>1</b>.</p><p id="p-0077" num="0076">As described above, in the image sensor <b>100</b>-<b>1</b> according to an example embodiment, an opening of the compensation pixel PXC may be formed to be larger than an opening of each of the other pixels to significantly reduce loss in sensitivity which may occur due to a size of the compensation microlens MLC.</p><p id="p-0078" num="0077">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, in the image sensor <b>100</b>-<b>1</b>, a pixel circuit may be disposed below the photodiode PD. The pixel circuit may be operated to obtain a pixel signal from the plurality of unit pixels PX.</p><p id="p-0079" num="0078">The pixel circuit may include interconnection patterns <b>170</b> and an insulating layer <b>180</b> covering the interconnection patterns <b>170</b>, and may be disposed on the second surface <b>112</b> of the substrate <b>110</b>.</p><p id="p-0080" num="0079">Although not illustrated in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the pixel circuit may include a plurality of elements, including a transmission transistor and a floating diffusion region.</p><p id="p-0081" num="0080"><figref idref="DRAWINGS">FIGS. <b>5</b> to <b>7</b></figref> are plan views illustrating pixels groups included in image sensors according to example embodiments, respectively.</p><p id="p-0082" num="0081">As described above, in the image sensors <b>100</b>-<b>1</b> and <b>100</b>-<b>2</b> according to example embodiments, each of the pixel groups PG may include a chromatic color filter CF, having at least one of green (G), red (R), and blue (B) colors, and a transparent (W) color filter CF.</p><p id="p-0083" num="0082">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, similarly to the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, an image sensor <b>200</b> according to an example embodiment may include a plurality of unit pixels PX including at least one normal pixel PX<b>1</b>, at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC, and each of the pixels may include a corresponding microlens ML and a corresponding grid GR.</p><p id="p-0084" num="0083">Pixel groups PG included in the image sensor <b>200</b> may each include two transparent color filters CF, not adjacent to each other, and two chromatic color filters CF, not adjacent to each other. In the image sensor <b>200</b>, the chromatic color filter CF may include a red (R) or blue (B) color filter and a green (G) color filter. The pixel group PG including the red (R) color filter and the pixel group PG including the blue (B) color filter may be alternately disposed in a second direction and a third direction.</p><p id="p-0085" num="0084">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, similarly to the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, an image sensor <b>300</b> according to an example embodiment may include a plurality of unit pixels PX including at least one normal pixel PX<b>1</b>, at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC, and each of the pixels may include a corresponding microlens ML and a corresponding grid GR.</p><p id="p-0086" num="0085">Pixel groups PG included in the image sensor <b>300</b> may each include two transparent color filters CF, not adjacent to each other, and two chromatic color filters CF, not adjacent to each other. In the image sensor <b>300</b>, the chromatic color filter CF may be one of cyan (C), magenta (M), and yellow (Y) color filters. Each of the pixel groups PG may include a cyan (C) or magenta (M) color filter and a yellow (Y) color filter. A pixel group PG including the magenta (M) color filter and a pixel group PG including the cyan (C) color filter may be alternately disposed in a second direction and a third direction.</p><p id="p-0087" num="0086">Referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref>, similarly to the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, an image sensor <b>400</b> according to an example embodiment may a plurality of unit pixels PX including at least one normal pixel PX<b>1</b>, at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC, and each of the pixels may include a corresponding microlens ML and a corresponding grid GR.</p><p id="p-0088" num="0087">Pixel groups PG included in the image sensor <b>400</b> may each include two transparent color filters CF, not adjacent to each other, and two chromatic color filters CF, not adjacent to each other. In the image sensor <b>400</b>, each of the pixel groups PG may include a red (R) color filter and a blue (B) color filter, not adjacent to each other.</p><p id="p-0089" num="0088">The above-described arrays of the color filters included in the image sensors <b>200</b>, <b>300</b>, and <b>400</b> illustrated in <figref idref="DRAWINGS">FIGS. <b>5</b> to <b>7</b></figref> are only examples, and, e.g., an image sensor may include color filters having various patterns.</p><p id="p-0090" num="0089">In the above-described example embodiments, an image sensor may include a normal pixel PX<b>1</b>, an autofocusing pixel PX<b>2</b>, and a compensation pixel PXC disposed on one side of the autofocusing pixel PX<b>2</b>. The compensation pixel PXC may include a compensation microlens MLC having a small size and compensation grid GRC having a small size.</p><p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a plan view illustrating a pixel array included in an image sensor according to an example embodiment.</p><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates an example of the pixel array <b>100</b>A of the image sensor <b>100</b>-<b>2</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>B</figref>.</p><p id="p-0093" num="0092">The pixel array <b>100</b>A may include a plurality of unit pixels PX arranged in a direction parallel to an upper surface of a substrate, and a logic circuit (not shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>) for obtaining a pixel signal from the plurality of unit pixels PX.</p><p id="p-0094" num="0093">In the pixel array <b>100</b>A, each of the plurality of unit pixels PX may be defined by a device isolation layer. The plurality of unit pixels PX may constitute a pixel group PG for every 2-by-2 array. The pixel groups PG may include a color filter having a color filter array CFA having a regular pattern in every 2-by-2 array.</p><p id="p-0095" num="0094">An autofocusing pixel PX<b>2</b> may include a pair of unit pixels PX arranged side by side, and the pair of unit pixels PX may include a chromatic color filters having the same color. Accordingly, the color filter array CFA may be irregular in some pixel groups PG.</p><p id="p-0096" num="0095">Each of the plurality of unit pixels PX may be one of a normal pixel PX<b>1</b>, an autofocusing pixel PX<b>2</b>, and a compensation pixel PXC. Each of the plurality of unit pixels PX may include color filters, separated from each other by a grid GR disposed on a device isolation layer, and microlenses ML disposed on the color filters.</p><p id="p-0097" num="0096">The compensation pixel PXC may be disposed on one side of the autofocusing pixel, and may include a transparent color filter. The compensation pixel PXC may be formed to compensate for a signal output from the autofocusing pixel PX<b>2</b>. As an example, the signal output from the autofocusing pixel PX<b>2</b> may be a signal for performing an autofocusing function, and the compensation pixel PXC may compensate for an asymmetric output signal to improve the autofocusing function of the image sensor <b>100</b>-<b>2</b>. The compensation may be implemented by a compensation microlens MLC included in the compensation pixel PXC. The compensation microlens MLC may be smaller than a normal microlens ML<b>1</b> included in a normal pixel PX<b>1</b>. Loss in sensitivity in the compensation pixel PXC, caused by a difference in size between the microlenses ML, may be improved, e.g., mitigated, using the compensation grid GRC smaller than the normal grid GRN.</p><p id="p-0098" num="0097">In connection with <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, the image sensor <b>100</b>-<b>1</b> is described as including a single autofocusing pixel PX<b>2</b> corresponding to a single pixel group PG. However, in other implementations, at least one of the plurality of pixel groups PG included in the image sensor <b>100</b>-<b>1</b> may not include the autofocusing pixel PX<b>2</b>. Also, similarly to the pixel array <b>100</b>A of the image sensor <b>100</b>-<b>2</b> illustrated in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, one autofocusing pixel PX<b>2</b> may correspond to two pixel groups PG, e.g., a pair of unit pixels PX included in the autofocusing pixel PX<b>2</b> may be disposed in each of two pixel groups PG that are adjacent to each other.</p><p id="p-0099" num="0098"><figref idref="DRAWINGS">FIGS. <b>9</b> to <b>12</b></figref> are diagrams illustrating image sensors according to example embodiments, respectively.</p><p id="p-0100" num="0099">Referring to <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>11</b></figref>, similarly to the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, image sensors <b>500</b> and <b>600</b> according to example embodiments may each include a plurality of unit pixels PX including at least one normal pixel PX<b>1</b>, at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC, and each of the pixels may include a corresponding microlens ML and a corresponding grid GR.</p><p id="p-0101" num="0100">The autofocusing pixels PX<b>2</b> included in the image sensors <b>500</b> and <b>600</b> may include a pair of unit pixels PX arranged side by side in a third direction (e.g., a Y direction), perpendicular to a first direction (e.g., a Z direction). The pair of unit pixels PX included in the autofocusing pixel PX<b>2</b> may share an autofocusing microlens ML<b>2</b> and a chromatic color filter CF.</p><p id="p-0102" num="0101">In <figref idref="DRAWINGS">FIGS. <b>9</b> and <b>10</b></figref>, the chromatic color filter CF in the image sensors <b>500</b> and <b>600</b> is illustrated as being a green (G) color filter. However, this is only an example and may be varied. In addition, an array of color filters and an array of a plurality of unit pixels PX may be varied relative to those illustrated in the drawings.</p><p id="p-0103" num="0102">A compensation pixel PXC included in each of the image sensors <b>500</b> and <b>600</b> may be disposed on one side of the autofocusing pixel PX<b>2</b> to compensate for a signal output from the autofocusing pixel PX<b>2</b>. The compensation pixel PXC may include a transparent (W) color filter, and may have a structure different from that of the normal pixel PX<b>1</b>.</p><p id="p-0104" num="0103">Referring to <figref idref="DRAWINGS">FIG. <b>9</b></figref>, a compensation pixel PXC included in the image sensor <b>500</b> may include a compensation microlens MLC smaller than a normal microlens ML<b>1</b> included in the normal pixel PX<b>1</b>. However, unlike the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, a grid included in the compensation pixel PXC may be the same as a normal grid GRN included in the normal pixel PX<b>1</b>.</p><p id="p-0105" num="0104">On the other hand, referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the compensation pixel PXC included in the image sensor <b>600</b> may include a compensation grid GRC smaller than the normal grid GRN included in the normal pixel PX<b>1</b>. However, unlike the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, a microlens ML included in the compensation pixel PXC may be the same as the normal microlens ML<b>1</b> included in the normal pixel PX<b>1</b>.</p><p id="p-0106" num="0105">Referring to <figref idref="DRAWINGS">FIGS. <b>10</b> and <b>12</b></figref>, the image sensors <b>500</b> and <b>600</b> according to example embodiments may include substrates <b>510</b> and <b>610</b> having first surfaces <b>511</b> and <b>611</b> and second surfaces <b>512</b> and <b>612</b> opposing each other, photodiodes PD disposed in the substrates <b>510</b> and <b>610</b> in each of a plurality of unit pixels PX, and device isolation layers DTI disposed between the plurality of unit pixels PX. The plurality of unit pixels PX may include at least one normal pixel PX<b>1</b>, at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC arranged in a direction that is parallel to the first surfaces <b>511</b> and <b>611</b>, respectively.</p><p id="p-0107" num="0106">Referring to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the compensation pixel PXC included in the image sensor <b>500</b> may include a compensation microlens MLC that is smaller than the normal microlens ML<b>1</b> included in the normal pixel PX<b>1</b>.</p><p id="p-0108" num="0107">On the other hand, referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the compensation pixel PXC included in the image sensor <b>600</b> may include a compensation grid GRC that is smaller than the normal grid GRN included in the normal pixel PX<b>1</b>. As an example, the compensation grid GRC may have a length shorter than a length of the normal grid GRN in all directions. Accordingly, the compensation pixel PXC of the image sensor <b>600</b> may have an opening that is wider than an opening of the normal pixel PX<b>1</b>.</p><p id="p-0109" num="0108"><figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref> are a plan view and a cross-sectional view illustrating a pixel array included in an image sensor according to an example embodiment, respectively.</p><p id="p-0110" num="0109">Referring to <figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref>, an image sensor <b>700</b> according to an example embodiment may include a pixel array in which a plurality of unit pixels PX are arranged. A plurality of unit pixels PX arranged in an 8-by-8 array are arranged in <figref idref="DRAWINGS">FIG. <b>13</b></figref>, as an example.</p><p id="p-0111" num="0110">In another implementation, the pixel array may include more unit pixels PX.</p><p id="p-0112" num="0111">In the image sensor <b>700</b>, the microlens ML and the grid GR that are included in the plurality of unit pixels PX may be decreased in size in a direction toward an edge of the pixel array. As an example, a microlens MLa included in unit pixels PX disposed in a central portion of a pixel array may have a first size, and a microlens MLb included in unit pixels disposed outside the central portion of the pixel array may have a second size that is smaller than the first size. In addition, a microlens included in unit pixels PX disposed on an edge of the pixel array may have a third size that is smaller than the second size.</p><p id="p-0113" num="0112">Similarly, a grid GRc disposed on a device isolation layer DTI that defines the unit pixels PX disposed on the edge of the pixel array may be smaller than a grid GRb disposed on a device isolation layer DTI that defines the unit pixels PX disposed in the pixel array. In addition, a grid GRa disposed on a device isolation layer DTI that defines the unit pixels PX disposed in the central portion of the pixel array may be larger than a grid GRb disposed on a device isolation layer that defines unit pixels disposed outside thereof.</p><p id="p-0114" num="0113">In the image sensor <b>700</b>, a size of the grid GR disposed between pixels including microlenses ML having different sizes may correspond to a size of a smaller microlens of microlenses included in two adjacent pixels.</p><p id="p-0115" num="0114">Similarly to the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>, the image sensor <b>700</b> may include a plurality of unit pixels PX including at least one normal pixel PX<b>1</b>, at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC, and each of the pixels may include a corresponding microlens ML and a corresponding grid GR.</p><p id="p-0116" num="0115">The image sensor <b>700</b> may prevent lens shading from occurring in an image generated using a difference in structures between a microlens ML and a grid GR in terms of the entire pixel array.</p><p id="p-0117" num="0116">In the image sensor <b>700</b>, the compensation pixel PXC, disposed on one side of the autofocusing pixel PX<b>2</b> included in the image sensor <b>700</b> and including a transparent (W) color filter, may prevent crosstalk in the autofocusing pixel PX<b>2</b> and may improve an autofocusing function of the image sensor <b>700</b>.</p><p id="p-0118" num="0117">Referring to <figref idref="DRAWINGS">FIG. <b>14</b></figref>, in the pixel array of the image sensor <b>700</b>, a central axis of each of the plurality of unit pixels PX and an optical axis of the microlens ML included in each of the plurality of unit pixels PX may not overlap each other in a first direction (e.g., a Z direction). As an example, a distance between the central axis of the unit pixel PX and the optical axis of the microlens ML may be increased in a direction toward an edge of the pixel array.</p><p id="p-0119" num="0118">In other implementations, the array of the color filters CF included in the image sensor <b>700</b> may be designed in various manners, and not only a size of the microlens ML and a size of the grid GR but also a shape of the unit pixels PX may be variously modified.</p><p id="p-0120" num="0119"><figref idref="DRAWINGS">FIGS. <b>15</b> and <b>16</b></figref> are a plan view and a cross-sectional view illustrating a pixel array included in an image sensor according to an example embodiment, respectively.</p><p id="p-0121" num="0120">Each of <figref idref="DRAWINGS">FIGS. <b>15</b> and <b>16</b></figref> may correspond to the image sensor <b>700</b> illustrated in <figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref>.</p><p id="p-0122" num="0121">Referring to <figref idref="DRAWINGS">FIGS. <b>15</b> and <b>16</b></figref>, an image sensor <b>800</b> according to an example embodiment may include a pixel array in which a plurality of unit pixels PX are arranged.</p><p id="p-0123" num="0122">The image sensor <b>800</b> may include a plurality of unit pixels PX including at least one normal pixel PX<b>1</b>, at least one autofocusing pixel PX<b>2</b>, and at least one compensation pixel PXC, and each of the pixels may include a corresponding microlens ML and a corresponding grid GR. The autofocusing pixel PX<b>2</b> may include a pair of unit pixels PX arranged side by side in one direction, and the compensation pixel PXC may be arranged on one side of the autofocusing pixel PX<b>2</b> in the one direction.</p><p id="p-0124" num="0123">In the image sensor <b>800</b>, a microlens ML and a grid GR included in the plurality of unit pixels PX may be decreased in size in a direction toward an edge of the pixel array. At the same time, the compensation pixel PXC may include a compensation microlens MLC and a compensation grid GRC disposed on a transparent (W) color filter, and each of the compensation microlens MLC and the compensation grid GRC may be smaller than a normal microlens ML<b>1</b> and a normal grid GRN included in a normal pixel PX<b>1</b>.</p><p id="p-0125" num="0124">As an example, a microlens MLa included in the unit pixels PX disposed in a central portion of the pixel array may have a first size, and a microlens MLb included in the unit pixels PX disposed outside the central portion of the pixel array may have a second size smaller than the first size. In addition, a microlens MLc included in unit pixels PX disposed on an edge of the pixel array may have a third size smaller than the second size.</p><p id="p-0126" num="0125">In addition, the microlenses ML and the grid GR included in the compensation pixel PXC may be smaller than microlenses ML and a grid GR included in the normal pixel PX<b>1</b> disposed therearound. As an example, a microlens MLd included in the compensation pixel PXC disposed on the edge of the pixel array may be smaller than the microlens MLc having the third size.</p><p id="p-0127" num="0126">Similarly, the transparent color filter included in the compensation pixel PXC disposed on the edge of the pixel array may be separated from the adjacent color filter by a grid GRd having a size smaller than a size of the grid GRc included in the adjacent normal pixel PX<b>1</b>.</p><p id="p-0128" num="0127">Similarly, the grid GRc disposed on the device isolation layer DTI defining the unit pixels PX disposed on the edge of the pixel array may be smaller than the grid GRb disposed on the device isolation layer DTI defining the unit pixels PX disposed inside thereof.</p><p id="p-0129" num="0128">In addition, a grid GRa disposed on the device isolation layer DTI defining the unit pixels PX disposed in the central portion of the pixel array may be larger than the grid GRb disposed on the device isolation layer DTI defining the unit pixels PX disposed outside thereof.</p><p id="p-0130" num="0129">Similarly to the image sensor <b>700</b> illustrated in <figref idref="DRAWINGS">FIGS. <b>13</b> and <b>14</b></figref>, the image sensor <b>800</b> may prevent lens shading from occurring in an image generated using a difference in structures between the microlens ML and the grid GR in terms of the entire pixel array.</p><p id="p-0131" num="0130">In addition, the compensation pixel PXC, including a transparent (W) color filter and disposed on one side of the autofocusing pixel PX<b>2</b> included in the image sensor <b>800</b>, may prevents crosstalk in the autofocusing pixel PX<b>2</b> and may improve an autofocusing function of the image sensor <b>800</b>.</p><p id="p-0132" num="0131"><figref idref="DRAWINGS">FIGS. <b>17</b>A to <b>17</b>F</figref> are cross-sectional views illustrating a process of forming an image sensor according to an example embodiment.</p><p id="p-0133" num="0132"><figref idref="DRAWINGS">FIGS. <b>17</b>A to <b>17</b>F</figref> are cross-sectional views illustrating sequential operations of a process of manufacturing the image sensor <b>100</b>-<b>1</b> according to an example embodiment described with reference to <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>.</p><p id="p-0134" num="0133">Referring to <figref idref="DRAWINGS">FIG. <b>17</b>A</figref>, the image sensor <b>100</b>-<b>1</b> may be manufactured by forming a device isolation layer DTI through a trench formed on a substrate <b>110</b>.</p><p id="p-0135" num="0134">As an example, a mask layer may be stacked on one surface of the substrate <b>110</b> to form a trench only in a space in which a device isolation layer DTI is to be formed. The trench may not be formed in a space in which a mask layer is present, and an insulating material may fill a trench, formed in a space in which the mask layer is absent, to form the device isolation layer DTI. The mask layer may then be removed by a polishing process, together with a portion of the substrate <b>110</b> and a portion of the device isolation layer DTI.</p><p id="p-0136" num="0135">An upper surface of the substrate <b>110</b>, remaining after the mask layer is removed by the polishing process, may be defined as a second surface <b>112</b>.</p><p id="p-0137" num="0136">Referring to <figref idref="DRAWINGS">FIG. <b>17</b>B</figref>, a pixel circuit may be disposed on the second surface <b>112</b> remaining after the polishing process is performed. As described above, the pixel circuit may include a plurality of elements, interconnection patterns <b>170</b> connected to the plurality of elements, and an insulating layer <b>180</b> covering the plurality of elements and the interconnection patterns <b>170</b>. The pixel circuit may be formed to control an operation of the image sensor <b>100</b>-<b>1</b>.</p><p id="p-0138" num="0137">Portions of the substrate <b>110</b> and the device isolation layer DTI, opposing the second surface <b>112</b> of the substrate <b>110</b>, may be removed by a polishing process. Thus, an internal structure and a pixel circuit of the substrate <b>110</b> included in the image sensor <b>100</b>-<b>1</b> may be formed.</p><p id="p-0139" num="0138">An upper surface of the substrate <b>110</b>, opposing the substrate <b>110</b> remaining after being removed in the polishing process, may be defined as a first surface <b>111</b>.</p><p id="p-0140" num="0139">Referring to <figref idref="DRAWINGS">FIG. <b>17</b>C</figref>, the device isolation layer DTI included in the image sensor <b>100</b>-<b>1</b> may penetrate through the second surface <b>112</b> and the first surface <b>111</b> of the substrate <b>110</b>. However, this may be varied, e.g., among the device isolation layers DTI, one or more device isolation layers DTI may be formed to have different lengths.</p><p id="p-0141" num="0140">The operations illustrated in <figref idref="DRAWINGS">FIGS. <b>17</b>D to <b>17</b>F</figref> may be operations of forming the upper structure of the unit pixel PX included in the image sensor <b>100</b>-<b>1</b> described with reference to <figref idref="DRAWINGS">FIG. <b>4</b></figref>.</p><p id="p-0142" num="0141">Referring to <figref idref="DRAWINGS">FIGS. <b>17</b>D to <b>17</b>F</figref>, a normal grid GRN and a compensation grid GRC may be formed on the device isolation layer DTI on the second surface <b>112</b> of the substrate <b>110</b>, a color filter CF may be formed on the grid GR and the second surface <b>112</b>, and a light transmitting layer <b>130</b> may be deposited on an upper surface of the resultant structure.</p><p id="p-0143" num="0142">Subsequently (not shown in <figref idref="DRAWINGS">FIGS. <b>17</b>D to <b>17</b>F</figref>), microlenses ML having various sizes allowing light to be incident may be deposited on an outermost side of the unit pixel PX, and may be provided as the image sensor <b>100</b>-<b>1</b> illustrated in <figref idref="DRAWINGS">FIG. <b>3</b>A</figref>.</p><p id="p-0144" num="0143">The manufacturing process may be varied depending on the configuration and effect of the image sensor <b>100</b>-<b>1</b>.</p><p id="p-0145" num="0144"><figref idref="DRAWINGS">FIGS. <b>18</b> and <b>19</b></figref> are schematic diagrams of an electronic device including an image sensor according to an example embodiment.</p><p id="p-0146" num="0145">Referring to <figref idref="DRAWINGS">FIG. <b>18</b></figref>, an electronic device <b>1000</b> may include a camera module group <b>1100</b>, an application processor <b>1200</b>, a power management integrated circuit (PMIC) <b>1300</b>, and an external memory <b>1400</b>.</p><p id="p-0147" num="0146">The camera module group <b>1100</b> may include a plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>. Although three camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>are illustrated as an example in <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the camera module group <b>1100</b> may be modified to include only two camera modules, or may be modified to include n camera modules (where n is a positive integer of 4 or more).</p><p id="p-0148" num="0147">At least one of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>included in the camera module group <b>1100</b> may include an image sensor according to one of the example embodiments described above with reference to <figref idref="DRAWINGS">FIGS. <b>1</b> to <b>17</b>F</figref>.</p><p id="p-0149" num="0148">Hereinafter, a detailed configuration of the camera module <b>1100</b><i>b </i>will be described with reference to <figref idref="DRAWINGS">FIG. <b>19</b></figref>, but the following description will be equally applied to the other camera modules <b>1100</b><i>a </i>and <b>1100</b><i>c </i>according to example embodiments.</p><p id="p-0150" num="0149">Referring to <figref idref="DRAWINGS">FIG. <b>19</b></figref>, the camera module <b>1100</b><i>b </i>may include a prism <b>1105</b>, an optical path folding element (hereinafter referred to as &#x201c;OPFE&#x201d;) <b>1110</b>, an actuator <b>1130</b>, an image sensing device <b>1140</b>, and a storage <b>150</b>.</p><p id="p-0151" num="0150">The prism <b>1105</b> may include a reflective surface <b>1107</b> of a light reflecting material to change a path of externally incident light L.</p><p id="p-0152" num="0151">The prism <b>1105</b> may change a path of light L, incident in an X direction, to an Y direction perpendicular to the X direction. The prism <b>1105</b> may rotate the reflective surface <b>1107</b> of the optical reflecting material about a central axis <b>1106</b> or may rotate the central axis <b>1106</b> in a direction &#x201c;B&#x201d; to change a path of the light incident in the X direction to the Y direction, a vertical direction. The OPFE <b>1110</b> may be moved in a Z direction perpendicular to the X direction and the Y direction.</p><p id="p-0153" num="0152">A maximum rotation angle of the prism <b>1105</b> in a direction &#x201c;A&#x201d; may be 15 degrees or less in a positive direction &#x201c;A&#x201d; and more than 15 degrees in a negative direction &#x201c;A,&#x201d; as an example.</p><p id="p-0154" num="0153">The prism <b>1105</b> may be moved at an angle of around 20 degrees, 10 degrees to 20 degrees, or 15 degrees to 20 degrees in a positive or negative direction &#x201c;B.&#x201d; The prism <b>1105</b> may be moved at the same angle in the positive or negative direction &#x201c;B,&#x201d; or may be moved at a nearly similar at an angle of around 1 degree.</p><p id="p-0155" num="0154">The prism <b>1105</b> may move the reflective surface <b>1107</b> of the light reflective material in a Z&#x2212; direction, parallel to a direction in which the central axis <b>1106</b> extends.</p><p id="p-0156" num="0155">The OPFE <b>1110</b> may include an optical lens including, e.g., m groups (where m is a positive integer). The m lenses may be moved in a third direction to change an optical zoom ratio of the camera module <b>1100</b><i>b</i>. For example, if a basic optical zoom magnification of the camera module <b>1100</b><i>b </i>is set to Z, when m optical lenses included in the OPFE <b>1110</b> are moved, the optical zoom magnification of the camera module <b>1100</b><i>b </i>may be changed to an optical zoom magnification of <b>3</b>Z, <b>5</b>Z, or more.</p><p id="p-0157" num="0156">The actuator <b>1130</b> may move the OPFE <b>1110</b> or an optical lens (hereinafter, referred to as an optical lens) to a specific position. For example, the actuator <b>1130</b> may adjust a position of the optical lens such that the sensor <b>1142</b> is disposed at a focal length of the optical lens to achieve accurate sensing. For example, the sensor <b>1142</b> may be an image sensor.</p><p id="p-0158" num="0157">The image sensing device <b>1140</b> may include a sensor <b>1142</b>, a control logic <b>1144</b>, and a memory <b>1146</b>. The sensor <b>1142</b> may sense an image of a sensing object using light L provided through an optical lens. The control logic <b>1144</b> may control the overall operation of the camera module <b>1100</b><i>b</i>. For example, the control logic <b>1144</b> may control an operation of the camera module <b>1100</b><i>b </i>in response to a control signal provided through a control signal line CSLb.</p><p id="p-0159" num="0158">The memory <b>1146</b> may store information that is used for the operation of the camera module <b>1100</b><i>b</i>, such as calibration data <b>1147</b>. The calibration data <b>1147</b> may include information used to generate image data using light L provided externally by the camera module <b>1100</b><i>b</i>. The calibration data <b>1147</b> may include, e.g., information on a degree of rotation, information on a focal length, and information on an optical axis, described above. When the camera module <b>1100</b><i>b </i>is implemented in the form of a multi-state camera having a focal length varying depending on a position of an optical lens, the calibration data <b>1147</b> may include a position-dependent (or state-dependent) focal length value of the optical lens and autofocusing-related information.</p><p id="p-0160" num="0159">The storage <b>1150</b> may store image data sensed by the sensor <b>1142</b>. The storage <b>1150</b> may be disposed outside the image sensing device <b>1140</b>, and may be implemented in the form of being stacked with a sensor chip constituting the image sensing device <b>1140</b>. The storage <b>1150</b> may be implemented as an electrically erasable programmable read-only memory (EEPROM), as an example.</p><p id="p-0161" num="0160">Referring to <figref idref="DRAWINGS">FIGS. <b>18</b> and <b>19</b></figref> together, each of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may include an actuator <b>1130</b>. Accordingly, each of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may include the same or different calibration data <b>1147</b> based on the operation of the actuator <b>1130</b> included therein.</p><p id="p-0162" num="0161">Among the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>, one camera module (for example, <b>1100</b><i>b</i>) may be a folded-lens type camera module including a prism <b>1105</b> and an OPFE <b>1110</b> described above, and each of the other cameras (for example, <b>1100</b><i>a </i>and <b>1100</b><i>c</i>) may be a vertical type camera module which does not include the prism <b>1105</b> and the OPFE <b>1110</b>.</p><p id="p-0163" num="0162">Among the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>, one camera module (for example, <b>1100</b><i>c</i>) may be, e.g., a vertical type depth camera extracting depth information using infrared rays (IR). In this case, an application processor <b>1200</b> may merge image data, provided from such a depth camera, and image data, provided from another camera module (for example, <b>1100</b><i>a </i>or <b>1100</b><i>b</i>), to generate a three-dimensional (3D) depth image.</p><p id="p-0164" num="0163">Among the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>, at least two camera modules (for example, <b>1100</b><i>a </i>and <b>1100</b><i>b</i>) may have different fields of view. In this case, e.g., optical lenses of at least two camera modules (for example, <b>1100</b><i>a </i>and <b>1100</b><i>b</i>), among the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>, may be different from each other.</p><p id="p-0165" num="0164">Fields of view of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may be different from each other. In this case, the optical lenses included in the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may also be different from each other.</p><p id="p-0166" num="0165">The plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may be disposed to be physically separated from each other, such that the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>do not use a sensing region of a single sensor <b>1142</b> after dividing the sensing region, but an independent sensor <b>1142</b> may be disposed inside each of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c. </i></p><p id="p-0167" num="0166">Returning to <figref idref="DRAWINGS">FIG. <b>18</b></figref>, the application processor <b>1200</b> may include an image processing device <b>1210</b>, a memory controller <b>1220</b>, and an internal memory <b>1230</b>. The application processor <b>1200</b> may be implemented by being separated from the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>. For example, the application processor <b>1200</b> and the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may be implemented by being separated from each other using an additional semiconductor chip.</p><p id="p-0168" num="0167">The image processing device <b>1210</b> may include a plurality of sub-processors <b>1212</b><i>a</i>, <b>1212</b><i>b</i>, and <b>1212</b><i>c</i>, an image generator <b>1214</b>, and a camera module controller <b>1216</b>. The number of the plurality of the sub-processors <b>1212</b><i>a</i>, <b>1212</b><i>b</i>, and <b>1212</b><i>c </i>may correspond to the number of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c. </i></p><p id="p-0169" num="0168">Image data, generated by the camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>, may be provided to the corresponding sub-processors <b>1212</b><i>a</i>, <b>1212</b><i>b</i>, and <b>1212</b><i>c </i>through separated image signal lines ISLa, ISLb, and ISLc. For example, image data generated by the camera module <b>1100</b><i>a </i>may be provided to the sub-processor <b>1212</b><i>a </i>through an image signal line ISLa, and image data generated by the camera module <b>1100</b><i>b </i>may be provided to the sub-processor <b>1212</b><i>b </i>through the image signal line ISLb, and image data generated by the camera module <b>1100</b><i>c </i>may be provided to the sub-processor <b>1212</b><i>c </i>through the image signal line ISLc.</p><p id="p-0170" num="0169">Image data transmission may be performed using, e.g., a camera serial interface (CSI) based on a mobile industry processor interface (MIPI).</p><p id="p-0171" num="0170">A single sub-processor may be arranged to correspond to a plurality of camera modules. For example, the sub-processor <b>1212</b><i>a </i>and the sub-processor <b>1212</b><i>c </i>may be implemented not by being separated from each other as illustrated, but by being integrated into a single sub-processor, and image data provided from the camera module <b>1100</b><i>a </i>and the camera module <b>1100</b><i>c </i>may be selected through a select element (e.g., a multiplexer), or the like, and then provided to the integrated sub-processor.</p><p id="p-0172" num="0171">The image data provided to each of the sub-processors <b>1212</b><i>a</i>, <b>1212</b><i>b</i>, and <b>1212</b><i>c </i>may be provided to the image generator <b>1214</b>. The image generator <b>1214</b> may generate an output image using image data, provided from each of the sub-processors <b>1212</b><i>a</i>, <b>1212</b><i>b</i>, and <b>1212</b><i>c</i>, based on image generating information or a mode signal.</p><p id="p-0173" num="0172">The image generator <b>1214</b> may merge at least a portion of the image data, generated by the camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>having different fields of view based on the image generating information or the mode signal, to generate an output image. Also, the image generator <b>1214</b> may select one of the image data, generated by the camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>having different fields of view based on the image generation information or the mode signal, to generate an output image.</p><p id="p-0174" num="0173">The image generating information may include a zoom signal or a zoom factor. In some embodiments, the mode signal may be, e.g., a signal based on a mode selected from a user.</p><p id="p-0175" num="0174">When the image generating information is a zoom signal (a zoom factor) and the camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>have different fields of view, the image generator <b>1214</b> may perform different operations depending on the type of the zoom signal. For example, when the zoom signal is a first signal, the image generator <b>1214</b> may merge image data output from the camera module <b>1100</b><i>a </i>and the image data output from the camera module <b>1100</b><i>c </i>and may then output an output image using a merged image signal and image data output from the camera module <b>1100</b><i>b </i>not used for the merging. When the zoom signal is a second signal different from the first signal, the image generator <b>1214</b> may not perform such an image data merging operation and may select one of the image data, output from the camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>, to generate an output image.</p><p id="p-0176" num="0175">The image generator <b>1214</b> may receive a plurality of pieces of image data having different exposure times from at least one of the plurality of sub-processors <b>1212</b><i>a</i>, <b>1212</b><i>b</i>, and <b>1212</b><i>c</i>, and may perform high dynamic range (HDR) processing on the plurality of pieces of image data to generate merged image data having an increased dynamic range.</p><p id="p-0177" num="0176">The camera module controller <b>1216</b> may provide a control signal to each of the camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>. The control signals, generated by the camera module controller <b>1216</b>, may be provided to the corresponding camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>through separated control signal lines CSLa, CSLb, and CSLc, respectively.</p><p id="p-0178" num="0177">One of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may be designated as a master camera (for example, <b>1100</b><i>b</i>) based on the image generating information or a mode signal including a zoom signal, and the other camera modules (for example, <b>1100</b><i>a </i>and <b>1100</b><i>c</i>) may be designated as slave cameras. Such information may be included in the control signal and provided to the corresponding camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>through the separated control signal lines CSLa, CSLb, and CSLc.</p><p id="p-0179" num="0178">A camera module, operating as a master camera and a slave camera, may vary depending on a zoom factor or an operating mode signal. For example, when a field of view of the camera module <b>1100</b><i>a </i>is wider than a field of view of the camera module <b>1100</b><i>b </i>and the zoom factor represents a low zoom magnification, the camera module <b>1100</b><i>b </i>may operate as a master camera and the camera module <b>1100</b><i>a </i>may operate as a slave camera. Conversely, when the zoom factor represents a high zoom magnification, the camera module <b>1100</b><i>a </i>may operate as a master camera and the camera module <b>1100</b><i>b </i>may operate as a slave camera.</p><p id="p-0180" num="0179">The control signal provided from the camera module controller <b>1216</b> to each of the camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may include a synchronization enable signal. For example, when the camera module <b>1100</b><i>b </i>is a master camera and the camera modules <b>1100</b><i>a </i>and <b>1100</b><i>c </i>are slave cameras, the camera module controller <b>1216</b> may transmit the synchronization enable signal to the camera module <b>1100</b><i>b</i>. The camera module <b>1100</b><i>b</i>, receiving the synchronization enable signal, may generate a synchronization signal based on the received synchronization enable signal, and may transmit the generated synchronization signal to the camera modules <b>1100</b><i>a </i>and <b>1100</b><i>c</i>. The camera module <b>1100</b><i>b </i>and the camera modules <b>1100</b><i>a </i>and <b>1100</b><i>c </i>may transmit image data to the application processor <b>1200</b> in synchronization with the synchronization signal.</p><p id="p-0181" num="0180">The control signal provided from the camera module controller <b>1216</b> to the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may include mode information on the mode signal. The plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may operate in a first operating mode and a second operating mode, based on the mode information, in relation to a sensing speed.</p><p id="p-0182" num="0181">The plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may generate an image signal at a first speed (for example, generate an image signal at a first frame rate) in a first operating mode, may encode the generated image signal at a second speed higher than the first speed (for example, encode the generated image signal at a second frame rate higher than the first frame rate), and may transmit the encoded image signal to the application processor <b>1200</b>. In this case, the second speed may be 30 times or less of the first speed.</p><p id="p-0183" num="0182">The application processor <b>1200</b> may store the received image signal, e.g., the encoded image signal, in the internal memory <b>1230</b> provided therein or the external memory <b>1400</b> outside the application processor <b>1200</b>, and then may read and decode the encoded image signal from the internal memory <b>1230</b> or the external memory <b>1400</b> and may display image data generated based on the decoded image signal. For example, among the plurality of sub-processors <b>1212</b><i>a</i>, <b>1212</b><i>b</i>, and <b>1212</b><i>c </i>of the image processing device <b>1210</b>, a corresponding sub-processor may perform a decoding process and may also perform an image processing operation on the decoded image signal.</p><p id="p-0184" num="0183">The plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>may generate an image signal at a third rate lower than the first rate (for example, generate an image signal at a third frame rate lower than the first frame rate) in the second operating mode, and may transmit the generated image signal to the application processor <b>1200</b>. The image signal provided to the application processor <b>1200</b> may be an unencoded signal. The application processor <b>1200</b> may perform image processing on the received image signal or may store the image signal in the internal memory <b>1230</b> or the external memory <b>1400</b>.</p><p id="p-0185" num="0184">The PMIC <b>1300</b> may supply power, e.g., a power supply voltage, to each of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>. For example, the PMIC <b>1300</b> may supply first power to the camera module <b>1100</b><i>a </i>through a power signal line PSLa, may supply second power to the camera module <b>1100</b><i>b </i>through a power signal line PSLb, and may supply third power to the camera module <b>1100</b><i>c </i>through a power signal line PSLc, under the control of the application processor <b>1200</b>.</p><p id="p-0186" num="0185">The PMIC <b>1300</b> may generate power corresponding to each of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c </i>in response to a power control signal PCON from the application processor <b>1200</b>, and may also adjust a level of the power. The power control signal PCON may include a power adjustment signal for each operating mode of the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>. For example, the operating mode may include a low power mode. In this case, the power control signal PCON may include information on a camera module operating in the low power mode and a set power level. Levels of the powers, respectively supplied to the plurality of camera modules <b>1100</b><i>a</i>, <b>1100</b><i>b</i>, and <b>1100</b><i>c</i>, may be the same or different from each other. Also, the levels of the powers may be dynamically changed.</p><p id="p-0187" num="0186">As described above, an image sensor according to an example embodiment may include a microlens and a grid formed to be small in a compensation pixel adjacent to an autofocusing pixel and including a transparent color filter. Accordingly, crosstalk in the autofocusing pixel may be prevented, and sensitivity in the compensation pixel may be improved.</p><p id="p-0188" num="0187">An image sensor according to an example embodiment may include a pixel including a microlens and a grid formed to be smaller in a direction toward an edge of a pixel array from a center of the pixel array. Accordingly, a crosstalk issue and a lens shading issue may be addressed.</p><p id="p-0189" num="0188">Example embodiments may provide an image sensor which may prevent crosstalk from occurring in an autofocusing pixel of an image sensor including a transparent color filter, may improve sensitivity of a pixel adjacent to the autofocusing pixel, and may generate images having improved image quality.</p><p id="p-0190" num="0189">Example embodiments have been disclosed herein, and although specific terms are employed, they are used and are to be interpreted in a generic and descriptive sense only and not for purpose of limitation. In some instances, as would be apparent to one of ordinary skill in the art as of the filing of the present application, features, characteristics, and/or elements described in connection with a particular embodiment may be used singly or in combination with features, characteristics, and/or elements described in connection with other embodiments unless otherwise specifically indicated. Accordingly, it will be understood by those of skill in the art that various changes in form and details may be made without departing from the spirit and scope of the present invention as set forth in the following claims.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An image sensor, comprising:<claim-text>a substrate, having a first surface and a second surface opposing each other in a first direction, on which a plurality of unit pixels are arranged, the plurality of unit pixels including at least one normal pixel, at least one autofocusing pixel, and at least one compensation pixel arranged parallel to the first surface;</claim-text><claim-text>a photodiode disposed in the substrate in each of the plurality of unit pixels; and</claim-text><claim-text>a device isolation layer disposed between the plurality of unit pixels, wherein:</claim-text><claim-text>the plurality of unit pixels includes color filters, disposed on the first surface and separated from each other by a grid, and microlenses disposed on the color filters,</claim-text><claim-text>the normal pixel includes a normal microlens, and</claim-text><claim-text>the compensation pixel is disposed on one side of the autofocusing pixel and includes a transparent color filter and a compensation microlens, which is smaller than the normal microlens.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The image sensor as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the autofocusing pixel includes a pair of unit pixels disposed side by side in a second direction, perpendicular to the first direction, and sharing an autofocusing microlens.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The image sensor as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the pair of unit pixels included in the autofocusing pixel include chromatic color filters having a same color.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The image sensor as claimed in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the compensation pixel is disposed on one side of the autofocusing pixel in the second direction.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The image sensor as claimed in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein a pixel disposed on the other side of the autofocusing pixel in the second direction is the normal pixel including a chromatic color filter.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. (canceled)</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The image sensor as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the grid includes a metal or a transparent material.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The image sensor as claimed in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the normal pixel includes a normal grid, and</claim-text><claim-text>the transparent color filter included in the compensation pixel is separated from adjacent color filters by a compensation grid, which is smaller than the normal grid.</claim-text></claim-text></claim><claim id="CLM-09-10" num="09-10"><claim-text><b>9</b>-<b>10</b>. (canceled)</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The image sensor as claimed in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein a length of a color filter included in the normal pixel is smaller, in a second direction perpendicular to the first direction, than a length of a color filter included in the compensation pixel.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. An image sensor, comprising:<claim-text>a substrate;</claim-text><claim-text>a pixel array including a plurality of pixel groups arranged parallel to an upper surface of the substrate; and</claim-text><claim-text>a logic circuit configured to obtain pixel signals from the pixel array, wherein:</claim-text><claim-text>each of the plurality of pixel groups includes a plurality of unit pixels forming at least one of an autofocusing pixel, a compensation pixel, and a normal pixel, which are respectively defined by a device isolation layer extending in a first direction, perpendicular to the upper surface of the substrate,</claim-text><claim-text>each unit pixel includes:<claim-text>a photodiode disposed in the substrate;</claim-text><claim-text>a color filter disposed on the upper surface of the substrate and separated from an adjacent color filter by a grid; and</claim-text><claim-text>a microlens disposed on the color filter,</claim-text></claim-text><claim-text>the autofocusing pixel includes a pair of unit pixels, and</claim-text><claim-text>the compensation pixel is configured to compensate for a signal output from the autofocusing pixel, and includes a compensation microlens, smaller than the microlens included in adjacent pixels, and a transparent color filter.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The image sensor as claimed in <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein unit pixels included in the autofocusing pixel are disposed side by side in a second direction, perpendicular to the first direction, and include chromatic color filters having a same color.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The image sensor as claimed in <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein:<claim-text>each of the plurality of pixel groups includes unit pixels arranged in a 2-by-2 array,</claim-text><claim-text>the plurality of pixel groups includes a first pixel group, which includes only the normal pixel and the compensation pixel,</claim-text><claim-text>the first pixel group includes two transparent color filters, not adjacent to each other, and</claim-text><claim-text>the first pixel group includes two chromatic color filters, not adjacent to each other.</claim-text></claim-text></claim><claim id="CLM-15-16" num="15-16"><claim-text><b>15</b>-<b>16</b>. (canceled)</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The image sensor as claimed in <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the microlenses and the grid are smaller in a direction toward an edge of the pixel array.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The image sensor as claimed in <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein:<claim-text>unit pixels included in the autofocusing pixel are disposed side by side in a second direction, perpendicular to the first direction, and</claim-text><claim-text>the compensation pixel is disposed on one side of the autofocusing pixel in the second direction.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The image sensor as claimed in <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein a distance between a central axis of each of the plurality of unit pixels and an optical axis of the microlens included in each of the plurality of unit pixels is increased in a direction toward the edge of the pixel array.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The image sensor as claimed in <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the compensation pixel includes a compensation grid that is smaller than the grid included in pixels adjacent to the compensation pixel.</claim-text></claim><claim id="CLM-00021" num="00021"><claim-text><b>21</b>. The image sensor as claimed in <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein a length of the grid in a second direction, perpendicular to the first direction, and a third direction, perpendicular to the second direction, corresponds to a size of the microlens having a smaller size, among microlenses respectively corresponding to the color filters separated by the grid.</claim-text></claim><claim id="CLM-00022" num="00022"><claim-text><b>22</b>. The image sensor as claimed in <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the pair of unit pixels included in the autofocusing pixel spans two adjacent pixel groups.</claim-text></claim><claim id="CLM-00023" num="00023"><claim-text><b>23</b>. An image sensor, comprising:<claim-text>a substrate, having a first surface and a second surface opposing each other in a first direction;</claim-text><claim-text>unit pixels on the first surface;</claim-text><claim-text>a photodiode in the substrate in each of the unit pixels; and</claim-text><claim-text>a device isolation layer between the unit pixels, wherein:</claim-text><claim-text>the unit pixels form an autofocusing pixel, a normal pixel, and a compensation pixel,</claim-text><claim-text>each unit pixel has a color filter, which is separated from an adjacent color filter by a grid, and a microlens on the color filter,</claim-text><claim-text>the autofocusing pixel includes a pair of unit pixels disposed side by side in a second direction and sharing a microlens and a color filter, and</claim-text><claim-text>the compensation pixel is configured to compensate for a signal output from the autofocusing pixel, has a structure different from a structure of the normal pixel, is disposed on one side of the autofocusing pixel in the second direction, and includes a transparent color filter.</claim-text></claim-text></claim><claim id="CLM-00024" num="00024"><claim-text><b>24</b>. The image sensor as claimed in <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the compensation pixel includes a compensation microlens that is smaller than a normal microlens included in the normal pixel.</claim-text></claim><claim id="CLM-00025" num="00025"><claim-text><b>25</b>. The image sensor as claimed in <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the compensation pixel includes a compensation grid having a length that is shorter than a length of a normal grid included in the normal pixel in the second direction and a third direction, perpendicular to the second direction.</claim-text></claim></claims></us-patent-application>
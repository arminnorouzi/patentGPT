<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230001942A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230001942</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17545935</doc-number><date>20211208</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2021-0086050</doc-number><date>20210630</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>W</subclass><main-group>50</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>01</class><subclass>C</subclass><main-group>21</main-group><subgroup>36</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>B</section><class>60</class><subclass>W</subclass><main-group>60</main-group><subgroup>00</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>50</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>01</class><subclass>C</subclass><main-group>21</main-group><subgroup>3647</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>60</main-group><subgroup>001</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20200201</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2556</main-group><subgroup>45</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>B</section><class>60</class><subclass>W</subclass><main-group>2050</main-group><subgroup>146</subgroup><symbol-position>L</symbol-position><classification-value>A</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e61">AUTONOMOUS VEHICLE, CONTROL SYSTEM FOR REMOTELY CONTROLLING THE SAME, AND METHOD THEREOF</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Hyundai Motor Company</orgname><address><city>Seoul</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Kia Corporation</orgname><address><city>Seoul</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Dong Hyuk</first-name><address><city>Hanam-Si</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Hyundai Motor Company</orgname><role>03</role><address><city>Seoul</city><country>KR</country></address></addressbook></assignee><assignee><addressbook><orgname>Kia Corporation</orgname><role>03</role><address><city>Seoul</city><country>KR</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">An autonomous vehicle may include a display device configured to display a driving path of the autonomous vehicle; and an autonomous driving control apparatus including a processor that displays a situation in which driving of the driving path is impossible on the display device in augmented reality when the situation in which the driving of the driving path is impossible occurs due to an external environment during autonomous driving of the autonomous vehicle, transmits information related to a misrecognized obstacle to a control system when receiving a request for deleting the misrecognized obstacle, and receives a driving path in which the misrecognized obstacle is deleted from the control system and controls and follows the received driving path.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="191.09mm" wi="150.28mm" file="US20230001942A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="210.06mm" wi="152.32mm" file="US20230001942A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="197.02mm" wi="145.88mm" orientation="landscape" file="US20230001942A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="162.39mm" wi="149.10mm" file="US20230001942A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="181.27mm" wi="143.34mm" file="US20230001942A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="181.36mm" wi="143.51mm" file="US20230001942A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="180.26mm" wi="145.46mm" file="US20230001942A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="178.82mm" wi="144.19mm" file="US20230001942A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00008" num="00008"><img id="EMI-D00008" he="178.22mm" wi="134.37mm" file="US20230001942A1-20230105-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00009" num="00009"><img id="EMI-D00009" he="176.87mm" wi="134.37mm" file="US20230001942A1-20230105-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00010" num="00010"><img id="EMI-D00010" he="160.19mm" wi="152.99mm" file="US20230001942A1-20230105-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00011" num="00011"><img id="EMI-D00011" he="193.29mm" wi="145.80mm" file="US20230001942A1-20230105-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00012" num="00012"><img id="EMI-D00012" he="226.91mm" wi="159.68mm" file="US20230001942A1-20230105-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00013" num="00013"><img id="EMI-D00013" he="184.40mm" wi="150.54mm" file="US20230001942A1-20230105-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATION</heading><p id="p-0002" num="0001">The present application claims priority to Korean Patent Application No. 10-2021-0086050, filed on Jun. 30, 2021, the entire contents of which is incorporated herein for all purposes by this reference.</p><heading id="h-0002" level="1">BACKGROUND OF THE INVENTION</heading><heading id="h-0003" level="1">Field of the Invention</heading><p id="p-0003" num="0002">The present invention relates to an autonomous vehicle, a control system for remotely controlling the same, and a method thereof, and more particularly, to a technique for correcting an error occurring in a remote control situation of an autonomous vehicle.</p><heading id="h-0004" level="1">Description of Related Art</heading><p id="p-0004" num="0003">As an electronic technique of a vehicle develops, an interest in an autonomous vehicle that drives to a destination by recognizing a driving environment of the vehicle itself without manipulation of a driver is growing more and more.</p><p id="p-0005" num="0004">An autonomous vehicle refers to a vehicle capable of operating by itself without manipulation of a driver or a passenger.</p><p id="p-0006" num="0005">While driving in an autonomous driving mode, there may be a situation in which it is impossible to follow a driving path to the destination normally although there is no abnormality in a function of the vehicle. Accordingly, when a situation where it is impossible to follow a path occurs during autonomous driving of the autonomous vehicle, it is often difficult to follow the driving path, such as when the driver directly intervenes in control of the vehicle or when the driver's intervention is difficult, the vehicle stops.</p><p id="p-0007" num="0006">The information disclosed in this Background of the Invention section is only for enhancement of understanding of the general background of the invention and may not be taken as an acknowledgement or any form of suggestion that this information forms the prior art already known to a person skilled in the art.</p><heading id="h-0005" level="1">BRIEF SUMMARY</heading><p id="p-0008" num="0007">Various aspects of the present invention are directed to providing an autonomous vehicle, a control system for remotely controlling the same, and a method thereof, configured for securing reliability for remote control by correcting a surrounding situation recognition error through remote control during remote control of the autonomous vehicle, improving commercialization of autonomous driving.</p><p id="p-0009" num="0008">Furthermore, various aspects of the present invention are directed to providing an autonomous vehicle, a control system for remotely controlling the same, and a method thereof, configured for increasing user convenience by displaying a change in a remote control path such that a driver can intuitively check it when the remote control path is changed.</p><p id="p-0010" num="0009">The technical objects of the present invention are not limited to the objects mentioned above, and other technical objects not mentioned may be clearly understood by those skilled in the art from the description of the claims.</p><p id="p-0011" num="0010">Various aspects of the present invention are directed to providing an autonomous vehicle, including a display device configured to display a driving path of the autonomous vehicle; and an autonomous driving control apparatus including a processor that displays a situation in which driving of the driving path is impossible on the display device in augmented reality when the situation in which the driving of the driving path is impossible occurs due to an external environment during autonomous driving of the autonomous vehicle, transmits information related to a misrecognized obstacle to a control system when receiving a request for deleting the misrecognized obstacle, and receives a driving path from which the misrecognized obstacle is deleted from the control system and controls and follows the received driving path.</p><p id="p-0012" num="0011">In various exemplary embodiments of the present invention, the autonomous vehicle may further include a sensing device configured to detect the situation in which the driving of the driving path is impossible.</p><p id="p-0013" num="0012">In various exemplary embodiments of the present invention, the processor may display the driving path in which the misrecognized obstacle is deleted received from the control system on the display device in the augmented reality.</p><p id="p-0014" num="0013">In various exemplary embodiments of the present invention, the processor may display an area in which the misrecognized obstacle is deleted in the driving path and controls the area to blink for a predetermined time period.</p><p id="p-0015" num="0014">In various exemplary embodiments of the present invention, the processor may mark or block an area in which a vehicle is unable to be driven in the driving path.</p><p id="p-0016" num="0015">In various exemplary embodiments of the present invention, the processor, when the driving path is displayed on the display device in the augmented reality, may display an area of a front target for maintaining an in-vehicle distance with a vehicle in front of the autonomous vehicle, and may distinguish and displays a line thickness or a line color indicating the area of the front target during a normal driving mode and a stop control mode of the autonomous vehicle.</p><p id="p-0017" num="0016">In various exemplary embodiments of the present invention, the processor may display a front signal condition during the stop control mode.</p><p id="p-0018" num="0017">In various exemplary embodiments of the present invention, the processor may display an area of the misrecognized obstacle in the driving path, and may display a line color or line thickness indicating the area of the misrecognized obstacle separately from that of the normal driving mode.</p><p id="p-0019" num="0018">In various exemplary embodiments of the present invention, the processor may transmit information related to the misrecognized obstacle to the control system when receiving a request for deleting the misrecognized obstacle from the driver.</p><p id="p-0020" num="0019">In various exemplary embodiments of the present invention, the processor, when receiving no request for deleting the misrecognized obstacle from the driver, may request remote control of the autonomous vehicle to the control system.</p><p id="p-0021" num="0020">In various exemplary embodiments of the present invention, the processor when receiving a remote control path for the remote control request from the control system, may display the remote control path in the augmented reality.</p><p id="p-0022" num="0021">In various exemplary embodiments of the present invention, the processor may display a screen for obtaining approval for the remote control path by a driver or an occupant on the display device.</p><p id="p-0023" num="0022">In various exemplary embodiments of the present invention, the processor may follow and control the remote control path when approval for the remote control path from the driver or the occupant is completed.</p><p id="p-0024" num="0023">In various exemplary embodiments of the present invention, the processor may transmit unapproved information and an unapproved remote control path to the control system when the approval for the remote control path is not completed.</p><p id="p-0025" num="0024">In various exemplary embodiments of the present invention, the autonomous driving control apparatus may further include: a communication device configured to communicate with the control system; and a storage configured to store the remote control path received from the control system.</p><p id="p-0026" num="0025">Various aspects of the present invention are directed to providing a control system including a processor configured to display a misrecognized obstacle on a driving path of an autonomous vehicle when receiving information related to the misrecognized obstacle from the autonomous vehicle, deletes the misrecognized obstacle on the driving path of the autonomous vehicle by receiving approval from an operator, and transmits a driving path of the autonomous vehicle in which the misrecognized obstacle is deleted to the autonomous vehicle.</p><p id="p-0027" num="0026">In various exemplary embodiments of the present invention, the processor may generate a remote control path to provide the remote control path to the autonomous vehicle when receiving a request for remote control of the autonomous vehicle for avoiding the misrecognized obstacle from the autonomous vehicle.</p><p id="p-0028" num="0027">In various exemplary embodiments of the present invention, the processor may re-generate a remote control path for avoiding the misrecognized obstacle when approval for the remote control path is not received from the autonomous vehicle.</p><p id="p-0029" num="0028">Various aspects of the present invention are directed to providing a remote control method for an autonomous vehicle, including: displaying a situation in which driving of a driving path is impossible on a display device in augmented reality when the situation in which the driving of the driving path is impossible occurs due to an external environment during autonomous driving; receiving a request for deleting a misrecognized obstacle from a driver; transmitting information related to the misrecognized obstacle to a control system; and following and controlling a driving path in which the misrecognized obstacle is deleted by receiving the driving path from the control system.</p><p id="p-0030" num="0029">In various exemplary embodiments of the present invention, displaying the driving path in which the misrecognized obstacle is deleted, wherein the displaying includes displaying an area in which the misrecognized obstacle is deleted, and controlling the area to blink for a predetermined time period.</p><p id="p-0031" num="0030">According to the present technique, it is possible to secure reliability for remote control by correcting a surrounding situation recognition error through remote control during remote control of the autonomous vehicle, improving commercialization of autonomous driving.</p><p id="p-0032" num="0031">Furthermore, according to the present technique, it is possible to increase user convenience by displaying a change in a remote control path such that a driver can intuitively check it when the remote control path is changed.</p><p id="p-0033" num="0032">Furthermore, various effects which may be directly or indirectly identified through the present specification may be provided.</p><p id="p-0034" num="0033">The methods and apparatuses of the present invention have other features and advantages which will be apparent from or are set forth in more detail in the accompanying drawings, which are incorporated herein, and the following Detailed Description, which together serve to explain certain principles of the present invention.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram showing a configuration of a remote control system for an autonomous apparatus according to various exemplary embodiments of the present invention.</p><p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> illustrates a view for describing a sensing device of an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates a sensing range of a sensing device of an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of a screen displaying an obstacle in augmented reality in a normal driving mode in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example of a screen displaying an obstacle in augmented reality in a stop control mode in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example of a screen displaying an obstacle including traffic light information in augmented reality in a stop control mode in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example of a screen displaying an obstacle including traffic light information which displays a misrecognized target in augmented reality in a misrecognition mode in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>7</b></figref> and <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrate examples of a screen for deleting a misrecognized obstacle depending on a driver request according to various exemplary embodiments of the present invention.</p><p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example of a screen on which a misrecognized obstacle is displayed depending on a driver request in a control system according to various exemplary embodiments of the present invention.</p><p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an example of a screen displaying a change in a remote control path in augmented reality in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0045" num="0044"><figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a flowchart showing a remote control method for an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0046" num="0045"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates a computing system according to various exemplary embodiments of the present invention.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><p id="p-0047" num="0046">It may be understood that the appended drawings are not necessarily to scale, presenting a somewhat simplified representation of various features illustrative of the basic principles of the present invention. The specific design features of the present invention as included herein, including, for example, specific dimensions, orientations, locations, and shapes will be determined in part by the particularly intended application and use environment.</p><p id="p-0048" num="0047">In the figures, reference numbers refer to the same or equivalent parts of the present invention throughout the several figures of the drawing.</p><heading id="h-0007" level="1">DETAILED DESCRIPTION</heading><p id="p-0049" num="0048">Reference will now be made in detail to various embodiments of the present invention(s), examples of which are illustrated in the accompanying drawings and described below. While the present invention(s) will be described in conjunction with exemplary embodiments of the present invention, it will be understood that the present description is not intended to limit the present invention(s) to those exemplary embodiments. On the other hand, the present invention(s) is/are intended to cover not only the exemplary embodiments of the present invention, but also various alternatives, modifications, equivalents and other embodiments, which may be included within the spirit and scope of the present invention as defined by the appended claims.</p><p id="p-0050" num="0049">Hereinafter, some exemplary embodiments of the present invention will be described in detail with reference to exemplary drawings. It should be noted that in adding reference numerals to constituent elements of each drawing, the same constituent elements have the same reference numerals as possible even though they are indicated on different drawings. Furthermore, in describing exemplary embodiments of the present invention, when it is determined that detailed descriptions of related well-known configurations or functions interfere with understanding of the exemplary embodiments of the present invention, the detailed descriptions thereof will be omitted.</p><p id="p-0051" num="0050">In describing constituent elements according to various exemplary embodiments of the present invention, terms such as first, second, A, B, (a), and (b) may be used. These terms are only for distinguishing the constituent elements from other constituent elements, and the nature, sequences, or orders of the constituent elements are not limited by the terms. Furthermore, all terms used herein including technical scientific terms have the same meanings as those which are generally understood by those skilled in the technical field to which various exemplary embodiments of the present invention pertains (those skilled in the art) unless they are differently defined. Terms defined in a generally used dictionary shall be construed to have meanings matching those in the context of a related art, and shall not be construed to have idealized or excessively formal meanings unless they are clearly defined in the present specification.</p><p id="p-0052" num="0051">Hereinafter, various exemplary embodiments of the present invention will be described in detail with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref> to <figref idref="DRAWINGS">FIG. <b>12</b></figref>.</p><p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram showing a configuration of a remote control system for an autonomous apparatus according to various exemplary embodiments of the present invention.</p><p id="p-0054" num="0053">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the remote control system for an autonomous vehicle according to various exemplary embodiments of the present invention includes a vehicle <b>100</b> and a control system <b>200</b>, and remote control may be performed through communication between the vehicle <b>100</b> and the control system <b>200</b>. In the instant case, the vehicle <b>100</b> may include an autonomous vehicle.</p><p id="p-0055" num="0054">The vehicle <b>100</b> may include an autonomous driving control apparatus <b>120</b>, a sensing device <b>120</b>, a steering control apparatus <b>130</b>, a braking control apparatus <b>140</b>, and an engine control apparatus <b>150</b>.</p><p id="p-0056" num="0055">The autonomous driving control apparatus <b>110</b> according to the exemplary embodiment of the present invention may be implemented inside the vehicle. In the instant case, the autonomous driving control apparatus <b>110</b> may be integrally formed with internal control units of the vehicle, or may be implemented as a separate device to be connected to control units of the vehicle by a separate connection means.</p><p id="p-0057" num="0056">The autonomous driving control device <b>110</b> may request remote control to the control system <b>200</b> when a situation occurs in which driving of a driving path is impossible due to an external environment during autonomous driving.</p><p id="p-0058" num="0057">In the instant case, when the situation in which the driving of the driving path is impossible occurs due to misrecognition of an obstacle detected by the sensing device <b>120</b>, the autonomous driving control apparatus <b>110</b> may delete the misrecognized obstacle.</p><p id="p-0059" num="0058">Furthermore, the autonomous driving control apparatus <b>110</b> may display the situation in which the driving of the driving path is impossible and the misrecognized obstacle based on augmented reality such that a driver can check it at a glance.</p><p id="p-0060" num="0059">When receiving a request for deleting the misrecognized obstacle from the driver, the autonomous driving control apparatus <b>110</b> may transmit information related to the misrecognized obstacle to the control system <b>200</b>, and may continue to perform autonomous driving by receiving the remote control path in which the misrecognized obstacle is deleted from the control system <b>200</b>.</p><p id="p-0061" num="0060">In the instant case, the autonomous driving control apparatus <b>110</b> may determine that the driver has requested the deletion of the misrecognized obstacle when the driver double-touches the misrecognized obstacle or presses and holds the misrecognized obstacle for a predetermined time period.</p><p id="p-0062" num="0061">Furthermore, when the driver does not request the deletion of the misrecognized obstacle, the autonomous driving control apparatus <b>110</b> may request the remote control for avoidance control for the misrecognized obstacle to the control system. Accordingly, the autonomous driving control apparatus <b>110</b> may receive a remote control path for avoidance control for the misrecognized obstacle from the control system <b>200</b> to continue the autonomous driving.</p><p id="p-0063" num="0062">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the autonomous driving control apparatus <b>110</b> may include a communication device <b>111</b>, a storage <b>112</b>, an interface device <b>113</b>, and a processor <b>114</b>.</p><p id="p-0064" num="0063">The communication device <b>111</b> is a hardware device implemented with various electronic circuits to transmit and receive signals through a wireless or wired connection, and may transmit and receive information based on in-vehicle devices and in-vehicle network communication techniques. As an example, the in-vehicle network communication techniques may include controller area network (CAN) communication, Local Interconnect Network (LIN) communication, flex-ray communication, Ethernet communication, and the like.</p><p id="p-0065" num="0064">Furthermore, the communication device <b>111</b> may perform communication by use of a server, infrastructure, or third vehicles outside the vehicle, and the like through a wireless Internet technique or short range communication technique. Herein, the wireless Internet technique may include wireless LAN (WLAN), wireless broadband (Wibro), Wi-Fi, Worldwide Interoperability for Microwave Access (WiMAX), Ethernet communication, etc. Furthermore, short-range communication technique may include Bluetooth, ZigBee, ultra wideband (UWB), radio frequency identification (RFID), infrared data association (IrDA), and the like. For example, the communication device <b>111</b> may perform wireless communication with the control system <b>200</b>, may transmit vehicle position information (e.g., vehicle coordinates), surrounding information (e.g., obstacle information), vehicle information (e.g., overall length and width of a host vehicle), a remote control request, etc. to the control system <b>200</b>, and may receive a remote control path, an approval request for the remote control path, a remote control command, and the like from the control system <b>200</b>.</p><p id="p-0066" num="0065">The storage <b>112</b> may store sensing results of the sensing device <b>120</b>, information received from the control system <b>200</b>, data and/or algorithms required for the processor <b>114</b> to operate, and the like.</p><p id="p-0067" num="0066">As an example, the storage <b>112</b> may store vehicle information, a vehicle driving path, front image data captured by a camera, and a remote control path received from the control system <b>200</b>.</p><p id="p-0068" num="0067">The storage <b>112</b> may include a storage medium of at least one type among memories of types such as a flash memory, a hard disk, a micro, a card (e.g., a secure digital (SD) card or an extreme digital (XD) card), a random access memory (RAM), a static RAM (SRAM), a read-only memory (ROM), a programmable ROM (PROM), an electrically erasable PROM (EEPROM), a magnetic memory (MRAM), a magnetic disk, and an optical disk.</p><p id="p-0069" num="0068">The interface device <b>113</b> may include an input means for receiving a control command from a user and an output means for outputting an operation state of the autonomous driving control apparatus <b>110</b> and results thereof. Herein, the input means may include a key button, and may further include a mouse, a keyboard, a touch screen, a microphone, a joystick, a jog shuttle, a stylus pen, and the like. Furthermore, the input means may further include a soft key implemented on the display.</p><p id="p-0070" num="0069">The output means may include a display, and may further include a voice output means such as a speaker. In the instant case, when a touch sensor formed of a touch film, a touch sheet, or a touch pad is provided on the display, the display may operate as a touch screen, and may be implemented in a form in which an input device and an output device are integrated.</p><p id="p-0071" num="0070">In the instant case, the display may include at least one of a liquid crystal display (LCD), a thin film transistor liquid crystal display (TFT LCD), an organic light emitting diode display (OLED display), a flexible display, a field emission display (FED), or a 3D display.</p><p id="p-0072" num="0071">As an example, the interface device <b>113</b> may be implemented as a head-up display (HUD), a cluster, an audio video navigation (AVN), a human machine interface (HM), a user setting menu (USM), or the like.</p><p id="p-0073" num="0072">For example, the interface device <b>113</b> may display the remote control path received from the control system <b>200</b>, the approval request for the remote control path, and the remote control command.</p><p id="p-0074" num="0073">Furthermore, the interface device <b>113</b> may receive an approval input from a driver or an occupant on an approval request screen for a remote control path received from the control system <b>200</b>. To the present end, the interface device <b>113</b> may receive the input from the driver through a mouse, a keyboard, a touch screen, a microphone, or the like.</p><p id="p-0075" num="0074">The processor <b>114</b> may be electrically connected to the communication device <b>111</b>, the storage <b>112</b>, the interface device <b>113</b>, and the like, may electrically control each component, and may be an electrical circuit that executes software commands, performing various data processing and calculations described below.</p><p id="p-0076" num="0075">The processor <b>114</b> may process a signal transferred between components of the autonomous driving control apparatus <b>110</b>, and may perform overall control such that each of the components can perform its function normally.</p><p id="p-0077" num="0076">The processor <b>114</b> may be implemented in a form of hardware, software, or a combination of hardware and software, or may be implemented as microprocessor, and may be, e.g., an electronic control unit (ECU), a micro controller unit (MCU), or other sub controllers mounted in the vehicle.</p><p id="p-0078" num="0077">When a situation in which driving of a driving path is impossible due to an external environment occurs during autonomous driving, the processor <b>114</b> may display the situation in which the driving of the driving path is impossible on the interface device <b>113</b> in the augmented reality. Furthermore, when receiving a request for deleting a misrecognized obstacle that causes the situation in which the driving of the driving path is impossible from the driver, the processor <b>114</b> transmit the information related to the misrecognized obstacle to the control system, and may receive the driving path in which the misrecognized obstacle is deleted from the control system <b>200</b> and follow and control the received driving path.</p><p id="p-0079" num="0078">The processor <b>114</b> may perform a remote control request for avoidance control of the misrecognized obstacle to the control system <b>200</b> when receiving no request for deleting the misrecognized obstacle from the driver.</p><p id="p-0080" num="0079">The processor <b>114</b> may transmit information for remote control when the remote control is requested to the control system <b>200</b>. In the instant case, the information may include vehicle position information (e.g., vehicle coordinates), image information around the vehicle, information around the vehicle (e.g., obstacles, moving vehicle information, stationary vehicle information (fixed objects), map information, and the like.</p><p id="p-0081" num="0080">The processor <b>114</b> may display the driving path in which the misrecognized obstacle received from the control system <b>200</b> is deleted on the interface device <b>113</b> in the augmented reality. That is, the processor <b>114</b> may display an area in which the misrecognized obstacle is deleted during the driving path, and may control the deleted area to blink for a predetermined time period. In the instant case, the deleted area may be displayed through box processing using a rectangle or the like, rounding processing of a circle, or the like. Furthermore, the processor <b>114</b> may mark or block an area in which vehicle driving is impossible in the driving path.</p><p id="p-0082" num="0081">When the driving path is displayed based on augmented reality on the interface device <b>113</b>, the processor <b>114</b> may box-process and display a front target for maintaining an inter-vehicle distance with a vehicle in front, and may distinguish and display a line thickness or a line color of the box of the front target during the normal driving mode and the stop control mode. Furthermore, the processor <b>114</b> may display a front signal condition (e.g., a traffic light) together during the stop control mode.</p><p id="p-0083" num="0082">The processor <b>114</b> may display the area of the misrecognized obstacle in the driving path, and may display a line color or thickness of the area of the misrecognized obstacle by distinguishing it from that in the normal driving mode. In the instant case, the area of the misrecognized obstacle may be displayed through a frame, box processing such as a rectangle, and a rounding process such as a circle of the misrecognized obstacle.</p><p id="p-0084" num="0083">When the misrecognized obstacle is double-touched by the driver, the processor <b>114</b> may recognize it as a deletion request, and may transmit the information related to the misrecognized obstacle to the control system.</p><p id="p-0085" num="0084">When receiving no request for deleting the misrecognized obstacle that causes the situation in which the driving of the driving path is impossible from the driver, the processor <b>114</b> may request remote control to the control system <b>200</b>.</p><p id="p-0086" num="0085">When receiving a remote control path for the remote control request from the control system, the processor <b>114</b> may display the remote control path based on the augmented reality.</p><p id="p-0087" num="0086">The processor <b>114</b> may display a screen for obtaining approval from a driver or an occupant for the remote control path on the interface device <b>113</b>.</p><p id="p-0088" num="0087">The processor <b>114</b> may follow and control the remote control path when the approval for the remote control path from the driver or the occupant is completed.</p><p id="p-0089" num="0088">The processor <b>114</b> may transmit unapproved information and an unapproved remote control path to the control system <b>200</b> when the approval for the remote control path from the driver or the occupant is not completed.</p><p id="p-0090" num="0089">The sensing device <b>120</b> may include one or more sensors that detect an obstacle, e.g., a preceding vehicle, positioned around the host vehicle and measure a distance with the obstacle and/or a relative speed thereof.</p><p id="p-0091" num="0090">The sensing device <b>120</b> may include a plurality of sensors to detect an external object of the vehicle, to obtain information related to a position of the external object, a speed of the external object, a moving direction of the external object, and/or a type of the external object (e.g., vehicles, pedestrians, bicycles or motorcycles, etc.). To the present end, the sensing device <b>120</b> may include an ultrasonic sensor, a radar, a camera, a laser scanner, and/or a corner radar, a Light Detection and Ranging (LiDAR), an acceleration sensor, a yaw rate sensor, a torque measurement sensor and/or a wheel speed sensor, a steering angle sensor, etc.</p><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> illustrates a view for describing a sensing device of an autonomous vehicle according to various exemplary embodiments of the present invention, and <figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates a sensing range of a sensing device of an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0093" num="0092">Referring to <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, the sensing device <b>120</b> may include a front radar mounted on the front of the vehicle, a Light Detection and Ranging (LiDAR), a side LiDAR, a side camera, a corner radar, a high-resolution LiDAR, a rear camera, a rear LiDAR, etc. Furthermore, referring to <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, a surrounding situation may be detected through radars, cameras, and LiDARs of the front, rear, and side of the vehicle.</p><p id="p-0094" num="0093">The steering control device <b>130</b> may be configured to control a steering angle of a vehicle, and may include a steering wheel, an actuator interlocked with the steering wheel, and a controller configured for controlling the actuator.</p><p id="p-0095" num="0094">The braking control device <b>140</b> may be configured to control braking of the vehicle, and may include a controller that is configured to control a brake thereof.</p><p id="p-0096" num="0095">The engine control unit (ECU) <b>150</b> may be configured to control engine driving of a vehicle, and may include a controller that is configured to control a speed of the vehicle.</p><p id="p-0097" num="0096">When receiving information related to a misrecognized obstacle from the autonomous vehicle <b>100</b>, the control system <b>200</b> displays the misrecognized obstacle on a driving path of the autonomous vehicle <b>100</b>, may delete the misrecognized obstacles on the driving path of the autonomous vehicle <b>100</b> by receiving approval from an operator, and may transmit the driving path of the autonomous vehicle <b>100</b> in which the misrecognized obstacle is deleted to the autonomous vehicle <b>100</b>.</p><p id="p-0098" num="0097">The control system <b>200</b> may include a communication device <b>211</b>, a storage <b>212</b>, an interface device <b>213</b>, and a processor <b>214</b>.</p><p id="p-0099" num="0098">The communication device <b>211</b> is a hardware device implemented with various electronic circuits to transmit and receive signals through a wireless or wired connection, and may transmit and receive information based on in-vehicle devices and in-vehicle network communication techniques. As an example, the in-vehicle network communication techniques may include controller area network (CAN) communication, Local Interconnect Network (LIN) communication, flex-ray communication, Ethernet communication, and the like.</p><p id="p-0100" num="0099">Furthermore, the communication device <b>211</b> may perform communication by use of a server, infrastructure, or third vehicles outside the vehicle, and the like through a wireless Internet technique or short range communication technique. Herein, the wireless Internet technique may include wireless LAN (WLAN), wireless broadband (Wibro), Wi-Fi, Worldwide Interoperability for Microwave Access (WiMAX), etc. Furthermore, short-range communication technique may include Bluetooth, ZigBee, ultra wideband (UWB), radio frequency identification (RFID), infrared data association (IrDA), and the like. For example, the communication device <b>211</b> may perform wireless communication with the vehicle <b>100</b>, may receive a remote control request from the vehicle <b>100</b>, and may transmit an approval request for the remote control path and a remote control command.</p><p id="p-0101" num="0100">The storage <b>212</b> may store information received from the vehicle <b>100</b>, and data and/or algorithm required for the processor <b>214</b> to operate, and the like.</p><p id="p-0102" num="0101">As an example, the storage <b>212</b> may store a vehicle path received from the vehicle <b>100</b>, image data photographed through a camera, a remote control path, a remote control command selected by an operator, and the like.</p><p id="p-0103" num="0102">The storage <b>212</b> may include a storage medium of at least one type among memories of types such as a flash memory, a hard disk, a micro, a card (e.g., a secure digital (SD) card or an extreme digital (XD) card), a random access memory (RAM), a static RAM (SRAM), a read-only memory (ROM), a programmable ROM (PROM), an electrically erasable PROM (EEPROM), a magnetic memory (MRAM), a magnetic disk, and an optical disk.</p><p id="p-0104" num="0103">The interface device <b>213</b> may include an input means configured for receiving a control command from an operator and an output means for outputting an operation state of the control system <b>200</b> and results thereof. Herein, the input means may include a key button, and may further include a mouse, a keyboard, a touch screen, a microphone, a joystick, a jog shuttle, a stylus pen, and the like. Furthermore, the input means may further include a soft key implemented on the display. For example, the interface device <b>213</b> may display map information in which a driving path of the vehicle, a current position of the vehicle, information related to surrounding objects, etc. are marked based on vehicle data received from the vehicle <b>100</b>. For example, the interface device may include all communication terminals such as a personal computer (PC), a notebook computer, a smartphone, a tablet PC, a pad, a personal digital assistant (PDA), and a wearable device.</p><p id="p-0105" num="0104">The output means may include a display, and may further include a voice output means such as a speaker. In the instant case, when a touch sensor formed of a touch film, a touch sheet, or a touch pad is provided on the display, the display may operate as a touch screen, and may be implemented in a form in which an input device and an output device are integrated.</p><p id="p-0106" num="0105">In the instant case, the display may include at least one of a liquid crystal display (LCD), a thin film transistor liquid crystal display (TFT LCD), an organic light emitting diode display (OLED display), a flexible display, a field emission display (FED), or a 3D display.</p><p id="p-0107" num="0106">The processor <b>214</b> may be electrically connected to the communication device <b>211</b>, the storage <b>212</b>, the interface device <b>213</b>, and the like, may electrically control each component, and may be an electrical circuit that executes software commands, performing various data processing and determinations described below.</p><p id="p-0108" num="0107">The processor <b>214</b> may process a signal transferred between components of the control system <b>200</b>, and may perform overall control such that each of the components can perform its function normally. The processor <b>214</b> may be implemented in a form of hardware, software, or a combination of hardware and software, or may be implemented as microprocessor.</p><p id="p-0109" num="0108">When receiving information related to a misrecognized obstacle from the autonomous vehicle, the processor <b>214</b> displays the misrecognized obstacle on a driving path of the autonomous vehicle, deletes the misrecognized obstacle on the driving path of the autonomous vehicle by receiving approval from an operator, and transmits the driving path of the autonomous vehicle in which the misrecognized obstacle is deleted to the autonomous vehicle.</p><p id="p-0110" num="0109">When receiving the remote control request from the autonomous vehicle <b>100</b>, the processor <b>214</b> may generate the remote control path based on the information received from the autonomous vehicle <b>100</b>.</p><p id="p-0111" num="0110">When receiving no approval for the remote control path from the autonomous vehicle <b>100</b>, the processor <b>214</b> may generate the remote control path for avoiding the misrecognized obstacle again.</p><p id="p-0112" num="0111"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example of a screen displaying an obstacle based on augmented reality in a normal driving mode in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0113" num="0112">Referring to <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the target <b>301</b> may be box-processed and displayed to maintain a distance between vehicles in front in a normal driving situation, and a driving path <b>302</b> may be displayed in the augmented reality.</p><p id="p-0114" num="0113"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example of a screen displaying an obstacle based on augmented reality in a stop control mode in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0115" num="0114">Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, during the stop control mode, i.e., when stopping is required to maintain the distance between vehicles in front, a target <b>401</b>, which is a reason for the stopping, is box-processed to be displayed, and a line color and thickness of the box of the target <b>301</b> during the normal driving mode of <figref idref="DRAWINGS">FIG. <b>3</b></figref> are differently displayed so that the normal driving mode and the stop control mode may be distinguished. In the instant case, the line color and thickness of the driving path <b>402</b> may be distinguished from those of the normal driving mode, but may be displayed in a same manner. <figref idref="DRAWINGS">FIG. <b>3</b></figref> and <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrate examples of box-processing the targets <b>301</b> and <b>401</b>, but the present invention is not limited thereto, and edge portions of the targets <b>301</b> and <b>401</b> may be darkly displayed, or may be displayed through rounding processing such as a circle.</p><p id="p-0116" num="0115"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an example of a screen displaying an obstacle including traffic light information based on augmented reality in a stop control mode in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0117" num="0116">Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, during the stop control mode, not only a front target <b>501</b> for maintaining a distance between vehicles in front but also a front traffic light <b>502</b> may be displayed together to indicate that the vehicle is stopped by the traffic light <b>502</b>. Similarly, the line color and thickness of the driving path <b>503</b> may be distinguished from those of the normal driving mode, but may be displayed in a same manner.</p><p id="p-0118" num="0117"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an example of a screen displaying an obstacle including traffic light information which displays a misrecognized target based on augmented reality in a misrecognition mode in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0119" num="0118">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, a front misrecognized target <b>601</b> may displayed through box processing, and the line color and thickness of the box of the misrecognized target <b>601</b> may be distinguished from those of the normal driving mode. Similarly, the line color and thickness of the driving path <b>602</b> may be distinguished from those of the normal driving mode, but may be displayed in a same manner.</p><p id="p-0120" num="0119"><figref idref="DRAWINGS">FIG. <b>7</b></figref> and <figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrate examples of a screen for deleting a misrecognized obstacle depending on a driver request according to various exemplary embodiments of the present invention.</p><p id="p-0121" num="0120">Referring to <figref idref="DRAWINGS">FIG. <b>7</b></figref> and <figref idref="DRAWINGS">FIG. <b>8</b></figref>, a driver may delete misrecognized obstacles <b>701</b> and <b>801</b> by directly double-touching them, or may select the misrecognized obstacles <b>701</b> and <b>801</b> to request remote control to the control system <b>200</b>. When the driver selects the misrecognized obstacles <b>701</b> and <b>801</b> to request the remote control to the control system <b>200</b>, information related to the misrecognized obstacles may be transmitted to the control system <b>200</b>. In the instant case, the information related to the misrecognized obstacles may include a current driving path, positions of the misrecognized obstacles, types and sizes thereof, and the like. The display device of the vehicle <b>100</b> may be implemented based on a touch screen to select the misrecognized obstacles <b>701</b> and <b>801</b>.</p><p id="p-0122" num="0121"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example of a screen on which a misrecognized obstacle is displayed depending on a driver request in a control system according to various exemplary embodiments of the present invention.</p><p id="p-0123" num="0122">When receiving information related to a misrecognized obstacle from vehicle <b>100</b>, the control system <b>200</b> enables an operator to grasp a situation at a glance by constructing and displaying a 3D screen based on a current driving path, a position of the misrecognized obstacle, a type and a size thereof, etc. In <figref idref="DRAWINGS">FIG. <b>9</b></figref>, a point <b>901</b> where a recognition error occurred is illustrated.</p><p id="p-0124" num="0123"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates an example of a screen displaying a change in a remote control path based on augmented reality in an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0125" num="0124">Referring to <figref idref="DRAWINGS">FIG. <b>10</b></figref>, the vehicle <b>100</b> may receive a remote control path from the control system <b>200</b> to display it on a display device. In the instant case, areas (e.g., no roads) <b>1001</b>, <b>1002</b>, and <b>1003</b> where vehicle driving is impossible in the remote control path may be displayed, and when a misrecognized obstacle is deleted, a deleted state may be displayed by processing it with a box <b>1004</b>. In the instant case, the areas (e.g., no roads) <b>1001</b>, <b>1002</b>, and <b>1003</b> where vehicle driving is impossible and the box <b>1004</b> in which the misrecognized obstacle is deleted may be displayed based on augmented reality such that a driver may intuitively check them in the driving path through separate colors, hatching, etc. The vehicle <b>100</b> displays the box <b>1004</b> in which the misrecognized obstacle is deleted in a blinking manner so that the driver can recognize at a glance that the misrecognized obstacle has been deleted. Furthermore, the areas <b>1001</b>, <b>1002</b>, and <b>1003</b> in which the vehicle driving is impossible may be marked or blocked.</p><p id="p-0126" num="0125">Furthermore, the vehicle <b>100</b> may display a remote control path <b>1005</b> and additionally display an arrow <b>1006</b>, and may blink or highlight the arrow <b>106</b> such that the driver can check at glance a portion which is modified from a driving path before finding a misrecognized obstacle to a remote control path which is generated to avoid the misrecognized obstacle.</p><p id="p-0127" num="0126">Hereinafter, a remote control method for an autonomous vehicle according to various exemplary embodiments of the present invention will be described in detail with reference to <figref idref="DRAWINGS">FIG. <b>11</b></figref>. <figref idref="DRAWINGS">FIG. <b>11</b></figref> illustrates a flowchart showing a remote control method for an autonomous vehicle according to various exemplary embodiments of the present invention.</p><p id="p-0128" num="0127">Hereinafter, it is assumed that the autonomous driving control apparatus <b>110</b> of the vehicle <b>100</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> and the control system <b>200</b> perform processes of <figref idref="DRAWINGS">FIG. <b>11</b></figref>. Furthermore, in the description of <figref idref="DRAWINGS">FIG. <b>11</b></figref>, it may be understood that operations referred to as being performed by each system are controlled by a processor of each of the systems.</p><p id="p-0129" num="0128">Referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, the vehicle <b>100</b> starts autonomous driving (S<b>101</b>), and the control system <b>200</b> prepares for remote control (S<b>102</b>).</p><p id="p-0130" num="0129">The vehicle <b>100</b> determines whether driving of a current path is impossible due to an external environment during autonomous driving (S<b>103</b>), and when the driving of the current path is impossible, displays a reason why the current route is impossible to drive, i.e., a reason the vehicle is stopped, on a display device based on the augmented reality (S<b>104</b>).</p><p id="p-0131" num="0130">Next, the vehicle <b>100</b> checks whether there is a request for ignoring a misrecognized obstacle from a driver (S<b>105</b>), and when receiving a request for ignoring the misrecognized obstacle from the driver, the vehicle <b>100</b> transmits misrecognition related information and surrounding images to the control system <b>200</b> (S<b>106</b>). In the instant case, the misrecognition related information may include information such as a current driving path, a position and size of an obstacle which is misrecognized on the current driving path, position information of the host vehicle, etc.</p><p id="p-0132" num="0131">Accordingly, the control system <b>200</b> checks whether a request of the driver to ignore the misrecognized obstacle is received from the vehicle <b>100</b> (S<b>107</b>), and when the request to ignore the misrecognized obstacle is not received, waits to receive a remote control request from the vehicle <b>100</b>.</p><p id="p-0133" num="0132">On the other hand, when receiving no request for ignoring the misrecognized obstacle from the vehicle <b>100</b>, the control system <b>200</b> displays the information related to the misrecognized obstacle received from the vehicle <b>100</b> such that an operator can see it (see <figref idref="DRAWINGS">FIG. <b>9</b></figref>), and when receiving a request for deleting the misrecognized obstacle from the operator after the operator checks the misrecognition related information (S<b>108</b>), deletes the misrecognized obstacle on the current driving path and transmits the path to the vehicle <b>100</b> (S<b>109</b>).</p><p id="p-0134" num="0133">On the other hand, when receiving no request for deleting the misrecognized obstacle (condition) from the operator, the control system <b>200</b> determines that the current driving path is mortified or remote control is required, and waits to receive a remote control request from the vehicle <b>100</b>.</p><p id="p-0135" num="0134">On the other hand, when receiving a path in which the misrecognized obstacle is deleted from the control system <b>200</b>, the vehicle <b>100</b> follows and controls the path in which the misrecognized obstacle is deleted (S<b>110</b>).</p><p id="p-0136" num="0135">In step S<b>105</b>, when receiving no request for ignoring the misrecognized obstacle, that is, when the driver does not ignore the misrecognized obstacle and wants to recognize it as a real obstacle, the vehicle <b>100</b> determines whether there is a remote control request for avoiding the obstacle from the driver (S<b>111</b>).</p><p id="p-0137" num="0136">When a remote control request is inputted from the driver, the vehicle <b>100</b> requests remote control to the control system <b>200</b> (S<b>112</b>). In the instant case, the vehicle <b>100</b> transmits information such as vehicle position information (coordinates), vehicle surrounding information (surrounding object information the current changing the color of the etc.), and map information (current path of the vehicle) together therewith when requesting the remote control.</p><p id="p-0138" num="0137">The control system <b>200</b> generates a remote control path based on the information received from the vehicle <b>100</b> when receiving the remote control request (S<b>113</b>), and transmits the generated remote control path to the vehicle <b>100</b> (S<b>114</b>).</p><p id="p-0139" num="0138">Accordingly, the vehicle <b>100</b> displays the remote control path received from the control system <b>200</b> on a display device based on augmented reality (S<b>115</b>), and receives approval of the displayed remote control path from the driver or an occupant.</p><p id="p-0140" num="0139">The vehicle <b>100</b> checks whether the displayed remote control path is approved by the driver or the occupant (S<b>116</b>), and when the approval is completed, the vehicle <b>100</b> follows and controls a modified remote control path received from the control system <b>200</b> (S<b>120</b>).</p><p id="p-0141" num="0140">On the other hand, when the displayed remote control path is not approved by the driver or occupant, the vehicle <b>100</b> transmits unapproved information and the mortified path to the control system <b>200</b> (S<b>117</b>).</p><p id="p-0142" num="0141">Accordingly, the control system <b>200</b> checks whether the mortified path is received from the vehicle <b>100</b> (S<b>118</b>), and when the mortified path is received, returns to the above-described step S<b>113</b> to re-generate the remote control path.</p><p id="p-0143" num="0142">On the other hand, the control system <b>200</b> determines that the vehicle <b>100</b> is being remotely controlled to the corresponding path when the mortified path is not received, and terminates the remote control when it is completed. In the instant case, when the remote control is completed, the vehicle <b>100</b> transmits the remote control path to the control system <b>200</b>.</p><p id="p-0144" num="0143">As described above, according to various exemplary embodiments of the present invention, when an obstacle recognized by the vehicle <b>100</b> through the sensing device <b>120</b> is misrecognized, the misrecognized obstacle may be deleted depending on a request of the driver, or remote control may be performed to delete the misrecognized obstacle. Accordingly, the driver of the vehicle <b>100</b> may easily correct errors that occur during autonomous driving, securing reliability of the remote control, improving commercialization of autonomous driving.</p><p id="p-0145" num="0144">Furthermore, according to various exemplary embodiments of the present invention, when the remote control path is changed due to a misrecognized obstacle, the changed remote control path may be displayed based on augmented reality to enable the driver to intuitively recognize it.</p><p id="p-0146" num="0145"><figref idref="DRAWINGS">FIG. <b>12</b></figref> illustrates a computing system according to various exemplary embodiments of the present invention.</p><p id="p-0147" num="0146">Referring to <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the computing system <b>1000</b> includes at least one processor <b>1100</b> connected through a bus <b>1200</b>, a memory <b>1300</b>, a user interface input device <b>1400</b>, a user interface output device <b>1500</b>, and a storage <b>1600</b>, and a network interface <b>1700</b>.</p><p id="p-0148" num="0147">The processor <b>1100</b> may be a central processing unit (CPU) or a semiconductor device that performs processing on commands stored in the memory <b>1300</b> and/or the storage <b>1600</b>. The memory <b>1300</b> and the storage <b>1600</b> may include various types of volatile or nonvolatile storage media. For example, the memory <b>1300</b> may include a read only memory (ROM) <b>1310</b> and a random access memory (RAM) <b>1320</b>.</p><p id="p-0149" num="0148">Accordingly, steps of a method or algorithm described in connection with the exemplary embodiments included herein may be directly implemented by hardware, a software module, or a combination of the two, executed by the processor <b>1100</b>. The software module may reside in a storage medium (i.e., the memory <b>1300</b> and/or the storage <b>1600</b>) such as a RAM memory, a flash memory, a ROM memory, an EPROM memory, a EEPROM memory, a register, a hard disk, a removable disk, and a CD-ROM.</p><p id="p-0150" num="0149">An exemplary storage medium is coupled to the processor <b>1100</b>, which can read information from and write information to the storage medium. Alternatively, the storage medium may be integrated with the processor <b>1100</b>. The processor and the storage medium may reside within an application specific integrated circuit (ASIC). The ASIC may reside within a user terminal. Alternatively, the processor and the storage medium may reside as separate components within the user terminal.</p><p id="p-0151" num="0150">The above description is merely illustrative of the technical idea of the present invention, and those skilled in the art to which various exemplary embodiments of the present invention pertains may make various modifications and variations without departing from the essential characteristics of the present invention.</p><p id="p-0152" num="0151">For convenience in explanation and accurate definition in the appended claims, the terms &#x201c;upper&#x201d;, &#x201c;lower&#x201d;, &#x201c;inner&#x201d;, &#x201c;outer&#x201d;, &#x201c;up&#x201d;, &#x201c;down&#x201d;, &#x201c;upwards&#x201d;, &#x201c;downwards&#x201d;, &#x201c;front&#x201d;, &#x201c;rear&#x201d;, &#x201c;back&#x201d;, &#x201c;inside&#x201d;, &#x201c;outside&#x201d;, &#x201c;inwardly&#x201d;, &#x201c;outwardly&#x201d;, &#x201c;interior&#x201d;, &#x201c;exterior&#x201d;, &#x201c;internal&#x201d;, &#x201c;external&#x201d;, &#x201c;forwards&#x201d;, and &#x201c;backwards&#x201d; are used to describe features of the exemplary embodiments with reference to the positions of such features as displayed in the figures. It will be further understood that the term &#x201c;connect&#x201d; or its derivatives refer both to direct and indirect connection.</p><p id="p-0153" num="0152">The foregoing descriptions of specific exemplary embodiments of the present invention have been presented for purposes of illustration and description. They are not intended to be exhaustive or to limit the present invention to the precise forms disclosed, and obviously many modifications and variations are possible in light of the above teachings. The exemplary embodiments were chosen and described to explain certain principles of the present invention and their practical application, to enable others skilled in the art to make and utilize various exemplary embodiments of the present invention, as well as various alternatives and modifications thereof. It is intended that the scope of the present invention be defined by the Claims appended hereto and their equivalents.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. An autonomous vehicle comprising:<claim-text>a display device configured to display a driving path of the autonomous vehicle; and</claim-text><claim-text>an autonomous driving control apparatus including a processor that is configured to:<claim-text>display a situation in which driving of the driving path is impossible on the display device in augmented reality when the situation in which the driving of the driving path is impossible occurs due to an external environment during autonomous driving of the autonomous vehicle,</claim-text><claim-text>transmit information related to a misrecognized obstacle to a control system when receiving a request for deleting the misrecognized obstacle, and</claim-text><claim-text>receive a driving path in which the misrecognized obstacle is deleted from the control system and control and follow the received driving path.</claim-text></claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The autonomous vehicle of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further including:<claim-text>a sensing device configured to detect the situation in which the driving of the driving path is impossible.</claim-text></claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The autonomous vehicle of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to display the driving path received from the control system, in which the misrecognized obstacle is deleted, on the display device in the augmented reality.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The autonomous vehicle of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the processor is configured to display an area in which the misrecognized obstacle is deleted in the driving path and to control the area to blink for a predetermined time period.</claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The autonomous vehicle of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the processor is configured to mark or block an area in which a vehicle is unable to be driven in the driving path.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The autonomous vehicle of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein when the driving path is displayed on the display device in the augmented reality, the processor is configured to:<claim-text>display an area of a front target for maintaining an in-vehicle distance with a vehicle in front of the autonomous vehicle, and</claim-text><claim-text>distinguish and display a line thickness or a line color indicating the area of the front target during a normal driving mode and a stop control mode of the autonomous vehicle.</claim-text></claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The autonomous vehicle of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the processor is configured to display a front signal condition during the stop control mode.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The autonomous vehicle of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to:<claim-text>display an area of the misrecognized obstacle in the driving path, and</claim-text><claim-text>display a line color or line thickness indicating the area of the misrecognized obstacle in a normal driving mode separately from that a stop control mode of the autonomous vehicle.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The autonomous vehicle of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processor is configured to transmit information related to the misrecognized obstacle to the control system in response to a request for deleting the misrecognized obstacle from a driver.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The autonomous vehicle of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein when receiving no request for deleting the misrecognized obstacle from a driver, the processor is configured to request remote control of the autonomous vehicle to the control system.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The autonomous vehicle of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein when receiving a remote control path for the requesting of the remote control from the control system, the processor is configured to display the remote control path in the augmented reality.</claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The autonomous vehicle of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the processor is configured to display a screen for obtaining approval for the remote control path by a driver or an occupant on the display device.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The autonomous vehicle of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the processor is configured to follow and control the remote control path when the approval for the remote control path by the driver or the occupant is completed.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The autonomous vehicle of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the processor is configured to transmit unapproved information and an unapproved remote control path to the control system when the approval for the remote control path by the driver or the occupant is not completed.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The autonomous vehicle of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the autonomous driving control apparatus includes:<claim-text>a communication device configured to communicate with the control system; and</claim-text><claim-text>a storage configured to store the remote control path received from the control system.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. A control system comprising:<claim-text>a processor configured to display a misrecognized obstacle on a driving path of an autonomous vehicle when receiving information related to the misrecognized obstacle from the autonomous vehicle, to delete the misrecognized obstacle on the driving path of the autonomous vehicle by receiving approval from an operator, and to transmit a driving path of the autonomous vehicle in which the misrecognized obstacle is deleted to the autonomous vehicle.</claim-text></claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The control system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the processor is configured to generate a remote control path to provide the generated remote control path to the autonomous vehicle when receiving a request for remote control of the autonomous vehicle for avoiding the misrecognized obstacle from the autonomous vehicle.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The control system of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the processor is configured to re-generate a remote control path for avoiding the misrecognized obstacle when the approval for the remote control path is not received from the autonomous vehicle.</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. A remote control method for an autonomous vehicle, the remote control method comprising:<claim-text>displaying, by an autonomous driving control apparatus, a situation in which driving of a driving path is impossible on a display device in augmented reality when the situation in which the driving of the driving path is impossible occurs due to an external environment during autonomous driving of the autonomous vehicle;</claim-text><claim-text>receiving, by the autonomous driving control apparatus, a request for deleting a misrecognized obstacle from a driver;</claim-text><claim-text>transmitting, by the autonomous driving control apparatus, information related to the misrecognized obstacle to a control system; and</claim-text><claim-text>following and controlling, by the autonomous driving control apparatus, a driving path in which the misrecognized obstacle is deleted by receiving the driving path from the control system.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The remote control method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further including:<claim-text>displaying, by the autonomous driving control apparatus, the driving path in which the misrecognized obstacle is deleted,</claim-text><claim-text>wherein the displaying includes displaying an area in which the misrecognized obstacle is deleted, and controlling the area to blink for a predetermined time period.</claim-text></claim-text></claim></claims></us-patent-application>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004792A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004792</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17367598</doc-number><date>20210705</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>08</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>3</main-group><subgroup>04</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>5</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">AUTOMATICALLY STRUCTURING USER INTERACTION TRAILS FOR KNOWLEDGE EXPANSION IN A KNOWLEDGE GRAPH</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>INTERNATIONAL BUSINESS MACHINES CORPORATION</orgname><address><city>Armonk</city><state>NY</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>de Mello Brandao</last-name><first-name>Rafael Rossi</first-name><address><city>Rio de Janeiro</city><country>BR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Ferreira Moreno</last-name><first-name>Marcio</first-name><address><city>Rio de Janeiro</city><country>BR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Ferreira Lima</last-name><first-name>Guilherme Augusto</first-name><address><city>Sao Paulo</city><country>BR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Fontoura de Gusmao Cerqueira</last-name><first-name>Renato</first-name><address><city>Rio de Janeiro</city><country>BR</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method and system of creating a knowledge graph includes capturing information of a user interacting with given data, as user interaction data. The user interaction data is structured as a trail of actions over time. An ontology for a domain related to the user interaction data is received. Each action of the trail of actions is matched onto entities of the ontology. The knowledge graph is created based on the ontology having the matched actions.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="114.55mm" wi="158.75mm" file="US20230004792A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="216.75mm" wi="163.91mm" file="US20230004792A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="171.96mm" wi="157.23mm" orientation="landscape" file="US20230004792A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="242.32mm" wi="161.12mm" orientation="landscape" file="US20230004792A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="241.64mm" wi="161.12mm" orientation="landscape" file="US20230004792A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="226.31mm" wi="176.28mm" orientation="landscape" file="US20230004792A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="170.01mm" wi="176.28mm" orientation="landscape" file="US20230004792A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="166.79mm" wi="141.99mm" file="US20230004792A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">BACKGROUND</heading><heading id="h-0002" level="1">Technical Field</heading><p id="p-0002" num="0001">The present disclosure generally relates to computers, and more particularly, to automatically capturing user interaction in a knowledge graph.</p><heading id="h-0003" level="1">Description of the Related Art</heading><p id="p-0003" num="0002">Today, representing users' creative and interpretive processes may be useful to identify problems and solutions associated with interactive decision-making processes of domain experts. Generally, these processes are related to the interaction of users with some content, such as text, video, audio, images, etc., collectively referred to herein as data, and structuring users' tacit and explicit knowledge. Tracking such process can generate a representation of users' trails. However, known representations are generally not well structured from a knowledge engineering perspective to facilitate machine learning by a computing device. Considering highly immersive environments with interaction through multiple modalities, tracking this knowledge becomes even more complex.</p><p id="p-0004" num="0003">On one hand, cognitive agents have been increasingly used to support decision-making practices, which may involve knowledge-intensive activities and critical thinking. On the other hand, these systems may demand an overly complex design and implementation given the lack of knowledge representations capable of describing steps of creative processes, including rich relationships between symbolic and non-symbolic data.</p><p id="p-0005" num="0004">Currently, there are two main bottlenecks in the knowledge engineering process related to structuring and extracting patterns from complex user activities. The first concerns the lack of consistent representations that focus on connecting heterogeneous data. Ideally, a representation should provide mechanisms for facilitating the structuring and processing of user input, data sources and knowledge entities as salient information. The second bottleneck comes from the difficulty of managing, populating, and expanding such datasets with complex user activities representations. In addition, extracting information and patterns from this type of data may pose a challenge as well.</p><p id="p-0006" num="0005">Current solutions for representing complex user activities, knowledge extraction and knowledge expansion typically focus on specific parts of the Knowledge Engineering process. Generally, known solutions either focus on inferring new concepts from existing symbolic representations or exploit user queries on knowledge-based systems to promote the expansion. Other solutions focus on capturing user interaction without contextual information or without a knowledge representation that is amenable to structuring and information extraction.</p><heading id="h-0004" level="1">SUMMARY</heading><p id="p-0007" num="0006">According to various exemplary embodiments, a computing device, a non-transitory computer readable storage medium, and a method are provided to automatically provide a knowledge graph. Information of a user interacting with given data is captured as user interaction data. The user interaction data is structured as a trail of actions over time. An ontology is received for a domain related to the user interaction data. Each action of the trail of actions is matched onto entities of the ontology. The knowledge graph is created based on the ontology having the matched actions.</p><p id="p-0008" num="0007">In one embodiment, the contextual information of the interaction data includes at least one of audio or video of the user interacting with the given data.</p><p id="p-0009" num="0008">In one embodiment, a facial expression of the user is determined for at least one action of the trail of actions.</p><p id="p-0010" num="0009">In one embodiment, the user interaction data is continuously captured. The knowledge graph is iteratively updated based on the continuously captured interaction data.</p><p id="p-0011" num="0010">In one embodiment, the structured interaction data includes one or more nested hierarchies of the trails of actions.</p><p id="p-0012" num="0011">In one embodiment, one or more actions of the matched trail of actions are adjusted upon receiving instructions from a domain expert.</p><p id="p-0013" num="0012">In one embodiment, the created knowledge graph is used as a corpus of data for machine learning to create an improved trail of actions for the ontology.</p><p id="p-0014" num="0013">In one embodiment, the machine learning is based on a graph neural network (GNN).</p><p id="p-0015" num="0014">In one embodiment, machine learning is used to create one or more new entities in the knowledge graph.</p><p id="p-0016" num="0015">These and other features will become apparent from the following detailed description of illustrative embodiments thereof, which is to be read in connection with the accompanying drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0017" num="0016">The drawings are of illustrative embodiments. They do not illustrate all embodiments. Other embodiments may be used in addition or instead. Details that may be apparent or unnecessary may be omitted to save space or for more effective illustration. Some embodiments may be practiced with additional components or steps and/or without all of the components or steps that are illustrated. When the same numeral appears in different drawings, it refers to the same or like components or steps.</p><p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is an example architecture of a system for automatically structuring user interaction trails for knowledge expansion in a knowledge graph, consistent with an illustrative embodiment.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is an example block diagram of aspects of the knowledge expansion engine of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, consistent with an illustrative embodiment.</p><p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a conceptual block diagram of a use case related to seismic cube exploration, consistent with an illustrative embodiment.</p><p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a conceptual block diagram of a use case related to machine learning model design, consistent with an illustrative embodiment.</p><p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>5</b></figref> describes a knowledge structure process, consistent with an illustrative embodiment.</p><p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>6</b></figref> describes a trail-based knowledge expansion process, consistent with an illustrative embodiment.</p><p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a functional block diagram illustration of a particularly configured computer hardware platform that can be used to implement the server of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0006" level="1">DETAILED DESCRIPTION</heading><heading id="h-0007" level="1">Overview</heading><p id="p-0025" num="0024">In the following detailed description, numerous specific details are set forth by way of examples in order to provide a thorough understanding of the relevant teachings. However, it should be apparent that the present teachings may be practiced without such details. In other instances, well-known methods, procedures, components, and/or circuitry have been described at a relatively high-level, without detail, in order to avoid unnecessarily obscuring aspects of the present teachings.</p><p id="p-0026" num="0025">In discussing the present technology, it may be helpful to describe various salient terms. As used herein linked data relates to an approach to structured data representation that manifests as a web of data. It enables transparent access to data (e.g., by way of hyperlinks) thereby enabling integration of data across disparate data sources as well as providing platform-independent data connectivity across new and existing enterprise solutions.</p><p id="p-0027" num="0026">As used herein, an ontology is a collection of entity type and entity relationship type definitions associated with a realm of discourse (e.g., a scientific domain). Ontologies can be constructed using linked data principles and may be loosely-coupled and shareable. Ontologies provide a description of a system as well as system relationship types that provide reasoning and inference performed by both humans and machines.</p><p id="p-0028" num="0027">As used herein, a knowledge graph relates to a semantic knowledge base organized as a graph where relationships between facts are formally described by an ontology. In a knowledge graph, each data item is referred to herein as a node or vertex, and are typically represented by circles. Each node is connected by &#x201c;edges&#x201d; represented by lines interconnecting the nodes. By virtue of using graphs (e.g., instead of tables or other disparate type of representation), it is possible to capture the fundamentally &#x201c;messy&#x201d; nature of data in a way that is easier to understand and that provides sufficient structure for a computer to be able to efficiently process the data. For example, both tabular data and tree like data can be captured efficiently by graphs. Images and texts can be represented. In some instances, audio and/or video can be played upon a selection of a node. Accordingly, data is presented not in an isolated way, but rather in relation to other data, which makes it easier to understand and digest. Knowledge graphs are created by describing entities (i.e., nodes in the graph, which can be conceptual knowledge or data) and entity relationship types using sentences that are deployed using linked data principles.</p><p id="p-0029" num="0028">The present disclosure generally relates to methods and systems of automatically structuring user interaction trails for knowledge expansion in such knowledge graphs. Inferring human interpretation and knowledge in such a representation in these processes captured in knowledge graphs are salient to improve the design of systems that support decision-making, as well as finetuning processes to improve quality and efficiency. In one aspect, the present disclosure applies high-level conceptual components in a knowledge representation to characterize users' interpretive trails. The teachings herein facilitate the computerized characterization of actions taken by a user (e.g., domain expert) with respect to a predetermined ontology related to a domain. Each of the actions, sometimes referred to herein as interaction activity or interaction data, is captured in a stream of events over time. The user interaction data is structured as a trail of actions. Each element of the trail is mapped onto nodes of the predetermined ontology.</p><p id="p-0030" num="0029">Applicants have determined that capturing these user interactions, as a user interacts with various forms of data, such as text, audio, video, graph, etc., is useful in identifying possible problems in the trail of actions, thereby facilitating optimization of the trail. In one aspect users' intent and reasoning is captured during these activities, which may involve multimodal data as well as the user emotions, experiences, insights, intuition, and observations related to the corresponding action taken.</p><p id="p-0031" num="0030">The proposed representation takes advantage of combining experts' interaction with data segments (e.g., sentences of a text document, fragments of images, segments of seismic data, frames of a video file, etc.,) with knowledge representations (conceptual entities in an ontology that can be reasoned upon). The knowledge representations discussed herein are capable of not only capturing user interaction data, but also structuring the user interaction as a trail of actions in time. Each of the actions is mapped to elements of an ontology for a domain (e.g., field of study or system).</p><p id="p-0032" num="0031">Knowledge graphs are not only created but also capable of being expanded and adjusted based on the computation of variations of different user activities. The structuring of complex user activities and knowledge intensive processes in the proposed representation system promotes a systematic presentation and consumption of knowledge. Furthermore, drawing on such representation pattern detection and information extraction pipelines can provide knowledge base expansion based on different learning strategies, including symbolic reasoning (e.g. rule based facts), non-symbolic (e.g. GNN, GANS or other ML predictive approach) or a combined neuro-symbolic approach discussed in more detail below. By virtue of the teachings herein, it is possible to create new coherent complex user data that can be further curated by users. For example, a multi-user dashboard GUI can allow visual interaction with the graph and enable users to explore trails and expansion strategies, as well as correct any aspect of the graph they deem should be corrected. The newly created knowledge data provided by the selected learning strategies and executed learning pipelines is used for maximizing the number of instances in the knowledge base, thereby facilitating new insights for users and providing a corpus of learning data for machine learning algorithms. Such data maximizes not only the instance of entities (e.g., a-box expansion), but also the classes in the ontology (e.g., t-box expansion). The techniques described herein may be implemented in a number of ways. Example implementations are provided below with reference to the following figures.</p><heading id="h-0008" level="1">Example Architecture</heading><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is an example architecture <b>100</b> of a system for automatically structuring user interaction trails for knowledge expansion in a knowledge graph, consistent with an illustrative embodiment. Architecture <b>100</b> may include one or more users <b>101</b>(<b>1</b>) to <b>101</b>(N), sometimes referred to herein as domain experts, who can interact individually or collaboratively with processing data <b>109</b> from one or more data sources related to their respective domain, collectively represented by data source <b>107</b>. By way of example and not by way of limitation, the domain may relate to rocket science and the data <b>109</b> being processed relates to an upcoming rocket launch. In various embodiments, the data <b>109</b> may include, textual, visual, video, graph, etc., information. Each user <b>101</b>(<b>1</b>) to <b>101</b>(N) can interact with the data <b>109</b> to learn from it, make adjustments, and base their decisions on the data <b>109</b>. Each of the interactions between a user <b>101</b>(<b>1</b>) to <b>101</b>(N) and the data <b>109</b> is recorded as electronic data packages <b>105</b>(<b>1</b>) to <b>105</b>(N), which may include, without limitation, what portion of the data <b>109</b> is being processed, what decisions are being made, amount of time spent on specific portions of the data <b>109</b>, changes being made to any portion of the data, etc., In some embodiments, higher-level information is recorded in the electronic data packages <b>105</b>(<b>1</b>) to <b>105</b>(N) to extract context, including facial expressions of the user, user intent, user intent, etc., discussed in more detail later.</p><p id="p-0034" num="0033">There is a network that <b>106</b> allows the various user devices <b>102</b>(<b>1</b>) to <b>101</b>(N) to communicate with the data repository <b>107</b>, a knowledge expansion server <b>116</b>, and/or each other. The network <b>106</b> may be, without limitation, a local area network (&#x201c;LAN&#x201d;), a virtual private network (&#x201c;VPN&#x201d;), a cellular network, the Internet, or a combination thereof. For example, the network <b>106</b> may include a mobile network that is communicatively coupled to a private network, sometimes referred to as an intranet, that provides various ancillary services, such as communication with various databases, the Internet, and the cloud <b>120</b>.</p><p id="p-0035" num="0034">For discussion purposes, different user/computing devices (e.g., <b>102</b>(<b>1</b>) to <b>102</b>(N)) appear in the drawing, to represent some examples of the client devices that may be used by a user (e.g., <b>101</b>(<b>1</b>) to <b>102</b>(N)) to communicate over the network <b>106</b>. Today, user devices typically take the form of portable handsets, smart-phones, tablet computers, personal digital assistants (PDAs), and smart watches, although they may be implemented in other form factors, including consumer, medical, and business electronic devices.</p><p id="p-0036" num="0035">In one embodiment, there is an ontology database <b>112</b> that is configured to store one or more ontologies that are related to a particular realm of discourse of the domain experts <b>101</b>(<b>1</b>) to <b>101</b>(N). There is a knowledge expansion engine <b>103</b> running on a server <b>116</b> that is configured to receive an ontology <b>113</b> from the ontology database <b>112</b> to glean therefrom a network of entities for a realm of discourse, sometimes simply referred to herein as a domain. The knowledge expansion engine <b>103</b> captures user interaction with the data <b>109</b> by way of the data packages <b>105</b>(<b>1</b>) to <b>105</b>(N). In various embodiments, the data packages <b>105</b>(<b>1</b>) to <b>105</b>(N), collectively referred to herein as user interaction data, may be received continuously (as the information becomes available) or upon a trigger event (e.g., predetermined time intervals or upon the user indicating that certain activities with respect to the data <b>109</b> have been completed). The knowledge expansion engine <b>103</b> captures the user interaction data <b>105</b>(<b>1</b>) to <b>105</b>(N) as a stream of events in time. The knowledge expansion engine <b>103</b> structures the user interaction data <b>105</b>(<b>1</b>) to <b>105</b>(N) as a trail of actions (interactions with the data over time). In one embodiment, the knowledge expansion engine is able to provide a semantic layer to the interaction data <b>105</b>(<b>1</b>) to <b>105</b>(N), providing meaning to each interaction, including industry domain information. There may be a polystore database <b>115</b> that may be used as a repository for the knowledge expansion engine. These concepts are explained in more detail below in the context of the discussion of <figref idref="DRAWINGS">FIGS. <b>2</b> to <b>4</b></figref>.</p><p id="p-0037" num="0036">While the one or more data sources <b>107</b>, ontology database <b>112</b>, and the server <b>116</b> are illustrated by way of example to be on different platforms, it will be understood that, in different embodiments, these platforms may be combined in different combinations. In other embodiments, one or more of these computing platforms may be implemented by virtual computing devices in the form of virtual machines or software containers that are hosted in the cloud <b>120</b>, thereby providing an elastic architecture for processing and storage. The cloud is discussed in more detail later.</p><heading id="h-0009" level="1">Example Block Diagram of Knowledge Expansion Engine</heading><p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is an example block diagram <b>200</b> of the knowledge expansion engine <b>103</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, consistent with an illustrative embodiment. For discussion purposes, block diagram <b>200</b> is discussed with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0039" num="0038">The system may include a dashboard graphical user interface (GUI) module <b>202</b> that is operative to provide one or more users <b>102</b>(<b>1</b>) to <b>102</b>(N) to interact with the data <b>109</b>. In various embodiments, the dashboard GUI <b>202</b> may be of the knowledge expansion engine <b>103</b> or user device (e.g., <b>102</b>(<b>1</b>) to <b>102</b>(N). There may be a device manager <b>204</b> that operative to handle all available sensors that capture user activities (i.e., interaction with the data <b>109</b>) as well as the context of each interaction. In various embodiments, information from a keypad, microphone, haptic element, touch sensitive display screen, mouse, stylus, motion sensor, gyroscope, etc., of the user device (e.g., <b>102</b>(<b>2</b>)) may be used as a source of this information.</p><p id="p-0040" num="0039">The information extraction module <b>208</b> is operative to extract relevant information embedded in the digital content <b>105</b>(<b>1</b>) to <b>105</b>(N). For example, every selection, annotation, explanation, etc., is interpreted by the extraction module <b>208</b>. In some embodiments, the audio signals harvested by the one or more sensors are also used to convert any captured speech to text. The information extraction module <b>208</b> may use natural language processing (NLP) to process the raw natural language content of the verbal queues of a user (e.g., <b>102</b>(<b>1</b>)). The knowledge expansion engine <b>103</b> can perform speech recognition to determine the textual representation thereof. In natural speech, there may not be discernable pauses between successive words. To that end, speech segmentation may be performed to separate the words into meaningful sentences.</p><p id="p-0041" num="0040">In one embodiment, concept expansion, such as the IBM Watson Concept Expansion&#x2122; can be used to identify the concept cues in a received in an electronic data package (e.g., <b>105</b>(<b>1</b>) reflecting the interaction interactions between a user and the data <b>109</b>, as well as the context information to determine the intent thereof). In this regard, large sets of unstructured sets of data may be provided to the information extraction module <b>208</b> during a training stage, such that it can learn therefrom. The large sets of unstructured data may relate to prior user interactions with data that were successfully interpreted by the information extraction module <b>208</b>, which now acts as a corpus of data to learn from. Such concept expansion enables the creation of a specialized dictionary for the cognitive application of identifying the subject matter and scope of each user interaction, collectively referred to herein as the &#x201c;intent&#x201d; of the interaction. Concept expansion enables the information extraction module <b>208</b> to build a specialized dictionary for the cognitive application of interacting with the electronic data package from the user (e.g., <b>105</b>(<b>1</b>)). Accordingly, by virtue of the information extraction module <b>208</b>, the knowledge expansion engine <b>103</b> can correctly understand industry specific terminology, local euphemisms, and colloquial terms that may be specific to a domain.</p><p id="p-0042" num="0041">In one embodiment, there is a knowledge structurer module <b>206</b> that is operative to structure the captured user interaction data and as a trail of actions (e.g., events over time). The goal is to have user interaction data connected and aligned with specialized ontologies. The alignment enables the mapping of low-level interaction events (e.g., streaming data with timestamps) to a high-level discovery-process that is described by the domain ontology.</p><p id="p-0043" num="0042">There may be a polystore database <b>220</b> that is operative to decide which module will be used to store each type of content. The polystore database <b>220</b> provides the possibility of storing information on different storage solutions in parallel. For instance, the system may use a mongoDB object database to store files and binary data, and a Jena triplestore for facts. The polystore provides an abstraction for the system that may be agnostic to the actual storage solutions. Generally a multimedia content module <b>224</b> is used to store all user content. In one embodiment, the intelligent mechanisms that enable knowledge expansion are stored in the learning pipelines <b>222</b>, whereas the structured user interactions (i.e., trails) are stored in the hyperlinked knowledge representation module <b>226</b>.</p><p id="p-0044" num="0043">In one embodiment, there is a knowledge analyzer module <b>210</b> that is operative to process the graph representation from the polystore database <b>220</b> (i.e., knowledge graph, data database, etc.), as well as identify learning strategies for expanding the knowledge graph based on existing trail-based structures (i.e., recorded trails for the subject domain).</p><p id="p-0045" num="0044">In one embodiment, there is a knowledge expander <b>212</b> that is operative to apply the strategy selected by the knowledge analyzer <b>210</b> to create new entities in the hyperlinked knowledge representation <b>109</b> (e.g., graph). The knowledge analyzer module <b>210</b> identifies viable strategies for expanding the KG (i.e. via ML algorithms, rule-based inference, etc.). The knowledge expander module <b>212</b> is in charge of actually executing these learning strategies and injecting the result in the KG for further inspection and curation.</p><heading id="h-0010" level="1">Example Use Case Scenarios</heading><p id="p-0046" num="0045">The concepts discussed herein may be better appreciated in view of some use case scenarios. Consider for example a geologist (e.g., domain expert) exploring seismic images (e.g., seismic cube) from disparate sources. In this regard, <figref idref="DRAWINGS">FIG. <b>3</b></figref> provides a conceptual block diagram <b>300</b> of a use case related to seismic cube exploration, consistent with an illustrative embodiment. For discussion purposes, <figref idref="DRAWINGS">FIG. <b>3</b></figref> is discussed below with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0047" num="0046">Upon a trigger event, the knowledge expansion engine <b>103</b> starts the knowledge structure process (<b>302</b>). The domain expert receives data related to seismic activity. For example, the domain expert interprets and annotates parts of a seismic cube received from a data source <b>107</b>. Additionally, the domain expert can review various sources of data to identify geological factors and make decisions based on their review of the data. For example, upon identifying certain patterns in the seismic cube, the domain expert takes one or more actions by annotating each relevant segment of the data with his/her findings (<b>304</b>). These findings may be entered into a dashboard GUI. Additional context data may be harvested by various sensors of the user device.</p><p id="p-0048" num="0047">The information extraction module <b>208</b> receives the electronic data package including the interaction data as well as the context data. The knowledge structurer module <b>206</b> structures the received electronic data and context data as a trail-based workflow (<b>306</b>). Stated differently, the received user interaction data and its corresponding context data is structured as a trail of actions. Each action in the trail is aligned onto entities of an ontology that describes the actions of the domain expert. For example, each of the actions is mapped to entities of an ontology for a domain (e.g., actions related to the analysis of specific subsurface structures in the domain of geology). In some embodiments, the actions may be hierarchical and nested, where a general action can be divided into trails of sub-actions at different levels of nesting. In one embodiment, a domain expert (e.g., the same domain expert performing the actions or another authorized user) can adjust the mapping after the initial mapping of the knowledge structurer <b>206</b>.</p><p id="p-0049" num="0048">The trail aligned to the ontology is used to generate a (e.g., hyperlinked) knowledge graph, which can be displayed on a user interface (e.g., GUI <b>202</b>) (<b>308</b>). The knowledge graph can be navigable and nested. For example, a user can select a node to go down to a more fine grain level of resolution of actions performed. The knowledge expansion engine <b>103</b> can compare various trails to determine which actions and sequence of actions are more effective with respect to the ontology. In this regard, the knowledge expansion engine <b>103</b> can make adjustments to elements (e.g., actions) of the trail, as discussed in more detail below in the context of the knowledge expansion process <b>310</b>.</p><p id="p-0050" num="0049">During a knowledge expansion process <b>310</b>, one or more available trails that are part of the knowledge graph are analyzed and opportunities for knowledge expansion are provided by the knowledge analyzer module <b>210</b>. For example, the knowledge analyzer <b>210</b> traverses the knowledge graph representation provided by the polystore database <b>220</b> and identifies one or more appropriate learning pipelines. As used herein, learning pipelines are the workflows that, if executed, create further instances (e.g., a-box expansion) or even new classes and relations (e.g., t-box expansion). These pipelines may involve ML tasks, but also other types of learning (e.g., rule-based inference, or other numerical processing workflows). In various embodiments, rule-based inference <b>320</b>, graph neural network (GNN) for link prediction <b>322</b>, and/or unsupervised learning <b>324</b> can be used to generate new facts, relations, and trails (e.g., a-box and t-box expansion). In this way, the knowledge expander module <b>212</b> can apply one or more of these strategies selected by the knowledge analyzer <b>210</b> to create new entities (e.g., nodes) in the (e.g., hyperlinked) knowledge graph. The knowledge expansion engine <b>103</b> can then display the structured (e.g., hyperlinked) knowledge graph, thereby facilitating knowledge curation by users and or by way of machine learning, while continuously learning through new user interaction. In one example, the criteria to select the appropriate strategy depends on the problem the user is addressing in his/her discovery-process. It is assumed this information will be modeled in the injected ontology. For instance, in the geoscience use case, the expert is trying to classify and annotate images. In this case, the system will try to create workflows that can ingest images and provide a classifier for parts of the seismic image.</p><p id="p-0051" num="0050">Reference now is made to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, which provides a conceptual block diagram <b>400</b> of a use case related to machine learning (ML) model design, consistent with an illustrative embodiment. Again, <figref idref="DRAWINGS">FIG. <b>4</b></figref> is discussed below with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref> for clarity. Since the overall architecture <b>400</b> is similar to that of <figref idref="DRAWINGS">FIG. <b>3</b></figref> discussed above, it will not be discussed in substantial detail for brevity, while it will be understood that similar actions can apply.</p><p id="p-0052" num="0051">Upon a trigger event, the knowledge expansion engine <b>103</b> starts the knowledge structure process (<b>402</b>). The domain (i.e., machine learning in the present example) expert receives raw data and creates a predictive model with respect to a classification task (<b>404</b>). The knowledge structurer module <b>206</b> structures the received electronic data and context data as a trail-based workflow (<b>406</b>). Each action in the trail is aligned onto entities of an ontology that governs the actions of the domain expert.</p><p id="p-0053" num="0052">The trail aligned to the ontology is used to generate a (e.g., hyperlinked) knowledge graph, which can be displayed on a user interface (e.g., GUI <b>202</b>) (<b>408</b>). As in the example of <figref idref="DRAWINGS">FIG. <b>3</b></figref>, the knowledge expansion engine <b>103</b> can compare various trails to determine which actions and sequence of actions are more effective with respect to the ontology.</p><p id="p-0054" num="0053">During a knowledge expansion process <b>410</b>, where new learning pipelines are developed, one or more available trails are analyzed and the knowledge graph is traversed for identifying opportunities for knowledge expansion by the knowledge analyzer module <b>210</b>. For example, the knowledge analyzer <b>210</b> traverses the knowledge graph representation provided by the polystore database <b>220</b> and identifies one or more appropriate learning pipelines. Automatic machine learning <b>420</b> may be used to develop new ML models <b>430</b>. For example, the corpus of data to learn from (e.g., training data) can be both trails and other data represented in the knowledge graph. If multiple trails are not provided, in one embodiment, one shot machine learning may be performed. Alternatively, or in addition, transfer learning <b>422</b> may be performed by the knowledge expansion engine <b>103</b> to provide a network topology (e.g., structure of neural networks) enhancement <b>432</b>, and/or data augmentation <b>424</b> to create new training data from existing content <b>434</b>. In this way, the knowledge expander module <b>212</b> can apply one or more of these strategies selected by the knowledge analyzer <b>210</b> to create new entities in the in the (e.g., hyperlinked) knowledge graph. The knowledge expansion engine <b>103</b> can then display the structured (e.g., hyperlinked) knowledge graph, thereby facilitating knowledge curation by users and/or by way of machine learning, while continuously learning through new user interaction.</p><heading id="h-0011" level="1">Example Processes</heading><p id="p-0055" num="0054">With the foregoing overview of the architecture <b>100</b>, example block diagram <b>200</b> of the knowledge expansion engine <b>103</b>, and example use cases <b>300</b> and <b>400</b>, it may be helpful now to consider a high-level discussion of example processes. To that end, <figref idref="DRAWINGS">FIGS. <b>5</b> and <b>6</b></figref> present illustrative processes <b>500</b> and <b>600</b> for automatically structuring user interaction trails for knowledge expansion in knowledge graphs. More specifically, <figref idref="DRAWINGS">FIG. <b>5</b></figref> describes a knowledge structure process and <figref idref="DRAWINGS">FIG. <b>6</b></figref> describes a subsequent trail-based knowledge expansion process, consistent with an illustrative embodiment.</p><p id="p-0056" num="0055">Processes <b>500</b> and <b>600</b> are each illustrated as a collection of blocks in a process, representing a sequence of operations that can be implemented in hardware, software, or a combination thereof. In the context of software, the blocks represent computer-executable instructions that, when executed by one or more processors, perform the recited operations. Generally, computer-executable instructions may include routines, programs, objects, components, data structures, and the like that perform particular functions or implement particular abstract data types. The order in which the operations are described is not intended to be construed as a limitation, and any number of the described blocks can be combined in any order and/or performed in parallel to implement the process. For discussion purposes, the processes <b>500</b> and <b>600</b> are described with reference to the architectures <b>100</b> and <b>200</b> of <figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref>, respectively.</p><p id="p-0057" num="0056">At block <b>502</b>, a user (e.g., domain expert) initiates interaction with data <b>109</b> by way of a dashboard GUI (e.g., <b>202</b>). In response, at block <b>504</b>, the device manager <b>204</b> starts capturing the user interaction with the data <b>109</b> by way of electronic data packages (e.g., <b>105</b>(<b>1</b>) to <b>105</b>(N)) harvested through various sensors, as discussed herein. In some embodiments, context of one or more user interactions are captured in the electronic data packages additionally.</p><p id="p-0058" num="0057">At block <b>506</b>, the information extraction module <b>208</b> of the knowledge expansion engine <b>103</b> extracts (e.g., interprets) information from the captured user interaction (and the context information if available, such as facial expression, user intent etc.,). For example, any selection, user input, video content, audio content, context information, annotation, explanation, etc., is interpreted by the extraction module <b>208</b> using one or more machine learning/artificial intelligence techniques, as discussed herein.</p><p id="p-0059" num="0058">At block <b>508</b>, the information extracted from the captured content is structured as a trail of actions (e.g., interactions over time) by the knowledge structurer module <b>206</b>. In one embodiment, facial expression, mood, etc., can be used as peripheral information that can be used to infer further the user intent.</p><p id="p-0060" num="0059">At block <b>510</b>, each of the trail of actions (which may also include the contextual information) is mapped onto a predetermined ontology <b>113</b>, which may be received from an ontology database <b>112</b>. Stated differently, the low-level events (e.g., actions) are aligned with high-level entities of the ontology by the knowledge structurer module <b>206</b>.</p><p id="p-0061" num="0060">At block <b>512</b>, the knowledge representation module <b>226</b> creates a knowledge graph based on the matched ontology. In one embodiment, the knowledge graph is hyperlinked (i.e., has references to other graphs). The knowledge graph can be stored in the polystore database <b>220</b> for further processing.</p><p id="p-0062" num="0061">At block <b>514</b>, the knowledge graph can be displayed on a GUI. A user can make trail corrections or adjustments, as well as use the knowledge graph as a basis of learning and having an overview of the actions taken in relation to the overall ontology.</p><p id="p-0063" num="0062">In one embodiment, the harvesting and updating of the knowledge graph is iterative in that the knowledge graph is continuously updated based on additionally harvested information (e.g., user interaction data and context data). In this regard, at block <b>516</b>, the expansion knowledge engine <b>103</b> determines whether the user interaction is complete. For example, the knowledge expansion engine <b>103</b> may wait a predetermined time period or send a request to a GUI of the user device to determine the status of the interaction. Upon determining that the user interaction is complete (i.e., &#x201c;YES&#x201d; at determination block <b>516</b>), the process ends. However, upon determining that the interaction is not complete (i.e., &#x201c;NO&#x201d; at determination block <b>516</b>), the process returns to block <b>504</b>, where the device manager <b>204</b> captures additional user interaction (and possibly context data), and the process continues iteratively.</p><p id="p-0064" num="0063">Reference now is made to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, which is a process flow related to a trail-based knowledge expansion, consistent with an illustrative embodiment. For example, the polystore database <b>220</b> may include many knowledge graphs capturing structured trail-based workflows (e.g., action of a trail matched onto entities of an ontology). In various embodiments, a (hyperlinked) graph can be structured to include multiple trails or each trail can be separated into a separate (e.g., hyperlinked) knowledge graph. At block <b>602</b>, for each knowledge graph, the knowledge analyzer <b>210</b> of the knowledge expansion engine <b>103</b> retrieves and processes the structured trail-based workflows captured in the knowledge graph.</p><p id="p-0065" num="0064">At block <b>604</b>, the knowledge analyzer <b>210</b> traverses the knowledge graph and identifies learning pipelines for the available trails (e.g., user interactions with data that are mapped onto the ontology) captured and structured in the knowledge graph. The knowledge analyzer <b>210</b> determines appropriate learning pipeline(s), including data augmentation, symbolic reasoning, and/or other artificial learning strategies, including (without limitation) unsupervised learning, supervised learning, auto-ML, GAN, link prediction, etc., for the available trail-based structures.</p><p id="p-0066" num="0065">At block <b>606</b>, the knowledge expander module <b>212</b> applies the determined expansion strategy provided by the knowledge analyzer <b>210</b> and creates new entities in the knowledge graph.</p><p id="p-0067" num="0066">At block <b>608</b>, a new knowledge graph is provided on a GUI (e.g., <b>202</b>) that includes the new entities. In one embodiment, the knowledge graph is hyperlinked.</p><p id="p-0068" num="0067">At block <b>610</b>, the knowledge expansion engine <b>103</b> determines whether a new trail is available. If not (i.e., &#x201c;NO&#x201d; at decision block <b>610</b>), the process ends. However, if a new entity is available (i.e., &#x201c;YES&#x201d; at decision block <b>610</b>), the process returns to block <b>602</b> to continue the iterative process.</p><heading id="h-0012" level="1">Example Computer Platform</heading><p id="p-0069" num="0068">As discussed above, functions relating to automatically structuring user interaction trails for knowledge expansion in knowledge graphs, and other functions discussed herein, can be performed with the use of one or more computing devices connected for data communication via wireless or wired communication, as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. <figref idref="DRAWINGS">FIG. <b>7</b></figref> is a functional block diagram illustration of a particularly configured computer hardware platform that can be used to implement the server <b>116</b> discussed in the context of <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p><p id="p-0070" num="0069">The computer platform <b>700</b> may include a central processing unit (CPU) <b>704</b>, a hard disk drive (HDD) <b>706</b>, random access memory (RAM) and/or read only memory (ROM) <b>708</b>, a keyboard <b>710</b>, a mouse <b>712</b>, a display <b>714</b>, and a communication interface <b>716</b>, which are connected to a system bus <b>702</b>.</p><p id="p-0071" num="0070">In one embodiment, the HDD <b>706</b>, has capabilities that include storing a program that can execute various processes, such as the knowledge expansion engine <b>740</b>, in a manner described herein. The knowledge expansion engine <b>740</b> may have various modules configured to perform different functions. For example, there may be a device manager module <b>204</b>, a knowledge structurer module <b>206</b>, an information extraction module <b>208</b>, a knowledge analyzer module <b>210</b>, an learning pipeline module <b>750</b>, a multimedia content module <b>756</b>, and/or a hyperlinked knowledge representation module <b>226</b>, as discussed herein.</p><heading id="h-0013" level="1">CONCLUSION</heading><p id="p-0072" num="0071">The descriptions of the various embodiments of the present teachings have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments. The terminology used herein was chosen to best explain the principles of the embodiments, the practical application or technical improvement over technologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.</p><p id="p-0073" num="0072">While the foregoing has described what are considered to be the best state and/or other examples, it is understood that various modifications may be made therein and that the subject matter disclosed herein may be implemented in various forms and examples, and that the teachings may be applied in numerous applications, only some of which have been described herein. It is intended by the following claims to claim any and all applications, modifications and variations that fall within the true scope of the present teachings.</p><p id="p-0074" num="0073">The components, steps, features, objects, benefits and advantages that have been discussed herein are merely illustrative. None of them, nor the discussions relating to them, are intended to limit the scope of protection. While various advantages have been discussed herein, it will be understood that not all embodiments necessarily include all advantages. Unless otherwise stated, all measurements, values, ratings, positions, magnitudes, sizes, and other specifications that are set forth in this specification, including in the claims that follow, are approximate, not exact. They are intended to have a reasonable range that is consistent with the functions to which they relate and with what is customary in the art to which they pertain.</p><p id="p-0075" num="0074">Numerous other embodiments are also contemplated. These include embodiments that have fewer, additional, and/or different components, steps, features, objects, benefits and advantages. These also include embodiments in which the components and/or steps are arranged and/or ordered differently.</p><p id="p-0076" num="0075">Aspects of the present disclosure are described herein with reference to call flow illustrations and/or block diagrams of a method, apparatus (systems), and computer program products according to embodiments of the present disclosure. It will be understood that each step of the flowchart illustrations and/or block diagrams, and combinations of blocks in the call flow illustrations and/or block diagrams, can be implemented by computer readable program instructions.</p><p id="p-0077" num="0076">These computer readable program instructions may be provided to a processor of a computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the call flow process and/or block diagram block or blocks. These computer readable program instructions may also be stored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein comprises an article of manufacture including instructions which implement aspects of the function/act specified in the call flow and/or block diagram block or blocks.</p><p id="p-0078" num="0077">The computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or other device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the call flow process and/or block diagram block or blocks.</p><p id="p-0079" num="0078">The flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present disclosure. In this regard, each block in the call flow process or block diagrams may represent a module, segment, or portion of instructions, which comprises one or more executable instructions for implementing the specified logical function(s). In some alternative implementations, the functions noted in the blocks may occur out of the order noted in the Figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and/or call flow illustration, and combinations of blocks in the block diagrams and/or call flow illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.</p><p id="p-0080" num="0079">While the foregoing has been described in conjunction with exemplary embodiments, it is understood that the term &#x201c;exemplary&#x201d; is merely meant as an example, rather than the best or optimal. Except as stated immediately above, nothing that has been stated or illustrated is intended or should be interpreted to cause a dedication of any component, step, feature, object, benefit, advantage, or equivalent to the public, regardless of whether it is or is not recited in the claims.</p><p id="p-0081" num="0080">It will be understood that the terms and expressions used herein have the ordinary meaning as is accorded to such terms and expressions with respect to their corresponding respective areas of inquiry and study except where specific meanings have otherwise been set forth herein. Relational terms such as first and second and the like may be used solely to distinguish one entity or action from another without necessarily requiring or implying any actual such relationship or order between such entities or actions. The terms &#x201c;comprises,&#x201d; &#x201c;comprising,&#x201d; or any other variation thereof, are intended to cover a non-exclusive inclusion, such that a process, method, article, or apparatus that comprises a list of elements does not include only those elements but may include other elements not expressly listed or inherent to such process, method, article, or apparatus. An element proceeded by &#x201c;a&#x201d; or &#x201c;an&#x201d; does not, without further constraints, preclude the existence of additional identical elements in the process, method, article, or apparatus that comprises the element.</p><p id="p-0082" num="0081">The Abstract of the Disclosure is provided to allow the reader to quickly ascertain the nature of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition, in the foregoing Detailed Description, it can be seen that various features are grouped together in various embodiments for the purpose of streamlining the disclosure. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments have more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive subject matter lies in less than all features of a single disclosed embodiment. Thus, the following claims are hereby incorporated into the Detailed Description, with each claim standing on its own as a separately claimed subject matter.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A computing device comprising:<claim-text>a processor;</claim-text><claim-text>a network interface coupled to the processor to enable communication over a network;</claim-text><claim-text>a storage device for content and programming coupled to the processor;</claim-text><claim-text>an engine stored in the storage device, wherein an execution of the engine by the processor configures the user device to perform acts comprising:</claim-text><claim-text>capturing information of a user interacting with given data, as user interaction data;</claim-text><claim-text>structuring the user interaction data as a trail of actions over time;</claim-text><claim-text>receiving an ontology for a domain related to the user interaction data;</claim-text><claim-text>matching each action of the trail of actions onto entities of the ontology; and</claim-text><claim-text>creating a knowledge graph based on the ontology having the matched actions.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the contextual information of the interaction data includes at least one of audio or video of the user interacting with the given data.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The computing device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the execution of the engine further configures the computing device to perform an act comprising determining a facial expression of the user for at least one action of the trail of actions.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:<claim-text>the user interaction data is continuously captured; and</claim-text><claim-text>the knowledge graph is iteratively updated based on the continuously captured interaction data.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the execution of the engine further configures the computing device to perform acts comprising determining an intent of each captured user interaction by way of artificial intelligence.</claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the structured interaction data includes one or more nested hierarchies of the trails of actions.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the execution of the engine further configures the computing device to perform an additional act comprising adjusting one or more actions of the matched trail of actions upon receiving instructions from a domain expert.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the execution of the engine further configures the computing device to perform an additional acts comprising using the created knowledge graph as a corpus of data for machine learning to create an improved trail of actions for the ontology.</claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The computing device of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the machine learning is based on a graph neural network (GNN).</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the execution of the engine further configures the computing device to perform additional acts comprising using machine learning to create one or more new entities in the knowledge graph.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. A non-transitory computer readable storage medium tangibly embodying a computer readable program code having computer readable instructions that, when executed, causes a computing device to carry out a method creating a knowledge graph, the method comprising:<claim-text>capturing information of a user interacting with given data, as user interaction data;</claim-text><claim-text>structuring the user interaction data as a trail of actions over time;</claim-text><claim-text>receiving an ontology for a domain related to the user interaction data;</claim-text><claim-text>matching each action of the trail of actions onto entities of the ontology; and</claim-text><claim-text>creating the knowledge graph based on the ontology having the matched actions.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The non-transitory computer readable storage medium of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the contextual information of the interaction data includes at least one of audio or video of the user interacting with the given data.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The non-transitory computer readable storage medium of <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising determining a facial expression of the user for at least one action of the trail of actions.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The non-transitory computer readable storage medium of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein:<claim-text>the user interaction data is continuously captured; and</claim-text><claim-text>the knowledge graph is iteratively updated based on the continuously captured interaction data.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The non-transitory computer readable storage medium of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the structured interaction data includes one or more nested hierarchies of the trails of actions.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer readable storage medium of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising adjusting one or more actions of the matched trail of actions upon receiving instructions from a domain expert.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer readable storage medium of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising using the created knowledge graph as a corpus of data for machine learning to create an improved trail of actions for the ontology.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer readable storage medium of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the machine learning is based on a graph neural network (GNN).</claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer readable storage medium of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising using machine learning to create one or more new entities in the knowledge graph.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. A computer implemented method comprising:<claim-text>capturing information of a user interacting with given data, as user interaction data;</claim-text><claim-text>structuring the user interaction data as a trail of actions over time;</claim-text><claim-text>receiving an ontology for a domain related to the user interaction data;</claim-text><claim-text>matching each action of the trail of actions onto entities of the ontology; and</claim-text><claim-text>creating the knowledge graph based on the ontology having the matched actions.</claim-text></claim-text></claim></claims></us-patent-application>
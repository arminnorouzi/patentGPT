<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004277A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004277</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17364636</doc-number><date>20210630</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0481</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0482</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>L</subclass><main-group>12</main-group><subgroup>58</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>04817</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>0482</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>L</subclass><main-group>51</main-group><subgroup>02</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">USER INTERFACE FOR SEARCHING CONTENT OF A COMMUNICATION PLATFORM USING REACTION ICONS</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Slack Technologies, Inc.</orgname><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Lowry</last-name><first-name>McKenna</first-name><address><city>Valhalla</city><state>NY</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Payan</last-name><first-name>Austen</first-name><address><city>New York City</city><state>NY</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Lee</last-name><first-name>Anthony Tae Jin</first-name><address><city>Oakland</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Harris</last-name><first-name>Racine</first-name><address><city>New York</city><state>NY</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A user interface comprising at least a set of reaction icons configured to initiate a search of content of a communication platform is described. In an example, at least the set of reaction icons can be presented via the user interface of the communication platform, wherein individual reaction icons of the set of reaction icons are selectable as search parameters in the user interface. In response to receiving a selection of at least one reaction icon, a search for content, associated with the at least one reaction icon, stored in a database associated with the communication platform can be initiated.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="138.18mm" wi="144.78mm" file="US20230004277A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="265.68mm" wi="171.37mm" orientation="landscape" file="US20230004277A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="235.46mm" wi="167.89mm" orientation="landscape" file="US20230004277A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="249.60mm" wi="159.34mm" orientation="landscape" file="US20230004277A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00004" num="00004"><img id="EMI-D00004" he="251.38mm" wi="162.48mm" orientation="landscape" file="US20230004277A1-20230105-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00005" num="00005"><img id="EMI-D00005" he="235.46mm" wi="159.34mm" orientation="landscape" file="US20230004277A1-20230105-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00006" num="00006"><img id="EMI-D00006" he="256.03mm" wi="166.62mm" file="US20230004277A1-20230105-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00007" num="00007"><img id="EMI-D00007" he="214.55mm" wi="146.81mm" file="US20230004277A1-20230105-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">A communication platform can leverage a network-based computing system to enable users to exchange data. In an example, users of the communication platform can communicate with other users via channels, direct messages, and/or other virtual spaces. A channel, direct message, and/or other virtual space can be a data route used for exchanging data between and among systems and devices associated with the communication platform. For example, a channel may be established between and among various user computing devices (e.g., clients), allowing the user computing devices to communicate and share data between and among each other over one or more networks. That is, in some examples, the communication platform can be a channel-based platform and/or hub for facilitating communication between and among users. In some examples, data associated with a channel, a direct message, and/or other virtual space can be presented via a user interface. In some examples, the user interface can present a data feed indicating messages posted to and/or actions taken with respect to a particular channel, direct message, and/or other virtual space.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0002" level="1">BRIEF DESCRIPTION OF THE FIGURES</heading><p id="p-0003" num="0002">The detailed description is described with reference to the accompanying figures. In the figures, the left-most digit of a reference number identifies the figure in which the reference number first appears. The use of the same reference numbers in different figures indicates similar or identical components or features. The figures are not drawn to scale.</p><p id="p-0004" num="0003"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example environment for performing techniques described herein.</p><p id="p-0005" num="0004"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> illustrates an example user interface associated with a communication platform, as described herein, wherein the user interface includes an affordance to initiate a search of content associated with the communication platform.</p><p id="p-0006" num="0005"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates another example of the user interface of <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, wherein the user interface presents at least one set of reaction icons that are selectable to initiate the search using a reaction icon as a search parameter.</p><p id="p-0007" num="0006"><figref idref="DRAWINGS">FIG. <b>2</b>C</figref> illustrates another example of the user interface of <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, wherein the user interface presents at least one set of reaction icons that are selectable to initiate the search using a reaction icon as a search parameter.</p><p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>2</b>D</figref> illustrates another example of the user interface of <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, wherein the user interface presents one or more search results based at least in part on a selected reaction icon.</p><p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example process for determining a set of reaction icons that are selectable via a user interface to initiate a search of content exchanged via a communication platform, as described herein.</p><p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example process for determining a set of reaction icons based at least in part on interaction data associated with content exchanged via a communication platform, as described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0003" level="1">DETAILED DESCRIPTION</heading><p id="p-0011" num="0010">This application relates to a user interface that is configured to present set(s) of reaction icons (e.g., emojis, reactjis, and/or the like) to facilitate a search of content associated with a communication platform. The communication platform, which, in some examples can be a group-based communication platform, a channel-based communication platform, a permission-based communication platform, a channel-based messaging platform, and/or any other platform for facilitating communication between and among users, can enable users to exchange messages and/or other data via the communication platform. In an example, the communication platform can curate set(s) of reaction icons for individual users, groups of users, and/or the like based at least in part on interaction data associated with content of the communication platform. In some examples, at least one of recency of interaction with individual reaction icon(s), frequency of interaction with individual reaction icon(s), and/or the like can be determined based at least in part on the interaction data and such recency of interaction with individual reaction icon(s), frequency of interaction with individual reaction icon(s), and/or the like can be used to curate the set(s) of reaction icons. In at least one example, individual reaction icon(s) in a set of reaction icons can be selectable as search parameter(s). That is, in at least one example, selection of a reaction icon can trigger a search for content, stored in a database of the communication platform, that is associated with the selected reaction icon. The communication platform can return a result with identified content.</p><p id="p-0012" num="0011">A &#x201c;message,&#x201d; as used herein, can refer to any electronically generated digital object provided by a user of the communication platform. A message can be configured for presentation within a channel, a direct message, and/or another virtual space as described herein. In at least one example, a message can be associated with message content, which can include text data, image data, video data, audio data, file(s), etc. In some examples, one or more users of the communication platform can interact with a message, for example, by associating a reaction icon (e.g., an emoji, a reactji, or the like) with the message. In some examples, one or more users of the communication platform can interact with a message by replying to the message. In some examples, a reply can be posted to a feed associated with a channel, direct message, or other virtual space. In other examples, a reply can comprise a new message in a &#x201c;thread.&#x201d; A thread can be a message associated with another message that is not posted to a channel, direct message, or other virtual space, but instead is maintained within an object associated with the original message. Messages and associated reactions (e.g., reaction icon(s) and/or reply(s)) can be stored in a datastore of the communication platform as &#x201c;content&#x201d; of the communication platform.</p><p id="p-0013" num="0012">In at least one example, the content of the communication platform, can be searchable, for example by term (e.g., key word), reaction icon, user, date, virtual space, and/or the like. That is, in at least one example, the communication platform can provide an affordance via a user interface to enable a user to search content of the communication platform via one or more search parameters. Such an affordance can enable a user to designate the one or more search parameters, which can be term(s), reaction icon(s), user(s), date(s), virtual space(s), and/or the like. In response to receiving a search request associated with one or more search parameters, the communication platform can perform a search of a datastore associated with the communication platform. The datastore can store content, as described above. Based at least in part on identifying one or more items of content that satisfy the search parameters, the communication platform can return one or more search results.</p><p id="p-0014" num="0013">In at least one example, techniques described herein relate to determining set(s) of reaction icons to present via a user interface to enable a user to search by reaction icon(s). That is, the communication platform can curate set(s) of one or more reaction icons that can be presented via a user interface for facilitating a search. Set(s) of reaction icons can be determined based at least in part on frequency of interaction with individual reaction icons, recency of interaction with individual reaction icons, and/or the like. In some examples, a set of reactions icons, which can comprise one or more reaction icons, can be particular to a user, a group of users, or the communication platform, generally. In at least one example, a reaction icon can comprise a search parameter such that upon receiving a search request associated with the reaction icon, the communication platform can perform a search for content associated with the communication platform that is associated with the reaction icon. If content associated with the communication platform is identified, the communication platform can return such content as a search result.</p><p id="p-0015" num="0014">Techniques described herein can be helpful for easily retrieving content associated with the communication platform. For example, a user can desire to recall a message posted to a channel where other users reacted with a particular reaction icon (e.g., a dancing chicken reactji). In existing techniques a user can search via a term, a user, a date, a virtual space, or the like, but the user may not recall a term, user, date, virtual space, or the like associated with the message. The user may recall how people reacted (e.g., using a dancing chicken reactji). In some existing techniques, if a user knows how a particular reaction icon is named or defined, the user could input the name or definition of the particular reaction icon (e.g., :dancing chicken:) into the search affordance. However, if a user does not know how a particular reaction icon is named or defined, the user may be left without a mechanism to retrieve the content. As such, techniques described herein offer an improvement to existing search technology.</p><p id="p-0016" num="0015">As described above, techniques described herein utilize interaction data associated with content exchanged via the communication platform to determine set(s) of reaction icons that are relevant to a particular user. As described above, at least one set of reaction icons can be determined based at least in part on frequency and/or recency of interaction with particular reaction icons, for example, by the user or a group of users with which the user may be similar to or otherwise related. As such, the communication platform can cause set(s) of reaction icons to be presented via a user interface, that are in some examples relevant or otherwise personalized for a user, to enable the user to select or otherwise set search parameters for a search.</p><p id="p-0017" num="0016">Techniques described herein offer improvements over existing search technologies by improving user interfaces used to facilitate searches, reducing the number of interactions required to retrieve content, and/or streamlining user interaction with user interfaces. That is, by presenting an affordance for a user to designate search parameters via an interaction with set(s) of reaction icons, techniques described herein provide a more user-friendly mechanism to initiate a search. As described herein, the set(s) of reaction icons can be determined to be relevant to a particular user and thus can narrow, at least initially, the search parameters presented for the user for selection. Further, by presenting an affordance for a user to designate search parameters via an interaction with set(s) of reaction icons, techniques described herein eliminate the need for a user to recall a term, user, virtual space, date, reaction icon name and/or definition, and/or the like. As such, search queries can be more accurate and/or precise, thereby reducing the number of interactions required to retrieve content via a search. This can conserve bandwidth and computing resources. Moreover, by determining and/or presenting relevant information, users need not navigate through various search parameter possibilities and search results can be more accurate and/or precise (due to search queries being more accurate and/or precise). As such, techniques described herein offer improvements over conventional search technologies.</p><p id="p-0018" num="0017">Additional or alternative benefits offered by techniques described herein are described herein.</p><p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an example environment <b>100</b> for performing techniques described herein. In at least one example, the example environment <b>100</b> can include one or more server computing devices (or &#x201c;server(s)&#x201d;) <b>102</b>. In at least one example, the server(s) <b>102</b> can include one or more servers or other types of computing devices that can be embodied in any number of ways. For example, in the case of a server, the functional components and data can be implemented on a single server, a cluster of servers, a server farm or data center, a cloud-hosted computing service, a cloud-hosted storage service, and so forth, although other computer architectures can additionally or alternatively be used.</p><p id="p-0020" num="0019">In at least one example, the server(s) <b>102</b> can be associated with a communication platform that can leverage a network-based computing system to enable users of the communication platform to exchange data. In at least one example, the communication platform can be &#x201c;group-based&#x201d; such that the platform, and associated systems, channels, messages, and/or virtual spaces, have security (that can be defined by permissions) to limit access to defined groups of users, such a defined group of users having, for instance, sole access to a given channel, message, and/or virtual space. In some examples, such groups of users can be defined by identifiers, which can be associated with common access credentials, domains, or the like. In some examples, the communication platform can be a hub, offering a secure and private virtual space to enable users to chat, meet, call, collaborate, transfer files or other data, message, or otherwise communicate between or among each other, within secure and private virtual spaces, such as channel(s), direct message(s), board(s), and/or the like.</p><p id="p-0021" num="0020">In some examples, each group can be associated with an organization, which can be associated with an organization identifier. Users associated with the organization identifier can chat, meet, call, collaborate, transfer files or other data, message, or otherwise communicate between or among each other in a secure and private virtual space available via the communication platform. In some examples, each group can be associated with a workspace, associated with a workspace identifier. Users associated with the workspace identifier can chat, meet, call, collaborate, transfer files or other data, message, or otherwise communicate between or among each other in a secure and private virtual space available via the communication platform. In some examples, a group can be associated with multiple organizations and/or workspaces. In some examples, an organization can be associated with multiple workspaces or a workspace can be associated with multiple organizations.</p><p id="p-0022" num="0021">In at least one example, the server(s) <b>102</b> can communicate with a user computing device <b>104</b> via one or more network(s) <b>106</b>. That is, the server(s) <b>102</b> and the user computing device <b>104</b> can transmit, receive, and/or store data (e.g., content, messages, and/or the like) using the network(s) <b>106</b>, as described herein. In some examples, the user computing device <b>104</b> can comprise a &#x201c;client&#x201d; associated with a user. The user computing device <b>104</b> can be any suitable type of computing device, e.g., portable, semi-portable, semi-stationary, or stationary. Some examples of the user computing device <b>104</b> can include a tablet computing device, a smart phone, a mobile communication device, a laptop, a netbook, a desktop computing device, a terminal computing device, a wearable computing device, an augmented reality device, an Internet of Things (IOT) device, or any other computing device capable of sending communications and performing the functions according to the techniques described herein. While a single user computing device <b>104</b> is shown, in practice, the example environment <b>100</b> can include multiple (e.g., tens of, hundreds of, thousands of, millions of) user computing devices. In at least one example, user computing devices, such as the user computing device <b>104</b>, can be operable by users to, among other things, access communication services via the communication platform. A user can be an individual, a group of individuals, an employer, an enterprise, an organization, or the like. In some examples, users can be associated with designated roles (e.g., based at least in part on an organization chart) and/or types (e.g., administrator, verified, etc.).</p><p id="p-0023" num="0022">The network(s) <b>106</b> can include, but are not limited to, any type of network known in the art, such as a local area network or a wide area network, the Internet, a wireless network, a cellular network, a local wireless network, Wi-Fi and/or close-range wireless communications, Bluetooth&#xae;, Bluetooth Low Energy (BLE), Near Field Communication (NFC), a wired network, or any other such network, or any combination thereof. Components used for such communications can depend at least in part upon the type of network, the environment selected, or both. Protocols for communicating over such network(s) <b>106</b> are well known and are not discussed herein in detail.</p><p id="p-0024" num="0023">In at least one example, the server(s) <b>102</b> can include one or more processors <b>108</b>, computer-readable media <b>110</b>, one or more communication interfaces <b>112</b>, and input/output devices <b>114</b>.</p><p id="p-0025" num="0024">In at least one example, each processor of the processor(s) <b>108</b> can be a single processing unit or multiple processing units, and can include single or multiple computing units or multiple processing cores. The processor(s) <b>108</b> can be implemented as one or more microprocessors, microcomputers, microcontrollers, digital signal processors, central processing units (CPUs), graphics processing units (GPUs), state machines, logic circuitries, and/or any devices that manipulate signals based on operational instructions. For example, the processor(s) <b>108</b> can be one or more hardware processors and/or logic circuits of any suitable type specifically programmed or configured to execute the algorithms and processes described herein. The processor(s) <b>108</b> can be configured to fetch and execute computer-readable instructions stored in the computer-readable media, which can program the processor(s) to perform the functions described herein.</p><p id="p-0026" num="0025">The computer-readable media <b>110</b> can include volatile, nonvolatile, removable, and/or non-removable memory or other media implemented in any type of technology for storage of data, such as computer-readable instructions, messages, program modules, or other data. Such computer-readable media <b>110</b> can include, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, optical storage, solid state storage, magnetic tape, magnetic disk storage, RAID storage systems, storage arrays, network attached storage, storage area networks, cloud storage, or any other medium that can be used to store the desired data and that can be accessed by a computing device. Depending on the configuration of the server(s) <b>102</b>, the computer-readable media <b>110</b> can be a type of computer-readable storage media and/or can be a tangible non-transitory media to the extent that when mentioned, non-transitory computer-readable media exclude media such as energy, carrier signals, electromagnetic waves, and signals per se.</p><p id="p-0027" num="0026">The computer-readable media <b>110</b> can be used to store any number of functional components that are executable by the processor(s) <b>108</b>. In many implementations, these functional components comprise instructions or programs that are executable by the processor(s) <b>108</b> and that, when executed, specifically configure the processor(s) <b>108</b> to perform the actions attributed above to the server(s) <b>102</b>. Functional components stored in the computer-readable media can optionally include a search component <b>116</b>, a channel management component <b>118</b>, a direct message management component <b>119</b>, an operating system <b>120</b>, and a datastore <b>122</b>.</p><p id="p-0028" num="0027">In at least one example, the search component <b>116</b> can facilitate searches of content associated with the communication platform. As described above, in at least one example, the content of the communication platform, can be searchable, for example by one or more search parameters. A search parameter can comprise a term (e.g., key word), reaction icon, user, date, virtual space, and/or the like. In some examples, a search request (or &#x201c;search query&#x201d;) can be associated with one or more search parameters. In at least one example, the search component <b>116</b> can provide an affordance via a user interface to enable a user to search content of the communication platform via one or more search parameters. Such an affordance can enable a user to designate the one or more search parameters, which can be term(s), reaction icon(s), user(s), date(s), virtual space(s), and/or the like. In response to receiving a search request associated with one or more search parameters, the search component <b>116</b> can perform a search of the datastore <b>122</b>. In at least one example, based at least in part on identifying one or more items of content that satisfy the search parameters, the search component <b>116</b> can return one or more search results. The one or more search results can be presented via a user interface of the communication platform. In at least one example, if no items of content satisfy the search parameters, the search component <b>116</b> can return an indication that there are no search results.</p><p id="p-0029" num="0028">In at least one example, the search component <b>116</b> can determine set(s) of reaction icons to present via a user interface to enable a user to search by reaction icon(s). As described above, a set of reaction icons can comprise one or more reaction icons. Further, as described above, a set of reaction icons can include one or more emojis, reactjis, or the like. Set(s) of reaction icons can be determined based at least in part on frequency of interaction with individual reaction icons, recency of interaction with individual reaction icons, a number of times a particular reaction icon has been interacted with (e.g., a count), and/or the like. As used herein, &#x201c;frequency of interaction&#x201d; can refer to a rate at which a user or group of users interacts with a reaction icon within a period of time. As used herein, &#x201c;recency of interaction&#x201d; can refer to an interaction occurring within a period of time comparatively close to a present time. For example, an interaction one minute prior to present time is more recent than an interaction two days prior to present time. Such metrics (e.g., frequency of interaction, recency of interaction, number of interactions, etc.) can be determined based at least in part on interaction data associated with content of the communication platform. Such interaction data, as described above, can indicate how users interact with content of the communication platform (e.g., which emojis and/or reactjis are used for reactions, whether a reply is sent, a date and/or time associated with such reactions, users associated with such reactions, and/or the like).</p><p id="p-0030" num="0029">In some examples, a set of reactions icons can be particular to a user, a group of users, or the communication platform, generally. That is, in at least one example, a set of reaction icons can be determined based on interaction data associated with a user and thus can be particular to the user. In such an example, the set of reaction icons can include one or more reaction icons that the user most frequently interacts with, most recently interacted with, has interacted with the highest number of times, etc. In some examples, such metrics (e.g., frequency, recency, count, etc.) can be used to determine a relevance metric. The search component <b>116</b> can rank reaction icons based at least in part on relevance metrics and can associate one or more reaction icons with the set based at least in part on the ranking. In some examples, the relevance metric can be determined using a machine-trained model. Such a machine-trained model can be trained using a machine learning mechanism (e.g., supervised, unsupervised, semi-supervised, deep, etc.) on training data which can include reaction icons, interaction data, and search queries associated with selected reaction icons. The machine-trained model can receive new interaction data and can output relevance metrics associated with reaction icons, which can be used for generating a set of reaction icons, as described above. That is, in at least one example, the search component <b>116</b> can determine a set of reaction icons based at least in part on one or more reaction icons that are associated with relevance metrics that meet or exceed a threshold, a number of reaction icons that are highest ranking, and/or the like.</p><p id="p-0031" num="0030">In some examples, a set of reaction icons can be determined based on interaction data associated with a group of users. In such examples, the set of reaction icons can be particular to the group of users. In some examples, the group of users can be associated with a same group identifier (and thus the same workspace and/or organization) as the user, share one or more characteristics with the user (e.g., same role, same geographic area, same age, same preference, etc.), a similarity metric that satisfies a threshold, and/or the like. In at least one example, the set of reaction icons can include one or more reaction icons that users associated with the group of users most frequently interact with, most recently interacted with, have interacted with the highest number of times, etc. In some examples, such metrics (e.g., frequency, recency, count, etc.) can be used to determine a relevance metric. The search component <b>116</b> can rank reaction icons based at least in part on relevance metrics and can associate one or more reaction icons with the set based at least in part on the ranking.</p><p id="p-0032" num="0031">In some examples, a set of reaction icons can be determined based on interaction data associated with the communication platform, and thus can be representative of all users of the communication platform. In such examples, the set of reaction icons can include one or more reaction icons that users associated with the communication platform most frequently interact with, most recently interacted with, have interacted with the highest number of times, etc. In some examples, such metrics (e.g., frequency, recency, count, etc.) can be used to determine a relevance metric. The search component <b>116</b> can rank reaction icons based at least in part on relevance metrics and can associate one or more reaction icons with the set based at least in part on the ranking.</p><p id="p-0033" num="0032">In at least one example, a reaction icon presented in association with a set of reaction icons can comprise a search parameter such that upon receiving a search request associated with the reaction icon, the search component <b>116</b> can perform a search for content associated with the search component <b>116</b> that is associated with the reaction icon. If content associated with the search component <b>116</b> is identified, the search component <b>116</b> can return such content as a search result.</p><p id="p-0034" num="0033">In at least one example, the channel management component <b>118</b> can manage channels of the communication platform. In at least one example, the communication platform can be &#x201c;channel-based&#x201d; such that the platform can be organized into channels having security (that can be defined by permissions) to limit access to defined groups of users (e.g., members of the channels). A channel, or virtual space, can be a data route used for exchanging data between and among systems and devices associated with the communication platform such as, for example, content and/or messages. In some examples, a channel may be &#x201c;public,&#x201d; which may allow any user within a group (e.g., associated with an organization identifier, associated with a workspace identifier, etc.) with which the channel is associated to join and participate in the data sharing through the channel. In some examples, a channel may be &#x201c;private,&#x201d; which may restrict data communications in the channel to certain users or users having particular roles (e.g., managers, administrators, etc.) and/or types (e.g., verified, administrator, etc.). In some examples, a channel may be an &#x201c;announcement&#x201d; channel, which may restrict communication in the channel to announcements or may otherwise be associated with announcements instead of other more granular topics of other channels.</p><p id="p-0035" num="0034">In at least one example, a channel can be associated with a defined group of users within the same organization. Such a channel can be an &#x201c;internal channel&#x201d; or an &#x201c;internally shared channel.&#x201d; In some examples, a channel may be &#x201c;shared&#x201d; or &#x201c;externally shared,&#x201d; which may allow users associated with two or more different groups (e.g., entities associated with two or more different organization and/or workspace identifiers) to join and participate in the data sharing through the channel. A shared channel may be public such that it is accessible to any user of groups associated with the shared channel, or may be private such that it is restricted to access by certain users or users having particular roles and/or types. A &#x201c;shared channel&#x201d; or an &#x201c;externally shared channel&#x201d; can enable two or more organizations, such as a first organization and a second organization to share data, exchange communications, and the like (hence, a &#x201c;shared&#x201d; channel or an &#x201c;externally shared channel&#x201d; can refer to a channel which is accessible across different organizations, whereas an &#x201c;internal channel&#x201d; can refer to a communication channel which is accessible within a same organization). In an example, the first organization and the second organization can be associated with different organization identifiers, can be associated with different business entities, have different tax identification numbers, and/or otherwise can be associated with different permissions such that users associated with the first organization and users associated with the second organization are not able to access data associated with the other organization, without the establishment of an externally shared channel. In some examples, a shared channel can be shared with one or more different workspaces and/or organizations that, without having a shared channel, would not otherwise have access to each other's data by the nature of the permission-based and/or group-based configuration of the communication platform described herein.</p><p id="p-0036" num="0035">In at least one example, the channel management component <b>118</b> can receive a request to generate a channel. In some examples, the request can include a name that is to be associated with the channel, one or more users to invite to join the channel, and/or permissions associated with the channel. In at least one example, one or more user identifiers associated with one or more users and/or one or more user accounts can be mapped to, or otherwise associated with, a channel (e.g., a channel identifier associated therewith). User(s) associated with a channel can be &#x201c;members&#x201d; of the channel. Members of a channel can communicate with other members via the channel. That is, in at least one example, the channel management component <b>118</b> can establish a channel between and among various user computing devices associated with user identifiers associated with the channel, allowing the user computing devices to communicate and share data between and among each other. As described herein, in some examples, such communication and/or sharing of data can be via one or more messages that can be exchanged via a channel. In at least one example, the channel management component <b>118</b> can manage such communications and/or sharing of data. In some examples, data associated with a channel can be presented via a user interface.</p><p id="p-0037" num="0036">As described above, in at least one example, one or more permissions can be mapped to, or otherwise associated with, a channel and/or members associated therewith. Such permission(s) can indicate which user(s) have permission to access the channel, actions and/or messages permitted in the channel, which user(s) and/or type(s) of users are permitted to add or remove members, which user(s) and/or types of users are permitted to share the channel with other users, a retention policy associated with data in the channel, whether the channel is public or private, or the like.</p><p id="p-0038" num="0037">In at least one example, the direct message management component <b>119</b> can manage &#x201c;direct messages,&#x201d; which can comprise communications with individual users or multiple specified users (e.g., instead of all, or a subset of, members of an organization). In at least one example, a &#x201c;direct message&#x201d; can comprise a data route, or virtual space, used for exchanging data between and among systems and devices associated with the communication platform (e.g., content and/or messages). In some examples, a direct message can be a private message between two or more users of the communication platform. In some examples, a direct message may be &#x201c;shared,&#x201d; which may allow users associated with two or more different groups (e.g., entities associated with two or more different organization and/or workspace identifiers) to join and participate in the data sharing through the direct message.</p><p id="p-0039" num="0038">In at least one example, the direct message management component <b>119</b> can receive a request to generate a direct message. In some examples, the request can include identifiers associated with one or more users that are intended recipient(s) (e.g., recipient user(s)) of the direct message. In at least one example, one or more user identifiers associated with one or more users and/or one or more user accounts can be mapped to, or otherwise associated with, a direct message (e.g., or direct message identifier associated therewith). User(s) associated with a direct message can communicate with one another and/or otherwise share data with one another via the direct message. As described herein, in some examples, such communication and/or sharing of data can be via one or more messages that can be exchanged via the direct message. In at least one example, the direct message management component <b>119</b> can manage such communications and/or sharing of data. In some examples, data associated with a direct message can be presented via a user interface.</p><p id="p-0040" num="0039">In at least one example, the operating system <b>120</b> can manage the processor(s) <b>108</b>, computer-readable media <b>110</b>, hardware, software, etc. of the server(s) <b>102</b>.</p><p id="p-0041" num="0040">In at least one example, the datastore <b>122</b> can be configured to store data that is accessible, manageable, and updatable. In some examples, the datastore <b>122</b> can be integrated with the server(s) <b>102</b>, as shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In other examples, the datastore <b>122</b> can be located remotely from the server(s) <b>102</b> and can be accessible to the server(s) <b>102</b> and/or user device(s), such as the user device <b>104</b>. The datastore <b>122</b> can comprise one or multiple databases, which can include user data <b>124</b>, permission data <b>125</b>, channel data <b>126</b>, direct message (DM) data <b>128</b>, content data <b>129</b>, and reaction icon(s) <b>130</b>. Additional or alternative data may be stored in the datastore and/or one or more other datastores.</p><p id="p-0042" num="0041">In at least one example, the user data <b>124</b> can store data associated with users of the communication platform. In at least one example, the user data <b>124</b> can store data in user profiles (which can also be referred to as &#x201c;user accounts&#x201d;). In some examples, a user can be associated with a single user profile. In some examples, a user can be associated with multiple user profiles. A user profile can store data associated with a user, including, but not limited to, one or more user identifiers associated with multiple, different organizations, groups, or entities with which the user is associated, one or more group identifiers for groups (or, organizations, teams, entities, or the like) with which the user is associated, one or more channel identifiers associated with channels to which the user has been granted access, an indication whether the user is an owner or manager of any channels, an indication whether the user has any channel restrictions, one or more direct message identifiers associated with direct messages with which the user is associated, one or more board identifiers associated with boards with which the user is associated, one or more meetings with which the user is associated, a plurality of messages, a plurality of emojis, a plurality of conversations, a plurality of conversation topics, an avatar, an email address, a real name (e.g., John Doe), a username (e.g., j doe), a password, a role, a preference, a time zone, a status, and the like.</p><p id="p-0043" num="0042">In at least one example, the permission data <b>125</b> can store data associated with permissions of individual users of the communication platform. In some examples, permissions can be set automatically or by an administrator of the communication platform, an employer, enterprise, organization, or other entity that utilizes the communication platform, a team leader, a group leader, or other entity that utilizes the communication platform for communicating with team members, group members, or the like, an individual user, or the like. In some examples, permissions associated with an individual user can be mapped to, or otherwise associated with, a profile and/or account associated with the user data <b>124</b>. In some examples, permissions can indicate which users can communicate directly with other users, which channels a user is permitted to access, restrictions on individual channels, which workspaces the user is permitted to access, restrictions on individual workspaces, and the like. In at least one example, the permissions can support the communication platform by maintaining security for limiting access to a defined group of users. In some examples, such users can be defined by common access credentials, group identifiers, or the like, as described above.</p><p id="p-0044" num="0043">In some examples, the permission data <b>125</b> can store data associated with permissions of groups associated with the communication platform. In some examples, permissions can be set automatically or by an administrator of the communication platform, an employer, enterprise, organization, or other entity that utilizes the communication platform, a team leader, a group leader, or other entity that utilizes the communication platform for communicating with team members, group members, or the like, an individual user, or the like. In some examples, permissions associated with a group can be mapped to, or otherwise associated with, data associated with the group. In some examples, permissions can indicate restrictions on individual groups, restrictions on channel(s) associated with individual groups, restrictions on user(s) associated with individual groups, and the like. In at least one example, the permissions can support the communication platform by maintaining security for limiting access to a defined group of users. In some examples, such groups can be defined by common access credentials, group identifiers, or the like, as described above.</p><p id="p-0045" num="0044">In some examples, the permission data <b>125</b> can store data associated with permissions of individual channels. In some examples, permissions can be set automatically or by an administrator of the communication platform, an employer, enterprise, organization, or other entity that utilizes the communication platform, a team leader, a group leader, or other entity that utilizes the communication platform for communicating with team members, group members, or the like, an individual user, or the like. In some examples, permissions associated with a channel can be mapped to, or otherwise associated with, data associated with the channel in the channel data <b>126</b>. In some examples, permissions can indicate restrictions on individual channels, restrictions on user(s) associated with individual channels, and the like.</p><p id="p-0046" num="0045">In some examples, the permission data <b>125</b> can store data associated with permissions of individual messages or other objects. In some examples, permissions can be set automatically or by an administrator of the communication platform, an employer, enterprise, organization, or other entity that utilizes the communication platform, a team leader, a group leader, or other entity that utilizes the communication platform for communicating with team members, group members, or the like, an individual user (e.g., the originator of the message), or the like. In some examples, permissions associated with a message or other object can be mapped to, or otherwise associated with, data associated with the message or other object. In some examples, permissions can indicate viewing permissions, access permissions, editing permissions, etc.</p><p id="p-0047" num="0046">In at least one example, the channel data <b>126</b> can store data associated with individual channels. In at least one example, the channel management component <b>118</b> can establish a channel between and among various user computing devices, allowing the user computing devices to communicate and share data between and among each other. In at least one example, a channel identifier may be assigned to a channel, which indicates the physical address in the channel data <b>126</b> where data related to that channel is stored. Individual messages or other objects posted to a channel can be stored in association with the channel data <b>126</b>.</p><p id="p-0048" num="0047">In at least one example, the DM data <b>128</b> can store data associated with individual direct messages. In at least one example, the direct message management component <b>119</b> can establish a direct message between and among various user computing devices, allowing the user computing devices to communicate and share data between and among each other via the direct message. In at least one example, a direct message identifier may be assigned to a direct message, which indicates the physical address in the DM data <b>128</b> where data related to that direct message is stored. Individual messages or other objects posted to a direct message can be stored in association with the DM data <b>128</b>.</p><p id="p-0049" num="0048">In at least one example, content data <b>129</b> can comprise content posted to channels, direct messages, and/or other virtual spaces. Content data <b>129</b> can include text content, audio content, visual content (e.g., image content and/or video content), combinations of the foregoing, etc. In at least one example, content stored in the content data <b>129</b> can be associated with a creator identifier (e.g., a user who created the content), a thread identifier (e.g., which thread the content is associated with), a message identifier (e.g., which message the content is associated with), a virtual space identifier (e.g., virtual space(s) with which the content is associated with and/or accessible by), etc. Interactions associated with content can also be stored in association with the content in the content data <b>129</b>. That is, replies, reaction icons (e.g., emoji(s), reactji(s), etc.), etc. associated with individual content can be stored in association with the content. In some examples, content can be mapped to, or otherwise associated with, individual users, messages, meetings, channels, direct messages, and/or the like.</p><p id="p-0050" num="0049">In at least one example, the datastore <b>122</b> can store one or more reaction icon(s) <b>130</b> or indications thereof. In at least one example, a reaction icon can comprise an icon representative of an emotion or a reaction. Examples of reaction icons include emojis and/or reactjis. In some examples, each reaction icon can be associated with a name and/or definition such that when the name and/or definition of a particular reaction icon is identified in data associated with the communication platform, a component of the communication platform can retrieve instructions for presenting the reaction icon via a user interface. That is, the name and/or definition of the reaction icon can be used to unfurl the reaction icon in data presented via a user interface of the communication platform. In some examples, reaction icons can be named and/or defined by the communication platform (e.g., a programmer associated therewith). In some examples, reaction icons can be named and/or defined by a user of the communication platform. In some examples, the user can be a programmer for a group or organization.</p><p id="p-0051" num="0050">In some examples, interaction data associated with individual reaction icon(s) can be stored in association therewith. Such interaction data can indicate a count of the number of times a particular reaction icon has been used, which users have used the particular reaction icon, dates and/or times associated with the particular reaction icon was used, etc. In some examples, such interaction data can be used to determine a recency of interaction with a particular reaction icon (e.g., the most recent date and/or time the particular reaction icon was used by a user, a group of users, users of the communication platform), a frequency of interaction (e.g., how frequently a particular reaction is used by a user, a group of users, users of the communication platform), and/or the like, which can be stored in association with the reaction icon(s) <b>130</b> in the datastore <b>122</b>.</p><p id="p-0052" num="0051">The datastore <b>122</b> can store additional or alternative types of data, which can include, but is not limited to board data (e.g., data posted to or otherwise associated with boards of the communication platform), interaction data (e.g., data associated with additional or alternative interactions with the communication platform), model(s), etc.</p><p id="p-0053" num="0052">In some examples, the datastore <b>122</b> can be partitioned into discrete items of data that may be accessed and managed individually (e.g., data shards). Data shards can simplify many technical tasks, such as data retention, unfurling (e.g., detecting that message contents include a link, crawling the link's metadata, and determining a uniform summary of the metadata), and integration settings. In some examples, data shards can be associated with groups (e.g., organizations, workspaces), channels, direct messages, users, or the like.</p><p id="p-0054" num="0053">In some examples, individual groups can be associated with a database shard within the datastore <b>122</b> that stores data related to a particular group identification. For example, a database shard may store electronic communication data associated with members of a particular group, which enables members of that particular group to communicate and exchange data with other members of the same group in real time or near-real time. In this example, the group itself can be the owner of the database shard and has control over where and how the related data is stored and/or accessed. In some examples, a database shard can store data related to two or more groups (e.g., as in a shared channel, such as an externally shared channel).</p><p id="p-0055" num="0054">In some examples, a channel can be associated with a database shard within the datastore <b>122</b> that stores data related to a particular channel identification. For example, a database shard may store electronic communication data associated with the channel, which enables members of that particular channel to communicate and exchange data with other members of the same channel in real time or near-real time. In this example, a group or organization can be the owner of the database shard and can control where and how the related data is stored and/or accessed.</p><p id="p-0056" num="0055">In some examples, a direct message can be associated with a database shard within the datastore <b>122</b> that stores data related to a particular direct message identification. For example, a database shard may store electronic communication data associated with the direct message, which enables a user associated with a particular direct message to communicate and exchange data with other users associated with the same direct message in real time or near-real time. In this example, a group or organization can be the owner of the database shard and can control where and how the related data is stored and/or accessed.</p><p id="p-0057" num="0056">In some examples, individual users can be associated with a database shard within the datastore <b>122</b> that stores data related to a particular user account. For example, a database shard may store electronic communication data associated with an individual user, which enables the user to communicate and exchange data with other users of the communication platform in real time or near-real time. In some examples, the user itself can be the owner of the database shard and has control over where and how the related data is stored and/or accessed.</p><p id="p-0058" num="0057">The communication interface(s) <b>112</b> can include one or more interfaces and hardware components for enabling communication with various other devices (e.g., the user computing device <b>104</b>), such as over the network(s) <b>106</b> or directly. In some examples, the communication interface(s) <b>112</b> can facilitate communication via Web sockets, Application Programming Interfaces (APIs) (e.g., using API calls), Hyper Text Transfer Protocols (HTTPs), etc.</p><p id="p-0059" num="0058">The server(s) <b>102</b> can further be equipped with various input/output devices <b>114</b> (e.g., I/O devices). Such I/O devices <b>114</b> can include a display, various user interface controls (e.g., buttons, joystick, keyboard, mouse, touch screen, etc.), audio speakers, connection ports and so forth.</p><p id="p-0060" num="0059">In at least one example, the user computing device <b>104</b> can include one or more processors <b>132</b>, computer-readable media <b>134</b>, one or more communication interfaces <b>136</b>, and input/output devices <b>138</b>.</p><p id="p-0061" num="0060">In at least one example, each processor of the processor(s) <b>132</b> can be a single processing unit or multiple processing units, and can include single or multiple computing units or multiple processing cores. The processor(s) <b>132</b> can comprise any of the types of processors described above with reference to the processor(s) <b>108</b> and may be the same as or different than the processor(s) <b>108</b>.</p><p id="p-0062" num="0061">The computer-readable media <b>134</b> can comprise any of the types of computer-readable media <b>134</b> described above with reference to the computer-readable media <b>110</b> and may be the same as or different than the computer-readable media <b>110</b>. Functional components stored in the computer-readable media can optionally include at least one application <b>140</b> and an operating system <b>142</b>.</p><p id="p-0063" num="0062">In at least one example, the application <b>140</b> can be a mobile application, a web application, or a desktop application, which can be provided by the communication platform or which can be an otherwise dedicated application. In at least one example, the application <b>140</b> can be a native application associated with the communication platform. In some examples, individual user computing devices associated with the environment <b>100</b> can have an instance or versioned instance of the application <b>140</b>, which can be downloaded from an application store, accessible via the Internet, or otherwise executable by the processor(s) <b>132</b> to perform operations as described herein. That is, the application <b>140</b> can be an access point, enabling the user computing device <b>104</b> to interact with the server(s) <b>102</b> to access and/or use communication services available via the communication platform. In at least one example, the application <b>140</b> can facilitate the exchange of data between and among various other user computing devices, for example via the server(s) <b>102</b>. In at least one example, the application <b>140</b> can present user interfaces, as described herein. In at least one example, a user can interact with the user interfaces via touch input, keyboard input, mouse input, spoken input, or any other type of input. Additional or alternative access points, such as a web browser, can be used to enable the user computing device <b>104</b> to interact with the server(s) <b>102</b> as described herein. That is, in examples where the application <b>140</b> is described as performing an operation below, in an additional or alternative example, such an operation can be performed by another access point, such as a web browser or the like.</p><p id="p-0064" num="0063">In at least one example, the user computing device <b>104</b> can correspond to a &#x201c;client&#x201d; of a user. In some examples, the user computing device <b>104</b> can be associated with multiple &#x201c;clients,&#x201d; in which case, each instance of an application or other access point can be its own client. For example, a user can be signed into a first client (e.g., the application <b>140</b>) and a second client (e.g., a web browser), both of which can be associated with the user computing device <b>104</b>. In another example, the user can be signed into a first client (e.g., the application <b>140</b>) and a second client, each of which can be on separate user computing devices.</p><p id="p-0065" num="0064">As described above, a client, which can be associated with the user computing device <b>104</b>, can present one or more user interfaces. A non-limiting example of a user interface <b>144</b> is shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. As illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, the user interface <b>144</b> can present data associated with one or more channels, direct messages, or other virtual spaces. In some examples, the user interface <b>144</b> can include a first section <b>146</b> (e.g., which can be a portion, pane, or other partitioned unit of the user interface <b>144</b>), that includes user interface element(s) representing data associated with channel(s), direct message(s), etc. with which the user (e.g., account of the user) is associated. Additional details associated with the first section <b>146</b> and user interface element(s) are described below with reference to <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>.</p><p id="p-0066" num="0065">In at least one example, the user interface <b>144</b> can include a second section <b>148</b> (e.g., which can be a portion, pane, or other partitioned unit of the user interface <b>144</b>) that can be associated with a data feed indicating messages posted to and/or actions taken with respect to one or more channels, direct messages, and/or other virtual spaces for facilitating communications (e.g., a virtual space associated with event(s) and/or action(s), etc.) as described herein. In at least one example, data associated with the second section <b>148</b> can be associated with the same or different workspaces. That is, in some examples, the second section <b>148</b> can present data associated with the same or different workspaces via an integrated data feed. In some examples, the data can be organized and/or is sortable by date, time (e.g., when associated data is posted or an associated operation is otherwise performed), type of action and/or data, workspace, channel, user, topic, relevance metric, and/or the like. In some examples, such data can be associated with an indication of which user (e.g., member of the channel) posted the message and/or performed an action. In examples where the second section <b>148</b> presents data associated with multiple workspaces, at least some data can be associated with an indication of which workspace the data is associated with.</p><p id="p-0067" num="0066">In at least one example, the first section <b>146</b> and the second section <b>148</b>, in combination, can be associated with a &#x201c;group-based communication user interface&#x201d; from which a user can interact with the communication platform. Additional details associated with the user interface <b>144</b>, the first section <b>146</b>, and the second section <b>148</b>, are described below with reference to <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>.</p><p id="p-0068" num="0067">In at least one example, the user interface <b>144</b> can include a search mechanism <b>150</b> to enable a user to perform a search of content associated with the communication platform. As described above, content of the communication platform, can be searchable, for example by term (e.g., key word), reaction icon, user, date, virtual space, and/or the like. In at least one example, the search component <b>116</b> can provide an affordance (e.g., the search mechanism <b>150</b>) via the user interface <b>144</b> to enable a user to search content of the communication platform via one or more search parameters. Such an affordance can enable a user to designate the one or more search parameters, which can be term(s), reaction icon(s), user(s), date(s), virtual space(s), and/or the like. In response to receiving a search request associated with one or more search parameters, the search component <b>116</b> can perform a search of the datastore <b>122</b>. The datastore <b>122</b> can store content data <b>129</b>, as described above. Based at least in part on identifying one or more items of content that satisfy the search parameters, the search component <b>116</b> can return one or more search results, as described above.</p><p id="p-0069" num="0068">In at least one example, the search component <b>116</b> can determine set(s) of reaction icons to present via the user interface <b>144</b> to enable a user to search by reaction icon(s). In <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a first set of reaction icons <b>152</b> is presented, which is particular to the user. In at least one example, the first set of reaction icons <b>152</b> can be determined by the search component <b>116</b> based at least in part on frequency of interaction between the user and individual reaction icons, recency of interaction between the user and individual reaction icons, and/or the like. In at least one example, a second set of reaction icons <b>154</b> is presented, which is associated with other user(s). That is, in some examples, a first set of reaction icons can be particular to the user and one or more other sets of reaction icons can be associated with at least one other user. In some examples, the second set of reaction icons <b>154</b> can be associated with a group of users that are similar to the user (e.g., based at least in part on a similarity metric meeting or exceeding a threshold), a group of users with which the user shares a characteristic (e.g., same group identifier, same role, same permission(s), a same set of channels and/or direct messages with which each user is associated, etc.), etc. In some examples, the second set of reaction icons <b>154</b> can be associated with all users of the communication platform. In at least one example, the user interface <b>144</b> can include a user interface element <b>156</b>, which can provide an affordance to enable the user to view additional or alternative reaction icons. Any reaction icon&#x2014;whether selected from the first set of reaction icons <b>152</b>, the second set of reaction icons <b>154</b>, or additional or alternative reaction icons presented in response to an actuation of the user interface element <b>156</b>&#x2014;can be used as a search parameter. In some examples, combinations of reaction icons can be used as search parameters. As described above, in at least one example, upon receiving a search request associated with the reaction icon, the search component <b>116</b> can perform a search for content associated with the communication platform (e.g., as stored in the content data <b>129</b>) that is associated with the selected reaction icon. If content associated with the communication platform is identified, the search component <b>116</b> can return such content as a search result. Additional details are described below.</p><p id="p-0070" num="0069">In at least one example, the operating system <b>142</b> can manage the processor(s) <b>132</b>, computer-readable media <b>134</b>, hardware, software, etc. of the user computing device <b>104</b>.</p><p id="p-0071" num="0070">The communication interface(s) <b>136</b> can include one or more interfaces and hardware components for enabling communication with various other devices (e.g., the user computing device <b>104</b>), such as over the network(s) <b>106</b> or directly. In some examples, the communication interface(s) <b>136</b> can facilitate communication via Websockets, APIs (e.g., using API calls), HTTPs, etc.</p><p id="p-0072" num="0071">The user computing device <b>104</b> can further be equipped with various input/output devices <b>138</b> (e.g., I/O devices). Such I/O devices <b>138</b> can include a display, various user interface controls (e.g., buttons, joystick, keyboard, mouse, touch screen, etc.), audio speakers, microphones, cameras, connection ports and so forth.</p><p id="p-0073" num="0072">While techniques described herein are described as being performed by the search component <b>116</b>, the channel management component <b>118</b>, the direct message management component <b>119</b>, and the application <b>140</b>, techniques described herein can be performed by any other component, or combination of components, which can be associated with the server(s) <b>102</b>, the user computing device <b>104</b>, or a combination thereof.</p><p id="p-0074" num="0073"><figref idref="DRAWINGS">FIG. <b>2</b>A</figref> illustrates an example user interface <b>200</b> presented via a communication platform, as described herein. The user interface <b>200</b> can correspond to the user interface <b>144</b> described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>. As described above, in some examples, a user interface <b>200</b> presented via the communication platform can include a first section <b>202</b> (which can correspond to the first section <b>146</b> described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>) that includes user interface element(s) representing virtual space(s) associated with the workspace(s) with which the user (e.g., account of the user) is associated. In at least one example, the first section <b>202</b> can include one or more sub-sections, which can represent different virtual spaces. For example, a first sub-section <b>204</b> can include user interface elements representing virtual spaces that can aggregate data associated with a plurality of channels and/or workspaces. In at least one example, each virtual space can be associated with a user interface element in the first sub-section <b>204</b>. In some examples, a user interface element can be associated with an actuation mechanism, that when actuated, can cause the application <b>140</b> to present data associated with the corresponding virtual space via a second section <b>206</b> of the user interface <b>200</b> (which can correspond to the second section <b>148</b> described above with reference to <figref idref="DRAWINGS">FIG. <b>1</b></figref>).</p><p id="p-0075" num="0074">In at least one example, a virtual space can be associated with all unread data associated with each of the workspaces with which the user is associated. That is, in some examples, if the user requests to access the virtual space associated with &#x201c;unreads,&#x201d; all data that has not been read (e.g., viewed) by the user can be presented in the second section <b>206</b>, for example in a feed.</p><p id="p-0076" num="0075">In another example, &#x201c;drafts&#x201d; can be associated with messages or other objects that have not yet been posted to a virtual space or otherwise sent to a receiving entity. In at least one example, a message, while being composed, can be associated with an indicator indicating that the message is a draft and can therefore be associated with the &#x201c;drafts&#x201d; referenced in the second sub-section <b>208</b>.</p><p id="p-0077" num="0076">In another example, &#x201c;threads&#x201d; can be associated with messages, files, etc. posted in threads to messages posted in a channel and/or a virtual space associated with &#x201c;mentions and reactions&#x201d; (e.g., &#x201c;M &#x26; R&#x201d;) can be associated with messages or threads where the user (e.g., User F) has been mentioned (e.g., via a tag) or another user has reacted (e.g., via an emoji, reaction, or the like) to a message or thread posted by the user.</p><p id="p-0078" num="0077">In some examples, if the first sub-section <b>204</b> includes a user interface element representative of a virtual space associated with &#x201c;snippets of content&#x201d; (e.g., stories) that is actuated by a user, snippets of content associated with the user, which can be associated with different channels and/or virtual spaces, can be presented via the second section <b>206</b>. In some examples, such snippets of content can be presented via a feed. For the purpose of this discussion, a snippet of content can correspond to audio and/or visual content provided by a user associated with the communication platform.</p><p id="p-0079" num="0078">In another example, a virtual space can be associated with &#x201c;boards&#x201d; with which the user is associated. In at least one example, if the user requests to access the virtual space associated with &#x201c;boards,&#x201d; one or more boards with which the user is associated can be presented via the user interface <b>200</b> (e.g., in the second section <b>206</b>). In at least one example, boards, as described herein, can be associated with individual groups and/or communication channels to enable users of the communication platform to create, interact with, and/or view data associated with such boards. That is, a board, which can be an &#x201c;electronic board,&#x201d; can be a virtual space, canvas, page, or the like for collaborative communication and/or organization within the communication platform. In at least one example, a board can support editable text and/or objects that can be ordered, added, deleted, modified, and/or the like. In some examples, a board can be associated with permissions defining which users of a communication platform can view and/or edit the board. In some examples, a board can be associated with a communication channel and at least some members of the communication channel can view and/or edit the board. In some examples, a board can be sharable such that data associated with the board is accessible to and/or interactable for members of the multiple communication channels, workspaces, organizations, and/or the like.</p><p id="p-0080" num="0079">In at least one example, a board can include section(s) and/or object(s). In some examples, each section can include one or more objects. In at least one example, an object can be associated with an object type, which can include, but is not limited to, text (e.g., which can be editable), a task, an event, an image, a graphic, a link to a local object, a link to a remote object, a file, and/or the like. In some examples, the sections and/or objects can be reordered and/or otherwise rearranged, new sections and/or objects can be added or removed, and/or data associated with such sections and/or objects can be edited and/or modified. That is, boards can be created and/or modified for various uses. That is, users can customize and/or personalize boards to serve individual needs as described herein. As an example, sections and/or objects can be arranged to create a project board that can be used to generate and/or assign tasks, track progress, and/or otherwise manage a project. Further, in some examples, boards can present company metrics and also enable access to company goals so that such data can be stored and/or accessed via a single location. In some examples, boards can be used to keep track of work progress and/or career growth, which can be used by managers or supervisors for managing and/or supervising employees, agents, and/or other workers. In at least one example, a board can be used to track incidents, incoming customer service requests, and/or the like. Additional details associated with boards are provided in U.S. patent application Ser. No. 16/993,859, filed on Aug. 14, 2020, the entire contents of which are incorporated by reference herein.</p><p id="p-0081" num="0080">In some examples, data presented via the second section can be organized and/or is sortable by date, time (e.g., when associated data is posted or an associated operation is otherwise performed), type of action and/or data, workspace, channel, user, topic, relevance metric, and/or the like. In some examples, such data can be associated with an indication of which user(s) (e.g., member(s) of a channel) posted a message, performed an action, and/or the like. Additional details are described below.</p><p id="p-0082" num="0081">In at least one example, the first section <b>202</b> of the user interface <b>200</b> can include a second sub-section <b>208</b> that includes user interface elements representing channels to which the user (i.e., user profile) has access. In some examples, the channels can include public channels, private channels, shared channels (e.g., between workspaces or organizations), single workspace channels, cross-workspace channels, announcement channels, combinations of the foregoing, or the like. In some examples, the channels represented can be associated with a single workspace. In some examples, the channels represented can be associated with different workspaces (e.g., cross-workspace). In some examples, the channels represented can be associated with combinations of channels associated with a single workspace and channels associated with different workspaces.</p><p id="p-0083" num="0082">In some examples, the second sub-section <b>208</b> can depict all channels, or a subset of all channels, that the user has permission to access (e.g., as determined by the permission data <b>125</b>). In such examples, the channels can be arranged alphabetically, based on most recent interaction, based on frequency of interactions, based on channel type (e.g., public, private, shared, cross-workspace, announcement, etc.), based on workspace, in user-designated sections, or the like. In some examples, the second sub-section <b>208</b> can depict all channels, or a subset of all channels, that the user is a member of, and the user can interact with the user interface <b>200</b> to browse or view other channels that the user is not a member of but are not currently displayed in the second sub-section <b>208</b>. In some examples, a new channel, generated subsequent to a request received at the channel management component <b>118</b> in <figref idref="DRAWINGS">FIG. <b>1</b></figref> and accessible to the user, can be added to the second sub-section <b>208</b>. The new channel can be generated by the user or added to the second sub-section <b>208</b> in reply to acceptance of an invite sent to the user to join a new channel. In some examples, different types of channels (e.g., public, private, shared, etc.) can be in different sections of the second sub-section <b>208</b>, or can have their own sub-sections or subsections in the user interface <b>200</b>. In some examples, channels associated with different workspaces can be in different portions of the second sub-section <b>208</b>, or can have their own sections or subsections in the user interface <b>200</b>.</p><p id="p-0084" num="0083">In some examples, the indicators can be associated with user interface elements that visually differentiate types of channels. For example, Channel B is associated with a double square user interface element instead of a circle user interface element. As a non-limiting example, and for the purpose of this discussion, the double square user interface element can indicate that the associated channel (e.g., Channel B) is an externally shared channel. In some examples, such a user interface element can be the same for all externally shared channels. In other examples, such a user interface element can be specific to the other group with which the externally shared channel is associated. In some examples, additional or alternative graphical elements can be used to differentiate between public channels, private channels, shared channels, channels associated with different workspaces, and the like. In other examples, channels that the user is not a current member of may not be displayed in the second sub-section <b>208</b> of the user interface <b>200</b>. In such examples, the user may navigate to a different interface (not shown) to browse additional channels that are accessible to the user but to which the user is not currently a member.</p><p id="p-0085" num="0084">In addition to the second sub-section <b>208</b>, the first section <b>202</b> can include a third subsection <b>210</b> that can include user interface elements representative of direct messages. That is, the third subsection <b>210</b> can include user interface elements representative of virtual spaces that are associated with private messages between one or more users, as described above.</p><p id="p-0086" num="0085">As described above, in at least one example, the user interface <b>200</b> can include a second section <b>206</b> that can be associated with data associated with virtual spaces of the communication platform. In some examples, data presented via the second section <b>206</b> can be presented as a feed indicating messages posted to and/or actions taken with respect to a channel and/or other virtual space (e.g., a virtual space associated with direct message communication(s), a virtual space associated with event(s) and/or action(s), etc.) for facilitating communications. As described above, in at least one example, data associated with the second section <b>206</b> can be associated with the same or different workspaces. That is, in some examples, the second section <b>206</b> can present data associated with the same or different workspaces via an integrated feed. In some examples, the data can be organized and/or is sortable by date, time (e.g., when associated data is posted or an associated operation is otherwise performed), type of action and/or data, workspace, channel, user, topic, relevance metric, and/or the like. In some examples, such data can be associated with an indication of which user(s) and/or entity(s) posted the message and/or performed an action.</p><p id="p-0087" num="0086">A channel, direct message, or other virtual space can be associated with data and/or content other than messages, or data and/or content that is associated with messages. For example, non-limiting examples of additional data and/or content that can be presented via the second section <b>206</b> of the user interface <b>144</b> include members added to and/or removed from the channel, file(s) (e.g., file attachment(s)) uploaded and/or removed from the channel, application(s) added to and/or removed from the channel, post(s) (data that can be edited collaboratively, in near real-time by one or members of a channel) added to and/or removed from the channel, description added to, modified, and/or removed from the channel, modifications of properties of the channel, etc.</p><p id="p-0088" num="0087">In some examples, the second section <b>206</b> can comprise a feed associated with a single channel. In such examples, data associated with the channel can be presented via the feed. In at least one example, data associated with a channel can be viewable to at least some of the users of a group of users associated with a same group identifier. In some examples, for members of a channel, the content of the channel (e.g., messaging communications and/or objects) can be displayed to each member of the channel. For instance, a common set of group-based messaging communications can be displayed to each member of the channel such that the content of the channel (e.g., messaging communications and/or objects) may not vary per member of the channel. In some examples, messaging communications associated with a channel can appear differently for different users (e.g., based on personal configurations, group membership, permissions, policies, etc.).</p><p id="p-0089" num="0088">In at least one example, the format of the individual channels or virtual spaces may appear differently to different users. In some examples, the format of the individual channels or virtual spaces may appear differently based on which workspace or organization a user is currently interacting with or most recently interacted with. In some examples, the format of the individual channels or virtual spaces may appear differently for different users (e.g., based on personal configurations, group membership, permission(s), etc.).</p><p id="p-0090" num="0089">In at least one example, the user interface <b>200</b> can include a search mechanism <b>212</b>, wherein a user can input a search term and the server(s) <b>102</b> can perform a search associated with the communication platform. The search mechanism <b>212</b> can correspond to the search mechanism <b>150</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In some examples, the search can be performed across each group with which the user is associated, or the search can be restricted to a particular group, based on a user specification. The search may be performed with one or more shards associated with each group across which the search is performed. As described above, a search can be associated with one or more search parameters, which can be used by the search component <b>116</b> to determine whether content stored in the content data <b>129</b> is associated with the search parameter(s). In some examples, a search parameter can be associated with a reaction icon, as described above. In at least one example, the application <b>140</b> can detect an interaction with the search mechanism <b>212</b>. In at least one example, the application <b>140</b> can send an indication of the interaction to the server(s) <b>102</b>. The search mechanism <b>116</b> can cause a search user interface to be presented via the user interface <b>200</b>, as illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>.</p><p id="p-0091" num="0090">In <figref idref="DRAWINGS">FIG. <b>2</b>A</figref>, the user can interact with the user interface element that corresponds to Channel D in the second sub-section <b>208</b> and as such, a feed associated with the channel can be presented via the second section <b>206</b> of the user interface. In some examples, the second section <b>206</b> can be associated with a header that includes user interface elements <b>214</b> representing data associated with Channel D. Furthermore, the second section <b>206</b> can include user interface elements <b>216</b>, <b>218</b>, <b>219</b>, <b>220</b>, <b>221</b>, and <b>222</b> which each represent messages posted to the channel (e.g., by a user and/or an application). As illustrated, the user interface elements representative of the messages <b>216</b>-<b>222</b> can include an indication of user(s) and/or entity(s) that posted the message, a time when the message was posted, content associated with the message, reactions associated with the message (e.g., emojis, reactjis, etc.), and/or the like. In at least one example, the second section <b>206</b> can include an input mechanism <b>222</b>, which can be associated with a composition user interface to enable a user to compose a message to be posted to the channel. That is, in at least one example, a user can provide input via the input mechanism <b>222</b> (e.g., type, speak, etc.) to generate a new message. In some examples, messages can be generated by applications and/or automatically by the communication platform. In some examples, the second section <b>206</b> can include user interface elements representative of other objects and/or data associated with the channel (or other virtual space).</p><p id="p-0092" num="0091"><figref idref="DRAWINGS">FIG. <b>2</b>B</figref> illustrates an example of the user interface <b>200</b>, wherein a search user interface <b>224</b> is presented to enable a user to designate search parameters associated with a search. As described above, content of the communication platform, can be searchable, for example by term (e.g., key word), reaction icon, user, date, virtual space, and/or the like. In at least one example, the search user interface <b>224</b> can include one or more mechanisms to enable a user to designate the one or more search parameters, which can be term(s), reaction icon(s), user(s), date(s), virtual space(s), and/or the like. In some examples, the user can input a search parameter in the search mechanism <b>212</b>, for example via a text input, image input, speech input, or the like. As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, the search user interface <b>224</b> can include one or more user interface elements <b>226</b> to enable the user to navigate to different types of search parameters (e.g., term(s) (e.g., key word(s)), reaction icon(s), user(s), date(s), virtual space(s), etc.). As described above, in response to receiving a search request associated with one or more search parameters, the search component <b>116</b> can perform a search of the datastore <b>122</b> for content associated with the one or more search parameters. The datastore <b>122</b> can store content data <b>129</b>, as described above. Based at least in part on identifying one or more items of content (e.g., in the content data <b>129</b>) that satisfy the search parameters, the search component <b>116</b> can return one or more search results, as described above.</p><p id="p-0093" num="0092">As described above, the search component <b>116</b> can determine set(s) of reaction icons to present via the user interface <b>200</b> to enable a user to search by reaction icon(s). In <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, a first set of reaction icons <b>228</b>, which can correspond to the first set of reaction icons <b>152</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, is presented, which is particular to the user. In at least one example, the first set of reaction icons <b>228</b> can be determined by the search component <b>116</b> based at least in part on frequency of interaction between the user and individual reaction icons, recency of interaction between the user and individual reaction icons, and/or the like. In at least one example, a second set of reaction icons <b>230</b>, which can correspond to the second set of reaction icons <b>154</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>, is presented, which is associated with other user(s). That is, in some examples, a first set of reaction icons can be particular to the user and one or more other sets of reaction icons can be associated with at least one other user.</p><p id="p-0094" num="0093">In some examples, the second set of reaction icons <b>230</b> can be associated with a group of users that are similar to the user (e.g., based at least in part on a similarity metric meeting or exceeding a threshold), a group of users with which the user shares a characteristic (e.g., same group identifier, same role, same permission(s), a same set of channels and/or direct messages with which each user is associated, etc.), etc. In some examples, the second set of reaction icons <b>230</b> can be associated with all users of the communication platform. In at least one example, the user interface <b>200</b> can include an affordance, which can be associated with a user interface element <b>232</b>, to enable the user to view additional or alternative reaction icons. Interaction with the user interface element <b>232</b> can cause additional or alternative reaction icons to be presented via the user interface <b>200</b>. In some examples, the additional or alternative reaction icons can be arranged based on relevance to the requesting user, alphabetically, based on topic, and/or the like. Any reaction icon&#x2014;whether selected from the first set of reaction icons <b>228</b>, the second set of reaction icons <b>230</b>, or additional or alternative reaction icons presented in response to an actuation of the user interface element <b>232</b>&#x2014;can be used as a search parameter. In some examples, combinations of reaction icons can be used as search parameters.</p><p id="p-0095" num="0094">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>, in at least one example, each of the reaction icons can be associated with an actuation mechanism such that interaction with a particular reaction icon can indicate that the reaction icon has been selected. That is, the application <b>140</b> can detect an input associated with a reaction icon and can associate the selected reaction icon with a search query as a search parameter. The application <b>140</b> can send the search query to the server(s) <b>102</b> to initiate a search. As described above, in at least one example, upon receiving a search query associated with the reaction icon, the search component <b>116</b> can perform a search for content associated with the communication platform (e.g., as stored in the content data <b>129</b>) that is associated with the selected reaction icon. If content associated with the communication platform is identified, the search component <b>116</b> can return such content as a search result.</p><p id="p-0096" num="0095"><figref idref="DRAWINGS">FIG. <b>2</b>C</figref> illustrates another example of the user interface <b>200</b>, wherein a search user interface <b>224</b> is presented. In <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>, the search user interface <b>224</b> includes a first set of reaction icons <b>228</b> and a second set of reaction icons <b>230</b>, as presented and described above with reference to <figref idref="DRAWINGS">FIG. <b>2</b>B</figref>. However, in <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>, each reaction icon is associated with a selectable user interface element to enable the user to indicate which reaction icon to include as a search parameter. In <figref idref="DRAWINGS">FIG. <b>2</b>C</figref>, each of the sets of reaction icons are associated with user interface elements <b>232</b>(A) and <b>232</b>(B) to enable the user to view additional or alternative reaction icons. In some examples, the additional or alternative reaction icons that are presented and/or the order in which the additional or alternative reaction icons are presented can be different depending on which user interface element <b>232</b>(A) or <b>232</b>(B) is selected by the user.</p><p id="p-0097" num="0096"><figref idref="DRAWINGS">FIG. <b>2</b>D</figref> illustrates an example of the user interface <b>200</b> wherein one or more search results are presented via the user interface <b>200</b>. In at least one example, selected reaction icon(s) can be used as search parameter(s). In <figref idref="DRAWINGS">FIG. <b>2</b>D</figref>, the selected reaction icon is a heart. The application <b>140</b> can send a search query associated with a search parameter that corresponds to the selected reaction icon (e.g., the heart) to the server(s) <b>102</b>. The search component <b>116</b> can perform a search of the content data <b>129</b> to determine whether any content items are associated with the selected reaction icon (e.g., the heart). Based at least in part on the search component <b>116</b> identifying one or more content items associated with the selected reaction icon (e.g., the heart), the search component <b>116</b> can send the one or more content items to the application <b>140</b> for presentation via the user interface <b>200</b>. In at least one example, such content items can comprise messages or other actions associated with virtual spaces of the communication platform. The user interface <b>200</b> can be associated with user interface elements <b>234</b>, <b>236</b>, and <b>238</b> that are representative of each of the content items associated with the selected reaction icon. In at least one example, each of the user interface elements <b>234</b>, <b>236</b>, and <b>238</b> can be associated with an actuation mechanism that when actuated causes the corresponding message to be presented, in context (e.g., in the channel, direct message, etc.), via the user interface <b>200</b>.</p><p id="p-0098" num="0097"><figref idref="DRAWINGS">FIGS. <b>1</b>-<b>2</b>D</figref> make reference to &#x201c;user interface elements.&#x201d; A user interface element can be any element of the user interface that is representative of an object, message object, virtual space, and/or the like. A user interface element can be a text element, a graphical element, a picture, a logo, a symbol, and/or the like. In some examples, a user interface element can be presented as a pop-up, overlay, new sections of the user interface <b>200</b>, a new user interface, part of another user interface element, and/or the like. In at least one example, individual of the user interface elements can be associated with actuation mechanisms. Such actuation mechanisms can make the corresponding user interface elements selectable or otherwise interactable. That is, actuation of an actuation mechanism as described herein can, in some examples, indicate a selection of a corresponding user interface element. In at least one example, the application <b>140</b> can receive an indication of an interaction with a user interface element (e.g., indication of a selection and/or actuation of an actuation mechanism) and can send an indication of such to the server(s) <b>102</b>. In some examples, the server(s) <b>102</b> can send data and/or instructions to the application <b>140</b> to generate new user interfaces and/or update the user interface <b>200</b>, as described herein.</p><p id="p-0099" num="0098">The example user interfaces and user interface elements described above are provided for illustrative purposes. In some examples, such user interfaces and user interface elements can include additional or alternative data, which can be presented in additional or alternative configurations. That is, the user interfaces and user interface elements should not be construed as limiting.</p><p id="p-0100" num="0099"><figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> are flowcharts showing example processes involving techniques as described herein. The processes illustrated in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> are described with reference to components of the environment <b>100</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref> for convenience and ease of understanding. However, the processes illustrated in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> are not limited to being performed using the components described above with reference to the environment <b>100</b>. Moreover, the components described above with reference to the environment <b>100</b> are not limited to performing the processes illustrated in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref>.</p><p id="p-0101" num="0100">The processes in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> are illustrated as collections of blocks in logical flowcharts, which represent sequences of operations that can be implemented in hardware, software, or a combination thereof. In the context of software, the blocks represent computer-executable instructions stored on one or more computer-readable storage media that, when executed by processor(s), perform the recited operations. Generally, computer-executable instructions include routines, programs, objects, components, message objects, and the like that perform particular functions or implement particular abstract data types. The order in which the operations are described is not intended to be construed as a limitation, and any number of the described blocks can be combined in any order and/or in parallel to implement the processes. In some embodiments, one or more blocks of the process can be omitted entirely. Moreover, the processes in <figref idref="DRAWINGS">FIGS. <b>3</b> and <b>4</b></figref> can be combined in whole or in part with each other or with other processes.</p><p id="p-0102" num="0101"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an example process <b>300</b> for determining a set of reaction icons that are selectable via a user interface to initiate a search of content exchanged via a communication platform, as described herein.</p><p id="p-0103" num="0102">At operation <b>302</b>, the server(s) <b>102</b> can receive content exchanged via a communication platform, wherein the content is associated with interaction data. As described above, users associated with the communication platform can exchange data via one or more virtual spaces, such as channels (e.g., managed by the channel management component <b>118</b>), direct messages (e.g., managed by the direct message management component <b>119</b>), and/or other virtual spaces. In some examples, such data can comprise &#x201c;content,&#x201d; which can be associated with messages. As described above, a &#x201c;message,&#x201d; as used herein, can refer to any electronically generated digital object provided by a user of the communication platform. A message can be configured for presentation within a channel, a direct message, and/or another virtual space as described herein. In at least one example, a message can be associated with message content, which can include text data, image data, video data, audio data, file(s), etc. In some examples, one or more users of the communication platform can interact with a message, for example, by associating a reaction icon (e.g., an emoji, a reactji, or the like) with the message. In some examples, one or more users of the communication platform can interact with a message by replying to the message. In some examples, a reply can be posted to a feed associated with a channel, direct message, or other virtual space. In other examples, a reply can comprise a new message in a &#x201c;thread.&#x201d; A thread can be a message associated with another message that is not posted to a channel, direct message, or other virtual space, but instead is maintained within an object associated with the original message. Messages and associated reactions (e.g., reaction icon(s) and/or reply(s)) can be stored in a datastore of the communication platform as &#x201c;content&#x201d; of the communication platform.</p><p id="p-0104" num="0103">In at least one example, the content can be associated with interaction data, which can indicate whether a user interacted with a content item, for example, via associating a reaction icon therewith, sending a reply, and/or the like. In some examples, the search component <b>116</b> can determine metrics based at least in part on interaction data associated with the content. Such metrics can indicate frequency of interaction with individual reaction icons, recency of interaction with individual reaction icons, a number of interactions with individual reaction icons, and/or the like. As described above, &#x201c;frequency of interaction&#x201d; can refer to a rate at which a user or group of users interacts with a reaction icon within a period of time. Further, &#x201c;recency of interaction&#x201d; can refer to an interaction occurring within a period of time comparatively close to a present time.</p><p id="p-0105" num="0104">At operation <b>304</b>, the server(s) <b>102</b> can store the content in a database associated with the communication platform. In at least one example, the database can comprise the content data <b>129</b>, which can be associated with the datastore <b>122</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref>. In at least one example, content data <b>129</b> can comprise content posted to channels, direct messages, meetings, etc. Content data <b>129</b> can include text content, audio content, visual content (e.g., image content and/or video content), combinations of the foregoing, etc. In at least one example, content stored in the content data <b>129</b> can be associated with a creator identifier (e.g., a user who created the content), a thread identifier (e.g., which thread the content is associated with), a message identifier (e.g., which message the content is associated with), a virtual space identifier (e.g., virtual space(s) with which the content is associated with and/or accessible by), etc. Interactions associated with content can also be stored in association with the content in the content data <b>129</b>. That is, interaction data indicating replies, reaction icons (e.g., emoji(s), reactji(s), etc.), etc. associated with individual content can be stored in association with the content. In some examples, content can be mapped to, or otherwise associated with, individual users, messages, meetings, channels, direct messages, and/or the like.</p><p id="p-0106" num="0105">At operation <b>306</b>, the search component <b>116</b> can determine a set of reaction icons based at least in part on the interaction data. In at least one example, the search component <b>116</b> can determine set(s) of reaction icons to present via a user interface to enable a user to search by reaction icon(s). As described above, a set of reaction icons can comprise one or more reaction icons. Further, as described above, a set of reaction icons can include one or more emojis, reactjis, or the like. Set(s) of reaction icons can be determined based at least in part on interaction data, from which frequency of interaction with individual reaction icons, recency of interaction with individual reaction icons, a number of times a particular reaction icon has been interacted with (e.g., a count), and/or the like can be determined. In at least one example, the search component <b>116</b> can access the reaction icon(s) <b>130</b> in the datastore <b>122</b>. As described above, the reaction icon(s) <b>130</b> can be associated with interaction data and/or metrics determined therefrom, which can be used by the search component <b>116</b> to determine set(s) of reaction icons.</p><p id="p-0107" num="0106">In some examples, a set of reactions icons can be particular to a user, a group of users, or the communication platform, generally. That is, in at least one example, a set of reaction icons can be determined based at least in part on interaction data associated with a user and thus can be particular to the user. In such an example, the set of reaction icons can include one or more reaction icons that the user most frequently interacts with, most recently interacted with, has interacted with the highest number of times, etc. In some examples, such metrics (e.g., frequency, recency, count, etc.) can be used to determine a relevance metric. The search component <b>116</b> can rank reaction icons based at least in part on relevance metrics and can associate one or more reaction icons with the set based at least in part on the ranking. In some examples, the relevance metric can be determined using a machine-trained model. Such a machine-trained model can be trained using a machine learning mechanism (e.g., supervised, unsupervised, semi-supervised, deep, etc.) on training data which can include reaction icons, interaction data, and search queries associated with selected reaction icons. The machine-trained model can receive new interaction data and can output relevance metrics associated with reaction icons, which can be used for generating a set of reaction icons, as described above.</p><p id="p-0108" num="0107">In some examples, a set of reaction icons can be determined based at least in part on interaction data associated with a group of users. In such examples, the set of reaction icons can be particular to the group of users. In some examples, the group of users can be associated with a same group identifier (and thus the same workspace and/or organization) as the user, share one or more characteristics with the user (e.g., same role, same geographic area, same age, same preference, etc.), a similarity metric that satisfies a threshold, and/or the like. In at least one example, the set of reaction icons can include one or more reaction icons that users associated with the group of users most frequently interact with, most recently interacted with, have interacted with the highest number of times, etc. In some examples, such metrics (e.g., frequency, recency, count, etc.) can be used to determine a relevance metric. The search component <b>116</b> can rank reaction icons based at least in part on relevance metrics and can associate one or more reaction icons with the set based at least in part on the ranking.</p><p id="p-0109" num="0108">In some examples, a set of reaction icons can be determined based at least in part on interaction data associated with the communication platform, and thus can be representative of all users of the communication platform. In such examples, the set of reaction icons can include one or more reaction icons that users associated with the communication platform most frequently interact with, most recently interacted with, have interacted with the highest number of times, etc. In some examples, such metrics (e.g., frequency, recency, count, etc.) can be used to determine a relevance metric. The search component <b>116</b> can rank reaction icons based at least in part on relevance metrics and can associate one or more reaction icons with the set based at least in part on the ranking.</p><p id="p-0110" num="0109">At operation <b>308</b>, the search component <b>116</b> can cause presentation of at least the set of reaction icons via a user interface of the communication platform. In at least one example, the search component <b>116</b> can cause presentation of at least one set of reaction icons via a user interface of the communication platform. In at least one example, the set(s) of reaction icons can be presented in association with a search user interface that can be presented in response to an interaction with a search mechanism presented via the user interface. An example of such a search user interface is provided above with reference to <figref idref="DRAWINGS">FIGS. <b>2</b>B and <b>2</b>C</figref>.</p><p id="p-0111" num="0110">At operation <b>310</b>, the search component <b>116</b> can determine whether a selection of at least one reaction icon is received. In at least one example, each of the reaction icons associated with the set of reaction icons can be associated with an actuation mechanism or other selection mechanism such that interaction with the actuation mechanism or other selection mechanism can indicate that a particular reaction icon has been selected. That is, in at least one example, the application <b>140</b> can detect an input associated with a reaction icon and can associate the selected reaction icon with a search query as a search parameter. The application <b>140</b> can send the search query to the server(s) <b>102</b> to initiate a search. In at least one example, the search component <b>116</b> can determine that a selection of at least one reaction icon is received based at least in part on receiving the search query associated with the selected reaction icon(s). In at least one example, the selected reaction icon(s) can comprise search parameter(s) for conducting the search.</p><p id="p-0112" num="0111">If a selection is not received, the search component <b>116</b> can wait until a selection is received, as illustrated by the arrow returning to operation <b>310</b>. In some examples, a selection may not be received within a period of time and/or before the user navigates away from the search user interface. In some examples, if a selection is not received, and a period of time has lapsed and/or the user navigates away from the search user interface, the process <b>300</b> can return to operation <b>302</b>, as illustrated by the dashed arrow returning to operation <b>302</b>.</p><p id="p-0113" num="0112">At operation <b>312</b>, based at least in part on a selection of at least one reaction icon being received (i.e., &#x201c;yes&#x201d; at operation <b>312</b>), the search component <b>116</b> can initiate a search based at least in part on the selected reaction icon(s), wherein the selected reaction icon(s) are search parameter(s) for the search.</p><p id="p-0114" num="0113">At operation <b>314</b>, the search component <b>116</b> can determine whether content associated with the selected reaction icon(s) are stored in the database. In at least one example, selected reaction icon(s) can be used as search parameter(s). The application <b>140</b> can send a search query associated with a search parameter that corresponds to the selected reaction icon to the server(s) <b>102</b>. The search component <b>116</b> can perform a search of the content data <b>129</b> to determine whether any content items are associated with the selected reaction icon(s). That is, the search component <b>116</b> can analyze content stored in the content data <b>129</b> to determine whether any of the content is associated with the selected reaction icon(s). In some examples, the selected reaction icon can be associated with message content, a reaction, a reply, and/or the like.</p><p id="p-0115" num="0114">At operation <b>316</b>, based at least in part on determining that content associated with the selected reaction icon(s) is stored in the database (i.e., &#x201c;yes&#x201d; at operation <b>314</b>), the search component <b>116</b> can return a search result based at least in part on the identified content that is associated with the selection reaction icon(s). Based at least in part on the search component <b>116</b> identifying one or more content items associated with the selected reaction icon, the search component <b>116</b> can send the one or more content items to the application <b>140</b> for presentation via a user interface of the communication platform. In at least one example, such content items can comprise messages or other actions associated with virtual spaces of the communication platform. In at least one example, the user interface can include one or more user interface elements representative of each of the search results. In at least one example, each user interface element can be associated with an actuation mechanism that when actuated causes the corresponding content item to be presented, in context (e.g., in the channel, direct message, etc.), via the user interface. An example of a user interface presenting search results associated with selected reaction icon(s) is illustrated above with reference to <figref idref="DRAWINGS">FIG. <b>2</b>D</figref>.</p><p id="p-0116" num="0115">At operation <b>318</b>, based at least in part on determining that there isn't content associated with the selected reaction icon(s) stored in the database (i.e., &#x201c;no&#x201d; at operation <b>314</b>), the search component <b>116</b> can return an indication that no content is associated with the selected reaction icon(s).</p><p id="p-0117" num="0116"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an example process <b>400</b> for determining a set of reaction icons based at least in part on interaction data associated with content exchanged via a communication platform, as described herein.</p><p id="p-0118" num="0117">At operation <b>402</b>, the server(s) <b>102</b> can receive content exchanged via a communication platform, wherein the content is associated with interaction data, as described above with reference to operation <b>302</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0119" num="0118">At operation <b>404</b>, the search component <b>116</b> can determine a frequency of interaction with individual reaction icons associated with the communication platform. In at least one example, a &#x201c;frequency of interaction&#x201d; can refer to a rate at which a user or group of users interacts with a reaction icon within a period of time. In at least one example, the search component <b>116</b> can analyze interaction data to determine a rate at which a user or group of users interacts with individual reaction icons. In some examples, such a metric (e.g., frequency of interaction) can be associated with individual reaction icons.</p><p id="p-0120" num="0119">At operation <b>406</b>, the search component <b>116</b> can determine a recency of interaction with individual reaction icons associated with the communication platform. In at least one example, a &#x201c;recency of interaction&#x201d; can refer to an interaction occurring within a period of time comparatively close to a present time. In at least one example, the search component <b>116</b> can analyze interaction data to determine timing associated with interactions with individual reaction icons and can determine recency based on such timing. In some examples, such a metric (e.g., recency of interaction) can be associated with individual reaction icons.</p><p id="p-0121" num="0120">At operation <b>408</b>, the search component <b>116</b> can determine a set of reaction icons based at least in part on at least one of the frequency of interaction or the recency of interaction with the individual reaction icons. Additional details associated with determining set(s) of reaction icons are described above with reference to operation <b>306</b> of <figref idref="DRAWINGS">FIG. <b>3</b></figref>.</p><p id="p-0122" num="0121">Techniques described herein, with reference to <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>4</b></figref>, can be helpful for easily retrieving content associated with the communication platform. As described above, in an example, a user can desire to recall a message posted to a channel where other users reacted with a particular reaction icon (e.g., a dancing chicken reactji). In existing techniques a user can search via a term, a user, a date, a virtual space, or the like, but the user may not recall a term, user, date, virtual space, or the like associated with the message. The user may recall how people reacted (e.g., using a dancing chicken reactji). In some existing techniques, if a user knows how a particular reaction icon is named or defined, the user could input the name or definition of the particular reaction icon (e.g., :dancing chicken:) into the search affordance. However, if a user does not know how a particular reaction icon is named or defined, the user may be left without a mechanism to retrieve the content. As such, techniques described herein offer an improvement to existing search technology.</p><p id="p-0123" num="0122">As described above, techniques described herein utilize interaction data associated with content exchanged via the communication platform to determine set(s) of reaction icons that are relevant to a particular user. As described above, at least one set of reaction icons can be determined based at least in part on frequency and/or recency of interaction with particular reaction icons, for example, by the user or a group of users with which the user may be similar to or otherwise related. As such, the communication platform can cause set(s) of reaction icons to be presented via a user interface, that are in some examples relevant or otherwise personalized for a user, to enable the user to select or otherwise set search parameters for a search.</p><p id="p-0124" num="0123">Techniques described herein offer improvements over existing search technologies by improving user interfaces used to facilitate searches, reducing the number of interactions required to retrieve content, and/or streamlining user interaction with user interfaces. That is, by presenting an affordance for a user to designate search parameters via an interaction with set(s) of reaction icons, techniques described herein provide a more user-friendly mechanism to initiate a search. As described herein, the set(s) of reaction icons can be determined to be relevant to a particular user and thus can narrow, at least initially, the search parameters presented for the user for selection. Further, by presenting an affordance for a user to designate search parameters via an interaction with set(s) of reaction icons, techniques described herein eliminate the need for a user to recall a term, user, virtual space, date, reaction icon name and/or definition, and/or the like. As such, search queries can be more accurate and/or precise, thereby reducing the number of interactions required to retrieve content via a search. This can conserve bandwidth and computing resources. Moreover, by determining and/or presenting relevant information, users need not navigate through various search parameter possibilities and search results can be more accurate and/or precise (due to search queries being more accurate and/or precise). As such, techniques described herein offer improvements over conventional search technologies.</p><heading id="h-0004" level="1">CONCLUSION</heading><p id="p-0125" num="0124">While one or more examples of the techniques described herein have been described, various alterations, additions, permutations and equivalents thereof are included within the scope of the techniques described herein.</p><p id="p-0126" num="0125">In the description of examples, reference is made to the accompanying drawings that form a part hereof, which show by way of illustration specific examples of the claimed subject matter. It is to be understood that other examples can be used and that changes or alterations, such as structural changes, can be made. Such examples, changes or alterations are not necessarily departures from the scope with respect to the intended claimed subject matter. While the steps herein can be presented in a certain order, in some cases the ordering can be changed so that certain inputs are provided at different times or in a different order without changing the function of the systems and methods described. The disclosed procedures could also be executed in different orders. Additionally, various computations that are herein need not be performed in the order disclosed, and other examples using alternative orderings of the computations could be readily implemented. In addition to being reordered, the computations could also be decomposed into sub-computations with the same results.</p><heading id="h-0005" level="1">Example Clauses</heading><p id="p-0127" num="0126">A. A method, implemented by at least one computing device of a communication platform, comprising: determining a set of reaction icons based at least in part on interaction data associated with content in the communication platform; causing presentation of at least the set of reaction icons via a user interface of the communication platform, wherein individual reaction icons associated with the set of reaction icons are selectable as search parameters in the user interface; receiving a selection of at least one reaction icon of the set of reaction icons; and in response to receiving the selection of the at least one reaction icon, initiating a search for content associated with the selection of the at least one reaction icon stored in a database associated with the communication platform.</p><p id="p-0128" num="0127">B. The method of paragraph A, wherein the set of reaction icons is a first set of reaction icons associated with a user of the communication platform.</p><p id="p-0129" num="0128">C. The method of paragraph B, further comprising causing presentation of a second set of reaction icons via the user interface, wherein the second set of reaction icons is associated with at least one different user of the communication platform.</p><p id="p-0130" num="0129">D. The method of any of paragraphs A-C, further comprising: determining, based at least in part on the interaction data, recency of interactions with individual reaction icons associated with the communication platform; and determining the set of reaction icons further based at least in part on the recency of interactions determined for the individual reaction icons.</p><p id="p-0131" num="0130">E. The method of any of paragraphs A-D, further comprising: determining, based at least in part on the interaction data, frequencies of interactions with individual reaction icons associated with the communication platform; and determining the set of reaction icons further based at least in part on the frequencies of interactions determined for the individual reaction icons.</p><p id="p-0132" num="0131">F. The method of any of paragraphs A-E, wherein the individual reaction icons are representative of at least one of an emoji or a reactji.</p><p id="p-0133" num="0132">G. The method of any of paragraphs A-F, further comprising causing, based at least in part on initiating the search of the database, one or more results to be presented via the user interface, wherein the one or more results are associated with the at least one reaction icon.</p><p id="p-0134" num="0133">H. A system comprising: one or more processors; and one or more non-transitory computer-readable media storing instructions that, when executed by the one or more processors, cause the system to perform operations comprising: determining a set of reaction icons based at least in part on interaction data associated with content in a communication platform; causing presentation of at least the set of reaction icons via a user interface of the communication platform, wherein individual reaction icons of the set of reaction icons are selectable as search parameters in the user interface; receiving a selection of at least one reaction icon of the set of reaction icons; and in response to receiving the selection of the at least one reaction icon, initiating a search for content associated with the selection of the at least one reaction icon stored in a database associated with the communication platform.</p><p id="p-0135" num="0134">I. The system of paragraph H, wherein the set of reaction icons is a first set of reaction icons associated with a user of the communication platform.</p><p id="p-0136" num="0135">J. The system of paragraph I, the operations further comprising causing presentation of a second set of reaction icons via the user interface, wherein the second set of reaction icons is associated with at least one different user of the communication platform.</p><p id="p-0137" num="0136">K. The system of any of paragraphs H-J, the operations further comprising: determining, based at least in part on the interaction data, recency of interactions with individual reaction icons associated with the communication platform; and determining the set of reaction icons further based at least in part on the recency of interactions determined for the individual reaction icons.</p><p id="p-0138" num="0137">L. The system of any of paragraphs H-K, the operations further comprising: determining, based at least in part on the interaction data, frequencies of interactions with individual reaction icons associated with the communication platform; and determining the set of reaction icons further based at least in part on the frequencies of interactions determined for the individual reaction icons.</p><p id="p-0139" num="0138">M. The system of any of paragraphs H-L, wherein the individual reaction icons are representative of at least one of an emoji or a reactji.</p><p id="p-0140" num="0139">N. The system of any of paragraphs H-M, the operations further comprising, causing, based at least in part on initiating the search of the database, one or more results to be presented via the user interface, wherein the one or more results are associated with the at least one reaction icon.</p><p id="p-0141" num="0140">O. One or more non-transitory computer-readable media storing instructions that, when executed by one or more processors, cause the one or more processors to perform operations comprising: determining a set of reaction icons based at least in part on interaction data associated with content in a communication platform; causing presentation of at least the set of reaction icons via a user interface of the communication platform, wherein individual reaction icons of the set of reaction icons are selectable as search parameters in the user interface; receiving a selection of at least one reaction icon of the set of reaction icons; and in response to receiving the selection of the at least one reaction icon, initiating a search for content associated with the selection of the at least one reaction icon stored in a database associated with the communication platform.</p><p id="p-0142" num="0141">P. The one or more non-transitory computer-readable media of paragraph O, wherein the set of reaction icons is a first set of reaction icons associated with a user of the communication platform.</p><p id="p-0143" num="0142">Q. The one or more non-transitory computer-readable media of paragraph P, the operations further comprising causing presentation of a second set of reaction icons via the user interface, wherein the second set of reaction icons is associated with at least one different user of the communication platform.</p><p id="p-0144" num="0143">R. The one or more non-transitory computer-readable media of any of paragraphs O-Q, the operations further comprising: determining, based at least in part on the interaction data, recency of interactions with individual reaction icons associated with the communication platform; and determining the set of reaction icons further based at least in part on the recency of interactions determined for the individual reaction icons.</p><p id="p-0145" num="0144">S. The one or more non-transitory computer-readable media of any of paragraphs O-R, the operations further comprising: determining, based at least in part on the interaction data, frequencies of interactions with individual reaction icons associated with the communication platform; and determining the set of reaction icons further based at least in part on the frequencies of interactions determined for the individual reaction icons.</p><p id="p-0146" num="0145">T. The one or more non-transitory computer-readable media of any of paragraphs O-S, wherein the individual reaction icons are representative of at least one of an emoji or a reactji.</p><p id="p-0147" num="0146">While the paragraphs above are described with respect to one particular implementation, it should be understood that, in the context of this document, the content of the paragraphs above can also be implemented via a method, device, system, a computer-readable medium, and/or another implementation. Additionally, any of paragraphs A-T may be implemented alone or in combination with any other one or more of the paragraphs A-T.</p><?detailed-description description="Detailed Description" end="tail"?></description><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method, implemented by at least one computing device of a communication platform, comprising:<claim-text>determining a set of reaction icons based at least in part on interaction data associated with content in the communication platform;</claim-text><claim-text>causing presentation of at least the set of reaction icons via a user interface of the communication platform, wherein individual reaction icons associated with the set of reaction icons are selectable as search parameters in the user interface;</claim-text><claim-text>receiving a selection of at least one reaction icon of the set of reaction icons; and</claim-text><claim-text>in response to receiving the selection of the at least one reaction icon, initiating a search for content associated with the selection of the at least one reaction icon stored in a database associated with the communication platform.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the set of reaction icons is a first set of reaction icons associated with a user of the communication platform.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising causing presentation of a second set of reaction icons via the user interface, wherein the second set of reaction icons is associated with at least one different user of the communication platform.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining, based at least in part on the interaction data, recency of interactions with individual reaction icons associated with the communication platform; and</claim-text><claim-text>determining the set of reaction icons further based at least in part on the recency of interactions determined for the individual reaction icons.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>determining, based at least in part on the interaction data, frequencies of interactions with individual reaction icons associated with the communication platform; and</claim-text><claim-text>determining the set of reaction icons further based at least in part on the frequencies of interactions determined for the individual reaction icons.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the individual reaction icons are representative of at least one of an emoji or a reactji.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising causing, based at least in part on initiating the search of the database, one or more results to be presented via the user interface, wherein the one or more results are associated with the at least one reaction icon.</claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A system comprising:<claim-text>one or more processors; and</claim-text><claim-text>one or more non-transitory computer-readable media storing instructions that, when executed by the one or more processors, cause the system to perform operations comprising:<claim-text>determining a set of reaction icons based at least in part on interaction data associated with content in a communication platform;</claim-text><claim-text>causing presentation of at least the set of reaction icons via a user interface of the communication platform, wherein individual reaction icons of the set of reaction icons are selectable as search parameters in the user interface;</claim-text><claim-text>receiving a selection of at least one reaction icon of the set of reaction icons; and</claim-text><claim-text>in response to receiving the selection of the at least one reaction icon, initiating a search for content associated with the selection of the at least one reaction icon stored in a database associated with the communication platform.</claim-text></claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the set of reaction icons is a first set of reaction icons associated with a user of the communication platform.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, the operations further comprising causing presentation of a second set of reaction icons via the user interface, wherein the second set of reaction icons is associated with at least one different user of the communication platform.</claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, the operations further comprising:<claim-text>determining, based at least in part on the interaction data, recency of interactions with individual reaction icons associated with the communication platform; and</claim-text><claim-text>determining the set of reaction icons further based at least in part on the recency of interactions determined for the individual reaction icons.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, the operations further comprising:<claim-text>determining, based at least in part on the interaction data, frequencies of interactions with individual reaction icons associated with the communication platform; and</claim-text><claim-text>determining the set of reaction icons further based at least in part on the frequencies of interactions determined for the individual reaction icons.</claim-text></claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the individual reaction icons are representative of at least one of an emoji or a reactji.</claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, the operations further comprising, causing, based at least in part on initiating the search of the database, one or more results to be presented via the user interface, wherein the one or more results are associated with the at least one reaction icon.</claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. One or more non-transitory computer-readable media storing instructions that, when executed by one or more processors, cause the one or more processors to perform operations comprising:<claim-text>determining a set of reaction icons based at least in part on interaction data associated with content in a communication platform;</claim-text><claim-text>causing presentation of at least the set of reaction icons via a user interface of the communication platform, wherein individual reaction icons of the set of reaction icons are selectable as search parameters in the user interface;</claim-text><claim-text>receiving a selection of at least one reaction icon of the set of reaction icons; and</claim-text><claim-text>in response to receiving the selection of the at least one reaction icon, initiating a search for content associated with the selection of the at least one reaction icon stored in a database associated with the communication platform.</claim-text></claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the set of reaction icons is a first set of reaction icons associated with a user of the communication platform.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00016">claim 16</claim-ref>, the operations further comprising causing presentation of a second set of reaction icons via the user interface, wherein the second set of reaction icons is associated with at least one different user of the communication platform.</claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, the operations further comprising:<claim-text>determining, based at least in part on the interaction data, recency of interactions with individual reaction icons associated with the communication platform; and</claim-text><claim-text>determining the set of reaction icons further based at least in part on the recency of interactions determined for the individual reaction icons.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, the operations further comprising:<claim-text>determining, based at least in part on the interaction data, frequencies of interactions with individual reaction icons associated with the communication platform; and</claim-text><claim-text>determining the set of reaction icons further based at least in part on the frequencies of interactions determined for the individual reaction icons.</claim-text></claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The one or more non-transitory computer-readable media of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the individual reaction icons are representative of at least one of an emoji or a reactji.</claim-text></claim></claims></us-patent-application>
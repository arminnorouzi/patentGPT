<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230004859A1-20230105.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20221221" date-publ="20230105"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20230004859</doc-number><kind>A1</kind><date>20230105</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>17365423</doc-number><date>20210701</date></document-id></application-reference><us-application-series-code>17</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>28</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>445</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>N</subclass><main-group>20</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc><further-cpc><classification-cpc><cpc-version-indicator><date>20190101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>16</main-group><subgroup>285</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>9</main-group><subgroup>44505</subgroup><symbol-position>L</symbol-position><classification-value>I</classification-value><action-date><date>20230105</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></further-cpc></classifications-cpc><invention-title id="d2e43">SYSTEMS AND METHODS TO CONFIGURE DEFAULTS BASED ON A MODEL</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>TOYOTA RESEARCH INSTITUTE, INC.</orgname><address><city>Los Altos</city><state>CA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Lyons</last-name><first-name>Kent</first-name><address><city>Los Altos</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Wu</last-name><first-name>Charlene C.</first-name><address><city>San Francisco</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Lee</last-name><first-name>Matthew</first-name><address><city>Mountain View</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Iliev</last-name><first-name>Rumen</first-name><address><city>Millbrae</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>Zhang</last-name><first-name>Yanxia</first-name><address><city>Foster City</city><state>CA</state><country>US</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>Weng</last-name><first-name>Yue</first-name><address><city>San Mateo</city><state>CA</state><country>US</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>TOYOTA RESEARCH INSTITUTE, INC.</orgname><role>02</role><address><city>Los Altos</city><state>CA</state><country>US</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A system and method for configuring a device includes using a machine learning model to generate a user behavior model based on user behavior data. The user behavior data may include time series data collected from user interactions with a first device, and the machine learning model may include a classification model configured to classify the user behavior data into the one or more classifications. A mapping may be created by training a machine learning model, using user behavior models from a plurality of users and device settings from the plurality of users, to identify one or more relationships between device settings and classifications of the user behavior data. The system and method configures one or more settings of a second device based on the user behavior model and the mapping.</p></abstract><drawings id="DRAWINGS"><figure id="Fig-EMI-D00000" num="00000"><img id="EMI-D00000" he="193.63mm" wi="143.59mm" file="US20230004859A1-20230105-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00001" num="00001"><img id="EMI-D00001" he="209.13mm" wi="145.63mm" file="US20230004859A1-20230105-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00002" num="00002"><img id="EMI-D00002" he="185.34mm" wi="130.56mm" file="US20230004859A1-20230105-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure><figure id="Fig-EMI-D00003" num="00003"><img id="EMI-D00003" he="107.70mm" wi="134.62mm" file="US20230004859A1-20230105-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/></figure></drawings><description id="description"><?summary-of-invention description="Summary of Invention" end="lead"?><heading id="h-0001" level="1">TECHNICAL FIELD</heading><p id="p-0002" num="0001">The present specification generally relates to systems and methods for configuring devices and, more specifically, using machine learning to generate user behavior models for automated configuration of devices.</p><heading id="h-0002" level="1">BACKGROUND</heading><p id="p-0003" num="0002">When a user initially uses an electronic device, some amount of configuration of the device is often necessary in order to accommodate user preferences. This configuration may be performed by the user directly changing device settings by interacting with a configuration interface or through a setup wizard that guides the user through the configuration process.</p><p id="p-0004" num="0003">In situations such as sharing public devices or renting devices for temporary use, reconfiguring each device to user preferences becomes tedious. Although device settings may be copied from one device to another in situations where different devices share a sufficiently similar hardware configuration, different devices frequently have differences in hardware and configuration options that make direct copying of configuration settings impossible. Thus when a user initially uses a new, shared, or rented device, they must choose to either configure the device manually or through a setup wizard, or simply accept differences in the device behavior that are contrary to user preferences.</p><p id="p-0005" num="0004">Accordingly, a need exists for alternative systems and methods of automatically configuring device settings.</p><heading id="h-0003" level="1">SUMMARY</heading><p id="p-0006" num="0005">In one embodiment, a method for configuring a device includes using a machine learning model to generate a user behavior model based on user behavior data. The user behavior data may include time series data collected from user interactions with a first device, the user behavior model may include one or more classifications of the user behavior data, and the machine learning model may include a classification model configured to classify the user behavior data into the one or more classifications. The method may further include creating a mapping between user behavior classifications and one or more settings and configuring one or more settings of a second device based on the user behavior model and the mapping.</p><p id="p-0007" num="0006">In another embodiment, the creating of the mapping further includes training a machine learning model, using user behavior models from a plurality of users and device settings from the plurality of users, to identify one or more relationships between device settings and classifications of the user behavior data.</p><p id="p-0008" num="0007">In yet another embodiment, the method further includes receiving one or more responses to questions presented to the user, identifying a user goal based on the one or more responses, and using the identified user goal to modify the user behavior model.</p><p id="p-0009" num="0008">In yet another embodiment, the method further includes training the machine learning model, using an unsupervised learning technique, to classify user behavior data of an individual user based on clustering identified in user behavior data of a plurality of individuals.</p><p id="p-0010" num="0009">In yet another embodiment, the method further includes configuring application settings of an application installed on the device based on the user behavior model and the mapping.</p><p id="p-0011" num="0010">Further embodiments include a computing device configured to perform the method steps of any of the methods described herein, and computer readable medium storing instructions that, when executed by the a processor, cause the processor to execute the method steps described herein.</p><p id="p-0012" num="0011">These and additional features provided by the embodiments described herein will be more fully understood in view of the following detailed description, in conjunction with the drawings.</p><?summary-of-invention description="Summary of Invention" end="tail"?><?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?><description-of-drawings><heading id="h-0004" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading><p id="p-0013" num="0012">The embodiments set forth in the drawings are illustrative and exemplary in nature and not intended to limit the subject matter defined by the claims. The following detailed description of the illustrative embodiments can be understood when read in conjunction with the following drawings, where like structure is indicated with like reference numerals and in which:</p><p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>1</b></figref> depicts a flow chart of an example method for generating user behavior models using machine learning classification and creating a mapping model for mapping the user behavior models to device settings, according to one or more embodiments shown and described herein;</p><p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a flow chart of an example method for configuring a second device based on a user behavior model created from user interactions with a first device, according to one or more embodiments shown and described herein;</p><p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a block diagram of an example computing device suitable for implementing the automatic configuration methods, according to one or more embodiments shown and described herein.</p></description-of-drawings><?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?><?detailed-description description="Detailed Description" end="lead"?><heading id="h-0005" level="1">DETAILED DESCRIPTION</heading><p id="p-0017" num="0016">The purpose of the disclosed embodiments is to automatically configure the settings of a device based on a model of a person. The device may comprise a vehicle, a mobile device, a software application, a display, an audio output device, or any other electronic device or electronically controlled device that has configuration settings.</p><p id="p-0018" num="0017">The closest technology either requires that a person manually configure a device, a previously configured device, or utilize a configuration process, such as a setup wizard, to configure the device. The disclosed embodiments comprise systems and methods that automatically make configuration decisions for a device based on a user behavior model of an individual, which may be the user of the device. The model of the person may be learned prior, does not need to be manually specified, and can be applied in a way consistent with the person's overall goals and desires.</p><p id="p-0019" num="0018">The system and method first generate a user behavior model. The user behavior model may be created based on one or more of user behavior data collected from user interactions with other devices or preference questions presented to the user. User behavior data may be retrieved from a database of prior behaviors recorded about the user. The preference questions may be designed to extract long-term goals to be encompassed in the user behavior model. For example, the user might have certain goals they want to meet (e.g., saving money or spending less time on social media), so questions that feed into the user behavior model may override recorded user behavior to facilitate desired future behavior. The model may be created by utilizing machine learning.</p><p id="p-0020" num="0019">A mapping between user behavior data or user behavior models and device settings may be used to automatically configure the device based on the a user behavior model. The mapping may be created based on user behavior data collected from a plurality of individuals interactions with a variety of devices. As a non-limiting example, a database of driving behaviors from many individuals (braking style, route selections, etc.) may be mapped onto vehicle settings (braking profiles, acceleration curves, navigation settings). When a new user interacts with the vehicle, the system and method may utilize data collected from the new user's interactions with another vehicle and automatically configure the current vehicle using the machine-learned mapping between user behavior and settings.</p><p id="p-0021" num="0020">In another non-limiting example, related to mobile phones, one user may want to be more deliberate about their phone usage, while another user may want to stay on top of everything. These two different users would likely have different settings for their phone or potentially for each app. The system and method can utilize these individuals' past behaviors as input for generating user behavior models for each individual and provide likely defaults for any new installed apps consistent with their current usage or overall usage goals.</p><p id="p-0022" num="0021">Various embodiments of the system and method for automatically configuring device settings will be described in more detail herein.</p><p id="p-0023" num="0022">Referring now to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, which depicts a flow chart <b>100</b> of generating user behavior models and a mapping model, a user may generate user behavior data by interacting with a one or more devices. According to some embodiments, the process of generating a user behavior model may begin with user interactions with devices <b>101</b>. The devices referred to herein may comprise a vehicle, a mobile device, a personal computer, a wearable device, a display device, and audio output device, or any device with electronically configurable device settings. Devices my further include any electronic or electronically controlled device. These devices tend to include hardware components that can be monitored, logged, configured and controlled. Although user behavior data may come from a plurality of devices, for simplicity, examples will be described with reference to a first device.</p><p id="p-0024" num="0023">User interactions with the first device may include any interaction that may be logged. If the first device is a mobile device with a touch interface, user interactions may comprise touching, tapping, dragging, and other gestures. User interactions may also include voice commands, biometric actions, time spent using different applications, user movements, or location data. If the first device is a vehicle, the interactions may comprise accelerating, braking, turning, or any user interactions with the vehicle systems. A person of ordinary skill in the art will understand that different devices may be capable of different interactions with the user and a user interaction, as used herein, is intended to include those interactions, without limitation.</p><p id="p-0025" num="0024">Time series user behavior data of a plurality of users <b>102</b> may be extracted from the user interactions with devices <b>101</b>. Each user may interact with the same first device or different devices that are copies of the first device with sufficient hardware similarities to record similar user interactions. As non-limiting examples, a plurality of users may interact with a single vehicle or a set of vehicles or the plurality of users may interact with a mobile device or a set of mobile devices. Thus, time series user behavior data of the plurality of users <b>102</b> may come from user interactions of a plurality of users with one or more devices.</p><p id="p-0026" num="0025">This time series user behavior data of the plurality of users <b>102</b> may be processed using machine learning classification <b>105</b> to generate behavior models of the plurality of users. According to some embodiments, the machine learning classification <b>105</b> may use unsupervised learning <b>104</b>, such as clustering, on the time series user behavior data of the plurality of users <b>102</b> to identify classifications of the user behavior data. For example, the system may create a machine learning classification model by monitoring large groups of users' behavior data. The large group of users may be broken down into different subgroups that appear to have similar goals. As such, users within the subgroups may have their devices configured similarly. Subgroups of users can be broken down in several different ways. For example, subgroups can be broken down by common behaviors, employer, occupations, recent purchases, entertainment choices, age, or any other distinguishing characteristic.</p><p id="p-0027" num="0026">Although the unsupervised learning <b>104</b> of <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates identification of clustering on two dimensions, dimension A and dimension B, this is for illustration purposes only, and a person of ordinary skill in the art will recognize that three or more dimensions may be used to identify clustering and other unsupervised learning methods may be used. Unsupervised learning may comprise parametric or non-parametric unsupervised learning. As non-limiting examples, the unsupervised learning <b>104</b> may comprise clustering, neural networks, and latent variable learning models. The clustering methods may further comprise exclusive clustering, hierarchical clustering, overlapping clustering, probabilistic clustering, k-means, Gaussian mixture models, DBSCAN, and OPTICS algorithms. Latent variable learning methods may comprise expectation-maximization algorithms, method of moments, principal component analysis, independent component analysis, non-negative matrix factorization, and singular value decomposition.</p><p id="p-0028" num="0027">The machine learning classification <b>105</b> of user behavior data generates a behavior model for each of the plurality of users. The behavior models are illustrated as BM<b>1</b> <b>106</b><i>a</i>, BM<b>2</b> <b>106</b><i>b</i>, BM<b>3</b> <b>106</b><i>c</i>, BM<b>4</b> <b>106</b><i>d </i>and BMn <b>106</b><i>n </i>in <figref idref="DRAWINGS">FIG. <b>1</b></figref>. According to some embodiments, these behavior models are used in combination with device settings in training a mapping model <b>108</b>.</p><p id="p-0029" num="0028">Device settings from the plurality of users <b>103</b> may also be collected from the one or more devices used to collect the user interactions with the devices <b>101</b>. As a non-limiting example, device settings may be collected from configuration files stored in an a memory of the first device. Individual device settings, S<b>1</b> <b>107</b><i>a</i>, S<b>2</b> <b>107</b><i>b</i>, S<b>3</b> <b>107</b><i>c</i>, S<b>4</b> <b>107</b><i>d </i>and Sn <b>107</b><i>n</i>, may be extracted for each of the plurality of users. According to some embodiments, these device settings. S<b>1</b> <b>107</b><i>a</i>, S<b>2</b> <b>107</b><i>b</i>, S<b>3</b> <b>107</b><i>c</i>, S<b>4</b> <b>107</b><i>d </i>and Sn <b>107</b><i>n</i>, are used in combination with user behavior models, BM<b>1</b> <b>106</b><i>a</i>, BM<b>2</b> <b>106</b><i>b</i>, BM<b>3</b> <b>106</b><i>c</i>, BM<b>4</b> <b>106</b><i>d </i>and BMn <b>106</b><i>n</i>, in training a mapping model <b>108</b>.</p><p id="p-0030" num="0029">Training of the mapping model <b>108</b> may include supervised machine learning or statistical methods for identifying correlations in data. As a non-limiting example, the training of the mapping model <b>108</b> may comprise using supervised learning techniques with a classification model to classify one or more behaviors in the user behavior data into classifications of device settings. The behavioral models may be used as inputs when training the mapping model <b>108</b>, and the settings may be used to determine and minimize an error in the outputs of the classification model. As another non-limiting example, the training of the mapping model <b>108</b> may comprise training a prediction model, using the behavior models and associated device settings, to predict the device settings based on the behavioral model as an input. A person of ordinary skill in the art will understand that one or more machine learning models may be used in the training of the mapping model <b>108</b>.</p><p id="p-0031" num="0030">The training of the mapping model, using user behavior data and device settings <b>108</b> generates a mapping model <b>109</b>, which can then be used for generating device settings based on an input of a behavioral model. Once the mapping model <b>109</b> is generated, the mapping model <b>109</b> may be applied to any new user behavior model generated, based on user behavior data, using the machine learning classification <b>105</b>.</p><p id="p-0032" num="0031">In summary, a user may interact with a first device and generate user behavior data that can be classified, using machine learning, into a user behavior model. The behavior model may then be input into the mapping model <b>109</b>. The mapping model may generate device settings for a second device, customized to the user's preferences, based on the user behavior model. The process using a user's interactions with a first device to generate a user behavior model used to automatically configure settings of a second device is described in greater detail with reference to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p><p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a flow chart of a method for configuring a second device based on a user behavior model created from user interactions with a first device, according to one or more embodiments shown and described herein. The method of <figref idref="DRAWINGS">FIG. <b>2</b></figref> may be performed by any computing device, as described herein, or equivalents. First, the computing device collects user interactions with the first device <b>201</b>. According to some embodiments, the user interactions may be collected and recorded by the first device or transmitted by the first device to a remote server for storage and/or processing. As a non-limiting example, the first device may comprise a vehicle, and user interactions with the first device may comprise acceleration and braking behavior. A processor may collect accelerator position data, brake pedal position data, and vehicle dynamics data such as speed, RPM, and g-forces in three dimensions. This time series user behavior data <b>202</b> comprises a representation of the user's preferences that may be inferred from the user's behavior as captured by interactions with the vehicle.</p><p id="p-0034" num="0033">The user interactions with the first device <b>201</b> generate time series user behavior data. The user behavior data may comprise any type of data collected from user interactions, including, but not limited to, all inputs and outputs of the device with associated time stamps and/or durations.</p><p id="p-0035" num="0034">The time series user behavior data <b>202</b> is processed through machine learning classification <b>203</b> to generate a user behavior model. Returning to the vehicle example, the user behavior model <b>204</b> generated based on time series user behavior data <b>202</b> gathered from user interactions with the vehicle comprises a representation of expected or desired behavior of the vehicle.</p><p id="p-0036" num="0035">According to some embodiments, the computing device may optionally present questions to the user in order to identify user goals. The user goals may be used to modify the behavior model <b>204</b> to better achieve the user's desired device behavior. In the vehicle example, the questions may comprise questions about braking behavior (late braking, or early braking), desired driving behavior, comfort, or performance level. As further non-limiting examples, questions presented to the user may include questions about a user's desire to increase or decrease device usage, or questions about limiting the time of a particular application. User responses <b>205</b> to the questions may be used to generate a modified user behavior model <b>206</b>. Alternatively, user responses <b>205</b> may be fed into the machine learning classification <b>203</b> in order to generate a modified user behavior model <b>206</b>.</p><p id="p-0037" num="0036">The user behavior model <b>204</b> may be input to the mapping process <b>207</b>. The mapping process <b>207</b> may use a mapping model to generate device settings <b>208</b> for a second device based on the user behavior model <b>204</b> or the modified user behavior model <b>206</b>. The second device is configured <b>209</b> based on the user behavior model <b>204</b> or the modified user behavior model <b>206</b> and the mapping process <b>207</b>. Returning to the vehicle example, a second vehicle may be automatically configured to exhibit braking and acceleration behavior similar to the first vehicle, as defined by the user behavior model <b>204</b>. The user behavior model <b>204</b> may capture user inputs and the vehicle response to user inputs, and the mapping process <b>207</b> may configure the second vehicle to respond similarly to the first vehicle when given similar inputs from the user.</p><p id="p-0038" num="0037">As a further example, using the systems and methods described herein, a second user may use a second user behavior model to automatically configure the same device, such as a vehicle, to the second user's preferences. Thus any user that uses the device can have the device automatically configured to that user's preferences without using a setup wizard or resorting to manual configuration. The system and method may also partially configure the settings of the device based on the user behavior model <b>204</b> or the modified user behavior model <b>206</b>. The system and method may prompt the user for a preferred setting for settings that are not set based on the model.</p><p id="p-0039" num="0038">According to some embodiments, the first device may collect and store the time series user behavior data, and use a local or remotely-hosted machine learning classification service to generate the user behavior model. This user behavior model may be stored on the first device, or stored in remote storage. The user behavior model may then be copied to the second device, which may use the mapping process to generate device settings and configured the second device. A person of ordinary skill in the art will understand that the steps of collecting user behavior data, generating a user behavior model, and mapping the user behavior model to device settings may be performed using processors of the first device, the second device, a remote device, or any combination thereof.</p><p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>3</b></figref> depicts a block diagram of a computing device suitable for implementing the automatic configuration methods, according to one or more embodiments shown and described herein. As shown, a computing device <b>300</b> may include a processor <b>302</b>, and data storage <b>304</b> including instructions <b>305</b>. The computing device may further include a communication interface <b>306</b>, a sensor <b>308</b>, and a user interface <b>310</b>, each of which are communicatively connected via a system bus <b>312</b>. Any component or combination of components of the disclosed embodiments may take the form of or include a computing device <b>300</b>. It should be understood that computing device <b>300</b> may include different and/or additional components, and some or all of the functions of a given component could instead be carried out by one or more different components. Computing device <b>300</b> may take the form of (or include) a virtual computing device or one or more computing resources in a cloud computing environment. Additionally, computing device <b>300</b> could take the form of (or include) a plurality of computing devices of any form, and some or all of the functions of a given component could be carried out by any combination of one or more of the computing devices in the plurality.</p><p id="p-0041" num="0040">Processor <b>302</b> may take the form of one or more general-purpose processors and/or one or more special-purpose processors, and may be integrated in whole or in part with data storage <b>304</b>, communication interface <b>306</b>, sensor <b>308</b>, user interface <b>310</b>, and/or any other component of computing device <b>300</b>, as examples. Accordingly, processor <b>302</b> may take the form of or include a controller, an integrated circuit, a microchip, a central processing unit (CPU), a microprocessor, a system on a chip (SoC), a field-programmable gate array (FPGA), and/or an application-specific integrated circuit (ASIC), among other possibilities.</p><p id="p-0042" num="0041">Data storage <b>304</b> may take the form of a non-transitory computer-readable storage medium such as a hard drive, a solid-state drive, an erasable programmable read-only memory (EPROM), a universal serial bus (USB) storage device, a compact disc read-only memory (CD-ROM) disk, a digital versatile disc (DVD), a relational database management system (RDBMS), any other non-volatile storage, or any combination of these, to name just a few examples.</p><p id="p-0043" num="0042">Instructions <b>305</b> may be stored in data storage <b>304</b>, and may include machine-language instructions executable by processor <b>302</b> to cause computing device <b>300</b> to perform the computing-device functions described herein. Additionally or alternatively, instructions <b>305</b> may include script instructions executable by a script interpreter configured to cause processor <b>302</b> and computing device <b>300</b> to execute the instructions specified in the script instructions. According to some embodiments, the instructions include instructions executable by the processor to cause the computing device to execute an artificial neural network. It should be understood that instructions <b>305</b> may take other forms as well.</p><p id="p-0044" num="0043">Additional data may be stored in data storage <b>304</b>, such as databases, data structures, data lakes, and/or network parameters of a neural network. The additional data could be stored such as a table, a flat file, data in a file system of the data storage, a heap file, a B+ tree, a hash table, a hash bucket, or any combination of these, as examples.</p><p id="p-0045" num="0044">Communication interface <b>306</b> may be any component capable of performing the communication-interface functions described herein, including facilitating wired and/or wireless communication between computing device <b>300</b> and another entity. As such, communication interface <b>306</b> could take the form of an Ethernet, Wi-Fi, Bluetooth, and/or USB interface, among many other examples. Communication interface <b>306</b> may receive data over a network via communication links, for instance.</p><p id="p-0046" num="0045">Sensor <b>308</b> could take the form of one or more sensors operable to perform any of the data collection functions described herein. The sensor could be positioned on a vehicle, including an interior and/or exterior of a vehicle. Though sensor <b>308</b> may be referenced in the singular throughout this disclosure, it should be understood that sensor <b>308</b> may take the form of (or include) a single sensor or multiple sensors.</p><p id="p-0047" num="0046">The sensor could include a radar sensor, a LIDAR sensor, a camera, an accelerometer, a speedometer, or any combination of these or other sensors. The radar sensor, LIDAR sensor, and/or camera may obtain signals (such as electromagnetic radiation) that can be used by computing device <b>300</b> to obtain information relevant to vehicle control. Additionally or alternatively, the accelerometer and the speedometer may be used to detect an acceleration and a speed of a vehicle. Sensor <b>308</b> may take other forms as well.</p><p id="p-0048" num="0047">User interface <b>310</b> may be any component capable of carrying out the user-interface functions described herein. For example, the user interface may be configured to receive input from a user and/or output information to the user. Output may be provided via a computer monitor, a loudspeaker (such as a computer speaker), or another component of (or communicatively linked to) computing device <b>300</b>. User input might be achieved via a keyboard, a mouse, or other component communicatively linked to the computing device. As another possibility, input may be realized via a touchscreen display of the computing device in the form of a smartphone or tablet device. Some components may provide for both input and output, such as the aforementioned touchscreen display. It should be understood that user interface <b>310</b> may take numerous other forms as well.</p><p id="p-0049" num="0048">System bus <b>312</b> may be any component capable of performing the system-bus functions described herein. In an embodiment, system bus <b>312</b> is any component configured to transfer data between processor <b>302</b>, data storage <b>304</b>, communication interface <b>306</b>, sensor <b>308</b>, user interface <b>310</b>, and/or any other component of computing device <b>300</b>. In an embodiment, system bus <b>312</b> includes a traditional bus as is known in the art. In other embodiments, system bus <b>312</b> includes a serial RS-232 communication link, a USB communication link, and/or an Ethernet communication link, alone or in combination with a traditional computer bus, among numerous other possibilities. In some examples, system bus <b>312</b> may be formed from any medium that is capable of transmitting a signal, such as conductive wires, conductive traces, or optical waveguides, among other possibilities. Moreover, system bus <b>312</b> may be formed from a combination of mediums capable of transmitting signals. The system bus could take the form of (or include) a vehicle bus, such as a local interconnect network (LIN) bus, a controller area network (CAN) bus, a vehicle area network (VAN) bus, or any combination of these or mediums. It should be understood that system bus <b>312</b> may take various other forms as well.</p><p id="p-0050" num="0049">It is noted that the terms &#x201c;substantially&#x201d; and &#x201c;about&#x201d; may be utilized herein to represent the inherent degree of uncertainty that may be attributed to any quantitative comparison, value, measurement, or other representation. These terms are also utilized herein to represent the degree by which a quantitative representation may vary from a stated reference without resulting in a change in the basic function of the subject matter at issue.</p><p id="p-0051" num="0050">While particular embodiments have been illustrated and described herein, it should be understood that various other changes and modifications may be made without departing from the spirit and scope of the claimed subject matter. Moreover, although various aspects of the claimed subject matter have been described herein, such aspects need not be utilized in combination. It is therefore intended that the appended claims cover all such changes and modifications that are within the scope of the claimed subject matter.</p><?detailed-description description="Detailed Description" end="tail"?></description><us-claim-statement>What is claimed is:</us-claim-statement><claims id="claims"><claim id="CLM-00001" num="00001"><claim-text><b>1</b>. A method for configuring a device, the method comprising:<claim-text>using a machine learning model to generate a user behavior model based on user behavior data,</claim-text><claim-text>wherein the user behavior data comprises time series data collected from user interactions with a first device,</claim-text><claim-text>wherein the user behavior model comprises one or more classifications of the user behavior data, and</claim-text><claim-text>wherein the machine learning model comprises a classification model configured to classify the user behavior data into the one or more classifications;</claim-text><claim-text>creating a mapping between user behavior classifications and one or more settings; and</claim-text><claim-text>configuring one or more settings of a second device based on the user behavior model and the mapping.</claim-text></claim-text></claim><claim id="CLM-00002" num="00002"><claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the creating of the mapping comprises mapping the one or more classifications of user behavior data to one or more device settings.</claim-text></claim><claim id="CLM-00003" num="00003"><claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the creating of the mapping further comprises training a machine learning model, using user behavior models from a plurality of users and device settings from the plurality of users, to identify one or more relationships between device settings and classifications of the user behavior data.</claim-text></claim><claim id="CLM-00004" num="00004"><claim-text><b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>receiving one or more responses to questions presented to the user,</claim-text><claim-text>identifying a user goal based on the one or more responses; and</claim-text><claim-text>using the identified user goal to modify the user behavior model.</claim-text></claim-text></claim><claim id="CLM-00005" num="00005"><claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>training the machine learning model, using an unsupervised learning technique, to classify user behavior data of an individual user based on clustering identified in user behavior data of a plurality of individuals.</claim-text></claim-text></claim><claim id="CLM-00006" num="00006"><claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the user behavior model further comprises one or more sub-classifications of the user behavior data.</claim-text></claim><claim id="CLM-00007" num="00007"><claim-text><b>7</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:<claim-text>further configuring application settings of an application installed on the device based on the user behavior model and the mapping.</claim-text></claim-text></claim><claim id="CLM-00008" num="00008"><claim-text><b>8</b>. A system for configuring a device, the system comprising:<claim-text>a processor; and</claim-text><claim-text>memory storing instructions that, when executed by the processor, cause the processor to perform steps of:</claim-text><claim-text>using a machine learning model to generate a user behavior model based on user behavior data,</claim-text><claim-text>wherein the user behavior data comprises time series data collected from user interactions with a first device,</claim-text><claim-text>wherein the user behavior model comprises one or more classifications of the user behavior data, and</claim-text><claim-text>wherein the machine learning model comprises a classification model configured to classify the user behavior data into the one or more classifications;</claim-text><claim-text>creating a mapping between user behavior classifications and one or more settings; and</claim-text><claim-text>configuring one or more settings of a second device based on the user behavior model and the mapping.</claim-text></claim-text></claim><claim id="CLM-00009" num="00009"><claim-text><b>9</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the creating of the mapping further comprises training a machine learning model, using user behavior models from a plurality of users and device settings from the plurality of users, to identify one or more relationships between device settings and classifications of the user behavior data.</claim-text></claim><claim id="CLM-00010" num="00010"><claim-text><b>10</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the processor further performs steps of:<claim-text>receiving one or more responses to questions presented to the user;</claim-text><claim-text>identifying a user goal based on the one or more responses; and</claim-text><claim-text>using the identified user goal to modify the user behavior model.</claim-text></claim-text></claim><claim id="CLM-00011" num="00011"><claim-text><b>11</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the processor further performs steps of:<claim-text>training the machine learning model, using an unsupervised learning technique, to classify user behavior data of an individual user based on clustering identified in user behavior data of a plurality of individuals.</claim-text></claim-text></claim><claim id="CLM-00012" num="00012"><claim-text><b>12</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the user behavior model further comprises one or more sub-classifications of the user behavior data.</claim-text></claim><claim id="CLM-00013" num="00013"><claim-text><b>13</b>. The system of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the processor further performs steps of:<claim-text>further configuring application settings of an application installed on the device based on the user behavior model and the mapping.</claim-text></claim-text></claim><claim id="CLM-00014" num="00014"><claim-text><b>14</b>. A non-transitory computer-readable medium storing instructions that, when executed by a processor, cause the processor to perform steps of:<claim-text>using a machine learning model to generate a user behavior model based on user behavior data,</claim-text><claim-text>wherein the user behavior data comprises time series data collected from user interactions with a first device,</claim-text><claim-text>wherein the user behavior model comprises one or more classifications of the user behavior data, and</claim-text><claim-text>wherein the machine learning model comprises a classification model configured to classify the user behavior data into the one or more classifications;</claim-text><claim-text>creating a mapping between user behavior classifications and one or more settings; and</claim-text><claim-text>configuring one or more settings of a second device based on the user behavior model and the mapping.</claim-text></claim-text></claim><claim id="CLM-00015" num="00015"><claim-text><b>15</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the creating of the mapping comprises mapping the one or more classifications of user behavior data to one or more device settings.</claim-text></claim><claim id="CLM-00016" num="00016"><claim-text><b>16</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the creating of the mapping further comprises training a machine learning model, using user behavior models from a plurality of users and device settings from the plurality of users, to identify one or more relationships between device settings and classifications of the user behavior data.</claim-text></claim><claim id="CLM-00017" num="00017"><claim-text><b>17</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, storing further instructions that, when executed by the processor, cause the processor to further perform steps of:<claim-text>receiving one or more responses to questions presented to the user;</claim-text><claim-text>identifying a user goal based on the one or more responses; and</claim-text><claim-text>using the identified user goal to modify the user behavior model.</claim-text></claim-text></claim><claim id="CLM-00018" num="00018"><claim-text><b>18</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, storing further instructions that, when executed by the processor, cause the processor to further perform steps of:<claim-text>training the machine learning model, using an unsupervised learning technique, to classify user behavior data of an individual user based on clustering identified in user behavior data of a plurality of individuals.</claim-text></claim-text></claim><claim id="CLM-00019" num="00019"><claim-text><b>19</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the user behavior model further comprises one or more sub-classifications of the user behavior data.</claim-text></claim><claim id="CLM-00020" num="00020"><claim-text><b>20</b>. The non-transitory computer-readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, storing further instructions that, when executed by the processor, cause the processor to further perform steps of:<claim-text>further configuring application settings of an application installed on the device based on the user behavior model and the mapping.</claim-text></claim-text></claim></claims></us-patent-application>